{
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Object-Centric_Video_Representation_for_Long-Term_Action_Anticipation_WACV_2024_paper.html": {
    "title": "Object-Centric Video Representation for Long-Term Action Anticipation",
    "volume": "main",
    "abstract": "This paper focuses on building object-centric representations for long-term action anticipation in videos. Our key motivation is that objects provide important cues to recognize and predict human-object interactions, especially when the predictions are longer term, as an observed \"background\" object could be used by the human actor in the future. We observe that existing object-based video recognition frameworks either assume the existence of in-domain supervised object detectors or follow a fully weakly-supervised pipeline to infer object locations from action labels. We propose to build object-centric video representations by leveraging visual-language pretrained models. This is achieved by \"object prompts\", an approach to extract task-specific object-centric representations from general-purpose pretrained models without finetuning. To recognize and predict human-object interactions, we use a Transformer-based neural architecture which allows the \"retrieval\" of relevant objects for action anticipation at various time scales. We conduct extensive evaluations on the Ego4D, 50Salads, and EGTEA Gaze+ benchmarks. Both quantitative and qualitative results confirm the effectiveness of our proposed method",
    "checked": true,
    "id": "1fe7a8fdba3d5300e1a7a6a72b1efcb8b4a66d95",
    "semantic_title": "object-centric video representation for long-term action anticipation",
    "citation_count": 0,
    "authors": [
      "Ce Zhang",
      "Changcheng Fu",
      "Shijie Wang",
      "Nakul Agarwal",
      "Kwonjoon Lee",
      "Chiho Choi",
      "Chen Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Honda_CLRerNet_Improving_Confidence_of_Lane_Detection_With_LaneIoU_WACV_2024_paper.html": {
    "title": "CLRerNet: Improving Confidence of Lane Detection With LaneIoU",
    "volume": "main",
    "abstract": "Lane marker detection is a crucial component of the autonomous driving and driver assistance systems. Modern deep lane detection methods with anchor-based lane representation exhibit excellent performance on lane detection benchmarks. Through preliminary oracle experiments, we firstly disentangle the lane representation components to determine the direction of our approach. We show that correct lane positions are already among the predictions of an existing anchor-based detector, and the confidence scores that accurately represent intersection-over-union (IoU) with ground truths are the most beneficial. Based on the finding, we propose LaneIoU that better correlates with the metric, by taking the local lane angles into consideration. We develop a novel detector coined CLRerNet featuring LaneIoU for the target assignment cost and loss functions aiming at the improved quality of confidence scores. Through careful and fair benchmark including cross validation, we demonstrate that CLRerNet outperforms the state-of-the-art by a large margin - enjoying F1 score of 81.43% compared with 80.47% of the existing method on CULane, and 86.47% compared with 86.10% on CurveLanes",
    "checked": true,
    "id": "13f1b60bbb44e0e33e3fab8e9c39077e2d918287",
    "semantic_title": "clrernet: improving confidence of lane detection with laneiou",
    "citation_count": 2,
    "authors": [
      "Hiroto Honda",
      "Yusuke Uchida"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Stojnic_Training_Ensembles_With_Inliers_and_Outliers_for_Semi-Supervised_Active_Learning_WACV_2024_paper.html": {
    "title": "Training Ensembles With Inliers and Outliers for Semi-Supervised Active Learning",
    "volume": "main",
    "abstract": "Deep active learning in the presence of outlier examples poses a realistic yet challenging scenario. Acquiring unlabeled data for annotation requires a delicate balance between avoiding outliers to conserve the annotation budget and prioritizing useful inlier examples for effective training. In this work, we present an approach that leverages three highly synergistic components, which are identified as key ingredients: joint classifier training with inliers and outliers, semi-supervised learning through pseudo-labeling, and model ensembling. Our work demonstrates that ensembling significantly enhances the accuracy of pseudo-labeling and improves the quality of data acquisition. By enabling semi-supervision through the joint training process, where outliers are properly handled, we observe a substantial boost in classifier accuracy through the use of all available unlabeled examples. Notably, we reveal that the integration of joint training renders explicit outlier detection unnecessary; a conventional component for acquisition in prior work. The three key components align seamlessly with numerous existing approaches. Through empirical evaluations, we showcase that their combined use leads to a performance increase. Remarkably, despite its simplicity, our proposed approach outperforms all other methods in terms of performance. Code: https://github.com/vladan-stojnic/active-outliers",
    "checked": true,
    "id": "6890bf5890f95d5f3d2a819f150f54d0cf304a03",
    "semantic_title": "training ensembles with inliers and outliers for semi-supervised active learning",
    "citation_count": 0,
    "authors": [
      "Vladan Stojnić",
      "Zakaria Laskar",
      "Giorgos Tolias"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Robust_Source-Free_Domain_Adaptation_for_Fundus_Image_Segmentation_WACV_2024_paper.html": {
    "title": "Robust Source-Free Domain Adaptation for Fundus Image Segmentation",
    "volume": "main",
    "abstract": "Unsupervised Domain Adaptation (UDA) is a learning technique that transfers knowledge learned in the source domain from labelled training data to the target domain with only unlabelled data. It is of significant importance to medical image segmentation because of the usual lack of labelled training data. Although extensive efforts have been made to optimize UDA techniques to improve the accuracy of segmentation models in the target domain, few studies have addressed the robustness of these models under UDA. In this study, we propose a two-stage training strategy for robust domain adaptation. In the source training stage, we utilize adversarial sample augmentation to enhance the robustness and generalization capability of the source model. And in the target training stage, we propose a novel robust pseudo-label and pseudo-boundary (PLPB) method, which effectively utilizes unlabeled target data to generate pseudo labels and pseudo boundaries that enable model self-adaptation without requiring source data. Extensive experimental results on cross-domain fundus image segmentation confirm the effectiveness and versatility of our method. Source code of this study is openly accessible at https://github.com/LinGrayy/PLPB",
    "checked": true,
    "id": "2314a9c503d2c4fd8d8b555dc7d7730f7399b3a8",
    "semantic_title": "robust source-free domain adaptation for fundus image segmentation",
    "citation_count": 0,
    "authors": [
      "Lingrui Li",
      "Yanfeng Zhou",
      "Ge Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Iwai_Controlling_Rate_Distortion_and_Realism_Towards_a_Single_Comprehensive_Neural_WACV_2024_paper.html": {
    "title": "Controlling Rate, Distortion, and Realism: Towards a Single Comprehensive Neural Image Compression Model",
    "volume": "main",
    "abstract": "In recent years, neural network-driven image compression (NIC) has gained significant attention. Some works adopt deep generative models such as GANs and diffusion models to enhance perceptual quality (realism). A critical obstacle of these generative NIC methods is that each model is optimized for a single bit rate. Consequently, multiple models are required to compress images to different bit rates, which is impractical for real-world applications. To tackle this issue, we propose a variable-rate generative NIC model. Specifically, we explore several discriminator designs tailored for the variable-rate approach and introduce a novel adversarial loss. Moreover, by incorporating the newly proposed multi-realism technique, our method allows the users to adjust the bit rate, distortion, and realism with a single model, achieving ultra-controllability. Unlike existing variable-rate generative NIC models, our method matches or surpasses the performance of state-of-the-art single-rate generative NIC models while covering a wide range of bit rates using just one model",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shoma Iwai",
      "Tomo Miyazaki",
      "Shinichiro Omachi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lim_MetaVers_Meta-Learned_Versatile_Representations_for_Personalized_Federated_Learning_WACV_2024_paper.html": {
    "title": "MetaVers: Meta-Learned Versatile Representations for Personalized Federated Learning",
    "volume": "main",
    "abstract": "One of the daunting challenges in federated learning (FL) is the heterogeneity across clients that hinders the successful federation of a global model. When the heterogeneity becomes worse, personalized federated learning (PFL) pursues to detour the hardship of capturing the commonality across clients by allowing the personalization of models built upon the federation. In the scope of PFL for visual models, on the contrary, the recent effort for aggregating an effective global representation rather than chasing further personalization draws great attention. Along the same lines, we aim to train a large-margin global representation with a strong generalization across clients by adopting the meta-learning framework and margin-based loss, which are widely accepted to be effective in handling multiple visual tasks. Our method called MetVers achieves state-of-the-art accuracies for the PFL benchmarks with the CIFAR-10, CIFAR-100, and CINIC-10 datasets while showing robustness against data reconstruction attacks. Noteworthy, the versatile representation of MetaVers exhibits a strong generalization when tested on new clients with novel classes",
    "checked": true,
    "id": "6f22e99f67adbc8cf39b4c53fd3b875012473fb7",
    "semantic_title": "metavers: meta-learned versatile representations for personalized federated learning",
    "citation_count": 0,
    "authors": [
      "Jin Hyuk Lim",
      "SeungBum Ha",
      "Sung Whan Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wallin_Improving_Open-Set_Semi-Supervised_Learning_With_Self-Supervision_WACV_2024_paper.html": {
    "title": "Improving Open-Set Semi-Supervised Learning With Self-Supervision",
    "volume": "main",
    "abstract": "Open-set semi-supervised learning (OSSL) embodies a practical scenario within semi-supervised learning, wherein the unlabeled training set encompasses classes absent from the labeled set. Many existing OSSL methods assume that these out-of-distribution data are harmful and put effort into excluding data belonging to unknown classes from the training objective. In contrast, we propose an OSSL framework that facilitates learning from all unlabeled data through self-supervision. Additionally, we utilize an energy-based score to accurately recognize data belonging to the known classes, making our method well-suited for handling uncurated data in deployment. We show through extensive experimental evaluations that our method yields state-of-the-art results on many of the evaluated benchmark problems in terms of closed-set accuracy and open-set recognition when compared with existing methods for OSSL. Our code is available at https://github.com/walline/ssl-tf2-sefoss",
    "checked": true,
    "id": "efb9cb7a0576a36c16297fe0992ddcb91e520ce9",
    "semantic_title": "improving open-set semi-supervised learning with self-supervision",
    "citation_count": 1,
    "authors": [
      "Erik Wallin",
      "Lennart Svensson",
      "Fredrik Kahl",
      "Lars Hammarstrand"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Barsellotti_FOSSIL_Free_Open-Vocabulary_Semantic_Segmentation_Through_Synthetic_References_Retrieval_WACV_2024_paper.html": {
    "title": "FOSSIL: Free Open-Vocabulary Semantic Segmentation Through Synthetic References Retrieval",
    "volume": "main",
    "abstract": "Unsupervised Open-Vocabulary Semantic Segmentation aims to segment an image into regions referring to an arbitrary set of concepts described by text, without relying on dense annotations that are available only for a subset of the categories. Previous works relied on inducing pixel-level alignment in a multi-modal space through contrastive training over vast corpora of image-caption pairs. However, representing a semantic category solely through its textual embedding is insufficient to encompass the wide-ranging variability in the visual appearances of the images associated with that category. In this paper, we propose FOSSIL, a pipeline that enables a self-supervised backbone to perform open-vocabulary segmentation relying only on the visual modality. In particular, we decouple the task into two components: (1) we leverage text-conditioned diffusion models to generate a large collection of visual embeddings, starting from a set of captions. These can be retrieved at inference time to obtain a support set of references for the set of textual concepts. Further, (2) we exploit self-supervised dense features to partition the image into semantically coherent regions. We demonstrate that our approach provides strong performance on different semantic segmentation datasets, without requiring any additional training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Barsellotti",
      "Roberto Amoroso",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rani_Activity-Based_Early_Autism_Diagnosis_Using_a_Multi-Dataset_Supervised_Contrastive_Learning_WACV_2024_paper.html": {
    "title": "Activity-Based Early Autism Diagnosis Using a Multi-Dataset Supervised Contrastive Learning Approach",
    "volume": "main",
    "abstract": "Autism Spectrum Disorder (ASD) is a neurological disorder. Its primary symptoms include difficulty in verbal/non-verbal communication and rigid/repetitive behavior. Traditional methods of autism diagnosis require multiple visits to a human specialist. However, this process is generally time-consuming and may result in a delayed (early) intervention. In this paper, we present a data-driven approach to automate autism diagnosis using video clips of subjects performing simple activities recorded in a weakly constrained environment. This task is particularly challenging since the available training data is small, videos from the two categories (\"ASD\" and \"Control\") are generally perceptually indistinguishable, and there is no clear understanding of what features would be beneficial in this task. To address these, we present a novel multi-dataset supervised contrastive learning technique to learn discriminative features simultaneously from multiple video datasets with significantly diverse distributions. Extensive empirical analyses demonstrate the promise of our approach compared to competing techniques on this challenging task",
    "checked": false,
    "id": "f4ed8030292fff494b591868fb8c1019cd054347",
    "semantic_title": "early-stage autism diagnosis using action videos and contrastive feature learning",
    "citation_count": 0,
    "authors": [
      "Asha Rani",
      "Yashaswi Verma"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ye_Label_Shift_Estimation_for_Class-Imbalance_Problem_A_Bayesian_Approach_WACV_2024_paper.html": {
    "title": "Label Shift Estimation for Class-Imbalance Problem: A Bayesian Approach",
    "volume": "main",
    "abstract": "As a type of distribution shift, label shift occurs when the source and target domains have different label distributions P(Y) but identical conditional distributions of data given labels P(X | Y). Under a Bayesian framework, we propose a novel Maximum A Posteriori (MAP) model and a novel posterior sampling model for the label shift problem. We prove the MAP objective admits a unique optimum and derive an EM algorithm that converges to the global optimum. We propose a novel Adaptive Prior Learning (APL) model to adaptively select prior parameters given data. We use the Markov Chain Monte Carlo (MCMC) method in our posterior sampling model to estimate and correct for label shift. Our methods can effectively resolve class imbalance problems on large-scale datasets without fine-tuning the classifier. Experiments show that our model outperforms existing methods on a variety of label shift settings. Our code is available at https://github.com/ChangkunYe/MAPLS/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changkun Ye",
      "Russell Tsuchida",
      "Lars Petersson",
      "Nick Barnes"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Adam_SeaTurtleID2022_A_Long-Span_Dataset_for_Reliable_Sea_Turtle_Re-Identification_WACV_2024_paper.html": {
    "title": "SeaTurtleID2022: A Long-Span Dataset for Reliable Sea Turtle Re-Identification",
    "volume": "main",
    "abstract": "This paper introduces the first public large-scale, long-span dataset with sea turtle photographs captured in the wild - SeaTurtleID2022. The dataset contains 8729 photographs of 438 unique individuals collected within 13 years, making it the longest-spanned dataset for animal re-identification. Each photograph includes various annotations, e.g., identity, encounter timestamp, and body parts segmentation masks. Instead of a standard \"random\" split, the dataset allows for two realistic and ecologically motivated splits: (i) time-aware: a closed-set with training, validation, and test data from different days/years, and (ii) open-set: with new unknown individuals in test and validation sets. We show that time-aware splits are essential for benchmarking methods for re-identification, as random splits lead to performance overestimation. Furthermore, a baseline instance segmentation and re-identification performance over various body parts is provided. At last, an end-to-end system for sea turtle re-identification is proposed and evaluated. The proposed system based on Hybrid Task Cascade for head instance segmentation and ArcFace-trained feature-extractor achieved an accuracy of 86.8%",
    "checked": true,
    "id": "47c5259bedc4e41aa99de1242752f36275c84d53",
    "semantic_title": "seaturtleid2022: a long-span dataset for reliable sea turtle re-identification",
    "citation_count": 1,
    "authors": [
      "Lukáš Adam",
      "Vojtěch Čermák",
      "Kostas Papafitsoros",
      "Lukas Picek"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_Self-Supervised_Edge_Detection_Reconstruction_for_Topology-Informed_3D_Axon_Segmentation_and_WACV_2024_paper.html": {
    "title": "Self-Supervised Edge Detection Reconstruction for Topology-Informed 3D Axon Segmentation and Centerline Detection",
    "volume": "main",
    "abstract": "Many machine learning-based axon tracing methods rely on image datasets with segmentation labels. This requires manual annotation from domain experts, which is labor-intensive and not practical for large-scale brain mapping on hemisphere or whole brain tissue at cellular or sub-cellular resolution. Additionally, preserving axon structure topology is crucial to understanding neural connections and brain function. Self-supervised learning (SSL) is a machine learning framework that allows models to learn an auxiliary task on unannotated data to aid performance on a supervised target task. In this work, we propose a novel SSL auxiliary task of reconstructing an edge detector for the target task of topology-oriented axon segmentation and centerline detection. We pretrained 3D U-Nets on three different SSL tasks using a mouse brain dataset: our proposed task, predicting the order of permuted slices, and playing a Rubik's cube. We then evaluated these U-Nets and a baseline model on a different mouse brain dataset. Across all experiments, the U-Net pretrained on our proposed task improved the baseline's segmentation, topology-preservation, and centerline detection by up to 5.03%, 4.65%, and 5.41%, respectively. In contrast, there was no consistent improvement over the baseline observed with the slice-permutation and Rubik's cube pretrained U-Nets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alec S. Xu",
      "Nina I. Shamsi",
      "Lars A. Gjesteby",
      "Laura J. Brattain"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Bi-Directional_Training_for_Composed_Image_Retrieval_via_Text_Prompt_Learning_WACV_2024_paper.html": {
    "title": "Bi-Directional Training for Composed Image Retrieval via Text Prompt Learning",
    "volume": "main",
    "abstract": "Composed image retrieval searches for a target image based on a multi-modal user query comprised of a reference image and modification text describing the desired changes. Existing approaches to solving this challenging task learn a mapping from the (reference image, modification text)-pair to an image embedding that is then matched against a large image corpus. One area that has not yet been explored is the reverse direction, which asks the question, what reference image when modified as described by the text would produce the given target image? In this work we propose a bi-directional training scheme that leverages such reversed queries and can be applied to existing composed image retrieval architectures with minimum changes, which improves the performance of the model. To encode the bi-directional query we prepend a learnable token to the modification text that designates the direction of the query and then finetune the parameters of the text embedding module. We make no other changes to the network architecture. Experiments on two standard datasets show that our novel approach achieves improved performance over a baseline BLIP-based model that itself already achieves competitive performance. Our code is released at https://github.com/Cuberick-Orion/Bi-Blip4CIR",
    "checked": true,
    "id": "690d87c9055c5a42ba25380603a82931a77e932c",
    "semantic_title": "bi-directional training for composed image retrieval via text prompt learning",
    "citation_count": 5,
    "authors": [
      "Zheyuan Liu",
      "Weixuan Sun",
      "Yicong Hong",
      "Damien Teney",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jing_iBARLE_imBalance-Aware_Room_Layout_Estimation_WACV_2024_paper.html": {
    "title": "iBARLE: imBalance-Aware Room Layout Estimation",
    "volume": "main",
    "abstract": "Room layout estimation predicts layouts from a single panorama. It requires datasets with large-scale and diverse room shapes to well train the models. However, there are significant imbalances in real-world datasets including the dimensions of layout complexity, camera locations, and variation in scene appearance. These issues considerably influence the model training performance. In this work, we propose imBalance-Aware Room Layout Estimation (iBARLE) framework to address these issues. iBARLE consists of: (1) Appearance Variation Generation (AVG) module, which promotes visual appearance domain generalization, (2) Complex Structure Mix-up (CSMix) module, which enhances generalizability w.r.t. room structure, and (3) a gradient-based layout objective function, which allows more effective accounting for occlusions in complex layouts. All modules are jointly trained and help each other to achieve the best performance. Experiments and ablation studies based on ZInD dataset illustrate that iBARLE has state-of-the-art performance compared with other layout estimation baselines",
    "checked": true,
    "id": "c2743e5addf9ff0a41295e8535884eb0e3436c12",
    "semantic_title": "ibarle: imbalance-aware room layout estimation",
    "citation_count": 0,
    "authors": [
      "Taotao Jing",
      "Lichen Wang",
      "Naji Khosravan",
      "Zhiqiang Wan",
      "Zachary Bessinger",
      "Zhengming Ding",
      "Sing Bing Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_FarSight_A_Physics-Driven_Whole-Body_Biometric_System_at_Large_Distance_and_WACV_2024_paper.html": {
    "title": "FarSight: A Physics-Driven Whole-Body Biometric System at Large Distance and Altitude",
    "volume": "main",
    "abstract": "Whole-body biometric recognition is an important area of research due to its vast applications in law enforcement, border security, and surveillance. This paper presents the end-to-end design, development and evaluation of FarSight, an innovative software system designed for whole-body (fusion of face, gait and body shape) biometric recognition. FarSight accepts videos from elevated platforms and drones as input and outputs a candidate list of identities from a gallery. The system is designed to address several challenges, including (i) low-quality imagery, (ii) large yaw and pitch angles, (iii) robust feature extraction to accommodate large intra-person variabilities and large inter-person similarities, and (iv) the large domain gap between training and test sets. FarSight combines the physics of imaging and deep learning models to enhance image restoration and biometric feature encoding. We test FarSight's effectiveness using the newly acquired IARPA Biometric Recognition and Identification at Altitude and Range (BRIAR) dataset. Notably, FarSight demonstrated a substantial performance increase on the BRIAR dataset, with gains of +11.82% Rank-20 identification and +11.3% TAR@1%FAR",
    "checked": true,
    "id": "018fd91891b8c3779ea195e2d4deb1933df53e54",
    "semantic_title": "farsight: a physics-driven whole-body biometric system at large distance and altitude",
    "citation_count": 4,
    "authors": [
      "Feng Liu",
      "Ryan Ashbaugh",
      "Nicholas Chimitt",
      "Najmul Hassan",
      "Ali Hassani",
      "Ajay Jaiswal",
      "Minchul Kim",
      "Zhiyuan Mao",
      "Christopher Perry",
      "Zhiyuan Ren",
      "Yiyang Su",
      "Pegah Varghaei",
      "Kai Wang",
      "Xingguang Zhang",
      "Stanley Chan",
      "Arun Ross",
      "Humphrey Shi",
      "Zhangyang Wang",
      "Anil Jain",
      "Xiaoming Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rothmeier_Time_To_Shine_Fine-Tuning_Object_Detection_Models_With_Synthetic_Adverse_WACV_2024_paper.html": {
    "title": "Time To Shine: Fine-Tuning Object Detection Models With Synthetic Adverse Weather Images",
    "volume": "main",
    "abstract": "The detection of vehicles, pedestrians, and obstacles plays an important role in the decision-making process of autonomous vehicles. While existing methods achieve high detection accuracy under good environmental conditions, they often fail in adverse weather conditions due to limited visibility, blurred contours, and low contrast. These \"edge-case\" scenarios are not well represented in existing datasets and are not handled properly by object detection algorithms. In our work, we propose a novel approach to synthesising photorealistic and highly diverse scenarios that can be used to fine-tune object detection algorithms in adverse weather conditions such as snow, fog, and rain. The approach uses the Midjourney text-to-image model to create accurate synthetic images of desired weather conditions. Our experiments show that training with our dataset significantly improves detection accuracy in harsh weather conditions. Our results are compared to baseline models and models fine-tuned on augmented clear weather images",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Rothmeier",
      "Werner Huber",
      "Alois C. Knoll"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chakraborty_Unsupervised_and_Semi-Supervised_Co-Salient_Object_Detection_via_Segmentation_Frequency_Statistics_WACV_2024_paper.html": {
    "title": "Unsupervised and Semi-Supervised Co-Salient Object Detection via Segmentation Frequency Statistics",
    "volume": "main",
    "abstract": "In this paper, we address the detection of co-occurring salient objects (CoSOD) in an image group using frequency statistics in an unsupervised manner, which further enable us to develop a semi-supervised method. While previous works have mostly focused on fully supervised CoSOD, less attention has been allocated to detecting co-salient objects when limited segmentation annotations are available for training. Our simple yet effective unsupervised method US-CoSOD combines the object co-occurrence frequency statistics of unsupervised single-image semantic segmentations with salient foreground detections using self-supervised feature learning. For the first time, we show that a large unlabeled dataset e.g. ImageNet-1k can be effectively leveraged to significantly improve unsupervised CoSOD performance. Our unsupervised model is a great pre-training initialization for our semi-supervised model SS-CoSOD, especially when very limited labeled data is available for training. To avoid propagating erroneous signals from predictions on unlabeled data, we propose a confidence estimation module to guide our semi-supervised training. Extensive experiments on three CoSOD benchmark datasets show that both of our unsupervised and semi-supervised models outperform the corresponding state-of-the-art models by a significant margin (e.g., on the Cosal2015 dataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised co-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over a SOTA semi-supervised CoSOD model)",
    "checked": true,
    "id": "8f7bd404e9968798d57a02314a74690bf5fd8faf",
    "semantic_title": "unsupervised and semi-supervised co-salient object detection via segmentation frequency statistics",
    "citation_count": 0,
    "authors": [
      "Souradeep Chakraborty",
      "Shujon Naha",
      "Muhammet Bastan",
      "Amit Kumar K. C.",
      "Dimitris Samaras"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yasarla_3SD_Self-Supervised_Saliency_Detection_With_No_Labels_WACV_2024_paper.html": {
    "title": "3SD: Self-Supervised Saliency Detection With No Labels",
    "volume": "main",
    "abstract": "We present a conceptually simple self-supervised method for saliency detection. Our method generates and uses pseudo-ground truth labels for training. The generated pseudo-GT labels don't require any kind of human annotations (e.g., pixel-wise labels or weak labels like scribbles). Recent works show that features extracted from classification tasks provide important saliency cues like structure and semantic information of salient objects in the image. Our method, called 3SD, exploits this idea by adding a branch for a self-supervised classification task in parallel with salient object detection, to obtain class activation maps (CAM maps). These CAM maps along with the edges of the input image are used to generate the pseudo-GT saliency maps to train our 3SD network. Specifically, we propose a contrastive learning-based training on multiple image patches for the classification task. We show the multi-patch classification with contrastive loss improves the quality of the CAM maps compared to naive classification on the entire image. Experiments on six benchmark datasets demonstrate that without any labels, our 3SD method outperforms all existing weakly supervised and unsupervised methods, and its performance is on par with the fully-supervised methods",
    "checked": true,
    "id": "2a78e1c0412cbcc851ba60224c15c501debe2049",
    "semantic_title": "3sd: self-supervised saliency detection with no labels",
    "citation_count": 3,
    "authors": [
      "Rajeev Yasarla",
      "Renliang Weng",
      "Wongun Choi",
      "Vishal M. Patel",
      "Amir Sadeghian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Pixel_Matching_Network_for_Cross-Domain_Few-Shot_Segmentation_WACV_2024_paper.html": {
    "title": "Pixel Matching Network for Cross-Domain Few-Shot Segmentation",
    "volume": "main",
    "abstract": "Few-Shot Segmentation (FSS) aims to segment the novel class images with a few annotated samples. In the past, numerous studies have concentrated on cross-category tasks, where the training and testing sets are derived from the same dataset, while these methods face significant difficulties in domain-shift scenarios. To better tackle the cross-domain tasks, we propose a pixel matching network (PMNet) to extract the domain-agnostic pixel-level affinity matching with a frozen backbone and capture both the pixel-to-pixel and pixel-to-patch relations in each support-query pair with the bidirectional 3D convolutions. Different from the existing methods that remove the support background, we design a hysteretic spatial filtering module (HSFM) to filter the background-related query features and retain the foreground-related query features with the assistance of the support background, which is beneficial for eliminating interference objects in the query background. We comprehensively evaluate our PMNet on ten benchmarks under cross-category, cross-dataset, and cross-domain FSS tasks. Experimental results demonstrate that PMNet performs very competitively under different settings with only 0.68M parameters, especially under cross-domain FSS tasks, showing its effectiveness and efficiency",
    "checked": false,
    "id": "97979cec79adf3cec0295189f572830771dc40cf",
    "semantic_title": "pseudo-interacting guided network for few-shot segmentation",
    "citation_count": 0,
    "authors": [
      "Hao Chen",
      "Yonghan Dong",
      "Zheming Lu",
      "Yunlong Yu",
      "Jungong Han"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tan_Cross-Domain_Few-Shot_Incremental_Learning_for_Point-Cloud_Recognition_WACV_2024_paper.html": {
    "title": "Cross-Domain Few-Shot Incremental Learning for Point-Cloud Recognition",
    "volume": "main",
    "abstract": "Sensing 3D objects is critical when 2D object recognition is not accessible. A robot pre-trained on a large point-cloud dataset will encounter unseen classes of 3D objects after deploying it. Therefore, the robot should be able to learn continuously in real-world scenarios. Few-shot class-incremental learning (FSCIL) requires the model to learn from few-shot new examples continually and not forget past classes. However, there is an implicit but strong assumption in the FSCIL that the distribution of the base and incremental classes is the same. In this paper, we focus on cross-domain FSCIL for point-cloud recognition. We decompose the catastrophic forgetting into base class forgetting and incremental class forgetting and alleviate them separately. We utilize the base model to discriminate base samples and new samples by treating base samples as in-distribution samples, and new objects as out-of-distribution samples. We retain the base model to avoid catastrophic forgetting of base classes and train an extra domain-specific module for all new samples to adapt to new classes. At inference, we first discriminate whether the sample belongs to the base class or the new class. Once classified at the model level, test samples are then passed to the corresponding model for class-level classification. To better mitigate the forgetting of new classes, we adopt the soft label and hard label replay together. Extensive experiments on synthetic-to-real incremental 3D datasets show that our proposed method can balance the performance between the base and new objects and outperforms the previous state-of-the-art methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwen Tan",
      "Xiang Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jang_Robust_Unsupervised_Domain_Adaptation_Through_Negative-View_Regularization_WACV_2024_paper.html": {
    "title": "Robust Unsupervised Domain Adaptation Through Negative-View Regularization",
    "volume": "main",
    "abstract": "In the realm of Unsupervised Domain Adaptation (UDA), Vision Transformers (ViTs) have recently demonstrated remarkable adaptability surpassing that of traditional Convolutional Neural Networks (CNNs). Nevertheless, the patch-based structure of ViTs heavily relies on local features within image patches, potentially leading to reduced robustness when confronted with out-of-distribution (OOD) samples. To address this concern, we introduce a novel regularizer tailored specifically for UDA. By leveraging negative views, i.e. target-domain samples applied by negative augmentations, we make the learning process more intricate, thereby preventing models from taking shortcuts in spatial context recognition. We present a novel loss function, rooted in contrastive principles, to effectively distinguish between the negative views and original target samples. By integrating this novel regularizer with existing UDA methodologies, we guide ViTs to prioritize context relationships among local patches, thereby enhancing the robustness of ViTs. Our proposed Negative View-based Contrastive (NVC) regularizer substantially boosts the performance of baseline UDA methods across diverse benchmark datasets. Furthermore, we release new dataset, Retail-71, comprising 71 classes of images commonly encountered in retail stores. Through comprehensive experimentation, we showcase the effectiveness of our approach on traditional benchmarks as well as the novel retail domain. These results substantiate the robust adaptation capabilities of our proposed method. Our method is implemented at our repository",
    "checked": true,
    "id": "071ff892c2a02a23a39fb66bbd8fb455cc20d680",
    "semantic_title": "robust unsupervised domain adaptation through negative-view regularization",
    "citation_count": 0,
    "authors": [
      "Joonhyeok Jang",
      "Sunhyeok Lee",
      "Seonghak Kim",
      "Jung-un Kim",
      "Seonghyun Kim",
      "Daeshik Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Katsumata_Soft_Curriculum_for_Learning_Conditional_GANs_With_Noisy-Labeled_and_Uncurated_WACV_2024_paper.html": {
    "title": "Soft Curriculum for Learning Conditional GANs With Noisy-Labeled and Uncurated Unlabeled Data",
    "volume": "main",
    "abstract": "Label-noise or curated unlabeled data are used to compensate for the assumption of clean labeled data in training the conditional generative adversarial network; however, satisfying such an extended assumption is occasionally laborious or impractical. As a step towards generative modeling accessible to everyone, we introduce a novel conditional image generation framework that accepts noisy-labeled and uncurated unlabeled data during training: (i) closed-set and open-set label noise in labeled data and (ii) closed-set and open-set unlabeled data. To combat it, we propose soft curriculum learning, which assigns instance-wise weights for adversarial training while assigning new labels for unlabeled data and correcting wrong labels for labeled data. Unlike popular curriculum learning, which uses a threshold to pick the training samples, our soft curriculum controls the effect of each training instance by using the weights predicted by the auxiliary classifier, resulting in the preservation of useful samples while ignoring harmful ones. Our experiments show that our approach outperforms existing semi-supervised and label-noise robust methods in terms of both quantitative and qualitative performance. In particular, the proposed approach matches the performance of (semi-)supervised GANs even with less than half the labeled data",
    "checked": true,
    "id": "0d12bb148b7b8490d2c79ba73296bd2107e9488a",
    "semantic_title": "soft curriculum for learning conditional gans with noisy-labeled and uncurated unlabeled data",
    "citation_count": 0,
    "authors": [
      "Kai Katsumata",
      "Duc Minh Vo",
      "Tatsuya Harada",
      "Hideki Nakayama"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Duran_HMP_Hand_Motion_Priors_for_Pose_and_Shape_Estimation_From_WACV_2024_paper.html": {
    "title": "HMP: Hand Motion Priors for Pose and Shape Estimation From Video",
    "volume": "main",
    "abstract": "Understanding how humans interact with the world necessitates accurate 3D hand pose estimation, a task complicated by the hand's high degree of articulation, frequent occlusions, self-occlusions, and rapid motions. While most existing methods rely on single-image inputs, videos have useful cues to address aforementioned issues. However, existing video-based 3D hand datasets are insufficient for training feedforward models to generalize to in-the-wild scenarios. On the other hand, we have access to large human motion capture datasets which also include hand motions, e.g. AMASS. Therefore, we develop a generative motion prior specific for hands, trained on the AMASS dataset which features diverse and high-quality hand motions. This motion prior is then employed for video-based 3D hand motion estimation following a latent optimization approach. Our integration of a robust motion prior significantly enhances performance, especially in occluded scenarios. It produces stable, temporally consistent results that surpass conventional single-frame methods. We demonstrate our method's efficacy via qualitative and quantitative evaluations on the HO3D and DexYCB datasets, with special emphasis on an occlusion-focused subset of HO3D. Code is available at https://hmp.is.tue.mpg.de",
    "checked": true,
    "id": "9da11bcdea67a605aa4bcbb5d17df977f5694d6e",
    "semantic_title": "hmp: hand motion priors for pose and shape estimation from video",
    "citation_count": 0,
    "authors": [
      "Enes Duran",
      "Muhammed Kocabas",
      "Vasileios Choutas",
      "Zicong Fan",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ao_Amodal_Intra-Class_Instance_Segmentation_Synthetic_Datasets_and_Benchmark_WACV_2024_paper.html": {
    "title": "Amodal Intra-Class Instance Segmentation: Synthetic Datasets and Benchmark",
    "volume": "main",
    "abstract": "Images of realistic scenes often contain intra-class objects that are heavily occluded from each other, making the amodal perception task that requires parsing the occluded parts of the objects challenging. Although important for downstream tasks such as robotic grasping systems, the lack of large-scale amodal datasets with detailed annotations makes it difficult to model intra-class occlusions explicitly. This paper introduces two new amodal datasets for image amodal completion tasks, which contain a total of over 267K images of intra-class occlusion scenarios, annotated with multiple masks, amodal bounding boxes, dual order relations and full appearance for instances and background. We also present a point-supervised scheme with layer priors for amodal instance segmentation specifically designed for intra-class occlusion scenarios. Experiments show that our weakly supervised approach outperforms the SOTA fully supervised methods, while our layer priors design exhibits remarkable performance improvements in the case of intra-class occlusion in both synthetic and real images",
    "checked": true,
    "id": "0fa9e3398b9e177a088b96ea30074f623d75069d",
    "semantic_title": "amodal intra-class instance segmentation: synthetic datasets and benchmark",
    "citation_count": 0,
    "authors": [
      "Jiayang Ao",
      "Qiuhong Ke",
      "Krista A. Ehinger"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cho_RMFER_Semi-Supervised_Contrastive_Learning_for_Facial_Expression_Recognition_With_Reaction_WACV_2024_paper.html": {
    "title": "RMFER: Semi-Supervised Contrastive Learning for Facial Expression Recognition With Reaction Mashup Video",
    "volume": "main",
    "abstract": "Facial expression recognition (FER) has greatly benefited from deep learning but still faces challenges in dataset collection due to the nuanced nature of facial expressions. In this study, we present a novel unlabeled dataset and semi-supervised contrastive learning framework that utilizes Reaction Mashup (RM) videos, a video that includes multiple individuals reacting to the same film. We created a Reaction Mashup dataset (RMset) from these videos. Our framework integrates three distinct modules: A classification module for supervised facial expression categorization, an attention module for inter-sample attention learning, and a contrastive module for attention-based contrastive learning using RMset. We utilize both the classification and attention modules for the initial training, subsequently incorporating the contrastive module to enhance the learning process. Our experiments demonstrate that our method improves feature learning and outperforms state-of-the-art models on three benchmark FER datasets. Codes are available at https://github.com/yunseongcho/RMFER",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunseong Cho",
      "Chanwoo Kim",
      "Hoseong Cho",
      "Yunhoe Ku",
      "Eunseo Kim",
      "Muhammadjon Boboev",
      "Joonseok Lee",
      "Seungryul Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Banerjee_AMEND_Adaptive_Margin_and_Expanded_Neighborhood_for_Efficient_Generalized_Category_WACV_2024_paper.html": {
    "title": "AMEND: Adaptive Margin and Expanded Neighborhood for Efficient Generalized Category Discovery",
    "volume": "main",
    "abstract": "Generalized Category Discovery aims to discover and cluster images from previously unseen classes, in addition to classifying images from seen classes correctly. In this work, we propose a simple, yet effective framework for this task, which not only performs on-par or better with the current approaches but is also significantly more efficient in terms of computational requirements. Our first contribution is to use expanded neighborhood information in contrastive learning to generate robust and generalizable features. To generate more discriminative feature representations, especially for fine-grained datasets and confusing classes, we propose a class-wise adaptive margin regularizer that aims at increasing the angular separation among the prototypes of all classes. Extensive experiments on three generic as well as four fine-grained benchmark datasets show the usefulness of the proposed Adaptive Margin and Expanded Neighborhood (AMEND) framework",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anwesha Banerjee",
      "Liyana Sahir Kallooriyakath",
      "Soma Biswas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Siddiquee_Brainomaly_Unsupervised_Neurologic_Disease_Detection_Utilizing_Unannotated_T1-Weighted_Brain_MR_WACV_2024_paper.html": {
    "title": "Brainomaly: Unsupervised Neurologic Disease Detection Utilizing Unannotated T1-Weighted Brain MR Images",
    "volume": "main",
    "abstract": "Harnessing the power of deep neural networks in the medical imaging domain is challenging due to the difficulties in acquiring large annotated datasets, especially for rare diseases, which involve high costs, time, and effort for annotation. Unsupervised disease detection methods, such as anomaly detection, can significantly reduce human effort in these scenarios. While anomaly detection typically focuses on learning from images of healthy subjects only, real-world situations often present unannotated datasets with a mixture of healthy and diseased subjects. Recent studies have demonstrated that utilizing such unannotated images can improve unsupervised disease and anomaly detection. However, these methods do not utilize knowledge specific to registered neuroimages, resulting in a subpar performance in neurologic disease detection. To address this limitation, we propose Brainomaly, a GAN-based image-to-image translation method specifically designed for neurologic disease detection. Brainomaly not only offers tailored image-to-image translation suitable for neuroimages but also leverages unannotated mixed images to achieve superior neurologic disease detection. Additionally, we address the issue of model selection for inference without annotated samples by proposing a pseudo-AUC metric, further enhancing Brainomaly's detection performance. Extensive experiments and ablation studies demonstrate that Brainomaly outperforms existing state-of-the-art unsupervised disease and anomaly detection methods by significant margins in Alzheimer's disease detection using a publicly available dataset and headache detection using an institutional dataset. The code is available from https://github.com/mahfuzmohammad/Brainomaly",
    "checked": true,
    "id": "191e94ac1aa0aed64d024f8abc7212fef4b99d09",
    "semantic_title": "brainomaly: unsupervised neurologic disease detection utilizing unannotated t1-weighted brain mr images",
    "citation_count": 2,
    "authors": [
      "Md Mahfuzur Rahman Siddiquee",
      "Jay Shah",
      "Teresa Wu",
      "Catherine Chong",
      "Todd J. Schwedt",
      "Gina Dumkrieger",
      "Simona Nikolova",
      "Baoxin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/De_Plaen_Contrastive_Learning_for_Multi-Object_Tracking_With_Transformers_WACV_2024_paper.html": {
    "title": "Contrastive Learning for Multi-Object Tracking With Transformers",
    "volume": "main",
    "abstract": "The DEtection TRansformer (DETR) opened new possibilities for object detection by modeling it as a translation task: converting image features into object-level representations. Previous works typically add expensive modules to DETR to perform Multi-Object Tracking (MOT), resulting in more complicated architectures. We instead show how DETR can be turned into a MOT model by employing an instance-level contrastive loss, a revised sampling strategy and a lightweight assignment method. Our training scheme learns object appearances while preserving detection capabilities and with little overhead. Its performance surpasses the previous state-of-the-art by +2.6 mMOTA on the challenging BDD100K dataset and is comparable to existing transformer-based methods on the MOT17 dataset",
    "checked": true,
    "id": "a48cd2f7dbcaec476ff330ab32e9afa8dddceb43",
    "semantic_title": "contrastive learning for multi-object tracking with transformers",
    "citation_count": 0,
    "authors": [
      "Pierre-François De Plaen",
      "Nicola Marinello",
      "Marc Proesmans",
      "Tinne Tuytelaars",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chang_BEVMap_Map-Aware_BEV_Modeling_for_3D_Perception_WACV_2024_paper.html": {
    "title": "BEVMap: Map-Aware BEV Modeling for 3D Perception",
    "volume": "main",
    "abstract": "In autonomous driving applications, there is a strong preference for modeling the world in Bird's-Eye View (BEV), as it leads to improved accuracy and performance. BEV features are widely used in perception tasks since they allow fusing information from multiple views in an efficient manner. However, BEV features generated from camera images are prone to be imprecise due to the difficulty of estimating depth in the perspective view. Improper placement of BEV features limits the accuracy of downstream tasks. We introduce a method for incorporating map information to improve perspective depth estimation from 2D camera images and thereby producing geometrically- and semantically-robust BEV features. We show that augmenting the camera images with the BEV map and map-to-camera projections can compensate for the depth uncertainty. Experiments on the nuScenes dataset demonstrate that our method outperforms previous approaches using only camera images in segmentation and detection tasks",
    "checked": false,
    "id": "89bdd8f7cdbc622b1a43eee102049126d19f4c99",
    "semantic_title": "occlubev: occlusion aware spatiotemporal modeling for multi-view 3d object detection",
    "citation_count": 0,
    "authors": [
      "Mincheol Chang",
      "Seokha Moon",
      "Reza Mahjourian",
      "Jinkyu Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Clemmer_PreciseDebias_An_Automatic_Prompt_Engineering_Approach_for_Generative_AI_To_WACV_2024_paper.html": {
    "title": "PreciseDebias: An Automatic Prompt Engineering Approach for Generative AI To Mitigate Image Demographic Biases",
    "volume": "main",
    "abstract": "Recent years have witnessed growing concerns over demographic biases in image-centric applications, including image search engines and generative systems. While the advent of generative AI offers a pathway to mitigate these biases by producing underrepresented images, existing solutions still fail to precisely generate images that reflect specified demographic distributions. In this paper, we propose PreciseDebias, a comprehensive end-to-end framework that can rectify demographic bias in image generation. By leveraging fine-tuned Large Language Models (LLMs) coupled with text-to-image generative models, PreciseDebias transforms generic text prompts to produce images in line with specified demographic distributions. The core component of PreciseDebias is our novel instruction-following LLM, meticulously designed with an emphasis on model bias assessment and balanced model training. Extensive experiments demonstrate the effectiveness of PreciseDebias in rectifying biases pertaining to both ethnicity and gender in images. Furthermore, when compared with two baselines, PreciseDebias illustrates its robustness and capability to capture demographic intricacies. The generalization of PreciseDebias is further illuminated by the diverse images it produces across multiple professions and demographic attributes. To ensure reproducibility, we will make PreciseDebias openly accessible to the broader research community by releasing all models and code",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Colton Clemmer",
      "Junhua Ding",
      "Yunhe Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sarkar_Benchmark_Generation_Framework_With_Customizable_Distortions_for_Image_Classifier_Robustness_WACV_2024_paper.html": {
    "title": "Benchmark Generation Framework With Customizable Distortions for Image Classifier Robustness",
    "volume": "main",
    "abstract": "We present a novel framework for generating adversarial benchmarks to evaluate the robustness of image classification models. The RLAB framework allows users to customize the types of distortions to be optimally applied to images, which helps address the specific distortions relevant to their deployment. The benchmark can generate datasets at various distortion levels to assess the robustness of different image classifiers. Our results show that the adversarial samples generated by our framework with any of the image classification models, like ResNet-50, Inception-V3, and VGG-16, are effective and transferable to other models causing them to fail. These failures happen even when these models are adversarially retrained using state-of-the-art techniques, demonstrating the generalizability of our adversarial samples. Our framework also allows the creation of adversarial samples for non-ground truth classes at different levels of intensity, enabling tunable benchmarks for the evaluation of false positives. We achieve competitive performance in terms of net L_2 distortion compared to state-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we demonstrate our framework achieves such results with simple distortions like Gaussian noise without introducing unnatural artifacts or color bleeds. This is made possible by a model-based reinforcement learning (RL) agent and a technique that reduces a deep tree search of the image for model sensitivity to perturbations, to a one-level analysis and action. The flexibility of choosing distortions and setting classification probability thresholds for multiple classes makes our framework suitable for algorithmic audits",
    "checked": true,
    "id": "257bab6daed684561398565894087128ff7a5857",
    "semantic_title": "benchmark generation framework with customizable distortions for image classifier robustness",
    "citation_count": 0,
    "authors": [
      "Soumyendu Sarkar",
      "Ashwin Ramesh Babu",
      "Sajad Mousavi",
      "Zachariah Carmichael",
      "Vineet Gundecha",
      "Sahand Ghorbanpour",
      "Ricardo Luna Gutierrez",
      "Antonio Guillen",
      "Avisek Naug"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Qiu_Shape-Biased_CNNs_Are_Not_Always_Superior_in_Out-of-Distribution_Robustness_WACV_2024_paper.html": {
    "title": "Shape-Biased CNNs Are Not Always Superior in Out-of-Distribution Robustness",
    "volume": "main",
    "abstract": "In recent years, Out-of-Distribution (o.o.d) Robustness has garnered increasing attention in Deep Learning, and shape-biased Convolutional Neural Networks (CNNs) are believed to exhibit higher robustness, attributed to the inherent shape-based decision rule of human cognition. In this work, we delve deeper into the intricate relationship between shape/texture information and o.o.d robustness by leveraging a carefully curated \"Category-Balanced ImageNet\" dataset. We find that shape information is not always superior in distinguishing distinct categories and shape-biased model is not always superior across various o.o.d scenarios. Motivated by these insightful findings, we design a novel method named Shape-Texture Adaptive Recombination (STAR) to achieve higher o.o.d robustness. A category-balanced dataset is firstly used to pretrain a debiased backbone and three specialized heads, each adept at robustly extracting shape, texture, and debiased features. Subsequently, an instance-adaptive recombination head is trained to adaptively adjust the contributions of these distinctive features for each given instance. Through comprehensive experiments, our proposed method achieves state-of-the-art o.o.d robustness across various scenarios such as image corruptions, adversarial attacks, style shifts, and dataset shifts, demonstrating its effectiveness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinkuan Qiu",
      "Meina Kan",
      "Yongbin Zhou",
      "Yanchao Bi",
      "Shiguang Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lu_Towards_Visual_Saliency_Explanations_of_Face_Verification_WACV_2024_paper.html": {
    "title": "Towards Visual Saliency Explanations of Face Verification",
    "volume": "main",
    "abstract": "In the past years, deep convolutional neural networks have been pushing the frontier of face recognition (FR) techniques in both verification and identification scenarios. Despite the high accuracy, they are often criticized for lacking explainability. There has been an increasing demand for understanding the decision-making process of deep face recognition systems. Recent studies have investigated the usage of visual saliency maps as an explanation, but they often lack a discussion and analysis in the context of face recognition. This paper concentrates on explainable face verification tasks and conceives a new explanation framework. Firstly, a definition of the saliency-based explanation method is provided, which focuses on the decisions made by the deep FR model. Secondly, a new model-agnostic explanation method named CorrRISE is proposed to produce saliency maps, which reveal both the similar and dissimilar regions of any given pair of face images. Then, an evaluation methodology is designed to measure the performance of general visual saliency explanation methods in face verification. Finally, substantial visual and quantitative results have shown that the proposed CorrRISE method demonstrates promising results in comparison with other state-of-the-art explainable face verification approaches",
    "checked": true,
    "id": "8ac875015cbefbec05a0d829202ced456bd9222f",
    "semantic_title": "towards visual saliency explanations of face verification",
    "citation_count": 1,
    "authors": [
      "Yuhang Lu",
      "Zewei Xu",
      "Touradj Ebrahimi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huber_Bias_and_Diversity_in_Synthetic-Based_Face_Recognition_WACV_2024_paper.html": {
    "title": "Bias and Diversity in Synthetic-Based Face Recognition",
    "volume": "main",
    "abstract": "Synthetic data is emerging as a substitute for authentic data to solve ethical and legal challenges in handling authentic face data. The current models can create real-looking face images of people who do not exist. However, it is a known and sensitive problem that face recognition systems are susceptible to bias, i.e. performance differences between different demographic and non-demographics attributes, which can lead to unfair decisions. In this work, we investigate how the diversity of synthetic face recognition datasets compares to authentic datasets, and how the distribution of the training data of the generative models affects the distribution of the synthetic data. To do this, we looked at the distribution of gender, ethnicity, age, and head position. Furthermore, we investigated the concrete bias of three recent synthetic-based face recognition models on the studied attributes in comparison to a baseline model trained on authentic data. Our results show that the generator generate a similar distribution as the used training data in terms of the different attributes. With regard to bias, it can be seen that the synthetic-based models share a similar bias behavior with the authentic-based models. However, with the uncovered lower intra-identity attribute consistency seems to be beneficial in reducing bias",
    "checked": true,
    "id": "3fd4c19b49143e5a72877028f028b679fbdb5445",
    "semantic_title": "bias and diversity in synthetic-based face recognition",
    "citation_count": 0,
    "authors": [
      "Marco Huber",
      "Anh Thi Luu",
      "Fadi Boutros",
      "Arjan Kuijper",
      "Naser Damer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Deshmukh_Textual_Alchemy_CoFormer_for_Scene_Text_Understanding_WACV_2024_paper.html": {
    "title": "Textual Alchemy: CoFormer for Scene Text Understanding",
    "volume": "main",
    "abstract": "The paper presents CoFormer (Convolutional Fourier Transformer), a robust and adaptable transformer architecture designed for a range of scene text tasks. CoFormer integrates convolution and Fourier operations into the transformer architecture. Thus, it leverages convolution properties such as shared weights, local receptive fields, and spatial subsampling, while the Fourier operation emphasizes composite characteristics from the frequency domain. The research further proposes the first pretraining datasets, named Textverse10M-E and Textverse10M-H. Using these datasets, we demonstrate the efficacy of pretraining for scene text understanding. CoFormer achieves state-of-theart results with and without pretraining on two downstream tasks: scene text recognition and scene text style transfer. The paper presents LISTNet (Language Invariant Style Transfer), a novel framework for bi-lingual scene text style transfer. It also introduces three datasets, viz., TST500K for scene text style transfer, CSTR2.5M and Akshara550 for scene text recognition",
    "checked": true,
    "id": "2ca72400a4026e9fe649e9c5e2458167b56f8452",
    "semantic_title": "textual alchemy: coformer for scene text understanding",
    "citation_count": 0,
    "authors": [
      "Gayatri Deshmukh",
      "Onkar Susladkar",
      "Dhruv Makwana",
      "Sparsh Mittal",
      "Sai Chandra Teja R."
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Singla_Data-Centric_Debugging_Mitigating_Model_Failures_via_Targeted_Image_Retrieval_WACV_2024_paper.html": {
    "title": "Data-Centric Debugging: Mitigating Model Failures via Targeted Image Retrieval",
    "volume": "main",
    "abstract": "Deep neural networks can be unreliable in the real world when the training set does not adequately cover all the settings where they are deployed. Focusing on image classification, we consider the setting where we have an error distribution E representing a deployment scenario where the model fails. We have access to a small set of samples E_sample from E and it can be expensive to obtain additional samples. In the traditional model development framework, mitigating failures of the model in E can be challenging and is often done in an ad hoc manner. In this paper, we propose a general methodology for model debugging that can systemically improve model performance on E while maintaining its performance on the original test set. Our key assumption is that we have access to a large pool of weakly (noisily) labeled data F. However, naively adding F to the training would hurt model performance due to the large extent of label noise. Our Data-Centric Debugging (DCD) framework carefully creates a debug-train set by selecting images from F that are perceptually similar to the images in E_sample. To do this, we use the l_2 distance in the feature space (penultimate layer activations) of various models including ResNet, Robust ResNet and DINO where we observe DINO ViTs are significantly better at discovering similar images compared to Resnets. Compared to the baselines that maintain model performance on the test set, we achieve significantly (+9.45%) improved results on the debug-heldout sets",
    "checked": false,
    "id": "8aa9f90d8bb3cebc6362eae1e4a764b44f697b60",
    "semantic_title": "data-centric debugging: mitigating model failures via targeted data collection",
    "citation_count": 4,
    "authors": [
      "Sahil Singla",
      "Atoosa Malemir Chegini",
      "Mazda Moayeri",
      "Soheil Feizi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fujitake_DTrOCR_Decoder-Only_Transformer_for_Optical_Character_Recognition_WACV_2024_paper.html": {
    "title": "DTrOCR: Decoder-Only Transformer for Optical Character Recognition",
    "volume": "main",
    "abstract": "Typical text recognition methods rely on an encoder-decoder structure, in which the encoder extracts features from an image, and the decoder produces recognized text from these features. In this study, we propose a simpler and more effective method for text recognition, known as the Decoder-only Transformer for Optical Character Recognition (DTrOCR). This method uses a decoder-only Transformer to take advantage of a generative language model that is pre-trained on a large corpus. We examined whether a generative language model that has been successful in natural language processing can also be effective for text recognition in computer vision. Our experiments demonstrated that DTrOCR outperforms current state-of-the-art methods by a large margin in the recognition of printed, handwritten, and scene text in both English and Chinese",
    "checked": true,
    "id": "01d7d75440c36c7d7ea5f781664662b6b143299f",
    "semantic_title": "dtrocr: decoder-only transformer for optical character recognition",
    "citation_count": 2,
    "authors": [
      "Masato Fujitake"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Efficient_Transferability_Assessment_for_Selection_of_Pre-Trained_Detectors_WACV_2024_paper.html": {
    "title": "Efficient Transferability Assessment for Selection of Pre-Trained Detectors",
    "volume": "main",
    "abstract": "Large-scale pre-training followed by downstream fine-tuning is an effective solution for transferring deep-learning-based models. Since finetuning all possible pre-trained models is computational costly, we aim to predict the transferability performance of these pre-trained models in a computational efficient manner. Different from previous work that seek out suitable models for downstream classification and segmentation tasks, this paper studies the efficient transferability assessment of pre-trained object detectors. To this end, we build up a detector transferability benchmark which contains a large and diverse zoo of pre-trained detectors with various architectures, source datasets and training schemes. Given this zoo, we adopt 6 target datasets from 5 diverse domains as the downstream target tasks for evaluation. Further, we propose to assess classification and regression sub-tasks simultaneously in a unified framework. Additionally, we design a complementary metric for evaluating tasks with varying objects. Experimental results demonstrate that our method outperforms other state-of-the-art approaches in assessing transferability under different target domains while efficiently reducing wall-clock time 32x and requiring a mere 5.2% memory footprint compared to brute-force fine-tuning of all pre-trained detectors. Our assessment code and benchmark will be publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhao Wang",
      "Aoxue Li",
      "Zhenguo Li",
      "Qi Dou"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pham_NVAutoNet_Fast_and_Accurate_360deg_3D_Visual_Perception_for_Self_WACV_2024_paper.html": {
    "title": "NVAutoNet: Fast and Accurate 360deg 3D Visual Perception for Self Driving",
    "volume": "main",
    "abstract": "Achieving robust and real-time 3D perception is fundamental for autonomous vehicles. While most existing 3D perception methods prioritize detection accuracy, they often overlook critical aspects such as computational efficiency, onboard chip deployment friendliness, resilience to sensor mounting deviations, and adaptability to various vehicle types. To address these challenges, we present NVAutoNet: a specialized Bird's-Eye-View (BEV) perception network tailored explicitly for automated vehicles. NVAutoNet takes synchronized camera images as input and predicts 3D signals like obstacles, freespaces, and parking spaces. The core of NVAutoNet's architecture (image and BEV backbones) relies on efficient convolutional networks, optimized for high performance using TensorRT. Our image-to-BEV transformation employs simple linear layers and BEV look-up tables, ensuring rapid inference speed. Trained on an extensive proprietary dataset, NVAutoNet consistently achieves elevated perception accuracy, operating remarkably at 53 frames per second on the NVIDIA DRIVE Orin SoC. Notably, NVAutoNet demonstrates resilience to sensor mounting deviations arising from diverse car models. Moreover, NVAutoNet excels in adapting to varied vehicle types, facilitated by inexpensive model fine-tuning procedures that expedite compatibility adjustments",
    "checked": false,
    "id": "164e278a392e84ceda654f25c7fe5105e802f342",
    "semantic_title": "nvautonet: fast and accurate 360° 3d visual perception for self driving",
    "citation_count": 1,
    "authors": [
      "Trung Pham",
      "Mehran Maghoumi",
      "Wanli Jiang",
      "Bala Siva Sashank Jujjavarapu",
      "Mehdi Sajjadi",
      "Xin Liu",
      "Hsuan-Chu Lin",
      "Bor-Jeng Chen",
      "Giang Truong",
      "Chao Fang",
      "Junghyun Kwon",
      "Minwoo Park"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_VideoFACT_Detecting_Video_Forgeries_Using_Attention_Scene_Context_and_Forensic_WACV_2024_paper.html": {
    "title": "VideoFACT: Detecting Video Forgeries Using Attention, Scene Context, and Forensic Traces",
    "volume": "main",
    "abstract": "Fake videos represent an important misinformation threat. While existing forensic networks have demonstrated strong performance on image forgeries, recent results reported on the Adobe VideoSham dataset show that these networks fail to identify fake content in videos. In response, we propose VideoFACT - a new network that is able to detect and localize a wide variety of video forgeries and manipulations. To overcome challenges that existing networks face when analyzing videos, our network utilizes both forensic embeddings to capture traces left by manipulation, context embeddings to control for variation in forensic traces introduced by video coding, and a deep self-attention mechanism to estimate the quality and relative importance of local forensic embeddings. We create several new video forgery datasets and use these, along with publicly available data, to experimentally evaluate our network's performance. These results show that our proposed network is able to identify a diverse set of video forgeries, including those not encountered during training. Furthermore, we show that our network can be fine-tuned to achieve even stronger performance on challenging AI-based manipulations",
    "checked": true,
    "id": "7105378af541b2b6df10bc9a9c7f569a1a2852ab",
    "semantic_title": "videofact: detecting video forgeries using attention, scene context, and forensic traces",
    "citation_count": 2,
    "authors": [
      "Tai D. Nguyen",
      "Shengbang Fang",
      "Matthew C. Stamm"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Vinod_TEGLO_High_Fidelity_Canonical_Texture_Mapping_From_Single-View_Images_WACV_2024_paper.html": {
    "title": "TEGLO: High Fidelity Canonical Texture Mapping From Single-View Images",
    "volume": "main",
    "abstract": "Recent work in Neural Fields (NFs) learn 3D representations from class-specific single view image collections. However, they are unable to reconstruct the input data preserving high-frequency details. Further, these methods do not disentangle appearance from geometry and hence are not suitable for tasks such as texture transfer and editing. In this work, we propose TEGLO (Textured EG3D-GLO) for learning 3D representations from single view in-the-wild image collections for a given class of objects. We accomplish this by training a conditional Neural Radiance Field (NeRF) without any explicit 3D supervision. We equip our method with editing capabilities by creating a dense correspondence mapping to a 2D canonical space. We demonstrate that such mapping enables texture transfer and texture editing without requiring meshes with shared topology. Our key insight is that by mapping the input image pixels onto the texture space we can achieve near perfect reconstruction (>74 dB PSNR at 1024^2 resolution). Our formulation allows for high quality 3D consistent novel view synthesis with high-frequency details even at megapixel image resolutions",
    "checked": true,
    "id": "03f050da6d7207ca6e8d7fdfa00cfacba5d19515",
    "semantic_title": "teglo: high fidelity canonical texture mapping from single-view images",
    "citation_count": 1,
    "authors": [
      "Vishal Vinod",
      "Tanmay Shah",
      "Dmitry Lagun"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nogueira_Prototypical_Contrastive_Network_for_Imbalanced_Aerial_Image_Segmentation_WACV_2024_paper.html": {
    "title": "Prototypical Contrastive Network for Imbalanced Aerial Image Segmentation",
    "volume": "main",
    "abstract": "Binary segmentation is the main task underpinning several remote sensing applications, which are particularly interested in identifying and monitoring a specific category/object. Although extremely important, such a task has several challenges, including huge intra-class variance for the background and data imbalance. Furthermore, most works tackling this task partially or completely ignore one or both of these challenges and their developments. In this paper, we propose a novel method to perform imbalanced binary segmentation of remote sensing images based on deep networks, prototypes, and contrastive loss. The proposed approach allows the model to focus on learning the foreground class while alleviating the class imbalance problem by allowing it to concentrate on the most difficult background examples. The results demonstrate that the proposed method outperforms state-of-the-art techniques for imbalanced binary segmentation of remote sensing images while taking much less training time",
    "checked": false,
    "id": "4be82db0438adfc5f0db37a56e8471a9c7861888",
    "semantic_title": "multiscale prototype contrast network for high-resolution aerial imagery semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Keiller Nogueira",
      "Mayara Maezano Faita-Pinheiro",
      "Ana Paula Marques Ramos",
      "Wesley Nunes Gonçalves",
      "José Marcato Junior",
      "Jefersson A. dos Santos"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Haitman_BoostRad_Enhancing_Object_Detection_by_Boosting_Radar_Reflections_WACV_2024_paper.html": {
    "title": "BoostRad: Enhancing Object Detection by Boosting Radar Reflections",
    "volume": "main",
    "abstract": "Automotive radars have an important role in autonomous driving systems. The main challenge in automotive radar detection is the radar's wide point spread function (PSF) in the angular domain that causes blurriness and clutter in the radar image. Numerous studies suggest employing an 'end-to-end' learning strategy using a Deep Neural Network (DNN) to directly detect objects from radar images. This approach implicitly addresses the PSF's impact on objects of interest. In this paper, we propose an alternative approach, which we term \"Boosting Radar Reflections\" (BoostRad). In BoostRad, a first DNN is trained to narrow the PSF for all the reflection points in the scene. The output of the first DNN is a boosted reflection image with higher resolution and reduced clutter, resulting in a sharper and cleaner image. Subsequently, a second DNN is employed to detect objects within the boosted reflection image. We develop a novel method for training the boosting DNN that incorporates domain knowledge of radar's PSF characteristics. BoostRad's performance is evaluated using the RADDet and CARRADA datasets, revealing its superiority over reference methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuval Haitman",
      "Oded Bialer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pham_Frequency_Attention_for_Knowledge_Distillation_WACV_2024_paper.html": {
    "title": "Frequency Attention for Knowledge Distillation",
    "volume": "main",
    "abstract": "Knowledge distillation is an attractive approach for learning compact deep neural networks, which learns a lightweight student model by distilling knowledge from a complex teacher model. Attention-based knowledge distillation is a specific form of intermediate feature-based knowledge distillation that uses attention mechanisms to encourage the student to better mimic the teacher. However, most of the previous attention-based distillation approaches perform attention in the spatial domain, which primarily affects local regions in the input image. This may not be sufficient when we need to capture the broader context or global information necessary for effective knowledge transfer. In frequency domain, since each frequency is determined from all pixels of the image in spatial domain, it can contain global information about the image. Inspired by the benefits of the frequency domain, we propose a novel module that functions as an attention mechanism in the frequency domain. The module consists of a learnable global filter that can adjust the frequencies of student's features under the guidance of the teacher's features, which encourages the student's features to have patterns similar to the teacher's features. We then propose an enhanced knowledge review-based distillation model by leveraging the proposed frequency attention module. The extensive experiments with various teacher and student architectures on image classification and object detection benchmark datasets show that the proposed approach outperforms other knowledge distillation methods",
    "checked": false,
    "id": "79ac49735c1e50c5c17b7e688306bf30a0eaa561",
    "semantic_title": "few-shot radar jamming recognition network via time-frequency self-attention and global knowledge distillation",
    "citation_count": 5,
    "authors": [
      "Cuong Pham",
      "Van-Anh Nguyen",
      "Trung Le",
      "Dinh Phung",
      "Gustavo Carneiro",
      "Thanh-Toan Do"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jang_Lost_Your_Style_Navigating_With_Semantic-Level_Approach_for_Text-To-Outfit_Retrieval_WACV_2024_paper.html": {
    "title": "Lost Your Style? Navigating With Semantic-Level Approach for Text-To-Outfit Retrieval",
    "volume": "main",
    "abstract": "Fashion stylists have historically bridged the gap between consumers' desires and perfect outfits, which involve intricate combinations of colors, patterns, and materials. Although recent advancements in fashion recommendation systems have made strides in outfit compatibility prediction and complementary item retrieval, these systems rely heavily on pre-selected customer choices. Therefore, we introduce a groundbreaking approach to fashion recommendations: text-to-outfit retrieval task that generates a complete outfit set based solely on textual descriptions given by users. Our model is devised at three semantic levels--item, style, and outfit--where each level progressively aggregates data to form a coherent outfit recommendation based on textual input. Here, we leverage strategies similar to those in the contrastive language-image pretraining model to address the intricate-style matrix within the outfit sets. Using the Maryland Polyvore and Polyvore Outfit datasets, our approach significantly outperformed state-of-the-art models in text-video retrieval tasks, solidifying its effectiveness in the fashion recommendation domain. This research not only pioneers a new facet of fashion recommendation systems, but also introduces a method that captures the essence of individual style preferences through textual descriptions",
    "checked": true,
    "id": "9dae57e2a3856b243194acd1778aa8abe726d25e",
    "semantic_title": "lost your style? navigating with semantic-level approach for text-to-outfit retrieval",
    "citation_count": 0,
    "authors": [
      "Junkyu Jang",
      "Eugene Hwang",
      "Sung-Hyuk Park"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bashirov_MoRF_Mobile_Realistic_Fullbody_Avatars_From_a_Monocular_Video_WACV_2024_paper.html": {
    "title": "MoRF: Mobile Realistic Fullbody Avatars From a Monocular Video",
    "volume": "main",
    "abstract": "We present a system to create Mobile Realistic Fullbody (MoRF) avatars. MoRF avatars are rendered in real-time on mobile devices, learned from monocular videos, and have high realism. We use SMPL-X as a proxy geometry and render it with DNR (neural texture and image-2-image network). We improve on prior work, by overfitting per-frame warping fields in the neural texture space, allowing to better align the training signal between different frames. We also refine SMPL-X mesh fitting procedure to improve the overall avatar quality. In the comparisons to other monocular video-based avatar systems, MoRF avatars achieve higher image sharpness and temporal consistency. Participants of our user study also preferred avatars generated by MoRF",
    "checked": true,
    "id": "3990ccfe8f432b4815efbf69b00875770338ab87",
    "semantic_title": "morf: mobile realistic fullbody avatars from a monocular video",
    "citation_count": 1,
    "authors": [
      "Renat Bashirov",
      "Alexey Larionov",
      "Evgeniya Ustinova",
      "Mikhail Sidorenko",
      "David Svitov",
      "Ilya Zakharkin",
      "Victor Lempitsky"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Flotzinger_dacl10k_Benchmark_for_Semantic_Bridge_Damage_Segmentation_WACV_2024_paper.html": {
    "title": "dacl10k: Benchmark for Semantic Bridge Damage Segmentation",
    "volume": "main",
    "abstract": "Reliably identifying reinforced concrete defects (RCDs) plays a crucial role in assessing the structural integrity, traffic safety, and long-term durability of concrete bridges, which represent the most common bridge type worldwide. Nevertheless, available datasets for the recognition of RCDs are small in terms of size and class variety, which questions their usability in real-world scenarios and their role as a benchmark. Our contribution to this problem is \"dacl10k\", an exceptionally diverse RCD dataset for multi-label semantic segmentation comprising 9,920 images deriving from real-world bridge inspections. dacl10k distinguishes 12 damage classes as well as 6 bridge components that play a key role in the building assessment and recommending actions, such as restoration works, traffic load limitations or bridge closures. In addition, we examine baseline models for dacl10k which are subsequently evaluated. The best model achieves a mean intersection-over-union of 0.42 on the test set. dacl10k, along with our baselines, will be openly accessible to researchers and practitioners, representing the currently biggest dataset regarding number of images and class diversity for semantic segmentation in the bridge inspection domain",
    "checked": true,
    "id": "fc3c9624b60ff9b12b66bd979deb7d78a90b2a56",
    "semantic_title": "dacl10k: benchmark for semantic bridge damage segmentation",
    "citation_count": 1,
    "authors": [
      "Johannes Flotzinger",
      "Philipp J. Rösch",
      "Thomas Braml"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bernhard_Whats_Outside_the_Intersection_Fine-Grained_Error_Analysis_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "What's Outside the Intersection? Fine-Grained Error Analysis for Semantic Segmentation Beyond IoU",
    "volume": "main",
    "abstract": "Semantic segmentation represents a fundamental task in computer vision with various application areas such as autonomous driving, medical imaging, or remote sensing. For evaluating and comparing semantic segmentation models, the mean intersection over union (mIoU) is currently the gold standard. However, while mIoU serves as a valuable benchmark, it does not offer insights into the types of errors incurred by a model. Moreover, different types of errors may have different impacts on downstream applications. To address this issue, we propose an intuitive method for the systematic categorization of errors, thereby enabling a fine-grained analysis of semantic segmentation models. Since we assign each erroneous pixel to precisely one error type, our method seamlessly extends the popular IoU-based evaluation by shedding more light on the false positive and false negative predictions. Our approach is model- and dataset-agnostic, as it does not rely on additional information besides the predicted and ground-truth segmentation masks. In our experiments, we demonstrate that our method accurately assesses model strengths and weaknesses on a quantitative basis, thus reducing the dependence on time-consuming qualitative model inspection. We analyze a variety of state-of-the-art semantic segmentation models, revealing systematic differences across various architectural paradigms. Exploiting the gained insights, we showcase that combining two models with complementary strengths in a straightforward way is sufficient to consistently improve mIoU, even for models setting the current state of the art on ADE20K. We release a toolkit for our evaluation method at https://github.com/mxbh/beyond-iou",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Bernhard",
      "Roberto Amoroso",
      "Yannic Kindermann",
      "Lorenzo Baraldi",
      "Rita Cucchiara",
      "Volker Tresp",
      "Matthias Schubert"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ghaleb_Co-Speech_Gesture_Detection_Through_Multi-Phase_Sequence_Labeling_WACV_2024_paper.html": {
    "title": "Co-Speech Gesture Detection Through Multi-Phase Sequence Labeling",
    "volume": "main",
    "abstract": "Gestures are integral components of face-to-face communication. They unfold over time, often following predictable movement phases of preparation, stroke, and retraction. Yet, the prevalent approach to automatic gesture detection treats the problem as binary classification, classifying a segment as either containing a gesture or not, thus failing to capture its inherently sequential and contextual nature. To address this, we introduce a novel framework that reframes the task as a multi-phase sequence labeling problem rather than binary classification. Our model processes sequences of skeletal movements over time windows, uses Transformer encoders to learn contextual embeddings, and leverages Conditional Random Fields to perform sequence labeling. We evaluate our proposal on a large dataset of diverse co-speech gestures in task-oriented face-to-face dialogues. The results consistently demonstrate that our method significantly outperforms strong baseline models in detecting gesture strokes. Furthermore, applying Transformer encoders to learn contextual embeddings from movement sequences substantially improves gesture unit detection. These results highlight our framework's capacity to capture the fine-grained dynamics of co-speech gesture phases, paving the way for more nuanced and accurate gesture detection and analysis",
    "checked": true,
    "id": "8772fac45cd1b1292147421687725a85f33cad0a",
    "semantic_title": "co-speech gesture detection through multi-phase sequence labeling",
    "citation_count": 1,
    "authors": [
      "Esam Ghaleb",
      "Ilya Burenko",
      "Marlou Rasenberg",
      "Wim Pouw",
      "Peter Uhrig",
      "Judith Holler",
      "Ivan Toni",
      "Aslı Özyürek",
      "Raquel Fernández"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Maheshwari_Missing_Modality_Robustness_in_Semi-Supervised_Multi-Modal_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Missing Modality Robustness in Semi-Supervised Multi-Modal Semantic Segmentation",
    "volume": "main",
    "abstract": "Using multiple spatial modalities has been proven helpful in improving semantic segmentation performance. However, there are several real-world challenges that have yet to be addressed: (a) improving label efficiency and (b) enhancing robustness in realistic scenarios where modalities are missing at the test time. To address these challenges, we first propose a simple yet efficient multi-modal fusion mechanism Linear Fusion, that performs better than the state-of-the-art multi-modal models even with limited supervision. Second, we propose M3L: Multi-modal Teacher for Masked Modality Learning, a semi-supervised framework that not only improves the multi-modal performance but also makes the model robust to the realistic missing modality scenario using unlabeled data. We create the first benchmark for semi-supervised multi-modal semantic segmentation and also report the robustness to missing modalities. Our proposal shows an absolute improvement of up to 5% on robust mIoU above the most competitive baselines. Our project page is at https://harshm121.github.io/projects/m3l.html",
    "checked": true,
    "id": "b767a2193c6ba98e11d482ad96aa7d860e492593",
    "semantic_title": "missing modality robustness in semi-supervised multi-modal semantic segmentation",
    "citation_count": 2,
    "authors": [
      "Harsh Maheshwari",
      "Yen-Cheng Liu",
      "Zsolt Kira"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ben-Dov_Adversarial_Likelihood_Estimation_With_One-Way_Flows_WACV_2024_paper.html": {
    "title": "Adversarial Likelihood Estimation With One-Way Flows",
    "volume": "main",
    "abstract": "Generative Adversarial Networks (GANs) can produce high-quality samples, but do not provide an estimate of the probability density around the samples. However, it has been noted that maximizing the log-likelihood within an energy-based setting can lead to an adversarial framework where the discriminator provides unnormalized density (often called energy). We further develop this perspective, incorporate importance sampling, and show that 1) Wasserstein GAN performs a biased estimate of the partition function, and we propose instead to use an unbiased estimator; and 2) when optimizing for likelihood, one must maximize generator entropy. This is hypothesized to provide a better mode coverage. Different from previous works, we explicitly compute the density of the generated samples. This is the key enabler to designing an unbiased estimator of the partition function and computation of the generator entropy term. The generator density is obtained via a new type of flow network, called one-way flow network, that is less constrained in terms of architecture, as it does not require a tractable inverse function. Our experimental results show that our method converges faster, produces comparable sample quality to GANs with similar architecture, successfully avoids over-fitting to commonly used datasets and produces smooth low-dimensional latent representations of the training data",
    "checked": true,
    "id": "d6d6b1e6b4579c4005e024b964eecca04f190e05",
    "semantic_title": "adversarial likelihood estimation with one-way flows",
    "citation_count": 0,
    "authors": [
      "Omri Ben-Dov",
      "Pravir Singh Gupta",
      "Victoria Abrevaya",
      "Michael J. Black",
      "Partha Ghosh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chang_Fast_Sun-Aligned_Outdoor_Scene_Relighting_Based_on_TensoRF_WACV_2024_paper.html": {
    "title": "Fast Sun-Aligned Outdoor Scene Relighting Based on TensoRF",
    "volume": "main",
    "abstract": "In this work, we introduce our method of outdoor scene relighting for Neural Radiance Fields (NeRF) named Sun-aligned Relighting TensoRF (SR-TensoRF). SR-TensoRF offers a lightweight and rapid pipeline aligned with the sun, thereby achieving a simplified workflow that eliminates the need for environment maps. Our sun-alignment strategy is motivated by the insight that shadows, unlike viewpoint-dependent albedo, are determined by light direction. We directly use the sun direction as an input during shadow generation, simplifying the requirements of the inference process significantly. Moreover, SR-TensoRF leverages the training efficiency of TensoRF by incorporating our proposed cubemap concept, resulting in notable acceleration in both training and rendering processes compared to existing methods",
    "checked": true,
    "id": "53f85ab058fbc33006399558f5f581eeb2dfbc8b",
    "semantic_title": "fast sun-aligned outdoor scene relighting based on tensorf",
    "citation_count": 0,
    "authors": [
      "Yeonjin Chang",
      "Yearim Kim",
      "Seunghyeon Seo",
      "Jung Yi",
      "Nojun Kwak"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hong_Robust_Eye_Blink_Detection_Using_Dual_Embedding_Video_Vision_Transformer_WACV_2024_paper.html": {
    "title": "Robust Eye Blink Detection Using Dual Embedding Video Vision Transformer",
    "volume": "main",
    "abstract": "Eye blink detection serves as a crucial biomarker for evaluating both physical and mental states, garnering considerable attention in biometric and video-based studies. Among various methods, video-based eye blink detection has been particularly favored due to its non-invasive nature, enabling broader applications. However, capturing eye blinks from different camera angles poses significant challenges, primarily because the eye region is relatively small and eye blinks occur rapidly, necessitating a robust detection algorithm. To address these challenges, we introduce Dual Embedding Video Vision Transformer (DE-ViViT), a novel approach for eye blink detection that employs two different embedding strategies: (i) tubelet embedding and (ii) residual embedding. Each embedding can capture large and subtle changes within the eye movement sequence respectively. We rigorously evaluate our proposed method using HUST-LEBW, a publicly available dataset, as well as our newly collected multi-angle eye blink dataset (MAEB). The results indicate that the proposed model consistently outperforms existing methods across both datasets, with notably minor performance variations depending on the camera angles",
    "checked": true,
    "id": "729e6c1b6021879f2084c8a920299769df25f8e7",
    "semantic_title": "robust eye blink detection using dual embedding video vision transformer",
    "citation_count": 0,
    "authors": [
      "Jeongmin Hong",
      "Joseph Shin",
      "Juhee Choi",
      "Minsam Ko"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Domain_Generalisation_via_Risk_Distribution_Matching_WACV_2024_paper.html": {
    "title": "Domain Generalisation via Risk Distribution Matching",
    "volume": "main",
    "abstract": "We propose a novel approach for domain generalisation (DG) leveraging risk distributions to characterise domains, thereby achieving domain invariance. In our findings, risk distributions effectively highlight differences between training domains and reveal their inherent complexities. In testing, we may observe similar, or potentially intensifying in magnitude, divergences between risk distributions. Hence, we propose a compelling proposition: Minimising the divergences between risk distributions across training domains leads to robust invariance for DG. The key rationale behind this concept is that a model, trained on domain-invariant or stable features, may consistently produce similar risk distributions across various domains. Building upon this idea, we propose Risk Distribution Matching (RDM). Using the maximum mean discrepancy (MMD) distance, RDM aims to minimise the variance of risk distributions across training domains. However, when the number of domains increases, the direct optimisation of variance leads to linear growth in MMD computations, resulting in inefficiency. Instead, we propose an approximation that requires only one MMD computation, by aligning just two distributions: that of the worst-case domain and the aggregated distribution from all domains. Notably, this method empirically outperforms optimising distributional variance while being computationally more efficient. Unlike conventional DG matching algorithms, RDM stands out for its enhanced efficacy by concentrating on scalar risk distributions, sidestepping the pitfalls of high-dimensional challenges seen in feature or gradient matching. Our extensive experiments on standard benchmark datasets demonstrate that RDM shows superior generalisation capability over state-of-the-art DG methods",
    "checked": true,
    "id": "82ee2ef27b9738e5f7bbf884acc975ff19be43bd",
    "semantic_title": "domain generalisation via risk distribution matching",
    "citation_count": 0,
    "authors": [
      "Toan Nguyen",
      "Kien Do",
      "Bao Duong",
      "Thin Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Panelformer_Sewing_Pattern_Reconstruction_From_2D_Garment_Images_WACV_2024_paper.html": {
    "title": "Panelformer: Sewing Pattern Reconstruction From 2D Garment Images",
    "volume": "main",
    "abstract": "In this paper, we present a novel approach for reconstructing garment sewing patterns from 2D garment images. Our method addresses the challenge of handling occlusion in 2D images by leveraging the symmetric and correlated nature of garment panels. We introduce a transformer-based deep neural network called Panelformer that learns the parametric space of garment sewing patterns. The network comprises two components: the panel transformer and the stitch predictor. The panel transformer estimates the parametric panel shapes, including the occluded panels, by learning from the visible ones. The stitch predictor determines the stitching information among the predicted panels, enabling the reconstruction of the complete garment. To mitigate the overfitting problem caused by strong panel correlations, we propose two tailor-made data augmentation techniques: panel masking and garment mixing. These techniques generate a wider variety of panel combinations, enhancing the model's robustness and generalization capability. We evaluate the effectiveness of Panelformer using a synthetic dataset with diverse garment types. The experimental results demonstrate that our method outperforms competing baselines and achieves comparable performance to NeuralTailor, which operates on 3D point cloud data. This validates the efficacy of our approach in the context of garment sewing pattern reconstruction. By utilizing 2D images as input, our method expands the potential applications of garment modeling and offers easy accessibility to end users. Our code is available online",
    "checked": false,
    "id": "aaedb11eac8c65e9d4e8f56e6004b0d3010ddf3d",
    "semantic_title": "panelformer: sewing pattern reconstruction from 2d garment images supplemental material",
    "citation_count": 0,
    "authors": [
      "Cheng-Hsiu Chen",
      "Jheng-Wei Su",
      "Min-Chun Hu",
      "Chih-Yuan Yao",
      "Hung-Kuo Chu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Omidi_Unsupervised_Domain_Adaptation_of_MRI_Skull-Stripping_Trained_on_Adult_Data_WACV_2024_paper.html": {
    "title": "Unsupervised Domain Adaptation of MRI Skull-Stripping Trained on Adult Data to Newborns",
    "volume": "main",
    "abstract": "Skull-stripping is an important first step when analyzing brain Magnetic Resonance Imaging (MRI) data. Deep learning-based supervised segmentation models, such as the U-net model, have shown promising results in automating this segmentation task. However, when it comes to newborn MRI data, there are no publicly available brain MRI datasets that come with manually annotated segmentation masks to be used as labels during the training of these models. Manual segmentation of brain MR images is time-consuming, labor-intensive, and requires expertise. Furthermore, using a segmentation model trained on adult brain MR images for segmenting newborn brain images is not effective due to a large domain shift between adult and newborn data. As a result, there is a need for more efficient and accurate skull-stripping methods for newborns' brain MRIs. In this paper, we present an unsupervised approach to adapt a U-net skull-stripping model trained on adult MRI to work effectively on newborns. Our results demonstrate the effectiveness of our novel unsupervised approach in enhancing segmentation accuracy. Our proposed method achieved an overall Dice coefficient of 0.916 +- 0.032 (mean +- std), and our ablation studies confirmed the effectiveness of our proposal. Remarkably, despite being unsupervised, our model's performance stands in close proximity to that of the current state-of-the-art supervised models against which we conducted our comparisons. These findings indicate the potential of this method as a valuable, easier, and faster tool for supporting healthcare professionals in the examination of MR images of newborn brains. All the codes are available at: https://github.com/abbasomidi77/DAUnet",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abbas Omidi",
      "Aida Mohammadshahi",
      "Neha Gianchandani",
      "Regan King",
      "Lara Leijser",
      "Roberto Souza"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Generated_Distributions_Are_All_You_Need_for_Membership_Inference_Attacks_WACV_2024_paper.html": {
    "title": "Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models",
    "volume": "main",
    "abstract": "Generative models have demonstrated revolutionary success in various visual creation tasks, but in the meantime, they have been exposed to the threat of leaking private information of their training data. Several membership inference attacks (MIAs) have been proposed to exhibit the privacy vulnerability of generative models by classifying a query image as a training dataset member or nonmember. However, these attacks suffer from major limitations, such as requiring shadow models and white-box access, and either ignoring or only focusing on the unique property of diffusion models, which block their generalization to multiple generative models. In contrast, we propose the first generalized membership inference attack against a variety of generative models such as generative adversarial networks, [variational] autoencoders, implicit functions, and the emerging diffusion models. We leverage only generated distributions from target generators and auxiliary non-member datasets, therefore regarding target generators as black boxes and agnostic to their architectures or application scenarios. Experiments validate that all the generative models are vulnerable to our attack. For instance, our work achieves attack AUC > 0.99 against DDPM, DDIM, and FastDPM trained on CIFAR-10 and CelebA. And the attack against VQGAN, LDM (for the text-conditional generation), and LIIF achieves AUC > 0.90. As a result, we appeal to our community to be aware of such privacy leakage risks when designing and publishing generative models",
    "checked": true,
    "id": "5e1015f87ccc0ef57c0a098395ebecc9bc6b2379",
    "semantic_title": "generated distributions are all you need for membership inference attacks against generative models",
    "citation_count": 0,
    "authors": [
      "Minxing Zhang",
      "Ning Yu",
      "Rui Wen",
      "Michael Backes",
      "Yang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shen_Multitask_Vision-Language_Prompt_Tuning_WACV_2024_paper.html": {
    "title": "Multitask Vision-Language Prompt Tuning",
    "volume": "main",
    "abstract": "Prompt Tuning, conditioning on task-specific learned prompt vectors, has emerged as a data-efficient and parameter-efficient method for adapting large pretrained vision-language models to multiple downstream tasks. However, existing approaches usually consider learning prompt vectors for each task independently from scratch, thereby failing to exploit the rich shareable knowledge across different vision-language tasks. In this paper, we propose multitask vision-language prompt tuning (MVLPT), which incorporates cross-task knowledge into prompt tuning for vision-language models. Specifically, (i) we demonstrate the effectiveness of learning a single transferable prompt from multiple source tasks to initialize the prompt for each target task; (ii) we show many target tasks can benefit each other from sharing prompt vectors and thus can be jointly learned via multitask prompt tuning. We benchmark the proposed MVLPT using three representative prompt tuning methods, namely text prompt tuning, visual prompt tuning, and the unified vision-language prompt tuning. Results in 20 vision tasks demonstrate that the proposed approach outperforms all single-task baseline prompt tuning methods, setting the new state-of-the-art on the few-shot ELEVATER benchmarks and cross-task generalization benchmarks. To understand where the cross-task knowledge is most effective, we also conduct a large-scale study on task transferability with 20 vision tasks in 400 combinations for each prompt tuning method. It shows that the most performant MVLPT for each prompt tuning method prefers different task combinations and many tasks can benefit each other, depending on their visual similarity and label similarity",
    "checked": true,
    "id": "fd8c1b8741163d8737652fbcd3507bcd7d6225c7",
    "semantic_title": "multitask vision-language prompt tuning",
    "citation_count": 19,
    "authors": [
      "Sheng Shen",
      "Shijia Yang",
      "Tianjun Zhang",
      "Bohan Zhai",
      "Joseph E. Gonzalez",
      "Kurt Keutzer",
      "Trevor Darrell"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Barbany_ProcSim_Proxy-Based_Confidence_for_Robust_Similarity_Learning_WACV_2024_paper.html": {
    "title": "ProcSim: Proxy-Based Confidence for Robust Similarity Learning",
    "volume": "main",
    "abstract": "Deep Metric Learning (DML) methods aim at learning an embedding space in which distances are closely related to the inherent semantic similarity of the inputs. Previous studies have shown that popular benchmark datasets often contain numerous wrong labels, and DML methods are susceptible to them. Intending to study the effect of realistic noise, we create an ontology of the classes in a dataset and use it to simulate semantically coherent labeling mistakes. To train robust DML models, we propose ProcSim, a simple framework that assigns a confidence score to each sample using the normalized distance to its class representative. The experimental results show that the proposed method achieves state-of-the-art performance on the DML benchmark datasets injected with uniform and the proposed semantically coherent noise",
    "checked": true,
    "id": "1d64d37f1ebc80098ef4a5c321345f33ab1eaf99",
    "semantic_title": "procsim: proxy-based confidence for robust similarity learning",
    "citation_count": 0,
    "authors": [
      "Oriol Barbany",
      "Xiaofan Lin",
      "Muhammet Bastan",
      "Arnab Dhua"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Hard-Label_Based_Small_Query_Black-Box_Adversarial_Attack_WACV_2024_paper.html": {
    "title": "Hard-Label Based Small Query Black-Box Adversarial Attack",
    "volume": "main",
    "abstract": "We consider the hard-label based black-box adversarial attack setting which solely observes the target model's predicted class. Most of the attack methods in this setting suffer from impractical number of queries required to achieve a successful attack. One approach to tackle this drawback is utilising the adversarial transferability between white-box surrogate models and black-box target model. However, the majority of the methods adopting this approach are soft-label based to take the full advantage of zeroth-order optimisation. Unlike mainstream methods, we propose a new practical setting of hard-label based attack with an optimisation process guided by a pre-trained surrogate model. Experiments show the proposed method significantly improves the query efficiency of the hard-label based black-box attack across various target model architectures. We find the proposed method achieves approximately 5 times higher attack success rate compared to the benchmarks, especially at the small query budgets as 100 and 250",
    "checked": false,
    "id": "2268170f52722f20d295d7532b8a8ef569ed00b6",
    "semantic_title": "boundary defense against black-box adversarial attacks",
    "citation_count": 4,
    "authors": [
      "Jeonghwan Park",
      "Paul Miller",
      "Niall McLaughlin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kwon_Learning_to_Detour_Shortcut_Mitigating_Augmentation_for_Weakly_Supervised_Semantic_WACV_2024_paper.html": {
    "title": "Learning to Detour: Shortcut Mitigating Augmentation for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Weakly supervised semantic segmentation (WSSS) employing weak forms of labels has been actively studied to alleviate the annotation cost of acquiring pixel-level labels. However, classifiers trained on biased datasets tend to exploit shortcut features and make predictions based on spurious correlations between certain backgrounds and objects, leading to a poor generalization performance. In this paper, we propose shortcut mitigating augmentation (SMA) for WSSS, which generates synthetic representations of object-background combinations not seen in the training data to reduce the use of shortcut features. Our approach disentangles the object-relevant and background features. We then shuffle and combine the disentangled representations to create synthetic features of diverse object-background combinations. SMA-trained classifier depends less on contexts and focuses more on the target object when making predictions. In addition, we analyzed the behavior of the classifier on shortcut usage after applying our augmentation using an attribution method-based metric. The proposed method achieved the improved performance of semantic segmentation result on PASCAL VOC 2012 and MS COCO 2014 datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "JuneHyoung Kwon",
      "Eunju Lee",
      "Yunsung Cho",
      "YoungBin Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Trinh_3D_Super-Resolution_Model_for_Vehicle_Flow_Field_Enrichment_WACV_2024_paper.html": {
    "title": "3D Super-Resolution Model for Vehicle Flow Field Enrichment",
    "volume": "main",
    "abstract": "In vehicle shape design from aerodynamic performance perspective, deep learning methods enable us to estimate the flow field in a short period. However, the estimated flow fields are generally coarse and of low resolution. Therefore, a super-resolution model is required to enrich them. In this study, we propose a novel super-resolution model to enrich the flow fields around the vehicle to a higher resolution. To deal with the complex flow fields of vehicles, we apply the residual-in-residual dense block (RRDB) as the basic network-building unit in the generator without batch normalization. We then apply the relativistic discriminator to provide better feedback regarding the lack of high-frequency components. In addition, we propose a distance-weighted loss to obtain better estimation in wake regions and regions near the vehicle surface. Physics-informed loss is used to help the model generate data that satisfies the physical governing equations. We also propose a new training strategy to improve the leaning effectiveness and avoid instability during training. Experimental results demonstrate that the proposed method outperforms the previous study in vehicle flow field enrichment tasks by a significant margin",
    "checked": false,
    "id": "4a73c896a0cb841c35ddecfb9211a109100e2dd8",
    "semantic_title": "step into geological samples digital twins",
    "citation_count": 0,
    "authors": [
      "Thanh Luan Trinh",
      "Fangge Chen",
      "Takuya Nanri",
      "Kei Akasaka"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liao_Multi-View_3D_Object_Reconstruction_and_Uncertainty_Modelling_With_Neural_Shape_WACV_2024_paper.html": {
    "title": "Multi-View 3D Object Reconstruction and Uncertainty Modelling With Neural Shape Prior",
    "volume": "main",
    "abstract": "3D object reconstruction is important for semantic scene understanding. It is challenging to reconstruct detailed 3D shapes from monocular images directly due to a lack of depth information, occlusion and noise. Most current methods generate deterministic object models without any awareness of the uncertainty of the reconstruction. We tackle this problem by leveraging a neural object representation which learns an object shape distribution from large dataset of 3d object models and maps it into a latent space. We propose a method to model uncertainty as part of the representation and define an uncertainty-aware encoder which generates latent codes with uncertainty directly from individual input images. Further, we propose a method to propagate the uncertainty in the latent code to SDF values and generate a 3d object mesh with local uncertainty for each mesh component. Finally, we propose an incremental fusion method under a Bayesian framework to fuse the latent codes from multi-view observations. We evaluate the system in both synthetic and real datasets to demonstrate the effectiveness of uncertainty-based fusion to improve 3D object reconstruction accuracy",
    "checked": true,
    "id": "d2e2bba282438864c1ed6dfa5bd4d1ea4ee3f82d",
    "semantic_title": "multi-view 3d object reconstruction and uncertainty modelling with neural shape prior",
    "citation_count": 1,
    "authors": [
      "Ziwei Liao",
      "Steven L. Waslander"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Djilali_Do_VSR_Models_Generalize_Beyond_LRS3_WACV_2024_paper.html": {
    "title": "Do VSR Models Generalize Beyond LRS3?",
    "volume": "main",
    "abstract": "The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of intense research in visual speech recognition (VSR) during the last few years. As a result, there is an increased risk of overfitting to its excessively used test set, which is only one hour duration. To alleviate this issue, we build a new VSR test set by closely following the LRS3 dataset creation processes. We then evaluate and analyse the extent to which the current VSR models generalize to the new test data. We evaluate a broad range of publicly available VSR models and find significant drops in performance on our test set, compared to their corresponding LRS3 results. Our results suggest that the increase in word error rates is caused by the models' inability to generalize to slightly \"harder\" and more realistic lip sequences than those found in the LRS3 test set. Our new test benchmark will be made public in order to enable future research towards more robust VSR models",
    "checked": true,
    "id": "f08076332559023bb8665875f9b7769c399b8836",
    "semantic_title": "do vsr models generalize beyond lrs3?",
    "citation_count": 0,
    "authors": [
      "Yasser Abdelaziz Dahou Djilali",
      "Sanath Narayan",
      "Eustache LeBihan",
      "Haithem Boussaid",
      "Ebtesam Almazrouei",
      "Merouane Debbah"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dessalene_Context_in_Human_Action_Through_Motion_Complementarity_WACV_2024_paper.html": {
    "title": "Context in Human Action Through Motion Complementarity",
    "volume": "main",
    "abstract": "Motivated by Goldman's Theory of Human Action - a framework in which action decomposes into 1) base physical movements, and 2) the context in which they occur - we propose a novel learning formulation for motion and context, where context is derived as the complement to motion. More specifically, we model physical movement through the adoption of Therbligs, a set of elemental physical motions centered around object manipulation. Context is modeled through the use of a contrastive mutual information loss that formulates context information as the action information not contained within movement information. We empirically prove the utility brought by this separation of representation, showing sizable improvements in action recognition and action anticipation accuracies for a variety of models. We present results over two object manipulation datasets: EPIC Kitchens 100, and 50 Salads",
    "checked": true,
    "id": "5ca21164fc4b035f2f95c65ffe4453918cee2f3d",
    "semantic_title": "context in human action through motion complementarity",
    "citation_count": 0,
    "authors": [
      "Eadom Dessalene",
      "Michael Maynord",
      "Cornelia Fermüller",
      "Yiannis Aloimonos"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hooda_D4_Detection_of_Adversarial_Diffusion_Deepfakes_Using_Disjoint_Ensembles_WACV_2024_paper.html": {
    "title": "D4: Detection of Adversarial Diffusion Deepfakes Using Disjoint Ensembles",
    "volume": "main",
    "abstract": "Detecting diffusion-generated deepfake images remains an open problem. Current detection methods fail against an adversary who adds imperceptible adversarial perturbations to the deepfake to evade detection. In this work, we propose Disjoint Diffusion Deepfake Detection (D4), a deepfake detector designed to improve black-box adversarial robustness beyond de facto solutions such as adversarial training. D4 uses an ensemble of models over disjoint subsets of the frequency spectrum to significantly improve adversarial robustness. Our key insight is to leverage a redundancy in the frequency domain and apply a saliency partitioning technique to disjointly distribute frequency components across multiple models. We formally prove that these disjoint ensembles lead to a reduction in the dimensionality of the input subspace where adversarial deepfakes lie, thereby making adversarial deepfakes harder to find for black-box attacks. We then empirically validate the D4 method against several black-box attacks and find that D4 significantly outperforms existing state-of-the-art defenses applied to diffusion-generated deepfake detection. We also demonstrate that D4 provides robustness against adversarial deepfakes from unseen data distributions as well as unseen generative techniques",
    "checked": true,
    "id": "d22030f2211d274187f6bf8b70736ec0ebb91e34",
    "semantic_title": "d4: detection of adversarial diffusion deepfakes using disjoint ensembles",
    "citation_count": 1,
    "authors": [
      "Ashish Hooda",
      "Neal Mangaokar",
      "Ryan Feng",
      "Kassem Fawaz",
      "Somesh Jha",
      "Atul Prakash"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Di_ProS_Facial_Omni-Representation_Learning_via_Prototype-Based_Self-Distillation_WACV_2024_paper.html": {
    "title": "ProS: Facial Omni-Representation Learning via Prototype-Based Self-Distillation",
    "volume": "main",
    "abstract": "This paper presents a novel approach, called Prototype-based Self-Distillation (ProS), for unsupervised face representation learning. The existing supervised methods heavily rely on a large amount of annotated training facial data, which poses challenges in terms of data collection and privacy concerns. To address these issues, we propose ProS, which leverages a vast collection of unlabeled face images to learn a comprehensive facial omni-representation. In particular, ProS consists of two vision-transformers (teacher and student models) that are trained with different augmented images (cropping, blurring, coloring, etc.). Besides, we build a face-aware retrieval system along with augmentations to obtain the curated images comprising predominantly facial areas. To enhance the discrimination of learned features, we introduce a prototype-based matching loss that aligns the similarity distributions between features (teacher or student) and a set of learnable prototypes. After pre-training, the teacher vision transformer serves as a backbone for downstream tasks, including attribute estimation, expression recognition, and landmark alignment, achieved through simple fine-tuning with additional layers. Extensive experiments demonstrate that our method achieves state-of-the-art performance on various tasks, both in full and few-shot settings. Furthermore, we investigate pre-training with synthetic face images, and ProS exhibits promising performance in this scenario as well",
    "checked": true,
    "id": "08071e1175b2da1fd796589ae112e40342693c65",
    "semantic_title": "pros: facial omni-representation learning via prototype-based self-distillation",
    "citation_count": 0,
    "authors": [
      "Xing Di",
      "Yiyu Zheng",
      "Xiaoming Liu",
      "Yu Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_TCP_Triplet_Contrastive-Relationship_Preserving_for_Class-Incremental_Learning_WACV_2024_paper.html": {
    "title": "TCP: Triplet Contrastive-Relationship Preserving for Class-Incremental Learning",
    "volume": "main",
    "abstract": "In class-incremental learning (CIL), when deep neural networks learn new classes, their recognition performance in old classes will drop significantly. This phenomenon is widely known as catastrophic forgetting. To alleviate catastrophic forgetting, existing methods store a small portion of old class data with a memory buffer and replay it while learning new classes. These methods suffer from a severe imbalance problem between old and new classes. In this paper, we discover that the imbalance problem in CIL makes it difficult to preserve the feature relation of old classes and hard to learn the feature relation between old and new classes. To mitigate the above two issues, we design a triplet contrastive preserving (TCP) loss to preserve old knowledge, and propose an asymmetric augmented contrastive learning (A2CL) method to learn new classes. Comprehensive experiments demonstrate the effectiveness of our method, which increases the average accuracies by 1.26% and 0.95% on CIFAR-100 and ImageNet. Especially under smaller memory buffer settings where the imbalance problem is more severe, our method can surpass the baselines by a large margin (up to 3.2%). We also show that TCP can be easily plugged into other methods and further improve their performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyao Li",
      "Xuefei Ning",
      "Shanghang Zhang",
      "Lidong Guo",
      "Tianchen Zhao",
      "Huazhong Yang",
      "Yu Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Musallam_Self-Supervised_Learning_for_Place_Representation_Generalization_Across_Appearance_Changes_WACV_2024_paper.html": {
    "title": "Self-Supervised Learning for Place Representation Generalization Across Appearance Changes",
    "volume": "main",
    "abstract": "Visual place recognition is a key to unlocking spatial navigation for animals, humans and robots. While state-of-the-art approaches are trained in a supervised manner and, therefore, hardly capture the information needed for generalizing to unusual conditions. We argue that self-supervised learning may help abstracting the place representation so that it can be foreseen, irrespective of the conditions. More precisely, in this paper, we investigate learning features that are robust to appearance modifications while sensitive to geometric transformations in a self-supervised manner. This dual-purpose training is made possible by combining the two self-supervision main paradigms, i.e. contrastive and predictive learning. Our results on standard benchmarks reveal that jointly learning such appearance-robust and geometry-sensitive image descriptors leads to competitive visual place recognition results across adverse seasonal and illumination conditions without requiring any humanannotated labels",
    "checked": true,
    "id": "6df2d8ce11107b1d4a84a5a76744a98a1cf29d15",
    "semantic_title": "self-supervised learning for place representation generalization across appearance changes",
    "citation_count": 0,
    "authors": [
      "Mohamed Adel Musallam",
      "Vincent Gaudillière",
      "Djamila Aouada"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Patch-Based_Selection_and_Refinement_for_Early_Object_Detection_WACV_2024_paper.html": {
    "title": "Patch-Based Selection and Refinement for Early Object Detection",
    "volume": "main",
    "abstract": "Early object detection (OD) is a crucial task for the safety of many dynamic systems. Current OD algorithms have limited success for small objects at a long distance. To improve the accuracy and efficiency of such a task, we propose a novel set of algorithms that divide the image into patches, select patches with objects at various scales, elaborate the details of a small object, and detect it as early as possible. Our approach is built upon a transformer-based network and integrates the diffusion model to improve the detection accuracy. As demonstrated on BDD100K, our algorithms enhance the mAP for small objects from 1.03 to 8.93, and reduce the data volume in computation by more than 77%",
    "checked": true,
    "id": "f966c89d2f63061daed90706f243682a2e59af51",
    "semantic_title": "patch-based selection and refinement for early object detection",
    "citation_count": 1,
    "authors": [
      "Tianyi Zhang",
      "Kishore Kasichainula",
      "Yaoxin Zhuo",
      "Baoxin Li",
      "Jae-Sun Seo",
      "Yu Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Berrada_Guided_Distillation_for_Semi-Supervised_Instance_Segmentation_WACV_2024_paper.html": {
    "title": "Guided Distillation for Semi-Supervised Instance Segmentation",
    "volume": "main",
    "abstract": "Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel \"guided burn-in\" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on the Cityscapes dataset we improve mask-AP from 23.7 to 33.9 when using labels for 10% of images, and on the COCO dataset we improve mask-AP from 18.3 to 34.1 when using labels for only 1% of the training data",
    "checked": true,
    "id": "a9b1414974257253222a88ddf23688aae0d8941d",
    "semantic_title": "guided distillation for semi-supervised instance segmentation",
    "citation_count": 0,
    "authors": [
      "Tariq Berrada",
      "Camille Couprie",
      "Karteek Alahari",
      "Jakob Verbeek"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Albanese_Optimizing_Long-Term_Robot_Tracking_With_Multi-Platform_Sensor_Fusion_WACV_2024_paper.html": {
    "title": "Optimizing Long-Term Robot Tracking With Multi-Platform Sensor Fusion",
    "volume": "main",
    "abstract": "Monitoring a fleet of robots requires stable long-term tracking with re-identification, which is yet an unsolved challenge in many scenarios. One application of this is the analysis of autonomous robotic soccer games at RoboCup. Tracking in these games requires handling of identically looking players, strong occlusions, and non-professional video recordings, but also offers state information estimated by the robots. In order to make effective use of the information coming from the robot sensors, we propose a robust tracking and identification pipeline. It fuses external non-calibrated camera data with the robots' internal states using quadratic optimization for tracklet matching. The approach is validated using game recordings from previous RoboCup World Cup tournaments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuliano Albanese",
      "Arka Mitra",
      "Jan-Nico Zaech",
      "Yupeng Zhao",
      "Ajad Chhatkuli",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mehta_HyperMix_Out-of-Distribution_Detection_and_Classification_in_Few-Shot_Settings_WACV_2024_paper.html": {
    "title": "HyperMix: Out-of-Distribution Detection and Classification in Few-Shot Settings",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) detection is an important topic for real-world machine learning systems, but settings with limited in-distribution samples have been underexplored. Such few-shot OOD settings are challenging, as models have scarce opportunities to learn the data distribution before being tasked with identifying OOD samples. Indeed, we demonstrate that recent state-of-the-art OOD methods fail to outperform simple baselines in the few-shot setting. We thus propose a hypernetwork framework called HyperMix, using Mixup on the generated classifier parameters, as well as a natural out-of-episode outlier exposure technique that does not require an additional outlier dataset. We conduct experiments on CIFAR-FS and MiniImageNet, significantly outperforming other OOD methods in the few-shot regime",
    "checked": true,
    "id": "05c8494cdeef84764f6a46a0802a74a12fdb70bb",
    "semantic_title": "hypermix: out-of-distribution detection and classification in few-shot settings",
    "citation_count": 0,
    "authors": [
      "Nikhil Mehta",
      "Kevin J. Liang",
      "Jing Huang",
      "Fu-Jen Chu",
      "Li Yin",
      "Tal Hassner"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bhattarai_TriPlaneNet_An_Encoder_for_EG3D_Inversion_WACV_2024_paper.html": {
    "title": "TriPlaneNet: An Encoder for EG3D Inversion",
    "volume": "main",
    "abstract": "Recent progress in NeRF-based GANs has introduced a number of approaches for high-resolution and high-fidelity generative modeling of human heads with a possibility for novel view rendering. At the same time, one must solve an inverse problem to be able to re-render or modify an existing image or video. Despite the success of universal optimization-based methods for 2D GAN inversion, those applied to 3D GANs may fail to extrapolate the result onto the novel view, whereas optimization-based 3D GAN inversion methods are time-consuming and can require at least several minutes per image. Fast encoder-based techniques, such as those developed for StyleGAN, may also be less appealing due to the lack of identity preservation. Our work introduces a fast technique that bridges the gap between the two approaches by directly utilizing the tri-plane representation presented for the EG3D generative model. In particular, we build upon a feed-forward convolutional encoder for the latent code and extend it with a fully-convolutional predictor of tri-plane numerical offsets. The renderings are similar in quality to the ones produced by optimization-based techniques and outperform the ones by encoder-based methods. As we empirically prove, this is a consequence of directly operating in the tri-plane space, not in the GAN parameter space, while making use of an encoder-based trainable approach. Finally, we demonstrate significantly more correct embedding of a face image in 3D than for all the baselines, further strengthened by a probably symmetric prior enabled during training",
    "checked": true,
    "id": "e996c09708a56ce074f4e72d1ae910a9a39f8b4f",
    "semantic_title": "triplanenet: an encoder for eg3d inversion",
    "citation_count": 11,
    "authors": [
      "Ananta R. Bhattarai",
      "Matthias Nießner",
      "Artem Sevastopolsky"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Anderson_Elusive_Images_Beyond_Coarse_Analysis_for_Fine-Grained_Recognition_WACV_2024_paper.html": {
    "title": "Elusive Images: Beyond Coarse Analysis for Fine-Grained Recognition",
    "volume": "main",
    "abstract": "While the community has seen many advances in recent years to address the challenging problem of Finegrained Visual Categorization (FGVC), progress seems to be slowing--new state-of-the-art methods often distinguish themselves by improving top-1 accuracy by mere tenths of a percent. However, across all of the now-standard FGVC datasets, there remain sizeable portions of the test data that none of the current state-of-the-art (SOTA) models can successfully predict. This paper provides a framework for identifying and studying the errors that current methods make across diverse fine-grained datasets. Three models of difficulty--Prediction Overlap, Prediction Rank and Pairwise Class Confusion--are employed to highlight the most challenging sets of images and classes. Extensive experiments apply a range of standard and SOTA methods, evaluating them on multiple FGVC domains and datasets. Insights acquired from coupling these difficulty paradigms with the careful analysis of experimental results suggest crucial areas for future FGVC research, focusing critically on the set of elusive images that none of the current models can correctly classify. Code is available at catalys1.github.io/elusive-images-fgvc",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Connor Anderson",
      "Matt Gwilliam",
      "Evelyn Gaskin",
      "Ryan Farrell"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dunnhofer_Tracking_Skiers_From_the_Top_to_the_Bottom_WACV_2024_paper.html": {
    "title": "Tracking Skiers From the Top to the Bottom",
    "volume": "main",
    "abstract": "Skiing is a popular winter sport discipline with a long history of competitive events. In this domain, computer vision has the potential to enhance the understanding of athletes' performance, but its application lags behind other sports due to limited studies and datasets. This paper makes a step forward in filling such gaps. A thorough investigation is performed on the task of skier tracking in a video capturing his/her complete performance. Obtaining continuous and accurate skier localization is preemptive for further higher-level performance analyses. To enable the study, the largest and most annotated dataset for computer vision in skiing, SkiTB, is introduced. Several visual object tracking algorithms, including both established methodologies and a newly introduced skier-optimized baseline algorithm, are tested using the dataset. The results provide valuable insights into the applicability of different tracking methods for vision-based skiing analysis. SkiTB, code, and results are available at https://machinelearning.uniud.it/datasets/skitb",
    "checked": true,
    "id": "1788dd2188df73639ee0a3f932e82eb0dd918114",
    "semantic_title": "tracking skiers from the top to the bottom",
    "citation_count": 0,
    "authors": [
      "Matteo Dunnhofer",
      "Luca Sordi",
      "Niki Martinel",
      "Christian Micheloni"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_BPKD_Boundary_Privileged_Knowledge_Distillation_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "BPKD: Boundary Privileged Knowledge Distillation for Semantic Segmentation",
    "volume": "main",
    "abstract": "Current knowledge distillation approaches in semantic segmentation tend to adopt a holistic approach that treats all spatial locations equally. However, for dense prediction, students' predictions on edge regions are highly uncertain due to contextual information leakage, requiring higher spatial sensitivity knowledge than the body regions. To address this challenge, this paper proposes a novel approach called boundary-privileged knowledge distillation (BPKD). it distils the knowledge from the teacher model's body and edges separately to the compact student model. Specifically, we employ two distinct loss functions: (i) edge loss, which aims to distinguish between ambiguous classes at the pixel level in edge regions; (ii) body loss, which utilizes shape constraints and selectively attends to the inner-semantic regions. Our experiments demonstrate that the proposed BPKD method provides extensive refinements and aggregation for edge and body regions. Additionally, the method achieves state-of-the-art distillation performance for semantic segmentation on three popular benchmark datasets, highlighting its effectiveness and generalization ability. BPKD shows consistent improvements across a diverse array of lightweight segmentation structures, including both CNNs and transformers, underscoring its architecture-agnostic adaptability",
    "checked": true,
    "id": "d88bad322c0b043ae0f2f00ccec1e3e10a55d68a",
    "semantic_title": "bpkd: boundary privileged knowledge distillation for semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Liyang Liu",
      "Zihan Wang",
      "Minh Hieu Phan",
      "Bowen Zhang",
      "Jinchao Ge",
      "Yifan Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xia_DREAM_Visual_Decoding_From_Reversing_Human_Visual_System_WACV_2024_paper.html": {
    "title": "DREAM: Visual Decoding From Reversing Human Visual System",
    "volume": "main",
    "abstract": "In this work we present DREAM, an fMRI-to-image method for reconstructing viewed images from brain activities, grounded on fundamental knowledge of the human visual system. We craft reverse pathways that emulate the hierarchical and parallel nature of how humans perceive the visual world. These tailored pathways are specialized to decipher semantics, color, and depth cues from fMRI data, mirroring the forward pathways from visual stimuli to fMRI recordings. To do so, two components mimic the inverse processes within the human visual system: the Reverse Visual Association Cortex (R-VAC) which reverses pathways of this brain region, extracting semantics from fMRI data; the Reverse Parallel PKM (R-PKM) component simultaneously predicting color and depth from fMRI signals. The experiments indicate that our method outperforms the current state-of-the-art models in terms of the consistency of appearance, structure, and semantics. Code will be available at https://github.com/weihaox/DREAM",
    "checked": true,
    "id": "5d998aed5a1b5143d4e79806cdb614281989587b",
    "semantic_title": "dream: visual decoding from reversing human visual system",
    "citation_count": 1,
    "authors": [
      "Weihao Xia",
      "Raoul de Charette",
      "Cengiz Oztireli",
      "Jing-Hao Xue"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Felt_Seeing_Stars_Learned_Star_Localization_for_Narrow-Field_Astrometry_WACV_2024_paper.html": {
    "title": "Seeing Stars: Learned Star Localization for Narrow-Field Astrometry",
    "volume": "main",
    "abstract": "Star localization in astronomical imagery is a computer vision task that underpins satellite tracking. Astronomical star extraction techniques often struggle to detect stars when applied to satellite tracking imagery due to the narrower fields of view and rate track observational modes of satellite tracking telescopes. We present a large dataset of real narrow-field rate-tracked imagery with ground truth stars, created using a combination of existing star detection techniques, an astrometric engine, and a star catalog. We train three state of the art object detection, instance segmentation, and line segment detection models on this dataset and evaluate them with object-wise, pixel-wise, and astrometric metrics. Our proposed approaches require no metadata; when paired with a lost-in-space astrometric engine, they find astrometric fits based solely on uncorrected image pixels. Experimental results on real data indicate the effectiveness of learned star detection: we report astrometric fit rates over double that of classical star detection algorithms, improved dim star recall, and comparable star localization residuals",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Violet Felt",
      "Justin Fletcher"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Demir_How_Do_Deepfakes_Move_Motion_Magnification_for_Deepfake_Source_Detection_WACV_2024_paper.html": {
    "title": "How Do Deepfakes Move? Motion Magnification for Deepfake Source Detection",
    "volume": "main",
    "abstract": "With the proliferation of deep generative models, deepfakes are improving in quality and quantity everyday. However, there are subtle authenticity signals in pristine videos, not replicated by current generative models. We contrast the movement in deepfakes and authentic videos by motion magnification towards building a generalized deepfake source detector. The sub-muscular motion in faces has different interpretations per different generative models, which is reflected in their generative residue. Our approach exploits the difference between real motion and the amplified generative artifacts, by combining deep and traditional motion magnification, to detect whether a video is fake and its source generator if so. Evaluating our approach on two multi-source datasets, we obtain 97.77% and 94.03% for video source detection. Our approach performs at least 4.08% better than the prior deepfake source detector and other complex architectures. We also analyze magnification amount, phase extraction window, backbone network, sample counts, and sample lengths. Finally, we report our results on skin tones and genders to assess the model bias",
    "checked": true,
    "id": "649b3575b51c8f22afcb725707957111eaa92d7c",
    "semantic_title": "how do deepfakes move? motion magnification for deepfake source detection",
    "citation_count": 2,
    "authors": [
      "Ilke Demir",
      "Umur Aybars Çiftçi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gopal_Separable_Self_and_Mixed_Attention_Transformers_for_Efficient_Object_Tracking_WACV_2024_paper.html": {
    "title": "Separable Self and Mixed Attention Transformers for Efficient Object Tracking",
    "volume": "main",
    "abstract": "The deployment of transformers for visual object tracking has shown state-of-the-art results on several benchmarks. However, the transformer-based models are under-utilized for Siamese lightweight tracking due to the computational complexity of their attention blocks. This paper proposes an efficient self and mixed attention transformer-based architecture for lightweight tracking. The proposed backbone utilizes the separable mixed attention transformers to fuse the template and search regions during feature extraction to generate superior feature encoding. Our prediction head performs global contextual modeling of the encoded features by leveraging efficient self-attention blocks for robust target state estimation. With these contributions, the proposed lightweight tracker deploys a transformer-based backbone and head module concurrently for the first time. Our ablation study testifies to the effectiveness of the proposed combination of backbone and head modules. Simulations show that our Separable Self and Mixed Attention-based Tracker, SMAT, surpasses the performance of related lightweight trackers on GOT10k, TrackingNet, LaSOT, NfS30, UAV123, and AVisT datasets, while running at 37 fps on CPU, 158 fps on GPU, and having 3.8M parameters. For example, it significantly surpasses the closely related trackers E.T.Track and MixFormerV2-S on GOT10k-test by a margin of 7.9% and 5.8%, respectively, in the AO metric. The tracker code and model is available at https://github.com/goutamyg/SMAT",
    "checked": true,
    "id": "c56f3121ccd1e2468ae797c757f2b29d91d70f85",
    "semantic_title": "separable self and mixed attention transformers for efficient object tracking",
    "citation_count": 0,
    "authors": [
      "Goutam Yelluru Gopal",
      "Maria A. Amer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ganz_CLIPAG_Towards_Generator-Free_Text-to-Image_Generation_WACV_2024_paper.html": {
    "title": "CLIPAG: Towards Generator-Free Text-to-Image Generation",
    "volume": "main",
    "abstract": "Perceptually Aligned Gradients (PAG) refer to an intriguing property observed in robust image classification models, wherein their input gradients align with human perception and pose semantic meanings. While this phenomenon has gained significant research attention, it was solely studied in the context of unimodal vision-only architectures. In this work, we extend the study of PAG to Vision-Language architectures, which form the foundations for diverse image-text tasks and applications. Through an adversarial robustification finetuning of CLIP, we demonstrate that robust Vision-Language models exhibit PAG in contrast to their vanilla counterparts. This work reveals the merits of CLIP with PAG (CLIPAG) in several vision-language generative tasks. Notably, we show that seamlessly integrating CLIPAG in a \"plug-n-play\" manner leads to substantial improvements in vision-language generative applications. Furthermore, leveraging its PAG property, CLIPAG enables text-to-image generation without any generative model, which typically requires huge generators",
    "checked": true,
    "id": "291d92da53d182c0fdf7eea465c9b519ef1fc1f3",
    "semantic_title": "clipag: towards generator-free text-to-image generation",
    "citation_count": 1,
    "authors": [
      "Roy Ganz",
      "Michael Elad"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rami_Source-Guided_Similarity_Preservation_for_Online_Person_Re-Identification_WACV_2024_paper.html": {
    "title": "Source-Guided Similarity Preservation for Online Person Re-Identification",
    "volume": "main",
    "abstract": "Online Unsupervised Domain Adaptation (OUDA) for person Re-Identification (Re-ID) is the task of continuously adapting a model trained on a well-annotated source-domain dataset to a target domain observed as a data stream. In OUDA, person Re-ID models face two main challenges: catastrophic forgetting and domain shift. In this work, we propose a new Source-guided Similarity Preservation (S2P) framework to alleviate these two problems. Our framework is based on the extraction of a support set composed of source images that maximizes the similarity with the target data. This support set is used to identify feature similarities that must be preserved during the learning process. S2P can incorporate multiple existing UDA methods to mitigate catastrophic forgetting. Our experiments show that S2P outperforms previous state-of-the-art methods on multiple real-to-real and synthetic-to-real challenging OUDA benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hamza Rami",
      "Jhony H. Giraldo",
      "Nicolas Winckler",
      "Stéphane Lathuilière"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Maag_Uncertainty-Weighted_Loss_Functions_for_Improved_Adversarial_Attacks_on_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Uncertainty-Weighted Loss Functions for Improved Adversarial Attacks on Semantic Segmentation",
    "volume": "main",
    "abstract": "State-of-the-art deep neural networks have been shown to be extremely powerful in a variety of perceptual tasks like semantic segmentation. However, these networks are vulnerable to adversarial perturbations of the input which are imperceptible for humans but lead to incorrect predictions. Treating image segmentation as a sum of pixel-wise classifications, adversarial attacks developed for classification models were shown to be applicable to segmentation models as well. In this work, we present simple uncertainty-based weighting schemes for the loss functions of such attacks that (i) put higher weights on pixel classifications which can more easily perturbed and (ii) zero-out the pixel-wise losses corresponding to those pixels that are already confidently misclassified. The weighting schemes can be easily integrated into the loss function of a range of well-known adversarial attackers with minimal additional computational overhead, but lead to significant improved perturbation performance, as we demonstrate in our empirical analysis on several datasets and models",
    "checked": true,
    "id": "d3fe3635e3288bd378b8d6228ef10536d854cbb0",
    "semantic_title": "uncertainty-weighted loss functions for improved adversarial attacks on semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Kira Maag",
      "Asja Fischer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rai_Towards_Realistic_Generative_3D_Face_Models_WACV_2024_paper.html": {
    "title": "Towards Realistic Generative 3D Face Models",
    "volume": "main",
    "abstract": "In recent years, there has been significant progress in 2D generative face models fueled by applications such as animation, synthetic data generation, and digital avatars. However, due to the absence of 3D information, these 2D models often struggle to accurately disentangle facial attributes like pose, expression, and illumination, limiting their editing capabilities. To address this limitation, this paper proposes a 3D controllable generative face model to produce high-quality albedo and precise 3D shapes by leveraging existing 2D generative models. By combining 2D face generative models with semantic face manipulation, this method enables editing of detailed 3D rendered faces. The proposed framework utilizes an alternating descent optimization approach over shape and albedo. Differentiable rendering is used to train high-quality shapes and albedo without 3D supervision. Moreover, this approach outperforms most state-of-the-art (SOTA) methods in the well-known NoW and REALY benchmarks for 3D face reconstruction. It also outperforms the SOTA reconstruction models in recovering rendered faces' identities across novel poses. Additionally, the paper demonstrates direct control of expressions in 3D faces by exploiting latent space leading to text-based editing of 3D faces",
    "checked": true,
    "id": "95ef8ca0c2d50e3d3d523812985d4dfcc9137651",
    "semantic_title": "towards realistic generative 3d face models",
    "citation_count": 5,
    "authors": [
      "Aashish Rai",
      "Hiresh Gupta",
      "Ayush Pandey",
      "Francisco Vicente Carrasco",
      "Shingo Jason Takagi",
      "Amaury Aubel",
      "Daeil Kim",
      "Aayush Prakash",
      "Fernando De la Torre"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Aminbeidokhti_Domain_Generalization_by_Rejecting_Extreme_Augmentations_WACV_2024_paper.html": {
    "title": "Domain Generalization by Rejecting Extreme Augmentations",
    "volume": "main",
    "abstract": "Data augmentation is one of the most powerful techniques for regularizing deep learning models and improving their recognition performance in a variety of tasks and domains. However, this holds for standard in-domain settings, in which the training and test data follow the same distribution. For the out-domain, in which the test data follows a different and unknown distribution, the best recipe for data augmentation is not clear. In this paper, we show that also for out-domain or domain generalization settings, data augmentation can bring a conspicuous and robust improvement in performance. For doing that, we propose a simple procedure: i) use uniform sampling on standard data augmentation transformations ii) increase transformations strength to adapt to the higher data variance expected when working out of domain iii) devise a new reward function to reject extreme transformations that can harm the training. With this simple formula, our data augmentation scheme achieves comparable or better results to state-of-the-art performance on most domain generalization datasets",
    "checked": true,
    "id": "1ce3e2440dd53beaaaeb0677483a9af5310e4e5b",
    "semantic_title": "domain generalization by rejecting extreme augmentations",
    "citation_count": 0,
    "authors": [
      "Masih Aminbeidokhti",
      "Fidel A. Guerrero Peña",
      "Heitor Rapela Medeiros",
      "Thomas Dubail",
      "Eric Granger",
      "Marco Pedersoli"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Prashanth_Towards_Accurate_Disease_Segmentation_in_Plant_Images_A_Comprehensive_Dataset_WACV_2024_paper.html": {
    "title": "Towards Accurate Disease Segmentation in Plant Images: A Comprehensive Dataset Creation and Network Evaluation",
    "volume": "main",
    "abstract": "Automated disease segmentation in plant images plays a crucial role in identifying and mitigating the impact of plant diseases on agricultural productivity. In this study, we address the problem of Northern Leaf Blight (NLB) disease segmentation in maize plants. We present a comprehensive dataset of 1000 plant images annotated with NLB disease regions. We employ the Mask R-CNN and Cascaded Mask R-CNN models with various backbone architectures to perform NLB disease segmentation. The experimental results demonstrate the effectiveness of the models in accurately delineating NLB disease regions. Specifically, the ResNet Strikes Back-50 backbone architecture achieves the highest mean average precision (mAP) score, indicating its ability to capture intricate details of NLB disease spots. Additionally, the cascaded approach enhances segmentation accuracy compared to the single-stage Mask R-CNN models. Our findings provide valuable insights into the performance of different backbone architectures and contribute to the development of automated NLB disease segmentation methods in plant images. The generated dataset and experimental results serve as a resource for further research in plant disease segmentation and management",
    "checked": true,
    "id": "bec5a34ae3cd081daf2f213892cdb58755453a02",
    "semantic_title": "towards accurate disease segmentation in plant images: a comprehensive dataset creation and network evaluation",
    "citation_count": 0,
    "authors": [
      "Komuravelli Prashanth",
      "Jaladi Sri Harsha",
      "Sivapuram Arun Kumar",
      "Jaladi Srilekha"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Deep_Subdomain_Alignment_for_Cross-Domain_Image_Classification_WACV_2024_paper.html": {
    "title": "Deep Subdomain Alignment for Cross-Domain Image Classification",
    "volume": "main",
    "abstract": "Unsupervised domain adaptation (UDA), which aims to transfer knowledge learned from a labeled source domain to an unlabeled target domain, is useful for various cross-domain image classification scenarios. A commonly used approach for UDA is to minimize the distribution differences between two domains, and subdomain alignment is found to be an effective method. However, most of the existing subdomain alignment methods are based on adversarial learning and focus on subdomain alignment procedures without considering the discriminability among individual subdomains, resulting in slow convergence and unsatisfactory adaptation results. To address these issues, we propose a novel deep subdomain alignment method for UDA in image classification, which consists of a Union Subdomain Contrastive Learning (USCL) module and a Multi-view Subdomain Alignment (MvSA) strategy. USCL can create discriminative and dispersed subdomains by bringing samples from the same subdomain closer while pushing away samples from different subdomains. MvSA makes use of labeled source domain data and easy target domain data to perform target-to-source and target-to-target alignment. Experimental results on three image classification datasets (Office-31, Office-Home, Visda-17) demonstrate that our proposed method is effective for UDA and achieves promising results in several cross-domain image classification tasks",
    "checked": false,
    "id": "7d79423db4d157e89291a3f9e05ece37837272c4",
    "semantic_title": "correlation subdomain alignment network based cross-domain hyperspectral image classification method",
    "citation_count": 0,
    "authors": [
      "Yewei Zhao",
      "Hu Han",
      "Shiguang Shan",
      "Xilin Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chien_Classifying_Cable_Tendency_With_Semantic_Segmentation_by_Utilizing_Real_and_WACV_2024_paper.html": {
    "title": "Classifying Cable Tendency With Semantic Segmentation by Utilizing Real and Simulated RGB Data",
    "volume": "main",
    "abstract": "Cable tendency is the potential shape or characteristic that a cable may possess while being manipulated, of which some are considered erroneous and should be identified as a part of anomaly detection during an automatic manipulation. This research explores the ability of deep-learning models in learning the cable tendencies that, contrary to typical classification tasks of multi-object scenarios, is to differentiate the multiple states displayable by the same object -- in this case, cables. By training multiple models with different combinations of self-collected real-world data and self-generated simulation data, a comparative study is carried out to compare the performance of each approach. In conclusion, the effectiveness of detecting three abnormal states and shapes of cables, and using simulation data is certificated in experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pei-Chun Chien",
      "Powei Liao",
      "Eiji Fukuzawa",
      "Jun Ohya"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Springstein_Visual_Narratives_Large-Scale_Hierarchical_Classification_of_Art-Historical_Images_WACV_2024_paper.html": {
    "title": "Visual Narratives: Large-Scale Hierarchical Classification of Art-Historical Images",
    "volume": "main",
    "abstract": "Iconography refers to the methodical study and interpretation of thematic content in the visual arts, distinguishing it, e.g., from purely formal or aesthetic considerations. In iconographic studies, Iconclass is a widely used taxonomy that encapsulates historical, biblical, and literary themes, among others. However, given the hierarchical nature and inherent complexity of such a taxonomy, it is highly desirable to use automated methods for (Iconclass-based) image classification. Previous studies either focused narrowly on certain subsets of narratives or failed to exploit Iconclass's hierarchical structure. In this paper, we propose a novel approach for Hierarchical Multi-label Classification (HMC) of iconographic concepts in images. We present three strategies, including Large Language Models (LLMs), for the generation of textual image descriptions using keywords extracted from Iconclass. These descriptions are utilized to pre-train a Vision-Language Model (VLM) based on a newly introduced data set of 477,569 images with more than 20,000 Iconclass concepts, far more than considered in previous studies. Furthermore, we present five approaches to multi-label classification, including a novel transformer decoder that leverages hierarchical information from the Iconclass taxonomy. Experimental results show the superiority of this approach over reasonable baselines",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthias Springstein",
      "Stefanie Schneider",
      "Javad Rahnama",
      "Julian Stalter",
      "Maximilian Kristen",
      "Eric Müller-Budack",
      "Ralph Ewerth"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Karim_Real-Time_Weakly_Supervised_Video_Anomaly_Detection_WACV_2024_paper.html": {
    "title": "Real-Time Weakly Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "Weakly supervised video anomaly detection is an important problem in many real-world applications where during training there are some anomalous videos, in addition to nominal videos, without labelled frames to indicate when the anomaly happens. State-of-the-art methods in this domain typically focus on offline anomaly detection without any concern for real-time detection. Most of these methods rely on ad hoc feature aggregation techniques and the use of metric learning losses, which limit the ability of the models to detect anomalies in real-time. In line with the premise of deep neural networks, there also has been a growing interest in developing end-to-end approaches that can automatically learn effective features directly from the raw data. We propose the first real-time and end-to-end trained algorithm for weakly supervised video anomaly detection. Our training procedure builds upon recent action recognition literature and uses a trainable video model to learn visual features. This is in contrast to existing approaches which largely depend on pre-trained feature extractors. The proposed method significantly improves the anomaly detection speed and AUC performance compared to the existing methods. Specifically, on the UCF-Crime dataset, our method achieves 86.94% AUC with a decision period of 6.4 seconds while the competing methods achieve at most 85.92% AUC with a decision period of 273 seconds",
    "checked": false,
    "id": "a80ffd49a32f575028888e3b91092ac1e5a857b4",
    "semantic_title": "batchnorm-based weakly supervised video anomaly detection",
    "citation_count": 0,
    "authors": [
      "Hamza Karim",
      "Keval Doshi",
      "Yasin Yilmaz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kulkarni_C2AIR_Consolidated_Compact_Aerial_Image_Haze_Removal_WACV_2024_paper.html": {
    "title": "C2AIR: Consolidated Compact Aerial Image Haze Removal",
    "volume": "main",
    "abstract": "Aerial image haze removal deals with improving the visibility and quality of images captured from aerial platforms, such as drones and satellites. Aerial images are commonly used in various applications such as environmental monitoring, and disaster response. These applications usually require cleaner data for accurate functioning. However, atmospheric conditions such as haze or fog can significantly degrade the quality of these images, reducing their contrast, color saturation, and sharpness, making it difficult to extract meaningful information from them. Existing methods rely on computationally heavy and haze density (light, moderate, dense) specific architectures for aerial image dehazing. In light of these limitations, we propose a novel lightweight and consolidated approach for aerial image dehazing. In this approach, we propose Density Aware Query Modulated Block for learning weather degradations in input features and guiding the restoration process. Further, we propose Cross Collaborative Feed-Forward Block for learning to restore varying sizes of the structures in the input images. Finally, we propose Gated Adaptive Feature Fusion block to achieve inter-scale and intra-feature attentive fusion, effective for aerial image restoration. Extensive analysis on benchmark aerial image dehazing datasets and real-world images, along with detailed ablation studies validate the effectiveness of the proposed approach. Further, we have analysed our method for other restoration task such as underwater image enhancement to experiment its wide applicability. The code is available at https: //github.com/AshutoshKulkarni4998/C2AIR",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashutosh Kulkarni",
      "Shruti S. Phutke",
      "Santosh Kumar Vipparthi",
      "Subrahmanyam Murala"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tran_Permutation-Aware_Activity_Segmentation_via_Unsupervised_Frame-To-Segment_Alignment_WACV_2024_paper.html": {
    "title": "Permutation-Aware Activity Segmentation via Unsupervised Frame-To-Segment Alignment",
    "volume": "main",
    "abstract": "This paper presents an unsupervised transformer-based framework for temporal activity segmentation which leverages not only frame-level cues but also segment-level cues. This is in contrast with previous methods which often rely on frame-level information only. Our approach begins with a frame-level prediction module which estimates framewise action classes via a transformer encoder. The frame-level prediction module is trained in an unsupervised manner via temporal optimal transport. To exploit segment-level information, we utilize a segment-level prediction module and a frame-to-segment alignment module. The former includes a transformer decoder for estimating video transcripts, while the latter matches frame-level features with segment-level features, yielding permutation-aware segmentation results. Moreover, inspired by temporal optimal transport, we introduce simple-yet-effective pseudo labels for unsupervised training of the above modules. Our experiments on four public datasets, i.e., 50 Salads, YouTube Instructions, Breakfast, and Desktop Assembly show that our approach achieves comparable or better performance than previous methods in unsupervised activity segmentation",
    "checked": false,
    "id": "9e941646b124aa5ff508ba97ed0549620d224df5",
    "semantic_title": "permutation-aware action segmentation via unsupervised frame-to-segment alignment",
    "citation_count": 2,
    "authors": [
      "Quoc-Huy Tran",
      "Ahmed Mehmood",
      "Muhammad Ahmed",
      "Muhammad Naufil",
      "Anas Zafar",
      "Andrey Konin",
      "Zeeshan Zia"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hesse_Prototype_Learning_for_Explainable_Brain_Age_Prediction_WACV_2024_paper.html": {
    "title": "Prototype Learning for Explainable Brain Age Prediction",
    "volume": "main",
    "abstract": "The lack of explainability of deep learning models limits the adoption of such models in clinical practice. Prototype-based models can provide inherent explainable predictions, but these have predominantly been designed for classification tasks, despite many important tasks in medical imaging being continuous regression problems. Therefore, in this work, we present ExPeRT: an explainable prototype-based model specifically designed for regression tasks. Our proposed model makes a sample prediction from the distances to a set of learned prototypes in latent space, using a weighted mean of prototype labels. The distances in latent space are regularized to be relative to label differences, and each of the prototypes can be visualized as a sample from the training set. The image-level distances are further constructed from patch-level distances, in which the patches of both images are structurally matched using optimal transport. This thus provides an example-based explanation with patch-level detail at inference time. We demonstrate our proposed model for brain age prediction on two imaging datasets: adult MR and fetal ultrasound. Our approach achieved state-of-the-art prediction performance while providing insight into the model's reasoning process",
    "checked": true,
    "id": "0756a9a3765c9982e4b02f4530efaea031c233a1",
    "semantic_title": "prototype learning for explainable brain age prediction",
    "citation_count": 0,
    "authors": [
      "Linde S. Hesse",
      "Nicola K. Dinsdale",
      "Ana I. L. Namburete"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wan_Exploiting_CLIP_for_Zero-Shot_HOI_Detection_Requires_Knowledge_Distillation_at_WACV_2024_paper.html": {
    "title": "Exploiting CLIP for Zero-Shot HOI Detection Requires Knowledge Distillation at Multiple Levels",
    "volume": "main",
    "abstract": "In this paper, we investigate the task of zero-shot human-object interaction (HOI) detection, a novel paradigm for identifying HOIs without the need for task-specific annotations. To address this challenging task, we employ CLIP, a large-scale pre-trained vision-language model (VLM), for knowledge distillation on multiple levels. To this end, we design a multi-branch neural network that leverages CLIP for learning HOI representations at various levels, including global images, local union regions encompassing human-object pairs, and individual instances of humans or objects. To train our model, CLIP is utilized to generate HOI scores for both global images and local union regions that serve as supervision signals. The extensive experiments demonstrate the effectiveness of our novel multi-level CLIP knowledge integration strategy. Notably, the model achieves strong performance, which is even comparable with some fully-supervised and weakly-supervised methods on the public HICO-DET benchmark",
    "checked": true,
    "id": "99905ba4f5c462b0026f3cc1b59d4f4d0cfd7155",
    "semantic_title": "exploiting clip for zero-shot hoi detection requires knowledge distillation at multiple levels",
    "citation_count": 0,
    "authors": [
      "Bo Wan",
      "Tinne Tuytelaars"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_SDNet_An_Extremely_Efficient_Portrait_Matting_Model_via_Self-Distillation_WACV_2024_paper.html": {
    "title": "SDNet: An Extremely Efficient Portrait Matting Model via Self-Distillation",
    "volume": "main",
    "abstract": "Most existing portrait matting models either require expensive auxiliary information or try to decompose the task into sub-tasks that are usually resource-hungry. These challenges limit its application on low-power computing devices. In addition, mobile networks tend to be less powerful than those cumbersome ones in feature representation mining. In this paper, we propose an extremely efficient portrait matting model via self-distillation (SDNet), that aims to provide a solution to performing accurate and effective portrait matting with limited computing resources. Our SDNet contains only 2M parameters, 2.2% of the parameters of MGM, and 1.5% of that of Matteformer. We introduce the training pipeline of self-distillation that can improve our lightweight baseline model without any parameter addition, network modification, or over-parameterized teacher models which need well-pretraining. Extensive experiments demonstrate the effectiveness of our self-distillation method and the lightweight SDNet network. Our SDNet outperforms the state-of-the-art (SOTA) lightweight approaches on both synthetic and real-world images",
    "checked": false,
    "id": "05abddfc2dcc0d975bb69766ebf125485cffb912",
    "semantic_title": "sdnet: an extremely efﬁcient portrait matting model via self-distillation",
    "citation_count": 0,
    "authors": [
      "Ziwen Li",
      "Bo Xu",
      "Jiake Xie",
      "Yong Tang",
      "Cheng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Han_Hybrid_Neural_Diffeomorphic_Flow_for_Shape_Representation_and_Generation_via_WACV_2024_paper.html": {
    "title": "Hybrid Neural Diffeomorphic Flow for Shape Representation and Generation via Triplane",
    "volume": "main",
    "abstract": "Deep Implicit Functions (DIFs) have gained popularity in 3D computer vision due to their compactness and continuous representation capabilities. However, addressing dense correspondences and semantic relationships across DIF-encoded shapes remains a critical challenge, limiting their applications in texture transfer and shape analysis. Moreover, recent endeavors in 3D shape generation using DIFs often neglect correspondence and topology preservation. This paper presents HNDF (Hybrid Neural Diffeomorphic Flow), a method that implicitly learns the underlying representation and decomposes intricate dense correspondences into explicitly axis-aligned triplane features. To avoid suboptimal representations trapped in local minima, we propose hybrid supervision that captures both local and global correspondences. Unlike conventional approaches that directly generate new 3D shapes, we further explore the idea of shape generation with deformed template shape via diffeomorphic flows, where the deformation is encoded by the generated triplane features. Leveraging a pre-existing 2D diffusion model, we produce high-quality and diverse 3D diffeomorphic flows through generated triplanes features, ensuring topological consistency with the template shape. Extensive experiments on medical image organ segmentation datasets evaluate the effectiveness of HNDF in 3D shape representation and generation",
    "checked": true,
    "id": "416f1b4c76a75bf893e927c51adbeb4c94856e24",
    "semantic_title": "hybrid neural diffeomorphic flow for shape representation and generation via triplane",
    "citation_count": 0,
    "authors": [
      "Kun Han",
      "Shanlin Sun",
      "Thanh-Tung Le",
      "Xiangyi Yan",
      "Haoyu Ma",
      "Chenyu You",
      "Xiaohui Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Benaim_Volumetric_Disentanglement_for_3D_Scene_Manipulation_WACV_2024_paper.html": {
    "title": "Volumetric Disentanglement for 3D Scene Manipulation",
    "volume": "main",
    "abstract": "Recently, advances in differential volumetric rendering enabled significant breakthroughs in the photo-realistic and fine-detailed reconstruction of complex 3D scenes, which is key for many virtual reality applications. However, in the context of augmented reality, one may also wish to effect semantic manipulations or augmentations of objects within a scene. To this end, we propose a volumetric framework for (i) disentangling or separating, the volumetric representation of a given foreground object from the background, and (ii) semantically manipulating the foreground object, as well as the background. Our method enables the separate control of pixel color and depth as well as 3D similarity transformations of both the foreground and background objects. We subsequently demonstrate our framework's applicability on several downstream manipulation tasks, going beyond the placement and movement of foreground objects. These tasks include object camouflage, non-negative 3D object inpainting, 3D object translation, 3D object inpainting, and 3D text-based object manipulation. Our framework takes as input a set of 2D masks specifying the desired foreground object for training views, together with the associated 2D views and poses, and produces a foreground-background disentanglement that respects the surrounding illumination, reflections, and partial occlusions, which can be applied to both training and novel views",
    "checked": true,
    "id": "e855b7797de4a9d78121f03adb66d89d239217d2",
    "semantic_title": "volumetric disentanglement for 3d scene manipulation",
    "citation_count": 11,
    "authors": [
      "Sagie Benaim",
      "Frederik Warburg",
      "Peter Ebert Christensen",
      "Serge Belongie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zheng_CAILA_Concept-Aware_Intra-Layer_Adapters_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.html": {
    "title": "CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "In this paper, we study the problem of Compositional Zero-Shot Learning (CZSL), which is to recognize novel attribute-object combinations with pre-existing concepts. Recent researchers focus on applying large-scale Vision-Language Pre-trained (VLP) models like CLIP with strong generalization ability. However, these methods treat the pre-trained model as a black box and focus on pre- and post-CLIP operations, which do not inherently mine the semantic concept between the layers inside CLIP. We propose to dive deep into the architecture and insert adapters, a parameter-efficient technique proven to be effective among large language models, into each CLIP encoder layer. We further equip adapters with concept awareness so that concept-specific features of \"object\", \"attribute\", and \"composition\" can be extracted. We assess our method on four popular CZSL datasets, MIT-States, C-GQA, UT-Zappos, and VAW-CZSL, which shows state-of-the-art performance compared to existing methods on all of them",
    "checked": true,
    "id": "3e23df3d723e35a1eead16c8131cae3feec92343",
    "semantic_title": "caila: concept-aware intra-layer adapters for compositional zero-shot learning",
    "citation_count": 0,
    "authors": [
      "Zhaoheng Zheng",
      "Haidong Zhu",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Capitani_ClusterFix_A_Cluster-Based_Debiasing_Approach_Without_Protected-Group_Supervision_WACV_2024_paper.html": {
    "title": "ClusterFix: A Cluster-Based Debiasing Approach Without Protected-Group Supervision",
    "volume": "main",
    "abstract": "The failures of Deep Networks can sometimes be ascribed to biases in the data or algorithmic choices. Existing debiasing approaches exploit prior knowledge to avoid unintended solutions; we acknowledge that, in real-world settings, it could be unfeasible to gather enough prior information to characterize the bias, or it could even raise ethical considerations. We hence propose a novel debiasing approach, termed ClusterFix, which does not require any external hint about the nature of biases. Such an approach alters the standard empirical risk minimization and introduces a per-example weight, encoding how critical and far from the majority an example is. Notably, the weights consider how difficult it is for the model to infer the correct pseudo-label, which is obtained in a self-supervised manner by dividing examples into multiple clusters. Extensive experiments show that the misclassification error incurred in identifying the correct cluster allows for identifying examples prone to bias-related issues. As a result, our approach outperforms existing methods on standard benchmarks for bias removal and fairness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giacomo Capitani",
      "Federico Bolelli",
      "Angelo Porrello",
      "Simone Calderara",
      "Elisa Ficarra"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cohen_Simple_Post-Training_Robustness_Using_Test_Time_Augmentations_and_Random_Forest_WACV_2024_paper.html": {
    "title": "Simple Post-Training Robustness Using Test Time Augmentations and Random Forest",
    "volume": "main",
    "abstract": "Although Deep Neural Networks (DNNs) achieve excellent performance on many real-world tasks, they are highly vulnerable to adversarial attacks. A leading defense against such attacks is adversarial training, a technique in which a DNN is trained to be robust to adversarial attacks by introducing adversarial noise to its input. This procedure is effective but must be done during the training phase. In this work, we propose Augmented Random Forest (ARF), a simple and easy-to-use strategy for robustifying an existing pretrained DNN without modifying its weights. For every image, we generate randomized test time augmentations by applying diverse color, blur, noise, and geometric transforms. Then we use the DNN's logits output to train a simple random forest to predict the real class label. Our method achieves state-of-the-art adversarial robustness on a diversity of white and black box attacks with minimal compromise on the natural images' classification. We test ARF also against numerous adaptive white-box attacks and it shows excellent results when combined with adversarial training",
    "checked": false,
    "id": "de8ac5752362608da615bc695792a9839422d5c9",
    "semantic_title": "a deep learning model using geostationary satellite data for forest fire detection with reduced detection latency",
    "citation_count": 19,
    "authors": [
      "Gilad Cohen",
      "Raja Giryes"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mazumder_Learning_Low-Rank_Latent_Spaces_With_Simple_Deterministic_Autoencoder_Theoretical_and_WACV_2024_paper.html": {
    "title": "Learning Low-Rank Latent Spaces With Simple Deterministic Autoencoder: Theoretical and Empirical Insights",
    "volume": "main",
    "abstract": "The autoencoder is an unsupervised learning paradigm that aims to create a compact latent representation of data by minimizing the reconstruction loss. However, it tends to overlook the fact that most data (images) are embedded in a lower-dimensional latent space, which is crucial for effective data representation. To address this limitation, we propose a novel approach called Low-Rank Autoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to adaptively learn a low-dimensional latent space while preserving the basic objective of an autoencoder. This helps embed the data in a lower-dimensional latent space while preserving important information. It is a simple autoencoder extension that learns low-rank latent space. Theoretically, we establish a tighter error bound for our model. Empirically, our model's superiority shines through various tasks such as image generation and downstream classification. Both theoretical and practical outcomes highlight the importance of acquiring low-dimensional embeddings",
    "checked": true,
    "id": "2da2a1c650eb93a7d3989dfef0fddca65e8f15c1",
    "semantic_title": "learning low-rank latent spaces with simple deterministic autoencoder: theoretical and empirical insights",
    "citation_count": 0,
    "authors": [
      "Alokendu Mazumder",
      "Tirthajit Baruah",
      "Bhartendu Kumar",
      "Rishab Sharma",
      "Vishwajeet Pattanaik",
      "Punit Rathore"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Khan_A_Hybrid_Graph_Network_for_Complex_Activity_Detection_in_Video_WACV_2024_paper.html": {
    "title": "A Hybrid Graph Network for Complex Activity Detection in Video",
    "volume": "main",
    "abstract": "Interpretation and understanding of video presents a challenging computer vision task in numerous fields - e.g. autonomous driving and sports analytics. Existing approaches to interpreting the actions taking place within a video clip are based upon Temporal Action Localisation (TAL), which typically identifies short-term actions. The emerging field of Complex Activity Detection (CompAD) extends this analysis to long-term activities, with a deeper understanding obtained by modelling the internal structure of a complex activity taking place within the video. We address the CompAD problem using a hybrid graph neural network which combines attention applied to a graph encoding the local (short-term) dynamic scene with a temporal graph modelling the overall long-duration activity. Our approach is as follows: i) Firstly, we propose a novel feature extraction technique which, for each video snippet, generates spatiotemporal 'tubes' for the active elements ('agents') in the (local) scene by detecting individual objects, tracking them and then extracting 3D features from all the agent tubes as well as the overall scene. ii) Next, we construct a local scene graph where each node (representing either an agent tube or the scene) is connected to all other nodes. Attention is then applied to this graph to obtain an overall representation of the local dynamic scene. iii) Finally, all local scene graph representations are interconnected via a temporal graph, to estimate the complex activity class together with its start and end time. The proposed framework outperforms all previous state-of-the-art methods on all three datasets including ActivityNet-1.3, Thumos-14, and ROAD",
    "checked": true,
    "id": "a28b64e8c3bba33a9caaff21a56480e2a3f9a1c7",
    "semantic_title": "a hybrid graph network for complex activity detection in video",
    "citation_count": 0,
    "authors": [
      "Salman Khan",
      "Izzeddin Teeti",
      "Andrew Bradley",
      "Mohamed Elhoseiny",
      "Fabio Cuzzolin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Movie_Genre_Classification_by_Language_Augmentation_and_Shot_Sampling_WACV_2024_paper.html": {
    "title": "Movie Genre Classification by Language Augmentation and Shot Sampling",
    "volume": "main",
    "abstract": "Video-based movie genre classification has garnered considerable attention due to its various applications in recommendation systems. Prior work has typically addressed this task by adapting models from traditional video classification tasks, such as action recognition or event detection. However, these models often neglect language elements (e.g., narrations or conversations) present in videos, which can implicitly convey high-level semantics of movie genres, like storylines or background context. Additionally, existing approaches are primarily designed to encode the entire content of the input video, leading to inefficiencies in predicting movie genres. Movie genre prediction may require only a few shots to accurately determine the genres, rendering a comprehensive understanding of the entire video unnecessary. To address these challenges, we propose a Movie genre Classification method based on Language augmentatIon and shot samPling (Movie-CLIP). Movie-CLIP mainly consists of two parts: a language augmentation module to recognize language elements from the input audio, and a shot sampling module to select representative shots from the entire video. We evaluate our method on MovieNet and Condensed Movies datasets, achieving approximate 6-9% improvement in mean Average Precision (mAP) over the baselines. We also generalize Movie-CLIP to the scene boundary detection task, achieving 1.1% improvement in Average Precision (AP) over the state-of-the-art. We release our implementation at github.com/Zhongping-Zhang/Movie-CLIP",
    "checked": true,
    "id": "0ff06122ea3359871652a1486fddf785b061b765",
    "semantic_title": "movie genre classification by language augmentation and shot sampling",
    "citation_count": 0,
    "authors": [
      "Zhongping Zhang",
      "Yiwen Gu",
      "Bryan A. Plummer",
      "Xin Miao",
      "Jiayi Liu",
      "Huayan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/DAmicantonio_Automated_Camera_Calibration_via_Homography_Estimation_With_GNNs_WACV_2024_paper.html": {
    "title": "Automated Camera Calibration via Homography Estimation With GNNs",
    "volume": "main",
    "abstract": "Over the past few decades, a significant rise of camera-based applications for traffic monitoring has occurred. Governments and local administrations are increasingly relying on the data collected from these cameras to enhance road safety and optimize traffic conditions. However, for effective data utilization, it is imperative to ensure accurate and automated calibration of the involved cameras. This paper proposes a novel approach to address this challenge by leveraging the topological structure of intersections. We propose a framework involving the generation of a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighbourhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters. As a result, the proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark",
    "checked": true,
    "id": "24b0a75621f792f46eedcbe0e4a2ebf091c85366",
    "semantic_title": "automated camera calibration via homography estimation with gnns",
    "citation_count": 0,
    "authors": [
      "Giacomo D'Amicantonio",
      "Egor Bondarev",
      "Peter H.N. de With"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Randomized_Adversarial_Style_Perturbations_for_Domain_Generalization_WACV_2024_paper.html": {
    "title": "Randomized Adversarial Style Perturbations for Domain Generalization",
    "volume": "main",
    "abstract": "We propose a novel domain generalization technique, referred to as Randomized Adversarial Style Perturbation (RASP), which is motivated by the observation that the characteristics of each domain are captured by the feature statistics corresponding to its style. The proposed algorithm perturbs the style of a feature in an adversarial direction towards a randomly selected class, and prevents the model from being misled by the unexpected styles observed in unseen target domains. While RASP is effective for handling domain shifts, its naive integration into the training procedure is prone to degrade the capability of learning knowledge from source domains due to the feature distortions caused by style perturbation. This challenge is alleviated by Normalized Feature Mixup (NFM) during training, which facilitates learning the original features while achieving robustness to perturbed representations. We evaluate the proposed algorithm via extensive experiments on various benchmarks and show that our approach improves domain generalization performance, especially in large-scale benchmarks",
    "checked": true,
    "id": "3892cba7b2d00a235e4ee168d90b9d55894c1d0f",
    "semantic_title": "randomized adversarial style perturbations for domain generalization",
    "citation_count": 1,
    "authors": [
      "Taehoon Kim",
      "Bohyung Han"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Theisen_C-CLIP_Contrastive_Image-Text_Encoders_To_Close_the_Descriptive-Commentative_Gap_WACV_2024_paper.html": {
    "title": "C-CLIP: Contrastive Image-Text Encoders To Close the Descriptive-Commentative Gap",
    "volume": "main",
    "abstract": "The interplay between the image and comment on a social media post is one of high importance for understanding its overall message. Recent strides in multimodal embedding models, namely CLIP, have provided an avenue forward in relating image and text. However the current training regime for CLIP models is insufficient for matching content found on social media, regardless of site or language. Current CLIP training data is based on what we call \"descriptive\" text: text in which an image is merely described. This is something rarely seen on social media, where the vast majority of text content is \"commentative\" in nature. The captions provide commentary and broader context related to the image, rather than describing what is in it. Current CLIP models perform poorly on retrieval tasks where image-caption pairs display a commentative relationship. Closing this gap would be beneficial for several important application areas related to social media. For instance, it would allow groups focused on Open-Source Intelligence Operations (OSINT) to further aid efforts during disaster events, such as the ongoing Russian invasion of Ukraine, by easily exposing data to non-technical users for discovery and analysis. In order to close this gap we demonstrate that training contrastive image-text encoders on explicitly commentative pairs results in large improvements in retrieval results, with the results extending across a variety of non-English languages",
    "checked": true,
    "id": "3deea3cfd5ca9ff1decd74dd62523a1e5121088f",
    "semantic_title": "c-clip: contrastive image-text encoders to close the descriptive-commentative gap",
    "citation_count": 0,
    "authors": [
      "William Theisen",
      "Walter J. Scheirer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hardy_LInKs_Lifting_Independent_Keypoints_-_Partial_Pose_Lifting_for_Occlusion_WACV_2024_paper.html": {
    "title": "LInKs \"Lifting Independent Keypoints\" - Partial Pose Lifting for Occlusion Handling With Improved Accuracy in 2D-3D Human Pose Estimation",
    "volume": "main",
    "abstract": "We present LInKs, a novel unsupervised learning method to recover 3D human poses from 2D kinematic skeletons obtained from a single image, even when occlusions are present. Our approach follows a unique two-step process, which involves first lifting the occluded 2D pose to the 3D domain, followed by filling in the occluded parts using the partially reconstructed 3D coordinates. This lift-then-fill approach leads to significantly more accurate results compared to models that complete the pose in 2D space alone. Additionally, we improve the stability and likelihood estimation of normalising flows through a custom sampling function replacing PCA dimensionality reduction used in prior work. Furthermore, we are the first to investigate if different parts of the 2D kinematic skeleton can be lifted independently which we find by itself reduces the error of current lifting approaches. We attribute this to the reduction of long-range keypoint correlations. In our detailed evaluation, we quantify the error under various realistic occlusion scenarios, showcasing the versatility and applicability of our model. Our results consistently demonstrate the superiority of handling all types of occlusions in 3D space when compared to others that complete the pose in 2D space. Our approach also exhibits consistent accuracy in scenarios without occlusion, as evidenced by a 7.9% reduction in reconstruction error compared to prior works on the Human3.6M dataset. Furthermore, our method excels in accurately retrieving complete 3D poses even in the presence of occlusions, making it highly applicable in situations where complete 2D pose information is unavailable",
    "checked": true,
    "id": "dbbfa4d4f92d297daf823e07f7f59d212a9402d8",
    "semantic_title": "links \"lifting independent keypoints\" - partial pose lifting for occlusion handling with improved accuracy in 2d-3d human pose estimation",
    "citation_count": 0,
    "authors": [
      "Peter Hardy",
      "Hansung Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Popordanoska_Beyond_Classification_Definition_and_Density-Based_Estimation_of_Calibration_in_Object_WACV_2024_paper.html": {
    "title": "Beyond Classification: Definition and Density-Based Estimation of Calibration in Object Detection",
    "volume": "main",
    "abstract": "Despite their impressive predictive performance in various computer vision tasks, deep neural networks (DNNs) tend to make overly confident predictions, which hinders their widespread use in safety-critical applications. While there have been recent attempts to calibrate DNNs, most of these efforts have primarily been focused on classification tasks, thus neglecting DNN-based object detectors. Although several recent works addressed calibration for object detection and proposed differentiable penalties, none of them are consistent estimators of established concepts in calibration. In this work, we tackle the challenge of defining and estimating calibration error specifically for this task. In particular, we adapt the definition of classification calibration error to handle the nuances associated with object detection, and predictions in structured output spaces more generally. Furthermore, we propose a consistent and differentiable estimator of the detection calibration error, utilizing kernel density estimation. Our experiments demonstrate the effectiveness of our estimator against competing train-time and post-hoc calibration methods, while maintaining similar detection performance",
    "checked": true,
    "id": "ad697aefab3d5ebc932c8143ce501188f12e4923",
    "semantic_title": "beyond classification: definition and density-based estimation of calibration in object detection",
    "citation_count": 0,
    "authors": [
      "Teodora Popordanoska",
      "Aleksei Tiulpin",
      "Matthew B. Blaschko"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tay_PrivObfNet_A_Weakly_Supervised_Semantic_Segmentation_Model_for_Data_Protection_WACV_2024_paper.html": {
    "title": "PrivObfNet: A Weakly Supervised Semantic Segmentation Model for Data Protection",
    "volume": "main",
    "abstract": "The use of social media has made it easy to communicate and share information over the internet. However, it also brings issues such as data privacy leakage, which can be exploited by recipients with malicious intentions to harm the sender. In this paper, we propose a deep neural network that analyzes the user's image for privacy sensitive content and automatically locates sensitive regions for obfuscation. Our approach relies solely on image level annotations and learns to (a) predict an overall privacy score, (b) detect sensitive attributes and (c) demarcate the sensitive regions for obfuscation, in a given input image. We validated the performance of our proposed method on three large datasets, VISPR, PASCAL VOC 2012 and MS COCO 2014, in terms of privacy score, attribute prediction and obfuscation performance. On the VISPR dataset, we achieved a Pearson correlation of 0.88 and a Spearman correlation of 0.86, outperforming previous methods. On PASCAL VOC 2012 and MS COCO 2014, our model achieved a mean IOU of 71.5% and 43.9% respectively, and is among the state-of-the-art techniques using weakly supervised semantic segmentation learning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "ChiatPin Tay",
      "Vigneshwaran Subbaraju",
      "Thivya Kandappu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Vuong_Toward_Planet-Wide_Traffic_Camera_Calibration_WACV_2024_paper.html": {
    "title": "Toward Planet-Wide Traffic Camera Calibration",
    "volume": "main",
    "abstract": "Despite the widespread deployment of outdoor cameras, their potential for automated analysis remains largely untapped due, in part, to calibration challenges. The absence of precise camera calibration data, including intrinsic and extrinsic parameters, hinders accurate real-world distance measurements from captured videos. To address this, we present a scalable framework that utilizes street-level imagery to reconstruct a metric 3D model, facilitating precise calibration of in-the-wild traffic cameras. Notably, our framework achieves 3D scene reconstruction and accurate localization of over 100 global traffic cameras and is scalable to any camera with sufficient street-level imagery. For evaluation, we introduce a dataset of 20 fully calibrated traffic cameras, demonstrating our method's significant enhancements over existing automatic calibration techniques. Furthermore, we highlight our approach's utility in traffic analysis by extracting insights via 3D vehicle reconstruction and speed measurement, thereby opening up the potential of using outdoor cameras for automated analysis",
    "checked": true,
    "id": "53e9acc6d551fed3ff6f423ec88da0da1a9d39db",
    "semantic_title": "toward planet-wide traffic camera calibration",
    "citation_count": 0,
    "authors": [
      "Khiem Vuong",
      "Robert Tamburo",
      "Srinivasa G. Narasimhan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_3D_Human_Pose_Estimation_With_Two-Step_Mixed-Training_Strategy_WACV_2024_paper.html": {
    "title": "3D Human Pose Estimation With Two-Step Mixed-Training Strategy",
    "volume": "main",
    "abstract": "In monocular 3D human pose estimation, target motions are generally stable and continuous, which indicates that joint velocity can provide valuable information for better estimation. Therefore, it is critical to learn the joint motion trajectory and spatio-temporal information from velocity. Previous works have shown that Transformers are effective in capturing the relationship between tokens. However, in practice, only 2D position is available and 3D velocity has not been explicitly used as a model input. To address this challenge, we propose TMT (Two-step Mixed-Training strategy), a transformer-based approach that effectively incorporates 3D velocity into the input vector during training, allowing for better learning of relevant features in the shallow layers. Extensive experiments demonstrate that TMT significantly improves the performance of state-of-the-art models, such as MixSTE, MHFormer, and PoseFomer, on two datasets: Human3.6M and MPI-INF-3DHP. TMT out performs the state-of-the-art approach by up to 13.8% on the Human3.6M dataset",
    "checked": false,
    "id": "80d61d2a099c14deb0268b643374753dc1a13177",
    "semantic_title": "upcoming oberseminars",
    "citation_count": 0,
    "authors": [
      "Yingfeng Wang",
      "Zhengwei Wang",
      "Muyu Li",
      "Hong Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chandran_Learning-Based_Spotlight_Position_Optimization_for_Non-Line-of-Sight_Human_Localization_and_Posture_WACV_2024_paper.html": {
    "title": "Learning-Based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification",
    "volume": "main",
    "abstract": "Non-line-of-sight imaging (NLOS) is the process of estimating information about a scene that is hidden from the direct line of sight of the camera. NLOS imaging typically requires time-resolved detectors and a laser source for illumination, which are both expensive and computationally intensive to handle. In this paper, we propose an NLOS-based localization and posture classification technique that works on a system of an off-the-shelf projector and camera. We leverage a message-passing neural network to learn a scene geometry and predict the best position to be spotlighted by the projector that can maximize the NLOS signal. The training of the neural network is performed in an end-to-end manner. Therefore, the ground truth spotlighted position is unnecessary during the training, and the network parameters are optimized to maximize the NLOS performance. Unlike prior deep-learning-based NLOS techniques that assume planar relay walls, our system allows us to handle line-of-sight scenes where scene geometries are more arbitrary. Our method demonstrates state-of-the-art performance in object localization and position classification using both synthetic and real scenes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sreenithy Chandran",
      "Tatsuya Yatagawa",
      "Hiroyuki Kubo",
      "Suren Jayasuriya"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Niemeijer_Generalization_by_Adaptation_Diffusion-Based_Domain_Extension_for_Domain-Generalized_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation",
    "volume": "main",
    "abstract": "When models, e.g., for semantic segmentation, are applied to images that are vastly different from training data, the performance will drop significantly. Domain adaptation methods try to overcome this issue, but need samples from the target domain. However, this might not always be feasible for various reasons and therefore domain generalization methods are useful as they do not require any target data. We present a new diffusion-based domain extension (DIDEX) method and employ a diffusion model to generate a pseudo-target domain with diverse text prompts. In contrast to existing methods, this allows to control the style and content of the generated images and to introduce a high diversity. In a second step, we train a generalizing model by adapting towards this pseudo-target domain. We outperform previous approaches by a large margin across various datasets and architectures without using any real data. For the generalization from GTA5, we improve state-of-the-art mIoU performance by 3.8% absolute on average and for SYNTHIA by 11.8% absolute, marking a big step for the generalization performance on these benchmarks. Code is available at https://github.com/JNiemeijer/DIDEX",
    "checked": true,
    "id": "aa242811d5fb3446f00f861eb5dfca9bdd05def3",
    "semantic_title": "generalization by adaptation: diffusion-based domain extension for domain-generalized semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Joshua Niemeijer",
      "Manuel Schwonberg",
      "Jan-Aike Termöhlen",
      "Nico M. Schmidt",
      "Tim Fingscheidt"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Baghbaderani_Temporally-Consistent_Video_Semantic_Segmentation_With_Bidirectional_Occlusion-Guided_Feature_Propagation_WACV_2024_paper.html": {
    "title": "Temporally-Consistent Video Semantic Segmentation With Bidirectional Occlusion-Guided Feature Propagation",
    "volume": "main",
    "abstract": "Despite recent progress in static image segmentation, video segmentation is still challenging due to the need for an accurate, fast, and temporally consistent model. Conducting per-frame static image segmentation is not acceptable since it is computationally prohibitive and prone to temporal inconsistency. In this paper, we present bidirectional occlusion-guided feature propagation (BOFP) method with the goal of improving temporal consistency of segmentation results without sacrificing segmentation accuracy, while at the same time keeping the operations at a low computation cost. It leverages temporal coherence in the video by feature propagation from keyframes to other frames along the motion paths in both forward and backward directions. We propose an occlusion-based attention network to estimate the distorted areas based on bidirectional optical flows, and utilize them as cues for correcting and fusing the propagated features. Extensive experiments on benchmark datasets demonstrate that the proposed BOFP method achieves superior performance in terms of temporal consistency while maintaining comparable level of segmentation accuracy at a low computation cost, striking a great balance among the three metrics essential to evaluate video segmentation solutions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Razieh Kaviani Baghbaderani",
      "Yuanxin Li",
      "Shuangquan Wang",
      "Hairong Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_MICS_Midpoint_Interpolation_To_Learn_Compact_and_Separated_Representations_for_WACV_2024_paper.html": {
    "title": "MICS: Midpoint Interpolation To Learn Compact and Separated Representations for Few-Shot Class-Incremental Learning",
    "volume": "main",
    "abstract": "Few-shot class-incremental learning (FSCIL) aims to learn a classification model for continually accepting novel classes with a few samples. The key of FSCIL is the joint success of the following two training stages: Base training stage to classify base classes and Incremental training stage with sequential learning of novel classes. However, recent efforts show a tendency to focus on one of the stages, or separately design strategies for each stage, so that less effort has been paid to devise a consistent strategy across the consecutive stages. In this paper, we first emphasize the particular aspects of the successful FSCIL algorithm that are worthwhile to consistently pursue during both stages, i.e., intra-class compactness and inter-class separability of the representation, which allows a model to reserve feature space in between current classes for preparing the acceptance of novel classes in the future. To achieve these aspects, we propose a mixup-based FSCIL method called MICS, which theoretically guarantees to enlarge the thickness of the margin space between different classes, leading to outstanding performance on the existing benchmarks. Code is available at https://github.com/solangii/MICS",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Solang Kim",
      "Yuho Jeong",
      "Joon Sung Park",
      "Sung Whan Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Abou-Chakra_ParticleNeRF_A_Particle-Based_Encoding_for_Online_Neural_Radiance_Fields_WACV_2024_paper.html": {
    "title": "ParticleNeRF: A Particle-Based Encoding for Online Neural Radiance Fields",
    "volume": "main",
    "abstract": "While existing Neural Radiance Fields (NeRFs) for dynamic scenes are offline methods with an emphasis on visual fidelity, our paper addresses the online use case that prioritises real-time adaptability. We present ParticleNeRF, a new approach that dynamically adapts to changes in the scene geometry by learning an up-to-date representation online, every 200ms. ParticleNeRF achieves this using a novel particle-based parametric encoding. We couple features to particles in space and backpropagate the photometric reconstruction loss into the particles' position gradients, which are then interpreted as velocity vectors. Governed by a lightweight physics system to handle collisions, this lets the features move freely with the changing scene geometry. We demonstrate ParticleNeRF on various dynamic scenes containing translating, rotating, articulated, and deformable objects. ParticleNeRF is the first online dynamic NeRF and achieves fast adaptability with better visual fidelity than brute-force online InstantNGP and other baseline approaches on dynamic scenes with online constraints",
    "checked": false,
    "id": "89835c5adbca97df6ef4216f55136431174de0ce",
    "semantic_title": "particlenerf: a particle-based encoding for online neural radiance fields in dynamic scenes",
    "citation_count": 10,
    "authors": [
      "Jad Abou-Chakra",
      "Feras Dayoub",
      "Niko Sünderhauf"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Residual_Graph_Convolutional_Network_for_Birds-Eye-View_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Residual Graph Convolutional Network for Bird's-Eye-View Semantic Segmentation",
    "volume": "main",
    "abstract": "Retrieving spatial information and understanding the semantic information of the surroundings are important for Bird's-Eye-View (BEV) semantic segmentation. In the application of autonomous driving, autonomous vehicles need to be aware of their surroundings to drive safely. However, current BEV semantic segmentation techniques, deep Convolutional Neural Networks (CNNs) and transformers, have difficulties in efficiently obtaining the global semantic relationships of the surroundings. In this paper, we propose to incorporate a novel Residual Graph Convolutional (RGC) module in deep CNNs to acquire both the global information and the region-level semantic relationship in the multi-view image domain. Specifically, the RGC module employs a non-overlapping graph space projection to efficiently project the complete BEV information into graph space. It then builds interconnected spatial and channel graphs to extract spatial information between each node and channel information within each node (i.e., extract contextual relationships of the global features). Furthermore, it uses a downsample residual process to enhance the coordinate feature reuse to maintain the global information. The segmentation data augmentation and alignment module helps to simultaneously augment and align BEV features and ground truth to geometrically preserve their alignment to achieve better segmentation results. Our experimental results on the nuScenes benchmark dataset demonstrate that the RGC network outperforms four state-of-the-art networks and its four variants in terms of IoU and mIoU. The proposed RGC network achieves a higher mIoU of 3.1% than the best state-of-the-art network, BEVFusion. Code and models will be released",
    "checked": true,
    "id": "ea92cb1b3452575975430149a867efad6138e3a0",
    "semantic_title": "residual graph convolutional network for bird's-eye-view semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Qiuxiao Chen",
      "Xiaojun Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yap_Group-Wise_Contrastive_Bottleneck_for_Weakly-Supervised_Visual_Representation_Learning_WACV_2024_paper.html": {
    "title": "Group-Wise Contrastive Bottleneck for Weakly-Supervised Visual Representation Learning",
    "volume": "main",
    "abstract": "Coarse or weak labels can serve as a cost-effective solution to the problem of visual representation learning. When fine-grained labels are unavailable, weak labels can provide some form of supervisory signals to guide the representation learning process. Some examples of weak labels include image captions, visual attributes and coarse-grained object categories. In this work, we consider the semantic grouping relationship that exists within certain types of weak labels and propose a group-wise contrastive bottleneck module to leverage this relationship. The semantic group may contain labels that are related to a general concept, such as the colour or shape of objects. Using the group-wise bottleneck module, we disentangle the global image features into multiple group features and apply contrastive learning in a group-wise manner to maximize the similarity of positive pairs within each semantic group. The positive pairs are defined based on the similarity of the labels captured by each group. To learn a more robust representation, we introduce a reconstruction objective where an image feature is reconstructed back from the disentangled features, and this reconstruction is encouraged to be consistent with the feature obtained from a different augmented view of the same image. We empirically verify the efficacy of the proposed method on several datasets in the context of visual attribute learning, fair representation learning and hierarchical label learning. The experimental results indicate that our proposed method outperforms prior weakly-supervised methods and is flexible in adapting to different representation learning settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boon Peng Yap",
      "Beng Koon Ng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kerim_Leveraging_Synthetic_Data_To_Learn_Video_Stabilization_Under_Adverse_Conditions_WACV_2024_paper.html": {
    "title": "Leveraging Synthetic Data To Learn Video Stabilization Under Adverse Conditions",
    "volume": "main",
    "abstract": "Stabilization plays a central role in improving the quality of videos. However, current methods perform poorly under adverse conditions. In this paper, we propose a synthetic-aware adverse weather video stabilization algorithm that dispenses real data for training, relying solely on synthetic data. Our approach leverages specially generated synthetic data to avoid the feature extraction issues faced by current methods. To achieve this, we present a novel data generator to produce the required training data with an automatic ground-truth extraction procedure. We also propose a new dataset, VSAC105Real, and compare our method to five recent video stabilization algorithms using two benchmarks. Our method generalizes well on real-world videos across all weather conditions and does not require large-scale synthetic training data. Implementations for our proposed video stabilization algorithm, generator, and datasets are available at https://github.com/A-Kerim/SyntheticData4VideoStabilization_WACV_2024",
    "checked": true,
    "id": "71c952915aeb5b63dd978c144933803700175e53",
    "semantic_title": "leveraging synthetic data to learn video stabilization under adverse conditions",
    "citation_count": 0,
    "authors": [
      "Abdulrahman Kerim",
      "Washington L. S. Ramos",
      "Leandro Soriano Marcolino",
      "Erickson R. Nascimento",
      "Richard Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Generation_of_Upright_Panoramic_Image_From_Non-Upright_Panoramic_Image_WACV_2024_paper.html": {
    "title": "Generation of Upright Panoramic Image From Non-Upright Panoramic Image",
    "volume": "main",
    "abstract": "The inclination of a spherical camera results in nonupright panoramic images. To carry out upright adjustment, traditional methods estimate camera inclination angles firstly, and then resample the image in terms of the estimated rotation to generate upright image. Since sampling an image is a time-consuming processing, a lookup table is usually used to achieve a high processing speed; however, the content of a lookup table depends on the rotational angles and needs extra memory to store also. In this paper we propose a new approach for panorama upright adjustment, which directly generates an upright panoramic image from an input nonupright one without rotation estimation and lookup tables as an intermediate processing. The proposed approach formulates panorama upright adjustment as a pixelwise image-to-image mapping problem, and the mapping is directly generated from an input nonupright panoramic image via an end-to-end neural network. As shown in the experiment of this paper, the proposed method results in a lightweight network, as less as 163MB, with high processing speed, as great as 9ms, for a 256x512 pixel panoramic image",
    "checked": false,
    "id": "c51d603302d965855ca390181dbb7495017b2ca7",
    "semantic_title": "an end-to-end network for upright adjustment of panoramic images",
    "citation_count": 0,
    "authors": [
      "Jingguo Liu",
      "Heyu Chen",
      "Shigang Li",
      "Jianfeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_RADIO_Reference-Agnostic_Dubbing_Video_Synthesis_WACV_2024_paper.html": {
    "title": "RADIO: Reference-Agnostic Dubbing Video Synthesis",
    "volume": "main",
    "abstract": "One of the most challenging problems in audio-driven talking head generation is achieving high-fidelity detail while ensuring precise synchronization. Given only a single reference image, extracting meaningful identity attributes becomes even more challenging, often causing the network to mirror the facial and lip structures too closely. To address these issues, we introduce RADIO, a framework engineered to yield high-quality dubbed videos regardless of the pose or expression in reference images. The key is to modulate the decoder layers using latent space composed of audio and reference features. Additionally, we incorporate ViT blocks into the decoder to emphasize high-fidelity details, especially in the lip region. Our experimental results demonstrate that RADIO displays high synchronization without the loss of fidelity. Especially in harsh scenarios where the reference frame deviates significantly from the ground truth, our method outperforms state-of-the-art methods, highlighting its robustness",
    "checked": true,
    "id": "5bb94c5faf2e0802caabaafce45c4cfd33c1e7c1",
    "semantic_title": "radio: reference-agnostic dubbing video synthesis",
    "citation_count": 0,
    "authors": [
      "Dongyeun Lee",
      "Chaewon Kim",
      "Sangjoon Yu",
      "Jaejun Yoo",
      "Gyeong-Moon Park"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Al-lahham_A_Coarse-To-Fine_Pseudo-Labeling_C2FPL_Framework_for_Unsupervised_Video_Anomaly_Detection_WACV_2024_paper.html": {
    "title": "A Coarse-To-Fine Pseudo-Labeling (C2FPL) Framework for Unsupervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "Detection of anomalous events in videos is an important problem in applications such as surveillance. Video anomaly detection (VAD) is well-studied in the one-class classification (OCC) and weakly supervised (WS) settings. However, fully unsupervised (US) video anomaly detection methods, which learn a complete system without any annotation or human supervision, have not been explored in depth. This is because the lack of any ground truth annotations significantly increases the magnitude of the VAD challenge. To address this challenge, we propose a simple-but-effective two-stage pseudo-label generation framework that produces segment-level (normal/anomaly) pseudo-labels, which can be further used to train a segment-level anomaly detector in a supervised manner. The proposed coarse-to-fine pseudo-label (C2FPL) generator employs carefully-designed hierarchical divisive clustering and statistical hypothesis testing to identify anomalous video segments from a set of completely unlabeled videos. The trained anomaly detector can be directly applied on segments of an unseen test video to obtain segment-level, and subsequently, frame-level anomaly predictions. Extensive studies on two large-scale public-domain datasets, UCF-Crime and XD-Violence, demonstrate that the proposed unsupervised approach achieves superior performance compared to all existing OCC and US methods, while yielding comparable performance to the state-of-the-art WS methods",
    "checked": true,
    "id": "a35b0178653ef2477f7b4cfa614f9daa0d66a79f",
    "semantic_title": "a coarse-to-fine pseudo-labeling (c2fpl) framework for unsupervised video anomaly detection",
    "citation_count": 0,
    "authors": [
      "Anas Al-lahham",
      "Nurbek Tastan",
      "Muhammad Zaigham Zaheer",
      "Karthik Nandakumar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Valois_Occlusion_Sensitivity_Analysis_With_Augmentation_Subspace_Perturbation_in_Deep_Feature_WACV_2024_paper.html": {
    "title": "Occlusion Sensitivity Analysis With Augmentation Subspace Perturbation in Deep Feature Space",
    "volume": "main",
    "abstract": "Deep Learning of neural networks has gained prominence in multiple life-critical applications like medical diagnoses and autonomous vehicle accident investigations. However, concerns about model transparency and biases persist. Explainable methods are viewed as the solution to address these challenges. In this study, we introduce the Occlusion Sensitivity Analysis with Deep Feature Augmentation Subspace (OSA-DAS), a novel perturbation-based interpretability approach for computer vision. While traditional perturbation methods make only use of occlusions to explain the model predictions, OSA-DAS extends standard occlusion sensitivity analysis by enabling the integration with diverse image augmentations. Distinctly, our method utilizes the output vector of a DNN to build low-dimensional subspaces within the deep feature vector space, offering a more precise explanation of the model prediction. The structural similarity between these subspaces encompasses the influence of diverse augmentations and occlusions. We test extensively on the ImageNet-1k, and our class- and model-agnostic approach outperforms commonly used interpreters, setting it apart in the realm of explainable AI",
    "checked": true,
    "id": "97d628444a00fbb9c7e1435cf0765392142326f2",
    "semantic_title": "occlusion sensitivity analysis with augmentation subspace perturbation in deep feature space",
    "citation_count": 0,
    "authors": [
      "Pedro H. V. Valois",
      "Koichiro Niinuma",
      "Kazuhiro Fukui"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chandrasekar_PhISH-Net_Physics_Inspired_System_for_High_Resolution_Underwater_Image_Enhancement_WACV_2024_paper.html": {
    "title": "PhISH-Net: Physics Inspired System for High Resolution Underwater Image Enhancement",
    "volume": "main",
    "abstract": "Underwater imaging presents numerous challenges due to refraction, light absorption, and scattering, resulting in color degradation, low contrast, and blurriness. Enhancing underwater images is crucial for high-level computer vision tasks, but existing methods either neglect the physics-based image formation process or require expensive computations. In this paper, we propose an effective framework that combines a physics-based Underwater Image Formation Model (UIFM) with a deep image enhancement approach based on the retinex model. Firstly, we remove backscatter by estimating attenuation coefficients using depth information. Then, we employ a retinex model-based deep image enhancement module to enhance the images. To ensure adherence to the UIFM, we introduce a novel Wideband Attenuation prior. The proposed PhISH-Net framework achieves real-time processing of high-resolution underwater images using a lightweight neural network and a bilateral-grid-based upsampler. Extensive experiments on two underwater image datasets demonstrate the superior performance of our method compared to state-of-the-art techniques. Additionally, qualitative evaluation on a cross-dataset scenario confirms its generalization capability. Our contributions lie in combining the physics-based UIFM with deep image enhancement methods, introducing the wideband attenuation prior, and achieving superior performance and efficiency",
    "checked": false,
    "id": "3232535521e60b91cd8de042756730d438051db4",
    "semantic_title": "supplementary for phish-net: physics inspired system for high resolution underwater image enhancement",
    "citation_count": 0,
    "authors": [
      "Aditya Chandrasekar",
      "Manogna Sreenivas",
      "Soma Biswas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pham_MixtureGrowth_Growing_Neural_Networks_by_Recombining_Learned_Parameters_WACV_2024_paper.html": {
    "title": "MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters",
    "volume": "main",
    "abstract": "Most deep neural networks are trained under fixed network architectures and require retraining when the architecture changes. If expanding the network's size is needed, it is necessary to retrain from scratch, which is expensive. To avoid this, one can grow from a small network by adding random weights over time to gradually achieve the target network size. However, this naive approach falls short in practice as it brings too much noise to the growing process. Prior work tackled this issue by leveraging the already learned weights and training data for generating new weights through conducting a computationally expensive analysis step. In this paper, we introduce MixtureGrowth, a new approach to growing networks that circumvents the initialization overhead in prior work. Before growing, each layer in our model is generated with a linear combination of parameter templates. Newly grown layer weights are generated by using a new linear combination of existing templates for a layer. On one hand, these templates are already trained for the task, providing a strong initialization. On the other, the new coefficients provide flexibility for the added layer weights to learn something new. We show that our approach boosts top-1 accuracy over the state-of-the-art by 2-2.5% on CIFAR-100 and ImageNet datasets, while achieving comparable performance with fewer FLOPs to a larger network trained from scratch. Code is available at https://github.com/chaudatascience/mixturegrowth",
    "checked": true,
    "id": "fd203cd888185b2a0d4962b70b52b298f2875bf1",
    "semantic_title": "mixturegrowth: growing neural networks by recombining learned parameters",
    "citation_count": 0,
    "authors": [
      "Chau Pham",
      "Piotr Teterwak",
      "Soren Nelson",
      "Bryan A. Plummer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pan_Zero-Shot_Building_Attribute_Extraction_From_Large-Scale_Vision_and_Language_Models_WACV_2024_paper.html": {
    "title": "Zero-Shot Building Attribute Extraction From Large-Scale Vision and Language Models",
    "volume": "main",
    "abstract": "Modern building recognition methods, exemplified by the BRAILS framework, utilize supervised learning to extract information from satellite and street-view images for image classification and semantic segmentation tasks. However, each task module requires human-annotated data, hindering the scalability and robustness to regional variations and annotation imbalances. In response, we propose a new zero-shot workflow for building attribute extraction that utilizes large-scale vision and language models to mitigate reliance on external annotations. The proposed workflow contains two key components: image-level captioning and segment-level captioning for the building images based on the vocabularies pertinent to structural and civil engineering. These two components generate descriptive captions by computing feature representations of the image and the vocabularies, and facilitating a semantic match between the visual and textual representations. Consequently, our framework offers a promising avenue to enhance AI-driven captioning for building attribute extraction in the structural and civil engineering domains, ultimately reducing reliance on human annotations while bolstering performance and adaptability",
    "checked": true,
    "id": "10c6f1a2a1ae24595e7472a2092e652c329862ab",
    "semantic_title": "zero-shot building attribute extraction from large-scale vision and language models",
    "citation_count": 0,
    "authors": [
      "Fei Pan",
      "Sangryul Jeon",
      "Brian Wang",
      "Frank Mckenna",
      "Stella X. Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Koohpayegani_SimA_Simple_Softmax-Free_Attention_for_Vision_Transformers_WACV_2024_paper.html": {
    "title": "SimA: Simple Softmax-Free Attention for Vision Transformers",
    "volume": "main",
    "abstract": "Recently, vision transformers have become very popular. However, deploying them in many applications is computationally expensive partly due to the Softmax layer in the attention block. We introduce a simple yet effective, Softmax-free attention block, SimA, which normalizes query and key matrices with simple l1-norm instead of using Softmax layer. Then, the attention block in SimA is a simple multiplication of three matrices, so SimA can dynamically change the ordering of the computation at the test time to achieve linear computation on the number of tokens or the number of channels. We empirically show that SimA applied to three SOTA variations of transformers, DeiT, XCiT, and CvT, results in on-par accuracy compared to the SOTA models, without any need for Softmax layer. Interestingly, changing SimA from multi-head to single-head has only a small effect on the accuracy, which further simplifies the attention block. Moreover, we show that SimA is much faster on small edge devices, e.g., Raspberry Pi, which we believe is due to higher complexity of Softmax layer on those devices. The code is available here: https://github.com/UCDvision/sima",
    "checked": true,
    "id": "1966c4df2cda0fb8daf7f36366d909a021b6d5c1",
    "semantic_title": "sima: simple softmax-free attention for vision transformers",
    "citation_count": 6,
    "authors": [
      "Soroush Abbasi Koohpayegani",
      "Hamed Pirsiavash"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sahu_POP-VQA_-_Privacy_Preserving_On-Device_Personalized_Visual_Question_Answering_WACV_2024_paper.html": {
    "title": "POP-VQA - Privacy Preserving, On-Device, Personalized Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pragya Paramita Sahu",
      "Abhishek Raut",
      "Jagdish Singh Samant",
      "Mahesh Gorijala",
      "Vignesh Lakshminarayanan",
      "Pinaki Bhaskar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tejero-de-Pablos_Complementary-Contradictory_Feature_Regularization_Against_Multimodal_Overfitting_WACV_2024_paper.html": {
    "title": "Complementary-Contradictory Feature Regularization Against Multimodal Overfitting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antonio Tejero-de-Pablos"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tanaka_Appearance-Based_Curriculum_for_Semi-Supervised_Learning_With_Multi-Angle_Unlabeled_Data_WACV_2024_paper.html": {
    "title": "Appearance-Based Curriculum for Semi-Supervised Learning With Multi-Angle Unlabeled Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuki Tanaka",
      "Shuhei M. Yoshida",
      "Takashi Shibata",
      "Makoto Terao",
      "Takayuki Okatani",
      "Masashi Sugiyama"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Incorporating_Physics_Principles_for_Precise_Human_Motion_Prediction_WACV_2024_paper.html": {
    "title": "Incorporating Physics Principles for Precise Human Motion Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Zhang",
      "Jeffrey O. Kephart",
      "Qiang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ren_MuSHRoom_Multi-Sensor_Hybrid_Room_Dataset_for_Joint_3D_Reconstruction_and_WACV_2024_paper.html": {
    "title": "MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuqian Ren",
      "Wenjia Wang",
      "Dingding Cai",
      "Tuuli Tuominen",
      "Juho Kannala",
      "Esa Rahtu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dutta_POISE_Pose_Guided_Human_Silhouette_Extraction_Under_Occlusions_WACV_2024_paper.html": {
    "title": "POISE: Pose Guided Human Silhouette Extraction Under Occlusions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arindam Dutta",
      "Rohit Lal",
      "Dripta S. Raychaudhuri",
      "Calvin-Khang Ta",
      "Amit K. Roy-Chowdhury"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Shape-Guided_Diffusion_With_Inside-Outside_Attention_WACV_2024_paper.html": {
    "title": "Shape-Guided Diffusion With Inside-Outside Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Huk Park",
      "Grace Luo",
      "Clayton Toste",
      "Samaneh Azadi",
      "Xihui Liu",
      "Maka Karalashvili",
      "Anna Rohrbach",
      "Trevor Darrell"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pang_Learning_Visual_Body-Shape-Aware_Embeddings_for_Fashion_Compatibility_WACV_2024_paper.html": {
    "title": "Learning Visual Body-Shape-Aware Embeddings for Fashion Compatibility",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaicheng Pang",
      "Xingxing Zou",
      "Waikeung Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ye_Unsupervised_Exemplar-Based_Image-to-Image_Translation_and_Cascaded_Vision_Transformers_for_Tagged_WACV_2024_paper.html": {
    "title": "Unsupervised Exemplar-Based Image-to-Image Translation and Cascaded Vision Transformers for Tagged and Untagged Cardiac Cine MRI Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Ye",
      "Mikael Kanski",
      "Dong Yang",
      "Leon Axel",
      "Dimitris Metaxas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Khan_Spectroformer_Multi-Domain_Query_Cascaded_Transformer_Network_for_Underwater_Image_Enhancement_WACV_2024_paper.html": {
    "title": "Spectroformer: Multi-Domain Query Cascaded Transformer Network for Underwater Image Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raqib Khan",
      "Priyanka Mishra",
      "Nancy Mehta",
      "Shruti S. Phutke",
      "Santosh Kumar Vipparthi",
      "Sukumar Nandi",
      "Subrahmanyam Murala"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huang_Removing_the_Quality_Tax_in_Controllable_Face_Generation_WACV_2024_paper.html": {
    "title": "Removing the Quality Tax in Controllable Face Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwen Huang",
      "Zhiqiu Yu",
      "Xinjie Yi",
      "Yue Wang",
      "James Tompkin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Santoso_On_Manipulating_Scene_Text_in_the_Wild_With_Diffusion_Models_WACV_2024_paper.html": {
    "title": "On Manipulating Scene Text in the Wild With Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua Santoso",
      "Christian Simon",
      "Williem"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sun_Improved_Techniques_for_Quantizing_Deep_Networks_With_Adaptive_Bit-Widths_WACV_2024_paper.html": {
    "title": "Improved Techniques for Quantizing Deep Networks With Adaptive Bit-Widths",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ximeng Sun",
      "Rameswar Panda",
      "Chun-Fu Richard Chen",
      "Naigang Wang",
      "Bowen Pan",
      "Aude Oliva",
      "Rogerio Feris",
      "Kate Saenko"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Duan_Mining_and_Unifying_Heterogeneous_Contrastive_Relations_for_Weakly-Supervised_Actor-Action_Segmentation_WACV_2024_paper.html": {
    "title": "Mining and Unifying Heterogeneous Contrastive Relations for Weakly-Supervised Actor-Action Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Duan",
      "Hao Tang",
      "Changchang Sun",
      "Ye Zhu",
      "Yan Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Rethinking_Knowledge_Distillation_With_Raw_Features_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Rethinking Knowledge Distillation With Raw Features for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Liu",
      "Chenshu Chen",
      "Xi Yang",
      "Wenming Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Fully-Automatic_Reflection_Removal_for_360-Degree_Images_WACV_2024_paper.html": {
    "title": "Fully-Automatic Reflection Removal for 360-Degree Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonghyuk Park",
      "Hyeona Kim",
      "Eunpil Park",
      "Jae-Young Sim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xian_MITFAS_Mutual_Information_Based_Temporal_Feature_Alignment_and_Sampling_for_WACV_2024_paper.html": {
    "title": "MITFAS: Mutual Information Based Temporal Feature Alignment and Sampling for Aerial Video Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqi Xian",
      "Xijun Wang",
      "Dinesh Manocha"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ziaratnia_Multimodal_Deep_Learning_for_Remote_Stress_Estimation_Using_CCT-LSTM_WACV_2024_paper.html": {
    "title": "Multimodal Deep Learning for Remote Stress Estimation Using CCT-LSTM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sayyedjavad Ziaratnia",
      "Tipporn Laohakangvalvit",
      "Midori Sugaya",
      "Peeraya Sripian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Let_the_Beat_Follow_You_-_Creating_Interactive_Drum_Sounds_WACV_2024_paper.html": {
    "title": "Let the Beat Follow You - Creating Interactive Drum Sounds From Body Rhythm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiulong Liu",
      "Kun Su",
      "Eli Shlizerman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sarkar_A_Visual_Active_Search_Framework_for_Geospatial_Exploration_WACV_2024_paper.html": {
    "title": "A Visual Active Search Framework for Geospatial Exploration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anindya Sarkar",
      "Michael Lanier",
      "Scott Alfeld",
      "Jiarui Feng",
      "Roman Garnett",
      "Nathan Jacobs",
      "Yevgeniy Vorobeychik"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhu_ShARc_Shape_and_Appearance_Recognition_for_Person_Identification_In-the-Wild_WACV_2024_paper.html": {
    "title": "ShARc: Shape and Appearance Recognition for Person Identification In-the-Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haidong Zhu",
      "Wanrong Zheng",
      "Zhaoheng Zheng",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yu_DocReal_Robust_Document_Dewarping_of_Real-Life_Images_via_Attention-Enhanced_Control_WACV_2024_paper.html": {
    "title": "DocReal: Robust Document Dewarping of Real-Life Images via Attention-Enhanced Control Point Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangchen Yu",
      "Yina Xie",
      "Lei Wu",
      "Yafei Wen",
      "Guozhi Wang",
      "Shuai Ren",
      "Xiaoxin Chen",
      "Jianfeng Mao",
      "Wenye Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pidaparthy_Multi-Level_Attention_Aggregation_for_Aesthetic_Face_Relighting_WACV_2024_paper.html": {
    "title": "Multi-Level Attention Aggregation for Aesthetic Face Relighting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hemanth Pidaparthy",
      "Abhay Chauhan",
      "Pavan Sudheendra"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Learning_Residual_Elastic_Warps_for_Image_Stitching_Under_Dirichlet_Boundary_WACV_2024_paper.html": {
    "title": "Learning Residual Elastic Warps for Image Stitching Under Dirichlet Boundary Condition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minsu Kim",
      "Yongjun Lee",
      "Woo Kyoung Han",
      "Kyong Hwan Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Myers-Dean_Interactive_Segmentation_for_Diverse_Gesture_Types_Without_Context_WACV_2024_paper.html": {
    "title": "Interactive Segmentation for Diverse Gesture Types Without Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Josh Myers-Dean",
      "Yifei Fan",
      "Brian Price",
      "Wilson Chan",
      "Danna Gurari"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Customizing_360-Degree_Panoramas_Through_Text-to-Image_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Customizing 360-Degree Panoramas Through Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Wang",
      "Xiaoyu Xiang",
      "Yuchen Fan",
      "Jing-Hao Xue"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hu_Temporal_Context_Enhanced_Referring_Video_Object_Segmentation_WACV_2024_paper.html": {
    "title": "Temporal Context Enhanced Referring Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Hu",
      "Basavaraj Hampiholi",
      "Heiko Neumann",
      "Jochen Lang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Revisiting_Token_Pruning_for_Object_Detection_and_Instance_Segmentation_WACV_2024_paper.html": {
    "title": "Revisiting Token Pruning for Object Detection and Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Liu",
      "Mathias Gehrig",
      "Nico Messikommer",
      "Marco Cannici",
      "Davide Scaramuzza"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gaarsdal_AssemblyNet_A_Point_Cloud_Dataset_and_Benchmark_for_Predicting_Part_WACV_2024_paper.html": {
    "title": "AssemblyNet: A Point Cloud Dataset and Benchmark for Predicting Part Directions in an Exploded Layout",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jesper Gaarsdal",
      "Joakim Bruslund Haurum",
      "Sune Wolff",
      "Claus Brøndgaard Madsen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Caron_Location-Aware_Self-Supervised_Transformers_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Location-Aware Self-Supervised Transformers for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mathilde Caron",
      "Neil Houlsby",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Anastasakis_Self-Supervised_Learning_for_Visual_Relationship_Detection_Through_Masked_Bounding_Box_WACV_2024_paper.html": {
    "title": "Self-Supervised Learning for Visual Relationship Detection Through Masked Bounding Box Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zacharias Anastasakis",
      "Dimitrios Mallis",
      "Markos Diomataris",
      "George Alexandridis",
      "Stefanos Kollias",
      "Vassilis Pitsikalis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ebmer_Real-Time_6-DoF_Pose_Estimation_by_an_Event-Based_Camera_Using_Active_WACV_2024_paper.html": {
    "title": "Real-Time 6-DoF Pose Estimation by an Event-Based Camera Using Active LED Markers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gerald Ebmer",
      "Adam Loch",
      "Minh Nhat Vu",
      "Roberto Mecca",
      "Germain Haessig",
      "Christian Hartl-Nesic",
      "Markus Vincze",
      "Andreas Kugi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ali_P-Age_Pexels_Dataset_for_Robust_Spatio-Temporal_Apparent_Age_Classification_WACV_2024_paper.html": {
    "title": "P-Age: Pexels Dataset for Robust Spatio-Temporal Apparent Age Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abid Ali",
      "Ashish Marisetty",
      "François Brémond"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mahmud_SSVOD_Semi-Supervised_Video_Object_Detection_With_Sparse_Annotations_WACV_2024_paper.html": {
    "title": "SSVOD: Semi-Supervised Video Object Detection With Sparse Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanvir Mahmud",
      "Chun-Hao Liu",
      "Burhaneddin Yaman",
      "Diana Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fletcher_Deep_Optics_for_Optomechanical_Control_Policy_Design_WACV_2024_paper.html": {
    "title": "Deep Optics for Optomechanical Control Policy Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin Fletcher"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Laczko_A_Generative_Multi-Resolution_Pyramid_and_Normal-Conditioning_3D_Cloth_Draping_WACV_2024_paper.html": {
    "title": "A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hunor Laczkó",
      "Meysam Madadi",
      "Sergio Escalera",
      "Jordi Gonzalez"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sagar_MAdVerse_A_Hierarchical_Dataset_of_Multi-Lingual_Ads_From_Diverse_Sources_WACV_2024_paper.html": {
    "title": "MAdVerse: A Hierarchical Dataset of Multi-Lingual Ads From Diverse Sources and Categories",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amruth Sagar",
      "Rishabh Srivastava",
      "Rakshitha R. T.",
      "Venkata Kesav Venna",
      "Ravi Kiran Sarvadevabhatla"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Schubert_Identifying_Label_Errors_in_Object_Detection_Datasets_by_Loss_Inspection_WACV_2024_paper.html": {
    "title": "Identifying Label Errors in Object Detection Datasets by Loss Inspection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marius Schubert",
      "Tobias Riedlinger",
      "Karsten Kahl",
      "Daniel Kröll",
      "Sebastian Schoenen",
      "Siniša Šegvić",
      "Matthias Rottmann"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Agnolucci_Reference-Based_Restoration_of_Digitized_Analog_Videotapes_WACV_2024_paper.html": {
    "title": "Reference-Based Restoration of Digitized Analog Videotapes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Agnolucci",
      "Leonardo Galteri",
      "Marco Bertini",
      "Alberto Del Bimbo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Narayanswamy_BigSmall_Efficient_Multi-Task_Learning_for_Disparate_Spatial_and_Temporal_Physiological_WACV_2024_paper.html": {
    "title": "BigSmall: Efficient Multi-Task Learning for Disparate Spatial and Temporal Physiological Measurements",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Girish Narayanswamy",
      "Yujia Liu",
      "Yuzhe Yang",
      "Chengqian Ma",
      "Xin Liu",
      "Daniel McDuff",
      "Shwetak Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kalla_Robust_Feature_Learning_and_Global_Variance-Driven_Classifier_Alignment_for_Long-Tail_WACV_2024_paper.html": {
    "title": "Robust Feature Learning and Global Variance-Driven Classifier Alignment for Long-Tail Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jayateja Kalla",
      "Soma Biswas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fischer_MagneticPillars_Efficient_Point_Cloud_Registration_Through_Hierarchized_Birds-Eye-View_Cell_Correspondence_WACV_2024_paper.html": {
    "title": "MagneticPillars: Efficient Point Cloud Registration Through Hierarchized Birds-Eye-View Cell Correspondence Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Fischer",
      "Martin Simon",
      "Stefan Milz",
      "Patrick Mäder"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Laroche_Fast_Diffusion_EM_A_Diffusion_Model_for_Blind_Inverse_Problems_WACV_2024_paper.html": {
    "title": "Fast Diffusion EM: A Diffusion Model for Blind Inverse Problems With Application to Deconvolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Charles Laroche",
      "Andrés Almansa",
      "Eva Coupeté"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Taketsugu_Active_Transfer_Learning_for_Efficient_Video-Specific_Human_Pose_Estimation_WACV_2024_paper.html": {
    "title": "Active Transfer Learning for Efficient Video-Specific Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hiromu Taketsugu",
      "Norimichi Ukita"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Training-Free_Layout_Control_With_Cross-Attention_Guidance_WACV_2024_paper.html": {
    "title": "Training-Free Layout Control With Cross-Attention Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghao Chen",
      "Iro Laina",
      "Andrea Vedaldi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/He_Learning_Transferable_Representations_for_Image_Anomaly_Localization_Using_Dense_Pretraining_WACV_2024_paper.html": {
    "title": "Learning Transferable Representations for Image Anomaly Localization Using Dense Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitian He",
      "Sarah Erfani",
      "Mingming Gong",
      "Qiuhong Ke"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Peven_Embedding_Task_Structure_for_Action_Detection_WACV_2024_paper.html": {
    "title": "Embedding Task Structure for Action Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Peven",
      "Gregory D. Hager"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shakibajahromi_RIMeshGNN_A_Rotation-Invariant_Graph_Neural_Network_for_Mesh_Classification_WACV_2024_paper.html": {
    "title": "RIMeshGNN: A Rotation-Invariant Graph Neural Network for Mesh Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bahareh Shakibajahromi",
      "Edward Kim",
      "David E. Breen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cheng_Stereo_Matching_in_Time_100_FPS_Video_Stereo_Matching_for_WACV_2024_paper.html": {
    "title": "Stereo Matching in Time: 100+ FPS Video Stereo Matching for Extended Reality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziang Cheng",
      "Jiayu Yang",
      "Hongdong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Delatolas_Learning_the_What_and_How_of_Annotation_in_Video_Object_WACV_2024_paper.html": {
    "title": "Learning the What and How of Annotation in Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanos Delatolas",
      "Vicky Kalogeiton",
      "Dim P. Papadopoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nasser_Reverse_Knowledge_Distillation_Training_a_Large_Model_Using_a_Small_WACV_2024_paper.html": {
    "title": "Reverse Knowledge Distillation: Training a Large Model Using a Small One for Retinal Image Matching on Limited Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sahar Almahfouz Nasser",
      "Nihar Gupte",
      "Amit Sethi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Schaefer_Edge_Inference_With_Fully_Differentiable_Quantized_Mixed_Precision_Neural_Networks_WACV_2024_paper.html": {
    "title": "Edge Inference With Fully Differentiable Quantized Mixed Precision Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clemens JS Schaefer",
      "Siddharth Joshi",
      "Shan Li",
      "Raul Blazquez"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nadeem_CAD_-_Contextual_Multi-Modal_Alignment_for_Dynamic_AVQA_WACV_2024_paper.html": {
    "title": "CAD - Contextual Multi-Modal Alignment for Dynamic AVQA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asmar Nadeem",
      "Adrian Hilton",
      "Robert Dawes",
      "Graham Thomas",
      "Armin Mustafa"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Singh_Discriminator-Free_Unsupervised_Domain_Adaptation_for_Multi-Label_Image_Classification_WACV_2024_paper.html": {
    "title": "Discriminator-Free Unsupervised Domain Adaptation for Multi-Label Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inder Pal Singh",
      "Enjie Ghorbel",
      "Anis Kacem",
      "Arunkumar Rathinam",
      "Djamila Aouada"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.html": {
    "title": "Continual Test-Time Domain Adaptation via Dynamic Sample Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanshuo Wang",
      "Jie Hong",
      "Ali Cheraghian",
      "Shafin Rahman",
      "David Ahmedt-Aristizabal",
      "Lars Petersson",
      "Mehrtash Harandi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rotstein_FuseCap_Leveraging_Large_Language_Models_for_Enriched_Fused_Image_Captions_WACV_2024_paper.html": {
    "title": "FuseCap: Leveraging Large Language Models for Enriched Fused Image Captions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Noam Rotstein",
      "David Bensaïd",
      "Shaked Brody",
      "Roy Ganz",
      "Ron Kimmel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hu_Learning_To_Adapt_CLIP_for_Few-Shot_Monocular_Depth_Estimation_WACV_2024_paper.html": {
    "title": "Learning To Adapt CLIP for Few-Shot Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueting Hu",
      "Ce Zhang",
      "Yi Zhang",
      "Bowen Hai",
      "Ke Yu",
      "Zhihai He"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shoshan_Asymmetric_Image_Retrieval_With_Cross_Model_Compatible_Ensembles_WACV_2024_paper.html": {
    "title": "Asymmetric Image Retrieval With Cross Model Compatible Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alon Shoshan",
      "Ori Linial",
      "Nadav Bhonker",
      "Elad Hirsch",
      "Lior Zamir",
      "Igor Kviatkovsky",
      "Gérard Medioni"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liao_Progressive_Hypothesis_Transformer_for_3D_Human_Mesh_Recovery_WACV_2024_paper.html": {
    "title": "Progressive Hypothesis Transformer for 3D Human Mesh Recovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huang-Ru Liao",
      "Jen-Chun Lin",
      "Chun-Yi Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lin_MPT_Mesh_Pre-Training_With_Transformers_for_Human_Pose_and_Mesh_WACV_2024_paper.html": {
    "title": "MPT: Mesh Pre-Training With Transformers for Human Pose and Mesh Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Lin",
      "Chung-Ching Lin",
      "Lin Liang",
      "Zicheng Liu",
      "Lijuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jeong_Training-Free_Content_Injection_Using_H-Space_in_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Training-Free Content Injection Using H-Space in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeseok Jeong",
      "Mingi Kwon",
      "Youngjung Uh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Hard_Sample-Aware_Consistency_for_Low-Resolution_Facial_Expression_Recognition_WACV_2024_paper.html": {
    "title": "Hard Sample-Aware Consistency for Low-Resolution Facial Expression Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bokyeung Lee",
      "Kyungdeuk Ko",
      "Jonghwan Hong",
      "Hanseok Ko"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Phan_ZEETAD_Adapting_Pretrained_Vision-Language_Model_for_Zero-Shot_End-to-End_Temporal_Action_WACV_2024_paper.html": {
    "title": "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thinh Phan",
      "Khoa Vo",
      "Duy Le",
      "Gianfranco Doretto",
      "Donald Adjeroh",
      "Ngan Le"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jindal_Army_of_Thieves_Enhancing_Black-Box_Model_Extraction_via_Ensemble_Based_WACV_2024_paper.html": {
    "title": "Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble Based Sample Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshit Jindal",
      "Vikram Goyal",
      "Saket Anand",
      "Chetan Arora"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.html": {
    "title": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vibhas K. Vats",
      "Sripad Joshi",
      "David J. Crandall",
      "Md. Alimoor Reza",
      "Soon-heung Jung"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Goswami_Active_Batch_Sampling_for_Multi-Label_Classification_With_Binary_User_Feedback_WACV_2024_paper.html": {
    "title": "Active Batch Sampling for Multi-Label Classification With Binary User Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debanjan Goswami",
      "Shayok Chakraborty"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Han_Efficient_MAE_Towards_Large-Scale_Vision_Transformers_WACV_2024_paper.html": {
    "title": "Efficient MAE Towards Large-Scale Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiu Han",
      "Gongjie Zhang",
      "Jiaxing Huang",
      "Peng Gao",
      "Zhang Wei",
      "Shijian Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jamal_M33D_Learning_3D_Priors_Using_Multi-Modal_Masked_Autoencoders_for_2D_WACV_2024_paper.html": {
    "title": "M33D: Learning 3D Priors Using Multi-Modal Masked Autoencoders for 2D Image and Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Abdullah Jamal",
      "Omid Mohareri"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Thakur_GraphGraph_A_Nested_Graph-Based_Framework_for_Early_Accident_Anticipation_WACV_2024_paper.html": {
    "title": "Graph(Graph): A Nested Graph-Based Framework for Early Accident Anticipation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nupur Thakur",
      "PrasanthSai Gouripeddi",
      "Baoxin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Joseph_Iterative_Multi-Granular_Image_Editing_Using_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Iterative Multi-Granular Image Editing Using Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "K. J. Joseph",
      "Prateksha Udhayanan",
      "Tripti Shukla",
      "Aishwarya Agarwal",
      "Srikrishna Karanam",
      "Koustava Goswami",
      "Balaji Vasan Srinivasan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Efficient_Feature_Distillation_for_Zero-Shot_Annotation_Object_Detection_WACV_2024_paper.html": {
    "title": "Efficient Feature Distillation for Zero-Shot Annotation Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoming Liu",
      "Xuefeng Hu",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_SpectralCLIP_Preventing_Artifacts_in_Text-Guided_Style_Transfer_From_a_Spectral_WACV_2024_paper.html": {
    "title": "SpectralCLIP: Preventing Artifacts in Text-Guided Style Transfer From a Spectral Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zipeng Xu",
      "Songlong Xing",
      "Enver Sangineto",
      "Nicu Sebe"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Das_Harnessing_the_Power_of_Multi-Lingual_Datasets_for_Pre-Training_Towards_Enhancing_WACV_2024_paper.html": {
    "title": "Harnessing the Power of Multi-Lingual Datasets for Pre-Training: Towards Enhancing Text Spotting Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alloy Das",
      "Sanket Biswas",
      "Ayan Banerjee",
      "Josep Lladós",
      "Umapada Pal",
      "Saumik Bhattacharya"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_Rethink_Cross-Modal_Fusion_in_Weakly-Supervised_Audio-Visual_Video_Parsing_WACV_2024_paper.html": {
    "title": "Rethink Cross-Modal Fusion in Weakly-Supervised Audio-Visual Video Parsing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yating Xu",
      "Conghui Hu",
      "Gim Hee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zang_Refine_and_Redistribute_Multi-Domain_Fusion_and_Dynamic_Label_Assignment_for_WACV_2024_paper.html": {
    "title": "Refine and Redistribute: Multi-Domain Fusion and Dynamic Label Assignment for Unbiased Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Zang",
      "Yaochen Li",
      "Yuan Gao",
      "Yimou Guo",
      "Wenneng Tang",
      "Yanxue Li",
      "Meklit Atlaw"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Semantic_Transfer_From_Head_to_Tail_Enlarging_Tail_Margin_for_WACV_2024_paper.html": {
    "title": "Semantic Transfer From Head to Tail: Enlarging Tail Margin for Long-Tailed Visual Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shan Zhang",
      "Yao Ni",
      "Jinhao Du",
      "Yanxia Liu",
      "Piotr Koniusz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_PoseDiff_Pose-Conditioned_Multimodal_Diffusion_Model_for_Unbounded_Scene_Synthesis_From_WACV_2024_paper.html": {
    "title": "PoseDiff: Pose-Conditioned Multimodal Diffusion Model for Unbounded Scene Synthesis From Sparse Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seoyoung Lee",
      "Joonseok Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sadhu_Leveraging_Task-Specific_Pre-Training_To_Reason_Across_Images_and_Videos_WACV_2024_paper.html": {
    "title": "Leveraging Task-Specific Pre-Training To Reason Across Images and Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arka Sadhu",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rodriguez_Recognition_of_Unseen_Bird_Species_by_Learning_From_Field_Guides_WACV_2024_paper.html": {
    "title": "Recognition of Unseen Bird Species by Learning From Field Guides",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrés C. Rodríguez",
      "Stefano D'Aronco",
      "Rodrigo Caye Daudt",
      "Jan D. Wegner",
      "Konrad Schindler"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hess_LidarCLIP_or_How_I_Learned_To_Talk_to_Point_Clouds_WACV_2024_paper.html": {
    "title": "LidarCLIP or: How I Learned To Talk to Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georg Hess",
      "Adam Tonderski",
      "Christoffer Petersson",
      "Kalle Åström",
      "Lennart Svensson"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sahin_Enhancing_Multimodal_Compositional_Reasoning_of_Visual_Language_Models_With_Generative_WACV_2024_paper.html": {
    "title": "Enhancing Multimodal Compositional Reasoning of Visual Language Models With Generative Negative Mining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ugur Sahin",
      "Hang Li",
      "Qadeer Khan",
      "Daniel Cremers",
      "Volker Tresp"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sung-Bin_LaughTalk_Expressive_3D_Talking_Head_Generation_With_Laughter_WACV_2024_paper.html": {
    "title": "LaughTalk: Expressive 3D Talking Head Generation With Laughter",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kim Sung-Bin",
      "Lee Hyun",
      "Da Hye Hong",
      "Suekyeong Nam",
      "Janghoon Ju",
      "Tae-Hyun Oh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rosskamp_Effects_of_Markers_in_Training_Datasets_on_the_Accuracy_of_WACV_2024_paper.html": {
    "title": "Effects of Markers in Training Datasets on the Accuracy of 6D Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Janis Rosskamp",
      "Rene Weller",
      "Gabriel Zachmann"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Alleviating_Foreground_Sparsity_for_Semi-Supervised_Monocular_3D_Object_Detection_WACV_2024_paper.html": {
    "title": "Alleviating Foreground Sparsity for Semi-Supervised Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijia Zhang",
      "Dongnan Liu",
      "Chao Ma",
      "Weidong Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Neoral_MFT_Long-Term_Tracking_of_Every_Pixel_WACV_2024_paper.html": {
    "title": "MFT: Long-Term Tracking of Every Pixel",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michal Neoral",
      "Jonáš Šerých",
      "Jiří Matas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kirchheim_Out-of-Distribution_Detection_With_Logical_Reasoning_WACV_2024_paper.html": {
    "title": "Out-of-Distribution Detection With Logical Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstantin Kirchheim",
      "Tim Gonschorek",
      "Frank Ortmeier"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_WalkFormer_Point_Cloud_Completion_via_Guided_Walks_WACV_2024_paper.html": {
    "title": "WalkFormer: Point Cloud Completion via Guided Walks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohang Zhang",
      "Yushi Li",
      "Rong Chen",
      "Yushan Pan",
      "Jia Wang",
      "Yunzhe Wang",
      "Rong Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Echterhoff_Driving_Through_the_Concept_Gridlock_Unraveling_Explainability_Bottlenecks_in_Automated_WACV_2024_paper.html": {
    "title": "Driving Through the Concept Gridlock: Unraveling Explainability Bottlenecks in Automated Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jessica Echterhoff",
      "An Yan",
      "Kyungtae Han",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Julian McAuley"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Spetlik_Single-Image_Deblurring_Trajectory_and_Shape_Recovery_of_Fast_Moving_Objects_WACV_2024_paper.html": {
    "title": "Single-Image Deblurring, Trajectory and Shape Recovery of Fast Moving Objects With Denoising Diffusion Probabilistic Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Radim Spetlik",
      "Denys Rozumnyi",
      "Jiří Matas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shaik_IDD-AW_A_Benchmark_for_Safe_and_Robust_Segmentation_of_Drive_WACV_2024_paper.html": {
    "title": "IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Furqan Ahmed Shaik",
      "Abhishek Reddy",
      "Nikhil Reddy Billa",
      "Kunal Chaudhary",
      "Sunny Manchanda",
      "Girish Varma"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Doubinsky_Semantic_Generative_Augmentations_for_Few-Shot_Counting_WACV_2024_paper.html": {
    "title": "Semantic Generative Augmentations for Few-Shot Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Perla Doubinsky",
      "Nicolas Audebert",
      "Michel Crucianu",
      "Hervé Le Borgne"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jeanneret_Text-to-Image_Models_for_Counterfactual_Explanations_A_Black-Box_Approach_WACV_2024_paper.html": {
    "title": "Text-to-Image Models for Counterfactual Explanations: A Black-Box Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Jeanneret",
      "Loïc Simon",
      "Frédéric Jurie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dong_Physical-Space_Multi-Body_Mesh_Detection_Achieved_by_Local_Alignment_and_Global_WACV_2024_paper.html": {
    "title": "Physical-Space Multi-Body Mesh Detection Achieved by Local Alignment and Global Dense Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoye Dong",
      "Tiange Xiang",
      "Sravan Chittupalli",
      "Jun Liu",
      "Dong Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Otholt_Guided_Cluster_Aggregation_A_Hierarchical_Approach_to_Generalized_Category_Discovery_WACV_2024_paper.html": {
    "title": "Guided Cluster Aggregation: A Hierarchical Approach to Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jona Otholt",
      "Christoph Meinel",
      "Haojin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Klenk_Masked_Event_Modeling_Self-Supervised_Pretraining_for_Event_Cameras_WACV_2024_paper.html": {
    "title": "Masked Event Modeling: Self-Supervised Pretraining for Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Klenk",
      "David Bonello",
      "Lukas Koestler",
      "Nikita Araslanov",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yoo_Real-Time_Polyp_Detection_in_Colonoscopy_Using_Lightweight_Transformer_WACV_2024_paper.html": {
    "title": "Real-Time Polyp Detection in Colonoscopy Using Lightweight Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youngbeom Yoo",
      "Jae Young Lee",
      "Dong-Jae Lee",
      "Jiwoon Jeon",
      "Junmo Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kolodiazhnyi_Top-Down_Beats_Bottom-Up_in_3D_Instance_Segmentation_WACV_2024_paper.html": {
    "title": "Top-Down Beats Bottom-Up in 3D Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maksim Kolodiazhnyi",
      "Anna Vorontsova",
      "Anton Konushin",
      "Danila Rukhovich"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sarkar_Open-Set_Object_Detection_by_Aligning_Known_Class_Representations_WACV_2024_paper.html": {
    "title": "Open-Set Object Detection by Aligning Known Class Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hiran Sarkar",
      "Vishal Chudasama",
      "Naoyuki Onoe",
      "Pankaj Wasnik",
      "Vineeth N. Balasubramanian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_DR2_Disentangled_Recurrent_Representation_Learning_for_Data-Efficient_Speech_Video_Synthesis_WACV_2024_paper.html": {
    "title": "DR2: Disentangled Recurrent Representation Learning for Data-Efficient Speech Video Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxu Zhang",
      "Chao Wang",
      "Yifan Zhao",
      "Shuo Cheng",
      "Linjie Luo",
      "Xiaohu Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bhattacharya_EvDNeRF_Reconstructing_Event_Data_With_Dynamic_Neural_Radiance_Fields_WACV_2024_paper.html": {
    "title": "EvDNeRF: Reconstructing Event Data With Dynamic Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anish Bhattacharya",
      "Ratnesh Madaan",
      "Fernando Cladera",
      "Sai Vemprala",
      "Rogerio Bonatti",
      "Kostas Daniilidis",
      "Ashish Kapoor",
      "Vijay Kumar",
      "Nikolai Matni",
      "Jayesh K. Gupta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Qin_DISCO_Distributed_Inference_With_Sparse_Communications_WACV_2024_paper.html": {
    "title": "DISCO: Distributed Inference With Sparse Communications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghai Qin",
      "Chao Sun",
      "Jaco Hofmann",
      "Dejan Vucinic"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Azari_EmoStyle_One-Shot_Facial_Expression_Editing_Using_Continuous_Emotion_Parameters_WACV_2024_paper.html": {
    "title": "EmoStyle: One-Shot Facial Expression Editing Using Continuous Emotion Parameters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bita Azari",
      "Angelica Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Harithas_FinderNet_A_Data_Augmentation_Free_Canonicalization_Aided_Loop_Detection_and_WACV_2024_paper.html": {
    "title": "FinderNet: A Data Augmentation Free Canonicalization Aided Loop Detection and Closure Technique for Point Clouds in 6-DOF Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sudarshan S. Harithas",
      "Gurkirat Singh",
      "Aneesh Chavan",
      "Sarthak Sharma",
      "Suraj Patni",
      "Chetan Arora",
      "Madhava Krishna"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Distortion-Disentangled_Contrastive_Learning_WACV_2024_paper.html": {
    "title": "Distortion-Disentangled Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinfeng Wang",
      "Sifan Song",
      "Jionglong Su",
      "S. Kevin Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gungor_Boosting_Weakly_Supervised_Object_Detection_Using_Fusion_and_Priors_From_WACV_2024_paper.html": {
    "title": "Boosting Weakly Supervised Object Detection Using Fusion and Priors From Hallucinated Depth",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cagri Gungor",
      "Adriana Kovashka"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Himmi_MS-EVS_Multispectral_Event-Based_Vision_for_Deep_Learning_Based_Face_Detection_WACV_2024_paper.html": {
    "title": "MS-EVS: Multispectral Event-Based Vision for Deep Learning Based Face Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saad Himmi",
      "Vincent Parret",
      "Ajad Chhatkuli",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Adaptive_Latent_Diffusion_Model_for_3D_Medical_Image_to_Image_WACV_2024_paper.html": {
    "title": "Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-Modal Magnetic Resonance Imaging Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonghun Kim",
      "Hyunjin Park"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Thakare_Lets_Observe_Them_Over_Time_An_Improved_Pedestrian_Attribute_Recognition_WACV_2024_paper.html": {
    "title": "Let's Observe Them Over Time: An Improved Pedestrian Attribute Recognition Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kamalakar Vijay Thakare",
      "Debi Prosad Dogra",
      "Heeseung Choi",
      "Haksub Kim",
      "Ig-Jae Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dey_AnyStar_Domain_Randomized_Universal_Star-Convex_3D_Instance_Segmentation_WACV_2024_paper.html": {
    "title": "AnyStar: Domain Randomized Universal Star-Convex 3D Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neel Dey",
      "Mazdak Abulnaga",
      "Benjamin Billot",
      "Esra Abaci Turk",
      "Ellen Grant",
      "Adrian V. Dalca",
      "Polina Golland"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Haalck_Solving_the_Plane-Sphere_Ambiguity_in_Top-Down_Structure-From-Motion_WACV_2024_paper.html": {
    "title": "Solving the Plane-Sphere Ambiguity in Top-Down Structure-From-Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lars Haalck",
      "Benjamin Risse"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Herzig_PromptonomyViT_Multi-Task_Prompt_Learning_Improves_Video_Transformers_Using_Synthetic_Scene_WACV_2024_paper.html": {
    "title": "PromptonomyViT: Multi-Task Prompt Learning Improves Video Transformers Using Synthetic Scene Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roei Herzig",
      "Ofir Abramovich",
      "Elad Ben Avraham",
      "Assaf Arbelle",
      "Leonid Karlinsky",
      "Ariel Shamir",
      "Trevor Darrell",
      "Amir Globerson"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Improving_the_Leaking_of_Augmentations_in_Data-Efficient_GANs_via_Adaptive_WACV_2024_paper.html": {
    "title": "Improving the Leaking of Augmentations in Data-Efficient GANs via Adaptive Negative Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyu Zhang",
      "Yang Hua",
      "Guanxiong Sun",
      "Hui Wang",
      "Seán McLoone"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Enhancing_Diverse_Intra-Identity_Representation_for_Visible-Infrared_Person_Re-Identification_WACV_2024_paper.html": {
    "title": "Enhancing Diverse Intra-Identity Representation for Visible-Infrared Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sejun Kim",
      "Soonyong Gwon",
      "Kisung Seo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Katageri_Synergizing_Contrastive_Learning_and_Optimal_Transport_for_3D_Point_Cloud_WACV_2024_paper.html": {
    "title": "Synergizing Contrastive Learning and Optimal Transport for 3D Point Cloud Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Katageri",
      "Arkadipta De",
      "Chaitanya Devaguptapu",
      "VSSV Prasad",
      "Charu Sharma",
      "Manohar Kaul"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Video_Instance_Matting_WACV_2024_paper.html": {
    "title": "Video Instance Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen Li",
      "Roberto Henschel",
      "Vidit Goel",
      "Marianna Ohanyan",
      "Shant Navasardyan",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_DPPMask_Masked_Image_Modeling_With_Determinantal_Point_Processes_WACV_2024_paper.html": {
    "title": "DPPMask: Masked Image Modeling With Determinantal Point Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junde Xu",
      "Zikai Lin",
      "Donghao Zhou",
      "Yaodong Yang",
      "Xiangyun Liao",
      "Qiong Wang",
      "Bian Wu",
      "Guangyong Chen",
      "Pheng-Ann Heng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kapil_ShadowSense_Unsupervised_Domain_Adaptation_and_Feature_Fusion_for_Shadow-Agnostic_Tree_WACV_2024_paper.html": {
    "title": "ShadowSense: Unsupervised Domain Adaptation and Feature Fusion for Shadow-Agnostic Tree Crown Detection From RGB-Thermal Drone Imagery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rudraksh Kapil",
      "Seyed Mojtaba Marvasti-Zadeh",
      "Nadir Erbilgin",
      "Nilanjan Ray"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Pruning_From_Scratch_via_Shared_Pruning_Module_and_Nuclear_Norm-Based_WACV_2024_paper.html": {
    "title": "Pruning From Scratch via Shared Pruning Module and Nuclear Norm-Based Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Donghyeon Lee",
      "Eunho Lee",
      "Youngbae Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jobin_Semantic_Labels-Aware_Transformer_Model_for_Searching_Over_a_Large_Collection_WACV_2024_paper.html": {
    "title": "Semantic Labels-Aware Transformer Model for Searching Over a Large Collection of Lecture-Slides",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "K. V. Jobin",
      "Anand Mishra",
      "C. V. Jawahar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Multimodal_Channel-Mixing_Channel_and_Spatial_Masked_AutoEncoder_on_Facial_Action_WACV_2024_paper.html": {
    "title": "Multimodal Channel-Mixing: Channel and Spatial Masked AutoEncoder on Facial Action Unit Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Zhang",
      "Huiyuan Yang",
      "Taoyue Wang",
      "Xiaotian Li",
      "Lijun Yin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ko_ZIGNeRF_Zero-Shot_3D_Scene_Representation_With_Invertible_Generative_Neural_Radiance_WACV_2024_paper.html": {
    "title": "ZIGNeRF: Zero-Shot 3D Scene Representation With Invertible Generative Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kanghyeok Ko",
      "Minhyeok Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lu_SLoSH_Set_Locality_Sensitive_Hashing_via_Sliced-Wasserstein_Embeddings_WACV_2024_paper.html": {
    "title": "SLoSH: Set Locality Sensitive Hashing via Sliced-Wasserstein Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhe Lu",
      "Xinran Liu",
      "Andrea Soltoggio",
      "Soheil Kolouri"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yuan_StreamMapNet_Streaming_Mapping_Network_for_Vectorized_Online_HD_Map_Construction_WACV_2024_paper.html": {
    "title": "StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map Construction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyuan Yuan",
      "Yicheng Liu",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Argaw_Blurry_Video_Compression_A_Trade-Off_Between_Visual_Enhancement_and_Data_WACV_2024_paper.html": {
    "title": "Blurry Video Compression: A Trade-Off Between Visual Enhancement and Data Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dawit Mureja Argaw",
      "Junsik Kim",
      "In So Kweon"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_Correlation-Aware_Active_Learning_for_Surgery_Video_Segmentation_WACV_2024_paper.html": {
    "title": "Correlation-Aware Active Learning for Surgery Video Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Wu",
      "Pablo Márquez-Neila",
      "Mingyi Zheng",
      "Hedyeh Rafii-Tari",
      "Raphael Sznitman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jeong_EResFD_Rediscovery_of_the_Effectiveness_of_Standard_Convolution_for_Lightweight_WACV_2024_paper.html": {
    "title": "EResFD: Rediscovery of the Effectiveness of Standard Convolution for Lightweight Face Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonhyun Jeong",
      "Beomyoung Kim",
      "Joonsang Yu",
      "YoungJoon Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Babaiee_Neural_Echos_Depthwise_Convolutional_Filters_Replicate_Biological_Receptive_Fields_WACV_2024_paper.html": {
    "title": "Neural Echos: Depthwise Convolutional Filters Replicate Biological Receptive Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zahra Babaiee",
      "Peyman M. Kiasari",
      "Daniela Rus",
      "Radu Grosu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Keshtkaran_Estimating_Blood_Alcohol_Level_Through_Facial_Features_for_Driver_Impairment_WACV_2024_paper.html": {
    "title": "Estimating Blood Alcohol Level Through Facial Features for Driver Impairment Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ensiyeh Keshtkaran",
      "Brodie von Berg",
      "Grant Regan",
      "David Suter",
      "Syed Zulqarnain Gilani"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Saffi_Auto-BPA_An_Enhanced_Ball-Pivoting_Algorithm_With_Adaptive_Radius_Using_Contextual_WACV_2024_paper.html": {
    "title": "Auto-BPA: An Enhanced Ball-Pivoting Algorithm With Adaptive Radius Using Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houda Saffi",
      "Naima Otberdout",
      "Youssef Hmamouche",
      "Amal El Fallah Seghrouchni"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kawamura_MIDAS_Mixing_Ambiguous_Data_With_Soft_Labels_for_Dynamic_Facial_WACV_2024_paper.html": {
    "title": "MIDAS: Mixing Ambiguous Data With Soft Labels for Dynamic Facial Expression Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryosuke Kawamura",
      "Hideaki Hayashi",
      "Noriko Takemura",
      "Hajime Nagahara"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/van_Rozendaal_MobileNVC_Real-Time_1080p_Neural_Video_Compression_on_a_Mobile_Device_WACV_2024_paper.html": {
    "title": "MobileNVC: Real-Time 1080p Neural Video Compression on a Mobile Device",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ties van Rozendaal",
      "Tushar Singhal",
      "Hoang Le",
      "Guillaume Sautiere",
      "Amir Said",
      "Krishna Buska",
      "Anjuman Raha",
      "Dimitris Kalatzis",
      "Hitarth Mehta",
      "Frank Mayer",
      "Liang Zhang",
      "Markus Nagel",
      "Auke Wiggers"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Improving_the_Effectiveness_of_Deep_Generative_Data_WACV_2024_paper.html": {
    "title": "Improving the Effectiveness of Deep Generative Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruyu Wang",
      "Sabrina Schmedding",
      "Marco F. Huber"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_Learning_Better_Keypoints_for_Multi-Object_6DoF_Pose_Estimation_WACV_2024_paper.html": {
    "title": "Learning Better Keypoints for Multi-Object 6DoF Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangzheng Wu",
      "Michael Greenspan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhu_Unsupervised_Graphic_Layout_Grouping_With_Transformers_WACV_2024_paper.html": {
    "title": "Unsupervised Graphic Layout Grouping With Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialiang Zhu",
      "Danqing Huang",
      "Chunyu Wang",
      "Mingxi Cheng",
      "Ji Li",
      "Han Hu",
      "Xin Geng",
      "Baining Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Can_Vision-Language_Models_Be_a_Good_Guesser_Exploring_VLMs_for_WACV_2024_paper.html": {
    "title": "Can Vision-Language Models Be a Good Guesser? Exploring VLMs for Times and Location Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gengyuan Zhang",
      "Yurui Zhang",
      "Kerui Zhang",
      "Volker Tresp"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cao_What_Decreases_Editing_Capability_Domain-Specific_Hybrid_Refinement_for_Improved_GAN_WACV_2024_paper.html": {
    "title": "What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pu Cao",
      "Lu Yang",
      "Dongxv Liu",
      "Xiaoya Yang",
      "Tianrui Huang",
      "Qing Song"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Longformer_Longitudinal_Transformer_for_Alzheimers_Disease_Classification_With_Structural_MRIs_WACV_2024_paper.html": {
    "title": "Longformer: Longitudinal Transformer for Alzheimer's Disease Classification With Structural MRIs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiuhui Chen",
      "Qiang Fu",
      "Hao Bai",
      "Yi Hong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Grafting_Vision_Transformers_WACV_2024_paper.html": {
    "title": "Grafting Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongwoo Park",
      "Kumara Kahatapitiya",
      "Donghyun Kim",
      "Shivchander Sudalairaj",
      "Quanfu Fan",
      "Michael S. Ryoo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sinha_Hardware_Aware_Evolutionary_Neural_Architecture_Search_Using_Representation_Similarity_Metric_WACV_2024_paper.html": {
    "title": "Hardware Aware Evolutionary Neural Architecture Search Using Representation Similarity Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nilotpal Sinha",
      "Abd El Rahman Shabayek",
      "Anis Kacem",
      "Peyman Rostami",
      "Carl Shneider",
      "Djamila Aouada"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_DECDM_Document_Enhancement_Using_Cycle-Consistent_Diffusion_Models_WACV_2024_paper.html": {
    "title": "DECDM: Document Enhancement Using Cycle-Consistent Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Zhang",
      "Joy Rimchala",
      "Lalla Mouatadid",
      "Kamalika Das",
      "Sricharan Kumar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Habib_Watch_Where_You_Head_A_View-Biased_Domain_Gap_in_Gait_WACV_2024_paper.html": {
    "title": "Watch Where You Head: A View-Biased Domain Gap in Gait Recognition and Unsupervised Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gavriel Habib",
      "Noa Barzilay",
      "Or Shimshi",
      "Rami Ben-Ari",
      "Nir Darshan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Show_Your_Face_Restoring_Complete_Facial_Images_From_Partial_Observations_WACV_2024_paper.html": {
    "title": "Show Your Face: Restoring Complete Facial Images From Partial Observations for VR Meeting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Chen",
      "Zhiqi Zhang",
      "Junsong Yuan",
      "Yi Xu",
      "Lantao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chaudhury_Shape_From_Shading_for_Robotic_Manipulation_WACV_2024_paper.html": {
    "title": "Shape From Shading for Robotic Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arkadeep Narayan Chaudhury",
      "Leonid Keselman",
      "Christopher G. Atkeson"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yasarla_Self-Supervised_Denoising_Transformer_With_Gaussian_Process_WACV_2024_paper.html": {
    "title": "Self-Supervised Denoising Transformer With Gaussian Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rajeev Yasarla",
      "Jeya Maria Jose Valanarasu",
      "Vishwanath Sindagi",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_SemST_Semantically_Consistent_Multi-Scale_Image_Translation_via_Structure-Texture_Alignment_WACV_2024_paper.html": {
    "title": "SemST: Semantically Consistent Multi-Scale Image Translation via Structure-Texture Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ganning Zhao",
      "Wenhui Cui",
      "Suya You",
      "C.-C. Jay Kuo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mounsaveng_Bag_of_Tricks_for_Fully_Test-Time_Adaptation_WACV_2024_paper.html": {
    "title": "Bag of Tricks for Fully Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saypraseuth Mounsaveng",
      "Florent Chiaroni",
      "Malik Boudiaf",
      "Marco Pedersoli",
      "Ismail Ben Ayed"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Majhi_OE-CTST_Outlier-Embedded_Cross_Temporal_Scale_Transformer_for_Weakly-Supervised_Video_Anomaly_WACV_2024_paper.html": {
    "title": "OE-CTST: Outlier-Embedded Cross Temporal Scale Transformer for Weakly-Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Snehashis Majhi",
      "Rui Dai",
      "Quan Kong",
      "Lorenzo Garattoni",
      "Gianpiero Francesca",
      "François Brémond"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Haslum_Bridging_Generalization_Gaps_in_High_Content_Imaging_Through_Online_Self-Supervised_WACV_2024_paper.html": {
    "title": "Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johan Fredin Haslum",
      "Christos Matsoukas",
      "Karl-Johan Leuchowius",
      "Kevin Smith"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tiwari_Using_Early_Readouts_To_Mediate_Featural_Bias_in_Distillation_WACV_2024_paper.html": {
    "title": "Using Early Readouts To Mediate Featural Bias in Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishabh Tiwari",
      "Durga Sivasubramanian",
      "Anmol Mekala",
      "Ganesh Ramakrishnan",
      "Pradeep Shenoy"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Atanyan_Continuous_Adaptation_for_Interactive_Segmentation_Using_Teacher-Student_Architecture_WACV_2024_paper.html": {
    "title": "Continuous Adaptation for Interactive Segmentation Using Teacher-Student Architecture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barsegh Atanyan",
      "Levon Khachatryan",
      "Shant Navasardyan",
      "Yunchao Wei",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Venkataramani_Causal_Feature_Alignment_Learning_To_Ignore_Spurious_Background_Features_WACV_2024_paper.html": {
    "title": "Causal Feature Alignment: Learning To Ignore Spurious Background Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rahul Venkataramani",
      "Parag Dutta",
      "Vikram Melapudi",
      "Ambedkar Dukkipati"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Abdessaied_VD-GR_Boosting_Visual_Dialog_With_Cascaded_Spatial-Temporal_Multi-Modal_Graphs_WACV_2024_paper.html": {
    "title": "VD-GR: Boosting Visual Dialog With Cascaded Spatial-Temporal Multi-Modal Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adnen Abdessaied",
      "Lei Shi",
      "Andreas Bulling"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ramachandra_Fingervein_Verification_Using_Convolutional_Multi-Head_Attention_Network_WACV_2024_paper.html": {
    "title": "Fingervein Verification Using Convolutional Multi-Head Attention Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raghavendra Ramachandra",
      "Sushma Venkatesh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_Foundation_Model_Assisted_Weakly_Supervised_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Foundation Model Assisted Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobo Yang",
      "Xiaojin Gong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ruan_Describe_Images_in_a_Boring_Way_Towards_Cross-Modal_Sarcasm_Generation_WACV_2024_paper.html": {
    "title": "Describe Images in a Boring Way: Towards Cross-Modal Sarcasm Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ruan",
      "Yue Wu",
      "Xiaojun Wan",
      "Yuesheng Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Offline-to-Online_Knowledge_Distillation_for_Video_Instance_Segmentation_WACV_2024_paper.html": {
    "title": "Offline-to-Online Knowledge Distillation for Video Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hojin Kim",
      "Seunghun Lee",
      "Hyeon Kang",
      "Sunghoon Im"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yuan_Rethinking_Multimodal_Content_Moderation_From_an_Asymmetric_Angle_With_Mixed-Modality_WACV_2024_paper.html": {
    "title": "Rethinking Multimodal Content Moderation From an Asymmetric Angle With Mixed-Modality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialin Yuan",
      "Ye Yu",
      "Gaurav Mittal",
      "Matthew Hall",
      "Sandra Sajeev",
      "Mei Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hekimoglu_Active_Learning_With_Task_Consistency_and_Diversity_in_Multi-Task_Networks_WACV_2024_paper.html": {
    "title": "Active Learning With Task Consistency and Diversity in Multi-Task Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aral Hekimoglu",
      "Michael Schmidt",
      "Alvaro Marcos-Ramiro"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chuah_Single_Domain_Generalization_via_Normalised_Cross-Correlation_Based_Convolutions_WACV_2024_paper.html": {
    "title": "Single Domain Generalization via Normalised Cross-Correlation Based Convolutions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "WeiQin Chuah",
      "Ruwan Tennakoon",
      "Reza Hoseinnezhad",
      "David Suter",
      "Alireza Bab-Hadiashar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kalshetti_Intrinsic_Hand_Avatar_Illumination-Aware_Hand_Appearance_and_Shape_Reconstruction_From_WACV_2024_paper.html": {
    "title": "Intrinsic Hand Avatar: Illumination-Aware Hand Appearance and Shape Reconstruction From Monocular RGB Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratik Kalshetti",
      "Parag Chaudhuri"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Therien_Object_Re-Identification_From_Point_Clouds_WACV_2024_paper.html": {
    "title": "Object Re-Identification From Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Thérien",
      "Chengjie Huang",
      "Adrian Chow",
      "Krzysztof Czarnecki"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ribeiro-Gomes_MotionGPT_Human_Motion_Synthesis_With_Improved_Diversity_and_Realism_via_WACV_2024_paper.html": {
    "title": "MotionGPT: Human Motion Synthesis With Improved Diversity and Realism via GPT-3 Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jose Ribeiro-Gomes",
      "Tianhui Cai",
      "Zoltán Á. Milacski",
      "Chen Wu",
      "Aayush Prakash",
      "Shingo Takagi",
      "Amaury Aubel",
      "Daeil Kim",
      "Alexandre Bernardino",
      "Fernando De la Torre"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Marvasti-Zadeh_Training-Based_Model_Refinement_and_Representation_Disagreement_for_Semi-Supervised_Object_Detection_WACV_2024_paper.html": {
    "title": "Training-Based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Efficient_Layout-Guided_Image_Inpainting_for_Mobile_Use_WACV_2024_paper.html": {
    "title": "Efficient Layout-Guided Image Inpainting for Mobile Use",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Li",
      "Yi Wei",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Giazitzis_SigmML_Metric_Meta-Learning_for_Writer_Independent_Offline_Signature_Verification_in_WACV_2024_paper.html": {
    "title": "SigmML: Metric Meta-Learning for Writer Independent Offline Signature Verification in the Space of SPD Matrices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexios Giazitzis",
      "Elias N. Zois"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Marouf_Mini_but_Mighty_Finetuning_ViTs_With_Mini_Adapters_WACV_2024_paper.html": {
    "title": "Mini but Mighty: Finetuning ViTs With Mini Adapters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Imad Eddine Marouf",
      "Enzo Tartaglione",
      "Stéphane Lathuilière"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fang_Dynamic_Multimodal_Information_Bottleneck_for_Multimodality_Classification_WACV_2024_paper.html": {
    "title": "Dynamic Multimodal Information Bottleneck for Multimodality Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingying Fang",
      "Shuang Wu",
      "Sheng Zhang",
      "Chaoyan Huang",
      "Tieyong Zeng",
      "Xiaodan Xing",
      "Simon Walsh",
      "Guang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Srinath_Learning_Generalizable_Perceptual_Representations_for_Data-Efficient_No-Reference_Image_Quality_Assessment_WACV_2024_paper.html": {
    "title": "Learning Generalizable Perceptual Representations for Data-Efficient No-Reference Image Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suhas Srinath",
      "Shankhanil Mitra",
      "Shika Rao",
      "Rajiv Soundararajan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Achary_Real_Time_GAZED_Online_Shot_Selection_and_Editing_of_Virtual_WACV_2024_paper.html": {
    "title": "Real Time GAZED: Online Shot Selection and Editing of Virtual Cameras From Wide-Angle Monocular Video Recordings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sudheer Achary",
      "Rohit Girmaji",
      "Adhiraj Anil Deshmukh",
      "Vineet Gandhi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jung_ConfTrack_Kalman_Filter-Based_Multi-Person_Tracking_by_Utilizing_Confidence_Score_of_WACV_2024_paper.html": {
    "title": "ConfTrack: Kalman Filter-Based Multi-Person Tracking by Utilizing Confidence Score of Detection Box",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeonchul Jung",
      "Seokjun Kang",
      "Takgen Kim",
      "HyeongKi Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Arora_Hybrid_Sample_Synthesis-Based_Debiasing_of_Classifier_in_Limited_Data_Setting_WACV_2024_paper.html": {
    "title": "Hybrid Sample Synthesis-Based Debiasing of Classifier in Limited Data Setting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piyush Arora",
      "Pratik Mazumder"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Islam_Visually_Guided_Audio_Source_Separation_With_Meta_Consistency_Learning_WACV_2024_paper.html": {
    "title": "Visually Guided Audio Source Separation With Meta Consistency Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Amirul Islam",
      "Seyed Shahabeddin Nabavi",
      "Irina Kezele",
      "Yang Wang",
      "Yuanhao Yu",
      "Jin Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Deane_RGBT-Dog_A_Parametric_Model_and_Pose_Prior_for_Canine_Body_WACV_2024_paper.html": {
    "title": "RGBT-Dog: A Parametric Model and Pose Prior for Canine Body Analysis Data Creation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jake Deane",
      "Sinéad Kearney",
      "Kwang In Kim",
      "Darren Cosker"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Harb_Diffusion-Based_Generation_of_Histopathological_Whole_Slide_Images_at_a_Gigapixel_WACV_2024_paper.html": {
    "title": "Diffusion-Based Generation of Histopathological Whole Slide Images at a Gigapixel Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robert Harb",
      "Thomas Pock",
      "Heimo Müller"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Bridging_the_Gap_Between_Multi-Focus_and_Multi-Modal_A_Focused_Integration_WACV_2024_paper.html": {
    "title": "Bridging the Gap Between Multi-Focus and Multi-Modal: A Focused Integration Framework for Multi-Modal Image Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xilai Li",
      "Xiaosong Li",
      "Tao Ye",
      "Xiaoqi Cheng",
      "Wuyang Liu",
      "Haishu Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Raine_Image_Labels_Are_All_You_Need_for_Coarse_Seagrass_Segmentation_WACV_2024_paper.html": {
    "title": "Image Labels Are All You Need for Coarse Seagrass Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Scarlett Raine",
      "Ross Marchant",
      "Brano Kusy",
      "Frederic Maire",
      "Tobias Fischer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Henrich_Registered_and_Segmented_Deformable_Object_Reconstruction_From_a_Single_View_WACV_2024_paper.html": {
    "title": "Registered and Segmented Deformable Object Reconstruction From a Single View Point Cloud",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pit Henrich",
      "Balázs Gyenes",
      "Paul Maria Scheikl",
      "Gerhard Neumann",
      "Franziska Mathis-Ullrich"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lazarou_Adaptive_Manifold_for_Imbalanced_Transductive_Few-Shot_Learning_WACV_2024_paper.html": {
    "title": "Adaptive Manifold for Imbalanced Transductive Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michalis Lazarou",
      "Yannis Avrithis",
      "Tania Stathaki"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lin_Restoring_Degraded_Old_Films_With_Recursive_Recurrent_Transformer_Networks_WACV_2024_paper.html": {
    "title": "Restoring Degraded Old Films With Recursive Recurrent Transformer Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shan Lin",
      "Edgar Simo-Serra"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chodosh_Re-Evaluating_LiDAR_Scene_Flow_WACV_2024_paper.html": {
    "title": "Re-Evaluating LiDAR Scene Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathaniel Chodosh",
      "Deva Ramanan",
      "Simon Lucey"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ji_Unsupervised_3D_Pose_Estimation_With_Non-Rigid_Structure-From-Motion_Modeling_WACV_2024_paper.html": {
    "title": "Unsupervised 3D Pose Estimation With Non-Rigid Structure-From-Motion Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haorui Ji",
      "Hui Deng",
      "Yuchao Dai",
      "Hongdong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yuan_FAKD_Feature_Augmented_Knowledge_Distillation_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "FAKD: Feature Augmented Knowledge Distillation for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianlong Yuan",
      "Minh Hieu Phan",
      "Liyang Liu",
      "Yifan Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ruan_TriCoLo_Trimodal_Contrastive_Loss_for_Text_To_Shape_Retrieval_WACV_2024_paper.html": {
    "title": "TriCoLo: Trimodal Contrastive Loss for Text To Shape Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Ruan",
      "Han-Hung Lee",
      "Yiming Zhang",
      "Ke Zhang",
      "Angel X. Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hur_Expanding_Expressiveness_of_Diffusion_Models_With_Limited_Data_via_Self-Distillation_WACV_2024_paper.html": {
    "title": "Expanding Expressiveness of Diffusion Models With Limited Data via Self-Distillation Based Fine-Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiwan Hur",
      "Jaehyun Choi",
      "Gyojin Han",
      "Dong-Jae Lee",
      "Junmo Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mukhopadhyay_Diff2Lip_Audio_Conditioned_Diffusion_Models_for_Lip-Synchronization_WACV_2024_paper.html": {
    "title": "Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumik Mukhopadhyay",
      "Saksham Suri",
      "Ravi Teja Gadde",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_A_Atrous_Spatial_Temporal_Action_Recognition_for_Real_Time_Applications_WACV_2024_paper.html": {
    "title": "A*: Atrous Spatial Temporal Action Recognition for Real Time Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myeongjun Kim",
      "Federica Spinola",
      "Philipp Benz",
      "Tae-hoon Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yi_Augment_the_Pairs_Semantics-Preserving_Image-Caption_Pair_Augmentation_for_Grounding-Based_Vision_WACV_2024_paper.html": {
    "title": "Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingru Yi",
      "Burak Uzkent",
      "Oana Ignat",
      "Zili Li",
      "Amanmeet Garg",
      "Xiang Yu",
      "Linda Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Valvano_Controllable_Image_Synthesis_of_Industrial_Data_Using_Stable_Diffusion_WACV_2024_paper.html": {
    "title": "Controllable Image Synthesis of Industrial Data Using Stable Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriele Valvano",
      "Antonino Agostino",
      "Giovanni De Magistris",
      "Antonino Graziano",
      "Giacomo Veneri"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dong_Understanding_Dark_Scenes_by_Contrasting_Multi-Modal_Observations_WACV_2024_paper.html": {
    "title": "Understanding Dark Scenes by Contrasting Multi-Modal Observations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Dong",
      "Naoto Yokoya"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Deng_Expanding_Hyperspherical_Space_for_Few-Shot_Class-Incremental_Learning_WACV_2024_paper.html": {
    "title": "Expanding Hyperspherical Space for Few-Shot Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Deng",
      "Xiang Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Luo_Differentially_Private_Video_Activity_Recognition_WACV_2024_paper.html": {
    "title": "Differentially Private Video Activity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zelun Luo",
      "Yuliang Zou",
      "Yijin Yang",
      "Zane Durante",
      "De-An Huang",
      "Zhiding Yu",
      "Chaowei Xiao",
      "Li Fei-Fei",
      "Animashree Anandkumar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gebauer_Towards_a_Dynamic_Vision_Sensor-Based_Insect_Camera_Trap_WACV_2024_paper.html": {
    "title": "Towards a Dynamic Vision Sensor-Based Insect Camera Trap",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eike Gebauer",
      "Sebastian Thiele",
      "Pierre Ouvrard",
      "Adrien Sicard",
      "Benjamin Risse"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chang_FLORA_Fine-Grained_Low-Rank_Architecture_Search_for_Vision_Transformer_WACV_2024_paper.html": {
    "title": "FLORA: Fine-Grained Low-Rank Architecture Search for Vision Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi-Chih Chang",
      "Yuan-Yao Sung",
      "Shixing Yu",
      "Ning-Chi Huang",
      "Diana Marculescu",
      "Kai-Chiang Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_Latent-Guided_Exemplar-Based_Image_Re-Colorization_WACV_2024_paper.html": {
    "title": "Latent-Guided Exemplar-Based Image Re-Colorization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Yang",
      "Ning Xu",
      "Yifei Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fang_Data_Augmentation_for_Object_Detection_via_Controllable_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Data Augmentation for Object Detection via Controllable Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Fang",
      "Boran Han",
      "Shuai Zhang",
      "Su Zhou",
      "Cuixiong Hu",
      "Wen-Ming Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Almalki_Self-Supervised_Learning_With_Masked_Autoencoders_for_Teeth_Segmentation_From_Intra-Oral_WACV_2024_paper.html": {
    "title": "Self-Supervised Learning With Masked Autoencoders for Teeth Segmentation From Intra-Oral 3D Scans",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amani Almalki",
      "Longin Jan Latecki"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mun_Small_Objects_Matters_in_Weakly-Supervised_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Small Objects Matters in Weakly-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheolhyun Mun",
      "Sanghuk Lee",
      "Youngjung Uh",
      "Junsuk Choe",
      "Hyeran Byun"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rashwan_MaskConver_Revisiting_Pure_Convolution_Model_for_Panoptic_Segmentation_WACV_2024_paper.html": {
    "title": "MaskConver: Revisiting Pure Convolution Model for Panoptic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdullah Rashwan",
      "Jiageng Zhang",
      "Ali Taalimi",
      "Fan Yang",
      "Xingyi Zhou",
      "Chaochao Yan",
      "Liang-Chieh Chen",
      "Yeqing Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Borer_From_Chaos_to_Calibration_A_Geometric_Mutual_Information_Approach_To_WACV_2024_paper.html": {
    "title": "From Chaos to Calibration: A Geometric Mutual Information Approach To Target-Free Camera LiDAR Extrinsic Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jack Borer",
      "Jeremy Tschirner",
      "Florian Ölsner",
      "Stefan Milz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Peng_PHG-Net_Persistent_Homology_Guided_Medical_Image_Classification_WACV_2024_paper.html": {
    "title": "PHG-Net: Persistent Homology Guided Medical Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaopeng Peng",
      "Hongxiao Wang",
      "Milan Sonka",
      "Danny Z. Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chin_Masking_Improves_Contrastive_Self-Supervised_Learning_for_ConvNets_and_Saliency_Tells_WACV_2024_paper.html": {
    "title": "Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi-Yi Chin",
      "Chieh-Ming Jiang",
      "Ching-Chun Huang",
      "Pin-Yu Chen",
      "Wei-Chen Chiu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zavrtanik_Cheating_Depth_Enhancing_3D_Surface_Anomaly_Detection_via_Depth_Simulation_WACV_2024_paper.html": {
    "title": "Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth Simulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vitjan Zavrtanik",
      "Matej Kristan",
      "Danijel Skočaj"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hirsch_CLID_Controlled-Length_Image_Descriptions_With_Limited_Data_WACV_2024_paper.html": {
    "title": "CLID: Controlled-Length Image Descriptions With Limited Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elad Hirsch",
      "Ayellet Tal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Steering_Prototypes_With_Prompt-Tuning_for_Rehearsal-Free_Continual_Learning_WACV_2024_paper.html": {
    "title": "Steering Prototypes With Prompt-Tuning for Rehearsal-Free Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuowei Li",
      "Long Zhao",
      "Zizhao Zhang",
      "Han Zhang",
      "Di Liu",
      "Ting Liu",
      "Dimitris N. Metaxas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lyou_Modality-Aware_Representation_Learning_for_Zero-Shot_Sketch-Based_Image_Retrieval_WACV_2024_paper.html": {
    "title": "Modality-Aware Representation Learning for Zero-Shot Sketch-Based Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunyi Lyou",
      "Doyeon Lee",
      "Jooeun Kim",
      "Joonseok Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yellin_Concurrent_Band_Selection_and_Traversability_Estimation_From_Long-Wave_Hyperspectral_Imagery_WACV_2024_paper.html": {
    "title": "Concurrent Band Selection and Traversability Estimation From Long-Wave Hyperspectral Imagery in Off-Road Settings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florence Yellin",
      "Scott McCloskey",
      "Cole Hill",
      "Eric Smith",
      "Brian Clipp"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Token_Fusion_Bridging_the_Gap_Between_Token_Pruning_and_Token_WACV_2024_paper.html": {
    "title": "Token Fusion: Bridging the Gap Between Token Pruning and Token Merging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minchul Kim",
      "Shangqian Gao",
      "Yen-Chang Hsu",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Global_Occlusion-Aware_Transformer_for_Robust_Stereo_Matching_WACV_2024_paper.html": {
    "title": "Global Occlusion-Aware Transformer for Robust Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihua Liu",
      "Yizhou Li",
      "Masatoshi Okutomi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Koch_SGRec3D_Self-Supervised_3D_Scene_Graph_Learning_via_Object-Level_Scene_Reconstruction_WACV_2024_paper.html": {
    "title": "SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sebastian Koch",
      "Pedro Hermosilla",
      "Narunas Vaskevicius",
      "Mirco Colosi",
      "Timo Ropinski"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ding_Estimating_Fog_Parameters_From_an_Image_Sequence_Using_Non-Linear_Optimisation_WACV_2024_paper.html": {
    "title": "Estimating Fog Parameters From an Image Sequence Using Non-Linear Optimisation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yining Ding",
      "Andrew M. Wallace",
      "Sen Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Phan_Fast_and_Interpretable_Face_Identification_for_Out-of-Distribution_Data_Using_Vision_WACV_2024_paper.html": {
    "title": "Fast and Interpretable Face Identification for Out-of-Distribution Data Using Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Phan",
      "Cindy X. Le",
      "Vu Le",
      "Yihui He",
      "Anh “Totti” Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Buettner_Investigating_the_Role_of_Attribute_Context_in_Vision-Language_Models_for_WACV_2024_paper.html": {
    "title": "Investigating the Role of Attribute Context in Vision-Language Models for Object Recognition and Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyle Buettner",
      "Adriana Kovashka"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cohen_Membership_Inference_Attack_Using_Self_Influence_Functions_WACV_2024_paper.html": {
    "title": "Membership Inference Attack Using Self Influence Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gilad Cohen",
      "Raja Giryes"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Eloul_Mixing_Gradients_in_Neural_Networks_as_a_Strategy_To_Enhance_WACV_2024_paper.html": {
    "title": "Mixing Gradients in Neural Networks as a Strategy To Enhance Privacy in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaltiel Eloul",
      "Fran Silavong",
      "Sanket Kamthe",
      "Antonios Georgiadis",
      "Sean J. Moran"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Leon-Alcazar_Learning_to_Read_Analog_Gauges_from_Synthetic_Data_WACV_2024_paper.html": {
    "title": "Learning to Read Analog Gauges from Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juan Leon-Alcazar",
      "Yazeed Alnumay",
      "Cheng Zheng",
      "Hassane Trigui",
      "Sahejad Patel",
      "Bernard Ghanem"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Djilali_Learning_Saliency_From_Fixations_WACV_2024_paper.html": {
    "title": "Learning Saliency From Fixations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasser Abdelaziz Dahou Djilali",
      "Kevin McGuinness",
      "Noel O’Connor"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dadashzadeh_PECoP_Parameter_Efficient_Continual_Pretraining_for_Action_Quality_Assessment_WACV_2024_paper.html": {
    "title": "PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhossein Dadashzadeh",
      "Shuchao Duan",
      "Alan Whone",
      "Majid Mirmehdi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Suwala_Face_Identity-Aware_Disentanglement_in_StyleGAN_WACV_2024_paper.html": {
    "title": "Face Identity-Aware Disentanglement in StyleGAN",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrian Suwała",
      "Bartosz Wójcik",
      "Magdalena Proszewska",
      "Jacek Tabor",
      "Przemysław Spurek",
      "Marek Śmieja"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_A_Robust_Diffusion_Modeling_Framework_for_Radar_Camera_3D_Object_WACV_2024_paper.html": {
    "title": "A Robust Diffusion Modeling Framework for Radar Camera 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizhang Wu",
      "Yunzhe Wu",
      "Xiaoquan Wang",
      "Yuanzhu Gan",
      "Jian Pu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Franchi_InfraParis_A_Multi-Modal_and_Multi-Task_Autonomous_Driving_Dataset_WACV_2024_paper.html": {
    "title": "InfraParis: A Multi-Modal and Multi-Task Autonomous Driving Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gianni Franchi",
      "Marwane Hariat",
      "Xuanlong Yu",
      "Nacim Belkhir",
      "Antoine Manzanera",
      "David Filliat"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ye_LAVSS_Location-Guided_Audio-Visual_Spatial_Audio_Separation_WACV_2024_paper.html": {
    "title": "LAVSS: Location-Guided Audio-Visual Spatial Audio Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Ye",
      "Wenming Yang",
      "Yapeng Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_PIDiffu_Pixel-Aligned_Diffusion_Model_for_High-Fidelity_Clothed_Human_Reconstruction_WACV_2024_paper.html": {
    "title": "PIDiffu: Pixel-Aligned Diffusion Model for High-Fidelity Clothed Human Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jungeun Lee",
      "Sanghun Kim",
      "Hansol Lee",
      "Tserendorj Adiya",
      "Hwasup Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tang_Kaizen_Practical_Self-Supervised_Continual_Learning_With_Continual_Fine-Tuning_WACV_2024_paper.html": {
    "title": "Kaizen: Practical Self-Supervised Continual Learning With Continual Fine-Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi Ian Tang",
      "Lorena Qendro",
      "Dimitris Spathis",
      "Fahim Kawsar",
      "Cecilia Mascolo",
      "Akhil Mathur"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lu_SBCFormer_Lightweight_Network_Capable_of_Full-Size_ImageNet_Classification_at_1_WACV_2024_paper.html": {
    "title": "SBCFormer: Lightweight Network Capable of Full-Size ImageNet Classification at 1 FPS on Single Board Computers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyong Lu",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Meronen_Fixing_Overconfidence_in_Dynamic_Neural_Networks_WACV_2024_paper.html": {
    "title": "Fixing Overconfidence in Dynamic Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lassi Meronen",
      "Martin Trapp",
      "Andrea Pilzer",
      "Le Yang",
      "Arno Solin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ramachandra_Multispectral_Imaging_for_Differential_Face_Morphing_Attack_Detection_A_Preliminary_WACV_2024_paper.html": {
    "title": "Multispectral Imaging for Differential Face Morphing Attack Detection: A Preliminary Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raghavendra Ramachandra",
      "Sushma Venkatesh",
      "Naser Damer",
      "Narayan Vetrekar",
      "R. S. Gad"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Singh_Learning_Robust_Deep_Visual_Representations_From_EEG_Brain_Recordings_WACV_2024_paper.html": {
    "title": "Learning Robust Deep Visual Representations From EEG Brain Recordings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prajwal Singh",
      "Dwip Dalal",
      "Gautam Vashishtha",
      "Krishna Miyapuram",
      "Shanmuganathan Raman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cao_Spiking_Denoising_Diffusion_Probabilistic_Models_WACV_2024_paper.html": {
    "title": "Spiking Denoising Diffusion Probabilistic Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahang Cao",
      "Ziqing Wang",
      "Hanzhong Guo",
      "Hao Cheng",
      "Qiang Zhang",
      "Renjing Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Petit_An_Analysis_of_Initial_Training_Strategies_for_Exemplar-Free_Class-Incremental_Learning_WACV_2024_paper.html": {
    "title": "An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Grégoire Petit",
      "Michaël Soumm",
      "Eva Feillet",
      "Adrian Popescu",
      "Bertrand Delezoide",
      "David Picard",
      "Céline Hudelot"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Malnick_Taming_Normalizing_Flows_WACV_2024_paper.html": {
    "title": "Taming Normalizing Flows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shimon Malnick",
      "Shai Avidan",
      "Ohad Fried"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hwang_Booster-SHOT_Boosting_Stacked_Homography_Transformations_for_Multiview_Pedestrian_Detection_With_WACV_2024_paper.html": {
    "title": "Booster-SHOT: Boosting Stacked Homography Transformations for Multiview Pedestrian Detection With Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinwoo Hwang",
      "Philipp Benz",
      "Pete Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Corley_ZRG_A_Dataset_for_Multimodal_3D_Residential_Rooftop_Understanding_WACV_2024_paper.html": {
    "title": "ZRG: A Dataset for Multimodal 3D Residential Rooftop Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Isaac Corley",
      "Jonathan Lwowski",
      "Peyman Najafirad"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Azad_Beyond_Self-Attention_Deformable_Large_Kernel_Attention_for_Medical_Image_Segmentation_WACV_2024_paper.html": {
    "title": "Beyond Self-Attention: Deformable Large Kernel Attention for Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reza Azad",
      "Leon Niggemeier",
      "Michael Hüttemann",
      "Amirhossein Kazerouni",
      "Ehsan Khodapanah Aghdam",
      "Yury Velichko",
      "Ulas Bagci",
      "Dorit Merhof"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Seifi_OOD_Aware_Supervised_Contrastive_Learning_WACV_2024_paper.html": {
    "title": "OOD Aware Supervised Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soroush Seifi",
      "Daniel Olmeda Reino",
      "Nikolay Chumerin",
      "Rahaf Aljundi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Meta-Learned_Kernel_for_Blind_Super-Resolution_Kernel_Estimation_WACV_2024_paper.html": {
    "title": "Meta-Learned Kernel for Blind Super-Resolution Kernel Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Royson Lee",
      "Rui Li",
      "Stylianos Venieris",
      "Timothy Hospedales",
      "Ferenc Huszár",
      "Nicholas D. Lane"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Almansoori_DDAM-PS_Diligent_Domain_Adaptive_Mixer_for_Person_Search_WACV_2024_paper.html": {
    "title": "DDAM-PS: Diligent Domain Adaptive Mixer for Person Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Khaleed Almansoori",
      "Mustansar Fiaz",
      "Hisham Cholakkal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bleidt_ArtQuest_Countering_Hidden_Language_Biases_in_ArtVQA_WACV_2024_paper.html": {
    "title": "ArtQuest: Countering Hidden Language Biases in ArtVQA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tibor Bleidt",
      "Sedigheh Eslami",
      "Gerard de Melo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gorlo_ISAR_A_Benchmark_for_Single-_and_Few-Shot_Object_Instance_Segmentation_WACV_2024_paper.html": {
    "title": "ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Gorlo",
      "Kenneth Blomqvist",
      "Francesco Milano",
      "Roland Siegwart"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kudale_Textron_Weakly_Supervised_Multilingual_Text_Detection_Through_Data_Programming_WACV_2024_paper.html": {
    "title": "Textron: Weakly Supervised Multilingual Text Detection Through Data Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dhruv Kudale",
      "Badri Vishal Kasuba",
      "Venkatapathy Subramanian",
      "Parag Chaudhuri",
      "Ganesh Ramakrishnan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Sharp-NeRF_Grid-Based_Fast_Deblurring_Neural_Radiance_Fields_Using_Sharpness_Prior_WACV_2024_paper.html": {
    "title": "Sharp-NeRF: Grid-Based Fast Deblurring Neural Radiance Fields Using Sharpness Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Byeonghyeon Lee",
      "Howoong Lee",
      "Usman Ali",
      "Eunbyung Park"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhou_4K-Resolution_Photo_Exposure_Correction_at_125_FPS_With_8K_Parameters_WACV_2024_paper.html": {
    "title": "4K-Resolution Photo Exposure Correction at 125 FPS With ~8K Parameters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijie Zhou",
      "Chao Li",
      "Jin Liang",
      "Tianyi Xu",
      "Xin Liu",
      "Jun Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Medina_Context-Based_Interpretable_Spatio-Temporal_Graph_Convolutional_Network_for_Human_Motion_Forecasting_WACV_2024_paper.html": {
    "title": "Context-Based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Edgar Medina",
      "Leyong Loh",
      "Namrata Gurung",
      "Kyung Hun Oh",
      "Niels Heller"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zheng_TPSeNCE_Towards_Artifact-Free_Realistic_Rain_Generation_for_Deraining_and_Object_WACV_2024_paper.html": {
    "title": "TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shen Zheng",
      "Changjie Lu",
      "Srinivasa G. Narasimhan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_Robust_Category-Level_3D_Pose_Estimation_From_Diffusion-Enhanced_Synthetic_Data_WACV_2024_paper.html": {
    "title": "Robust Category-Level 3D Pose Estimation From Diffusion-Enhanced Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Yang",
      "Wufei Ma",
      "Angtian Wang",
      "Xiaoding Yuan",
      "Alan Yuille",
      "Adam Kortylewski"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rad_Vision_Transformer_for_Multispectral_Satellite_Imagery_Advancing_Landcover_Classification_WACV_2024_paper.html": {
    "title": "Vision Transformer for Multispectral Satellite Imagery: Advancing Landcover Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryan Rad"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lau_ENTED_Enhanced_Neural_Texture_Extraction_and_Distribution_for_Reference-Based_Blind_WACV_2024_paper.html": {
    "title": "ENTED: Enhanced Neural Texture Extraction and Distribution for Reference-Based Blind Face Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuen-Fui Lau",
      "Tianjia Zhang",
      "Zhefan Rao",
      "Qifeng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_A_Sequential_Learning-Based_Approach_for_Monocular_Human_Performance_Capture_WACV_2024_paper.html": {
    "title": "A Sequential Learning-Based Approach for Monocular Human Performance Capture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianchun Chen",
      "Jayakorn Vongkulbhisal",
      "Fernando De la Torre Frade"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_VCISR_Blind_Single_Image_Super-Resolution_With_Video_Compression_Synthetic_Data_WACV_2024_paper.html": {
    "title": "VCISR: Blind Single Image Super-Resolution With Video Compression Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyang Wang",
      "Bowen Liu",
      "Shiyu Liu",
      "Fengyu Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pan_Synthesizing_Coherent_Story_With_Auto-Regressive_Latent_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Synthesizing Coherent Story With Auto-Regressive Latent Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xichen Pan",
      "Pengda Qin",
      "Yuhong Li",
      "Hui Xue",
      "Wenhu Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Text-to-Image_Editing_by_Image_Information_Removal_WACV_2024_paper.html": {
    "title": "Text-to-Image Editing by Image Information Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongping Zhang",
      "Jian Zheng",
      "Zhiyuan Fang",
      "Bryan A. Plummer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Self-Annotated_3D_Geometric_Learning_for_Smeared_Points_Removal_WACV_2024_paper.html": {
    "title": "Self-Annotated 3D Geometric Learning for Smeared Points Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miaowei Wang",
      "Daniel Morris"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gurbuz_Deep_Metric_Learning_With_Chance_Constraints_WACV_2024_paper.html": {
    "title": "Deep Metric Learning With Chance Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeti Z. Gürbüz",
      "Oğul Can",
      "Aydin Alatan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Parslov_CrashCar101_Procedural_Generation_for_Damage_Assessment_WACV_2024_paper.html": {
    "title": "CrashCar101: Procedural Generation for Damage Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jens Parslov",
      "Erik Riise",
      "Dim P. Papadopoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Reddy_Towards_Domain-Aware_Knowledge_Distillation_for_Continual_Model_Generalization_WACV_2024_paper.html": {
    "title": "Towards Domain-Aware Knowledge Distillation for Continual Model Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikhil Reddy",
      "Mahsa Baktashmotlagh",
      "Chetan Arora"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_SCoRD_Subject-Conditional_Relation_Detection_With_Text-Augmented_Data_WACV_2024_paper.html": {
    "title": "SCoRD: Subject-Conditional Relation Detection With Text-Augmented Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyan Yang",
      "Kushal Kafle",
      "Zhe Lin",
      "Scott Cohen",
      "Zhihong Ding",
      "Vicente Ordonez"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_THInImg_Cross-Modal_Steganography_for_Presenting_Talking_Heads_in_Images_WACV_2024_paper.html": {
    "title": "THInImg: Cross-Modal Steganography for Presenting Talking Heads in Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Zhao",
      "Hongxuan Li",
      "Xuefei Ning",
      "Xinru Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ahmad_Causal_Analysis_for_Robust_Interpretability_of_Neural_Networks_WACV_2024_paper.html": {
    "title": "Causal Analysis for Robust Interpretability of Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ola Ahmad",
      "Nicolas Béreux",
      "Loïc Baret",
      "Vahid Hashemi",
      "Freddy Lecue"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ashraf_TransFed_A_Way_To_Epitomize_Focal_Modulation_Using_Transformer-Based_Federated_WACV_2024_paper.html": {
    "title": "TransFed: A Way To Epitomize Focal Modulation Using Transformer-Based Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tajamul Ashraf",
      "Fuzayil Bin Afzal Mir",
      "Iqra Altaf Gillani"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hsiao_Natural_Light_Can_Also_Be_Dangerous_Traffic_Sign_Misinterpretation_Under_WACV_2024_paper.html": {
    "title": "Natural Light Can Also Be Dangerous: Traffic Sign Misinterpretation Under Adversarial Natural Light Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Teng-Fang Hsiao",
      "Bo-Lun Huang",
      "Zi-Xiang Ni",
      "Yan-Ting Lin",
      "Hong-Han Shuai",
      "Yung-Hui Li",
      "Wen-Huang Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shyam_PAIR_Perception_Aided_Image_Restoration_for_Natural_Driving_Conditions_WACV_2024_paper.html": {
    "title": "PAIR: Perception Aided Image Restoration for Natural Driving Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pranjay Shyam",
      "HyunJin Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kohler_RecycleNet_Latent_Feature_Recycling_Leads_to_Iterative_Decision_Refinement_WACV_2024_paper.html": {
    "title": "RecycleNet: Latent Feature Recycling Leads to Iterative Decision Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gregor Köhler",
      "Tassilo Wald",
      "Constantin Ulrich",
      "David Zimmerer",
      "Paul F. Jäger",
      "Jörg K.H. Franke",
      "Simon Kohl",
      "Fabian Isensee",
      "Klaus H. Maier-Hein"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Khan_CamoFocus_Enhancing_Camouflage_Object_Detection_With_Split-Feature_Focal_Modulation_and_WACV_2024_paper.html": {
    "title": "CamoFocus: Enhancing Camouflage Object Detection With Split-Feature Focal Modulation and Context Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abbas Khan",
      "Mustaqeem Khan",
      "Wail Gueaieb",
      "Abdulmotaleb El Saddik",
      "Giulia De Masi",
      "Fakhri Karray"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Noguchi_Scene_Text_Image_Super-Resolution_Based_on_Text-Conditional_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Scene Text Image Super-Resolution Based on Text-Conditional Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chihiro Noguchi",
      "Shun Fukuda",
      "Masao Yamanaka"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pal_Domain_Adaptive_3D_Shape_Retrieval_From_Monocular_Images_WACV_2024_paper.html": {
    "title": "Domain Adaptive 3D Shape Retrieval From Monocular Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harsh Pal",
      "Ritwik Khandelwal",
      "Shivam Pande",
      "Biplab Banerjee",
      "Srikrishna Karanam"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Learning_Quality_Labels_for_Robust_Image_Classification_WACV_2024_paper.html": {
    "title": "Learning Quality Labels for Robust Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaosong Wang",
      "Ziyue Xu",
      "Dong Yang",
      "Leo Tam",
      "Holger Roth",
      "Daguang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chang_LibreFace_An_Open-Source_Toolkit_for_Deep_Facial_Expression_Analysis_WACV_2024_paper.html": {
    "title": "LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Chang",
      "Yufeng Yin",
      "Zongjian Li",
      "Minh Tran",
      "Mohammad Soleymani"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_SCUNet_Swin-UNet_and_CNN_Bottleneck_Hybrid_Architecture_With_Multi-Fusion_Dense_WACV_2024_paper.html": {
    "title": "SCUNet++: Swin-UNet and CNN Bottleneck Hybrid Architecture With Multi-Fusion Dense Skip Connection for Pulmonary Embolism CT Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Chen",
      "Binfeng Zou",
      "Zhaoxin Guo",
      "Yiyu Huang",
      "Yifan Huang",
      "Feiwei Qin",
      "Qinhai Li",
      "Changmiao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Vieira_e_Silva_Attention_Modules_Improve_Image-Level_Anomaly_Detection_for_Industrial_Inspection_A_WACV_2024_paper.html": {
    "title": "Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "André Luiz Vieira e Silva",
      "Francisco Simões",
      "Danny Kowerko",
      "Tobias Schlosser",
      "Felipe Battisti",
      "Veronica Teichrieb"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Matsumoto_Indoor_Visual_Localization_Using_Point_and_Line_Correspondences_in_Dense_WACV_2024_paper.html": {
    "title": "Indoor Visual Localization Using Point and Line Correspondences in Dense Colored Point Cloud",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuya Matsumoto",
      "Gaku Nakano",
      "Kazumine Ogura"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Teigen_RGB-D_Mapping_and_Tracking_in_a_Plenoxel_Radiance_Field_WACV_2024_paper.html": {
    "title": "RGB-D Mapping and Tracking in a Plenoxel Radiance Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas L. Teigen",
      "Yeonsoo Park",
      "Annette Stahl",
      "Rudolf Mester"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ganesh_An_Empirical_Investigation_Into_Benchmarking_Model_Multiplicity_for_Trustworthy_Machine_WACV_2024_paper.html": {
    "title": "An Empirical Investigation Into Benchmarking Model Multiplicity for Trustworthy Machine Learning: A Case Study on Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prakhar Ganesh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Carmichael_Pixel-Grounded_Prototypical_Part_Networks_WACV_2024_paper.html": {
    "title": "Pixel-Grounded Prototypical Part Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zachariah Carmichael",
      "Suhas Lohit",
      "Anoop Cherian",
      "Michael J. Jones",
      "Walter J. Scheirer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_LatentDR_Improving_Model_Generalization_Through_Sample-Aware_Latent_Degradation_and_Restoration_WACV_2024_paper.html": {
    "title": "LatentDR: Improving Model Generalization Through Sample-Aware Latent Degradation and Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ran Liu",
      "Sahil Khose",
      "Jingyun Xiao",
      "Lakshmi Sathidevi",
      "Keerthan Ramnath",
      "Zsolt Kira",
      "Eva L. Dyer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rahman_G-CASCADE_Efficient_Cascaded_Graph_Convolutional_Decoding_for_2D_Medical_Image_WACV_2024_paper.html": {
    "title": "G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mostafijur Rahman",
      "Radu Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Naumann_TAMPAR_Visual_Tampering_Detection_for_Parcel_Logistics_in_Postal_Supply_WACV_2024_paper.html": {
    "title": "TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Naumann",
      "Felix Hertlein",
      "Laura Dörr",
      "Kai Furmans"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_PGVT_Pose-Guided_Video_Transformer_for_Fine-Grained_Action_Recognition_WACV_2024_paper.html": {
    "title": "PGVT: Pose-Guided Video Transformer for Fine-Grained Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haosong Zhang",
      "Mei Chee Leong",
      "Liyuan Li",
      "Weisi Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Black_Multi-View_Classification_Using_Hybrid_Fusion_and_Mutual_Distillation_WACV_2024_paper.html": {
    "title": "Multi-View Classification Using Hybrid Fusion and Mutual Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Black",
      "Richard Souvenir"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Real-Time_User-Guided_Adaptive_Colorization_With_Vision_Transformer_WACV_2024_paper.html": {
    "title": "Real-Time User-Guided Adaptive Colorization With Vision Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gwanghan Lee",
      "Saebyeol Shin",
      "Taeyoung Na",
      "Simon S. Woo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Limanta_CAMOT_Camera_Angle-Aware_Multi-Object_Tracking_WACV_2024_paper.html": {
    "title": "CAMOT: Camera Angle-Aware Multi-Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Limanta",
      "Kuniaki Uto",
      "Koichi Shinoda"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shiota_Egocentric_Action_Recognition_by_Capturing_Hand-Object_Contact_and_Object_State_WACV_2024_paper.html": {
    "title": "Egocentric Action Recognition by Capturing Hand-Object Contact and Object State",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsukasa Shiota",
      "Motohiro Takagi",
      "Kaori Kumagai",
      "Hitoshi Seshimo",
      "Yushi Aono"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Schoonbeek_IndustReal_A_Dataset_for_Procedure_Step_Recognition_Handling_Execution_Errors_WACV_2024_paper.html": {
    "title": "IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim J. Schoonbeek",
      "Tim Houben",
      "Hans Onvlee",
      "Peter H.N. de With",
      "Fons van der Sommen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Suresh_FastCLIPstyler_Optimisation-Free_Text-Based_Image_Style_Transfer_Using_Style_Representations_WACV_2024_paper.html": {
    "title": "FastCLIPstyler: Optimisation-Free Text-Based Image Style Transfer Using Style Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ananda Padhmanabhan Suresh",
      "Sanjana Jain",
      "Pavit Noinongyao",
      "Ankush Ganguly",
      "Ukrit Watchareeruetai",
      "Aubin Samacoits"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shin_Video-kMaX_A_Simple_Unified_Approach_for_Online_and_Near-Online_Video_WACV_2024_paper.html": {
    "title": "Video-kMaX: A Simple Unified Approach for Online and Near-Online Video Panoptic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inkyu Shin",
      "Dahun Kim",
      "Qihang Yu",
      "Jun Xie",
      "Hong-Seok Kim",
      "Bradley Green",
      "In So Kweon",
      "Kuk-Jin Yoon",
      "Liang-Chieh Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Aketi_Cross-Feature_Contrastive_Loss_for_Decentralized_Deep_Learning_on_Heterogeneous_Data_WACV_2024_paper.html": {
    "title": "Cross-Feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Aparna Aketi",
      "Kaushik Roy"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Raychaudhuri_MOPA_Modular_Object_Navigation_With_PointGoal_Agents_WACV_2024_paper.html": {
    "title": "MOPA: Modular Object Navigation With PointGoal Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sonia Raychaudhuri",
      "Tommaso Campari",
      "Unnat Jain",
      "Manolis Savva",
      "Angel X. Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Grieggs_The_Paleographers_Eye_ex_machina_Using_Computer_Vision_To_Assist_WACV_2024_paper.html": {
    "title": "The Paleographer's Eye ex machina: Using Computer Vision To Assist Humanists in Scribal Hand Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Grieggs",
      "C. E. M. Henderson",
      "Sebastian Sobecki",
      "Alexandra Gillespie",
      "Walter Scheirer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zunair_Learning_To_Recognize_Occluded_and_Small_Objects_With_Partial_Inputs_WACV_2024_paper.html": {
    "title": "Learning To Recognize Occluded and Small Objects With Partial Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hasib Zunair",
      "A. Ben Hamza"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_BALF_Simple_and_Efficient_Blur_Aware_Local_Feature_Detector_WACV_2024_paper.html": {
    "title": "BALF: Simple and Efficient Blur Aware Local Feature Detector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenjun Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_RS2G_Data-Driven_Scene-Graph_Extraction_and_Embedding_for_Robust_Autonomous_Perception_WACV_2024_paper.html": {
    "title": "RS2G: Data-Driven Scene-Graph Extraction and Embedding for Robust Autonomous Perception and Scenario Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyao Wang",
      "Arnav Vaibhav Malawade",
      "Junhong Zhou",
      "Shih-Yuan Yu",
      "Mohammad Abdullah Al Faruque"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Leveraging_the_Power_of_Data_Augmentation_for_Transformer-Based_Tracking_WACV_2024_paper.html": {
    "title": "Leveraging the Power of Data Augmentation for Transformer-Based Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Zhao",
      "Johan Edstedt",
      "Michael Felsberg",
      "Dong Wang",
      "Huchuan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shen_Med-DANet_V2_A_Flexible_Dynamic_Architecture_for_Efficient_Medical_Volumetric_WACV_2024_paper.html": {
    "title": "Med-DANet V2: A Flexible Dynamic Architecture for Efficient Medical Volumetric Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Shen",
      "Yifu Zhang",
      "Wenxuan Wang",
      "Chen Chen",
      "Jing Liu",
      "Shanshan Song",
      "Jiangyun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bamba_Partial_Binarization_of_Neural_Networks_for_Budget-Aware_Efficient_Learning_WACV_2024_paper.html": {
    "title": "Partial Binarization of Neural Networks for Budget-Aware Efficient Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Udbhav Bamba",
      "Neeraj Anand",
      "Saksham Aggarwal",
      "Dilip K. Prasad",
      "Deepak K. Gupta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Improving_the_Fairness_of_the_Min-Max_Game_in_GANs_Training_WACV_2024_paper.html": {
    "title": "Improving the Fairness of the Min-Max Game in GANs Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyu Zhang",
      "Yang Hua",
      "Hui Wang",
      "Seán McLoone"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yu_When_3D_Bounding-Box_Meets_SAM_Point_Cloud_Instance_Segmentation_With_WACV_2024_paper.html": {
    "title": "When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation With Weak-and-Noisy Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingtao Yu",
      "Heming Du",
      "Chen Liu",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gondal_Domain_Aligned_CLIP_for_Few-Shot_Classification_WACV_2024_paper.html": {
    "title": "Domain Aligned CLIP for Few-Shot Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Waleed Gondal",
      "Jochen Gast",
      "Inigo Alonso Ruiz",
      "Richard Droste",
      "Tommaso Macri",
      "Suren Kumar",
      "Luitpold Staudigl"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Van_Landeghem_Beyond_Document_Page_Classification_Design_Datasets_and_Challenges_WACV_2024_paper.html": {
    "title": "Beyond Document Page Classification: Design, Datasets, and Challenges",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jordy Van Landeghem",
      "Sanket Biswas",
      "Matthew Blaschko",
      "Marie-Francine Moens"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dubinski_Towards_More_Realistic_Membership_Inference_Attacks_on_Large_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Towards More Realistic Membership Inference Attacks on Large Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Dubiński",
      "Antoni Kowalczuk",
      "Stanisław Pawlak",
      "Przemyslaw Rokita",
      "Tomasz Trzciński",
      "Paweł Morawiecki"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cho_Slice_and_Conquer_A_Planar-to-3D_Framework_for_Efficient_Interactive_Segmentation_WACV_2024_paper.html": {
    "title": "Slice and Conquer: A Planar-to-3D Framework for Efficient Interactive Segmentation of Volumetric Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonwoo Cho",
      "Dongmin Choi",
      "Hyesu Lim",
      "Jinho Choi",
      "Saemee Choi",
      "Hyun-seok Min",
      "Sungbin Lim",
      "Jaegul Choo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Mitigate_Domain_Shift_by_Primary-Auxiliary_Objectives_Association_for_Generalizing_Person_WACV_2024_paper.html": {
    "title": "Mitigate Domain Shift by Primary-Auxiliary Objectives Association for Generalizing Person ReID",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qilei Li",
      "Shaogang Gong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Marsal_MonoProb_Self-Supervised_Monocular_Depth_Estimation_With_Interpretable_Uncertainty_WACV_2024_paper.html": {
    "title": "MonoProb: Self-Supervised Monocular Depth Estimation With Interpretable Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rémi Marsal",
      "Florian Chabot",
      "Angélique Loesch",
      "William Grolleau",
      "Hichem Sahbi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pham_LP-OVOD_Open-Vocabulary_Object_Detection_by_Linear_Probing_WACV_2024_paper.html": {
    "title": "LP-OVOD: Open-Vocabulary Object Detection by Linear Probing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chau Pham",
      "Truong Vu",
      "Khoi Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Beck_Beyond_Active_Learning_Leveraging_the_Full_Potential_of_Human_Interaction_WACV_2024_paper.html": {
    "title": "Beyond Active Learning: Leveraging the Full Potential of Human Interaction via Auto-Labeling, Human Correction, and Human Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Beck",
      "Krishnateja Killamsetty",
      "Suraj Kothawade",
      "Rishabh Iyer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Agnolucci_ARNIQA_Learning_Distortion_Manifold_for_Image_Quality_Assessment_WACV_2024_paper.html": {
    "title": "ARNIQA: Learning Distortion Manifold for Image Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Agnolucci",
      "Leonardo Galteri",
      "Marco Bertini",
      "Alberto Del Bimbo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ma_CVTHead_One-Shot_Controllable_Head_Avatar_With_Vertex-Feature_Transformer_WACV_2024_paper.html": {
    "title": "CVTHead: One-Shot Controllable Head Avatar With Vertex-Feature Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Ma",
      "Tong Zhang",
      "Shanlin Sun",
      "Xiangyi Yan",
      "Kun Han",
      "Xiaohui Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yenamandra_FIRe_Fast_Inverse_Rendering_Using_Directional_and_Signed_Distance_Functions_WACV_2024_paper.html": {
    "title": "FIRe: Fast Inverse Rendering Using Directional and Signed Distance Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Yenamandra",
      "Ayush Tewari",
      "Nan Yang",
      "Florian Bernard",
      "Christian Theobalt",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lin_Ego2HandsPose_A_Dataset_for_Egocentric_Two-Hand_3D_Global_Pose_Estimation_WACV_2024_paper.html": {
    "title": "Ego2HandsPose: A Dataset for Egocentric Two-Hand 3D Global Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanqing Lin",
      "Tony Martinez"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_Improving_Vision-and-Language_Reasoning_via_Spatial_Relations_Modeling_WACV_2024_paper.html": {
    "title": "Improving Vision-and-Language Reasoning via Spatial Relations Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Yang",
      "Rui Xu",
      "Ye Guo",
      "Peixiang Huang",
      "Yiru Chen",
      "Wenkui Ding",
      "Zhongyuan Wang",
      "Hong Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Greenwell_WATCH_Wide-Area_Terrestrial_Change_Hypercube_WACV_2024_paper.html": {
    "title": "WATCH: Wide-Area Terrestrial Change Hypercube",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Connor Greenwell",
      "Jon Crall",
      "Matthew Purri",
      "Kristin Dana",
      "Nathan Jacobs",
      "Armin Hadzic",
      "Scott Workman",
      "Matt Leotta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Detecting_Content_Segments_From_Online_Sports_Streaming_Events_Challenges_and_WACV_2024_paper.html": {
    "title": "Detecting Content Segments From Online Sports Streaming Events: Challenges and Solutions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongyi Liu",
      "Yarong Feng",
      "Shunyan Luo",
      "Yuan Ling",
      "Shujing Dong",
      "Shuyi Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shukla_Vikriti-ID_A_Novel_Approach_for_Real_Looking_Fingerprint_Data-Set_Generation_WACV_2024_paper.html": {
    "title": "Vikriti-ID: A Novel Approach for Real Looking Fingerprint Data-Set Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishabh Shukla",
      "Aditya Sinha",
      "Vansh Singh",
      "Harkeerat Kaur"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Berman_PETIT-GAN_Physically_Enhanced_Thermal_Image-Translating_Generative_Adversarial_Network_WACV_2024_paper.html": {
    "title": "PETIT-GAN: Physically Enhanced Thermal Image-Translating Generative Adversarial Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omri Berman",
      "Navot Oz",
      "David Mendlovic",
      "Nir Sochen",
      "Yafit Cohen",
      "Iftach Klapp"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Radhakrishnan_Design_Choices_for_Enhancing_Noisy_Student_Self-Training_WACV_2024_paper.html": {
    "title": "Design Choices for Enhancing Noisy Student Self-Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aswathnarayan Radhakrishnan",
      "Jim Davis",
      "Zachary Rabin",
      "Benjamin Lewis",
      "Matthew Scherreik",
      "Roman Ilin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shugaev_ArcGeo_Localizing_Limited_Field-of-View_Images_Using_Cross-View_Matching_WACV_2024_paper.html": {
    "title": "ArcGeo: Localizing Limited Field-of-View Images Using Cross-View Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxim Shugaev",
      "Ilya Semenov",
      "Kyle Ashley",
      "Michael Klaczynski",
      "Naresh Cuntoor",
      "Mun Wai Lee",
      "Nathan Jacobs"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yue_Understanding_Hyperbolic_Metric_Learning_Through_Hard_Negative_Sampling_WACV_2024_paper.html": {
    "title": "Understanding Hyperbolic Metric Learning Through Hard Negative Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Yue",
      "Fangzhou Lin",
      "Guanyi Mou",
      "Ziming Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chhikara_FIRE_Food_Image_to_REcipe_Generation_WACV_2024_paper.html": {
    "title": "FIRE: Food Image to REcipe Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prateek Chhikara",
      "Dhiraj Chaurasia",
      "Yifan Jiang",
      "Omkar Masur",
      "Filip Ilievski"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shen_DiffCLIP_Leveraging_Stable_Diffusion_for_Language_Grounded_3D_Classification_WACV_2024_paper.html": {
    "title": "DiffCLIP: Leveraging Stable Diffusion for Language Grounded 3D Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sitian Shen",
      "Zilin Zhu",
      "Linqian Fan",
      "Harry Zhang",
      "Xinxiao Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/De_Nardin_A_One-Shot_Learning_Approach_To_Document_Layout_Segmentation_of_Ancient_WACV_2024_paper.html": {
    "title": "A One-Shot Learning Approach To Document Layout Segmentation of Ancient Arabic Manuscripts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Axel De Nardin",
      "Silvia Zottin",
      "Claudio Piciarelli",
      "Emanuela Colombi",
      "Gian Luca Foresti"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gilg_Do_We_Still_Need_Non-Maximum_Suppression_Accurate_Confidence_Estimates_and_WACV_2024_paper.html": {
    "title": "Do We Still Need Non-Maximum Suppression? Accurate Confidence Estimates and Implicit Duplication Modeling With IoU-Aware Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes Gilg",
      "Torben Teepe",
      "Fabian Herzog",
      "Philipp Wolters",
      "Gerhard Rigoll"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Saad_On_the_Importance_of_Large_Objects_in_CNN_Based_Object_WACV_2024_paper.html": {
    "title": "On the Importance of Large Objects in CNN Based Object Detection Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Ben Saad",
      "Gabriele Facciolo",
      "Axel Davy"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Goto_Learning_Intra-Class_Multimodal_Distributions_With_Orthonormal_Matrices_WACV_2024_paper.html": {
    "title": "Learning Intra-Class Multimodal Distributions With Orthonormal Matrices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jumpei Goto",
      "Yohei Nakata",
      "Kiyofumi Abe",
      "Yasunori Ishii",
      "Takayoshi Yamashita"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Christensen_Assessing_Neural_Network_Robustness_via_Adversarial_Pivotal_Tuning_WACV_2024_paper.html": {
    "title": "Assessing Neural Network Robustness via Adversarial Pivotal Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Ebert Christensen",
      "Vésteinn Snæbjarnarson",
      "Andrea Dittadi",
      "Serge Belongie",
      "Sagie Benaim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shukla_Opinion_Unaware_Image_Quality_Assessment_via_Adversarial_Convolutional_Variational_Autoencoder_WACV_2024_paper.html": {
    "title": "Opinion Unaware Image Quality Assessment via Adversarial Convolutional Variational Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ankit Shukla",
      "Avinash Upadhyay",
      "Swati Bhugra",
      "Manoj Sharma"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Matsune_A_Geometry_Loss_Combination_for_3D_Human_Pose_Estimation_WACV_2024_paper.html": {
    "title": "A Geometry Loss Combination for 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ai Matsune",
      "Shichen Hu",
      "Guangquan Li",
      "Sihan Wen",
      "Xiantan Zhu",
      "Zhiming Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fukushi_Few-Shot_Generative_Model_for_Skeleton-Based_Human_Action_Synthesis_Using_Cross-Domain_WACV_2024_paper.html": {
    "title": "Few-Shot Generative Model for Skeleton-Based Human Action Synthesis Using Cross-Domain Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kenichiro Fukushi",
      "Yoshitaka Nozaki",
      "Kosuke Nishihara",
      "Kentaro Nakahara"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liang_Linking_Convolutional_Kernel_Size_to_Generalization_Bias_in_Face_Analysis_WACV_2024_paper.html": {
    "title": "Linking Convolutional Kernel Size to Generalization Bias in Face Analysis CNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Liang",
      "Josue Ortega Caro",
      "Vikram Maheshri",
      "Ankit B. Patel",
      "Guha Balakrishnan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yuan_Cross-Attention_Between_Satellite_and_Ground_Views_for_Enhanced_Fine-Grained_Robot_WACV_2024_paper.html": {
    "title": "Cross-Attention Between Satellite and Ground Views for Enhanced Fine-Grained Robot Geo-Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Yuan",
      "Frederic Maire",
      "Feras Dayoub"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Song_StyleGAN-Fusion_Diffusion_Guided_Domain_Adaptation_of_Image_Generators_WACV_2024_paper.html": {
    "title": "StyleGAN-Fusion: Diffusion Guided Domain Adaptation of Image Generators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunpeng Song",
      "Ligong Han",
      "Bingchen Liu",
      "Dimitris Metaxas",
      "Ahmed Elgammal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_TSP-Transformer_Task-Specific_Prompts_Boosted_Transformer_for_Holistic_Scene_Understanding_WACV_2024_paper.html": {
    "title": "TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Wang",
      "Jing Li",
      "Zibo Zhao",
      "Dongze Lian",
      "Binbin Huang",
      "Xiaomei Wang",
      "Zhengxin Li",
      "Shenghua Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Amosy_Late_to_the_Party_On-Demand_Unlabeled_Personalized_Federated_Learning_WACV_2024_paper.html": {
    "title": "Late to the Party? On-Demand Unlabeled Personalized Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ohad Amosy",
      "Gal Eyal",
      "Gal Chechik"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Batzner_EfficientAD_Accurate_Visual_Anomaly_Detection_at_Millisecond-Level_Latencies_WACV_2024_paper.html": {
    "title": "EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level Latencies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kilian Batzner",
      "Lars Heckler",
      "Rebecca König"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Naylor_Implicit_Neural_Representation_for_Change_Detection_WACV_2024_paper.html": {
    "title": "Implicit Neural Representation for Change Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Naylor",
      "Diego Di Carlo",
      "Arianna Traviglia",
      "Makoto Yamada",
      "Marco Fiorucci"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Maximum_Knowledge_Orthogonality_Reconstruction_With_Gradients_in_Federated_Learning_WACV_2024_paper.html": {
    "title": "Maximum Knowledge Orthogonality Reconstruction With Gradients in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Wang",
      "Senem Velipasalar",
      "M. Cenk Gursoy"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ragusa_ENIGMA-51_Towards_a_Fine-Grained_Understanding_of_Human_Behavior_in_Industrial_WACV_2024_paper.html": {
    "title": "ENIGMA-51: Towards a Fine-Grained Understanding of Human Behavior in Industrial Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Ragusa",
      "Rosario Leonardi",
      "Michele Mazzamuto",
      "Claudia Bonanno",
      "Rosario Scavo",
      "Antonino Furnari",
      "Giovanni Maria Farinella"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_HELA-VFA_A_Hellinger_Distance-Attention-Based_Feature_Aggregation_Network_for_Few-Shot_Classification_WACV_2024_paper.html": {
    "title": "HELA-VFA: A Hellinger Distance-Attention-Based Feature Aggregation Network for Few-Shot Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gao Yu Lee",
      "Tanmoy Dam",
      "Daniel Puiu Poenar",
      "Vu N. Duong",
      "Md Meftahul Ferdaus"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Abdelreheem_ScanEnts3D_Exploiting_Phrase-to-3D-Object_Correspondences_for_Improved_Visio-Linguistic_Models_in_3D_WACV_2024_paper.html": {
    "title": "ScanEnts3D: Exploiting Phrase-to-3D-Object Correspondences for Improved Visio-Linguistic Models in 3D Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Abdelreheem",
      "Kyle Olszewski",
      "Hsin-Ying Lee",
      "Peter Wonka",
      "Panos Achlioptas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Subramanya_A_Closer_Look_at_Robustness_of_Vision_Transformers_to_Backdoor_WACV_2024_paper.html": {
    "title": "A Closer Look at Robustness of Vision Transformers to Backdoor Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshayvarun Subramanya",
      "Soroush Abbasi Koohpayegani",
      "Aniruddha Saha",
      "Ajinkya Tejankar",
      "Hamed Pirsiavash"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Reich_Differentiable_JPEG_The_Devil_Is_in_the_Details_WACV_2024_paper.html": {
    "title": "Differentiable JPEG: The Devil Is in the Details",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christoph Reich",
      "Biplob Debnath",
      "Deep Patel",
      "Srimat Chakradhar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wysoczanska_CLIP-DIY_CLIP_Dense_Inference_Yields_Open-Vocabulary_Semantic_Segmentation_For-Free_WACV_2024_paper.html": {
    "title": "CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic Segmentation For-Free",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Monika Wysoczańska",
      "Michaël Ramamonjisoa",
      "Tomasz Trzciński",
      "Oriane Siméoni"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Choi_Dual_Domain_Diffusion_Guidance_for_3D_CBCT_Metal_Artifact_Reduction_WACV_2024_paper.html": {
    "title": "Dual Domain Diffusion Guidance for 3D CBCT Metal Artifact Reduction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongjin Choi",
      "Doeyoung Kwon",
      "Seung Jun Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/McGriff_Joint_3D_Shape_and_Motion_Estimation_From_Rolling_Shutter_Light-Field_WACV_2024_paper.html": {
    "title": "Joint 3D Shape and Motion Estimation From Rolling Shutter Light-Field Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hermès McGriff",
      "Renato Martins",
      "Nicolas Andreff",
      "Cédric Demonceaux"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Purohit_ConeQuest_A_Benchmark_for_Cone_Segmentation_on_Mars_WACV_2024_paper.html": {
    "title": "ConeQuest: A Benchmark for Cone Segmentation on Mars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mirali Purohit",
      "Jacob Adler",
      "Hannah Kerner"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Doshi_A_Multimodal_Benchmark_and_Improved_Architecture_for_Zero_Shot_Learning_WACV_2024_paper.html": {
    "title": "A Multimodal Benchmark and Improved Architecture for Zero Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keval Doshi",
      "Amanmeet Garg",
      "Burak Uzkent",
      "Xiaolong Wang",
      "Mohamed Omar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lopes_PlantPlotGAN_A_Physics-Informed_Generative_Adversarial_Network_for_Plant_Disease_Prediction_WACV_2024_paper.html": {
    "title": "PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felipe A. Lopes",
      "Vasit Sagan",
      "Flavio Esposito"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lin_Common_Diffusion_Noise_Schedules_and_Sample_Steps_Are_Flawed_WACV_2024_paper.html": {
    "title": "Common Diffusion Noise Schedules and Sample Steps Are Flawed",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanchuan Lin",
      "Bingchen Liu",
      "Jiashi Li",
      "Xiao Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Roy_Efficient_Expansion_and_Gradient_Based_Task_Inference_for_Replay_Free_WACV_2024_paper.html": {
    "title": "Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumya Roy",
      "Vinay Verma",
      "Deepak Gupta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_PolyMaX_General_Dense_Prediction_With_Mask_Transformer_WACV_2024_paper.html": {
    "title": "PolyMaX: General Dense Prediction With Mask Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Yang",
      "Liangzhe Yuan",
      "Kimberly Wilber",
      "Astuti Sharma",
      "Xiuye Gu",
      "Siyuan Qiao",
      "Stephanie Debats",
      "Huisheng Wang",
      "Hartwig Adam",
      "Mikhail Sirotenko",
      "Liang-Chieh Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Weiherer_Approximating_Intersections_and_Differences_Between_Linear_Statistical_Shape_Models_Using_WACV_2024_paper.html": {
    "title": "Approximating Intersections and Differences Between Linear Statistical Shape Models Using Markov Chain Monte Carlo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Weiherer",
      "Finn Klein",
      "Bernhard Egger"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shi_Few-Shot_Shape_Recognition_by_Learning_Deep_Shape-Aware_Features_WACV_2024_paper.html": {
    "title": "Few-Shot Shape Recognition by Learning Deep Shape-Aware Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenlong Shi",
      "Changsheng Lu",
      "Ming Shao",
      "Yinjie Zhang",
      "Siyu Xia",
      "Piotr Koniusz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kolbeinsson_Multi-Class_Segmentation_From_Aerial_Views_Using_Recursive_Noise_Diffusion_WACV_2024_paper.html": {
    "title": "Multi-Class Segmentation From Aerial Views Using Recursive Noise Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benedikt Kolbeinsson",
      "Krystian Mikolajczyk"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Aung_Enhancing_Multi-View_Pedestrian_Detection_Through_Generalized_3D_Feature_Pulling_WACV_2024_paper.html": {
    "title": "Enhancing Multi-View Pedestrian Detection Through Generalized 3D Feature Pulling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sithu Aung",
      "Haesol Park",
      "Hyungjoo Jung",
      "Junghyun Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fujii_Automated_Sperm_Assessment_Framework_and_Neural_Network_Specialized_for_Sperm_WACV_2024_paper.html": {
    "title": "Automated Sperm Assessment Framework and Neural Network Specialized for Sperm Video Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takuro Fujii",
      "Hayato Nakagawa",
      "Teppei Takeshima",
      "Yasushi Yumura",
      "Tomoki Hamagami"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shoeb_Have_We_Ever_Encountered_This_Before_Retrieving_Out-of-Distribution_Road_Obstacles_WACV_2024_paper.html": {
    "title": "Have We Ever Encountered This Before? Retrieving Out-of-Distribution Road Obstacles From Driving Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youssef Shoeb",
      "Robin Chan",
      "Gesina Schwalbe",
      "Azarm Nowzad",
      "Fatma Güney",
      "Hanno Gottschalk"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Polarimetric_PatchMatch_Multi-View_Stereo_WACV_2024_paper.html": {
    "title": "Polarimetric PatchMatch Multi-View Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyu Zhao",
      "Jumpei Oishi",
      "Yusuke Monno",
      "Masatoshi Okutomi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jonnarth_High-Fidelity_Pseudo-Labels_for_Boosting_Weakly-Supervised_Segmentation_WACV_2024_paper.html": {
    "title": "High-Fidelity Pseudo-Labels for Boosting Weakly-Supervised Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arvi Jonnarth",
      "Yushan Zhang",
      "Michael Felsberg"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yoon_Optical_Flow_Domain_Adaptation_via_Target_Style_Transfer_WACV_2024_paper.html": {
    "title": "Optical Flow Domain Adaptation via Target Style Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeongbeen Yoon",
      "Sanghyun Kim",
      "Suha Kwak",
      "Minsu Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Controlling_Character_Motions_Without_Observable_Driving_Source_WACV_2024_paper.html": {
    "title": "Controlling Character Motions Without Observable Driving Source",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyuan Li",
      "Bin Dai",
      "Ziyi Zhou",
      "Qi Yao",
      "Baoyuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Vellenga_Evaluation_of_Video_Masked_Autoencoders_Performance_and_Uncertainty_Estimations_for_WACV_2024_paper.html": {
    "title": "Evaluation of Video Masked Autoencoders' Performance and Uncertainty Estimations for Driver Action and Intention Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Koen Vellenga",
      "H. Joe Steinhauer",
      "Göran Falkman",
      "Tomas Björklund"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Elata_Nested_Diffusion_Processes_for_Anytime_Image_Generation_WACV_2024_paper.html": {
    "title": "Nested Diffusion Processes for Anytime Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Noam Elata",
      "Bahjat Kawar",
      "Tomer Michaeli",
      "Michael Elad"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Venkataraman_Can_You_Even_Tell_Left_From_Right_Presenting_a_New_WACV_2024_paper.html": {
    "title": "Can You Even Tell Left From Right? Presenting a New Challenge for VQA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Raam Venkataraman",
      "Rishi Sridhar Rao",
      "S. Balasubramanian",
      "R. Raghunatha Sarma",
      "Chandra Sekhar Vorugunti"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Unal_2D_Feature_Distillation_for_Weakly-_and_Semi-Supervised_3D_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ozan Unal",
      "Dengxin Dai",
      "Lukas Hoyer",
      "Yigit Baran Can",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Krispel_MAELi_Masked_Autoencoder_for_Large-Scale_LiDAR_Point_Clouds_WACV_2024_paper.html": {
    "title": "MAELi: Masked Autoencoder for Large-Scale LiDAR Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georg Krispel",
      "David Schinagl",
      "Christian Fruhwirth-Reisinger",
      "Horst Possegger",
      "Horst Bischof"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lai_Empowering_Unsupervised_Domain_Adaptation_With_Large-Scale_Pre-Trained_Vision-Language_Models_WACV_2024_paper.html": {
    "title": "Empowering Unsupervised Domain Adaptation With Large-Scale Pre-Trained Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengfeng Lai",
      "Haoping Bai",
      "Haotian Zhang",
      "Xianzhi Du",
      "Jiulong Shan",
      "Yinfei Yang",
      "Chen-Nee Chuah",
      "Meng Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_FreMIM_Fourier_Transform_Meets_Masked_Image_Modeling_for_Medical_Image_WACV_2024_paper.html": {
    "title": "FreMIM: Fourier Transform Meets Masked Image Modeling for Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Jing Wang",
      "Chen Chen",
      "Jianbo Jiao",
      "Yuanxiu Cai",
      "Shanshan Song",
      "Jiangyun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hisadome_Rotation-Constrained_Cross-View_Feature_Fusion_for_Multi-View_Appearance-Based_Gaze_Estimation_WACV_2024_paper.html": {
    "title": "Rotation-Constrained Cross-View Feature Fusion for Multi-View Appearance-Based Gaze Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yoichiro Hisadome",
      "Tianyi Wu",
      "Jiawei Qin",
      "Yusuke Sugano"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ranem_Continual_Atlas-Based_Segmentation_of_Prostate_MRI_WACV_2024_paper.html": {
    "title": "Continual Atlas-Based Segmentation of Prostate MRI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amin Ranem",
      "Camila González",
      "Daniel Pinto dos Santos",
      "Andreas M. Bucher",
      "Ahmed E. Othman",
      "Anirban Mukhopadhyay"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pepe_CGAPoseNetGCAN_A_Geometric_Clifford_Algebra_Network_for_Geometry-Aware_Camera_Pose_WACV_2024_paper.html": {
    "title": "CGAPoseNet+GCAN: A Geometric Clifford Algebra Network for Geometry-Aware Camera Pose Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alberto Pepe",
      "Joan Lasenby",
      "Sven Buchholz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Contextual_Affinity_Distillation_for_Image_Anomaly_Detection_WACV_2024_paper.html": {
    "title": "Contextual Affinity Distillation for Image Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Zhang",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tang_Semantic-Aware_Video_Representation_for_Few-Shot_Action_Recognition_WACV_2024_paper.html": {
    "title": "Semantic-Aware Video Representation for Few-Shot Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Tang",
      "Benjamín Béjar",
      "René Vidal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ilhan_Adaptive_Deep_Neural_Network_Inference_Optimization_With_EENet_WACV_2024_paper.html": {
    "title": "Adaptive Deep Neural Network Inference Optimization With EENet",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fatih Ilhan",
      "Ka-Ho Chow",
      "Sihao Hu",
      "Tiansheng Huang",
      "Selim Tekin",
      "Wenqi Wei",
      "Yanzhao Wu",
      "Myungjin Lee",
      "Ramana Kompella",
      "Hugo Latapie",
      "Gaowen Liu",
      "Ling Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_MIVC_Multiple_Instance_Visual_Component_for_Visual-Language_Models_WACV_2024_paper.html": {
    "title": "MIVC: Multiple Instance Visual Component for Visual-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyi Wu",
      "Qi Li",
      "Wenliang Zhong",
      "Junzhou Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hegde_Attentive_Prototypes_for_Source-Free_Unsupervised_Domain_Adaptive_3D_Object_Detection_WACV_2024_paper.html": {
    "title": "Attentive Prototypes for Source-Free Unsupervised Domain Adaptive 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deepti Hegde",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Panev_Exploring_the_Impact_of_Rendering_Method_and_Motion_Quality_on_WACV_2024_paper.html": {
    "title": "Exploring the Impact of Rendering Method and Motion Quality on Model Performance When Using Multi-View Synthetic Data for Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stanislav Panev",
      "Emily Kim",
      "Sai Abhishek Si Namburu",
      "Desislava Nikolova",
      "Celso de Melo",
      "Fernando De la Torre",
      "Jessica Hodgins"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Krumpl_ATS_Adaptive_Temperature_Scaling_for_Enhancing_Out-of-Distribution_Detection_Methods_WACV_2024_paper.html": {
    "title": "ATS: Adaptive Temperature Scaling for Enhancing Out-of-Distribution Detection Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gerhard Krumpl",
      "Henning Avenhaus",
      "Horst Possegger",
      "Horst Bischof"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Exploring_Adversarial_Robustness_of_Vision_Transformers_in_the_Spectral_Perspective_WACV_2024_paper.html": {
    "title": "Exploring Adversarial Robustness of Vision Transformers in the Spectral Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gihyun Kim",
      "Juyeop Kim",
      "Jong-Seok Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mehraban_MotionAGFormer_Enhancing_3D_Human_Pose_Estimation_With_a_Transformer-GCNFormer_Network_WACV_2024_paper.html": {
    "title": "MotionAGFormer: Enhancing 3D Human Pose Estimation With a Transformer-GCNFormer Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soroush Mehraban",
      "Vida Adeli",
      "Babak Taati"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wan_Density-Based_Flow_Mask_Integration_via_Deformable_Convolution_for_Video_People_WACV_2024_paper.html": {
    "title": "Density-Based Flow Mask Integration via Deformable Convolution for Video People Flux Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chang-Lin Wan",
      "Feng-Kai Huang",
      "Hong-Han Shuai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bele_Learning_Class_and_Domain_Augmentations_for_Single-Source_Open-Domain_Generalization_WACV_2024_paper.html": {
    "title": "Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prathmesh Bele",
      "Valay Bundele",
      "Avigyan Bhattacharya",
      "Ankit Jha",
      "Gemma Roig",
      "Biplab Banerjee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Feng_RankDVQA_Deep_VQA_Based_on_Ranking-Inspired_Hybrid_Training_WACV_2024_paper.html": {
    "title": "RankDVQA: Deep VQA Based on Ranking-Inspired Hybrid Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Feng",
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Reynolds_Salient_Object_Detection_for_Images_Taken_by_People_With_Vision_WACV_2024_paper.html": {
    "title": "Salient Object Detection for Images Taken by People With Vision Impairments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jarek Reynolds",
      "Chandra Kanth Nagesh",
      "Danna Gurari"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_HD-Fusion_Detailed_Text-to-3D_Generation_Leveraging_Multiple_Noise_Estimation_WACV_2024_paper.html": {
    "title": "HD-Fusion: Detailed Text-to-3D Generation Leveraging Multiple Noise Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinbo Wu",
      "Xiaobo Gao",
      "Xing Liu",
      "Zhengyang Shen",
      "Chen Zhao",
      "Haocheng Feng",
      "Jingtuo Liu",
      "Errui Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sreenivas_pSTarC_Pseudo_Source_Guided_Target_Clustering_for_Fully_Test-Time_Adaptation_WACV_2024_paper.html": {
    "title": "pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manogna Sreenivas",
      "Goirik Chakrabarty",
      "Soma Biswas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_FocusTune_Tuning_Visual_Localization_Through_Focus-Guided_Sampling_WACV_2024_paper.html": {
    "title": "FocusTune: Tuning Visual Localization Through Focus-Guided Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Son Tung Nguyen",
      "Alejandro Fontan",
      "Michael Milford",
      "Tobias Fischer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Khoshsirat_Improving_Normalization_With_the_James-Stein_Estimator_WACV_2024_paper.html": {
    "title": "Improving Normalization With the James-Stein Estimator",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seyedalireza Khoshsirat",
      "Chandra Kambhamettu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Depth_From_Asymmetric_Frame-Event_Stereo_A_Divide-and-Conquer_Approach_WACV_2024_paper.html": {
    "title": "Depth From Asymmetric Frame-Event Stereo: A Divide-and-Conquer Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xihao Chen",
      "Wenming Weng",
      "Yueyi Zhang",
      "Zhiwei Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hossain_Framework-Agnostic_Semantically-Aware_Global_Reasoning_for_Segmentation_WACV_2024_paper.html": {
    "title": "Framework-Agnostic Semantically-Aware Global Reasoning for Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mir Rayat Imtiaz Hossain",
      "Leonid Sigal",
      "James J. Little"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_Self-Supervised_Relation_Alignment_for_Scene_Graph_Generation_WACV_2024_paper.html": {
    "title": "Self-Supervised Relation Alignment for Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bicheng Xu",
      "Renjie Liao",
      "Leonid Sigal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Tackling_Data_Bias_in_MUSIC-AVQA_Crafting_a_Balanced_Dataset_for_WACV_2024_paper.html": {
    "title": "Tackling Data Bias in MUSIC-AVQA: Crafting a Balanced Dataset for Unbiased Question-Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiulong Liu",
      "Zhikang Dong",
      "Peng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_RPCANet_Deep_Unfolding_RPCA_Based_Infrared_Small_Target_Detection_WACV_2024_paper.html": {
    "title": "RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengyi Wu",
      "Tianfang Zhang",
      "Lei Li",
      "Yian Huang",
      "Zhenming Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_GLAD_Global-Local_View_Alignment_and_Background_Debiasing_for_Unsupervised_Video_WACV_2024_paper.html": {
    "title": "GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation With Large Domain Gap",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyogun Lee",
      "Kyungho Bae",
      "Seong Jong Ha",
      "Yumin Ko",
      "Gyeong-Moon Park",
      "Jinwoo Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Teterwak_Learning_To_Compose_SuperWeights_for_Neural_Parameter_Allocation_Search_WACV_2024_paper.html": {
    "title": "Learning To Compose SuperWeights for Neural Parameter Allocation Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piotr Teterwak",
      "Soren Nelson",
      "Nikoli Dryden",
      "Dina Bashkirova",
      "Kate Saenko",
      "Bryan A. Plummer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wen_Second-Order_Graph_ODEs_for_Multi-Agent_Trajectory_Forecasting_WACV_2024_paper.html": {
    "title": "Second-Order Graph ODEs for Multi-Agent Trajectory Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Song Wen",
      "Hao Wang",
      "Di Liu",
      "Qilong Zhangli",
      "Dimitris Metaxas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Boyne_FOUND_Foot_Optimization_With_Uncertain_Normals_for_Surface_Deformation_Using_WACV_2024_paper.html": {
    "title": "FOUND: Foot Optimization With Uncertain Normals for Surface Deformation Using Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oliver Boyne",
      "Gwangbin Bae",
      "James Charles",
      "Roberto Cipolla"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fox_Unsupervised_Event-Based_Video_Reconstruction_WACV_2024_paper.html": {
    "title": "Unsupervised Event-Based Video Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gereon Fox",
      "Xingang Pan",
      "Ayush Tewari",
      "Mohamed Elgharib",
      "Christian Theobalt"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Can_CLIP_Help_Sound_Source_Localization_WACV_2024_paper.html": {
    "title": "Can CLIP Help Sound Source Localization?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sooyoung Park",
      "Arda Senocak",
      "Joon Son Chung"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lin_FastSR-NeRF_Improving_NeRF_Efficiency_on_Consumer_Devices_With_a_Simple_WACV_2024_paper.html": {
    "title": "FastSR-NeRF: Improving NeRF Efficiency on Consumer Devices With a Simple Super-Resolution Pipeline",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chien-Yu Lin",
      "Qichen Fu",
      "Thomas Merth",
      "Karren Yang",
      "Anurag Ranjan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Raghavan_Online_Class-Incremental_Learning_for_Real-World_Food_Image_Classification_WACV_2024_paper.html": {
    "title": "Online Class-Incremental Learning for Real-World Food Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddeshwar Raghavan",
      "Jiangpeng He",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bansal_United_We_Stand_Divided_We_Fall_UnityGraph_for_Unsupervised_Procedure_WACV_2024_paper.html": {
    "title": "United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure Learning From Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddhant Bansal",
      "Chetan Arora",
      "C. V. Jawahar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Feng_3D_Face_Style_Transfer_With_a_Hybrid_Solution_of_NeRF_WACV_2024_paper.html": {
    "title": "3D Face Style Transfer With a Hybrid Solution of NeRF and Mesh Rasterization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianwei Feng",
      "Prateek Singhal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jeon_USDN_A_Unified_Sample-Wise_Dynamic_Network_With_Mixed-Precision_and_Early-Exit_WACV_2024_paper.html": {
    "title": "USDN: A Unified Sample-Wise Dynamic Network With Mixed-Precision and Early-Exit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji-Ye Jeon",
      "Xuan Truong Nguyen",
      "Soojung Ryu",
      "Hyuk-Jae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hoang_Learn_To_Unlearn_for_Deep_Neural_Networks_Minimizing_Unlearning_Interference_WACV_2024_paper.html": {
    "title": "Learn To Unlearn for Deep Neural Networks: Minimizing Unlearning Interference With Gradient Projection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuan Hoang",
      "Santu Rana",
      "Sunil Gupta",
      "Svetha Venkatesh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Human_Motion_Aware_Text-to-Video_Generation_With_Explicit_Camera_Control_WACV_2024_paper.html": {
    "title": "Human Motion Aware Text-to-Video Generation With Explicit Camera Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taehoon Kim",
      "ChanHee Kang",
      "JaeHyuk Park",
      "Daun Jeong",
      "ChangHee Yang",
      "Suk-Ju Kang",
      "Kyeongbo Kong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mayer_Beyond_SOT_Tracking_Multiple_Generic_Objects_at_Once_WACV_2024_paper.html": {
    "title": "Beyond SOT: Tracking Multiple Generic Objects at Once",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christoph Mayer",
      "Martin Danelljan",
      "Ming-Hsuan Yang",
      "Vittorio Ferrari",
      "Luc Van Gool",
      "Alina Kuznetsova"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Katsumata_Revisiting_Latent_Space_of_GAN_Inversion_for_Robust_Real_Image_WACV_2024_paper.html": {
    "title": "Revisiting Latent Space of GAN Inversion for Robust Real Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Katsumata",
      "Duc Minh Vo",
      "Bei Liu",
      "Hideki Nakayama"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kenia_Robust_TRISO-Fueled_Pebble_Identification_by_Digit_Recognition_WACV_2024_paper.html": {
    "title": "Robust TRISO-Fueled Pebble Identification by Digit Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roshan Kenia",
      "Jihane Mendil",
      "Ahmed Jasim",
      "Muthanna Al-Dahhan",
      "Zhaozheng Yin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Duan_Evidential_Uncertainty_Quantification_A_Variance-Based_Perspective_WACV_2024_paper.html": {
    "title": "Evidential Uncertainty Quantification: A Variance-Based Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruxiao Duan",
      "Brian Caffo",
      "Harrison X. Bai",
      "Haris I. Sair",
      "Craig Jones"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Neshatavar_ICF-SRSR_Invertible_Scale-Conditional_Function_for_Self-Supervised_Real-World_Single_Image_Super-Resolution_WACV_2024_paper.html": {
    "title": "ICF-SRSR: Invertible Scale-Conditional Function for Self-Supervised Real-World Single Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reyhaneh Neshatavar",
      "Mohsen Yavartanoo",
      "Sanghyun Son",
      "Kyoung Mu Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ding_PATROL_Privacy-Oriented_Pruning_for_Collaborative_Inference_Against_Model_Inversion_Attacks_WACV_2024_paper.html": {
    "title": "PATROL: Privacy-Oriented Pruning for Collaborative Inference Against Model Inversion Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiwei Ding",
      "Lan Zhang",
      "Miao Pan",
      "Xiaoyong Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sarukkai_Collage_Diffusion_WACV_2024_paper.html": {
    "title": "Collage Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishnu Sarukkai",
      "Linden Li",
      "Arden Ma",
      "Christopher Ré",
      "Kayvon Fatahalian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wijayasingha_Camera-Independent_Single_Image_Depth_Estimation_From_Defocus_Blur_WACV_2024_paper.html": {
    "title": "Camera-Independent Single Image Depth Estimation From Defocus Blur",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lahiru Wijayasingha",
      "Homa Alemzadeh",
      "John A. Stankovic"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Wakening_Past_Concepts_Without_Past_Data_Class-Incremental_Learning_From_Online_WACV_2024_paper.html": {
    "title": "Wakening Past Concepts Without Past Data: Class-Incremental Learning From Online Placebos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaoyao Liu",
      "Yingying Li",
      "Bernt Schiele",
      "Qianru Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wahed_Fine-Grained_Alignment_for_Cross-Modal_Recipe_Retrieval_WACV_2024_paper.html": {
    "title": "Fine-Grained Alignment for Cross-Modal Recipe Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muntasir Wahed",
      "Xiaona Zhou",
      "Tianjiao Yu",
      "Ismini Lourentzou"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bernal_NOMAD_A_Natural_Occluded_Multi-Scale_Aerial_Dataset_for_Emergency_Response_WACV_2024_paper.html": {
    "title": "NOMAD: A Natural, Occluded, Multi-Scale Aerial Dataset, for Emergency Response Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arturo Miguel Russell Bernal",
      "Walter Scheirer",
      "Jane Cleland-Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_UNSPAT_Uncertainty-Guided_SpatioTemporal_Transformer_for_3D_Human_Pose_and_Shape_WACV_2024_paper.html": {
    "title": "UNSPAT: Uncertainty-Guided SpatioTemporal Transformer for 3D Human Pose and Shape Estimation on Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minsoo Lee",
      "Hyunmin Lee",
      "Bumsoo Kim",
      "Seunghwan Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhu_Consistent_Multimodal_Generation_via_a_Unified_GAN_Framework_WACV_2024_paper.html": {
    "title": "Consistent Multimodal Generation via a Unified GAN Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Zhu",
      "Yijun Li",
      "Weijie Lyu",
      "Krishna Kumar Singh",
      "Zhixin Shu",
      "Sören Pirk",
      "Derek Hoiem"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kwon_Self-Supervised_Learning_of_Semantic_Correspondence_Using_Web_Videos_WACV_2024_paper.html": {
    "title": "Self-Supervised Learning of Semantic Correspondence Using Web Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Donghyeon Kwon",
      "Minsu Cho",
      "Suha Kwak"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Grimal_TIAM_-_A_Metric_for_Evaluating_Alignment_in_Text-to-Image_Generation_WACV_2024_paper.html": {
    "title": "TIAM - A Metric for Evaluating Alignment in Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Grimal",
      "Hervé Le Borgne",
      "Olivier Ferret",
      "Julien Tourille"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xue_HDMNet_A_Hierarchical_Matching_Network_With_Double_Attention_for_Large-Scale_WACV_2024_paper.html": {
    "title": "HDMNet: A Hierarchical Matching Network With Double Attention for Large-Scale Outdoor LiDAR Point Cloud Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyi Xue",
      "Fan Lu",
      "Guang Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_UGPNet_Universal_Generative_Prior_for_Image_Restoration_WACV_2024_paper.html": {
    "title": "UGPNet: Universal Generative Prior for Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hwayoon Lee",
      "Kyoungkook Kang",
      "Hyeongmin Lee",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sun_Defense_Against_Adversarial_Cloud_Attack_on_Remote_Sensing_Salient_Object_WACV_2024_paper.html": {
    "title": "Defense Against Adversarial Cloud Attack on Remote Sensing Salient Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiming Sun",
      "Lan Fu",
      "Jinlong Li",
      "Qing Guo",
      "Zibo Meng",
      "Tianyun Zhang",
      "Yuewei Lin",
      "Hongkai Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Diffusion_in_the_Dark_A_Diffusion_Model_for_Low-Light_Text_WACV_2024_paper.html": {
    "title": "Diffusion in the Dark: A Diffusion Model for Low-Light Text Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cindy M. Nguyen",
      "Eric R. Chan",
      "Alexander W. Bergman",
      "Gordon Wetzstein"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Drenkow_RobustCLEVR_A_Benchmark_and_Framework_for_Evaluating_Robustness_in_Object-Centric_WACV_2024_paper.html": {
    "title": "RobustCLEVR: A Benchmark and Framework for Evaluating Robustness in Object-Centric Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Drenkow",
      "Mathias Unberath"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yan_AFTer-SAM_Adapting_SAM_With_Axial_Fusion_Transformer_for_Medical_Imaging_WACV_2024_paper.html": {
    "title": "AFTer-SAM: Adapting SAM With Axial Fusion Transformer for Medical Imaging Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyi Yan",
      "Shanlin Sun",
      "Kun Han",
      "Thanh-Tung Le",
      "Haoyu Ma",
      "Chenyu You",
      "Xiaohui Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gomez-Villa_Plasticity-Optimized_Complementary_Networks_for_Unsupervised_Continual_Learning_WACV_2024_paper.html": {
    "title": "Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Gomez-Villa",
      "Bartlomiej Twardowski",
      "Kai Wang",
      "Joost van de Weijer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Weijler_FATE_Feature-Agnostic_Transformer-Based_Encoder_for_Learning_Generalized_Embedding_Spaces_in_WACV_2024_paper.html": {
    "title": "FATE: Feature-Agnostic Transformer-Based Encoder for Learning Generalized Embedding Spaces in Flow Cytometry Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lisa Weijler",
      "Florian Kowarsch",
      "Michael Reiter",
      "Pedro Hermosilla",
      "Margarita Maurer-Granofszky",
      "Michael Dworzak"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Katsumata_Label_Augmentation_As_Inter-Class_Data_Augmentation_for_Conditional_Image_Synthesis_WACV_2024_paper.html": {
    "title": "Label Augmentation As Inter-Class Data Augmentation for Conditional Image Synthesis With Imbalanced Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Katsumata",
      "Duc Minh Vo",
      "Hideki Nakayama"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xie_Sign_Language_Production_With_Latent_Motion_Transformer_WACV_2024_paper.html": {
    "title": "Sign Language Production With Latent Motion Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pan Xie",
      "Taiying Peng",
      "Yao Du",
      "Qipeng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Stypulkowski_Diffused_Heads_Diffusion_Models_Beat_GANs_on_Talking-Face_Generation_WACV_2024_paper.html": {
    "title": "Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michał Stypułkowski",
      "Konstantinos Vougioukas",
      "Sen He",
      "Maciej Zięba",
      "Stavros Petridis",
      "Maja Pantic"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_U3DS3_Unsupervised_3D_Semantic_Scene_Segmentation_WACV_2024_paper.html": {
    "title": "U3DS3: Unsupervised 3D Semantic Scene Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxu Liu",
      "Zhengdi Yu",
      "Toby P. Breckon",
      "Hubert P. H. Shum"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_GIPCOL_Graph-Injected_Soft_Prompting_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.html": {
    "title": "GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyue Xu",
      "Joyce Chai",
      "Parisa Kordjamshidi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Garcia-Bordils_STEP_-_Towards_Structured_Scene-Text_Spotting_WACV_2024_paper.html": {
    "title": "STEP - Towards Structured Scene-Text Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sergi Garcia-Bordils",
      "Dimosthenis Karatzas",
      "Marçal Rusiñol"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Roy_ClipSitu_Effectively_Leveraging_CLIP_for_Conditional_Predictions_in_Situation_Recognition_WACV_2024_paper.html": {
    "title": "ClipSitu: Effectively Leveraging CLIP for Conditional Predictions in Situation Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debaditya Roy",
      "Dhruv Verma",
      "Basura Fernando"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Multimodality-Guided_Image_Style_Transfer_Using_Cross-Modal_GAN_Inversion_WACV_2024_paper.html": {
    "title": "Multimodality-Guided Image Style Transfer Using Cross-Modal GAN Inversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanyu Wang",
      "Pengxiang Wu",
      "Kevin Dela Rosa",
      "Chen Wang",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Verma_Meta-Learned_Attribute_Self-Interaction_Network_for_Continual_and_Generalized_Zero-Shot_Learning_WACV_2024_paper.html": {
    "title": "Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vinay Verma",
      "Nikhil Mehta",
      "Kevin J. Liang",
      "Aakansha Mishra",
      "Lawrence Carin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nicolas_MoP-CLIP_A_Mixture_of_Prompt-Tuned_CLIP_Models_for_Domain_Incremental_WACV_2024_paper.html": {
    "title": "MoP-CLIP: A Mixture of Prompt-Tuned CLIP Models for Domain Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julien Nicolas",
      "Florent Chiaroni",
      "Imtiaz Ziko",
      "Ola Ahmad",
      "Christian Desrosiers",
      "Jose Dolz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gloudemans_So_You_Think_You_Can_Track_WACV_2024_paper.html": {
    "title": "So You Think You Can Track?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Derek Gloudemans",
      "Gergely Zachár",
      "Yanbing Wang",
      "Junyi Ji",
      "Matt Nice",
      "Matt Bunting",
      "William W. Barbour",
      "Jonathan Sprinkle",
      "Benedetto Piccoli",
      "Maria Laura Delle Monache",
      "Alexandre Bayen",
      "Benjamin Seibold",
      "Daniel B. Work"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Srivastava_OmniVec_Learning_Robust_Representations_With_Cross_Modal_Sharing_WACV_2024_paper.html": {
    "title": "OmniVec: Learning Robust Representations With Cross Modal Sharing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Srivastava",
      "Gaurav Sharma"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Song_MSCC_Multi-Scale_Transformers_for_Camera_Calibration_WACV_2024_paper.html": {
    "title": "MSCC: Multi-Scale Transformers for Camera Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Song",
      "Hao Kang",
      "Atsunori Moteki",
      "Genta Suzuki",
      "Yoshie Kobayashi",
      "Zhiming Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hou_Multi-Modal_Gaze_Following_in_Conversational_Scenarios_WACV_2024_paper.html": {
    "title": "Multi-Modal Gaze Following in Conversational Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Hou",
      "Zhongqun Zhang",
      "Nora Horanyi",
      "Jaewon Moon",
      "Yihua Cheng",
      "Hyung Jin Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Contrastive_Viewpoint-Aware_Shape_Learning_for_Long-Term_Person_Re-Identification_WACV_2024_paper.html": {
    "title": "Contrastive Viewpoint-Aware Shape Learning for Long-Term Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vuong D. Nguyen",
      "Khadija Khaldi",
      "Dung Nguyen",
      "Pranav Mantini",
      "Shishir Shah"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huang_Scale-Adaptive_Feature_Aggregation_for_Efficient_Space-Time_Video_Super-Resolution_WACV_2024_paper.html": {
    "title": "Scale-Adaptive Feature Aggregation for Efficient Space-Time Video Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhewei Huang",
      "Ailin Huang",
      "Xiaotao Hu",
      "Chen Hu",
      "Jun Xu",
      "Shuchang Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhu_SSP_Semi-Signed_Prioritized_Neural_Fitting_for_Surface_Reconstruction_From_Unoriented_WACV_2024_paper.html": {
    "title": "SSP: Semi-Signed Prioritized Neural Fitting for Surface Reconstruction From Unoriented Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runsong Zhu",
      "Di Kang",
      "Ka-Hei Hui",
      "Yue Qian",
      "Shi Qiu",
      "Zhen Dong",
      "Linchao Bao",
      "Pheng-Ann Heng",
      "Chi-Wing Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fedynyak_DeVos_Flow-Guided_Deformable_Transformer_for_Video_Object_Segmentation_WACV_2024_paper.html": {
    "title": "DeVos: Flow-Guided Deformable Transformer for Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Volodymyr Fedynyak",
      "Yaroslav Romanus",
      "Bohdan Hlovatskyi",
      "Bohdan Sydor",
      "Oles Dobosevych",
      "Igor Babin",
      "Roman Riazantsev"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Verma_GraphFill_Deep_Image_Inpainting_Using_Graphs_WACV_2024_paper.html": {
    "title": "GraphFill: Deep Image Inpainting Using Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shashikant Verma",
      "Aman Sharma",
      "Roopa Sheshadri",
      "Shanmuganathan Raman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kuang_AU-Aware_Dynamic_3D_Face_Reconstruction_From_Videos_With_Transformer_WACV_2024_paper.html": {
    "title": "AU-Aware Dynamic 3D Face Reconstruction From Videos With Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyi Kuang",
      "Jeffrey O. Kephart",
      "Qiang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gandikota_Unified_Concept_Editing_in_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Unified Concept Editing in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohit Gandikota",
      "Hadas Orgad",
      "Yonatan Belinkov",
      "Joanna Materzyńska",
      "David Bau"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bui_MEGANet_Multi-Scale_Edge-Guided_Attention_Network_for_Weak_Boundary_Polyp_Segmentation_WACV_2024_paper.html": {
    "title": "MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary Polyp Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nhat-Tan Bui",
      "Dinh-Hieu Hoang",
      "Quang-Thuc Nguyen",
      "Minh-Triet Tran",
      "Ngan Le"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.html": {
    "title": "GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-Ray Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Wang",
      "Hongyi Pan",
      "Armstrong Aboah",
      "Zheyuan Zhang",
      "Elif Keles",
      "Drew Torigian",
      "Baris Turkbey",
      "Elizabeth Krupinski",
      "Jayaram Udupa",
      "Ulas Bagci"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Silva_LipAT_Beyond_Style_Transfer_for_Controllable_Neural_Simulation_of_Lipstick_WACV_2024_paper.html": {
    "title": "LipAT: Beyond Style Transfer for Controllable Neural Simulation of Lipstick Using Cosmetic Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amila Silva",
      "Olga Moskvyak",
      "Alexander Long",
      "Ravi Garg",
      "Stephen Gould",
      "Gil Avraham",
      "Anton van den Hengel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cermak_WildlifeDatasets_An_Open-Source_Toolkit_for_Animal_Re-Identification_WACV_2024_paper.html": {
    "title": "WildlifeDatasets: An Open-Source Toolkit for Animal Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vojtěch Čermák",
      "Lukas Picek",
      "Lukáš Adam",
      "Kostas Papafitsoros"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_OTAS_Unsupervised_Boundary_Detection_for_Object-Centric_Temporal_Action_Segmentation_WACV_2024_paper.html": {
    "title": "OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuerong Li",
      "Zhengrong Xue",
      "Huazhe Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Luthra_Deblur-NSFF_Neural_Scene_Flow_Fields_for_Blurry_Dynamic_Scenes_WACV_2024_paper.html": {
    "title": "Deblur-NSFF: Neural Scene Flow Fields for Blurry Dynamic Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Achleshwar Luthra",
      "Shiva Souhith Gantha",
      "Xiyun Song",
      "Heather Yu",
      "Zongfang Lin",
      "Liang Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Belal_Multi-Source_Domain_Adaptation_for_Object_Detection_With_Prototype-Based_Mean_Teacher_WACV_2024_paper.html": {
    "title": "Multi-Source Domain Adaptation for Object Detection With Prototype-Based Mean Teacher",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atif Belal",
      "Akhil Meethal",
      "Francisco Perdigon Romero",
      "Marco Pedersoli",
      "Eric Granger"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yellapragada_PathLDM_Text_Conditioned_Latent_Diffusion_Model_for_Histopathology_WACV_2024_paper.html": {
    "title": "PathLDM: Text Conditioned Latent Diffusion Model for Histopathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srikar Yellapragada",
      "Alexandros Graikos",
      "Prateek Prasanna",
      "Tahsin Kurc",
      "Joel Saltz",
      "Dimitris Samaras"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hwang_EASUM_Enhancing_Affective_State_Understanding_Through_Joint_Sentiment_and_Emotion_WACV_2024_paper.html": {
    "title": "EASUM: Enhancing Affective State Understanding Through Joint Sentiment and Emotion Modeling for Multimodal Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yewon Hwang",
      "Jong-Hwan Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huber_Efficient_Explainable_Face_Verification_Based_on_Similarity_Score_Argument_Backpropagation_WACV_2024_paper.html": {
    "title": "Efficient Explainable Face Verification Based on Similarity Score Argument Backpropagation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Huber",
      "Anh Thi Luu",
      "Philipp Terhörst",
      "Naser Damer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sachdeva_Rank2Tell_A_Multimodal_Driving_Dataset_for_Joint_Importance_Ranking_and_WACV_2024_paper.html": {
    "title": "Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enna Sachdeva",
      "Nakul Agarwal",
      "Suhas Chundi",
      "Sean Roelofs",
      "Jiachen Li",
      "Mykel Kochenderfer",
      "Chiho Choi",
      "Behzad Dariush"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hayon_ArcAid_Analysis_of_Archaeological_Artifacts_Using_Drawings_WACV_2024_paper.html": {
    "title": "ArcAid: Analysis of Archaeological Artifacts Using Drawings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Offry Hayon",
      "Stefan Münger",
      "Ilan Shimshoni",
      "Ayellet Tal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dawkins_FishTrack23_An_Ensemble_Underwater_Dataset_for_Multi-Object_Tracking_WACV_2024_paper.html": {
    "title": "FishTrack23: An Ensemble Underwater Dataset for Multi-Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Dawkins",
      "Jack Prior",
      "Bryon Lewis",
      "Robin Faillettaz",
      "Thompson Banez",
      "Mary Salvi",
      "Audrey Rollo",
      "Julien Simon",
      "Matthew Campbell",
      "Matthew Lucero",
      "Aashish Chaudhary",
      "Benjamin Richards",
      "Anthony Hoogs"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Reducing_the_Side-Effects_of_Oscillations_in_Training_of_Quantized_YOLO_WACV_2024_paper.html": {
    "title": "Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kartik Gupta",
      "Akshay Asthana"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Grady_PressureVision_Estimating_Fingertip_Pressure_From_Diverse_RGB_Images_WACV_2024_paper.html": {
    "title": "PressureVision++: Estimating Fingertip Pressure From Diverse RGB Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Grady",
      "Jeremy A. Collins",
      "Chengcheng Tang",
      "Christopher D. Twigg",
      "Kunal Aneja",
      "James Hays",
      "Charles C. Kemp"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tailanian_Diffusion_Models_Meet_Image_Counter-Forensics_WACV_2024_paper.html": {
    "title": "Diffusion Models Meet Image Counter-Forensics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matías Tailanián",
      "Marina Gardella",
      "Alvaro Pardo",
      "Pablo Musé"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bose_STYLIP_Multi-Scale_Style-Conditioned_Prompt_Learning_for_CLIP-Based_Domain_Generalization_WACV_2024_paper.html": {
    "title": "STYLIP: Multi-Scale Style-Conditioned Prompt Learning for CLIP-Based Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shirsha Bose",
      "Ankit Jha",
      "Enrico Fini",
      "Mainak Singha",
      "Elisa Ricci",
      "Biplab Banerjee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Metta_Increasing_Biases_Can_Be_More_Efficient_Than_Increasing_Weights_WACV_2024_paper.html": {
    "title": "Increasing Biases Can Be More Efficient Than Increasing Weights",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carlo Metta",
      "Marco Fantozzi",
      "Andrea Papini",
      "Gianluca Amato",
      "Matteo Bergamaschi",
      "Silvia Giulia Galfrè",
      "Alessandro Marchetti",
      "Michelangelo Vegliò",
      "Maurizio Parton",
      "Francesco Morandin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dalbah_TransRadar_Adaptive-Directional_Transformer_for_Real-Time_Multi-View_Radar_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "TransRadar: Adaptive-Directional Transformer for Real-Time Multi-View Radar Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yahia Dalbah",
      "Jean Lahoud",
      "Hisham Cholakkal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Sequential_Transformer_for_End-to-End_Video_Text_Detection_WACV_2024_paper.html": {
    "title": "Sequential Transformer for End-to-End Video Text Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun-Bo Zhang",
      "Meng-Biao Zhao",
      "Fei Yin",
      "Cheng-Lin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kara_The_Background_Also_Matters_Background-Aware_Motion-Guided_Objects_Discovery_WACV_2024_paper.html": {
    "title": "The Background Also Matters: Background-Aware Motion-Guided Objects Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sandra Kara",
      "Hejer Ammar",
      "Florian Chabot",
      "Quoc-Cuong Pham"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Neural_Style_Protection_Counteracting_Unauthorized_Neural_Style_Transfer_WACV_2024_paper.html": {
    "title": "Neural Style Protection: Counteracting Unauthorized Neural Style Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxin Li",
      "Jie Ren",
      "Han Xu",
      "Hui Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ogawa_FRoG-MOT_Fast_and_Robust_Generic_Multiple-Object_Tracking_by_IoU_and_WACV_2024_paper.html": {
    "title": "FRoG-MOT: Fast and Robust Generic Multiple-Object Tracking by IoU and Motion-State Associations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takuya Ogawa",
      "Takashi Shibata",
      "Toshinori Hosoi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Alexandropoulos_OVeNet_Offset_Vector_Network_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "OVeNet: Offset Vector Network for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stamatis Alexandropoulos",
      "Christos Sakaridis",
      "Petros Maragos"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Logothetis_A_Neural_Height-Map_Approach_for_the_Binocular_Photometric_Stereo_Problem_WACV_2024_paper.html": {
    "title": "A Neural Height-Map Approach for the Binocular Photometric Stereo Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fotios Logothetis",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Feinglass_Towards_Addressing_the_Misalignment_of_Object_Proposal_Evaluation_for_Vision-Language_WACV_2024_paper.html": {
    "title": "Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua Feinglass",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lin_Spiking_Neural_Networks_for_Active_Time-Resolved_SPAD_Imaging_WACV_2024_paper.html": {
    "title": "Spiking Neural Networks for Active Time-Resolved SPAD Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Lin",
      "Edoardo Charbon"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Domain_Generalization_With_Correlated_Style_Uncertainty_WACV_2024_paper.html": {
    "title": "Domain Generalization With Correlated Style Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheyuan Zhang",
      "Bin Wang",
      "Debesh Jha",
      "Ugur Demir",
      "Ulas Bagci"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Thakur_Leveraging_Next-Active_Objects_for_Context-Aware_Anticipation_in_Egocentric_Videos_WACV_2024_paper.html": {
    "title": "Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanket Thakur",
      "Cigdem Beyan",
      "Pietro Morerio",
      "Vittorio Murino",
      "Alessio Del Bue"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fan_CryoRL_Reinforcement_Learning_Enables_Efficient_Cryo-EM_Data_Collection_WACV_2024_paper.html": {
    "title": "CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quanfu Fan",
      "Yilai Li",
      "Yuguang Yao",
      "John Cohn",
      "Sijia Liu",
      "Ziping Xu",
      "Seychelle Vos",
      "Michael Cianfrocco"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mehra_On_the_Fly_Neural_Style_Smoothing_for_Risk-Averse_Domain_Generalization_WACV_2024_paper.html": {
    "title": "On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshay Mehra",
      "Yunbei Zhang",
      "Bhavya Kailkhura",
      "Jihun Hamm"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ntavelis_StyleGenes_Discrete_and_Efficient_Latent_Distributions_for_GANs_WACV_2024_paper.html": {
    "title": "StyleGenes: Discrete and Efficient Latent Distributions for GANs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Evangelos Ntavelis",
      "Mohamad Shahbazi",
      "Iason Kastanis",
      "Martin Danelljan",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sanyal_Aligning_Non-Causal_Factors_for_Transformer-Based_Source-Free_Domain_Adaptation_WACV_2024_paper.html": {
    "title": "Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sunandini Sanyal",
      "Ashish Ramayee Asokan",
      "Suvaansh Bhambri",
      "Pradyumna YM",
      "Akshay Kulkarni",
      "Jogendra Nath Kundu",
      "R. Venkatesh Babu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shi_Benchmarking_Out-of-Distribution_Detection_in_Visual_Question_Answering_WACV_2024_paper.html": {
    "title": "Benchmarking Out-of-Distribution Detection in Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangxi Shi",
      "Stefan Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shvets_Joint_Depth_Prediction_and_Semantic_Segmentation_With_Multi-View_SAM_WACV_2024_paper.html": {
    "title": "Joint Depth Prediction and Semantic Segmentation With Multi-View SAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mykhailo Shvets",
      "Dongxu Zhao",
      "Marc Niethammer",
      "Roni Sengupta",
      "Alexander C. Berg"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rawal_GC-VTON_Predicting_Globally_Consistent_and_Occlusion_Aware_Local_Flows_With_WACV_2024_paper.html": {
    "title": "GC-VTON: Predicting Globally Consistent and Occlusion Aware Local Flows With Neighborhood Integrity Preservation for Virtual Try-On",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hamza Rawal",
      "Muhammad Junaid Ahmad",
      "Farooq Zaman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Enforcing_Sparsity_on_Latent_Space_for_Robust_and_Explainable_Representations_WACV_2024_paper.html": {
    "title": "Enforcing Sparsity on Latent Space for Robust and Explainable Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanao Li",
      "Tian Han"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_With_Pseudo_Label_Self-Refinement_WACV_2024_paper.html": {
    "title": "Unsupervised Domain Adaptation for Semantic Segmentation With Pseudo Label Self-Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingchen Zhao",
      "Niluthpol Chowdhury Mithun",
      "Abhinav Rajvanshi",
      "Han-Pang Chiu",
      "Supun Samarasekera"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Medeiros_HalluciDet_Hallucinating_RGB_Modality_for_Person_Detection_Through_Privileged_Information_WACV_2024_paper.html": {
    "title": "HalluciDet: Hallucinating RGB Modality for Person Detection Through Privileged Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heitor Rapela Medeiros",
      "Fidel A. Guerrero Peña",
      "Masih Aminbeidokhti",
      "Thomas Dubail",
      "Eric Granger",
      "Marco Pedersoli"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ju_Improving_Fairness_in_Deepfake_Detection_WACV_2024_paper.html": {
    "title": "Improving Fairness in Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Ju",
      "Shu Hu",
      "Shan Jia",
      "George H. Chen",
      "Siwei Lyu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yu_Evolve_Enhancing_Unsupervised_Continual_Learning_With_Multiple_Experts_WACV_2024_paper.html": {
    "title": "Evolve: Enhancing Unsupervised Continual Learning With Multiple Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofan Yu",
      "Tajana Rosing",
      "Yunhui Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sun_NeRFEditor_Differentiable_Style_Decomposition_for_3D_Scene_Editing_WACV_2024_paper.html": {
    "title": "NeRFEditor: Differentiable Style Decomposition for 3D Scene Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunyi Sun",
      "Yanbin Liu",
      "Junlin Han",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_Personalized_Face_Inpainting_With_Diffusion_Models_by_Parallel_Visual_Attention_WACV_2024_paper.html": {
    "title": "Personalized Face Inpainting With Diffusion Models by Parallel Visual Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianjin Xu",
      "Saman Motamed",
      "Praneetha Vaddamanu",
      "Chen Henry Wu",
      "Christian Haene",
      "Jean-Charles Bazin",
      "Fernando De la Torre"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Karthikeyan_AvatarOne_Monocular_3D_Human_Animation_WACV_2024_paper.html": {
    "title": "AvatarOne: Monocular 3D Human Animation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akash Karthikeyan",
      "Robert Ren",
      "Yash Kant",
      "Igor Gilitschenski"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hukkelas_Synthesizing_Anyone_Anywhere_in_Any_Pose_WACV_2024_paper.html": {
    "title": "Synthesizing Anyone, Anywhere, in Any Pose",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Håkon Hukkelås",
      "Frank Lindseth"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Deng_Ray_Deformation_Networks_for_Novel_View_Synthesis_of_Refractive_Objects_WACV_2024_paper.html": {
    "title": "Ray Deformation Networks for Novel View Synthesis of Refractive Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijian Deng",
      "Dylan Campbell",
      "Chunyi Sun",
      "Shubham Kanitkar",
      "Matthew Shaffer",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hempel_NITEC_Versatile_Hand-Annotated_Eye_Contact_Dataset_for_Ego-Vision_Interaction_WACV_2024_paper.html": {
    "title": "NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thorsten Hempel",
      "Magnus Jung",
      "Ahmed A. Abdelrahman",
      "Ayoub Al-Hamadi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Inkawhich_Tunable_Hybrid_Proposal_Networks_for_the_Open_World_WACV_2024_paper.html": {
    "title": "Tunable Hybrid Proposal Networks for the Open World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Inkawhich",
      "Nathan Inkawhich",
      "Hai Li",
      "Yiran Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cha_3D_Reconstruction_of_Interacting_Multi-Person_in_Clothing_From_a_Single_WACV_2024_paper.html": {
    "title": "3D Reconstruction of Interacting Multi-Person in Clothing From a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junuk Cha",
      "Hansol Lee",
      "Jaewon Kim",
      "Nhat Nguyen Bao Truong",
      "Jaeshin Yoon",
      "Seungryul Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_LensNeRF_Rethinking_Volume_Rendering_Based_on_Thin-Lens_Camera_Model_WACV_2024_paper.html": {
    "title": "LensNeRF: Rethinking Volume Rendering Based on Thin-Lens Camera Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min-Jung Kim",
      "Gyojung Gu",
      "Jaegul Choo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jamwal_Composite_Diffusion_whole__Sparts_WACV_2024_paper.html": {
    "title": "Composite Diffusion: whole >= Sparts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vikram Jamwal",
      "Ramaneswaran S."
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chong_P2D_Plug_and_Play_Discriminator_for_Accelerating_GAN_Frameworks_WACV_2024_paper.html": {
    "title": "P2D: Plug and Play Discriminator for Accelerating GAN Frameworks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Jin Chong",
      "Krishna Kumar Singh",
      "Yijun Li",
      "Jingwan Lu",
      "David Forsyth"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xian_PMI_Sampler_Patch_Similarity_Guided_Frame_Selection_for_Aerial_Action_WACV_2024_paper.html": {
    "title": "PMI Sampler: Patch Similarity Guided Frame Selection for Aerial Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqi Xian",
      "Xijun Wang",
      "Divya Kothandaraman",
      "Dinesh Manocha"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.html": {
    "title": "REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Skyler Seto",
      "Barry-John Theobald",
      "Federico Danieli",
      "Navdeep Jaitly",
      "Dan Busbridge"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xiao_TSA2_Temporal_Segment_Adaptation_and_Aggregation_for_Video_Harmonization_WACV_2024_paper.html": {
    "title": "TSA2: Temporal Segment Adaptation and Aggregation for Video Harmonization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyu Xiao",
      "Yurui Zhu",
      "Xueyang Fu",
      "Zhiwei Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_PMVC_Promoting_Multi-View_Consistency_for_3D_Scene_Reconstruction_WACV_2024_paper.html": {
    "title": "PMVC: Promoting Multi-View Consistency for 3D Scene Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chushan Zhang",
      "Jinguang Tong",
      "Tao Jun Lin",
      "Chuong Nguyen",
      "Hongdong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_MGM-AE_Self-Supervised_Learning_on_3D_Shape_Using_Mesh_Graph_Masked_WACV_2024_paper.html": {
    "title": "MGM-AE: Self-Supervised Learning on 3D Shape Using Mesh Graph Masked Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangsihao Yang",
      "Kaize Ding",
      "Huan Liu",
      "Yalin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cho_Interactive_Network_Perturbation_Between_Teacher_and_Students_for_Semi-Supervised_Semantic_WACV_2024_paper.html": {
    "title": "Interactive Network Perturbation Between Teacher and Students for Semi-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyuna Cho",
      "Injun Choi",
      "Suha Kwak",
      "Won Hwa Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yashwanth_Minimizing_Layerwise_Activation_Norm_Improves_Generalization_in_Federated_Learning_WACV_2024_paper.html": {
    "title": "Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "M. Yashwanth",
      "Gaurav Kumar Nayak",
      "Harsh Rangwani",
      "Arya Singh",
      "R. Venkatesh Babu",
      "Anirban Chakraborty"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hu_ReCLIP_Refine_Contrastive_Language_Image_Pre-Training_With_Source_Free_Domain_WACV_2024_paper.html": {
    "title": "ReCLIP: Refine Contrastive Language Image Pre-Training With Source Free Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuefeng Hu",
      "Ke Zhang",
      "Lu Xia",
      "Albert Chen",
      "Jiajia Luo",
      "Yuyin Sun",
      "Ken Wang",
      "Nan Qiao",
      "Xiao Zeng",
      "Min Sun",
      "Cheng-Hao Kuo",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tran_PointCT_Point_Central_Transformer_Network_for_Weakly-Supervised_Point_Cloud_Semantic_WACV_2024_paper.html": {
    "title": "PointCT: Point Central Transformer Network for Weakly-Supervised Point Cloud Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anh-Thuan Tran",
      "Hoanh-Su Le",
      "Suk-Hwan Lee",
      "Ki-Ryong Kwon"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Khorramshahi_Lightweight_Delivery_Detection_on_Doorbell_Cameras_WACV_2024_paper.html": {
    "title": "Lightweight Delivery Detection on Doorbell Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pirazh Khorramshahi",
      "Zhe Wu",
      "Tianchen Wang",
      "Luke DeLuccia",
      "Hongcheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jaziri_Designing_a_Hybrid_Neural_System_To_Learn_Real-World_Crack_Segmentation_WACV_2024_paper.html": {
    "title": "Designing a Hybrid Neural System To Learn Real-World Crack Segmentation From Fractal-Based Simulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Achref Jaziri",
      "Martin Mundt",
      "Andres Fernandez",
      "Visvanathan Ramesh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Karaderi_Deep_Visual-Genetic_Biometrics_for_Taxonomic_Classification_of_Rare_Species_WACV_2024_paper.html": {
    "title": "Deep Visual-Genetic Biometrics for Taxonomic Classification of Rare Species",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tayfun Karaderi",
      "Tilo Burghardt",
      "Raphaël Morard",
      "Daniela N. Schmidt"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Handformer2T_A_Lightweight_Regression-Based_Model_for_Interacting_Hands_Pose_Estimation_WACV_2024_paper.html": {
    "title": "Handformer2T: A Lightweight Regression-Based Model for Interacting Hands Pose Estimation From a Single RGB Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Zhang",
      "Deying Kong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yan_Universal_Semi-Supervised_Model_Adaptation_via_Collaborative_Consistency_Training_WACV_2024_paper.html": {
    "title": "Universal Semi-Supervised Model Adaptation via Collaborative Consistency Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizheng Yan",
      "Yushuang Wu",
      "Yipeng Qin",
      "Xiaoguang Han",
      "Shuguang Cui",
      "Guanbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Marsden_Universal_Test-Time_Adaptation_Through_Weight_Ensembling_Diversity_Weighting_and_Prior_WACV_2024_paper.html": {
    "title": "Universal Test-Time Adaptation Through Weight Ensembling, Diversity Weighting, and Prior Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robert A. Marsden",
      "Mario Döbler",
      "Bin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Siddiqui_Uncertainty_Estimation_in_Instance_Segmentation_With_Star-Convex_Shapes_WACV_2024_paper.html": {
    "title": "Uncertainty Estimation in Instance Segmentation With Star-Convex Shapes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qasim M. K. Siddiqui",
      "Sebastian Starke",
      "Peter Steinbach"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kobayashi_Spatio-Temporal_Filter_Analysis_Improves_3D-CNN_for_Action_Classification_WACV_2024_paper.html": {
    "title": "Spatio-Temporal Filter Analysis Improves 3D-CNN for Action Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takumi Kobayashi",
      "Jiaxing Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chopin_Bipartite_Graph_Diffusion_Model_for_Human_Interaction_Generation_WACV_2024_paper.html": {
    "title": "Bipartite Graph Diffusion Model for Human Interaction Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baptiste Chopin",
      "Hao Tang",
      "Mohamed Daoudi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mei_Latent_Feature-Guided_Diffusion_Models_for_Shadow_Removal_WACV_2024_paper.html": {
    "title": "Latent Feature-Guided Diffusion Models for Shadow Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangfu Mei",
      "Luis Figueroa",
      "Zhe Lin",
      "Zhihong Ding",
      "Scott Cohen",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Weilharter_HAMMER_Learning_Entropy_Maps_To_Create_Accurate_3D_Models_in_WACV_2024_paper.html": {
    "title": "HAMMER: Learning Entropy Maps To Create Accurate 3D Models in Multi-View Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rafael Weilharter",
      "Friedrich Fraundorfer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Localization_and_Manipulation_of_Immoral_Visual_Cues_for_Safe_Text-to-Image_WACV_2024_paper.html": {
    "title": "Localization and Manipulation of Immoral Visual Cues for Safe Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seongbeom Park",
      "Suhong Moon",
      "Seunghyun Park",
      "Jinkyu Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Dynamic Token-Pass Transformers for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuang Liu",
      "Qiang Zhou",
      "Jing Wang",
      "Zhibin Wang",
      "Fan Wang",
      "Jun Wang",
      "Wei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rahman_MIST_Medical_Image_Segmentation_Transformer_With_Convolutional_Attention_Mixing_CAM_WACV_2024_paper.html": {
    "title": "MIST: Medical Image Segmentation Transformer With Convolutional Attention Mixing (CAM) Decoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Motiur Rahman",
      "Shiva Shokouhmand",
      "Smriti Bhatt",
      "Miad Faezipour"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yamani_Active_Learning_for_Single-Stage_Object_Detection_in_UAV_Images_WACV_2024_paper.html": {
    "title": "Active Learning for Single-Stage Object Detection in UAV Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asma Yamani",
      "Albandari Alyami",
      "Hamzah Luqman",
      "Bernard Ghanem",
      "Silvio Giancola"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jeevan_WaveMixSR_Resource-Efficient_Neural_Network_for_Image_Super-Resolution_WACV_2024_paper.html": {
    "title": "WaveMixSR: Resource-Efficient Neural Network for Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pranav Jeevan",
      "Akella Srinidhi",
      "Pasunuri Prathiba",
      "Amit Sethi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Disentangled_Pre-Training_for_Image_Matting_WACV_2024_paper.html": {
    "title": "Disentangled Pre-Training for Image Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanda Li",
      "Zilong Huang",
      "Gang Yu",
      "Ling Chen",
      "Yunchao Wei",
      "Jianbo Jiao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_PromptAD_Zero-Shot_Anomaly_Detection_Using_Text_Prompts_WACV_2024_paper.html": {
    "title": "PromptAD: Zero-Shot Anomaly Detection Using Text Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiting Li",
      "Adam Goodge",
      "Fayao Liu",
      "Chuan-Sheng Foo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hirsch_Random_Walks_for_Temporal_Action_Segmentation_With_Timestamp_Supervision_WACV_2024_paper.html": {
    "title": "Random Walks for Temporal Action Segmentation With Timestamp Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Hirsch",
      "Regev Cohen",
      "Tomer Golany",
      "Daniel Freedman",
      "Ehud Rivlin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wu_Masked_Collaborative_Contrast_for_Weakly_Supervised_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Masked Collaborative Contrast for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangwen Wu",
      "Jingxuan He",
      "Yufei Yin",
      "Yanbin Hao",
      "Gang Huang",
      "Lechao Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kanebako_Critical_Gap_Between_Generalization_Error_and_Empirical_Error_in_Active_WACV_2024_paper.html": {
    "title": "Critical Gap Between Generalization Error and Empirical Error in Active Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuke Kanebako"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Semi-Supervised_Scene_Change_Detection_by_Distillation_From_Feature-Metric_Alignment_WACV_2024_paper.html": {
    "title": "Semi-Supervised Scene Change Detection by Distillation From Feature-Metric Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seonhoon Lee",
      "Jong-Hwan Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Point-DynRF_Point-Based_Dynamic_Radiance_Fields_From_a_Monocular_Video_WACV_2024_paper.html": {
    "title": "Point-DynRF: Point-Based Dynamic Radiance Fields From a Monocular Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Byeongjun Park",
      "Changick Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lee_Re-VoxelDet_Rethinking_Neck_and_Head_Architectures_for_High-Performance_Voxel-Based_3D_WACV_2024_paper.html": {
    "title": "Re-VoxelDet: Rethinking Neck and Head Architectures for High-Performance Voxel-Based 3D Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jae-Keun Lee",
      "Jin-Hee Lee",
      "Joohyun Lee",
      "Soon Kwon",
      "Heechul Jung"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Paruchuri_Motion_Matters_Neural_Motion_Transfer_for_Better_Camera_Physiological_Measurement_WACV_2024_paper.html": {
    "title": "Motion Matters: Neural Motion Transfer for Better Camera Physiological Measurement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshay Paruchuri",
      "Xin Liu",
      "Yulu Pan",
      "Shwetak Patel",
      "Daniel McDuff",
      "Soumyadip Sengupta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shimoda_Towards_Diverse_and_Consistent_Typography_Generation_WACV_2024_paper.html": {
    "title": "Towards Diverse and Consistent Typography Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wataru Shimoda",
      "Daichi Haraguchi",
      "Seiichi Uchida",
      "Kota Yamaguchi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Darestani_IR-FRestormer_Iterative_Refinement_With_Fourier-Based_Restormer_for_Accelerated_MRI_Reconstruction_WACV_2024_paper.html": {
    "title": "IR-FRestormer: Iterative Refinement With Fourier-Based Restormer for Accelerated MRI Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Zalbagi Darestani",
      "Vishwesh Nath",
      "Wenqi Li",
      "Yufan He",
      "Holger R. Roth",
      "Ziyue Xu",
      "Daguang Xu",
      "Reinhard Heckel",
      "Can Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shu_Deep_Plug-and-Play_Nighttime_Non-Blind_Deblurring_With_Saturated_Pixel_Handling_Schemes_WACV_2024_paper.html": {
    "title": "Deep Plug-and-Play Nighttime Non-Blind Deblurring With Saturated Pixel Handling Schemes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hung-Yu Shu",
      "Yi-Hsien Lin",
      "Yi-Chang Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Manandhar_One_Style_Is_All_You_Need_To_Generate_a_Video_WACV_2024_paper.html": {
    "title": "One Style Is All You Need To Generate a Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sandeep Manandhar",
      "Auguste Genovesio"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mori_Wino_Vidi_Vici_Conquering_Numerical_Instability_of_8-Bit_Winograd_Convolution_WACV_2024_paper.html": {
    "title": "Wino Vidi Vici: Conquering Numerical Instability of 8-Bit Winograd Convolution for Accurate Inference Acceleration on Edge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pierpaolo Mori",
      "Lukas Frickenstein",
      "Shambhavi Balamuthu Sampath",
      "Moritz Thoma",
      "Nael Fasfous",
      "Manoj Rohit Vemparala",
      "Alexander Frickenstein",
      "Christian Unger",
      "Walter Stechele",
      "Daniel Mueller-Gritschneder",
      "Claudio Passerone"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ehrlich_Leveraging_Bitstream_Metadata_for_Fast_Accurate_Generalized_Compressed_Video_Quality_WACV_2024_paper.html": {
    "title": "Leveraging Bitstream Metadata for Fast, Accurate, Generalized Compressed Video Quality Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Max Ehrlich",
      "Jon Barker",
      "Namitha Padmanabhan",
      "Larry Davis",
      "Andrew Tao",
      "Bryan Catanzaro",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wodlinger_ECSIC_Epipolar_Cross_Attention_for_Stereo_Image_Compression_WACV_2024_paper.html": {
    "title": "ECSIC: Epipolar Cross Attention for Stereo Image Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthias Wödlinger",
      "Jan Kotera",
      "Manuel Keglevic",
      "Jan Xu",
      "Robert Sablatnig"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Georgiou_FacadeNet_Conditional_Facade_Synthesis_via_Selective_Editing_WACV_2024_paper.html": {
    "title": "FacadeNet: Conditional Facade Synthesis via Selective Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiangos Georgiou",
      "Marios Loizou",
      "Tom Kelly",
      "Melinos Averkiou"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ren_VEATIC_Video-Based_Emotion_and_Affect_Tracking_in_Context_Dataset_WACV_2024_paper.html": {
    "title": "VEATIC: Video-Based Emotion and Affect Tracking in Context Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihang Ren",
      "Jefferson Ortega",
      "Yifan Wang",
      "Zhimin Chen",
      "Yunhui Guo",
      "Stella X. Yu",
      "David Whitney"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_SimpliMix_A_Simplified_Manifold_Mixup_for_Few-Shot_Point_Cloud_Classification_WACV_2024_paper.html": {
    "title": "SimpliMix: A Simplified Manifold Mixup for Few-Shot Point Cloud Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minmin Yang",
      "Weiheng Chai",
      "Jiyang Wang",
      "Senem Velipasalar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.html": {
    "title": "ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ligong Han",
      "Song Wen",
      "Qi Chen",
      "Zhixing Zhang",
      "Kunpeng Song",
      "Mengwei Ren",
      "Ruijiang Gao",
      "Anastasis Stathopoulos",
      "Xiaoxiao He",
      "Yuxiao Chen",
      "Di Liu",
      "Qilong Zhangli",
      "Jindong Jiang",
      "Zhaoyang Xia",
      "Akash Srivastava",
      "Dimitris Metaxas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nayman_Diverse_Imagenet_Models_Transfer_Better_WACV_2024_paper.html": {
    "title": "Diverse Imagenet Models Transfer Better",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niv Nayman",
      "Avram Golbert",
      "Asaf Noy",
      "Lihi Zelnik-Manor"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huang_SOAP_Cross-Sensor_Domain_Adaptation_for_3D_Object_Detection_Using_Stationary_WACV_2024_paper.html": {
    "title": "SOAP: Cross-Sensor Domain Adaptation for 3D Object Detection Using Stationary Object Aggregation Pseudo-Labelling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengjie Huang",
      "Vahdat Abdelzad",
      "Sean Sedwards",
      "Krzysztof Czarnecki"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Park_Layer-Wise_Auto-Weighting_for_Non-Stationary_Test-Time_Adaptation_WACV_2024_paper.html": {
    "title": "Layer-Wise Auto-Weighting for Non-Stationary Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyoung Park",
      "Jin Kim",
      "Hyeongjun Kwon",
      "Ilhoon Yoon",
      "Kwanghoon Sohn"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/DInca_Improving_Fairness_Using_Vision-Language_Driven_Image_Augmentation_WACV_2024_paper.html": {
    "title": "Improving Fairness Using Vision-Language Driven Image Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moreno D'Incà",
      "Christos Tzelepis",
      "Ioannis Patras",
      "Nicu Sebe"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Brahimi_SupeRVol_Super-Resolution_Shape_and_Reflectance_Estimation_in_Inverse_Volume_Rendering_WACV_2024_paper.html": {
    "title": "SupeRVol: Super-Resolution Shape and Reflectance Estimation in Inverse Volume Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Brahimi",
      "Bjoern Haefner",
      "Tarun Yenamandra",
      "Bastian Goldluecke",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mathur_Object_Aware_Contrastive_Prior_for_Interactive_Image_Segmentation_WACV_2024_paper.html": {
    "title": "Object Aware Contrastive Prior for Interactive Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Praful Mathur",
      "Shashi Kumar Parwani",
      "Mrinmoy Sen",
      "Roopa Sheshadri",
      "Aman Sharma"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Torque_Based_Structured_Pruning_for_Deep_Neural_Network_WACV_2024_paper.html": {
    "title": "Torque Based Structured Pruning for Deep Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arshita Gupta",
      "Tien Bau",
      "Joonsoo Kim",
      "Zhe Zhu",
      "Sumit Jha",
      "Hrishikesh Garud"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Instruct_Me_More_Random_Prompting_for_Visual_In-Context_Learning_WACV_2024_paper.html": {
    "title": "Instruct Me More! Random Prompting for Visual In-Context Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Zhang",
      "Bowen Wang",
      "Liangzhi Li",
      "Yuta Nakashima",
      "Hajime Nagahara"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Madan_CL-MAE_Curriculum-Learned_Masked_Autoencoders_WACV_2024_paper.html": {
    "title": "CL-MAE: Curriculum-Learned Masked Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neelu Madan",
      "Nicolae-Cătălin Ristea",
      "Kamal Nasrollahi",
      "Thomas B. Moeslund",
      "Radu Tudor Ionescu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ishay_Think_Before_You_Simulate_Symbolic_Reasoning_To_Orchestrate_Neural_Computation_WACV_2024_paper.html": {
    "title": "Think Before You Simulate: Symbolic Reasoning To Orchestrate Neural Computation for Counterfactual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Ishay",
      "Zhun Yang",
      "Joohyung Lee",
      "Ilgu Kang",
      "Dongjae Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Robust_Object_Detection_in_Challenging_Weather_Conditions_WACV_2024_paper.html": {
    "title": "Robust Object Detection in Challenging Weather Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Himanshu Gupta",
      "Oleksandr Kotlyar",
      "Henrik Andreasson",
      "Achim J. Lilienthal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Okuyama_DiffBody_Diffusion-Based_Pose_and_Shape_Editing_of_Human_Images_WACV_2024_paper.html": {
    "title": "DiffBody: Diffusion-Based Pose and Shape Editing of Human Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuta Okuyama",
      "Yuki Endo",
      "Yoshihiro Kanamori"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/He_Sound3DVDet_3D_Sound_Source_Detection_Using_Multiview_Microphone_Array_and_WACV_2024_paper.html": {
    "title": "Sound3DVDet: 3D Sound Source Detection Using Multiview Microphone Array and RGB Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang He",
      "Sangyun Shin",
      "Anoop Cherian",
      "Niki Trigoni",
      "Andrew Markham"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Liu_Annotation-Free_Audio-Visual_Segmentation_WACV_2024_paper.html": {
    "title": "Annotation-Free Audio-Visual Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinxiang Liu",
      "Yu Wang",
      "Chen Ju",
      "Chaofan Ma",
      "Ya Zhang",
      "Weidi Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Juyal_SC-MIL_Supervised_Contrastive_Multiple_Instance_Learning_for_Imbalanced_Classification_in_WACV_2024_paper.html": {
    "title": "SC-MIL: Supervised Contrastive Multiple Instance Learning for Imbalanced Classification in Pathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dinkar Juyal",
      "Siddhant Shingi",
      "Syed Ashar Javed",
      "Harshith Padigela",
      "Chintan Shah",
      "Anand Sampat",
      "Archit Khosla",
      "John Abel",
      "Amaro Taylor-Weiner"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kang_MetaSeg_MetaFormer-Based_Global_Contexts-Aware_Network_for_Efficient_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "MetaSeg: MetaFormer-Based Global Contexts-Aware Network for Efficient Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beoungwoo Kang",
      "Seunghun Moon",
      "Yubin Cho",
      "Hyunwoo Yu",
      "Suk-Ju Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Guermal_JOADAA_Joint_Online_Action_Detection_and_Action_Anticipation_WACV_2024_paper.html": {
    "title": "JOADAA: Joint Online Action Detection and Action Anticipation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Guermal",
      "Abid Ali",
      "Rui Dai",
      "François Brémond"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yu_Denoising_and_Selecting_Pseudo-Heatmaps_for_Semi-Supervised_Human_Pose_Estimation_WACV_2024_paper.html": {
    "title": "Denoising and Selecting Pseudo-Heatmaps for Semi-Supervised Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoran Yu",
      "Manchen Wang",
      "Yanbei Chen",
      "Paolo Favaro",
      "Davide Modolo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hung_CSAM_A_2.5D_Cross-Slice_Attention_Module_for_Anisotropic_Volumetric_Medical_WACV_2024_paper.html": {
    "title": "CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Ling Yu Hung",
      "Haoxin Zheng",
      "Kai Zhao",
      "Xiaoxi Du",
      "Kaifeng Pang",
      "Qi Miao",
      "Steven S. Raman",
      "Demetri Terzopoulos",
      "Kyunghyun Sung"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ren_Segment_Anything_From_Space_WACV_2024_paper.html": {
    "title": "Segment Anything, From Space?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simiao Ren",
      "Francesco Luzi",
      "Saad Lahrichi",
      "Kaleb Kassaw",
      "Leslie M. Collins",
      "Kyle Bradbury",
      "Jordan M. Malof"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bui_UOW-Vessel_A_Benchmark_Dataset_of_High-Resolution_Optical_Satellite_Images_for_WACV_2024_paper.html": {
    "title": "UOW-Vessel: A Benchmark Dataset of High-Resolution Optical Satellite Images for Vessel Detection and Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ly Bui",
      "Son Lam Phung",
      "Yang Di",
      "Thanh Le",
      "Tran Thanh Phong Nguyen",
      "Sandy Burden",
      "Abdesselam Bouzerdoum"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Guttikonda_Single_Frame_Semantic_Segmentation_Using_Multi-Modal_Spherical_Images_WACV_2024_paper.html": {
    "title": "Single Frame Semantic Segmentation Using Multi-Modal Spherical Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suresh Guttikonda",
      "Jason Rambach"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Singh_SynthProv_Interpretable_Framework_for_Profiling_Identity_Leakage_WACV_2024_paper.html": {
    "title": "SynthProv: Interpretable Framework for Profiling Identity Leakage",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaisidh Singh",
      "Harshil Bhatia",
      "Mayank Vatsa",
      "Richa Singh",
      "Aparna Bharati"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tanjim_Discovering_and_Mitigating_Biases_in_CLIP-Based_Image_Editing_WACV_2024_paper.html": {
    "title": "Discovering and Mitigating Biases in CLIP-Based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mehrab Tanjim",
      "Krishna Kumar Singh",
      "Kushal Kafle",
      "Ritwik Sinha",
      "Garrison W. Cottrell"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Repetitive_Action_Counting_With_Motion_Feature_Learning_WACV_2024_paper.html": {
    "title": "Repetitive Action Counting With Motion Feature Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinjie Li",
      "Huijuan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sinitsa_Deep_Image_Fingerprint_Towards_Low_Budget_Synthetic_Image_Detection_and_WACV_2024_paper.html": {
    "title": "Deep Image Fingerprint: Towards Low Budget Synthetic Image Detection and Model Lineage Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sergey Sinitsa",
      "Ohad Fried"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Biswas_HALSIE_Hybrid_Approach_to_Learning_Segmentation_by_Simultaneously_Exploiting_Image_WACV_2024_paper.html": {
    "title": "HALSIE: Hybrid Approach to Learning Segmentation by Simultaneously Exploiting Image and Event Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shristi Das Biswas",
      "Adarsh Kosta",
      "Chamika Liyanagedera",
      "Marco Apolinario",
      "Kaushik Roy"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lu_Hierarchical_Diffusion_Autoencoders_and_Disentangled_Image_Manipulation_WACV_2024_paper.html": {
    "title": "Hierarchical Diffusion Autoencoders and Disentangled Image Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyu Lu",
      "Chengyue Wu",
      "Xinyuan Chen",
      "Yaohui Wang",
      "Lei Bai",
      "Yu Qiao",
      "Xihui Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shamsi_Improved_Topological_Preservation_in_3D_Axon_Segmentation_and_Centerline_Detection_WACV_2024_paper.html": {
    "title": "Improved Topological Preservation in 3D Axon Segmentation and Centerline Detection Using Geometric Assessment-Driven Topological Smoothing (GATS)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nina I. Shamsi",
      "Alec S. Xu",
      "Lars A. Gjesteby",
      "Laura J. Brattain"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Destro_CycleCL_Self-Supervised_Learning_for_Periodic_Videos_WACV_2024_paper.html": {
    "title": "CycleCL: Self-Supervised Learning for Periodic Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Destro",
      "Michael Gygli"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/ElHabebe_DR10K_Transfer_Learning_Using_Weak_Labels_for_Grading_Diabetic_Retinopathy_WACV_2024_paper.html": {
    "title": "DR10K: Transfer Learning Using Weak Labels for Grading Diabetic Retinopathy on DR10K Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohamed ElHabebe",
      "Shereen ElKordi",
      "Ahmed Gamal ElDin",
      "Noha Adly",
      "Marwan Torki",
      "Ahmed Elmassry",
      "Islam SH Ahmed"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Open-NeRF_Towards_Open_Vocabulary_NeRF_Decomposition_WACV_2024_paper.html": {
    "title": "Open-NeRF: Towards Open Vocabulary NeRF Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Zhang",
      "Fang Li",
      "Narendra Ahuja"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Everaert_Exploiting_the_Signal-Leak_Bias_in_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Exploiting the Signal-Leak Bias in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Nicolas Everaert",
      "Athanasios Fitsios",
      "Marco Bocchio",
      "Sami Arpa",
      "Sabine Süsstrunk",
      "Radhakrishna Achanta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bar-Shalom_Weakly-Supervised_Representation_Learning_for_Video_Alignment_and_Analysis_WACV_2024_paper.html": {
    "title": "Weakly-Supervised Representation Learning for Video Alignment and Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guy Bar-Shalom",
      "George Leifman",
      "Michael Elad"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cha_NCIS_Neural_Contextual_Iterative_Smoothing_for_Purifying_Adversarial_Perturbations_WACV_2024_paper.html": {
    "title": "NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial Perturbations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungmin Cha",
      "Naeun Ko",
      "Heewoong Choi",
      "Youngjoon Yoo",
      "Taesup Moon"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_D3GU_Multi-Target_Active_Domain_Adaptation_via_Enhancing_Domain_Alignment_WACV_2024_paper.html": {
    "title": "D3GU: Multi-Target Active Domain Adaptation via Enhancing Domain Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Zhang",
      "Linghan Xu",
      "Saman Motamed",
      "Shayok Chakraborty",
      "Fernando De la Torre"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Barral_Fixed_Pattern_Noise_Removal_for_Multi-View_Single-Sensor_Infrared_Camera_WACV_2024_paper.html": {
    "title": "Fixed Pattern Noise Removal for Multi-View Single-Sensor Infrared Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnaud Barral",
      "Pablo Arias",
      "Axel Davy"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Painterly_Image_Harmonization_via_Adversarial_Residual_Learning_WACV_2024_paper.html": {
    "title": "Painterly Image Harmonization via Adversarial Residual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xudong Wang",
      "Li Niu",
      "Junyan Cao",
      "Yan Hong",
      "Liqing Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Verma_CoD_Coherent_Detection_of_Entities_From_Images_With_Multiple_Modalities_WACV_2024_paper.html": {
    "title": "CoD: Coherent Detection of Entities From Images With Multiple Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vinay Verma",
      "Dween Sanny",
      "Abhishek Singh",
      "Deepak Gupta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hart_Improving_Graph_Networks_Through_Selection-Based_Convolution_WACV_2024_paper.html": {
    "title": "Improving Graph Networks Through Selection-Based Convolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Hart",
      "Bryan Morse"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xie_Beyond_Fusion_Modality_Hallucination-Based_Multispectral_Fusion_for_Pedestrian_Detection_WACV_2024_paper.html": {
    "title": "Beyond Fusion: Modality Hallucination-Based Multispectral Fusion for Pedestrian Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Xie",
      "Ta-Ying Cheng",
      "Jia-Xing Zhong",
      "Kaichen Zhou",
      "Andrew Markham",
      "Niki Trigoni"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Conde_BSRAW_Improving_Blind_RAW_Image_Super-Resolution_WACV_2024_paper.html": {
    "title": "BSRAW: Improving Blind RAW Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcos V. Conde",
      "Florin Vasluianu",
      "Radu Timofte"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sani_SICKLE_A_Multi-Sensor_Satellite_Imagery_Dataset_Annotated_With_Multiple_Key_WACV_2024_paper.html": {
    "title": "SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated With Multiple Key Cropping Parameters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Depanshu Sani",
      "Sandeep Mahato",
      "Sourabh Saini",
      "Harsh Kumar Agarwal",
      "Charu Chandra Devshali",
      "Saket Anand",
      "Gaurav Arora",
      "Thiagarajan Jayaraman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Corneanu_LatentPaint_Image_Inpainting_in_Latent_Space_With_Diffusion_Models_WACV_2024_paper.html": {
    "title": "LatentPaint: Image Inpainting in Latent Space With Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ciprian Corneanu",
      "Raghudeep Gadde",
      "Aleix M. Martinez"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Efficient_Semantic_Matching_With_Hypercolumn_Correlation_WACV_2024_paper.html": {
    "title": "Efficient Semantic Matching With Hypercolumn Correlation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungwook Kim",
      "Juhong Min",
      "Minsu Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ahuja_OptFlow_Fast_Optimization-Based_Scene_Flow_Estimation_Without_Supervision_WACV_2024_paper.html": {
    "title": "OptFlow: Fast Optimization-Based Scene Flow Estimation Without Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rahul Ahuja",
      "Chris Baker",
      "Wilko Schwarting"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nikhal_HashReID_Dynamic_Network_With_Binary_Codes_for_Efficient_Person_Re-Identification_WACV_2024_paper.html": {
    "title": "HashReID: Dynamic Network With Binary Codes for Efficient Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kshitij Nikhal",
      "Yujunrong Ma",
      "Shuvra S. Bhattacharyya",
      "Benjamin S. Riggan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shi_Conditional_Velocity_Score_Estimation_for_Image_Restoration_WACV_2024_paper.html": {
    "title": "Conditional Velocity Score Estimation for Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqiang Shi",
      "Rujie Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jain_Stochastic_Binary_Network_for_Universal_Domain_Adaptation_WACV_2024_paper.html": {
    "title": "Stochastic Binary Network for Universal Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saurabh Kumar Jain",
      "Sukhendu Das"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yin_FG-Net_Facial_Action_Unit_Detection_With_Generalizable_Pyramidal_Features_WACV_2024_paper.html": {
    "title": "FG-Net: Facial Action Unit Detection With Generalizable Pyramidal Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufeng Yin",
      "Di Chang",
      "Guoxian Song",
      "Shen Sang",
      "Tiancheng Zhi",
      "Jing Liu",
      "Linjie Luo",
      "Mohammad Soleymani"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gu_Complex_Organ_Mask_Guided_Radiology_Report_Generation_WACV_2024_paper.html": {
    "title": "Complex Organ Mask Guided Radiology Report Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiancheng Gu",
      "Dongnan Liu",
      "Zhiyuan Li",
      "Weidong Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wittmann_Link_Prediction_for_Flow-Driven_Spatial_Networks_WACV_2024_paper.html": {
    "title": "Link Prediction for Flow-Driven Spatial Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bastian Wittmann",
      "Johannes C. Paetzold",
      "Chinmay Prabhakar",
      "Daniel Rueckert",
      "Bjoern Menze"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shi_Training-Free_Object_Counting_With_Prompts_WACV_2024_paper.html": {
    "title": "Training-Free Object Counting With Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zenglin Shi",
      "Ying Sun",
      "Mengmi Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nagar_SEMA_Semantic_Attention_for_Capturing_Long-Range_Dependencies_in_Egocentric_Lifelogs_WACV_2024_paper.html": {
    "title": "SEMA: Semantic Attention for Capturing Long-Range Dependencies in Egocentric Lifelogs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pravin Nagar",
      "K.N. Ajay Shastry",
      "Jayesh Chaudhari",
      "Chetan Arora"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jiang_Neural_Image_Compression_Using_Masked_Sparse_Visual_Representation_WACV_2024_paper.html": {
    "title": "Neural Image Compression Using Masked Sparse Visual Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Jiang",
      "Wei Wang",
      "Yue Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chen_Letting_3D_Guide_the_Way_3D_Guided_2D_Few-Shot_Image_WACV_2024_paper.html": {
    "title": "Letting 3D Guide the Way: 3D Guided 2D Few-Shot Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiajing Chen",
      "Minmin Yang",
      "Senem Velipasalar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Iwaguchi_Specular_Object_Reconstruction_Behind_Frosted_Glass_by_Differentiable_Rendering_WACV_2024_paper.html": {
    "title": "Specular Object Reconstruction Behind Frosted Glass by Differentiable Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takafumi Iwaguchi",
      "Hiroyuki Kubo",
      "Hiroshi Kawasaki"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Debiasing_Calibrating_and_Improving_Semi-Supervised_Learning_Performance_via_Simple_Ensemble_WACV_2024_paper.html": {
    "title": "Debiasing, Calibrating, and Improving Semi-Supervised Learning Performance via Simple Ensemble Projector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khanh-Binh Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kansal_Privacy-Enhancing_Person_Re-Identification_Framework_-_A_Dual-Stage_Approach_WACV_2024_paper.html": {
    "title": "Privacy-Enhancing Person Re-Identification Framework - A Dual-Stage Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kajal Kansal",
      "Yongkang Wong",
      "Mohan Kankanhalli"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Scheurer_Detection_Defenses_An_Empty_Promise_Against_Adversarial_Patch_Attacks_on_WACV_2024_paper.html": {
    "title": "Detection Defenses: An Empty Promise Against Adversarial Patch Attacks on Optical Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Erik Scheurer",
      "Jenny Schmalfuss",
      "Alexander Lis",
      "Andrés Bruhn"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xie_SAM_Fewshot_Finetuning_for_Anatomical_Segmentation_in_Medical_Images_WACV_2024_paper.html": {
    "title": "SAM Fewshot Finetuning for Anatomical Segmentation in Medical Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyi Xie",
      "Nathalie Willems",
      "Shubham Patil",
      "Yang Li",
      "Mayank Kumar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sastry_BirdSAT_Cross-View_Contrastive_Masked_Autoencoders_for_Bird_Species_Classification_and_WACV_2024_paper.html": {
    "title": "BirdSAT: Cross-View Contrastive Masked Autoencoders for Bird Species Classification and Mapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srikumar Sastry",
      "Subash Khanal",
      "Aayush Dhakal",
      "Di Huang",
      "Nathan Jacobs"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhuo_FELGA_Unsupervised_Fragment_Embedding_for_Fine-Grained_Cross-Modal_Association_WACV_2024_paper.html": {
    "title": "FELGA: Unsupervised Fragment Embedding for Fine-Grained Cross-Modal Association",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaoxin Zhuo",
      "Baoxin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tantaru_Weakly-Supervised_Deepfake_Localization_in_Diffusion-Generated_Images_WACV_2024_paper.html": {
    "title": "Weakly-Supervised Deepfake Localization in Diffusion-Generated Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dragoș-Constantin Țânțaru",
      "Elisabeta Oneață",
      "Dan Oneață"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Woo_Sketch-Based_Video_Object_Localization_WACV_2024_paper.html": {
    "title": "Sketch-Based Video Object Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangmin Woo",
      "So-Yeong Jeon",
      "Jinyoung Park",
      "Minji Son",
      "Sumin Lee",
      "Changick Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Moreira_Hyperbolic_vs_Euclidean_Embeddings_in_Few-Shot_Learning_Two_Sides_of_WACV_2024_paper.html": {
    "title": "Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriel Moreira",
      "Manuel Marques",
      "João Paulo Costeira",
      "Alexander Hauptmann"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Raswa_Attention-Guided_Prototype_Mixing_Diversifying_Minority_Context_on_Imbalanced_Whole_Slide_WACV_2024_paper.html": {
    "title": "Attention-Guided Prototype Mixing: Diversifying Minority Context on Imbalanced Whole Slide Images Classification Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Farchan Hakim Raswa",
      "Chun-Shien Lu",
      "Jia-Ching Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Perez_StyleAvatar_Stylizing_Animatable_Head_Avatars_WACV_2024_paper.html": {
    "title": "StyleAvatar: Stylizing Animatable Head Avatars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juan C. Pérez",
      "Thu Nguyen-Phuoc",
      "Chen Cao",
      "Artsiom Sanakoyeu",
      "Tomas Simon",
      "Pablo Arbeláez",
      "Bernard Ghanem",
      "Ali Thabet",
      "Albert Pumarola"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_On_the_Quantification_of_Image_Reconstruction_Uncertainty_Without_Training_Data_WACV_2024_paper.html": {
    "title": "On the Quantification of Image Reconstruction Uncertainty Without Training Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Zhang",
      "Sirui Bi",
      "Victor Fung"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Sparse_Convolutional_Networks_for_Surface_Reconstruction_From_Noisy_Point_Clouds_WACV_2024_paper.html": {
    "title": "Sparse Convolutional Networks for Surface Reconstruction From Noisy Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wang",
      "Jing Wu",
      "Ze Ji",
      "Yu-Kun Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Leng_Self-Sampling_Meta_SAM_Enhancing_Few-Shot_Medical_Image_Segmentation_With_Meta-Learning_WACV_2024_paper.html": {
    "title": "Self-Sampling Meta SAM: Enhancing Few-Shot Medical Image Segmentation With Meta-Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianang Leng",
      "Yiming Zhang",
      "Kun Han",
      "Xiaohui Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Makwana_LIVENet_A_Novel_Network_for_Real-World_Low-Light_Image_Denoising_and_WACV_2024_paper.html": {
    "title": "LIVENet: A Novel Network for Real-World Low-Light Image Denoising and Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dhruv Makwana",
      "Gayatri Deshmukh",
      "Onkar Susladkar",
      "Sparsh Mittal",
      "Sai Chandra Teja R."
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Stergiou_Holistic_Representation_Learning_for_Multitask_Trajectory_Anomaly_Detection_WACV_2024_paper.html": {
    "title": "Holistic Representation Learning for Multitask Trajectory Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandros Stergiou",
      "Brent De Weerdt",
      "Nikos Deligiannis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hasan_Text-Guided_Face_Recognition_Using_Multi-Granularity_Cross-Modal_Contrastive_Learning_WACV_2024_paper.html": {
    "title": "Text-Guided Face Recognition Using Multi-Granularity Cross-Modal Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mahedi Hasan",
      "Shoaib Meraj Sami",
      "Nasser Nasrabadi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Smink_Computer_Vision_on_the_Edge_Individual_Cattle_Identification_in_Real-Time_WACV_2024_paper.html": {
    "title": "Computer Vision on the Edge: Individual Cattle Identification in Real-Time With ReadMyCow System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moniek Smink",
      "Haotian Liu",
      "Dörte Döpfer",
      "Yong Jae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gorade_SynergyNet_Bridging_the_Gap_Between_Discrete_and_Continuous_Representations_for_WACV_2024_paper.html": {
    "title": "SynergyNet: Bridging the Gap Between Discrete and Continuous Representations for Precise Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vandan Gorade",
      "Sparsh Mittal",
      "Debesh Jha",
      "Ulas Bagci"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sun_Rethinking_Visibility_in_Human_Pose_Estimation_Occluded_Pose_Reasoning_via_WACV_2024_paper.html": {
    "title": "Rethinking Visibility in Human Pose Estimation: Occluded Pose Reasoning via Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengzhan Sun",
      "Kerui Gu",
      "Yunsong Wang",
      "Linlin Yang",
      "Angela Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jahedi_CCMR_High_Resolution_Optical_Flow_Estimation_via_Coarse-To-Fine_Context-Guided_Motion_WACV_2024_paper.html": {
    "title": "CCMR: High Resolution Optical Flow Estimation via Coarse-To-Fine Context-Guided Motion Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Azin Jahedi",
      "Maximilian Luz",
      "Marc Rivinius",
      "Andrés Bruhn"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hyun_ReConPatch_Contrastive_Patch_Representation_Learning_for_Industrial_Anomaly_Detection_WACV_2024_paper.html": {
    "title": "ReConPatch: Contrastive Patch Representation Learning for Industrial Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeeho Hyun",
      "Sangyun Kim",
      "Giyoung Jeon",
      "Seung Hwan Kim",
      "Kyunghoon Bae",
      "Byung Jun Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huix_Are_Natural_Domain_Foundation_Models_Useful_for_Medical_Image_Classification_WACV_2024_paper.html": {
    "title": "Are Natural Domain Foundation Models Useful for Medical Image Classification?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joana Palés Huix",
      "Adithya Raju Ganeshan",
      "Johan Fredin Haslum",
      "Magnus Söderberg",
      "Christos Matsoukas",
      "Kevin Smith"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shastry_Favoring_One_Among_Equals_-_Not_a_Good_Idea_Many-to-One_WACV_2024_paper.html": {
    "title": "Favoring One Among Equals - Not a Good Idea: Many-to-One Matching for Robust Transformer Based Pedestrian Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "K.N. Ajay Shastry",
      "K. Ravi Sri Teja",
      "Aditya Nigam",
      "Chetan Arora"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ma_MACP_Efficient_Model_Adaptation_for_Cooperative_Perception_WACV_2024_paper.html": {
    "title": "MACP: Efficient Model Adaptation for Cooperative Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunsheng Ma",
      "Juanwu Lu",
      "Can Cui",
      "Sicheng Zhao",
      "Xu Cao",
      "Wenqian Ye",
      "Ziran Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Szatkowski_Adapt_Your_Teacher_Improving_Knowledge_Distillation_for_Exemplar-Free_Continual_Learning_WACV_2024_paper.html": {
    "title": "Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-Free Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filip Szatkowski",
      "Mateusz Pyla",
      "Marcin Przewięźlikowski",
      "Sebastian Cygert",
      "Bartłomiej Twardowski",
      "Tomasz Trzciński"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ren_Content-Aware_Image_Color_Editing_With_Auxiliary_Color_Restoration_Tasks_WACV_2024_paper.html": {
    "title": "Content-Aware Image Color Editing With Auxiliary Color Restoration Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Ren",
      "Jing Shi",
      "Zhifei Zhang",
      "Yifei Fan",
      "Zhe Lin",
      "Bo He",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gao_Self-Supervised_Representation_Learning_With_Cross-Context_Learning_Between_Global_and_Hypercolumn_WACV_2024_paper.html": {
    "title": "Self-Supervised Representation Learning With Cross-Context Learning Between Global and Hypercolumn Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Gao",
      "Chen Feng",
      "Ioannis Patras"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Weber_Constrained_Probabilistic_Mask_Learning_for_Task-Specific_Undersampled_MRI_Reconstruction_WACV_2024_paper.html": {
    "title": "Constrained Probabilistic Mask Learning for Task-Specific Undersampled MRI Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Weber",
      "Michael Ingrisch",
      "Bernd Bischl",
      "David Rügamer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_CPSeg_Finer-Grained_Image_Semantic_Segmentation_via_Chain-of-Thought_Language_Prompting_WACV_2024_paper.html": {
    "title": "CPSeg: Finer-Grained Image Semantic Segmentation via Chain-of-Thought Language Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Hyb-NeRF_A_Multiresolution_Hybrid_Encoding_for_Neural_Radiance_Fields_WACV_2024_paper.html": {
    "title": "Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Wang",
      "Yi Gong",
      "Yuan Zeng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_SequenceMatch_Revisiting_the_Design_of_Weak-Strong_Augmentations_for_Semi-Supervised_Learning_WACV_2024_paper.html": {
    "title": "SequenceMatch: Revisiting the Design of Weak-Strong Augmentations for Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khanh-Binh Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Robust_Learning_via_Conditional_Prevalence_Adjustment_WACV_2024_paper.html": {
    "title": "Robust Learning via Conditional Prevalence Adjustment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh Nguyen",
      "Alan Q. Wang",
      "Heejong Kim",
      "Mert R. Sabuncu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Suri_GRIT_GAN_Residuals_for_Paired_Image-to-Image_Translation_WACV_2024_paper.html": {
    "title": "GRIT: GAN Residuals for Paired Image-to-Image Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saksham Suri",
      "Moustafa Meshry",
      "Larry S. Davis",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hu_Embodied_Human_Activity_Recognition_WACV_2024_paper.html": {
    "title": "Embodied Human Activity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sha Hu",
      "Yu Gong",
      "Greg Mori"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kazerouni_INCODE_Implicit_Neural_Conditioning_With_Prior_Knowledge_Embeddings_WACV_2024_paper.html": {
    "title": "INCODE: Implicit Neural Conditioning With Prior Knowledge Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhossein Kazerouni",
      "Reza Azad",
      "Alireza Hosseini",
      "Dorit Merhof",
      "Ulas Bagci"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Niloy_Effective_Restoration_of_Source_Knowledge_in_Continual_Test_Time_Adaptation_WACV_2024_paper.html": {
    "title": "Effective Restoration of Source Knowledge in Continual Test Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fahim Faisal Niloy",
      "Sk Miraj Ahmed",
      "Dripta S. Raychaudhuri",
      "Samet Oymak",
      "Amit K. Roy-Chowdhury"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fulari_Unsupervised_Model-Based_Learning_for_Simultaneous_Video_Deflickering_and_Deblotching_WACV_2024_paper.html": {
    "title": "Unsupervised Model-Based Learning for Simultaneous Video Deflickering and Deblotching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anuj Fulari",
      "Satish Mulleti",
      "Ajit Rajwade"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Westfechtel_Gradual_Source_Domain_Expansion_for_Unsupervised_Domain_Adaptation_WACV_2024_paper.html": {
    "title": "Gradual Source Domain Expansion for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Westfechtel",
      "Hao-Wei Yeh",
      "Dexuan Zhang",
      "Tatsuya Harada"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sun_Towards_Better_Structured_Pruning_Saliency_by_Reorganizing_Convolution_WACV_2024_paper.html": {
    "title": "Towards Better Structured Pruning Saliency by Reorganizing Convolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinglong Sun",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Controllable_Text-to-Image_Synthesis_for_Multi-Modality_MR_Images_WACV_2024_paper.html": {
    "title": "Controllable Text-to-Image Synthesis for Multi-Modality MR Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyuri Kim",
      "Yoonho Na",
      "Sung-Joon Ye",
      "Jimin Lee",
      "Sung Soo Ahn",
      "Ji Eun Park",
      "Hwiyoung Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhu_CATS_Combined_Activation_and_Temporal_Suppression_for_Efficient_Network_Inference_WACV_2024_paper.html": {
    "title": "CATS: Combined Activation and Temporal Suppression for Efficient Network Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeqi Zhu",
      "Arash Pourtaherian",
      "Luc Waeijen",
      "Ibrahim Batuhan Akkaya",
      "Egor Bondarev",
      "Orlando Moreira"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ishikawa_Learnable_Cube-Based_Video_Encryption_for_Privacy-Preserving_Action_Recognition_WACV_2024_paper.html": {
    "title": "Learnable Cube-Based Video Encryption for Privacy-Preserving Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchi Ishikawa",
      "Masayoshi Kondo",
      "Hirokatsu Kataoka"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hariat_Learning_To_Generate_Training_Datasets_for_Robust_Semantic_Segmentation_WACV_2024_paper.html": {
    "title": "Learning To Generate Training Datasets for Robust Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marwane Hariat",
      "Olivier Laurent",
      "Rémi Kazmierczak",
      "Shihao Zhang",
      "Andrei Bursuc",
      "Angela Yao",
      "Gianni Franchi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Mehl_Stereo_Conversion_With_Disparity-Aware_Warping_Compositing_and_Inpainting_WACV_2024_paper.html": {
    "title": "Stereo Conversion With Disparity-Aware Warping, Compositing and Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Mehl",
      "Andrés Bruhn",
      "Markus Gross",
      "Christopher Schroers"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xu_GTP-ViT_Efficient_Vision_Transformers_via_Graph-Based_Token_Propagation_WACV_2024_paper.html": {
    "title": "GTP-ViT: Efficient Vision Transformers via Graph-Based Token Propagation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuwei Xu",
      "Sen Wang",
      "Yudong Chen",
      "Yanping Zheng",
      "Zhewei Wei",
      "Jiajun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kapitanov_HaGRID_--_HAnd_Gesture_Recognition_Image_Dataset_WACV_2024_paper.html": {
    "title": "HaGRID -- HAnd Gesture Recognition Image Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Kapitanov",
      "Karina Kvanchiani",
      "Alexander Nagaev",
      "Roman Kraynov",
      "Andrei Makhliarchuk"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Glatt_Beyond_RGB_A_Real_World_Dataset_for_Multispectral_Imaging_in_WACV_2024_paper.html": {
    "title": "Beyond RGB: A Real World Dataset for Multispectral Imaging in Mobile Devices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ortal Glatt",
      "Yotam Ater",
      "Woo-Shik Kim",
      "Shira Werman",
      "Oded Berby",
      "Yael Zini",
      "Shay Zelinger",
      "Sangyoon Lee",
      "Heejin Choi",
      "Evgeny Soloveichik"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhong_Lightweight_Portrait_Matting_via_Regional_Attention_and_Refinement_WACV_2024_paper.html": {
    "title": "Lightweight Portrait Matting via Regional Attention and Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yatao Zhong",
      "Ilya Zharkov"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shao_Analyzing_the_Domain_Shift_Immunity_of_Deep_Homography_Estimation_WACV_2024_paper.html": {
    "title": "Analyzing the Domain Shift Immunity of Deep Homography Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingzhen Shao",
      "Tolga Tasdizen",
      "Sarang Joshi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sivasubramanian_Gradient_Coreset_for_Federated_Learning_WACV_2024_paper.html": {
    "title": "Gradient Coreset for Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Durga Sivasubramanian",
      "Lokesh Nagalapatti",
      "Rishabh Iyer",
      "Ganesh Ramakrishnan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Huang_Semantic_Fusion_Augmentation_and_Semantic_Boundary_Detection_A_Novel_Approach_WACV_2024_paper.html": {
    "title": "Semantic Fusion Augmentation and Semantic Boundary Detection: A Novel Approach to Multi-Target Video Moment Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Huang",
      "Yi-Lun Wu",
      "Hong-Han Shuai",
      "Ching-Chun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Burges_CHAI_Craters_in_Historical_Aerial_Images_WACV_2024_paper.html": {
    "title": "CHAI: Craters in Historical Aerial Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marvin Burges",
      "Sebastian Zambanini",
      "Philipp Pirker"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Aakerberg_PDA-RWSR_Pixel-Wise_Degradation_Adaptive_Real-World_Super-Resolution_WACV_2024_paper.html": {
    "title": "PDA-RWSR: Pixel-Wise Degradation Adaptive Real-World Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Aakerberg",
      "Majed El Helou",
      "Kamal Nasrollahi",
      "Thomas Moeslund"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Luo_Zero-Shot_Video_Moment_Retrieval_From_Frozen_Vision-Language_Models_WACV_2024_paper.html": {
    "title": "Zero-Shot Video Moment Retrieval From Frozen Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dezhao Luo",
      "Jiabo Huang",
      "Shaogang Gong",
      "Hailin Jin",
      "Yang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Krull_Image_Denoising_and_the_Generative_Accumulation_of_Photons_WACV_2024_paper.html": {
    "title": "Image Denoising and the Generative Accumulation of Photons",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Krull",
      "Hector Basevi",
      "Benjamin Salmon",
      "Andre Zeug",
      "Franziska Müller",
      "Samuel Tonks",
      "Leela Muppala",
      "Aleš Leonardis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shah_Ordinal_Classification_With_Distance_Regularization_for_Robust_Brain_Age_Prediction_WACV_2024_paper.html": {
    "title": "Ordinal Classification With Distance Regularization for Robust Brain Age Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jay Shah",
      "Md Mahfuzur Rahman Siddiquee",
      "Yi Su",
      "Teresa Wu",
      "Baoxin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wen_The_Growing_Strawberries_Dataset_Tracking_Multiple_Objects_With_Biological_Development_WACV_2024_paper.html": {
    "title": "The Growing Strawberries Dataset: Tracking Multiple Objects With Biological Development Over an Extended Period",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhan Wen",
      "Camiel R. Verschoor",
      "Chengming Feng",
      "Irina-Mona Epure",
      "Thomas Abeel",
      "Mathijs de Weerdt"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Fang_Face_Presentation_Attack_Detection_by_Excavating_Causal_Clues_and_Adapting_WACV_2024_paper.html": {
    "title": "Face Presentation Attack Detection by Excavating Causal Clues and Adapting Embedding Statistics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meiling Fang",
      "Naser Damer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Xiong_Glance_To_Count_Learning_To_Rank_With_Anchors_for_Weakly-Supervised_WACV_2024_paper.html": {
    "title": "Glance To Count: Learning To Rank With Anchors for Weakly-Supervised Crowd Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Xiong",
      "Liangyu Chai",
      "Wenxi Liu",
      "Yongtuo Liu",
      "Sucheng Ren",
      "Shengfeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Lan_Gradient-Guided_Knowledge_Distillation_for_Object_Detectors_WACV_2024_paper.html": {
    "title": "Gradient-Guided Knowledge Distillation for Object Detectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qizhen Lan",
      "Qing Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tarsi_SciOL_and_MuLMS-Img_Introducing_a_Large-Scale_Multimodal_Scientific_Dataset_and_WACV_2024_paper.html": {
    "title": "SciOL and MuLMS-Img: Introducing a Large-Scale Multimodal Scientific Dataset and Models for Image-Text Tasks in the Scientific Domain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim Tarsi",
      "Heike Adel",
      "Jan Hendrik Metzen",
      "Dan Zhang",
      "Matteo Finco",
      "Annemarie Friedrich"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tahmasebzadeh_Few-Shot_Event_Classification_in_Images_Using_Knowledge_Graphs_for_Prompting_WACV_2024_paper.html": {
    "title": "Few-Shot Event Classification in Images Using Knowledge Graphs for Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Golsa Tahmasebzadeh",
      "Matthias Springstein",
      "Ralph Ewerth",
      "Eric Müller-Budack"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Petryk_Simple_Token-Level_Confidence_Improves_Caption_Correctness_WACV_2024_paper.html": {
    "title": "Simple Token-Level Confidence Improves Caption Correctness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suzanne Petryk",
      "Spencer Whitehead",
      "Joseph E. Gonzalez",
      "Trevor Darrell",
      "Anna Rohrbach",
      "Marcus Rohrbach"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ofori-Oduro_Defending_Object_Detection_Models_Against_Image_Distortions_WACV_2024_paper.html": {
    "title": "Defending Object Detection Models Against Image Distortions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mark Ofori-Oduro",
      "Maria Amer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Khanfir_Graph_Neural_Networks_for_End-to-End_Information_Extraction_From_Handwritten_Documents_WACV_2024_paper.html": {
    "title": "Graph Neural Networks for End-to-End Information Extraction From Handwritten Documents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yessine Khanfir",
      "Marwa Dhiaf",
      "Emna Ghodhbani",
      "Ahmed Cheikh Rouhou",
      "Yousri Kessentini"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Odo_Automated_Monitoring_of_Ear_Biting_in_Pigs_by_Tracking_Individuals_WACV_2024_paper.html": {
    "title": "Automated Monitoring of Ear Biting in Pigs by Tracking Individuals and Events",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anicetus Odo",
      "Niall McLaughlin",
      "Ilias Kyriazakis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sun_RSMPNet_Relationship_Guided_Semantic_Map_Prediction_WACV_2024_paper.html": {
    "title": "RSMPNet: Relationship Guided Semantic Map Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwen Sun",
      "Jing Wu",
      "Ze Ji",
      "Yu-Kun Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Dittakavi_CARE_Counterfactual-Based_Algorithmic_Recourse_for_Explainable_Pose_Correction_WACV_2024_paper.html": {
    "title": "CARE: Counterfactual-Based Algorithmic Recourse for Explainable Pose Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bhat Dittakavi",
      "Bharathi Callepalli",
      "Aleti Vardhan",
      "Sai Vikas Desai",
      "Vineeth N. Balasubramanian"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hekimoglu_Monocular_3D_Object_Detection_With_LiDAR_Guided_Semi_Supervised_Active_WACV_2024_paper.html": {
    "title": "Monocular 3D Object Detection With LiDAR Guided Semi Supervised Active Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aral Hekimoglu",
      "Michael Schmidt",
      "Alvaro Marcos-Ramiro"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Johanson_S3AD_Semi-Supervised_Small_Apple_Detection_in_Orchard_Environments_WACV_2024_paper.html": {
    "title": "S3AD: Semi-Supervised Small Apple Detection in Orchard Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robert Johanson",
      "Christian Wilms",
      "Ole Johannsen",
      "Simone Frintrop"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Task-Oriented_Human-Object_Interactions_Generation_With_Implicit_Neural_Representations_WACV_2024_paper.html": {
    "title": "Task-Oriented Human-Object Interactions Generation With Implicit Neural Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quanzhou Li",
      "Jingbo Wang",
      "Chen Change Loy",
      "Bo Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Yang_Convolutional_Masked_Image_Modeling_for_Dense_Prediction_Tasks_on_Pathology_WACV_2024_paper.html": {
    "title": "Convolutional Masked Image Modeling for Dense Prediction Tasks on Pathology Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Yang",
      "Liyuan Pan",
      "Liu Liu",
      "Eric A. Stone"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_Controlling_Virtual_Try-On_Pipeline_Through_Rendering_Policies_WACV_2024_paper.html": {
    "title": "Controlling Virtual Try-On Pipeline Through Rendering Policies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kedan Li",
      "Jeffrey Zhang",
      "Shao-Yu Chang",
      "David Forsyth"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wan_Interpretable_Object_Recognition_by_Semantic_Prototype_Analysis_WACV_2024_paper.html": {
    "title": "Interpretable Object Recognition by Semantic Prototype Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiyang Wan",
      "Ruiping Wang",
      "Xilin Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Sharma_Assist_Is_Just_As_Important_as_the_Goal_Image_Resurfacing_WACV_2024_paper.html": {
    "title": "Assist Is Just As Important as the Goal: Image Resurfacing To Aid Model's Robust Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhijith Sharma",
      "Phil Munz",
      "Apurva Narayan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Murugesan_Prompting_Classes_Exploring_the_Power_of_Prompt_Class_Learning_in_WACV_2024_paper.html": {
    "title": "Prompting Classes: Exploring the Power of Prompt Class Learning in Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Balamurali Murugesan",
      "Rukhshanda Hussain",
      "Rajarshi Bhattacharya",
      "Ismail Ben Ayed",
      "Jose Dolz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wen_From_Denoising_Training_To_Test-Time_Adaptation_Enhancing_Domain_Generalization_for_WACV_2024_paper.html": {
    "title": "From Denoising Training To Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruxue Wen",
      "Hangjie Yuan",
      "Dong Ni",
      "Wenbo Xiao",
      "Yaoyao Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Kim_Implicit_Neural_Image_Stitching_With_Enhanced_and_Blended_Feature_Reconstruction_WACV_2024_paper.html": {
    "title": "Implicit Neural Image Stitching With Enhanced and Blended Feature Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minsu Kim",
      "Jaewon Lee",
      "Byeonghun Lee",
      "Sunghoon Im",
      "Kyong Hwan Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Teng_360BEV_Panoramic_Semantic_Mapping_for_Indoor_Birds-Eye_View_WACV_2024_paper.html": {
    "title": "360BEV: Panoramic Semantic Mapping for Indoor Bird's-Eye View",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhifeng Teng",
      "Jiaming Zhang",
      "Kailun Yang",
      "Kunyu Peng",
      "Hao Shi",
      "Simon Reiß",
      "Ke Cao",
      "Rainer Stiefelhagen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Rahman_Semi-Supervised_Semantic_Depth_Estimation_Using_Symbiotic_Transformer_and_NearFarMix_Augmentation_WACV_2024_paper.html": {
    "title": "Semi-Supervised Semantic Depth Estimation Using Symbiotic Transformer and NearFarMix Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Awsafur Rahman",
      "Shaikh Anowarul Fattah"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tripathi_Query-Guided_Attention_in_Vision_Transformers_for_Localizing_Objects_Using_a_WACV_2024_paper.html": {
    "title": "Query-Guided Attention in Vision Transformers for Localizing Objects Using a Single Sketch",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aditay Tripathi",
      "Anand Mishra",
      "Anirban Chakraborty"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pham_I-AI_A_Controllable__Interpretable_AI_System_for_Decoding_Radiologists_WACV_2024_paper.html": {
    "title": "I-AI: A Controllable & Interpretable AI System for Decoding Radiologists' Intense Focus for Accurate CXR Diagnoses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Trong Thang Pham",
      "Jacob Brecheisen",
      "Anh Nguyen",
      "Hien Nguyen",
      "Ngan Le"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Suin_Diffuse_and_Restore_A_Region-Adaptive_Diffusion_Model_for_Identity-Preserving_Blind_WACV_2024_paper.html": {
    "title": "Diffuse and Restore: A Region-Adaptive Diffusion Model for Identity-Preserving Blind Face Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maitreya Suin",
      "Nithin Gopalakrishnan Nair",
      "Chun Pong Lau",
      "Vishal M. Patel",
      "Rama Chellappa"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Roy_Interaction_Region_Visual_Transformer_for_Egocentric_Action_Anticipation_WACV_2024_paper.html": {
    "title": "Interaction Region Visual Transformer for Egocentric Action Anticipation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debaditya Roy",
      "Ramanathan Rajendiran",
      "Basura Fernando"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Preserving_Image_Properties_Through_Initializations_in_Diffusion_Models_WACV_2024_paper.html": {
    "title": "Preserving Image Properties Through Initializations in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeffrey Zhang",
      "Shao-Yu Chang",
      "Kedan Li",
      "David Forsyth"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Das_Limited_Data_Unlimited_Potential_A_Study_on_ViTs_Augmented_by_WACV_2024_paper.html": {
    "title": "Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srijan Das",
      "Tanmay Jain",
      "Dominick Reilly",
      "Pranav Balaji",
      "Soumyajit Karmakar",
      "Shyam Marjit",
      "Xiang Li",
      "Abhijit Das",
      "Michael S. Ryoo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ahmed_Unsupervised_Co-Generation_of_Foreground-Background_Segmentation_From_Text-to-Image_Synthesis_WACV_2024_paper.html": {
    "title": "Unsupervised Co-Generation of Foreground-Background Segmentation From Text-to-Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeruru Asrar Ahmed",
      "Anurag Mittal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ardelean_High-Fidelity_Zero-Shot_Texture_Anomaly_Localization_Using_Feature_Correspondence_Analysis_WACV_2024_paper.html": {
    "title": "High-Fidelity Zero-Shot Texture Anomaly Localization Using Feature Correspondence Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrei-Timotei Ardelean",
      "Tim Weyrich"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Long_Hierarchical_Text_Spotter_for_Joint_Text_Spotting_and_Layout_Analysis_WACV_2024_paper.html": {
    "title": "Hierarchical Text Spotter for Joint Text Spotting and Layout Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangbang Long",
      "Siyang Qin",
      "Yasuhisa Fujii",
      "Alessandro Bissacco",
      "Michalis Raptis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Law_Label-Free_Synthetic_Pretraining_of_Object_Detectors_WACV_2024_paper.html": {
    "title": "Label-Free Synthetic Pretraining of Object Detectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hei Law",
      "Jia Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Haalck_Tracking_Tiny_Insects_in_Cluttered_Natural_Environments_Using_Refinable_Recurrent_WACV_2024_paper.html": {
    "title": "Tracking Tiny Insects in Cluttered Natural Environments Using Refinable Recurrent Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lars Haalck",
      "Sebastian Thiele",
      "Benjamin Risse"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html": {
    "title": "RGB-X Object Detection via Scene-Specific Fusion Modules",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sri Aditya Deevi",
      "Connor Lee",
      "Lu Gan",
      "Sushruth Nagesh",
      "Gaurav Pandey",
      "Soon-Jo Chung"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ni_3D-Aware_Talking-Head_Video_Motion_Transfer_WACV_2024_paper.html": {
    "title": "3D-Aware Talking-Head Video Motion Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haomiao Ni",
      "Jiachen Liu",
      "Yuan Xue",
      "Sharon X. Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shyam_Lightweight_Thermal_Super-Resolution_and_Object_Detection_for_Robust_Perception_in_WACV_2024_paper.html": {
    "title": "Lightweight Thermal Super-Resolution and Object Detection for Robust Perception in Adverse Weather Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pranjay Shyam",
      "HyunJin Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Qin_Revolutionize_the_Oceanic_Drone_RGB_Imagery_With_Pioneering_Sun_Glint_WACV_2024_paper.html": {
    "title": "Revolutionize the Oceanic Drone RGB Imagery With Pioneering Sun Glint Detection and Removal Techniques",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangying Qin",
      "Ming Li",
      "Jie Zhao",
      "Jiageng Zhong",
      "Hanqi Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Pang_Revisiting_Pixel-Level_Contrastive_Pre-Training_on_Scene_Images_WACV_2024_paper.html": {
    "title": "Revisiting Pixel-Level Contrastive Pre-Training on Scene Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongshang Pang",
      "Yuta Nakashima",
      "Mayu Otani",
      "Hajime Nagahara"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Wang_Neural_Textured_Deformable_Meshes_for_Robust_Analysis-by-Synthesis_WACV_2024_paper.html": {
    "title": "Neural Textured Deformable Meshes for Robust Analysis-by-Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angtian Wang",
      "Wufei Ma",
      "Alan Yuille",
      "Adam Kortylewski"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Cosma_PsyMo_A_Dataset_for_Estimating_Self-Reported_Psychological_Traits_From_Gait_WACV_2024_paper.html": {
    "title": "PsyMo: A Dataset for Estimating Self-Reported Psychological Traits From Gait",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrian Cosma",
      "Emilian Radoi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Jiang_Back_to_Optimization_Diffusion-Based_Zero-Shot_3D_Human_Pose_Estimation_WACV_2024_paper.html": {
    "title": "Back to Optimization: Diffusion-Based Zero-Shot 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongyu Jiang",
      "Zhuoran Zhou",
      "Lei Li",
      "Wenhao Chai",
      "Cheng-Yen Yang",
      "Jenq-Neng Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ben-Shabat_IKEA_Ego_3D_Dataset_Understanding_Furniture_Assembly_Actions_From_Ego-View_WACV_2024_paper.html": {
    "title": "IKEA Ego 3D Dataset: Understanding Furniture Assembly Actions From Ego-View 3D Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhak Ben-Shabat",
      "Jonathan Paul",
      "Eviatar Segev",
      "Oren Shrout",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Hong_Concept-Centric_Transformers_Enhancing_Model_Interpretability_Through_Object-Centric_Concept_Learning_Within_WACV_2024_paper.html": {
    "title": "Concept-Centric Transformers: Enhancing Model Interpretability Through Object-Centric Concept Learning Within a Shared Global Workspace",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyung Hong",
      "Keun Hee Park",
      "Theodore P. Pavlic"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gothe_Whats_in_the_Flow_Exploiting_Temporal_Motion_Cues_for_Unsupervised_WACV_2024_paper.html": {
    "title": "What's in the Flow? Exploiting Temporal Motion Cues for Unsupervised Generic Event Boundary Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sourabh Vasant Gothe",
      "Vibhav Agarwal",
      "Sourav Ghosh",
      "Jayesh Rajkumar Vachhani",
      "Pranay Kashyap",
      "Barath Raj Kandur Raja"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Song_SyntheWorld_A_Large-Scale_Synthetic_Dataset_for_Land_Cover_Mapping_and_WACV_2024_paper.html": {
    "title": "SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Song",
      "Hongruixuan Chen",
      "Naoto Yokoya"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Galappaththige_Generalizing_to_Unseen_Domains_in_Diabetic_Retinopathy_Classification_WACV_2024_paper.html": {
    "title": "Generalizing to Unseen Domains in Diabetic Retinopathy Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chamuditha Jayanga Galappaththige",
      "Gayal Kuruppu",
      "Muhammad Haris Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Ehret_A_Generic_and_Flexible_Regularization_Framework_for_NeRFs_WACV_2024_paper.html": {
    "title": "A Generic and Flexible Regularization Framework for NeRFs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thibaud Ehret",
      "Roger Marí",
      "Gabriele Facciolo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Paheding_MarsLS-Net_Martian_Landslides_Segmentation_Network_and_Benchmark_Dataset_WACV_2024_paper.html": {
    "title": "MarsLS-Net: Martian Landslides Segmentation Network and Benchmark Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sidike Paheding",
      "Abel A. Reyes",
      "A. Rajaneesh",
      "K.S. Sajinkumar",
      "Thomas Oommen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gupta_You_Can_Run_but_Not_Hide_Improving_Gait_Recognition_With_WACV_2024_paper.html": {
    "title": "You Can Run but Not Hide: Improving Gait Recognition With Intrinsic Occlusion Type Awareness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayush Gupta",
      "Rama Chellappa"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Gava_SphereCraft_A_Dataset_for_Spherical_Keypoint_Detection_Matching_and_Camera_WACV_2024_paper.html": {
    "title": "SphereCraft: A Dataset for Spherical Keypoint Detection, Matching and Camera Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christiano Gava",
      "Yunmin Cho",
      "Federico Raue",
      "Sebastian Palacio",
      "Alain Pagani",
      "Andreas Dengel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Weng_Best_of_Both_Worlds_Learning_Arbitrary-Scale_Blind_Super-Resolution_via_Dual_WACV_2024_paper.html": {
    "title": "Best of Both Worlds: Learning Arbitrary-Scale Blind Super-Resolution via Dual Degradation Representations and Cycle-Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shao-Yu Weng",
      "Hsuan Yuan",
      "Yu-Syuan Xu",
      "Ching-Chun Huang",
      "Wei-Chen Chiu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Li_VMFormer_End-to-End_Video_Matting_With_Transformer_WACV_2024_paper.html": {
    "title": "VMFormer: End-to-End Video Matting With Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen Li",
      "Vidit Goel",
      "Marianna Ohanyan",
      "Shant Navasardyan",
      "Yunchao Wei",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Bohdal_Feed-Forward_Latent_Domain_Adaptation_WACV_2024_paper.html": {
    "title": "Feed-Forward Latent Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ondrej Bohdal",
      "Da Li",
      "Shell Xu Hu",
      "Timothy Hospedales"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nie_Triplet_Attention_Transformer_for_Spatiotemporal_Predictive_Learning_WACV_2024_paper.html": {
    "title": "Triplet Attention Transformer for Spatiotemporal Predictive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuesong Nie",
      "Xi Chen",
      "Haoyuan Jin",
      "Zhihang Zhu",
      "Yunfeng Yan",
      "Donglian Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Tsai_Arbitrary-Resolution_and_Arbitrary-Scale_Face_Super-Resolution_With_Implicit_Representation_Networks_WACV_2024_paper.html": {
    "title": "Arbitrary-Resolution and Arbitrary-Scale Face Super-Resolution With Implicit Representation Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Ting Tsai",
      "Yu Wei Chen",
      "Hong-Han Shuai",
      "Ching-Chun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shoshan_FPGAN-Control_A_Controllable_Fingerprint_Generator_for_Training_With_Synthetic_Data_WACV_2024_paper.html": {
    "title": "FPGAN-Control: A Controllable Fingerprint Generator for Training With Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alon Shoshan",
      "Nadav Bhonker",
      "Emanuel Ben Baruch",
      "Ori Nizan",
      "Igor Kviatkovsky",
      "Joshua Engelsma",
      "Manoj Aggarwal",
      "Gérard Medioni"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Chawla_Continual_Learning_of_Unsupervised_Monocular_Depth_From_Videos_WACV_2024_paper.html": {
    "title": "Continual Learning of Unsupervised Monocular Depth From Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hemang Chawla",
      "Arnav Varma",
      "Elahe Arani",
      "Bahram Zonooz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Shentu_CXR-IRGen_An_Integrated_Vision_and_Language_Model_for_the_Generation_WACV_2024_paper.html": {
    "title": "CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Shentu",
      "Noura Al Moubayed"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Song_Overcoming_Catastrophic_Forgetting_for_Multi-Label_Class-Incremental_Learning_WACV_2024_paper.html": {
    "title": "Overcoming Catastrophic Forgetting for Multi-Label Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Song",
      "Kuang Shu",
      "Songlin Dong",
      "Jie Cheng",
      "Xing Wei",
      "Yihong Gong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024/html/Nagendra_PatchRefineNet_Improving_Binary_Segmentation_by_Incorporating_Signals_From_Optimal_Patch-Wise_WACV_2024_paper.html": {
    "title": "PatchRefineNet: Improving Binary Segmentation by Incorporating Signals From Optimal Patch-Wise Binarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Savinay Nagendra",
      "Daniel Kifer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Kholiavchenko_KABR_In-Situ_Dataset_for_Kenyan_Animal_Behavior_Recognition_From_Drone_WACVW_2024_paper.html": {
    "title": "KABR: In-Situ Dataset for Kenyan Animal Behavior Recognition From Drone Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maksim Kholiavchenko",
      "Jenna Kline",
      "Michelle Ramirez",
      "Sam Stevens",
      "Alec Sheets",
      "Reshma Babu",
      "Namrata Banerji",
      "Elizabeth Campolongo",
      "Matthew Thompson",
      "Nina Van Tiel",
      "Jackson Miliko",
      "Eduardo Bessa",
      "Isla Duporge",
      "Tanya Berger-Wolf",
      "Daniel Rubenstein",
      "Charles Stewart"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Zhou_Efficient_Domain_Adaptation_via_Generative_Prior_for_3D_Infant_Pose_WACVW_2024_paper.html": {
    "title": "Efficient Domain Adaptation via Generative Prior for 3D Infant Pose Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoran Zhou",
      "Zhongyu Jiang",
      "Wenhao Chai",
      "Cheng-Yen Yang",
      "Lei Li",
      "Jenq-Neng Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Nepovinnykh_NORPPA_NOvel_Ringed_Seal_Re-Identification_by_Pelage_Pattern_Aggregation_WACVW_2024_paper.html": {
    "title": "NORPPA: NOvel Ringed Seal Re-Identification by Pelage Pattern Aggregation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ekaterina Nepovinnykh",
      "Tuomas Eerola",
      "Heikki Kälviäinen",
      "Ilia Chelak"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Straka_The_Hitchhikers_Guide_to_Endangered_Species_Pose_Estimation_WACVW_2024_paper.html": {
    "title": "The Hitchhiker's Guide to Endangered Species Pose Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jakub Straka",
      "Marek Hruz",
      "Lukas Picek"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Shooter_DigiDogs_Single-View_3D_Pose_Estimation_of_Dogs_Using_Synthetic_Training_WACVW_2024_paper.html": {
    "title": "DigiDogs: Single-View 3D Pose Estimation of Dogs Using Synthetic Training Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moira Shooter",
      "Charles Malleson",
      "Adrian Hilton"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Hatamimajoumerd_Challenges_in_Video-Based_Infant_Action_Recognition_A_Critical_Examination_of_WACVW_2024_paper.html": {
    "title": "Challenges in Video-Based Infant Action Recognition: A Critical Examination of the State of the Art",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elaheh Hatamimajoumerd",
      "Pooria Daneshvar Kakhaki",
      "Xiaofei Huang",
      "Lingfei Luan",
      "Somaieh Amraee",
      "Sarah Ostadabbas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Cotton_Dynamic_Gaussian_Splatting_From_Markerless_Motion_Capture_Reconstruct_Infants_Movements_WACVW_2024_paper.html": {
    "title": "Dynamic Gaussian Splatting From Markerless Motion Capture Reconstruct Infants Movements",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "R. James Cotton",
      "Colleen Peyton"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Amraee_Multiple_Toddler_Tracking_in_Indoor_Videos_WACVW_2024_paper.html": {
    "title": "Multiple Toddler Tracking in Indoor Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Somaieh Amraee",
      "Bishoy Galoaa",
      "Matthew Goodwin",
      "Elaheh Hatamimajoumerd",
      "Sarah Ostadabbas"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Waldmann_Neural_Texture_Puppeteer_A_Framework_for_Neural_Geometry_and_Texture_WACVW_2024_paper.html": {
    "title": "Neural Texture Puppeteer: A Framework for Neural Geometry and Texture Rendering of Articulated Shapes, Enabling Re-Identification at Interactive Speed",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Urs Waldmann",
      "Ole Johannsen",
      "Bastian Goldluecke"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4Smalls/html/Peng_Learning_Part_Segmentation_From_Synthetic_Animals_WACVW_2024_paper.html": {
    "title": "Learning Part Segmentation From Synthetic Animals",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Peng",
      "Ju He",
      "Prakhar Kaushik",
      "Zihao Xiao",
      "Jiteng Mu",
      "Alan Yuille"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Madsen_Person_Fall_Detection_Using_Weakly_Supervised_Methods_WACVW_2024_paper.html": {
    "title": "Person Fall Detection Using Weakly Supervised Methods",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kjartan Madsen",
      "Zenjie Li",
      "Francois Lauze",
      "Kamal Nasrollahi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Bui_C2T-Net_Channel-Aware_Cross-Fused_Transformer-Style_Networks_for_Pedestrian_Attribute_Recognition_WACVW_2024_paper.html": {
    "title": "C2T-Net: Channel-Aware Cross-Fused Transformer-Style Networks for Pedestrian Attribute Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Doanh C. Bui",
      "Thinh V. Le",
      "Ba Hung Ngo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Friederich_Security_Fence_Inspection_at_Airports_Using_Object_Detection_WACVW_2024_paper.html": {
    "title": "Security Fence Inspection at Airports Using Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nils Friederich",
      "Andreas Specker"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Gkrispanis_Filter-Pruning_of_Lightweight_Face_Detectors_Using_a_Geometric_Median_Criterion_WACVW_2024_paper.html": {
    "title": "Filter-Pruning of Lightweight Face Detectors Using a Geometric Median Criterion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstantinos Gkrispanis",
      "Nikolaos Gkalelis",
      "Vasileios Mezaris"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Nguyen_Temporal_3D_Shape_Modeling_for_Video-Based_Cloth-Changing_Person_Re-Identification_WACVW_2024_paper.html": {
    "title": "Temporal 3D Shape Modeling for Video-Based Cloth-Changing Person Re-Identification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vuong D. Nguyen",
      "Pranav Mantini",
      "Shishir K. Shah"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/AlMarri_A_Multi-Head_Approach_With_Shuffled_Segments_for_Weakly-Supervised_Video_Anomaly_WACVW_2024_paper.html": {
    "title": "A Multi-Head Approach With Shuffled Segments for Weakly-Supervised Video Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Salem AlMarri",
      "Muhammad Zaigham Zaheer",
      "Karthik Nandakumar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/OBrien_Accenture-MM1_A_Multimodal_Person_Recognition_Dataset_WACVW_2024_paper.html": {
    "title": "Accenture-MM1: A Multimodal Person Recognition Dataset",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyle O'Brien",
      "Michelle Rybak",
      "Jiong Huang",
      "Adam Stevens",
      "Madeline Fredriksz",
      "Michael Chaberski",
      "Danielle Russell",
      "Lindsey Castin",
      "Michelle Jou",
      "Nishant Gurrapadi",
      "Marc Bosch"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Tu_FedFSLAR_A_Federated_Learning_Framework_for_Few-Shot_Action_Recognition_WACVW_2024_paper.html": {
    "title": "FedFSLAR: A Federated Learning Framework for Few-Shot Action Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nguyen Anh Tu",
      "Assanali Abu",
      "Nartay Aikyn",
      "Nursultan Makhanov",
      "Min-Ho Lee",
      "Khiem Le-Huy",
      "Kok-Seng Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Cormier_Enhancing_Skeleton-Based_Action_Recognition_in_Real-World_Scenarios_Through_Realistic_Data_WACVW_2024_paper.html": {
    "title": "Enhancing Skeleton-Based Action Recognition in Real-World Scenarios Through Realistic Data Augmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mickael Cormier",
      "Yannik Schmid",
      "Jürgen Beyerer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Nunez_Identifying_Loitering_Behavior_With_Trajectory_Analysis_WACVW_2024_paper.html": {
    "title": "Identifying Loitering Behavior With Trajectory Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johnny Núñez",
      "Zenjie Li",
      "Sergio Escalera",
      "Kamal Nasrollahi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Tan_Overlooked_Video_Classification_in_Weakly_Supervised_Video_Anomaly_Detection_WACVW_2024_paper.html": {
    "title": "Overlooked Video Classification in Weakly Supervised Video Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijun Tan",
      "Qi Yao",
      "Jingfeng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Oliu_Swin_on_Axes_Extending_Swin_Transformers_to_Quadtree_Image_Representations_WACVW_2024_paper.html": {
    "title": "Swin on Axes: Extending Swin Transformers to Quadtree Image Representations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marc Oliu",
      "Kamal Nasrollahi",
      "Sergio Escalera",
      "Thomas B. Moeslund"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Blanch_LiDAR-Assisted_3D_Human_Detection_for_Video_Surveillance_WACVW_2024_paper.html": {
    "title": "LiDAR-Assisted 3D Human Detection for Video Surveillance",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miquel Romero Blanch",
      "Zenjie Li",
      "Sergio Escalera",
      "Kamal Nasrollahi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Wolf_Knowledge-Distillation-Based_Label_Smoothing_for_Fine-Grained_Open-Set_Vehicle_Recognition_WACVW_2024_paper.html": {
    "title": "Knowledge-Distillation-Based Label Smoothing for Fine-Grained Open-Set Vehicle Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stefan Wolf",
      "Dennis Loran",
      "Jürgen Beyerer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Arkushin_GEFF_Improving_Any_Clothes-Changing_Person_ReID_Model_Using_Gallery_Enrichment_WACVW_2024_paper.html": {
    "title": "GEFF: Improving Any Clothes-Changing Person ReID Model Using Gallery Enrichment With Face Features",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Arkushin",
      "Bar Cohen",
      "Shmuel Peleg",
      "Ohad Fried"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Teepe_EarlyBird_Early-Fusion_for_Multi-View_Tracking_in_the_Birds_Eye_View_WACVW_2024_paper.html": {
    "title": "EarlyBird: Early-Fusion for Multi-View Tracking in the Bird's Eye View",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Torben Teepe",
      "Philipp Wolters",
      "Johannes Gilg",
      "Fabian Herzog",
      "Gerhard Rigoll"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Rahman_Spatio-Temporal_Activity_Detection_via_Joint_Optimization_of_Spatial_and_Temporal_WACVW_2024_paper.html": {
    "title": "Spatio-Temporal Activity Detection via Joint Optimization of Spatial and Temporal Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Atiqur Rahman",
      "Robert Laganière"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Ha_HOD_New_Harmful_Object_Detection_Benchmarks_for_Robust_Surveillance_WACVW_2024_paper.html": {
    "title": "HOD: New Harmful Object Detection Benchmarks for Robust Surveillance",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eungyeom Ha",
      "Heemook Kim",
      "Dongbin Na"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Shyam_Enhancing_Self-Supervised_Monocular_Depth_Estimation_via_Piece-Wise_Pose_Estimation_and_WACVW_2024_paper.html": {
    "title": "Enhancing Self-Supervised Monocular Depth Estimation via Piece-Wise Pose Estimation and Geometric Constraints",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pranjay Shyam",
      "Alexandre Okon",
      "HyunJin Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Munir_Investigation_of_UAV_Detection_in_Images_With_Complex_Backgrounds_and_WACVW_2024_paper.html": {
    "title": "Investigation of UAV Detection in Images With Complex Backgrounds and Rainy Artifacts",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adnan Munir",
      "Abdul Jabbar Siddiqui",
      "Saeed Anwar"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Hwang_Aerial_View_3D_Human_Pose_Estimation_Using_Double_Vector_Quantized-Variational_WACVW_2024_paper.html": {
    "title": "Aerial View 3D Human Pose Estimation Using Double Vector Quantized-Variational AutoEncoders",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juheon Hwang",
      "Jiwoo Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Khaldi_Unsupervised_Person_Re-Identification_in_Aerial_Imagery_WACVW_2024_paper.html": {
    "title": "Unsupervised Person Re-Identification in Aerial Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khadija Khaldi",
      "Vuong D. Nguyen",
      "Pranav Mantini",
      "Shishir Shah"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Cormier_UPAR_Challenge_2024_Pedestrian_Attribute_Recognition_and_Attribute-Based_Person_Retrieval_WACVW_2024_paper.html": {
    "title": "UPAR Challenge 2024: Pedestrian Attribute Recognition and Attribute-Based Person Retrieval - Dataset, Design, and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mickael Cormier",
      "Andreas Specker",
      "Julio C. S. Jacques Junior",
      "Lennart Moritz",
      "Jürgen Metzler",
      "Thomas B. Moeslund",
      "Kamal Nasrollahi",
      "Sergio Escalera",
      "Jürgen Beyerer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Fawakherji_TextAug_Test_Time_Text_Augmentation_for_Multimodal_Person_Re-Identification_WACVW_2024_paper.html": {
    "title": "TextAug: Test Time Text Augmentation for Multimodal Person Re-Identification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mulham Fawakherji",
      "Eduard Vazquez",
      "Pasquale Giampa",
      "Binod Bhattarai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Latortue_Evaluating_Supervision_Levels_Trade-Offs_for_Infrared-Based_People_Counting_WACVW_2024_paper.html": {
    "title": "Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Latortue",
      "Moetez Kdayem",
      "Fidel A. Guerrero Peña",
      "Eric Granger",
      "Marco Pedersoli"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Lerch_Unsupervised_3D_Skeleton-Based_Action_Recognition_Using_Cross-Attention_With_Conditioned_Generation_WACVW_2024_paper.html": {
    "title": "Unsupervised 3D Skeleton-Based Action Recognition Using Cross-Attention With Conditioned Generation Capabilities",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David J. Lerch",
      "Zeyun Zhong",
      "Manuel Martin",
      "Michael Voit",
      "Jürgen Beyerer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/RWS/html/Huang_Iterative_Scale-Up_ExpansionIoU_and_Deep_Features_Association_for_Multi-Object_Tracking_WACVW_2024_paper.html": {
    "title": "Iterative Scale-Up ExpansionIoU and Deep Features Association for Multi-Object Tracking in Sports",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hsiang-Wei Huang",
      "Cheng-Yen Yang",
      "Jiacheng Sun",
      "Pyong-Kun Kim",
      "Kwang-Ju Kim",
      "Kyoungoh Lee",
      "Chung-I Huang",
      "Jenq-Neng Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Park_RealPixVSR_Pixel-Level_Visual_Representation_Informed_Super-Resolution_of_Real-World_Videos_WACVW_2024_paper.html": {
    "title": "RealPixVSR: Pixel-Level Visual Representation Informed Super-Resolution of Real-World Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tony Nokap Park",
      "Yunho Jeon",
      "Taeyoung Na"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Saini_HIDRO-VQA_High_Dynamic_Range_Oracle_for_Video_Quality_Assessment_WACVW_2024_paper.html": {
    "title": "HIDRO-VQA: High Dynamic Range Oracle for Video Quality Assessment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shreshth Saini",
      "Avinab Saha",
      "Alan C. Bovik"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Daultani_Consolidating_Separate_Degradations_Model_via_Weights_Fusion_and_Distillation_WACVW_2024_paper.html": {
    "title": "Consolidating Separate Degradations Model via Weights Fusion and Distillation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dinesh Daultani",
      "Hugo Larochelle"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Poudel_DeepLIR_Attention-Based_Approach_for_Mask-Based_Lensless_Image_Reconstruction_WACVW_2024_paper.html": {
    "title": "DeepLIR: Attention-Based Approach for Mask-Based Lensless Image Reconstruction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arpan Poudel",
      "Ukash Nakarmi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Feng_Noise-Free_Audio_Signal_Processing_in_Noisy_Environment_A_Hardware_and_WACVW_2024_paper.html": {
    "title": "Noise-Free Audio Signal Processing in Noisy Environment: A Hardware and Algorithm Solution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yarong Feng",
      "Zongyi Liu",
      "Shunyan Luo",
      "Yuan Ling",
      "Shujing Dong",
      "Shuyi Wang",
      "Bruce Ferry"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Zhao_A_Lightweight_Generalizable_Evaluation_and_Enhancement_Framework_for_Generative_Models_WACVW_2024_paper.html": {
    "title": "A Lightweight Generalizable Evaluation and Enhancement Framework for Generative Models and Generated Samples",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ganning Zhao",
      "Vasileios Magoulianitis",
      "Suya You",
      "C.-C. Jay Kuo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Bhatta_Impact_of_Blur_and_Resolution_on_Demographic_Disparities_in_1-to-Many_WACVW_2024_paper.html": {
    "title": "Impact of Blur and Resolution on Demographic Disparities in 1-to-Many Facial Identification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aman Bhatta",
      "Gabriella Pangelinan",
      "Michael C. King",
      "Kevin W. Bowyer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Sharma_Generating_Point_Cloud_Augmentations_via_Class-Conditioned_Diffusion_Model_WACVW_2024_paper.html": {
    "title": "Generating Point Cloud Augmentations via Class-Conditioned Diffusion Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gulshan Sharma",
      "Chetan Gupta",
      "Aastha Agarwal",
      "Lalit Sharma",
      "Abhinav Dhall"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Gupta_Perceptual_Synchronization_Scoring_of_Dubbed_Content_Using_Phoneme-Viseme_Agreement_WACVW_2024_paper.html": {
    "title": "Perceptual Synchronization Scoring of Dubbed Content Using Phoneme-Viseme Agreement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honey Gupta"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Lee_AutoCaCoNet_Automatic_Cartoon_Colorization_Network_Using_Self-Attention_GAN_Segmentation_and_WACVW_2024_paper.html": {
    "title": "AutoCaCoNet: Automatic Cartoon Colorization Network Using Self-Attention GAN, Segmentation, and Color Correction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungpeel Lee",
      "Eunil Park"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Freeman_Enhancing_Surveillance_Camera_FOV_Quality_via_Semantic_Line_Detection_and_WACVW_2024_paper.html": {
    "title": "Enhancing Surveillance Camera FOV Quality via Semantic Line Detection and Classification With Deep Hough Transform",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew Freeman",
      "Wenjing Shi",
      "Bin Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Wang_A_Diffusion-Based_Method_for_Multi-Turn_Compositional_Image_Generation_WACVW_2024_paper.html": {
    "title": "A Diffusion-Based Method for Multi-Turn Compositional Image Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Yuan_Inflation_With_Diffusion_Efficient_Temporal_Adaptation_for_Text-to-Video_Super-Resolution_WACVW_2024_paper.html": {
    "title": "Inflation With Diffusion: Efficient Temporal Adaptation for Text-to-Video Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Yuan",
      "Jinoo Baek",
      "Keyang Xu",
      "Omer Tov",
      "Hongliang Fei"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Ma_Super_Efficient_Neural_Network_for_Compression_Artifacts_Reduction_and_Super_WACVW_2024_paper.html": {
    "title": "Super Efficient Neural Network for Compression Artifacts Reduction and Super Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Ma",
      "Qiuwen Lou",
      "Arman Kazemi",
      "Julian Faraone",
      "Tariq Afzal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Denize_COMEDIAN_Self-Supervised_Learning_and_Knowledge_Distillation_for_Action_Spotting_Using_WACVW_2024_paper.html": {
    "title": "COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting Using Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julien Denize",
      "Mykola Liashuha",
      "Jaonary Rabarisoa",
      "Astrid Orcesi",
      "Romain Hérault"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Shrestha_Self-Supervised_Pre-Training_for_Semantic_Segmentation_in_an_Indoor_Scene_WACVW_2024_paper.html": {
    "title": "Self-Supervised Pre-Training for Semantic Segmentation in an Indoor Scene",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sulabh Shrestha",
      "Yimeng Li",
      "Jana Košecká"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Fang_E-ViLM_Efficient_Video-Language_Model_via_Masked_Video_Modeling_With_Semantic_WACVW_2024_paper.html": {
    "title": "E-ViLM: Efficient Video-Language Model via Masked Video Modeling With Semantic Vector-Quantized Tokenizer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Fang",
      "Skyler Zheng",
      "Vasu Sharma",
      "Robinson Piramuthu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Katageri_Metric_Learning_for_3D_Point_Clouds_Using_Optimal_Transport_WACVW_2024_paper.html": {
    "title": "Metric Learning for 3D Point Clouds Using Optimal Transport",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Katageri",
      "Srinjay Sarkar",
      "Charu Sharma"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Seth_Does_the_Fairness_of_Your_Pre-Training_Hold_Up_Examining_the_WACVW_2024_paper.html": {
    "title": "Does the Fairness of Your Pre-Training Hold Up? Examining the Influence of Pre-Training Techniques on Skin Tone Bias in Skin Lesion Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratinav Seth",
      "Abhilash K. Pai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Nanduri_Semi-Supervised_Cross-Spectral_Face_Recognition_With_Small_Datasets_WACVW_2024_paper.html": {
    "title": "Semi-Supervised Cross-Spectral Face Recognition With Small Datasets",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anirudh Nanduri",
      "Rama Chellappa"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Li_Labeling_Indoor_Scenes_With_Fusion_of_Out-of-the-Box_Perception_Models_WACVW_2024_paper.html": {
    "title": "Labeling Indoor Scenes With Fusion of Out-of-the-Box Perception Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yimeng Li",
      "Navid Rajabi",
      "Sulabh Shrestha",
      "Reza Alimoor",
      "Jana Košecká"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Zielinski_RDIR_Capturing_Temporally-Invariant_Representations_of_Multiple_Objects_in_Videos_WACVW_2024_paper.html": {
    "title": "RDIR: Capturing Temporally-Invariant Representations of Multiple Objects in Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piotr Zieliński",
      "Tomasz Kajdanowicz"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Mei_SLVP_Self-Supervised_Language-Video_Pre-Training_for_Referring_Video_Object_Segmentation_WACVW_2024_paper.html": {
    "title": "SLVP: Self-Supervised Language-Video Pre-Training for Referring Video Object Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Mei",
      "AJ Piergiovanni",
      "Jenq-Neng Hwang",
      "Wei Li"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Zhang_How_Does_Contrastive_Learning_Organize_Images_WACVW_2024_paper.html": {
    "title": "How Does Contrastive Learning Organize Images?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunzhe Zhang",
      "Yao Lu",
      "Qi Xuan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Yamagiwa_Zero-Shot_Edge_Detection_With_SCESAME_Spectral_Clustering-Based_Ensemble_for_Segment_WACVW_2024_paper.html": {
    "title": "Zero-Shot Edge Detection With SCESAME: Spectral Clustering-Based Ensemble for Segment Anything Model Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hiroaki Yamagiwa",
      "Yusuke Takase",
      "Hiroyuki Kambe",
      "Ryosuke Nakamoto"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Rizzoli_Source-Free_Domain_Adaptation_for_RGB-D_Semantic_Segmentation_With_Vision_Transformers_WACVW_2024_paper.html": {
    "title": "Source-Free Domain Adaptation for RGB-D Semantic Segmentation With Vision Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giulia Rizzoli",
      "Donald Shenaj",
      "Pietro Zanuttigh"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Panta_Cross-Modal_Contrastive_Learning_With_Asymmetric_Co-Attention_Network_for_Video_Moment_WACVW_2024_paper.html": {
    "title": "Cross-Modal Contrastive Learning With Asymmetric Co-Attention Network for Video Moment Retrieval",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Love Panta",
      "Prashant Shrestha",
      "Brabeem Sapkota",
      "Amrita Bhattarai",
      "Suresh Manandhar",
      "Anand Kumar Sah"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Lekkala_Evaluating_Pretrained_Models_for_Deployable_Lifelong_Learning_WACVW_2024_paper.html": {
    "title": "Evaluating Pretrained Models for Deployable Lifelong Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiran Lekkala",
      "Eshan Bhargava",
      "Laurent Itti"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Rangel_A_Unified_Framework_for_Cropland_Field_Boundary_Detection_and_Segmentation_WACVW_2024_paper.html": {
    "title": "A Unified Framework for Cropland Field Boundary Detection and Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rodrigo Fill Rangel",
      "Vítor Nascimento Lourenço",
      "Lucas Volochen Oldoni",
      "Ana Flavia Carrara Bonamigo",
      "Wallas Santos",
      "Bruno Silva Oliveira",
      "Mateus Neves Barreto"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Peng_MLP_Kernel-Based_To_Predict_the_Optimal_Conditions_of_Transglutaminase_on_WACVW_2024_paper.html": {
    "title": "MLP Kernel-Based To Predict the Optimal Conditions of Transglutaminase on Protein Polymerization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zengyan Peng",
      "Miao-Hsin Hsu",
      "Dong-Meau Chang",
      "Chun-Chi Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Liu_The_Optimizated_CIELAB_Colour_Model_for_All-Analog_Photoelectronic_High_Speed_WACVW_2024_paper.html": {
    "title": "The Optimizated CIELAB Colour Model for All-Analog Photoelectronic High Speed Vision-Task Chip (ACCEL) by Creative Computing Approach",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinwei Liu",
      "Yuchen Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Yang_Security_and_Privacy_Concerns_in_Information_Usability_WACVW_2024_paper.html": {
    "title": "Security and Privacy Concerns in Information Usability",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang-Chih Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Tang_Consumer_Evaluation_Using_Machine_Learning_for_the_Predictive_Analysis_of_WACVW_2024_paper.html": {
    "title": "Consumer Evaluation Using Machine Learning for the Predictive Analysis of Consumer Purchase Indicators",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "BaoFu Tang",
      "Dong-Meau Chang",
      "Junjie Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Quelennec_Towards_On-Device_Learning_on_the_Edge_Ways_To_Select_Neurons_WACVW_2024_paper.html": {
    "title": "Towards On-Device Learning on the Edge: Ways To Select Neurons To Update Under a Budget Constraint",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aël Quélennec",
      "Enzo Tartaglione",
      "Pavlo Mozharovskyi",
      "Van-Tam Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Zhang_Image_Detection_of_Rare_Orthopedic_Diseases_Based_on_Explainable_AI_WACVW_2024_paper.html": {
    "title": "Image Detection of Rare Orthopedic Diseases Based on Explainable AI",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi-Xiang Zhang",
      "Shun-Ping Wang",
      "Yu-Wei Chan",
      "Chih-Hung Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Liang_Semi-Supervised_SPO_Tree_Classifier_Based_on_the_DPC_Framework_WACVW_2024_paper.html": {
    "title": "Semi-Supervised SPO Tree Classifier Based on the DPC Framework",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhou Liang",
      "Liqiong Lu",
      "Junjie Yang",
      "Weiming Hong",
      "Dong-Meau Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Hsu_Designing_a_Secure_and_Scalable_Service_Model_Using_Blockchain_and_WACVW_2024_paper.html": {
    "title": "Designing a Secure and Scalable Service Model Using Blockchain and MQTT for IoT Devices",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tse-Chuan Hsu",
      "Han-Sheng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Yang_Colour_Creation_Muse_CCM_Focusing_on_Primary_Colours_for_an_WACVW_2024_paper.html": {
    "title": "Colour Creation Muse (CCM): Focusing on Primary Colours for an Imagination Based Creativity Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongji Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/SCIoT/html/Tsai_An_Effective_Deep_Neural_Network_in_Edge_Computing_Enabled_Internet_WACVW_2024_paper.html": {
    "title": "An Effective Deep Neural Network in Edge Computing Enabled Internet of Things for Plant Diseases Monitoring",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao-Hong Tsai",
      "Tse-Chuan Hsu"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/DACL/html/Flotzinger_Dacl-Challenge_Semantic_Segmentation_During_Visual_Bridge_Inspections_WACVW_2024_paper.html": {
    "title": "Dacl-Challenge: Semantic Segmentation During Visual Bridge Inspections",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes Flotzinger",
      "Philipp J. Rösch",
      "Christian Benz",
      "Muneer Ahmad",
      "Murat Cankaya",
      "Helmut Mayer",
      "Volker Rodehorst",
      "Norbert Oswald",
      "Thomas Braml"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/PRAW/html/Kikuchi_Self-Supervised_Human-Object_Interaction_of_Complex_Scenes_With_Context-Aware_Mixing_Towards_WACVW_2024_paper.html": {
    "title": "Self-Supervised Human-Object Interaction of Complex Scenes With Context-Aware Mixing: Towards In-Store Consumer Behavior Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takashi Kikuchi",
      "Shun Takeuchi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/PRAW/html/Bhattacharya_PMTL_A_Progressive_Multi-Level_Training_Framework_for_Retail_Taxonomy_Classification_WACVW_2024_paper.html": {
    "title": "PMTL: A Progressive Multi-Level Training Framework for Retail Taxonomy Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaurab Bhattacharya",
      "Gaurav Sharma",
      "Kallol Chatterjee",
      "Chakrapani",
      "Bagya Lakshmi V",
      "Jayavardhana Gubbi",
      "Arpan Pal",
      "Ramachandran Rajagopalan"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CDL/html/Luckett_The_SARFish_Dataset_and_Challenge_WACVW_2024_paper.html": {
    "title": "The SARFish Dataset and Challenge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Connor Luckett",
      "Benjamin McCarthy",
      "Tri-Tan Cao",
      "Antonio Robles-Kelly"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/3D4Science/html/de_Chanlatte_Proceedings_of_the_Workshop_on_3D_Geometry_Generation_for_Scientific_WACVW_2024_paper.html": {
    "title": "Proceedings of the Workshop on 3D Geometry Generation for Scientific Computing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marissa Ramirez de Chanlatte",
      "Phil Colella",
      "Trevor Darrell",
      "Alexandra Katherine Carlson",
      "Peter H. N. de With",
      "Huayu Deng",
      "Shanyan Guan",
      "James Hays",
      "Tim Houben",
      "Thomas Huisman",
      "Nikita Jaipuria",
      "Hans Johansen",
      "Shuja Khalid",
      "Akshay Krishnan",
      "Chuming Li",
      "Maxim Pisarenco",
      "Amit Raj",
      "Frank Rudzicz",
      "Tim J. Schoonbeek",
      "Sandhya Sridhar",
      "Nathan Tseng",
      "Fons van der Sommen",
      "Chen Wang",
      "Yunbo Wang",
      "Tong Wu",
      "Xiaokang Yang",
      "Jiawei Yao",
      "Derek Young",
      "Xianling Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4EO/html/Straka_Modernized_Training_of_U-Net_for_Aerial_Semantic_Segmentation_WACVW_2024_paper.html": {
    "title": "Modernized Training of U-Net for Aerial Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jakub Straka",
      "Ivan Gruber"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4EO/html/Khomiakov_GAST_Geometry-Aware_Structure_Transformer_WACVW_2024_paper.html": {
    "title": "GAST: Geometry-Aware Structure Transformer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxim Khomiakov",
      "Michael Riis Andersen",
      "Jes Frellsen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4EO/html/Zhu_TinyWT_A_Large-Scale_Wind_Turbine_Dataset_of_Satellite_Images_for_WACVW_2024_paper.html": {
    "title": "TinyWT: A Large-Scale Wind Turbine Dataset of Satellite Images for Tiny Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingye Zhu",
      "Zhicheng Yang",
      "Hang Zhou",
      "Chen Du",
      "Andy Wong",
      "Yibing Wei",
      "Zhuo Deng",
      "Mei Han",
      "Jui-Hsin Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/CV4EO/html/Zhang_CNet_A_Novel_Seabed_Coral_Reef_Image_Segmentation_Approach_Based_WACVW_2024_paper.html": {
    "title": "CNet: A Novel Seabed Coral Reef Image Segmentation Approach Based on Deep Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanqi Zhang",
      "Ming Li",
      "Jiageng Zhong",
      "Jiangying Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Yang_Sea_You_Later_Metadata-Guided_Long-Term_Re-Identification_for_UAV-Based_Multi-Object_Tracking_WACVW_2024_paper.html": {
    "title": "Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based Multi-Object Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng-Yen Yang",
      "Hsiang-Wei Huang",
      "Zhongyu Jiang",
      "Heng-Cheng Kuo",
      "Jie Mei",
      "Chung-I Huang",
      "Jenq-Neng Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Chowdhury_Active_Learning_Strategy_Using_Contrastive_Learning_and_K-Means_for_Aquatic_WACVW_2024_paper.html": {
    "title": "Active Learning Strategy Using Contrastive Learning and K-Means for Aquatic Invasive Species Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaif Chowdhury",
      "Greg Hamerly",
      "Monica McGarrity"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Savathrakis_An_Automated_Method_for_the_Creation_of_Oriented_Bounding_Boxes_WACVW_2024_paper.html": {
    "title": "An Automated Method for the Creation of Oriented Bounding Boxes in Remote Sensing Ship Detection Datasets",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giorgos Savathrakis",
      "Antonis Argyros"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Tran_SafeSea_Synthetic_Data_Generation_for_Adverse__Low_Probability_Maritime_WACVW_2024_paper.html": {
    "title": "SafeSea: Synthetic Data Generation for Adverse & Low Probability Maritime Conditions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Tran",
      "Jordan Shipard",
      "Hermawan Mulyono",
      "Arnold Wiliem",
      "Clinton Fookes"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Kiefer_2nd_Workshop_on_Maritime_Computer_Vision_MaCVi_2024_Challenge_Results_WACVW_2024_paper.html": {
    "title": "2nd Workshop on Maritime Computer Vision (MaCVi) 2024: Challenge Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Kiefer",
      "Lojze Žust",
      "Matej Kristan",
      "Janez Perš",
      "Matija Teršek",
      "Arnold Wiliem",
      "Martin Messmer",
      "Cheng-Yen Yang",
      "Hsiang-Wei Huang",
      "Zhongyu Jiang",
      "Heng-Cheng Kuo",
      "Jie Mei",
      "Jenq-Neng Hwang",
      "Daniel Stadler",
      "Lars Sommer",
      "Kaer Huang",
      "Aiguo Zheng",
      "Weitu Chong",
      "Kanokphan Lertniphonphan",
      "Jun Xie",
      "Feng Chen",
      "Jian Li",
      "Zhepeng Wang",
      "Luca Zedda",
      "Andrea Loddo",
      "Cecilia Di Ruberto",
      "Tuan-Anh Vu",
      "Hai Nguyen-Truong",
      "Tan-Sang Ha",
      "Quan-Dung Pham",
      "Sai-Kit Yeung",
      "Yuan Feng",
      "Nguyen Thanh Thien",
      "Lixin Tian",
      "Andreas Michel",
      "Wolfgang Gross",
      "Martin Weinmann",
      "Borja Carrillo-Perez",
      "Alexander Klein",
      "Antje Alex",
      "Edgardo Solano-Carrillo",
      "Yannik Steiniger",
      "Angel Bueno Rodriguez",
      "Sheng-Yao Kuan",
      "Yuan-Hao Ho",
      "Felix Sattler",
      "Matej Fabijanić",
      "Magdalena Šimunec",
      "Nadir Kapetanović"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Gulsoylu_Image_and_AIS_Data_Fusion_Technique_for_Maritime_Computer_Vision_WACVW_2024_paper.html": {
    "title": "Image and AIS Data Fusion Technique for Maritime Computer Vision Applications",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emre Gülsoylu",
      "Paul Koch",
      "Mert Yildiz",
      "Manfred Constapel",
      "André Peter Kelm"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MaCVi/html/Trinh_SeaDSC_A_Video-Based_Unsupervised_Method_for_Dynamic_Scene_Change_Detection_WACVW_2024_paper.html": {
    "title": "SeaDSC: A Video-Based Unsupervised Method for Dynamic Scene Change Detection in Unmanned Surface Vehicles",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linh Trinh",
      "Ali Anwar",
      "Siegfried Mercelis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/FRCSyn/html/Melzi_FRCSyn_Challenge_at_WACV_2024_Face_Recognition_Challenge_in_the_WACVW_2024_paper.html": {
    "title": "FRCSyn Challenge at WACV 2024: Face Recognition Challenge in the Era of Synthetic Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pietro Melzi",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Minchul Kim",
      "Christian Rathgeb",
      "Xiaoming Liu",
      "Ivan DeAndres-Tame",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia",
      "Weisong Zhao",
      "Xiangyu Zhu",
      "Zheyu Yan",
      "Xiao-Yu Zhang",
      "Jinlin Wu",
      "Zhen Lei",
      "Suvidha Tripathi",
      "Mahak Kothari",
      "Md Haider Zama",
      "Debayan Deb",
      "Bernardo Biesseck",
      "Pedro Vidal",
      "Roger Granada",
      "Guilherme Fickel",
      "Gustavo Führ",
      "David Menotti",
      "Alexander Unnervik",
      "Anjith George",
      "Christophe Ecabert",
      "Hatef Otroshi Shahreza",
      "Parsa Rahimi",
      "Sébastien Marcel",
      "Ioannis Sarridis",
      "Christos Koutlis",
      "Georgia Baltsou",
      "Symeon Papadopoulos",
      "Christos Diou",
      "Nicolò Di Domenico",
      "Guido Borghi",
      "Lorenzo Pellegrini",
      "Enrique Mas-Candela",
      "Ángela Sánchez-Pérez",
      "Andrea Atzori",
      "Fadi Boutros",
      "Naser Damer",
      "Gianni Fenu",
      "Mirko Marras"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Yang_Human-Centric_Autonomous_Systems_With_LLMs_for_User_Command_Reasoning_WACVW_2024_paper.html": {
    "title": "Human-Centric Autonomous Systems With LLMs for User Command Reasoning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Yang",
      "Qingwen Zhang",
      "Ci Li",
      "Daniel Simões Marta",
      "Nazre Batool",
      "John Folkesson"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Shubodh_LIP-Loc_LiDAR_Image_Pretraining_for_Cross-Modal_Localization_WACVW_2024_paper.html": {
    "title": "LIP-Loc: LiDAR Image Pretraining for Cross-Modal Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Shubodh",
      "Mohammad Omama",
      "Husain Zaidi",
      "Udit Singh Parihar",
      "Madhava Krishna"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Cui_A_Survey_on_Multimodal_Large_Language_Models_for_Autonomous_Driving_WACVW_2024_paper.html": {
    "title": "A Survey on Multimodal Large Language Models for Autonomous Driving",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Can Cui",
      "Yunsheng Ma",
      "Xu Cao",
      "Wenqian Ye",
      "Yang Zhou",
      "Kaizhao Liang",
      "Jintai Chen",
      "Juanwu Lu",
      "Zichong Yang",
      "Kuei-Da Liao",
      "Tianren Gao",
      "Erlong Li",
      "Kun Tang",
      "Zhipeng Cao",
      "Tong Zhou",
      "Ao Liu",
      "Xinrui Yan",
      "Shuqi Mei",
      "Jianguo Cao",
      "Ziran Wang",
      "Chao Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Park_VLAAD_Vision_and_Language_Assistant_for_Autonomous_Driving_WACVW_2024_paper.html": {
    "title": "VLAAD: Vision and Language Assistant for Autonomous Driving",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "SungYeon Park",
      "MinJae Lee",
      "JiHyuk Kang",
      "Hahyeon Choi",
      "Yoonah Park",
      "Juhwan Cho",
      "Adam Lee",
      "DongKyu Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Cui_Drive_As_You_Speak_Enabling_Human-Like_Interaction_With_Large_Language_WACVW_2024_paper.html": {
    "title": "Drive As You Speak: Enabling Human-Like Interaction With Large Language Models in Autonomous Vehicles",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Can Cui",
      "Yunsheng Ma",
      "Xu Cao",
      "Wenqian Ye",
      "Ziran Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Inoue_NuScenes-MQA_Integrated_Evaluation_of_Captions_and_QA_for_Autonomous_Driving_WACVW_2024_paper.html": {
    "title": "NuScenes-MQA: Integrated Evaluation of Captions and QA for Autonomous Driving Datasets Using Markup Annotations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuichi Inoue",
      "Yuki Yada",
      "Kotaro Tanahashi",
      "Yu Yamaguchi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Zampokas_Latency_Driven_Spatially_Sparse_Optimization_for_Multi-Branch_CNNs_for_Semantic_WACVW_2024_paper.html": {
    "title": "Latency Driven Spatially Sparse Optimization for Multi-Branch CNNs for Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georgios Zampokas",
      "Christos-Savvas Bouganis",
      "Dimitrios Tzovaras"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Zhong_A_Safer_Vision-Based_Autonomous_Planning_System_for_Quadrotor_UAVs_With_WACVW_2024_paper.html": {
    "title": "A Safer Vision-Based Autonomous Planning System for Quadrotor UAVs With Dynamic Obstacle Trajectory Prediction and Its Application With LLMs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiageng Zhong",
      "Ming Li",
      "Yinliang Chen",
      "Zihang Wei",
      "Fan Yang",
      "Haoran Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/ASTAD/html/Nizan_K-NNN_Nearest_Neighbors_of_Neighbors_for_Anomaly_Detection_WACVW_2024_paper.html": {
    "title": "K-NNN: Nearest Neighbors of Neighbors for Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ori Nizan",
      "Ayellet Tal"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/ASTAD/html/Noghre_An_Exploratory_Study_on_Human-Centric_Video_Anomaly_Detection_Through_Variational_WACVW_2024_paper.html": {
    "title": "An Exploratory Study on Human-Centric Video Anomaly Detection Through Variational Autoencoders and Trajectory Prediction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Hamed Tabkhi"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Jauhari_Iris_Presentation_Attack_Assessing_the_Impact_of_Combining_Vanadium_Dioxide_WACVW_2024_paper.html": {
    "title": "Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films With Artificial Eyes",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Darshika Jauhari",
      "Renu Sharma",
      "Cunjian Chen",
      "Nelson Sepulveda",
      "Arun Ross"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Medvedev_Fused_Classification_for_Differential_Face_Morphing_Detection_WACVW_2024_paper.html": {
    "title": "Fused Classification for Differential Face Morphing Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iurii Medvedev",
      "Joana Alves Pimenta",
      "Nuno Gonçalves"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Ivanovska_On_the_Vulnerability_of_Deepfake_Detectors_to_Attacks_Generated_by_WACVW_2024_paper.html": {
    "title": "On the Vulnerability of Deepfake Detectors to Attacks Generated by Denoising Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marija Ivanovska",
      "Vitomir Struc"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Li_Does_Capture_Background_Influence_the_Accuracy_of_the_Deep_Learning_WACVW_2024_paper.html": {
    "title": "Does Capture Background Influence the Accuracy of the Deep Learning Based Fingerphoto Presentation Attack Detection Techniques?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hailin Li",
      "Raghavendra Ramachandra"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Ciamarra_Deepfake_Detection_by_Exploiting_Surface_Anomalies_The_SurFake_Approach_WACVW_2024_paper.html": {
    "title": "Deepfake Detection by Exploiting Surface Anomalies: The SurFake Approach",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Ciamarra",
      "Roberto Caldelli",
      "Federico Becattini",
      "Lorenzo Seidenari",
      "Alberto Del Bimbo"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Sharma_Investigating_Weight-Perturbed_Deep_Neural_Networks_With_Application_in_Iris_Presentation_WACVW_2024_paper.html": {
    "title": "Investigating Weight-Perturbed Deep Neural Networks With Application in Iris Presentation Attack Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renu Sharma",
      "Redwan Sony",
      "Arun Ross"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Bhuiyan_Forensic_Iris_Image_Synthesis_WACVW_2024_paper.html": {
    "title": "Forensic Iris Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rasel Ahmed Bhuiyan",
      "Adam Czajka"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Banerjee_Alpha-Wolves_and_Alpha-Mammals_Exploring_Dictionary_Attacks_on_Iris_Recognition_Systems_WACVW_2024_paper.html": {
    "title": "Alpha-Wolves and Alpha-Mammals: Exploring Dictionary Attacks on Iris Recognition Systems",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sudipta Banerjee",
      "Anubhav Jain",
      "Zehua Jiang",
      "Nasir Memon",
      "Julian Togelius",
      "Arun Ross"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Seraj_Semi-Supervised_Deep_Domain_Adaptation_for_Deepfake_Detection_WACVW_2024_paper.html": {
    "title": "Semi-Supervised Deep Domain Adaptation for Deepfake Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Shamim Seraj",
      "Ankita Singh",
      "Shayok Chakraborty"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/WVLL/html/Nasim_Fog-Resilient_Bangla_Car_Plate_Recognition_Using_Dark_Channel_Prior_and_WACVW_2024_paper.html": {
    "title": "Fog-Resilient Bangla Car Plate Recognition Using Dark Channel Prior and YOLO",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hamim Ibne Nasim",
      "Fateha Jannat Printia",
      "Mahamudul Hasan",
      "Rubaba Rashid",
      "Iffat Jahan Chowdhury",
      "Joyanta Jyoti Mondal",
      "Md. Farhadul Islam",
      "Jannatun Noor"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/WVLL/html/Rabby_Enhancement_of_Bengali_OCR_by_Specialized_Models_and_Advanced_Techniques_WACVW_2024_paper.html": {
    "title": "Enhancement of Bengali OCR by Specialized Models and Advanced Techniques for Diverse Document Types",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "AKM Shahariar Azad Rabby",
      "Hasmot Ali",
      "Md. Majedul Islam",
      "Sheikh Abujar",
      "Fuad Rahman"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/WVLL/html/Fayyazsanavi_Fingerspelling_PoseNet_Enhancing_Fingerspelling_Translation_With_Pose-Based_Transformer_Models_WACVW_2024_paper.html": {
    "title": "Fingerspelling PoseNet: Enhancing Fingerspelling Translation With Pose-Based Transformer Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pooya Fayyazsanavi",
      "Negar Nejatishahidin",
      "Jana Košecká"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/DVPBA/html/Rezgui_Enhancing_Soft_Biometric_Face_Template_Privacy_With_Mutual_Information-Based_Image_WACVW_2024_paper.html": {
    "title": "Enhancing Soft Biometric Face Template Privacy With Mutual Information-Based Image Attacks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zohra Rezgui",
      "Nicola Strisciuglio",
      "Raymond Veldhuis"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/DVPBA/html/Kotwal_Mitigating_Demographic_Bias_in_Face_Recognition_via_Regularized_Score_Calibration_WACVW_2024_paper.html": {
    "title": "Mitigating Demographic Bias in Face Recognition via Regularized Score Calibration",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ketan Kotwal",
      "Sébastien Marcel"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/DVPBA/html/Wu_Facial_Hair_Area_in_Face_Recognition_Across_Demographics_Small_Size_WACVW_2024_paper.html": {
    "title": "Facial Hair Area in Face Recognition Across Demographics: Small Size, Big Effect",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiyu Wu",
      "Sicong Tian",
      "Aman Bhatta",
      "Kağan Öztürk",
      "Karl Ricanek",
      "Kevin W. Bowyer"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/DVPBA/html/Merino_Who_Wore_It_Best_And_Who_Paid_Less_Effects_of_WACVW_2024_paper.html": {
    "title": "Who Wore It Best? And Who Paid Less? Effects of Privacy-Preserving Techniques Across Demographics",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xavier Merino",
      "Michael King"
    ]
  },
  "https://openaccess.thecvf.com/content/WACV2024W/DVPBA/html/Pangelinan_The_CHROMA-FIT_Dataset_Characterizing_Human_Ranges_of_Melanin_for_Increased_WACVW_2024_paper.html": {
    "title": "The CHROMA-FIT Dataset: Characterizing Human Ranges of Melanin for Increased Tone-Awareness",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriella Pangelinan",
      "Xavier Merino",
      "Samuel Langborgh",
      "Kushal Vangara",
      "Joyce Annan",
      "Audison Beaubrun",
      "Troy Weekes",
      "Michael C. King"
    ]
  }
}