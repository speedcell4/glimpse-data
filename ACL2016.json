{
  "https://aclanthology.org/P16-1001": {
    "title": "Noise reduction and targeted exploration in imitation learning for Abstract Meaning Representation parsing",
    "abstract": "Semantic parsers map natural language statements into meaning representations, and must abstract over syntactic phenomena, resolve anaphora, and identify word senses to eliminate ambiguous interpretations. Abstract meaning representation (AMR) is a recent example of one such semantic formalism which, similar to a dependency parse, utilizes a graph to represent relationships between concepts (Banarescu et al., 2013). As with dependency parsing, transition-based approaches are a common approach to this problem. However, when trained in the traditional manner these systems are susceptible to the accumulation of errors when they find undesirable states during greedy decoding. Imitation learning algorithms have been shown to help these systems recover from such errors. To effectively use these methods for AMR parsing we find it highly beneficial to introduce two novel extensions: noise reduction and targeted exploration. The former mitigates the noise in the feature representation, a result of the complexity of the task. The latter targets the exploration steps of imitation learning towards areas which are likely to provide the most information in the context of a large action-space. We achieve state-ofthe art results, and improve upon standard transition-based parsing by 4.7 F1 points",
    "volume": "long",
    "checked": true,
    "id": "49af035c598901fbf766da2cfb040cca7336a8ac",
    "citation_count": 48
  },
  "https://aclanthology.org/P16-1002": {
    "title": "Data Recombination for Neural Semantic Parsing",
    "abstract": "Modeling crisp logical regularities is crucial in semantic parsing, making it difficult for neural models with no task-specific prior knowledge to achieve good results. In this paper, we introduce data recombination, a novel framework for injecting such prior knowledge into a model. From the training data, we induce a high-precision synchronous context-free grammar, which captures important conditional independence properties commonly found in semantic parsing. We then train a sequence-to-sequence recurrent network (RNN) model with a novel attention-based copying mechanism on datapoints sampled from this grammar, thereby teaching the model about these structural properties. Data recombination improves the accuracy of our RNN model on three semantic parsing datasets, leading to new state-of-the-art performance on the standard GeoQuery dataset for models with comparable supervision",
    "volume": "long",
    "checked": true,
    "id": "b7eac64a8410976759445cce235469163d23ee65",
    "citation_count": 406
  },
  "https://aclanthology.org/P16-1003": {
    "title": "Inferring Logical Forms From Denotations",
    "abstract": "A core problem in learning semantic parsers from denotations is picking out consistent logical forms--those that yield the correct denotation--from a combinatorially large space. To control the search space, previous work relied on restricted set of rules, which limits expressivity. In this paper, we consider a much more expressive class of logical forms, and show how to use dynamic programming to efficiently represent the complete set of consistent logical forms. Expressivity also introduces many more spurious logical forms which are consistent with the correct denotation but do not represent the meaning of the utterance. To address this, we generate fictitious worlds and use crowdsourced denotations on these worlds to filter out spurious logical forms. On the WikiTableQuestions dataset, we increase the coverage of answerable questions from 53.5% to 76%, and the additional crowdsourced supervision lets us rule out 92.1% of spurious logical forms",
    "volume": "long",
    "checked": true,
    "id": "2d6cd38755e2cf2bd43e75c532a201e20ede128b",
    "citation_count": 54
  },
  "https://aclanthology.org/P16-1004": {
    "title": "Language to Logical Form with Neural Attention",
    "abstract": "Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domain- or representation-specific. In this paper we present a general method based on an attention-enhanced encoder-decoder model. We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations",
    "volume": "long",
    "checked": true,
    "id": "558ac446dc26bee9789d660a251b75728cb6eeb2",
    "citation_count": 607
  },
  "https://aclanthology.org/P16-1005": {
    "title": "Unsupervised Person Slot Filling based on Graph Mining",
    "abstract": "Slot filling aims to extract the values (slot fillers) of specific attributes (slots types) for a given entity (query) from a largescale corpus. Slot filling remains very challenging over the past seven years. We propose a simple yet effective unsupervised approach to extract slot fillers based on the following two observations: (1) a trigger is usually a salient node relative to the query and filler nodes in the dependency graph of a context sentence; (2) a relation is likely to exist if the query and candidate filler nodes are strongly connected by a relation-specific trigger. Thus we design a graph-based algorithm to automatically identify triggers based on personalized PageRank and Affinity Propagation for a given (query, filler) pair and then label the slot type based on the identified triggers. Our approach achieves 11.6%-25% higher F-score over state-ofthe-art English slot filling methods. Our experiments also demonstrate that as long as a few trigger seeds, name tagging and dependency parsing capabilities exist, this approach can be quickly adapted to any language and new slot types. Our promising results on Chinese slot filling can serve as a new benchmark",
    "volume": "long",
    "checked": true,
    "id": "2909e53b5abab88da090b84964ee1758ad7ad0e2",
    "citation_count": 24
  },
  "https://aclanthology.org/P16-1006": {
    "title": "A Multi-media Approach to Cross-lingual Entity Knowledge Transfer",
    "abstract": "When a large-scale incident or disaster occurs, there is often a great demand for rapidly developing a system to extract detailed and new information from lowresource languages (LLs). We propose a novel approach to discover comparable documents in high-resource languages (HLs), and project Entity Discovery and Linking results from HLs documents back to LLs. We leverage a wide variety of language-independent forms from multiple data modalities, including image processing (image-to-image retrieval, visual similarity and face recognition) and sound matching. We also propose novel methods to learn entity priors from a large-scale HL corpus and knowledge base. Using Hausa and Chinese as the LLs and English as the HL, experiments show that our approach achieves 36.1% higher Hausa name tagging F-score over a costly supervised model, and 9.4% higher Chineseto-English Entity Linking accuracy over state-of-the-art",
    "volume": "long",
    "checked": true,
    "id": "a3240c680cb26e6e4a398253e5cfd5c2e4e4d2da",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-1007": {
    "title": "Models and Inference for Prefix-Constrained Machine Translation",
    "abstract": "We apply phrase-based and neural models to a core task in interactive machine translation: suggesting how to complete a partial translation. For the phrase-based system, we demonstrate improvements in suggestion quality using novel objective functions, learning techniques, and inference algorithms tailored to this task. Our contributions include new tunable metrics, an improved beam search strategy, an n-best extraction method that increases suggestion diversity, and a tuning procedure for a hierarchical joint model of alignment and translation. The combination of these techniques improves next-word suggestion accuracy dramatically from 28.5% to 41.2% in a large-scale English-German experiment. Our recurrent neural translation system increases accuracy yet further to 53.0%, but inference is two orders of magnitude slower. Manual error analysis shows the strengths and weaknesses of both approaches",
    "volume": "long",
    "checked": true,
    "id": "29260b18158c7207c10155024e05a7348da9e241",
    "citation_count": 49
  },
  "https://aclanthology.org/P16-1008": {
    "title": "Modeling Coverage for Neural Machine Translation",
    "abstract": "Attention mechanism has enhanced state-of-the-art Neural Machine Translation (NMT) by jointly learning to align and translate. It tends to ignore past alignment information, however, which often leads to over-translation and under-translation. To address this problem, we propose coverage-based NMT in this paper. We maintain a coverage vector to keep track of the attention history. The coverage vector is fed to the attention model to help adjust future attention, which lets NMT system to consider more about untranslated source words. Experiments show that the proposed approach significantly improves both translation quality and alignment quality over standard attention-based NMT",
    "volume": "long",
    "checked": true,
    "id": "33108287fbc8d94160787d7b2c7ef249d3ad6437",
    "citation_count": 665
  },
  "https://aclanthology.org/P16-1009": {
    "title": "Improving Neural Machine Translation Models with Monolingual Data",
    "abstract": "Neural Machine Translation (NMT) has obtained state-of-the art performance for several language pairs, while only using parallel data for training. Target-side monolingual data plays an important role in boosting fluency for phrase-based statistical machine translation, and we investigate the use of monolingual data for NMT. In contrast to previous work, which combines NMT models with separately trained language models, we note that encoder-decoder NMT architectures already have the capacity to learn the same information as a language model, and we explore strategies to train with monolingual data without changing the neural network architecture. By pairing monolingual training data with an automatic back-translation, we can treat it as additional parallel training data, and we obtain substantial improvements on the WMT 15 task English German (+2.8-3.7 BLEU), and for the low-resourced IWSLT 14 task Turkish->English (+2.1-3.4 BLEU), obtaining new state-of-the-art results. We also show that fine-tuning on in-domain monolingual and parallel data gives substantial improvements for the IWSLT 15 task English->German",
    "volume": "long",
    "checked": true,
    "id": "f3b96ef2dc1fc5e14982f1b963db8db6a54183bb",
    "citation_count": 1976
  },
  "https://aclanthology.org/P16-1010": {
    "title": "Graph-Based Translation Via Graph Segmentation",
    "abstract": "One major drawback of phrase-based translation is that it segments an input sentence into continuous phrases. To support linguistically informed source discontinuity, in this paper we construct graphs which combine bigram and dependency relations and propose a graph-based translation model. The model segments an input graph into connected subgraphs, each of which may cover a discontinuous phrase. We use beam search to combine translations of each subgraph left-to-right to produce a complete translation. Experiments on Chinese–English and German– English tasks show that our system is significantly better than the phrase-based model by up to +1.5/+0.5 BLEU scores. By explicitly modeling the graph segmentation, our system obtains further improvement, especially on German–English",
    "volume": "long",
    "checked": true,
    "id": "38cc23f9bb433b423e665357af16c966aeb48411",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-1011": {
    "title": "Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction",
    "abstract": "As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands and to learn new actions from human language instructions. To address this issue, this paper presents an approach that explicitly represents verb semantics through hypothesis spaces of fluents and automatically acquires these hypothesis spaces by interacting with humans. The learned hypothesis spaces can be used to automatically plan for lower-level primitive actions towards physical world interaction. Our empirical results have shown that the representation of a hypothesis space of fluents, combined with the learned hypothesis selection algorithm, outperforms a previous baseline. In addition, our approach applies incremental learning, which can contribute to life-long learning from humans in the future",
    "volume": "long",
    "checked": true,
    "id": "364aa270e9fcb256c367768240c79fc3305be829",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-1012": {
    "title": "Language Transfer Learning for Supervised Lexical Substitution",
    "abstract": "We propose a framework for lexical substitution that is able to perform transfer learning across languages. Datasets for this task are available in at least three languages (English, Italian, and German). Previous work has addressed each of these tasks in isolation. In contrast, we regard the union of three shared tasks as a combined multilingual dataset. We show that a supervised system can be trained effectively, even if training and evaluation data are from different languages. Successful transfer learning between languages suggests that the learned model is in fact independent of the underlying language. We combine state-of-the-art unsupervised features obtained from syntactic word embeddings and distributional thesauri in a supervised delexicalized ranking system. Our system improves over state of the art in the full lexical substitution task in all three languages",
    "volume": "long",
    "checked": true,
    "id": "dde4033117c82f22db4d3adf4684ef7b46b5f461",
    "citation_count": 14
  },
  "https://aclanthology.org/P16-1013": {
    "title": "Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning",
    "abstract": "We use Bayesian optimization to learn curricula for word representation learning, optimizing performance on downstream tasks that depend on the learned representations as features. The curricula are modeled by a linear ranking function which is the scalar product of a learned weight vector and an engineered feature vector that characterizes the different aspects of the complexity of each instance in the training corpus. We show that learning the curriculum improves performance on a variety of downstream tasks over random orders and in comparison to the natural corpus order",
    "volume": "long",
    "checked": true,
    "id": "2af3485c32ed22911f3bb592406f56671c00aa59",
    "citation_count": 70
  },
  "https://aclanthology.org/P16-1014": {
    "title": "Pointing the Unknown Words",
    "abstract": "The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems, including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence, and the other predicts a word in the shortlist vocabulary. At each time-step, the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context.~We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.~We observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model",
    "volume": "long",
    "checked": true,
    "id": "aa5b35dcf8b024f5352db73cc3944e8fad4f3793",
    "citation_count": 478
  },
  "https://aclanthology.org/P16-1015": {
    "title": "Generalized Transition-based Dependency Parsing via Control Parameters",
    "abstract": "In this paper, we present a generalized transition-based parsing framework where parsers are instantiated in terms of a set of control parameters that constrain transitions between parser states. This generalization provides a unified framework to describe and compare various transitionbased parsing approaches from both a theoretical and empirical perspective. This includes well-known transition systems, but also previously unstudied systems",
    "volume": "long",
    "checked": true,
    "id": "53b74171f3a4205677afb3e9de057c2c92ef50be",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-1016": {
    "title": "A Transition-Based System for Joint Lexical and Syntactic Analysis",
    "abstract": "We present a transition-based system that jointly predicts the syntactic structure and lexical units of a sentence by building two structures over the input words: a syntactic dependency tree and a",
    "volume": "long",
    "checked": true,
    "id": "eaffaf8acd0c34c5754deb508ebfcee2d197c04a",
    "citation_count": 56
  },
  "https://aclanthology.org/P16-1017": {
    "title": "Neural Greedy Constituent Parsing with Dynamic Oracles",
    "abstract": "Dynamic oracle training has shown substantial improvements for dependency parsing in various settings, but has not been explored for constituent parsing. The present article introduces a dynamic oracle for transition-based constituent parsing. Experiments on the 9 languages of the SPMRL dataset show that a neural greedy parser with morphological features , trained with a dynamic oracle, leads to accuracies comparable with the best non-reranking and non-ensemble parsers",
    "volume": "long",
    "checked": true,
    "id": "b4fd524944b2e8f243ba6a140012954d16af71d2",
    "citation_count": 26
  },
  "https://aclanthology.org/P16-1018": {
    "title": "Literal and Metaphorical Senses in Compositional Distributional Semantic Models",
    "abstract": "Metaphorical expressions are pervasive in natural language and pose a substantial challenge for computational semantics. The inherent compositionality of metaphor makes it an important test case for compositional distributional semantic models (CDSMs). This paper is the first to investigate whether metaphorical composition warrants a distinct treatment in the CDSM framework. We propose a method to learn metaphors as linear transformations in a vector space and find that, across a variety of semantic domains, explicitly modeling metaphor improves the resulting semantic representations. We then use these representations in a metaphor identification task, achieving a high performance of 0.82 in terms of F-score",
    "volume": "long",
    "checked": true,
    "id": "f2ee0679ee65d21fb57dd5c9ebd9cd7dca17af0c",
    "citation_count": 53
  },
  "https://aclanthology.org/P16-1019": {
    "title": "Idiom Token Classification using Sentential Distributed Semantics",
    "abstract": "Idiom token classification is the task of deciding for a set of potentially idiomatic phrases whether each occurrence of a phrase is a literal or idiomatic usage of the phrase. In this work we explore the use of Skip-Thought Vectors to create distributed representations that encode features that are predictive with respect to idiom token classification. We show that classifiers using these representations have competitive performance compared with the state of the art in idiom token classification. Importantly, however, our models use only the sentence containing the target phrase as input and are thus less dependent on a potentially inaccurate or incomplete model of discourse context. We further demonstrate the feasibility of using these representations to train a competitive general idiom token classifier",
    "volume": "long",
    "checked": true,
    "id": "17b6456927145a72121276f06a942cf4a252dfde",
    "citation_count": 36
  },
  "https://aclanthology.org/P16-1020": {
    "title": "Adaptive Joint Learning of Compositional and Non-Compositional Phrase Embeddings",
    "abstract": "We present a novel method for jointly learning compositional and non-compositional phrase embeddings by adaptively weighting both types of embeddings using a compositionality scoring function. The scoring function is used to quantify the level of compositionality of each phrase, and the parameters of the function are jointly optimized with the objective for learning phrase embeddings. In experiments, we apply the adaptive joint learning method to the task of learning embeddings of transitive verb phrases, and show that the compositionality scores have strong correlation with human ratings for verb-object compositionality, substantially outperforming the previous state of the art. Moreover, our embeddings improve upon the previous best model on a transitive verb disambiguation task. We also show that a simple ensemble technique further improves the results for both tasks",
    "volume": "long",
    "checked": true,
    "id": "39f0fafb66e87f95a4727317c8c3287969782d75",
    "citation_count": 30
  },
  "https://aclanthology.org/P16-1021": {
    "title": "Metaphor Detection with Topic Transition, Emotion and Cognition in Context",
    "abstract": "Metaphor is a common linguistic tool in communication, making its detection in discourse a crucial task for natural language understanding. One popular approach to this challenge is to capture semantic incohesion between a metaphor and the dominant topic of the surrounding text. While these methods are effective, they tend to overclassify target words as metaphorical when they deviate in meaning from its context. We present a new approach that (1) distinguishes literal and non-literal use of target words by examining sentence-level topic transitions and (2) captures the motivation of speakers to express emotions and abstract concepts metaphorically. Experiments on an online breast cancer discussion forum dataset demonstrate a significant improvement in metaphor detection over the state-of-theart. These experimental results also reveal a tendency toward metaphor usage in personal topics and certain emotional contexts",
    "volume": "long",
    "checked": true,
    "id": "0d356807cd84ab3767d80e31350a815b82283563",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-1022": {
    "title": "Compressing Neural Language Models by Sparse Word Representations",
    "abstract": "Neural networks are among the state-of-the-art techniques for language modeling. Existing neural language models typically map discrete words to distributed, dense vector representations. After information processing of the preceding context words by hidden layers, an output layer estimates the probability of the next word. Such approaches are time- and memory-intensive because of the large numbers of parameters for word embeddings and the output layer. In this paper, we propose to compress neural language models by sparse word representations. In the experiments, the number of parameters in our model increases very slowly with the growth of the vocabulary size, which is almost imperceptible. Moreover, our approach not only reduces the parameter space to a large extent, but also improves the performance in terms of the perplexity measure",
    "volume": "long",
    "checked": true,
    "id": "a6a0946c91209001e6d179717f6a49126c836623",
    "citation_count": 26
  },
  "https://aclanthology.org/P16-1023": {
    "title": "Intrinsic Subspace Evaluation of Word Embedding Representations",
    "abstract": "We introduce a new methodology for intrinsic evaluation of word representations. Specifically, we identify four fundamental criteria based on the characteristics of natural language that pose difficulties to NLP systems; and develop tests that directly show whether or not representations contain the subspaces necessary to satisfy these criteria. Current intrinsic evaluations are mostly based on the overall similarity or full-space similarity of words and thus view vector representations as points. We show the limits of these point-based intrinsic evaluations. We apply our evaluation methodology to the comparison of a count vector model and several neural network models and demonstrate important properties of these models",
    "volume": "long",
    "checked": true,
    "id": "997825fac3f0e1eb8429a5ab83fb547f9f31de4c",
    "citation_count": 33
  },
  "https://aclanthology.org/P16-1024": {
    "title": "On the Role of Seed Lexicons in Learning Bilingual Word Embeddings",
    "abstract": "A shared bilingual word embedding space (SBWES) is an indispensable resource in a variety of cross-language NLP and IR tasks. A common approach to the SBWES induction is to learn a mapping function between monolingual semantic spaces, where the mapping critically relies on a seed word lexicon used in the learning process. In this work, we analyze the importance and properties of seed lexicons for the SBWES induction across different dimensions (i.e., lexicon source, lexicon size, translation method, translation pair reliability). On the basis of our analysis, we propose a simple but effective hybrid bilingual word embedding (BWE) model. This model (HYBWE) learns the mapping between two monolingual embedding spaces using only highly reliable symmetric translation pairs from a seed document-level embedding space. We perform bilingual lexicon learning (BLL) with 3 language pairs and show that by carefully selecting reliable translation pairs our new HYBWE model outperforms benchmarking BWE learning models, all of which use more expensive bilingual signals. Effectively, we demonstrate that a SBWES may be induced by leveraging only a very weak bilingual signal (document alignments) along with monolingual data",
    "volume": "long",
    "checked": true,
    "id": "bfb54568ddeadf62bcee04f56b72fd4dfdd23ac5",
    "citation_count": 99
  },
  "https://aclanthology.org/P16-1025": {
    "title": "Liberal Event Extraction and Event Schema Induction",
    "abstract": "We propose a brand new \"Liberal\" Event Extraction paradigm to extract events and discover event schemas from any input corpus simultaneously. We incorporate symbolic (e.g., Abstract Meaning Representation) and distributional semantics to detect and represent event structures and adopt a joint typing framework to simultaneously extract event types and argument roles and discover an event schema. Experiments on general and specific domains demonstrate that this framework can construct high-quality schemas with many event and argument role types, covering a high proportion of event types and argument roles in manually defined schemas. We show that extraction performance using discovered schemas is comparable to supervised models trained from a large amount of data labeled according to predefined event types. The extraction quality of new event types is also promising",
    "volume": "long",
    "checked": true,
    "id": "56e0ec93d19c4e2796533ce1050c8639d45c40eb",
    "citation_count": 103
  },
  "https://aclanthology.org/P16-1026": {
    "title": "Jointly Event Extraction and Visualization on Twitter via Probabilistic Modelling",
    "abstract": "Event extraction from texts aims to detect structured information such as what has happened, to whom, where and when. Event extraction and visualization are typically considered as two different tasks. In this paper, we propose a novel approach based on probabilistic modelling to jointly extract and visualize events from tweets where both tasks benefit from each other. We model each event as a joint distribution over named entities, a date, a location and event-related keywords. Moreover, both tweets and event instances are associated with coordinates in the visualization space. The manifold assumption that the intrinsic geometry of tweets is a low-rank, non-linear manifold within the high-dimensional space is incorporated into the learning framework using a regularization. Experimental results show that the proposed approach can effectively deal with both event extraction and visualization and performs remarkably better than both the state-of-the-art event extraction method and a pipeline approach for event extraction and visualization",
    "volume": "long",
    "checked": true,
    "id": "2e5c46c26c590af0b9883df1453f5f4e521d7418",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-1027": {
    "title": "Using Sentence-Level LSTM Language Models for Script Inference",
    "abstract": "There is a small but growing body of research on statistical scripts, models of event sequences that allow probabilistic inference of implicit events from documents. These systems operate on structured verb-argument events produced by an NLP pipeline. We compare these systems with recent Recurrent Neural Net models that directly operate on raw tokens to predict sentences, finding the latter to be roughly comparable to the former in terms of predicting missing events in documents",
    "volume": "long",
    "checked": true,
    "id": "9f31286c322d35fd9d8d860eef6059ac24cea89a",
    "citation_count": 64
  },
  "https://aclanthology.org/P16-1028": {
    "title": "Two Discourse Driven Language Models for Semantics",
    "abstract": "Natural language understanding often requires deep semantic knowledge. Expanding on previous proposals, we suggest that some important aspects of semantic knowledge can be modeled as a language model if done at an appropriate level of abstraction. We develop two distinct models that capture semantic frame chains and discourse information while abstracting over the specific mentions of predicates and entities. For each model, we investigate four implementations: a \"standard\" N-gram language model and three discriminatively trained \"neural\" language models that generate embeddings for semantic frames. The quality of the semantic language models (SemLM) is evaluated both intrinsically, using perplexity and a narrative cloze test and extrinsically - we show that our SemLM helps improve performance on semantic natural language processing tasks such as co-reference resolution and discourse parsing",
    "volume": "long",
    "checked": true,
    "id": "81f244048b912e739eddaf0b84a2ebc4ec226106",
    "citation_count": 37
  },
  "https://aclanthology.org/P16-1029": {
    "title": "Sentiment Domain Adaptation with Multiple Sources",
    "abstract": "Domain adaptation is an important research topic in sentiment analysis area. Existing domain adaptation methods usually transfer sentiment knowledge from only one source domain to target domain. In this paper, we propose a new domain adaptation approach which can exploit sentiment knowledge from multiple source domains. We first extract both global and domain-specific sentiment knowledge from the data of multiple source domains using multi-task learning. Then we transfer them to target domain with the help of words' sentiment polarity relations extracted from the unlabeled target domain data. The similarities between target domain and different source domains are also incorporated into the adaptation process. Experimental results on benchmark dataset show the effectiveness of our approach in improving cross-domain sentiment classification performance",
    "volume": "long",
    "checked": true,
    "id": "09f0885d1727a0b82300e94856e0be2f2f72561c",
    "citation_count": 71
  },
  "https://aclanthology.org/P16-1030": {
    "title": "Connotation Frames: A Data-Driven Investigation",
    "abstract": "Through a particular choice of a predicate (e.g., \"x violated y\"), a writer can subtly connote a range of implied sentiments and presupposed facts about the entities x and y: (1) writer's perspective: projecting x as an \"antagonist\"and y as a \"victim\", (2) entities' perspective: y probably dislikes x, (3) effect: something bad happened to y, (4) value: y is something valuable, and (5) mental state: y is distressed by the event. We introduce connotation frames as a representation formalism to organize these rich dimensions of connotation using typed relations. First, we investigate the feasibility of obtaining connotative labels through crowdsourcing experiments. We then present models for predicting the connotation frames of verb predicates based on their distributional word representations and the interplay between different types of connotative relations. Empirical results confirm that connotation frames can be induced from various data sources that reflect how people use language and give rise to the connotative meanings. We conclude with analytical results that show the potential use of connotation frames for analyzing subtle biases in online news media",
    "volume": "long",
    "checked": true,
    "id": "0c6545a75ca1f42b2f10faf2de4c5b7bec000975",
    "citation_count": 55
  },
  "https://aclanthology.org/P16-1031": {
    "title": "Bi-Transferring Deep Neural Networks for Domain Adaptation",
    "abstract": "Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). Due to the mismatch among different domains, a sentiment classifier trained in one domain may not work well when directly applied to other domains. Thus, domain adaptation for sentiment classification algorithms are highly desirable to reduce the domain discrepancy and manual labeling costs. To address the above challenge, we propose a novel domain adaptation method, called Bi-Transferring Deep Neural Networks (BTDNNs). The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also transfer the target domain examples to the source domain. The linear transformation of BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner. As a result, the transferred source domain is supervised and follows similar distribution as the target domain. Therefore, any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in a target domain. We conduct experiments on a benchmark composed of reviews of 4 types of Amazon products. Experimental results show that our proposed approach significantly outperforms the several baseline methods, and achieves an accuracy which is competitive with the state-of-the-art method for domain adaptation",
    "volume": "long",
    "checked": true,
    "id": "08bbae0615a197c5f13da527097bdd8eef100dbe",
    "citation_count": 45
  },
  "https://aclanthology.org/P16-1032": {
    "title": "Document-level Sentiment Inference with Social, Faction, and Discourse Context",
    "abstract": "We present a new approach for documentlevel sentiment inference, where the goal is to predict directed opinions (who feels positively or negatively towards whom) for all entities mentioned in a text. To encourage more complete and consistent predictions, we introduce an ILP that jointly models (1) sentenceand discourse-level sentiment cues, (2) factual evidence about entity factions, and (3) global constraints based on social science theories such as homophily, social balance, and reciprocity. Together, these cues allow for rich inference across groups of entities, including for example that CEOs and the companies they lead are likely to have similar sentiment towards others. We evaluate performance on new, densely labeled data that provides supervision for all pairs, complementing previous work that only labeled pairs mentioned in the same sentence. Experiments demonstrate that the global model outperforms sentence-level baselines, by providing more coherent predictions across sets of related entities",
    "volume": "long",
    "checked": true,
    "id": "be199e77c66d26a71e1fdbfd881d9e923cd9bcf1",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-1033": {
    "title": "Active Learning for Dependency Parsing with Partial Annotation",
    "abstract": "Different from traditional active learning based on sentence-wise full annotation (FA), this paper proposes active learning with dependency-wise partial annotation (PA) as a finer-grained unit for dependency parsing. At each iteration, we select a few most uncertain words from an unlabeled data pool, manually annotate their syntactic heads, and add the partial trees into labeled data for parser retraining. Compared with sentence-wise FA, dependency-wise PA gives us more flexibility in task selection and avoids wasting time on annotating trivial tasks in a sentence. Our work makes the following contributions. First, we are the first to apply a probabilistic model to active learning for dependency parsing, which can 1) provide tree probabilities and dependency marginal probabilities as principled uncertainty metrics, and 2) directly learn parameters from PA based on a forest-based training objective. Second, we propose and compare several uncertainty metrics through simulation experiments on both Chinese and English. Finally, we conduct human annotation experiments to compare FA and PA on real annotation time and quality",
    "volume": "long",
    "checked": true,
    "id": "94a610b6d44ddd07b5a6cec4b316b2cd46e3accf",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-1034": {
    "title": "Dependency Parsing with Bounded Block Degree and Well-nestedness via Lagrangian Relaxation and Branch-and-Bound",
    "abstract": "We present a novel dependency parsing method which enforces two structural properties on dependency trees: bounded block degree and well-nestedness. These properties are useful to better represent the set of admissible dependency structures in treebanks and connect dependency parsing to context-sensitive grammatical formalisms. We cast this problem as an Integer Linear Program that we solve with Lagrangian Relaxation from which we derive a heuristic and an exact method based on a Branch-and-Bound search. Experimentally, we see that these methods are efficient and competitive compared to a baseline unconstrained parser, while enforcing structural properties in all cases",
    "volume": "long",
    "checked": true,
    "id": "d9722bad13e8acf5c396bdc2a255493cef499bcb",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-1035": {
    "title": "Query Expansion with Locally-Trained Word Embeddings",
    "abstract": "Continuous space word embeddings have received a great deal of attention in the natural language processing and machine learning communities for their ability to model term similarity and other relationships. We study the use of term relatedness in the context of query expansion for ad hoc information retrieval. We demonstrate that word embeddings such as word2vec and GloVe, when trained globally, underperform corpus and query specific embeddings for retrieval tasks. These results suggest that other tasks benefiting from global embeddings may also benefit from local embeddings",
    "volume": "long",
    "checked": true,
    "id": "ba7ce0dd3d21771ae2093c9b722e8f55b6d8c1f3",
    "citation_count": 255
  },
  "https://aclanthology.org/P16-1036": {
    "title": "Together we stand: Siamese Networks for Similar Question Retrieval",
    "abstract": "Community Question Answering (cQA) services like Yahoo! Answers1, Baidu Zhidao2, Quora3, StackOverflow4 etc. provide a platform for interaction with experts and help users to obtain precise and accurate answers to their questions. The time lag between the user posting a question and receiving its answer could be reduced by retrieving similar historic questions from the cQA archives. The main challenge in this task is the \"lexicosyntactic\" gap between the current and the previous questions. In this paper, we propose a novel approach called \"Siamese Convolutional Neural Network for cQA (SCQA)\" to find the semantic similarity between the current and the archived questions. SCQA consist of twin convolutional neural networks with shared parameters and a contrastive loss function joining them. SCQA learns the similarity metric for question-question pairs by leveraging the question-answer pairs available in cQA forum archives. The model projects semantically similar question pairs nearer to each other and dissimilar question pairs farther away from each other in the semantic space. Experiments on large scale reallife \"Yahoo! Answers\" dataset reveals that SCQA outperforms current state-of-theart approaches based on translation models, topic models and deep neural network https://answers.yahoo.com/ http://zhidao.baidu.com/ http://www.quora.com/ http://stackoverflow.com/ based models which use non-shared parameters",
    "volume": "long",
    "checked": true,
    "id": "62a97ac04e742ad1513cf164760e4d6a25d93203",
    "citation_count": 83
  },
  "https://aclanthology.org/P16-1037": {
    "title": "News Citation Recommendation with Implicit and Explicit Semantics",
    "abstract": "In this work, we focus on the problem of news citation recommendation. The task aims to recommend news citations for both authors and readers to create and search news references. Due to the sparsity issue of news citations and the engineering difficulty in obtaining information on authors, we focus on content similarity-based methods instead of collaborative filtering-based approaches. In this paper, we explore word embedding (i.e., implicit semantics) and grounded entities (i.e., explicit semantics) to address the variety and ambiguity issues of language. We formulate the problem as a reranking task and integrate different similarity measures under the learning to rank framework. We evaluate our approach on a real-world dataset. The experimental results show the efficacy of our method",
    "volume": "long",
    "checked": true,
    "id": "306e20852c7e38a12ebb5ec754d973006d0835d4",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-1038": {
    "title": "Grapheme-to-Phoneme Models for (Almost) Any Language",
    "abstract": "Grapheme-to-phoneme (g2p) models are rarely available in low-resource languages, as the creation of training and evaluation data is expensive and time-consuming. We use Wiktionary to obtain more than 650k word-pronunciation pairs in more than 500 languages. We then develop phoneme and language distance metrics based on phonological and linguistic knowledge; applying those, we adapt g2p models for highresource languages to create models for related low-resource languages. We provide results for models for 229 adapted languages",
    "volume": "long",
    "checked": true,
    "id": "689f7d0121cf712250a0288a187ec8f7ed7cbdc9",
    "citation_count": 67
  },
  "https://aclanthology.org/P16-1039": {
    "title": "Neural Word Segmentation Learning for Chinese",
    "abstract": "Most previous approaches to Chinese word segmentation formalize this problem as a character-based sequence labeling task where only contextual information within fixed sized local windows and simple interactions between adjacent tags can be captured. In this paper, we propose a novel neural framework which thoroughly eliminates context windows and can utilize complete segmentation history. Our model employs a gated combination neural network over characters to produce distributed representations of word candidates, which are then given to a long short-term memory (LSTM) language scoring model. Experiments on the benchmark datasets show that without the help of feature engineering as most existing approaches, our models achieve competitive or better performances with previous state-of-the-art methods",
    "volume": "long",
    "checked": true,
    "id": "0a3489330820856f82e100de239aac82a3459c4a",
    "citation_count": 154
  },
  "https://aclanthology.org/P16-1040": {
    "title": "Transition-Based Neural Word Segmentation",
    "abstract": "Character-based and word-based methods are two main types of statistical models for Chinese word segmentation, the former exploiting sequence labeling models over characters and the latter typically exploiting a transition-based model, with the advantages that word-level features can be easily utilized. Neural models have been exploited for character-based Chinese word segmentation, giving high accuracies by making use of external character embeddings, yet requiring less feature engineering. In this paper, we study a neural model for word-based Chinese word segmentation, by replacing the manuallydesigned discrete features with neural features in a word-based segmentation framework. Experimental results demonstrate that word features lead to comparable performances to the best systems in the literature, and a further combination of discrete and neural features gives top accuracies",
    "volume": "long",
    "checked": true,
    "id": "22882a68702c16270cef2f370684e71ad65d4022",
    "citation_count": 117
  },
  "https://aclanthology.org/P16-1041": {
    "title": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data",
    "abstract": "Understanding unstructured text is a major goal within natural language processing. Comprehension tests pose questions based on short text passages to evaluate such understanding. In this work, we investigate machine comprehension on the challenging {\\it MCTest} benchmark. Partly because of its limited size, prior work on {\\it MCTest} has focused mainly on engineering better features. We tackle the dataset with a neural approach, harnessing simple neural networks arranged in a parallel hierarchy. The parallel hierarchy enables our model to compare the passage, question, and answer from a variety of trainable perspectives, as opposed to using a manually designed, rigid feature set. Perspectives range from the word level to sentence fragments to sequences of sentences; the networks operate only on word-embedding representations of text. When trained with a methodology designed to help cope with limited training data, our Parallel-Hierarchical model sets a new state of the art for {\\it MCTest}, outperforming previous feature-engineered approaches slightly and previous neural approaches by a significant margin (over 15\\% absolute)",
    "volume": "long",
    "checked": true,
    "id": "46147f08468e873ff90d1d51e65493f262c7bb57",
    "citation_count": 45
  },
  "https://aclanthology.org/P16-1042": {
    "title": "Combining Natural Logic and Shallow Reasoning for Question Answering",
    "abstract": "Broad domain question answering is often difficult in the absence of structured knowledge bases, and can benefit from shallow lexical methods (broad coverage) and logical reasoning (high precision). We propose an approach for incorporating both of these signals in a unified framework based on natural logic. We extend the breadth of inferences afforded by natural logic to include relational entailment (e.g., buy → own) and meronymy (e.g., a person born in a city is born the city's country). Furthermore, we train an evaluation function – akin to gameplaying – to evaluate the expected truth of candidate premises on the fly. We evaluate our approach on answering multiple choice science questions, achieving strong results on the dataset",
    "volume": "long",
    "checked": true,
    "id": "8ecb5cc8acc9fc704549da1dd127af5344b1333c",
    "citation_count": 25
  },
  "https://aclanthology.org/P16-1043": {
    "title": "Easy Questions First? A Case Study on Curriculum Learning for Question Answering",
    "abstract": "Cognitive science researchers have emphasized the importance of ordering a complex task into a sequence of easy to hard problems. Such an ordering provides an easier path to learning and increases the speed of acquisition of the task compared to conventional learning. Recent works in machine learning have explored a curriculum learning approach called selfpaced learning which orders data samples on the easiness scale so that easy samples can be introduced to the learning algorithm first and harder samples can be introduced successively. We introduce a number of heuristics that improve upon selfpaced learning. Then, we argue that incorporating easy, yet, a diverse set of samples can further improve learning. We compare these curriculum learning proposals in the context of four non-convex models for QA and show that they lead to real improvements in each of them",
    "volume": "long",
    "checked": true,
    "id": "992018dd6d98f37352437c19f16c5bc87c3b6f22",
    "citation_count": 64
  },
  "https://aclanthology.org/P16-1044": {
    "title": "Improved Representation Learning for Question Answer Matching",
    "abstract": "Passage-level question answer matching is a challenging task since it requires effective representations that capture the complex semantic relations between questions and answers. In this work, we propose a series of deep learning models to address passage answer selection. To match passage answers to questions accommodating their complex semantic relations, unlike most previous work that utilizes a single deep learning structure, we develop hybrid models that process the text using both convolutional and recurrent neural networks, combining the merits on extracting linguistic information from both structures. Additionally, we also develop a simple but effective attention mechanism for the purpose of constructing better answer representations according to the input question, which is imperative for better modeling long answer sequences. The results on two public benchmark datasets, InsuranceQA and TREC-QA, show that our proposed models outperform a variety of strong baselines",
    "volume": "long",
    "checked": true,
    "id": "1261fe9bfde319abcc5d011bc70f7e7547b5258f",
    "citation_count": 231
  },
  "https://aclanthology.org/P16-1045": {
    "title": "Tables as Semi-structured Knowledge for Question Answering",
    "abstract": "Question answering requires access to a knowledge base to check facts and reason about information. Knowledge in the form of natural language text is easy to acquire, but difficult for automated reasoning. Highly-structured knowledge bases can facilitate reasoning, but are difficult to acquire. In this paper we explore tables as a semi-structured formalism that provides a balanced compromise to this trade-off. We first use the structure of tables to guide the construction of a dataset of over 9000 multiple-choice questions with rich alignment annotations, easily and efficiently via crowd-sourcing. We then use this annotated data to train a semi-structured feature-driven model for question answering that uses tables as a knowledge base. In benchmark evaluations, we significantly outperform both a strong unstructured retrieval baseline and a highly structured Markov Logic Network model",
    "volume": "long",
    "checked": true,
    "id": "bb52d22530727259c12cdbbfc73f3d5f4ebd5210",
    "citation_count": 37
  },
  "https://aclanthology.org/P16-1046": {
    "title": "Neural Summarization by Extracting Sentences and Words",
    "abstract": "Traditional approaches to extractive summarization rely heavily on humanengineered features. In this work we propose a data-driven approach based on neural networks and continuous sentence features. We develop a general framework for single-document summarization composed of a hierarchical document encoder and an attention-based extractor. This architecture allows us to develop different classes of summarization models which can extract sentences or words. We train our models on large scale corpora containing hundreds of thousands of document-summary pairs 1 . Experimental results on two summarization datasets demonstrate that our models obtain results comparable to the state of the art without any access to linguistic annotation",
    "volume": "long",
    "checked": true,
    "id": "29a294eaec7b485245aa21d994f7300f6b5da8fc",
    "citation_count": 660
  },
  "https://aclanthology.org/P16-1047": {
    "title": "Neural Networks For Negation Scope Detection",
    "abstract": "Automatic negation scope detection is a task that has been tackled using different classifiers and heuristics. Most systems are however 1) highly-engineered, 2) English-specific, and 3) only tested on the same genre they were trained on. We start by addressing 1) and 2) using a neural network architecture. Results obtained on data from the *SEM2012 shared task on negation scope detection show that even a simple feed-forward neural network using word-embedding features alone, performs on par with earlier classifiers, with a bi-directional LSTM outperforming all of them. We then address 3) by means of a specially-designed synthetic test set; in doing so, we explore the problem of detecting the negation scope more in depth and show that performance suffers from genre effects and differs with the type of negation considered",
    "volume": "long",
    "checked": true,
    "id": "710d36afa8ecd1c8d164d1ce7d70fb40c92a9d6b",
    "citation_count": 94
  },
  "https://aclanthology.org/P16-1048": {
    "title": "CSE: Conceptual Sentence Embeddings based on Attention Model",
    "abstract": "Most sentence embedding models typically represent each sentence only using word surface, which makes these models indiscriminative for ubiquitous homonymy and polysemy. In order to enhance representation capability of sentence, we employ conceptualization model to assign associated concepts for each sentence in the text corpus, and then learn conceptual sentence embedding (CSE). Hence, this semantic representation is more expressive than some widely-used text representation models such as latent topic model, especially for short-text. Moreover, we further extend CSE models by utilizing a local attention-based model that select relevant words within the context to make more efficient prediction. In the experiments, we evaluate the CSE models on two tasks, text classification and information retrieval. The experimental results show that the proposed models outperform typical sentence embed-ding models",
    "volume": "long",
    "checked": true,
    "id": "a58faf545f6434402ee383bac5766a1d0cfc3182",
    "citation_count": 44
  },
  "https://aclanthology.org/P16-1049": {
    "title": "DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents",
    "abstract": "Most current chatbot engines are designed to reply to user utterances based on existing utterance-response (or Q-R)1 pairs. In this paper, we present DocChat, a novel information retrieval approach for chatbot engines that can leverage unstructured documents, instead of Q-R pairs, to respond to utterances. A learning to rank model with features designed at different levels of granularity is proposed to measure the relevance between utterances and responses directly. We evaluate our proposed approach in both English and Chinese: (i) For English, we evaluate DocChat on WikiQA and QASent, two answer sentence selection tasks, and compare it with state-of-the-art methods. Reasonable improvements and good adaptability are observed. (ii) For Chinese, we compare DocChat with XiaoIce2, a famous chitchat engine in China, and side-by-side evaluation shows that DocChat is a perfect complement for chatbot engines using Q-R pairs as main source of responses",
    "volume": "long",
    "checked": true,
    "id": "91e9387c92b7c9d295c1188719d30dd179cc81e8",
    "citation_count": 88
  },
  "https://aclanthology.org/P16-1050": {
    "title": "Investigating the Sources of Linguistic Alignment in Conversation",
    "abstract": "In conversation, speakers tend to \"accommodate\" or \"align\" to their partners, changing the style and substance of their communications to be more similar to their partners' utterances. We focus here on \"linguistic alignment,\" changes in word choice based on others' choices. Although linguistic alignment is observed across many different contexts and its degree correlates with important social factors such as power and likability, its sources are still uncertain. We build on a recent probabilistic model of alignment, using it to separate out alignment attributable to words versus word categories. We model alignment in two contexts: telephone conversations and microblog replies. Our results show evidence of alignment, but it is primarily lexical rather than categorical. Furthermore, we find that discourse acts modulate alignment substantially. This evidence supports the view that alignment is shaped by strategic communicative processes related to the ongoing discourse",
    "volume": "long",
    "checked": true,
    "id": "019b80fbf9af5c8c64dbd753ea6aeef1e4ef253f",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-1051": {
    "title": "Entropy Converges Between Dialogue Participants: Explanations from an Information-Theoretic Perspective",
    "abstract": "The applicability of entropy rate constancy to dialogue is examined on two spoken dialogue corpora. The principle is found to hold; however, new entropy change patterns within the topic episodes of dialogue are described, which are different from written text. Speaker's dynamic roles as topic initiators and topic responders are associated with decreasing and increasing entropy, respectively, which results in local convergence between these speakers in each topic episode. This implies that the sentence entropy in dialogue is conditioned on different contexts determined by the speaker's roles. Explanations from the perspectives of grounding theory and interactive alignment are discussed, resulting in a novel, unified informationtheoretic approach of dialogue",
    "volume": "long",
    "checked": true,
    "id": "f19a371e292c6677a8f904941c0a0f7352a282f9",
    "citation_count": 9
  },
  "https://aclanthology.org/P16-1052": {
    "title": "Finding the Middle Ground - A Model for Planning Satisficing Answers",
    "abstract": "To establish sophisticated dialogue systems, text planning needs to cope with congruent as well as incongruent interlocutor interests as given in everyday dialogues. Little attention has been given to this topic in text planning in contrast to dialogues that are fully aligned with anticipated user interests. When considering dialogues with congruent and incongruent interlocutor interests, dialogue partners are facing the constant challenge of finding a balance between cooperation and competition. We introduce the concept of fairness that operationalize an equal and adequate, i.e. equitable satisfaction of all interlocutors' interests. Focusing on Question-Answering (QA) settings, we describe an answer planning approach that support fair dialogues under congruent and incongruent interlocutor interests. Due to the fact that fairness is subjective per se, we present promising results from an empirical study (N=107) in which human subjects interacted with a QA system implementing the proposed approach",
    "volume": "long",
    "checked": true,
    "id": "f0e95908041fcee63c87d5db07b76c7ee75d9901",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-1053": {
    "title": "A Sentence Interaction Network for Modeling Dependence between Sentences",
    "abstract": "Modeling interactions between two sentences is crucial for a number of natural language processing tasks including Answer Selection, Dialogue Act Analysis, etc. While deep learning methods like Recurrent Neural Network or Convolutional Neural Network have been proved to be powerful for sentence modeling, prior studies paid less attention on interactions between sentences. In this work, we propose a Sentence Interaction Network (SIN) for modeling the complex interactions between two sentences. By introducing \"interaction states\" for word and phrase pairs, SIN is powerful and flexible in capturing sentence interactions for different tasks. We obtain significant improvements on Answer Selection and Dialogue Act Analysis without any feature engineering",
    "volume": "long",
    "checked": true,
    "id": "6d2467d75a21d94a4e172d647564b5e238ddfdbe",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-1054": {
    "title": "Towards more variation in text generation: Developing and evaluating variation models for choice of referential form",
    "abstract": "In this study, we introduce a nondeterministic method for referring expression generation. We describe two models that account for individual variation in the choice of referential form in automatically generated text: a Naive Bayes model and a Recurrent Neural Network. Both are evaluated using the VaREG corpus. Then we select the best performing model to generate referential forms in texts from the GREC-2.0 corpus and conduct an evaluation experiment in which humans judge the coherence and comprehensibility of the generated texts, comparing them both with the original references and those produced by a random baseline model",
    "volume": "long",
    "checked": true,
    "id": "c151627b73a9d5b9af5402e70d18f4fa7623a4e7",
    "citation_count": 24
  },
  "https://aclanthology.org/P16-1055": {
    "title": "How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions",
    "abstract": "How much is 131 million US dollars? To help readers put such numbers in context, we propose a new task of automatically generating short descriptions known as perspectives, e.g. \"$131 million is about the cost to employ everyone in Texas over a lunch period\". First, we collect a dataset of numeric mentions in news articles, where each mention is labeled with a set of rated perspectives. We then propose a system to generate these descriptions consisting of two steps: formula construction and description generation. In construction, we compose formulae from numeric facts in a knowledge base and rank the resulting formulas based on familiarity, numeric proximity and semantic compatibility. In generation, we convert a formula into natural language using a sequence-to-sequence recurrent neural network. Our system obtains a 15.2% F1 improvement over a non-compositional baseline at formula construction and a 12.5 BLEU point improvement over a baseline description generation",
    "volume": "long",
    "checked": true,
    "id": "c825b92effcf400ab1679071cef8233a5a6a18ba",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-1056": {
    "title": "Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus",
    "abstract": "Over the past decade, large-scale supervised learning corpora have enabled machine learning researchers to make substantial advances. However, to this date, there are no large-scale question-answer corpora available. In this paper we present the 30M Factoid Question-Answer Corpus, an enormous question answer pair corpus produced by applying a novel neural network architecture on the knowledge base Freebase to transduce facts into natural language questions. The produced question answer pairs are evaluated both by human evaluators and using automatic evaluation metrics, including well-established machine translation and sentence similarity metrics. Across all evaluation criteria the question-generation model outperforms the competing template-based baseline. Furthermore, when presented to human evaluators, the generated questions appear comparable in quality to real human-generated questions",
    "volume": "long",
    "checked": true,
    "id": "d7eeffce7df899dd9ca35c541350ee6b690ec629",
    "citation_count": 243
  },
  "https://aclanthology.org/P16-1057": {
    "title": "Latent Predictor Networks for Code Generation",
    "abstract": "Many language generation tasks require the production of text conditioned on both structured and unstructured inputs. We present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions. Crucially, our approach allows both the choice of conditioning context and the granularity of generation, for example characters or tokens, to be marginalised, thus permitting scalable and effective training. Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. We create two new data sets for this paradigm derived from the collectible trading card games Magic the Gathering and Hearthstone. On these, and a third preexisting corpus, we demonstrate that marginalising multiple predictors allows our model to outperform strong benchmarks",
    "volume": "long",
    "checked": true,
    "id": "e957747f4f8600940be4c5bb001aa70c84e53a53",
    "citation_count": 307
  },
  "https://aclanthology.org/P16-1058": {
    "title": "Easy Things First: Installments Improve Referring Expression Generation for Objects in Photographs",
    "abstract": "Research on generating referring expressions has so far mostly focussed on \"oneshot reference\", where the aim is to generate a single, discriminating expression. In interactive settings, however, it is not uncommon for reference to be established in \"installments\", where referring information is offered piecewise until success has been confirmed. We show that this strategy can also be advantageous in technical systems that only have uncertain access to object attributes and categories. We train a recently introduced model of grounded word meaning on a data set of REs for objects in images and learn to predict semantically appropriate expressions. In a human evaluation, we observe that users are sensitive to inadequate object names which unfortunately are not unlikely to be generated from low-level visual input. We propose a solution inspired from human task-oriented interaction and implement strategies for avoiding and repairing semantically inaccurate words. We enhance a word-based REG with contextaware, referential installments and find that they substantially improve the referential success of the system",
    "volume": "long",
    "checked": true,
    "id": "06d7968ced2bdeba0d7dc58fb8e12406a3ccb3c8",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-1059": {
    "title": "Collective Entity Resolution with Multi-Focal Attention",
    "abstract": "Entity resolution is the task of linking each mention of an entity in text to the corresponding record in a knowledge base (KB). Coherence models for entity resolution encourage all referring expressions in a document to resolve to entities that are related in the KB. We explore attentionlike mechanisms for coherence, where the evidence for each candidate is based on a small set of strong relations, rather than relations to all other entities in the document. The rationale is that documentwide support may simply not exist for non-salient entities, or entities not densely connected in the KB. Our proposed system outperforms state-of-the-art systems on the CoNLL 2003, TAC KBP 2010, 2011 and 2012 tasks",
    "volume": "long",
    "checked": true,
    "id": "4988a269e9f61c6fd1da502e34648b93dfd1a54d",
    "citation_count": 101
  },
  "https://aclanthology.org/P16-1060": {
    "title": "Which Coreference Evaluation Metric Do You Trust? A Proposal for a Link-based Entity Aware Metric",
    "abstract": "Interpretability and discriminative power are the two most basic requirements for an evaluation metric. In this paper, we report the mention identification effect in the B3, CEAF, and BLANC coreference evaluation metrics that makes it impossible to interpret their results properly. The only metric which is insensitive to this flaw is MUC, which, however, is known to be the least discriminative metric. It is a known fact that none of the current metrics are reliable. The common practice for ranking coreference resolvers is to use the average of three different metrics. However, one cannot expect to obtain a reliable score by averaging three unreliable metrics. We propose LEA, a Link-based Entity-Aware evaluation metric that is designed to overcome the shortcomings of the current evaluation metrics. LEA is available as branch LEA-scorer in the reference implementation of the official CoNLL scorer",
    "volume": "long",
    "checked": true,
    "id": "fba28688404c090661d29cd8b90acf1cb74d959c",
    "citation_count": 101
  },
  "https://aclanthology.org/P16-1061": {
    "title": "Improving Coreference Resolution by Learning Entity-Level Distributed Representations",
    "abstract": "A long-standing challenge in coreference resolution has been the incorporation of entity-level information - features defined over clusters of mentions instead of mention pairs. We present a neural network based coreference system that produces high-dimensional vector representations for pairs of coreference clusters. Using these representations, our system learns when combining clusters is desirable. We train the system with a learning-to-search algorithm that teaches it which local decisions (cluster merges) will lead to a high-scoring final coreference partition. The system substantially outperforms the current state-of-the-art on the English and Chinese portions of the CoNLL 2012 Shared Task dataset despite using few hand-engineered features",
    "volume": "long",
    "checked": true,
    "id": "e9ff2d0274bcb76bdea4ab8ae1d2c972f6e83c74",
    "citation_count": 291
  },
  "https://aclanthology.org/P16-1062": {
    "title": "Effects of Creativity and Cluster Tightness on Short Text Clustering Performance",
    "abstract": "Properties of corpora, such as the diversity of vocabulary and how tightly related texts cluster together, impact the best way to cluster short texts. We examine several such properties in a variety of corpora and track their effects on various combinations of similarity metrics and clustering algorithms. We show that semantic similarity metrics outperform traditional n-gram and dependency similarity metrics for kmeans clustering of a linguistically creative dataset, but do not help with less creative texts. Yet the choice of similarity metric interacts with the choice of clustering method. We find that graphbased clustering methods perform well on tightly clustered data but poorly on loosely clustered data. Semantic similarity metrics generate loosely clustered output even when applied to a tightly clustered dataset. Thus, the best performing clustering systems could not use semantic metrics",
    "volume": "long",
    "checked": true,
    "id": "31d7e1a085a5df84381163c738d66cf692d83c08",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-1063": {
    "title": "Generative Topic Embedding: a Continuous Representation of Documents",
    "abstract": "Word embedding maps words into a low-dimensional continuous embedding space by exploiting the local word collocation patterns in a small context window. On the other hand, topic modeling maps documents onto a low-dimensional topic space, by utilizing the global word collocation patterns in the same document. These two types of patterns are complementary. In this paper, we propose a generative topic embedding model to combine the two types of patterns. In our model, topics are represented by embedding vectors, and are shared across documents. The probability of each word is influenced by both its local context and its topic. A variational inference method yields the topic embeddings as well as the topic mixing proportions for each document. Jointly they represent the document in a low-dimensional continuous space. In two document classification tasks, our method performs better than eight existing methods, with fewer features. In addition, we illustrate with an example that our method can generate coherent topics even based on only one document",
    "volume": "long",
    "checked": true,
    "id": "132c8b4d0760d2d35c99b0358c8bc5a51170e5e7",
    "citation_count": 96
  },
  "https://aclanthology.org/P16-1064": {
    "title": "Detecting Common Discussion Topics Across Culture From News Reader Comments",
    "abstract": "News reader comments found in many on-line news websites are typically massive in amount. We investigate the task of Cultural-common Topic Detection (CTD), which is aimed at discovering common discussion topics from news reader comments written in different languages. We propose a new probabilistic graphical model called MCTA which can cope with the language gap and capture the common semantics in different languages. We also develop a partially collapsed Gibbs sampler which effectively incorporates the term translation relationship into the detection of cultural-common topics for model parameter learning. Experimental results show improvements over the state-of-the-art model",
    "volume": "long",
    "checked": true,
    "id": "c3020af98fec349567481e2a8b2251c1e3dd9c6b",
    "citation_count": 10
  },
  "https://aclanthology.org/P16-1065": {
    "title": "A Discriminative Topic Model using Document Network Structure",
    "abstract": "Document collections often have links between documents—citations, hyperlinks, or revisions—and which links are added is often based on topical similarity. To model these intuitions, we introduce a new topic model for documents situated within a network structure, integrating latent blocks of documents with a max-margin learning criterion for link prediction using topicand word-level features. Experiments on a scientific paper dataset and collection of webpages show that, by more robustly exploiting the rich link structure within a document network, our model improves link prediction, topic quality, and block distributions",
    "volume": "long",
    "checked": true,
    "id": "dd3d357b3edd50781b928044c835e69e1346c5dd",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-1066": {
    "title": "AraSenTi: Large-Scale Twitter-Specific Arabic Sentiment Lexicons",
    "abstract": "Sentiment Analysis (SA) is an active research area nowadays due to the tremendous interest in aggregating and evaluating opinions being disseminated by users on the Web. SA of English has been thoroughly researched; however research on SA of Arabic has just flourished. Twitter is considered a powerful tool for disseminating information and a rich resource for opinionated text containing views on many different topics. In this paper we attempt to bridge a gap in Arabic SA of Twitter which is the lack of sentiment lexicons that are tailored for the informal language of Twitter. We generate two lexicons extracted from a large dataset of tweets using two approaches and evaluate their use in a simple lexicon based method. The evaluation is performed on internal and external datasets. The performance of these automatically generated lexicons was very promising, albeit the simple method used for classification. The best F-score obtained was 89.58% on the internal dataset and 63.1-64.7% on the exter-",
    "volume": "long",
    "checked": true,
    "id": "5abf8f224e216d284dc31c66647ef2303976ea9e",
    "citation_count": 63
  },
  "https://aclanthology.org/P16-1067": {
    "title": "Unsupervised Multi-Author Document Decomposition Based on Hidden Markov Model",
    "abstract": "This paper proposes an unsupervised approach for segmenting a multiauthor document into authorial components. The key novelty is that we utilize the sequential patterns hidden among document elements when determining their authorships. For this purpose, we adopt Hidden Markov Model (HMM) and construct a sequential probabilistic model to capture the dependencies of sequential sentences and their authorships. An unsupervised learning method is developed to initialize the HMM parameters. Experimental results on benchmark datasets have demonstrated the significant benefit of our idea and our approach has outperformed the state-of-the-arts on all tests. As an example of its applications, the proposed approach is applied for attributing authorship of a document and has also shown promising results",
    "volume": "long",
    "checked": true,
    "id": "50262748e69b6e165280055de55676d80c808dd0",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-1068": {
    "title": "Automatic Text Scoring Using Neural Networks",
    "abstract": "Automated Text Scoring (ATS) provides a cost-effective and consistent alternative to human marking. However, in order to achieve good performance, the predictive features of the system need to be manually engineered by human experts. We introduce a model that forms word representations by learning the extent to which specific words contribute to the text's score. Using Long-Short Term Memory networks to represent the meaning of texts, we demonstrate that a fully automated framework is able to achieve excellent results over similar approaches. In an attempt to make our results more interpretable, and inspired by recent advances in visualizing neural networks, we introduce a novel method for identifying the regions of the text that the model has found more discriminative",
    "volume": "long",
    "checked": true,
    "id": "a5db13d03cb5e4556cee86e659ebd77505489820",
    "citation_count": 172
  },
  "https://aclanthology.org/P16-1069": {
    "title": "Improved Semantic Parsers For If-Then Statements",
    "abstract": "Digital personal assistants are becoming both more common and more useful. The major NLP challenge for personal assistants is machine understanding: translating natural language user commands into an executable representation. This paper focuses on understanding rules written as If-Then statements, though the techniques should be portable to other semantic parsing tasks. We view understanding as structure prediction and show improved models using both conventional techniques and neural network models. We also discuss various ways to improve generalization and reduce overfitting: synthetic training data from paraphrase, grammar combinations, feature selection and ensembles of multiple systems. An ensemble of these techniques achieves a new state of the art result with 8% accuracy improvement",
    "volume": "long",
    "checked": true,
    "id": "cfa275ce08c510331051382fa8677306b5fa27de",
    "citation_count": 23
  },
  "https://aclanthology.org/P16-1070": {
    "title": "Universal Dependencies for Learner English",
    "abstract": "We introduce the Treebank of Learner English (TLE), the first publicly available syntactic treebank for English as a Second Language (ESL). The TLE provides manually annotated POS tags and Universal Dependency (UD) trees for 5,124 sentences from the Cambridge First Certificate in English (FCE) corpus. The UD annotations are tied to a pre-existing error annotation of the FCE, whereby full syntactic analyses are provided for both the original and error corrected versions of each sentence. Further on, we delineate ESL annotation guidelines that allow for consistent syntactic treatment of ungrammatical English. Finally, we benchmark POS tagging and dependency parsing performance on the TLE dataset and measure the effect of grammatical errors on parsing accuracy. We envision the treebank to support a wide range of linguistic and computational research on second language acquisition as well as automatic processing of ungrammatical language. The treebank is available at universaldependencies.org. The annotation manual used in this project and a graphical query engine are available at esltreebank.org",
    "volume": "long",
    "checked": true,
    "id": "eb82f228531f4e3f360454e40de3d53e41631410",
    "citation_count": 53
  },
  "https://aclanthology.org/P16-1071": {
    "title": "Extracting token-level signals of syntactic processing from fMRI - with an application to PoS induction",
    "abstract": "Neuro-imaging studies on reading different parts of speech (PoS) report somewhat mixed results, yet some of them indicate different activations with different PoS. This paper addresses the difficulty of using fMRI to discriminate between linguistic tokens in reading of running text because of low temporal resolution. We show that once we solve this problem, fMRI data contains a signal of PoS distinctions to the extent that it improves PoS induction with error reductions of more than 4%",
    "volume": "long",
    "checked": true,
    "id": "7381c6ebdafdfab5a09ba1a61159a566494dbd48",
    "citation_count": 12
  },
  "https://aclanthology.org/P16-1072": {
    "title": "Bidirectional Recurrent Convolutional Neural Network for Relation Classification",
    "abstract": "Relation classification is an important semantic processing task in the field of natural language processing (NLP). In this paper, we present a novel model BRCNN to classify the relation of two entities in a sentence. Some state-of-the-art systems concentrate on modeling the shortest dependency path (SDP) between two entities leveraging convolutional or recurrent neural networks. We further explore how to make full use of the dependency relations information in the SDP, by combining convolutional neural networks and twochannel recurrent neural networks with long short term memory (LSTM) units. We propose a bidirectional architecture to learn relation representations with directional information along the SDP forwards and backwards at the same time, which benefits classifying the direction of relations. Experimental results show that our method outperforms the state-of-theart approaches on the SemEval-2010 Task 8 dataset",
    "volume": "long",
    "checked": true,
    "id": "08b63b1f9a770c1b6f8545c2e1e4a9bfb6a2de6d",
    "citation_count": 161
  },
  "https://aclanthology.org/P16-1073": {
    "title": "Sentence Rewriting for Semantic Parsing",
    "abstract": "A major challenge of semantic parsing is the vocabulary mismatch problem between natural language and target ontology. In this paper, we propose a sentence rewriting based semantic parsing method, which can effectively resolve the mismatch problem by rewriting a sentence into a new form which has the same structure with its target logical form. Specifically, we propose two sentence-rewriting methods for two common types of mismatch: a dictionary-based method for 1-N mismatch and a template-based method for N-1 mismatch. We evaluate our entence rewriting based semantic parser on the benchmark semantic parsing dataset -- WEBQUESTIONS. Experimental results show that our system outperforms the base system with a 3.4% gain in F1, and generates logical forms more accurately and parses sentences more robustly",
    "volume": "long",
    "checked": true,
    "id": "8a9b63cf0181befe9b312870fe04181d24b080bc",
    "citation_count": 17
  },
  "https://aclanthology.org/P16-1074": {
    "title": "Chinese Zero Pronoun Resolution with Deep Neural Networks",
    "abstract": "While unsupervised anaphoric zero pronoun (AZP) resolvers have recently been shown to rival their supervised counterparts in performance, it is relatively difficult to scale them up to reach the next level of performance due to the large amount of feature engineering efforts involved and their ineffectiveness in exploiting lexical features. To address these weaknesses, we propose a supervised approach to AZP resolution based on deep neural networks, taking advantage of their ability to learn useful task-specific representations and effectively exploit lexical features via word embeddings. Our approach achieves stateof-the-art performance when resolving the Chinese AZPs in the OntoNotes corpus",
    "volume": "long",
    "checked": true,
    "id": "fef7cfacecd821d61b49c981da3bf0ac897bbf05",
    "citation_count": 43
  },
  "https://aclanthology.org/P16-1075": {
    "title": "Constrained Multi-Task Learning for Automated Essay Scoring",
    "abstract": "This is the author accepted manuscript. The final version is available from Association for Computational Linguistics at http://acl2016.org/index.php?article_id=71",
    "volume": "long",
    "checked": true,
    "id": "a55cca8a9160f8efed1d776c66e9b439cc15807c",
    "citation_count": 42
  },
  "https://aclanthology.org/P16-1076": {
    "title": "CFO: Conditional Focused Neural Question Answering with Large-scale Knowledge Bases",
    "abstract": "How can we enable computers to automatically answer questions like \"Who created the character Harry Potter\"? Carefully built knowledge bases provide rich sources of facts. However, it remains a challenge to answer factoid questions raised in natural language due to numerous expressions of one question. In particular, we focus on the most common questions --- ones that can be answered with a single fact in the knowledge base. We propose CFO, a Conditional Focused neural-network-based approach to answering factoid questions with knowledge bases. Our approach first zooms in a question to find more probable candidate subject mentions, and infers the final answers with a unified conditional probabilistic framework. Powered by deep recurrent neural networks and neural embeddings, our proposed CFO achieves an accuracy of 75.7% on a dataset of 108k questions - the largest public one to date. It outperforms the current state of the art by an absolute margin of 11.8%",
    "volume": "long",
    "checked": true,
    "id": "76d28a1f4c52b2fbb798501e479023c4075b4803",
    "citation_count": 120
  },
  "https://aclanthology.org/P16-1077": {
    "title": "Verbs Taking Clausal and Non-Finite Arguments as Signals of Modality – Revisiting the Issue of Meaning Grounded in Syntax",
    "abstract": "We revisit Levin's theory about the correspondence of verb meaning and syntax and infer semantic classes from a large syntactic classification of more than 600 German verbs taking clausal and non-finite arguments. Grasping the meaning components of Levin-classes is known to be hard. We address this challenge by setting up a multi-perspective semantic characterization of the inferred classes. To this end, we link the inferred classes and their English translation to independently constructed semantic classes in three different lexicons - the German wordnet GermaNet, VerbNet and FrameNet - and perform a detailed analysis and evaluation of the resulting German-English classification (available at www.ukp.tu-darmstadt.de/modality-verbclasses/)",
    "volume": "long",
    "checked": true,
    "id": "ce9e92a80ab8414b03bfc7247b7e7ea0368de7fb",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-1078": {
    "title": "Tree-to-Sequence Attentional Neural Machine Translation",
    "abstract": "Most of the existing Neural Machine Translation (NMT) models focus on the conversion of sequential data and do not directly use syntactic information. We propose a novel end-to-end syntactic NMT model, extending a sequence-to-sequence model with the source-side phrase structure. Our model has an attention mechanism that enables the decoder to generate a translated word while softly aligning it with phrases as well as words of the source sentence. Experimental results on the WAT'15 English-to-Japanese dataset demonstrate that our proposed model considerably outperforms sequence-to-sequence attentional NMT models and compares favorably with the state-of-the-art tree-to-string SMT system",
    "volume": "long",
    "checked": true,
    "id": "db02cd07726371790a825208cec377ec15f5b5f1",
    "citation_count": 236
  },
  "https://aclanthology.org/P16-1079": {
    "title": "Coordination Annotation Extension in the Penn Tree Bank",
    "abstract": "Coordination is an important and common syntactic construction which is not handled well by state of the art parsers. Coordinations in the Penn Treebank are missing internal structure in many cases, do not include explicit marking of the conjuncts and contain various errors and inconsistencies. In this work, we initiated manual annotation process for solving these issues. We identify the different elements in a coordination phrase and label each element with its function. We add phrase boundaries when these are missing, unify inconsistencies, and fix errors. The outcome is an extension of the PTB that includes consistent and detailed structures for coordinations. We make the coordination annotation publicly available, in hope that they will facilitate further research into coordination disambiguation",
    "volume": "long",
    "checked": true,
    "id": "19a88698a3f0c16af480f4f1a0f4045b4f2a2857",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-1080": {
    "title": "Analyzing Biases in Human Perception of User Age and Gender from Text",
    "abstract": "User traits disclosed through written text, such as age and gender, can be used to personalize applications such as recommender systems or conversational agents. However, human perception of these traits is not perfectly aligned with reality. In this paper, we conduct a large-scale crowdsourcing experiment on guessing age and gender from tweets. We systematically analyze the quality and possible biases of these predictions. We identify the textual cues which lead to miss-assessments of traits or make annotators more or less confident in their choice. Our study demonstrates that differences between real and perceived traits are noteworthy and elucidates inaccurately used stereotypes in human perception",
    "volume": "long",
    "checked": true,
    "id": "52d791bae58bfb4a08c3a591ed916ab148bf09e8",
    "citation_count": 45
  },
  "https://aclanthology.org/P16-1081": {
    "title": "Modeling Social Norms Evolution for Personalized Sentiment Classification",
    "abstract": "Motivated by the findings in social science that people's opinions are diverse and variable while together they are shaped by evolving social norms, we perform personalized sentiment classification via shared model adaptation over time. In our proposed solution, a global sentiment model is constantly updated to capture the homogeneity in which users express opinions, while personalized models are simultaneously adapted from the global model to recognize the heterogeneity of opinions from individuals. Global model sharing alleviates data sparsity issue, and individualized model adaptation enables efficient online model learning. Extensive experimentations are performed on two large review collections from Amazon and Yelp, and encouraging performance gain is achieved against several state-of-the-art transfer learning and multi-task learning based sentiment classification solutions",
    "volume": "long",
    "checked": true,
    "id": "e1fa9206eb753b1a7424777f951c84ddd30d35a5",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-1082": {
    "title": "Modeling Concept Dependencies in a Scientific Corpus",
    "abstract": "Our goal is to generate reading lists for students that help them optimally learn technical material. Existing retrieval algorithms return items directly relevant to a query but do not return results to help users read about the concepts supporting their query. This is because the dependency structure of concepts that must be understood before reading material pertaining to a given query is never considered. Here we formulate an information-theoretic view of concept dependency and present methods to construct a \"concept graph\" automatically from a text corpus. We perform the first human evaluation of concept dependency edges (to be published as open data), and the results verify the feasibility of automatic approaches for inferring concepts and their dependency relations. This result can support search capabilities that may be tuned to help users learn a subject rather than retrieve documents based on a single query",
    "volume": "long",
    "checked": true,
    "id": "fbb5d9a795935a5efe2ebfa2a013d0160cf5bdf0",
    "citation_count": 48
  },
  "https://aclanthology.org/P16-1083": {
    "title": "Normalized Log-Linear Interpolation of Backoff Language Models is Efficient",
    "abstract": "We prove that log-linearly interpolated backoff language models can be efﬁciently and exactly collapsed into a single normalized backoff model, contradicting Hsu (2007). While prior work reported that log-linear interpolation yields lower perplexity than linear interpolation, normalizing at query time was impractical. We normalize the model ofﬂine in advance, which is efﬁcient due to a recurrence relationship between the normalizing factors. To tune interpolation weights, we apply Newton's method to this convex problem and show that the derivatives can be computed efﬁciently in a batch process. These ﬁnd-ings are combined in new open-source interpolation tool, which is distributed with KenLM. With 21 out-of-domain corpora, log-linear interpolation yields 72.58 perplexity on TED talks, compared to 75.91 for linear interpolation",
    "volume": "long",
    "checked": true,
    "id": "05ebfb48f601dbb451d257d2ec1818a6b5ca1668",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-1084": {
    "title": "How well do Computers Solve Math Word Problems? Large-Scale Dataset Construction and Evaluation",
    "abstract": "Recently a few systems for automatically solving math word problems have reported promising results. However, the datasets used for evaluation have limitations in both scale and diversity. In this paper, we build a large-scale dataset which is more than 9 times the size of previous ones, and contains many more problem types. Problems in the dataset are semiautomatically obtained from community question-answering (CQA) web pages. A ranking SVM model is trained to automatically extract problem answers from the answer text provided by CQA users, which significantly reduces human annotation cost. Experiments conducted on the new dataset lead to interesting and surprising results",
    "volume": "long",
    "checked": true,
    "id": "09900b36ca35af12301507cf992675808a709838",
    "citation_count": 90
  },
  "https://aclanthology.org/P16-1085": {
    "title": "Embeddings for Word Sense Disambiguation: An Evaluation Study",
    "abstract": "Recent years have seen a dramatic growth in the popularity of word embeddings mainly owing to their ability to capture semantic information from massive amounts of textual content. As a result, many tasks in Natural Language Processing have tried to take advantage of the potential of these distributional models. In this work, we study how word embeddings can be used in Word Sense Disambiguation, one of the oldest tasks in Natural Language Processing and Artificial Intelligence. We propose different methods through which word embeddings can be leveraged in a state-of-the-art supervised WSD system architecture, and perform a deep analysis of how different parameters affect performance. We show how a WSD system that makes use of word embeddings alone, if designed properly, can provide significant performance improvement over a state-ofthe-art WSD system that incorporates several standard WSD features",
    "volume": "long",
    "checked": true,
    "id": "00cc08c90bc4ae7d3523e4dad2ca3a8fafc8501a",
    "citation_count": 263
  },
  "https://aclanthology.org/P16-1086": {
    "title": "Text Understanding with the Attention Sum Reader Network",
    "abstract": "Several large cloze-style context-question-answer datasets have been introduced recently: the CNN and Daily Mail news data and the Children's Book Test. Thanks to the size of these datasets, the associated text comprehension task is well suited for deep-learning techniques that currently seem to outperform all alternative approaches. We present a new, simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document as is usual in similar models. This makes the model particularly suitable for question-answering problems where the answer is a single word from the document. Ensemble of our models sets new state of the art on all evaluated datasets",
    "volume": "long",
    "checked": true,
    "id": "f2e50e2ee4021f199877c8920f1f984481c723aa",
    "citation_count": 303
  },
  "https://aclanthology.org/P16-1087": {
    "title": "Investigating LSTMs for Joint Extraction of Opinion Entities and Relations",
    "abstract": "We investigate the use of deep bidirectional LSTMs for joint extraction of opinion entities and the IS-FROM and ISABOUT relations that connect them — the first such attempt using a deep learning approach. Perhaps surprisingly, we find that standard LSTMs are not competitive with a state-of-the-art CRF+ILP joint inference approach (Yang and Cardie, 2013) to opinion entities extraction, performing below even the standalone sequencetagging CRF. Incorporating sentence-level and a novel relation-level optimization, however, allows the LSTM to identify opinion relations and to perform within 1– 3% of the state-of-the-art joint model for opinion entities and the IS-FROM relation; and to perform as well as the state-of-theart for the IS-ABOUT relation — all without access to opinion lexicons, parsers and other preprocessing components required for the feature-rich CRF+ILP approach",
    "volume": "long",
    "checked": true,
    "id": "f5e4e57c7b39ab176066b0268d4bde68303c9582",
    "citation_count": 89
  },
  "https://aclanthology.org/P16-1088": {
    "title": "Transition-Based Left-Corner Parsing for Identifying PTB-Style Nonlocal Dependencies",
    "abstract": "This paper proposes a left-corner parser which can identify nonlocal dependencies. Our parser integrates nonlocal dependency identification into a transition-based system. We use a structured perceptron which enables our parser to utilize global features captured by nonlocal dependencies. An experimental result demonstrates that our parser achieves a good balance between constituent parsing and nonlocal dependency identification",
    "volume": "long",
    "checked": true,
    "id": "610212c729680cf0635f0e280dcddd94b8c87a1d",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-1089": {
    "title": "Siamese CBOW: Optimizing Word Embeddings for Sentence Representations",
    "abstract": "We present the Siamese Continuous Bag of Words (Siamese CBOW) model, a neural network for efficient estimation of high-quality sentence embeddings. Averaging the embeddings of words in a sentence has proven to be a surprisingly successful and efficient way of obtaining sentence embeddings. However, word embeddings trained with the methods currently available are not optimized for the task of sentence representation, and, thus, likely to be suboptimal. Siamese CBOW handles this problem by training word embeddings directly for the purpose of being averaged. The underlying neural network learns word embeddings by predicting, from a sentence representation, its surrounding sentences. We show the robustness of the Siamese CBOW model by evaluating it on 20 datasets stemming from a wide variety of sources",
    "volume": "long",
    "checked": true,
    "id": "0f5d5a74572f272b919ca383ee47cb6663d38d62",
    "citation_count": 233
  },
  "https://aclanthology.org/P16-1090": {
    "title": "Unanimous Prediction for 100% Precision with Application to Learning Semantic Mappings",
    "abstract": "Can we train a system that, on any new input, either says \"don't know\" or makes a prediction that is guaranteed to be correct? We answer the question in the affirmative provided our model family is well-specified. Specifically, we introduce the unanimity principle: only predict when all models consistent with the training data predict the same output. We operationalize this principle for semantic parsing, the task of mapping utterances to logical forms. We develop a simple, efficient method that reasons over the infinite set of all consistent models by only checking two of the models. We prove that our method obtains 100% precision even with a modest amount of training data from a possibly adversarial distribution. Empirically, we demonstrate the effectiveness of our approach on the standard GeoQuery dataset",
    "volume": "long",
    "checked": true,
    "id": "e9fba8b381528630681573cf4b990a0bfe5e0238",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-1091": {
    "title": "Exploring Convolutional and Recurrent Neural Networks in Sequential Labelling for Dialogue Topic Tracking",
    "abstract": "Dialogue topic tracking is a sequential labelling problem of recognizing the topic state at each time step in given dialogue sequences. This paper presents various artificial neural network models for dialogue topic tracking, including convolutional neural networks to account for semantics at each individual utterance, and recurrent neural networks to account for conversational contexts along multiple turns in the dialogue history. The experimental results demonstrate that our proposed models can significantly improve the tracking performances in human-human conversations",
    "volume": "long",
    "checked": true,
    "id": "2c820a75f471d0943a82ac0ebf7c0a0e951b8db7",
    "citation_count": 25
  },
  "https://aclanthology.org/P16-1092": {
    "title": "Cross-Lingual Lexico-Semantic Transfer in Language Learning",
    "abstract": "Ekaterina Kochmar's research is supported by Cambridge English Language Assessment via the ALTA Institute. Ekaterina Shutova's research is supported by the Leverhulme Trust Early Career Fellowship",
    "volume": "long",
    "checked": true,
    "id": "19a5579f197af090d4f66a289baddd8c97eaad0c",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-1093": {
    "title": "A CALL System for Learning Preposition Usage",
    "abstract": "Fill-in-the-blank items are commonly featured in computer-assisted language learning (CALL) systems. An item displays a sentence with a blank, and often proposes a number of choices for filling it. These choices should include one correct answer and several plausible distractors. We describe a system that, given an English corpus, automatically generates distractors to produce items for preposition usage. We report a comprehensive evaluation on this system, involving both experts and learners. First, we analyze the difficulty levels of machine-generated carrier sentences and distractors, comparing several methods that exploit learner error and learner revision patterns. We show that the quality of machine-generated items approaches that of human-crafted ones. Further, we investigate the extent to which mismatched L1 between the user and the learner corpora affects the quality of distractors. Finally, we measure the system's impact on the user's language proficiency in both the short and the long term",
    "volume": "long",
    "checked": true,
    "id": "00c906df217946107cb41b3b863b839ee8a817fe",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-1094": {
    "title": "A Persona-Based Neural Conversation Model",
    "abstract": "We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gains in speaker consistency as measured by human judges",
    "volume": "long",
    "checked": true,
    "id": "1ea75cdb7ce8c4f5f2599165e3698034b4142e08",
    "citation_count": 859
  },
  "https://aclanthology.org/P16-1095": {
    "title": "Discriminative Deep Random Walk for Network Classification",
    "abstract": "Deep Random Walk (DeepWalk) can learn a latent space representation for describing the topological structure of a network. However, for relational network classification, DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task. In this paper, we present Discriminative Deep Random Walk (DDRW), a novel method for relational network classification. By solving a joint optimization problem, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are discriminative for the network classification task. Our experimental results on several real social networks demonstrate that DDRW significantly outperforms DeepWalk on multilabel network classification tasks, while retaining the topological structure in the latent space. DDRW is stable and consistently outperforms the baseline methods by various percentages of labeled data. DDRW is also an online method that is scalable and can be naturally parallelized",
    "volume": "long",
    "checked": true,
    "id": "a6fd225417efdbf0bb9aef2ef2046335d2d0885e",
    "citation_count": 104
  },
  "https://aclanthology.org/P16-1096": {
    "title": "Normalising Medical Concepts in Social Media Texts by Learning Semantic Representation",
    "abstract": "Automatically recognising medical concepts mentioned in social media messages (e.g. tweets) enables several applications for enhancing health quality of people in a community, e.g. real-time monitoring of infectious diseases in population. However, the discrepancy between the type of language used in social media and medical ontologies poses a major challenge. Existing studies deal with this challenge by employing techniques, such as lexical term matching and statistical machine translation. In this work, we handle the medical concept normalisation at the semantic level. We investigate the use of neural networks to learn the transition between layman's language used in social media messages and formal medical language used in the descriptions of medical concepts in a standard ontology. We evaluate our approaches using three different datasets, where social media texts are extracted from Twitter messages and blog posts. Our experimental results show that our proposed approaches significantly and consistently outperform existing effective baselines, which achieved state-of-the-art performance on several medical concept normalisation tasks, by up to 44%",
    "volume": "long",
    "checked": true,
    "id": "4cc3ae2b373f198d33ea667f0f2d6d93763e3a47",
    "citation_count": 119
  },
  "https://aclanthology.org/P16-1097": {
    "title": "Agreement-based Learning of Parallel Lexicons and Phrases from Non-Parallel Corpora",
    "abstract": "We introduce an agreement-based approach to learning parallel lexicons and phrases from non-parallel corpora. The basic idea is to encourage two asymmetric latent-variable translation models (i.e., source-to-target and target-to-source) to agree on identifying latent phrase and word alignments. The agreement is defined at both word and phrase levels. We develop a Viterbi EM algorithm for jointly training the two unidirectional models efficiently. Experiments on the Chinese-English dataset show that agreement-based learning significantly improves both alignment and translation performance",
    "volume": "long",
    "checked": true,
    "id": "7523ddd3cea99755facb475e47533dc5f55ab337",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-1098": {
    "title": "Deep Fusion LSTMs for Text Semantic Matching",
    "abstract": "Recently, there is rising interest in modelling the interactions of text pair with deep neural networks. In this paper, we propose a model of deep fusion LSTMs (DF-LSTMs) to model the strong interaction of text pair in a recursive matching way. Specifically, DF-LSTMs consist of two interdependent LSTMs, each of which models a sequence under the influence of another. We also use external memory to increase the capacity of LSTMs, thereby possibly capturing more complicated matching patterns. Experiments on two very large datasets demonstrate the efficacy of our proposed architecture. Furthermore, we present an elaborate qualitative analysis of our models, giving an intuitive understanding how our model worked",
    "volume": "long",
    "checked": true,
    "id": "adc184fcb04107f95e35ea1b07ef9aad749da8d7",
    "citation_count": 65
  },
  "https://aclanthology.org/P16-1099": {
    "title": "Understanding Discourse on Work and Job-Related Well-Being in Public Social Media",
    "abstract": "We construct a humans-in-the-loop supervised learning framework that integrates crowdsourcing feedback and local knowledge to detect job-related tweets from individual and business accounts. Using data-driven ethnography, we examine discourse about work by fusing language-based analysis with temporal, geospational, and labor statistics information",
    "volume": "long",
    "checked": true,
    "id": "e32666501e824d1cfdc19534b0ed009c7268cd8a",
    "citation_count": 15
  },
  "https://aclanthology.org/P16-1100": {
    "title": "Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models",
    "abstract": "Nearly all previous work on neural machine translation (NMT) has used quite restricted vocabularies, perhaps with a subsequent method to patch in unknown words. This paper presents a novel word-character solution to achieving open vocabulary NMT. We build hybrid systems that translate mostly at the word level and consult the character components for rare words. Our character-level recurrent neural networks compute source word representations and recover unknown target words when needed. The twofold advantage of such a hybrid approach is that it is much faster and easier to train than character-based ones; at the same time, it never produces unknown words as in the case of word-based models. On the WMT'15 English to Czech translation task, this hybrid approach offers an addition boost of +2.1-11.4 BLEU points over models that already handle unknown words. Our best system achieves a new state-of-the-art result with 20.7 BLEU score. We demonstrate that our character models can successfully learn to not only generate well-formed words for Czech, a highly-inflected language with a very complex vocabulary, but also build correct representations for English source words",
    "volume": "long",
    "checked": true,
    "id": "733b821faeebe49b6efcf5369e3b9902b476529e",
    "citation_count": 353
  },
  "https://aclanthology.org/P16-1101": {
    "title": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF",
    "abstract": "State-of-the-art sequence labeling systems traditionally require large amounts of task-specific knowledge in the form of hand-crafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both word- and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data pre-processing, thus making it applicable to a wide range of sequence labeling tasks. We evaluate our system on two data sets for two sequence labeling tasks --- Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain state-of-the-art performance on both the two data --- 97.55\\% accuracy for POS tagging and 91.21\\% F1 for NER",
    "volume": "long",
    "checked": true,
    "id": "8dd6aae51e31a72752c4be5cddbdd76dfdc6cda4",
    "citation_count": 2215
  },
  "https://aclanthology.org/P16-1102": {
    "title": "Off-topic Response Detection for Spontaneous Spoken English Assessment",
    "abstract": "© 2016 Association for Computational Linguistics. Automatic spoken language assessment systems are becoming increasingly important to meet the demand for English second language learning. This is a challenging task due to the high error rates of, even state-of-the-art, non-native speech recognition. Consequently current systems primarily assess fluency and pronunciation. However, content assessment is essential for full automation. As a first stage it is important to judge whether the speaker responds on topic to test questions designed to elicit spontaneous speech. Standard approaches to off-topic response detection assess similarity between the response and question based on bag-of-words representations. An alternative framework based on Recurrent Neural Network Language Models (RNNLM) is proposed in this paper. The RNNLM is adapted to the topic of each test question. It learns to associate example responses to questions with points in a topic space constructed using these example responses. Classification is done by ranking the topic-conditional posterior probabilities of a response. The RNNLMs associate a broad range of responses with each topic, incorporate sequence information and scale better with additional training data, unlike standard methods. On experiments conducted on data from the Business Language Testing Service (BULATS) this approach outperforms standard approaches",
    "volume": "long",
    "checked": true,
    "id": "9e3876f4fb0c5245ad9fa7f03ae13569343eb7c8",
    "citation_count": 12
  },
  "https://aclanthology.org/P16-1103": {
    "title": "Synthesizing Compound Words for Machine Translation",
    "abstract": "Most machine translation systems construct translations from a closed vocabulary of target word forms, posing problems for translating into languages that have productive compounding processes. We present a simple and effective approach that deals with this problem in two phases. First, we build a classifier that identifies spans of the input text that can be translated into a single compound word in the target language. Then, for each identified span, we generate a pool of possible compounds which are added to the translation model as \"synthetic\" phrase translations. Experiments reveal that (i) we can effectively predict what spans can be compounded; (ii) our compound generation model produces good compounds; and (iii) modest improvements are possible in end-to-end English‐German and English‐Finnish translation tasks. We additionally introduce KomposEval, a new multi-reference dataset of English phrases and their translations into German compounds",
    "volume": "long",
    "checked": true,
    "id": "0c6ec786230d1f338f2471b9b8004c21a70ad2d0",
    "citation_count": 9
  },
  "https://aclanthology.org/P16-1104": {
    "title": "Harnessing Cognitive Features for Sarcasm Detection",
    "abstract": "In this paper, we propose a novel mechanism for enriching the feature vector, for the task of sarcasm detection, with cognitive features extracted from eye-movement patterns of human readers. Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruity- implicit or explicit- affects the way readers eyes move through the text. We observe the difference in the behaviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by this observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features obtained from readers eye movement data. We perform statistical classification using the enhanced feature set so obtained. The augmented cognitive features improve sarcasm detection by 3.7% (in terms of Fscore), over the performance of the best reported system",
    "volume": "long",
    "checked": true,
    "id": "d5c89b9f9759d4f1bfe9214fde5938a0b5039af1",
    "citation_count": 51
  },
  "https://aclanthology.org/P16-1105": {
    "title": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures",
    "abstract": "We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components",
    "volume": "long",
    "checked": true,
    "id": "3899f87a2031f3434f89beb68c11a1ca6428328a",
    "citation_count": 921
  },
  "https://aclanthology.org/P16-1107": {
    "title": "Context-aware Argumentative Relation Mining",
    "abstract": "Context is crucial for identifying argumentative relations in text, but many argument mining methods make little use of contextual features. This paper presents contextaware argumentative relation mining that uses features extracted from writing topics as well as from windows of context sentences. Experiments on student essays demonstrate that the proposed features improve predictive performance in two argumentative relation classification tasks",
    "volume": "long",
    "checked": true,
    "id": "53731ecd14f879ee1b0c6985208e741b2131d2ba",
    "citation_count": 58
  },
  "https://aclanthology.org/P16-1108": {
    "title": "Leveraging Inflection Tables for Stemming and Lemmatization",
    "abstract": "We present several methods for stemming and lemmatization based on discriminative string transduction. We exploit the paradigmatic regularity of semi-structured inflection tables to identify stems in an unsupervised manner with over 85% accuracy. Experiments on English, Dutch and German show that our stemmers substantially outperform Snowball and Morfessor, and approach the accuracy of a supervised model. Furthermore, the generated stems are more consistent than those annotated by experts. Our direct lemmatization model is more accurate than Morfette and Lemming on most datasets. Finally, we test our methods on the data from the shared task on morphological reinflection",
    "volume": "long",
    "checked": true,
    "id": "96d1029a962cc757d550e59bf72a9934e7e9283d",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-1109": {
    "title": "Scaling a Natural Language Generation System",
    "abstract": "A key goal in natural language generation (NLG) is to enable fast generation even with large vocabularies, grammars and worlds. In this work, we build upon a recently proposed NLG system, Sentence Tree Realization with UCT (STRUCT). We describe four enhancements to this system: (i) pruning the grammar based on the world and the communicative goal, (ii) intelligently caching and pruning the combinatorial space of semantic bindings, (iii) reusing the lookahead search tree at different search depths, and (iv) learning and using a search control heuristic. We evaluate the resulting system on three datasets of increasing size and complexity, the largest of which has a vocabulary of about 10K words, a grammar of about 32K lexicalized trees and a world with about 11K entities and 23K relations between them. Our results show that the system has a median generation time of 8.5s and finds the best sentence on average within 25s. These results are based on a sequential, interpreted implementation and are significantly better than the state of the art for planningbased NLG systems",
    "volume": "long",
    "checked": true,
    "id": "2b9e2a7887c00a9c60fcd7941581e5b8657fea2c",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-1110": {
    "title": "ALTO: Active Learning with Topic Overviews for Speeding Label Induction and Document Labeling",
    "abstract": "Effective text classification requires experts to annotate data with labels; these training data are time-consuming and expensive to obtain. If you know what labels you want, active learning can reduce the number of labeled documents needed. However, establishing the label set remains difficult. Annotators often lack the global knowledge needed to induce a label set. We introduce ALTO: Active Learning with Topic Overviews, an interactive system to help humans annotate documents: topic models provide a global overview of what labels to create and active learning directs them to the right documents to label. Our forty-annotator user study shows that while active learning alone is best in extremely resource limited conditions, topic models (even by themselves) lead to better label sets, and ALTO's combination is best overall",
    "volume": "long",
    "checked": true,
    "id": "ca8692289189dbdee455561a425963f096008b36",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-1111": {
    "title": "Predicting the Rise and Fall of Scientific Topics from Trends in their Rhetorical Framing",
    "abstract": "Computationally modeling the evolution of science by tracking how scientific topics rise and fall over time has important implications for research funding and public policy. However, little is known about the mechanisms underlying topic growth and decline. We investigate the role of rhetorical framing: whether the rhetorical role or function that authors ascribe to topics (as methods, as goals, as results, etc.) relates to the historical trajectory of the topics. We train topic models and a rhetorical function classifier to map topic models onto their rhetorical roles in 2.4 million abstracts from the Web of Science from 1991-2010. We find that a topic's rhetorical function is highly predictive of its eventual growth or decline. For example, topics that are rhetorically described as results tend to be in decline, while topics that function as methods tend to be in early phases of growth",
    "volume": "long",
    "checked": true,
    "id": "f6098b7071a05f3226ba130600461b1bbdf477b8",
    "citation_count": 43
  },
  "https://aclanthology.org/P16-1112": {
    "title": "Compositional Sequence Labeling Models for Error Detection in Learner Writing",
    "abstract": "In this paper, we present the first experiments using neural network models for the task of error detection in learner writing. We perform a systematic comparison of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs. Experiments on the CoNLL-14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing. Finally, the model is integrated with a publicly deployed self-assessment system, leading to performance comparable to human annotators",
    "volume": "long",
    "checked": true,
    "id": "2ebc224d52761d5b76704c7b8f51369247a73d5f",
    "citation_count": 90
  },
  "https://aclanthology.org/P16-1113": {
    "title": "Neural Semantic Role Labeling with Dependency Path Embeddings",
    "abstract": "This paper introduces a novel model for semantic role labeling that makes use of neural sequence modeling techniques. Our approach is motivated by the observation that complex syntactic structures and related phenomena, such as nested subordinations and nominal predicates, are not handled well by existing models. Our model treats such instances as subsequences of lexicalized dependency paths and learns suitable embedding representations. We experimentally demonstrate that such embeddings can improve results over previous state-of-the-art semantic role labelers, and showcase qualitative improvements obtained by our method",
    "volume": "long",
    "checked": true,
    "id": "70d3d2e0a8f34d6c3cb7890e249e2ed6a574ce50",
    "citation_count": 176
  },
  "https://aclanthology.org/P16-1114": {
    "title": "Prediction of Prospective User Engagement with Intelligent Assistants",
    "abstract": "Intelligent assistants on mobile devices, such as Siri, have recently gained considerable attention as novel applications of dialogue technologies. A tremendous amount of real users of intelligent assistants provide us with an opportunity to explore a novel task of predicting whether users will continually use their intelligent assistants in the future. We developed prediction models of prospective user engagement by using large-scale user logs obtained from a commercial intelligent assistant. Experiments demonstrated that our models can predict prospective user engagement reasonably well, and outperforms a strong baseline that makes prediction based past utterance frequency",
    "volume": "long",
    "checked": true,
    "id": "65d25888b82af66c9fbc8a90f1e3887eed44e084",
    "citation_count": 23
  },
  "https://aclanthology.org/P16-1115": {
    "title": "Resolving References to Objects in Photographs using the Words-As-Classifiers Model",
    "abstract": "A common use of language is to refer to visually present objects. Modelling it in computers requires modelling the link between language and perception. The \"words as classifiers\" model of grounded semantics views words as classifiers of perceptual contexts, and composes the meaning of a phrase through composition of the denotations of its component words. It was recently shown to perform well in a game-playing scenario with a small number of object types. We apply it to two large sets of real-world photographs that contain a much larger variety of types and for which referring expressions are available. Using a pre-trained convolutional neural network to extract image features, and augmenting these with in-picture positional information, we show that the model achieves performance competitive with the state of the art in a reference resolution task (given expression, find bounding box of its referent), while, as we argue, being conceptually simpler and more flexible",
    "volume": "long",
    "checked": true,
    "id": "13a721dc8a7c774ca3feec3710212c809a28dd1d",
    "citation_count": 43
  },
  "https://aclanthology.org/P16-1116": {
    "title": "RBPB: Regularization-Based Pattern Balancing Method for Event Extraction",
    "abstract": "Event extraction is a particularly challenging information extraction task, which intends to identify and classify event triggers and arguments from raw text. In recent works, when determining event types (trigger classification), most of the works are either pattern-only or feature-only. However, although patterns cannot cover all representations of an event, it is still a very important feature. In addition, when identifying and classifying arguments, previous works consider each candidate argument separately while ignoring the relationship between arguments. This paper proposes a Regularization-Based Pattern Balancing Method (RBPB). Inspired by the progress in representation learning, we use trigger embedding, sentence-level embedding and pattern features together as our features for trigger classification so that the effect of patterns and other useful features can be balanced. In addition, RBPB uses a regularization method to take advantage of the relationship between arguments. Experiments show that we achieve results better than current state-of-art equivalents",
    "volume": "long",
    "checked": true,
    "id": "14e8581100bb3a6e4d71caa906e7bbcec569db3f",
    "citation_count": 29
  },
  "https://aclanthology.org/P16-1117": {
    "title": "Neural Network-Based Model for Japanese Predicate Argument Structure Analysis",
    "abstract": "This paper presents a novel model for Japanese predicate argument structure (PAS) analysis based on a neural network framework. Japanese PAS analysis is challenging due to the tangled characteristics of the Japanese language, such as case disappearance and argument omission. To unravel this problem, we learn selectional preferences from a large raw corpus, and incorporate them into a SOTA PAS analysis model, which considers the consistency of all PASs in a given sentence. We demonstrate that the proposed PAS analysis model significantly outperforms the base SOTA system",
    "volume": "long",
    "checked": true,
    "id": "999e79111daaabaceb9e474624571398608b82c4",
    "citation_count": 17
  },
  "https://aclanthology.org/P16-1118": {
    "title": "Addressing Limited Data for Textual Entailment Across Domains",
    "abstract": "We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain",
    "volume": "long",
    "checked": true,
    "id": "a24ef0cc13f3641ed15708471244b630a179d044",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-1119": {
    "title": "Annotating and Predicting Non-Restrictive Noun Phrase Modifications",
    "abstract": "The distinction between restrictive and non-restrictive modification in noun phrases is a well studied subject in linguistics. Automatically identifying non-restrictive modifiers can provide NLP applications with shorter, more salient arguments, which were found beneficial by several recent works. While previous work showed that restrictiveness can be annotated with high agreement, no large scale corpus was created, hindering the development of suitable classification algorithms. In this work we devise a novel crowdsourcing annotation methodology, and an accompanying large scale corpus. Then, we present a robust automated system which identifies non-restrictive modifiers, notably improving over prior methods",
    "volume": "long",
    "checked": true,
    "id": "5815adadcc427c5e6b871394e247eb1e1f8fc9e7",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-1120": {
    "title": "Bilingual Segmented Topic Model",
    "abstract": "This study proposes the bilingual segmented topic model (BiSTM), which hierarchically models documents by treating each document as a set of segments, e.g., sections. While previous bilingual topic models, such as bilingual latent Dirichlet allocation (BiLDA) (Mimno et al., 2009; Ni et al., 2009), consider only cross-lingual alignments between entire documents, the proposed model considers cross-lingual alignments between segments in addition to document-level alignments and assigns the same topic distribution to aligned segments. This study also presents a method for simultaneously inferring latent topics and segmentation boundaries, incorporating unsupervised topic segmentation (Du et al., 2013) into BiSTM. Experimental results show that the proposed model significantly outperforms BiLDA in terms of perplexity and demonstrates improved performance in translation pair extraction (up to +0.083 extraction accuracy)",
    "volume": "long",
    "checked": true,
    "id": "1ce75e970321f8c0f8e03d06fffaba7ec02954ed",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-1121": {
    "title": "Learning Semantically and Additively Compositional Distributional Representations",
    "abstract": "This paper connects a vector-based composition model to a formal semantics, the Dependency-based Compositional Semantics (DCS). We show theoretical evidence that the vector compositions in our model conform to the logic of DCS. Experimentally, we show that vector-based composition brings a strong ability to calculate similar phrases as similar vectors, achieving near state-of-the-art on a wide range of phrase similarity tasks and relation classification; meanwhile, DCS can guide building vectors for structured queries that can be directly executed. We evaluate this utility on sentence completion task and report a new state-of-the-art",
    "volume": "long",
    "checked": true,
    "id": "7e2484a08adcf09ea166119b48faa27adf25390a",
    "citation_count": 17
  },
  "https://aclanthology.org/P16-1122": {
    "title": "Inner Attention based Recurrent Neural Networks for Answer Selection",
    "abstract": "Attention based recurrent neural networks have shown advantages in representing natural language sentences (Hermann et al., 2015; Rocktäschel et al., 2015; Tan et al., 2015). Based on recurrent neural networks (RNN), external attention information was added to hidden representations to get an attentive sentence representation. Despite the improvement over nonattentive models, the attention mechanism under RNN is not well studied. In this work, we analyze the deficiency of traditional attention based RNN models quantitatively and qualitatively. Then we present three new RNN models that add attention information before RNN hidden representation, which shows advantage in representing sentence and achieves new stateof-art results in answer selection task",
    "volume": "long",
    "checked": true,
    "id": "52956422f86722aca6becb67ea4c3ad61f0c1aea",
    "citation_count": 176
  },
  "https://aclanthology.org/P16-1123": {
    "title": "Relation Classification via Multi-Level Attention CNNs",
    "abstract": "Relation classification is a crucial ingredient   in numerous information extraction systems   seeking to mine structured facts from   text. We propose a novel convolutional   neural network architecture for this task,   relying on two levels of attention in order   to better discern patterns in heterogeneous   contexts. This architecture enables endto-end   learning from task-specific labeled   data, forgoing the need for external knowledge   such as explicit dependency structures.   Experiments show that our model outperforms   previous state-of-the-art methods, including   those relying on much richer forms   of prior knowledge",
    "volume": "long",
    "checked": true,
    "id": "d00c31df3c50cd57eba2ad39709e1cb14a208246",
    "citation_count": 385
  },
  "https://aclanthology.org/P16-1124": {
    "title": "Knowledge Base Completion via Coupled Path Ranking",
    "abstract": "Knowledge bases (KBs) are often greatly incomplete, necessitating a demand for KB completion. The path ranking algorithm (PRA) is one of the most promising approaches to this task. Previous work on PRA usually follows a single-task learning paradigm, building a prediction model for each relation independently with its own training data. It ignores meaningful associations among certain relations, and might not get enough training data for less frequent relations. This paper proposes a novel multi-task learning framework for PRA, referred to as coupled PRA (CPRA). It first devises an agglomerative clustering strategy to automatically discover relations that are highly correlated to each other, and then employs a multi-task learning strategy to effectively couple the prediction of such relations. As such, CPRA takes into account relation association and enables implicit data sharing among them. We empirically evaluate CPRA on benchmark data created from Freebase. Experimental results show that CPRA can effectively identify coherent clusters in which relations are highly correlated. By further coupling such relations, CPRA significantly outperforms PRA, in terms of both predictive accuracy and model interpretability",
    "volume": "long",
    "checked": true,
    "id": "35547948c302f6aa30898bda94e7ee29dab463a2",
    "citation_count": 59
  },
  "https://aclanthology.org/P16-1125": {
    "title": "Larger-Context Language Modelling with Recurrent Neural Network",
    "abstract": "In this work, we propose a novel method to incorporate corpus-level discourse information into language modelling. We call this larger-context language model. We introduce a late fusion approach to a recurrent language model based on long shortterm memory units (LSTM), which helps the LSTM unit keep intra-sentence dependencies and inter-sentence dependencies separate from each other. Through the evaluation on four corpora (IMDB, BBC, Penn TreeBank, and Fil9), we demonstrate that the proposed model improves perplexity significantly. In the experiments, we evaluate the proposed approach while varying the number of context sentences and observe that the proposed late fusion is superior to the usual way of incorporating additional inputs to the LSTM. By analyzing the trained larger-context language model, we discover that content words, including nouns, adjectives and verbs, benefit most from an increasing number of context sentences. This analysis suggests that larger-context language model improves the unconditional language model by capturing the theme of a document better and more easily",
    "volume": "long",
    "checked": true,
    "id": "722e01d5ba05083f7a091f3188cfdfcf183a325d",
    "citation_count": 48
  },
  "https://aclanthology.org/P16-1126": {
    "title": "The Creation and Analysis of a Website Privacy Policy Corpus",
    "abstract": "Website privacy policies are often ignored by Internet users, because these documents tend to be long and difficult to understand. However, the significance of privacy policies greatly exceeds the attention paid to them: these documents are binding legal agreements between website operators and their users, and their opaqueness is a challenge not only to Internet users but also to policy regulators. One proposed alternative to the status quo is to automate or semi-automate the extraction of salient details from privacy policy text, using a combination of crowdsourcing, natural language processing, and machine learning. However, there has been a relative dearth of datasets appropriate for identifying data practices in privacy policies. To remedy this problem, we introduce a corpus of 115 privacy policies (267K words) with manual annotations for 23K fine-grained data practices. We describe the process of using skilled annotators and a purpose-built annotation tool to produce the data. We provide findings based on a census of the annotations and show results toward automating the annotation procedure. Finally, we describe challenges and opportunities for the research community to use this corpus to advance research in both privacy and language technologies",
    "volume": "long",
    "checked": true,
    "id": "e14883353786ca0f38f743cc064b1dc4b2ff73bd",
    "citation_count": 176
  },
  "https://aclanthology.org/P16-1127": {
    "title": "Sequence-based Structured Prediction for Semantic Parsing",
    "abstract": "We propose an approach for semantic parsing that uses a recurrent neural network to map a natural language question into a logical form representation of a KB query. Building on recent work by (Wang et al., 2015), the interpretable logical forms, which are structured objects obeying certain constraints, are enumerated by an underlying grammar and are paired with their canonical realizations. In order to use sequence prediction, we need to sequentialize these logical forms. We compare three sequentializations: a direct linearization of the logical form, a linearization of the associated canonical realization, and a sequence consisting of derivation steps relative to the underlying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNN-based sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints",
    "volume": "long",
    "checked": true,
    "id": "bcf16c08a41009d9f9174c6f72b2ff534232c147",
    "citation_count": 96
  },
  "https://aclanthology.org/P16-1128": {
    "title": "Learning Word Meta-Embeddings",
    "abstract": "Word embeddings – distributed representations of words – in deep learning are beneficial for many tasks in NLP. However, different embedding sets vary greatly in quality and characteristics of the captured information. Instead of relying on a more advanced algorithm for embedding learning, this paper proposes an ensemble approach of combining different public embedding sets with the aim of learning metaembeddings. Experiments on word similarity and analogy tasks and on part-of-speech tagging show better performance of metaembeddings compared to individual embedding sets. One advantage of metaembeddings is the increased vocabulary coverage. We release our metaembeddings publicly at http:// cistern.cis.lmu.de/meta-emb",
    "volume": "long",
    "checked": true,
    "id": "0ab02efb13c1af6b1a5ab6f7597c79caf1d5c215",
    "citation_count": 89
  },
  "https://aclanthology.org/P16-1129": {
    "title": "Towards Constructing Sports News from Live Text Commentary",
    "abstract": "In this paper, we investigate the possibility to automatically generate sports news from live text commentary scripts. As a preliminary study, we treat this task as a special kind of document summarization based on sentence extraction. We formulate the task in a supervised learning to rank framework, utilizing both traditional sentence features for generic document summarization and novelly designed task-specific features. To tackle the problem of local redundancy, we also propose a probabilistic sentence selection algorithm. Experiments on our collected data from football live commentary scripts and corresponding sports news demonstrate the feasibility of this task. Evaluation results show that our methods are indeed appropriate for this task, outperforming several baseline methods in different aspects",
    "volume": "long",
    "checked": true,
    "id": "7c7dbe4769eab35f7d33f09c4f36af5a7b51d2c0",
    "citation_count": 34
  },
  "https://aclanthology.org/P16-1130": {
    "title": "A Continuous Space Rule Selection Model for Syntax-based Statistical Machine Translation",
    "abstract": "One of the major challenges for statistical machine translation (SMT) is to choose the appropriate translation rules based on the sentence context. This paper proposes a continuous space rule selection (CSRS) model for syntax-based SMT to perform this context-dependent rule selection. In contrast to existing maximum entropy based rule selection (MERS) models, which use discrete representations of words as features, the CSRS model is learned by a feed-forward neural network and uses real-valued vector representations of words, allowing for better generalization. In addition, we propose a method to train the rule selection models only on minimal rules, which are more frequent and have richer training data compared to non-minimal rules. We tested our model on different translation tasks and the CSRS model outperformed a baseline without rule selection and the previous MERS model by up to 2.2 and 1.1 points of BLEU score respectively",
    "volume": "long",
    "checked": true,
    "id": "a182a8a0678857df5c513d52469fa707c32e69ec",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-1131": {
    "title": "Probabilistic Graph-based Dependency Parsing with Convolutional Neural Network",
    "abstract": "This paper presents neural probabilistic parsing models which explore up to thirdorder graph-based parsing with maximum likelihood training criteria. Two neural network extensions are exploited for performance improvement. Firstly, a convolutional layer that absorbs the influences of all words in a sentence is used so that sentence-level information can be effectively captured. Secondly, a linear layer is added to integrate different order neural models and trained with perceptron method. The proposed parsers are evaluated on English and Chinese Penn Treebanks and obtain competitive accuracies",
    "volume": "long",
    "checked": true,
    "id": "69af98a197b1e9c93af74a84e8f8645143c30a0f",
    "citation_count": 56
  },
  "https://aclanthology.org/P16-1132": {
    "title": "A Search-Based Dynamic Reranking Model for Dependency Parsing",
    "abstract": "We propose a novel reranking method to extend a deterministic neural dependency parser. Different to conventional k-best reranking, the proposed model integrates search and learning by utilizing a dynamic action revising process, using the reranking model to guide modification for the base outputs and to rerank the candidates. The dynamic reranking model achieves an absolute 1.78% accuracy improvement over the deterministic baseline parser on PTB, which is the highest improvement by neural rerankers in the literature",
    "volume": "long",
    "checked": true,
    "id": "e2b5240c2a5ea93139ec03417e59875cfe05e749",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-1133": {
    "title": "Cross-Lingual Sentiment Classification with Bilingual Document Representation Learning",
    "abstract": "Cross-lingual sentiment classification aims to adapt the sentiment resource in a resource-rich language to a resource-poor language. In this study, we propose a representation learning approach which simultaneously learns vector representations for the texts in both the source and the target languages. Different from previous research which only gets bilingual word embedding, our Bilingual Document Representation Learning model BiDRL directly learns document representations. Both semantic and sentiment correlations are utilized to map the bilingual texts into the same embedding space. The experiments are based on the multilingual multi-domain Amazon review dataset. We use English as the source language and use Japanese, German and French as the target languages. The experimental results show that BiDRL outperforms the state-of-the-art methods for all the target languages",
    "volume": "long",
    "checked": true,
    "id": "c65ecfd126f8218df9d589c5e4b6eca4dfd45ad4",
    "citation_count": 102
  },
  "https://aclanthology.org/P16-1134": {
    "title": "Segment-Level Sequence Modeling using Gated Recursive Semi-Markov Conditional Random Fields",
    "abstract": "Most of the sequence tagging tasks in natural language processing require to recognize segments with certain syntactic role or semantic meaning in a sentence. They are usually tackled with Conditional Random Fields (CRFs), which do indirect word-level modeling over word-level features and thus cannot make full use of segment-level information. Semi-Markov Conditional Random Fields (Semi-CRFs) model segments directly but extracting segment-level features for Semi-CRFs is still a very challenging problem. This paper presents Gated Recursive Semi-CRFs (grSemi-CRFs), which model segments directly and automatically learn segmentlevel features through a gated recursive convolutional neural network. Our experiments on text chunking and named entity recognition (NER) demonstrate that grSemi-CRFs generally outperform other neural models",
    "volume": "long",
    "checked": true,
    "id": "e10d7c8773d7adeecb5e6d264b7546cea41b16cf",
    "citation_count": 23
  },
  "https://aclanthology.org/P16-1135": {
    "title": "Identifying Causal Relations Using Parallel Wikipedia Articles",
    "abstract": "The automatic detection of causal relationships in text is important for natural language understanding. This task has proven to be difficult, however, due to the need for world knowledge and inference. We focus on a sub-task of this problem where an open class set of linguistic markers can provide clues towards understanding causality. Unlike the explicit markers, a closed class, these markers vary significantly in their linguistic forms. We leverage parallel Wikipedia corpora to identify new markers that are variations on known causal phrases, creating a training set via distant supervision. We also train a causal classifier using features from the open class markers and semantic features providing contextual information. The results show that our features provide an 11.05 point absolute increase over the baseline on the task of identifying causality in text",
    "volume": "long",
    "checked": true,
    "id": "6be01a493416ea35f1b3bbbf2ee147e64455703e",
    "citation_count": 50
  },
  "https://aclanthology.org/P16-1136": {
    "title": "Compositional Learning of Embeddings for Relation Paths in Knowledge Base and Text",
    "abstract": "Modeling relation paths has offered significant gains in embedding models for knowledge base (KB) completion. However, enumerating paths between two entities is very expensive, and existing approaches typically resort to approximation with a sampled subset. This problem is particularly acute when text is jointly modeled with KB relations and used to provide direct evidence for facts mentioned in it. In this paper, we propose the first exact dynamic programming algorithm which enables efficient incorporation of all relation paths of bounded length, while modeling both relation types and intermediate nodes in the compositional path representations. We conduct a theoretical analysis of the efficiency gain from the approach. Experiments on two datasets show that it addresses representational limitations in prior approaches and improves accuracy in KB completion",
    "volume": "long",
    "checked": true,
    "id": "d2072e4bc03c82697be667c265d728045712bc46",
    "citation_count": 132
  },
  "https://aclanthology.org/P16-1137": {
    "title": "Commonsense Knowledge Base Completion",
    "abstract": "We enrich a curated resource of commonsense knowledge by formulating the problem as one of knowledge base completion (KBC). Most work in KBC focuses on knowledge bases like Freebase that relate entities drawn from a fixed set. However, the tuples in ConceptNet (Speer and Havasi, 2012) define relations between an unbounded set of phrases. We develop neural network models for scoring tuples on arbitrary phrases and evaluate them by their ability to distinguish true held-out tuples from false ones. We find strong performance from a bilinear model using a simple additive architecture to model phrases. We manually evaluate our trained model's ability to assign quality scores to novel tuples, finding that it can propose tuples at the same quality level as mediumconfidence tuples from ConceptNet",
    "volume": "long",
    "checked": true,
    "id": "96743201dc771df1829f061c2648fd0ee1a70e59",
    "citation_count": 129
  },
  "https://aclanthology.org/P16-1138": {
    "title": "Simpler Context-Dependent Logical Forms via Model Projections",
    "abstract": "We consider the task of learning a context-dependent mapping from utterances to denotations. With only denotations at training time, we must search over a combinatorially large space of logical forms, which is even larger with context-dependent utterances. To cope with this challenge, we perform successive projections of the full model onto simpler models that operate over equivalence classes of logical forms. Though less expressive, we find that these simpler models are much faster and can be surprisingly effective. Moreover, they can be used to bootstrap the full model. Finally, we collected three new context-dependent semantic parsing datasets, and develop a new left-to-right parser",
    "volume": "long",
    "checked": true,
    "id": "7306437b2145677fe7bf3b7711ac8aa25989f1e3",
    "citation_count": 83
  },
  "https://aclanthology.org/P16-1139": {
    "title": "A Fast Unified Model for Parsing and Sentence Understanding",
    "abstract": "Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suer from two key technical problems that make them slow and unwieldyforlarge-scaleNLPtasks: theyusually operate on parsed sentences and they do not directly support batched computation. We address these issues by introducingtheStack-augmentedParser-Interpreter NeuralNetwork(SPINN),whichcombines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shiftreduceparser. Ourmodelsupportsbatched computation for a speedup of up to 25◊ over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models",
    "volume": "long",
    "checked": true,
    "id": "36c097a225a95735271960e2b63a2cb9e98bff83",
    "citation_count": 294
  },
  "https://aclanthology.org/P16-1140": {
    "title": "Investigating Language Universal and Specific Properties in Word Embeddings",
    "abstract": "Recently, many NLP tasks have benefited from distributed word representation. However, it remains unknown whether embedding models are really immune to the typological diversity of languages, despite the language-independent architecture. Here we investigate three representative models on a large set of language samples by mapping dense embedding to sparse linguistic property space. Experiment results reveal the language universal and specific properties encoded in various word representation. Additionally, strong evidence supports the utility of word form, especially for inflectional languages",
    "volume": "long",
    "checked": true,
    "id": "61d0e65485e05cb5e8ffe65002cf6c816514eaa4",
    "citation_count": 50
  },
  "https://aclanthology.org/P16-1141": {
    "title": "Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change",
    "abstract": "Understanding how words change their meanings over time is key to models of language and cultural evolution, but historical data on meaning is scarce, making theories hard to develop and test. Word embeddings show promise as a diachronic tool, but have not been carefully evaluated. We develop a robust methodology for quantifying semantic change by evaluating word embeddings (PPMI, SVD, word2vec) against known historical changes. We then use this methodology to reveal statistical laws of semantic evolution. Using six historical corpora spanning four languages and two centuries, we propose two quantitative laws of semantic change: (i) the law of conformity---the rate of semantic change scales with an inverse power-law of word frequency; (ii) the law of innovation---independent of frequency, words that are more polysemous have higher rates of semantic change",
    "volume": "long",
    "checked": true,
    "id": "7ee0a337faec1d87bbb15d84856a43a4aa64ac65",
    "citation_count": 683
  },
  "https://aclanthology.org/P16-1142": {
    "title": "Beyond Plain Spatial Knowledge: Determining Where Entities Are and Are Not Located, and For How Long",
    "abstract": "This paper complements semantic role representations with spatial knowledge beyond indicating plain locations",
    "volume": "long",
    "checked": true,
    "id": "4c26ce6bcca3245900d47c6c8ad25c987638db53",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-1143": {
    "title": "LexSemTm: A Semantic Dataset Based on All-words Unsupervised Sense Distribution Learning",
    "abstract": "There has recently been a lot of interest in unsupervised methods for learning sense distributions, particularly in applications where sense distinctions are needed. This paper analyses a state-of-the-art method for sense distribution learning, and optimises it for application to the entire vocabulary of a given language. The optimised method is then used to produce LEXSEMTM: a sense frequency and semantic dataset of unprecedented size, spanning approximately 88% of polysemous, English simplex lemmas, which is released as a public resource to the community. Finally, the quality of this data is investigated, and the LEXSEMTM sense distributions are shown to be superior to those based on the WORDNET first sense for lemmas missing from SEMCOR, and at least on par with SEMCOR-based distributions otherwise",
    "volume": "long",
    "checked": true,
    "id": "62d25d582b15889ff23d2abedbf9652015bb9f66",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-1144": {
    "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context",
    "abstract": "We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text",
    "volume": "long",
    "checked": true,
    "id": "77fb0b7aef619dfac650423d4677170df2158e0d",
    "citation_count": 177
  },
  "https://aclanthology.org/P16-1145": {
    "title": "WikiReading: A Novel Large-scale Language Understanding Task over Wikipedia",
    "abstract": "We present WIKIREADING, a large-scale natural language understanding task and publicly-available dataset with 18 million instances. The task is to predict textual values from the structured knowledge base Wikidata by reading the text of the corresponding Wikipedia articles. The task contains a rich variety of challenging classification and extraction sub-tasks, making it well-suited for end-to-end models such as deep neural networks (DNNs). We compare various state-of-the-art DNNbased architectures for document classification, information extraction, and question answering. We find that models supporting a rich answer space, such as word or character sequences, perform best. Our best-performing model, a word-level sequence to sequence model with a mechanism to copy out-of-vocabulary words, obtains an accuracy of 71.8%",
    "volume": "long",
    "checked": true,
    "id": "832fc9327695f7425d8759c6aaeec0fa2d7b0a90",
    "citation_count": 123
  },
  "https://aclanthology.org/P16-1146": {
    "title": "Optimizing Spectral Learning for Parsing",
    "abstract": "We describe a search algorithm for optimizing the number of latent states when estimating latent-variable PCFGs with spectral methods. Our results show that contrary to the common belief that the number of latent states for each nonterminal in an L-PCFG can be decided in isolation with spectral methods, parsing results significantly improve if the number of latent states for each nonterminal is globally optimized, while taking into account interactions between the different nonterminals. In addition, we contribute an empirical analysis of spectral algorithms on eight morphologically rich languages: Basque, French, German, Hebrew, Hungarian, Korean, Polish and Swedish. Our results show that our estimation consistently performs better or close to coarse-to-fine expectation-maximization techniques for these languages",
    "volume": "long",
    "checked": true,
    "id": "b8ccc962237fbb6735fa57000a71108182b7bc20",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-1147": {
    "title": "Stack-propagation: Improved Representation Learning for Syntax",
    "abstract": "Traditional syntax models typically leverage part-of-speech (POS) information by constructing features from hand-tuned templates. We demonstrate that a better approach is to utilize POS tags as a regularizer of learned representations. We propose a simple method for learning a stacked pipeline of models which we call \"stack-propagation\". We apply this to dependency parsing and tagging, where we use the hidden layer of the tagger network as a representation of the input tokens for the parser. At test time, our parser does not require predicted POS tags. On 19 languages from the Universal Dependencies, our method is 1.3% (absolute) more accurate than a state-of-the-art graph-based approach and 2.7% more accurate than the most comparable greedy model",
    "volume": "long",
    "checked": true,
    "id": "0c133f79b23e8c680891d2e49a66f0e3d37f1466",
    "citation_count": 85
  },
  "https://aclanthology.org/P16-1148": {
    "title": "Inferring Perceived Demographics from User Emotional Tone and User-Environment Emotional Contrast",
    "abstract": "We examine communications in a social network to study user emotional contrast – the propensity of users to express different emotions than those expressed by their neighbors. Our analysis is based on a large Twitter dataset, consisting of the tweets of 123,513 users from the USA and Canada. Focusing on Ekman's basic emotions, we analyze differences between the emotional tone expressed by these users and their neighbors of different types, and correlate these differences with perceived user demographics. We demonstrate that many perceived demographic traits correlate with the emotional contrast between users and their neighbors. Unlike other approaches on inferring user attributes that rely solely on user communications, we explore the network structure and show that it is possible to accurately predict a range of perceived demographic traits based solely on the emotions emanating from users and their neighbors",
    "volume": "long",
    "checked": true,
    "id": "23d1f54c6be21801870ef02c2e58cf608076b1c5",
    "citation_count": 52
  },
  "https://aclanthology.org/P16-1149": {
    "title": "Prototype Synthesis for Model Laws",
    "abstract": "State legislatures often rely on existing text when drafting new bills. Resource and expertise constraints, which often drive this copying behavior, can be taken advantage of by lobbyists and special interest groups. These groups provide model bills, which encode policy agendas, with the intent that the models become actual law. Unfortunately, model legislation is often opaque to the public–both in source and content. In this paper we present LOBBYBACK, a system that reverse engineers model legislation from observed text. LOBBYBACK identifies clusters of bills which have text reuse and generates \"prototypes\" that represent a canonical version of the text shared between the documents. We demonstrate that LOBBYBACK accurately reconstructs model legislation and apply it to a dataset of over 550k bills",
    "volume": "long",
    "checked": true,
    "id": "1d2d925d5ba6f4a071e89c32bbb499fcd837b370",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-1150": {
    "title": "Which argument is more convincing? Analyzing and predicting convincingness of Web arguments using bidirectional LSTM",
    "abstract": "We propose a new task in the field of computational argumentation in which we investigate qualitative properties of Web arguments, namely their convincingness. We cast the problem as relation classification, where a pair of arguments having the same stance to the same prompt is judged. We annotate a large datasets of 16k pairs of arguments over 32 topics and investigate whether the relation \"A is more convincing than B\" exhibits properties of total ordering; these findings are used as global constraints for cleaning the crowdsourced data. We propose two tasks: (1) predicting which argument from an argument pair is more convincing and (2) ranking all arguments to the topic based on their convincingness. We experiment with feature-rich SVM and bidirectional LSTM and obtain 0.76-0.78 accuracy and 0.35-0.40 Spearman's correlation in a cross-topic evaluation. We release the newly created corpus UKPConvArg1 and the experimental software under open licenses",
    "volume": "long",
    "checked": true,
    "id": "25ae911c13da7ef9def56ee30170920ebd48a668",
    "citation_count": 170
  },
  "https://aclanthology.org/P16-1151": {
    "title": "Discovery of Treatments from Text Corpora",
    "abstract": "An extensive literature in computational social science examines how features of messages, advertisements, and other corpora affect individuals' decisions, but these analyses must specify the relevant features of the text before the experiment. Automated text analysis methods are able to discover features of text, but these methods cannot be used to obtain the estimates of causal effects—the quantity of interest for applied researchers. We introduce a new experimental design and statistical model to simultaneously discover treatments in a corpora and estimate causal effects for these discovered treatments. We prove the conditions to identify the treatment effects of texts and introduce the supervised Indian Buffet process to discover those treatments. Our method enables us to discover treatments in a training set using a collection of texts and individuals' responses to those texts, and then estimate the effects of these interventions in a test set of new texts and survey respondents. We apply the model to an experiment about candidate biographies, recovering intuitive features of voters' decisions and revealing a penalty for lawyers and a bonus for military service",
    "volume": "long",
    "checked": true,
    "id": "3cbc814f6e42ac6c6cc2700f26ce3d7354a00150",
    "citation_count": 36
  },
  "https://aclanthology.org/P16-1152": {
    "title": "Learning Structured Predictors from Bandit Feedback for Interactive NLP",
    "abstract": "Structured prediction from bandit feedback describes a learning scenario where instead of having access to a gold standard structure, a learner only receives partial feedback in form of the loss value of a predicted structure. We present new learning objectives and algorithms for this interactive scenario, focusing on convergence speed and ease of elicitability of feedback. We present supervised-to-bandit simulation experiments for several NLP tasks (machine translation, sequence labeling, text classification), showing that bandit learning from relative preferences eases feedback strength and yields improved empirical convergence",
    "volume": "long",
    "checked": true,
    "id": "d1c822344cacb4350ef3f2b3bbaba69814169349",
    "citation_count": 28
  },
  "https://aclanthology.org/P16-1153": {
    "title": "Deep Reinforcement Learning with a Natural Language Action Space",
    "abstract": "This paper introduces a novel architecture for reinforcement learning with deep neural networks designed to handle state and action spaces characterized by natural language, as found in text-based games. Termed a deep reinforcement relevance network (DRRN), the architecture represents action and state spaces with separate embedding vectors, which are combined with an interaction function to approximate the Q-function in reinforcement learning. We evaluate the DRRN on two popular text games, showing superior performance over other deep Q-learning architectures. Experiments with paraphrased action descriptions show that the model is extracting meaning rather than simply memorizing strings of text",
    "volume": "long",
    "checked": true,
    "id": "6118910c4014cc6c061198a2d88c080ab56ea452",
    "citation_count": 163
  },
  "https://aclanthology.org/P16-1154": {
    "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
    "abstract": "We address an important problem in sequence-to-sequence (Seq2Seq) learning referred to as copying, in which certain segments in the input sequence are selectively replicated in the output sequence. A similar phenomenon is observable in human language communication. For example, humans tend to repeat entity names or even long phrases in conversation. The challenge with regard to copying in Seq2Seq is that new machinery is needed to decide when to perform the operation. In this paper, we incorporate copying into neural network-based Seq2Seq learning and propose a new model called CopyNet with encoder-decoder structure. CopyNet can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub-sequences in the input sequence and put them at proper places in the output sequence. Our empirical study on both synthetic data sets and real world data sets demonstrates the efficacy of CopyNet. For example, CopyNet can outperform regular RNN-based model with remarkable margins on text summarization tasks",
    "volume": "long",
    "checked": true,
    "id": "ba30df190664193514d1d309cb673728ed48f449",
    "citation_count": 1271
  },
  "https://aclanthology.org/P16-1155": {
    "title": "Cross-domain Text Classification with Multiple Domains and Disparate Label Sets",
    "abstract": "Advances in transfer learning have let go the limitations of traditional supervised machine learning algorithms for being dependent on annotated training data for training new models for every new domain. However, several applications encounter scenarios where models need to transfer/adapt across domains when the label sets vary both in terms of count of labels as well as their connotations. This paper presents first-of-its-kind transfer learning algorithm for cross-domain classification with multiple source domains and disparate label sets. It starts with identifying transferable knowledge from across multiple domains that can be useful for learning the target domain task. This knowledge in the form of selective labeled instances from different domains is congregated to form an auxiliary training set which is used for learning the target domain task. Experimental results validate the efficacy of the proposed algorithm against strong baselines on a real world social media and the 20 Newsgroups datasets",
    "volume": "long",
    "checked": true,
    "id": "70da13dabcc47ac7fe0ce9e48e45b8ee0c5d8b90",
    "citation_count": 15
  },
  "https://aclanthology.org/P16-1156": {
    "title": "Morphological Smoothing and Extrapolation of Word Embeddings",
    "abstract": "Languages with rich inflectional morphology exhibit lexical data sparsity, since the word used to express a given concept will vary with the syntactic context. For instance, each count noun in Czech has 12 forms (where English uses only singular and plural). Even in large corpora, we are unlikely to observe all inflections of a given lemma. This reduces the vocabulary coverage of methods that induce continuous representations for words from distributional corpus information. We solve this problem by exploiting existing morphological resources that can enumerate a word's component morphemes. We present a latentvariable Gaussian graphical model that allows us to extrapolate continuous representations for words not observed in the training corpus, as well as smoothing the representations provided for the observed words. The latent variables represent embeddings of morphemes, which combine to create embeddings of words. Over several languages and training sizes, our model improves the embeddings for words, when evaluated on an analogy task, skip-gram predictive accuracy, and word similarity",
    "volume": "long",
    "checked": true,
    "id": "2990cf242558ede739d6a26a2f8b098f94390323",
    "citation_count": 62
  },
  "https://aclanthology.org/P16-1157": {
    "title": "Cross-lingual Models of Word Embeddings: An Empirical Comparison",
    "abstract": "Despite interest in using cross-lingual knowledge to learn word embeddings for various tasks, a systematic comparison of the possible approaches is lacking in the literature. We perform an extensive evaluation of four popular approaches of inducing cross-lingual embeddings, each requiring a different form of supervision, on four typographically different language pairs. Our evaluation setup spans four different tasks, including intrinsic evaluation on mono-lingual and cross-lingual similarity, and extrinsic evaluation on downstream semantic and syntactic applications. We show that models which require expensive cross-lingual knowledge almost always perform better, but cheaply supervised models often prove competitive on certain tasks",
    "volume": "long",
    "checked": true,
    "id": "bee7127aaa42ba266c939b65eec20dc66be4592c",
    "citation_count": 183
  },
  "https://aclanthology.org/P16-1158": {
    "title": "Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility of Vector Differences for Lexical Relation Learning",
    "abstract": "Recent work on word embeddings has shown that simple vector subtraction over pre-trained embeddings is surprisingly effective at capturing different lexical relations, despite lacking explicit supervision. Prior work has evaluated this intriguing result using a word analogy prediction formulation and hand-selected relations, but the generality of the finding over a broader range of lexical relation types and different learning settings has not been evaluated. In this paper, we carry out such an evaluation in two learning settings: (1) spectral clustering to induce word relations, and (2) supervised learning to classify vector differences into relation types. We find that word embeddings capture a surprising amount of information, and that, under suitable supervised training, vector subtraction generalises well to a broad range of relations, including over unseen lexical items",
    "volume": "long",
    "checked": true,
    "id": "9937d5b404662c56b33fcbfa35453b72d250b319",
    "citation_count": 125
  },
  "https://aclanthology.org/P16-1159": {
    "title": "Minimum Risk Training for Neural Machine Translation",
    "abstract": "We propose minimum risk training for end-to-end neural machine translation. Unlike conventional maximum likelihood estimation, minimum risk training is capable of optimizing model parameters directly with respect to arbitrary evaluation metrics, which are not necessarily differentiable. Experiments show that our approach achieves significant improvements over maximum likelihood estimation on a state-of-the-art neural machine translation system across various languages pairs. Transparent to architectures, our approach can be applied to more neural networks and potentially benefit more NLP tasks",
    "volume": "long",
    "checked": true,
    "id": "9f2a8e923965b23c11066a2ead79658208f1fae1",
    "citation_count": 389
  },
  "https://aclanthology.org/P16-1160": {
    "title": "A Character-level Decoder without Explicit Segmentation for Neural Machine Translation",
    "abstract": "The existing machine translation systems, whether phrase-based or neural, have relied almost exclusively on word-level modelling with explicit segmentation. In this paper, we ask a fundamental question: can neural machine translation generate a character sequence without any explicit segmentation? To answer this question, we evaluate an attention-based encoder-decoder with a subword-level encoder and a character-level decoder on four language pairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15. Our experiments show that the models with a character-level decoder outperform the ones with a subword-level decoder on all of the four language pairs. Furthermore, the ensembles of neural models with a character-level decoder outperform the state-of-the-art non-neural machine translation systems on En-Cs, En-De and En-Fi and perform comparably on En-Ru",
    "volume": "long",
    "checked": true,
    "id": "acec46ffd3f6046af97529127d98f1d623816ea4",
    "citation_count": 312
  },
  "https://aclanthology.org/P16-1161": {
    "title": "Target-Side Context for Discriminative Models in Statistical Machine Translation",
    "abstract": "Discriminative translation models utilizing source context have been shown to help statistical machine translation performance. We propose a novel extension of this work using target context information. Surprisingly, we show that this model can be efficiently integrated directly in the decoding process. Our approach scales to large training data sizes and results in consistent improvements in translation quality on four language pairs. We also provide an analysis comparing the strengths of the baseline source-context model with our extended source-context and target-context model and we show that our extension allows us to better capture morphological coherence. Our work is freely available as part of Moses",
    "volume": "long",
    "checked": true,
    "id": "ec0c590c87be8550b6637e2c5caf5506aa71b589",
    "citation_count": 13
  },
  "https://aclanthology.org/P16-1162": {
    "title": "Neural Machine Translation of Rare Words with Subword Units",
    "abstract": "Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively",
    "volume": "long",
    "checked": true,
    "id": "1af68821518f03568f913ab03fc02080247a27ff",
    "citation_count": 5193
  },
  "https://aclanthology.org/P16-1163": {
    "title": "Implicit Discourse Relation Detection via a Deep Architecture with Gated Relevance Network",
    "abstract": "Word pairs, which are one of the most easily accessible features between two text segments, have been proven to be very useful for detecting the discourse relations held between text segments. However, because of the data sparsity problem, the performance achieved by using word pair features is limited. In this paper, in order to overcome the data sparsity problem, we propose the use of word embeddings to replace the original words. Moreover, we adopt a gated relevance network to capture the semantic interaction between word pairs, and then aggregate those semantic interactions using a pooling layer to select the most informative interactions. Experimental results on Penn Discourse Tree Bank show that the proposed method without using manually designed features can achieve better performance on recognizing the discourse level relations in all of the relations",
    "volume": "long",
    "checked": true,
    "id": "7e07abeb4da256413d66d6bc692665596a45bf00",
    "citation_count": 64
  },
  "https://aclanthology.org/P16-1164": {
    "title": "Model Architectures for Quotation Detection",
    "abstract": "Quotation detection is the task of locating spans of quoted speech in text. The state of the art treats this problem as a sequence labeling task and employs linear-chain conditional random fields. We question the efficacy of this choice: The Markov assumption in the model prohibits it from making joint decisions about the begin, end, and internal context of a quotation. We perform an extensive analysis with two new model architectures. We find that (a), simple boundary classification combined with a greedy prediction strategy is competitive with the state of the art; (b), a semi-Markov model significantly outperforms all others, by relaxing the Markov assumption",
    "volume": "long",
    "checked": true,
    "id": "062edb5f2f8dac87f276430cf9090f10e57d3a64",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-1165": {
    "title": "Speech Act Modeling of Written Asynchronous Conversations with Task-Specific Embeddings and Conditional Structured Models",
    "abstract": "This paper addresses the problem of speech act recognition in written asynchronous conversations (e.g., fora, emails). We propose a class of conditional structured models defined over arbitrary graph structures to capture the conversational dependencies between sentences. Our models use sentence representations encoded by a long short term memory (LSTM) recurrent neural model. Empirical evaluation shows the effectiveness of our approach over existing ones: (i) LSTMs provide better task-specific representations, and (ii) the global joint model improves over local models",
    "volume": "long",
    "checked": true,
    "id": "197410510312a9db323c291dbdde973fe14b9742",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-1166": {
    "title": "Situation entity types: automatic classification of clause-level aspect",
    "abstract": "This paper describes the first robust approach to automatically labeling clauses with their situation entity type (Smith, 2003), capturing aspectual phenomena at the clause level which are relevant for interpreting both semantics at the clause level and discourse structure. Previous work on this task used a small data set from a limited domain, and relied mainly on words as features, an approach which is impractical in larger settings. We provide a new corpus of texts from 13 genres (40,000 clauses) annotated with situation entity types. We show that our sequence labeling approach using distributional information in the form of Brown clusters, as well as syntactic-semantic features targeted to the task, is robust across genres, reaching accuracies of up to 76%",
    "volume": "long",
    "checked": true,
    "id": "e458e5ac8488a9c3f3a389c093118dba1590cfb1",
    "citation_count": 38
  },
  "https://aclanthology.org/P16-1167": {
    "title": "Learning Prototypical Event Structure from Photo Albums",
    "abstract": "Activities and events in our lives are structural, be it a vacation, a camping trip, or a wedding. While individual details vary, there are characteristic patterns that are specific to each of these scenarios. For example, a wedding typically consists of a sequence of events such as walking down the aisle, exchanging vows, and dancing. In this paper, we present a data-driven approach to learning event knowledge from a large collection of photo albums. We formulate the task as constrained optimization to induce the prototypical temporal structure of an event, integrating both visual and textual cues. Comprehensive evaluation demonstrates that it is possible to learn multimodal knowledge of event structure from noisy web content",
    "volume": "long",
    "checked": true,
    "id": "f6a5f61942da1653725315dc23b1bd399b056d97",
    "citation_count": 13
  },
  "https://aclanthology.org/P16-1168": {
    "title": "Cross-Lingual Image Caption Generation",
    "abstract": "Automatically generating a natural language description of an image is a fundamental problem in artificial intelligence. This task involves both computer vision and natural language processing and is called \"image caption generation.\" Research on image caption generation has typically focused on taking in an image and generating a caption in English as existing image caption corpora are mostly in English. The lack of corpora in languages other than English is an issue, especially for morphologically rich languages such as Japanese. There is thus a need for corpora sufficiently large for image captioning in other languages. We have developed a Japanese version of the MS COCO caption dataset and a generative model based on a deep recurrent architecture that takes in an image and uses this Japanese version of the dataset to generate a caption in Japanese. As the Japanese portion of the corpus is small, our model was designed to transfer the knowledge representation obtained from the English portion into the Japanese portion. Experiments showed that the resulting bilingual comparable corpus has better performance than a monolingual corpus, indicating that image understanding using a resource-rich language benefits a resource-poor language",
    "volume": "long",
    "checked": true,
    "id": "558c587373e2ea44898f70de7858da71aa217b8d",
    "citation_count": 67
  },
  "https://aclanthology.org/P16-1169": {
    "title": "Learning Concept Taxonomies from Multi-modal Data",
    "abstract": "We study the problem of automatically building hypernym taxonomies from textual and visual data. Previous works in taxonomy induction generally ignore the increasingly prominent visual data, which encode important perceptual semantics. Instead, we propose a probabilistic model for taxonomy induction by jointly leveraging text and images. To avoid hand-crafted feature engineering, we design end-to-end features based on distributed representations of images and words. The model is discriminatively trained given a small set of existing ontologies and is capable of building full taxonomies from scratch for a collection of unseen conceptual label items with associated images. We evaluate our model and features on the WordNet hierarchies, where our system outperforms previous approaches by a large gap",
    "volume": "long",
    "checked": true,
    "id": "58e6230e119feb5b6e4a9760872c7d65ada5fcb5",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-1170": {
    "title": "Generating Natural Questions About an Image",
    "abstract": "There has been an explosion of work in the vision & language community during the past few years from image captioning to video transcription, and answering questions about images. These tasks have focused on literal descriptions of the image. To move beyond the literal, we choose to explore how questions about an image are often directed at commonsense inference and the abstract events evoked by objects in the image. In this paper, we introduce the novel task of Visual Question Generation (VQG), where the system is tasked with asking a natural and engaging question when shown an image. We provide three datasets which cover a variety of images from object-centric to event-centric, with considerably more abstract training data than provided to state-of-the-art captioning systems thus far. We train and test several generative and retrieval models to tackle the task of VQG. Evaluation results show that while such models ask reasonable questions for a variety of images, there is still a wide gap with human performance which motivates further work on connecting images with commonsense knowledge and pragmatics. Our proposed task offers a new challenge to the community which we hope furthers interest in exploring deeper connections between vision & language",
    "volume": "long",
    "checked": true,
    "id": "8ae09bb88506aa667ac01642f0cbc9dbb30a628d",
    "citation_count": 245
  },
  "https://aclanthology.org/P16-1171": {
    "title": "Physical Causality of Action Verbs in Grounded Language Understanding",
    "abstract": "Linguistics studies have shown that action verbs often denote some Change of State (CoS) as the result of an action. However, the causality of action verbs and its potential connection with the physical world has not been systematically explored. To address this limitation, this paper presents a study on physical causality of action verbs and their implied changes in the physical world. We first conducted a crowdsourcing experiment and identified eighteen categories of physical causality for action verbs. For a subset of these categories, we then defined a set of detectors that detect the corresponding change from visual perception of the physical environment. We further incorporated physical causality modeling and state detection in grounded language understanding. Our empirical studies have demonstrated the effectiveness of causality modeling in grounding language to perception",
    "volume": "long",
    "checked": true,
    "id": "46c714a1ab88936cc3f3be5076a916d9e6ac1298",
    "citation_count": 40
  },
  "https://aclanthology.org/P16-1172": {
    "title": "Optimizing an Approximation of ROUGE - a Problem-Reduction Approach to Extractive Multi-Document Summarization",
    "abstract": "This paper presents a problem-reduction   approach to extractive multi-document   summarization: we propose a reduction   to the problem of scoring individual sentences   with their ROUGE scores based on   supervised learning. For the summarization,   we solve an optimization problem   where the ROUGE score of the selected   summary sentences is maximized. To this   end, we derive an approximation of the   ROUGE-N score of a set of sentences, and   define a principled discrete optimization   problem for sentence selection. Mathematical   and empirical evidence suggests   that the sentence selection step is solved   almost exactly, thus reducing the problem   to the sentence scoring task. We perform   a detailed experimental evaluation on two   DUC datasets to demonstrate the validity   of our approach",
    "volume": "long",
    "checked": true,
    "id": "65455772149b5d0d7db369da2fb9f1795ad2acf8",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-1173": {
    "title": "Phrase Structure Annotation and Parsing for Learner English",
    "abstract": "There has been almost no work on phrase structure annotation and parsing specially designed for learner English despite the fact that they are useful for representing the structural characteristics of learner English. To address this problem, in this paper, we first propose a phrase structure annotation scheme for learner English and annotate two different learner corpora using it. Second, we show their usefulness, reporting on (a) inter-annotator agreement rate, (b) characteristic CFG rules in the corpora, and (c) parsing performance on them. In addition, we explore methods to improve phrase structure parsing for learner English (achieving an F -measure of 0.878). Finally, we release the full annotation guidelines, the annotated data, and the improved parser model for learner English to the public",
    "volume": "long",
    "checked": true,
    "id": "70ffa886b3507fb48d49ac483ab0619d35e33a91",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-1174": {
    "title": "A Trainable Spaced Repetition Model for Language Learning",
    "abstract": "We present half-life regression (HLR) , a novel model for spaced repetition practice with applications to second language acquisition. HLR combines psycholinguistic theory with modern machine learning techniques, indirectly estimating the \"half-life\" of a word or concept in a student's long-term memory. We use data from Duolingo — a popular online language learning application — to ﬁt HLR models, reducing error by 45%+ compared to several baselines at predicting student recall rates. HLR model weights also shed light on which linguistic concepts are system-atically challenging for second language learners. Finally, HLR was able to improve Duolingo daily student engagement by 12% in an operational user study",
    "volume": "long",
    "checked": true,
    "id": "cb836d2b8e126dc31ded5e674d73021604dcc6e0",
    "citation_count": 123
  },
  "https://aclanthology.org/P16-1175": {
    "title": "User Modeling in Language Learning with Macaronic Texts",
    "abstract": "Foreign language learners can acquire new vocabulary by using cognate and context clues when reading. To measure such incidental comprehension, we devise an experimental framework that involves reading mixed-language \"macaronic\" sentences. Using data collected via Amazon Mechanical Turk, we train a graphical model to simulate a human subject's comprehension of foreign words, based on cognate clues (edit distance to an English word), context clues (pointwise mutual in-formation), and prior exposure. Our model does a reasonable job at predicting which words a user will be able to understand, which should facilitate the automatic construction of comprehensible text for personalized foreign language education",
    "volume": "long",
    "checked": true,
    "id": "ad7eac156b117169836264eea52762f07054dc57",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-1176": {
    "title": "On the Similarities Between Native, Non-native and Translated Texts",
    "abstract": "We present a computational analysis of three language varieties: native, advanced non-native, and translation. Our goal is to investigate the similarities and differences between non-native language productions and translations, contrasting both with native language. Using a collection of computational methods we establish three main results: (1) the three types of texts are easily distinguishable; (2) nonnative language and translations are closer to each other than each of them is to native language; and (3) some of these characteristics depend on the source or native language, while others do not, reflecting, perhaps, unified principles that similarly affect translations and non-native language",
    "volume": "long",
    "checked": true,
    "id": "b63fca61d26aa08e99e74c40078bfdb936b14919",
    "citation_count": 19
  },
  "https://aclanthology.org/P16-1177": {
    "title": "Learning Text Pair Similarity with Context-sensitive Autoencoders",
    "abstract": "We present a pairwise context-sensitive Autoencoder for computing text pair similarity. Our model encodes input text into context-sensitive representations and uses them to compute similarity between text pairs. Our model outperforms the state-of-the-art models in two semantic retrieval tasks and a contextual word similarity task. For retrieval, our unsupervised approach that merely ranks inputs with respect to the cosine similarity between their hidden representations shows comparable performance with the state-of-the-art supervised models and in some cases outperforms them",
    "volume": "long",
    "checked": true,
    "id": "6cd41844f49718f22db8f79854ded452cca79016",
    "citation_count": 41
  },
  "https://aclanthology.org/P16-1178": {
    "title": "Linguistic Benchmarks of Online News Article Quality",
    "abstract": "Online news editors ask themselves the same question many times: what is missing in this news article to go online? This is not an easy question to be answered by computational linguistic methods. In this work, we address this important question and characterise the constituents of news article editorial quality. More specifically, we identify 14 aspects related to the content of news articles. Through a correlation analysis, we quantify their independence and relation to assessing an article's editorial quality. We also demonstrate that the identified aspects, when combined together, can be used effectively in quality control methods for online news",
    "volume": "long",
    "checked": true,
    "id": "532166252876cb8c09511f47583aa98512a9a209",
    "citation_count": 12
  },
  "https://aclanthology.org/P16-1179": {
    "title": "Alleviating Poor Context with Background Knowledge for Named Entity Disambiguation",
    "abstract": "Named Entity Disambiguation (NED) algorithms disambiguate mentions of named entities with respect to a knowledge-base, but sometimes the context might be poor or misleading. In this paper we introduce the acquisition of two kinds of background information to alleviate that problem: entity similarity and selectional preferences for syntactic positions. We show, using a generative Näive Bayes model for NED, that the additional sources of context are complementary, and improve results in the CoNLL 2003 and TAC KBP DEL 2014 datasets, yielding the third best and the best results, respectively. We provide examples and analysis which show the value of the acquired background information",
    "volume": "long",
    "checked": true,
    "id": "755fc188715f7a00512d63c784c6c8b170c929ef",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-1180": {
    "title": "Mining Paraphrasal Typed Templates from a Plain Text Corpus",
    "abstract": "Finding paraphrases in text is an important task with implications for generation, summarization and question answering, among other applications. Of particular interest to those applications is the specific formulation of the task where the paraphrases are templated, which provides an easy way to lexicalize one message in multiple ways by simply plugging in the relevant entities. Previous work has focused on mining paraphrases from parallel and comparable corpora, or mining very short sub-sentence synonyms and paraphrases. In this paper we present an approach which combines distributional and KB-driven methods to allow robust mining of sentence-level paraphrasal templates, utilizing a rich type system for the slots, from a plain text corpus",
    "volume": "long",
    "checked": true,
    "id": "e9b9e6cfa83d5d46cf40b56623b6e9d2a49457fe",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-1181": {
    "title": "How to Train Dependency Parsers with Inexact Search for Joint Sentence Boundary Detection and Parsing of Entire Documents",
    "abstract": "We cast sentence boundary detection and syntactic parsing as a joint problem, so an entire text document forms a training instance for transition-based dependency parsing. When trained with an early update or max-violation strategy for inexact search, we observe that only a tiny part of these very long training instances is ever exploited. We demonstrate this effect by extending the ArcStandard transition system with swap for the joint prediction task. When we use an alternative update strategy, our models are considerably better on both tasks and train in substantially less time compared to models trained with early update/max-violation. A comparison between a standard pipeline and our joint model furthermore empirically shows the usefulness of syntactic information on the task of sentence boundary detection",
    "volume": "long",
    "checked": true,
    "id": "315ad10e3dc28fd87c582694f1fd88fda147688e",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-1182": {
    "title": "MUTT: Metric Unit TesTing for Language Generation Tasks",
    "abstract": "Precise evaluation metrics are important for assessing progress in high-level language generation tasks such as machine translation or image captioning. Historically, these metrics have been evaluated using correlation with human judgment. However, human-derived scores are often alarmingly inconsistent and are also limited in their ability to identify precise areas of weakness. In this paper, we perform a case study for metric evaluation by measuring the effect that systematic sentence transformations (e.g. active to passive voice) have on the automatic metric scores. These sentence \"corruptions\" serve as unit tests for precisely measuring the strengths and weaknesses of a given metric. We find that not only are human annotations heavily inconsistent in this study, but that the Metric Unit TesT analysis is able to capture precise shortcomings of particular metrics (e.g. comparing passive and active sentences) better than a simple correlation with human judgment can",
    "volume": "long",
    "checked": true,
    "id": "d0631ba22add59684fff926d80d2e6948dfb7d7e",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-1183": {
    "title": "N-gram language models for massively parallel devices",
    "abstract": "For many applications, the query speed of N -gram language models is a computational bottleneck. Although massively parallel hardware like GPUs offer a potential solution to this bottleneck, exploiting this hardware requires a careful rethinking of basic algorithms and data structures. We present the first language model designed for such hardware, using B-trees to maximize data parallelism and minimize memory footprint and latency. Compared with a single-threaded instance of KenLM (Heafield, 2011), a highly optimized CPUbased language model, our GPU implementation produces identical results with a smaller memory footprint and a sixfold increase in throughput on a batch query task. When we saturate both devices, the GPU delivers nearly twice the throughput per hardware dollar even when the CPU implementation uses faster data structures. Our implementation is freely available at",
    "volume": "long",
    "checked": true,
    "id": "8f8c0588a7126a03a366b6f30000543ae1211b79",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-1184": {
    "title": "Cross-Lingual Morphological Tagging for Low-Resource Languages",
    "abstract": "Morphologically rich languages often lack the annotated linguistic resources required to develop accurate natural language processing tools. We propose models suitable for training morphological taggers with rich tagsets for low-resource languages without using direct supervision. Our approach extends existing approaches of projecting part-of-speech tags across languages, using bitext to infer constraints on the possible tags for a given word type or token. We propose a tagging model using Wsabie, a discriminative embeddingbased model with rank-based learning. In our evaluation on 11 languages, on average this model performs on par with a baseline weakly-supervised HMM, while being more scalable. Multilingual experiments show that the method performs best when projecting between related language pairs. Despite the inherently lossy projection, we show that the morphological tags predicted by our models improve the downstream performance of a parser by +0.6 LAS on average",
    "volume": "long",
    "checked": true,
    "id": "5941df790aa678f9d3f7a1f2bde7f6be353bf244",
    "citation_count": 39
  },
  "https://aclanthology.org/P16-1185": {
    "title": "Semi-Supervised Learning for Neural Machine Translation",
    "abstract": "While end-to-end neural machine translation (NMT) has made remarkable progress recently, NMT systems only rely on parallel corpora for parameter estimation. Since parallel corpora are usually limited in quantity, quality, and coverage, especially for low-resource languages, it is appealing to exploit monolingual corpora to improve NMT. We propose a semi-supervised approach for training NMT models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. The central idea is to reconstruct the monolingual corpora using an autoencoder, in which the source-to-target and target-to-source translation models serve as the encoder and decoder, respectively. Our approach can not only exploit the monolingual corpora of the target language, but also of the source language. Experiments on the Chinese-English dataset show that our approach achieves significant improvements over state-of-the-art SMT and NMT systems",
    "volume": "long",
    "checked": true,
    "id": "593338fbbb79065891beaf985a95860bd39f52bf",
    "citation_count": 159
  },
  "https://aclanthology.org/P16-1186": {
    "title": "Strategies for Training Large Vocabulary Neural Language Models",
    "abstract": "Training neural network language models over large vocabularies is still computationally very costly compared to count-based models such as Kneser-Ney. At the same time, neural language models are gaining popularity for many applications such as speech recognition and machine translation whose success depends on scalability. We present a systematic comparison of strategies to represent and train large vocabularies, including softmax, hierarchical softmax, target sampling, noise contrastive estimation and self normalization. We further extend self normalization to be a proper estimator of likelihood and introduce an efficient variant of softmax. We evaluate each method on three popular benchmarks, examining performance on rare words, the speed/accuracy trade-off and complementarity to Kneser-Ney",
    "volume": "long",
    "checked": true,
    "id": "759956bb98689dbcc891528636d8994e54318f85",
    "citation_count": 130
  },
  "https://aclanthology.org/P16-1187": {
    "title": "Predicting the Compositionality of Nominal Compounds: Giving Word Embeddings a Hard Time",
    "abstract": "Distributional semantic models (DSMs) are often evaluated on artificial similarity datasets containing single words or fully compositional phrases. We present a large-scale multilingual evaluation of DSMs for predicting the degree of semantic compositionality of nominal compounds on 4 datasets for English and French. We build a total of 816 DSMs and perform 2,856 evaluations using word2vec, GloVe, and PPMI-based models. In addition to the DSMs, we compare the impact of different parameters, such as level of corpus preprocessing, context window size and number of dimensions. The results obtained have a high correlation with human judgments, being comparable to or outperforming the state of the art for some datasets (Spearman's ρ=.82 for the Reddy dataset)",
    "volume": "long",
    "checked": true,
    "id": "43fb77798308826742692ab4e1e293fe552162e6",
    "citation_count": 39
  },
  "https://aclanthology.org/P16-1188": {
    "title": "Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints",
    "abstract": "We present a discriminative model for single-document summarization that integrally combines compression and anaphoricity constraints. Our model selects textual units to include in the summary based on a rich set of sparse features whose weights are learned on a large corpus. We allow for the deletion of content within a sentence when that deletion is licensed by compression rules; in our framework, these are implemented as dependencies between subsentential units of text. Anaphoricity constraints then improve cross-sentence coherence by guaranteeing that, for each pronoun included in the summary, the pronoun's antecedent is included as well or the pronoun is rewritten as a full mention. When trained end-to-end, our final system outperforms prior work on both ROUGE as well as on human judgments of linguistic quality",
    "volume": "long",
    "checked": true,
    "id": "507d6e09f51b2fc93f756ab748f6eadd11b7b86e",
    "citation_count": 135
  },
  "https://aclanthology.org/P16-1189": {
    "title": "Set-Theoretic Alignment for Comparable Corpora",
    "abstract": "We describe and evaluate a simple method to extract parallel sentences from comparable corpora. The approach, termed STACC, is based on expanded lexical sets and the Jaccard similarity coefficient. We evaluate our system against state-of-theart methods on a large range of datasets in different domains, for ten language pairs, showing that it either matches or outperforms current methods across the board and gives significantly better results on the noisiest datasets. STACC is a portable method, requiring no particular adaptation for new domains or language pairs, thus enabling the efficient mining of parallel sentences in comparable corpora",
    "volume": "long",
    "checked": true,
    "id": "33f4c87dd6fe0d8467f498b6c3d301f2e4a286bc",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-1190": {
    "title": "Jointly Learning to Embed and Predict with Multiple Languages",
    "abstract": "We propose a joint formulation for learning task-specific cross-lingual word embeddings, along with classifiers for that task. Unlike prior work, which first learns the embeddings from parallel data and then plugs them in a supervised learning problem, our approach is oneshot: a single optimization problem combines a co-regularizer for the multilingual embeddings with a task-specific loss. We present theoretical results showing the limitation of Euclidean co-regularizers to increase the embedding dimension, a limitation which does not exist for other co-regularizers (such as the '1distance). Despite its simplicity, our method achieves state-of-the-art accuracies on the RCV1/RCV2 dataset when transferring from English to German, with training times below 1 minute. On the TED Corpus, we obtain the highest reported scores on 10 out of 11 languages",
    "volume": "long",
    "checked": true,
    "id": "fb533d488d84620cddf027e83dfbe46b1ae0e17e",
    "citation_count": 24
  },
  "https://aclanthology.org/P16-1191": {
    "title": "Supersense Embeddings: A Unified Model for Supersense Interpretation, Prediction, and Utilization",
    "abstract": "Coarse-grained semantic categories such as supersenses have proven useful for a range of downstream tasks such as question answering or machine translation. To date, no effort has been put into integrating the supersenses into distributional word representations. We present a novel joint embedding model of words and supersenses, providing insights into the relationship between words and supersenses in the same vector space. Using these embeddings in a deep neural network model, we demonstrate that the supersense enrichment leads to a significant improvement in a range of downstream classification tasks",
    "volume": "long",
    "checked": true,
    "id": "9c7c96521eb20b09733378af30c3335466f7a175",
    "citation_count": 56
  },
  "https://aclanthology.org/P16-1192": {
    "title": "Efficient techniques for parsing with tree automata",
    "abstract": "Parsing for a wide variety of grammar formalisms can be performed by intersecting finite tree automata. However, naive implementations of parsing by intersection are very inefficient. We present techniques that speed up tree-automata-based parsing, to the point that it becomes practically feasible on realistic data when applied to context-free, TAG, and graph parsing. For graph parsing, we obtain the best runtimes in the literature",
    "volume": "long",
    "checked": true,
    "id": "25d9aa0086a27ea28544c3e47260d8d9f8e2a586",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-1193": {
    "title": "A Vector Space for Distributional Semantics for Entailment",
    "abstract": "Distributional semantics creates vector-space representations that capture many forms of semantic similarity, but their relation to semantic entailment has been less clear. We propose a vector-space model which provides a formal foundation for a distributional semantics of entailment. Using a mean-field approximation, we develop approximate inference procedures and entailment operators over vectors of probabilities of features being known (versus unknown). We use this framework to reinterpret an existing distributional-semantic model (Word2Vec) as approximating an entailment-based model of the distributions of words in contexts, thereby predicting lexical entailment relations. In both unsupervised and semi-supervised experiments on hyponymy detection, we get substantial improvements over previous results",
    "volume": "long",
    "checked": true,
    "id": "9004af5f4a155dc8ca0ce09ae276fdbcd673d341",
    "citation_count": 23
  },
  "https://aclanthology.org/P16-1194": {
    "title": "Hidden Softmax Sequence Model for Dialogue Structure Analysis",
    "abstract": "We propose a new unsupervised learning model, hidden softmax sequence model (HSSM), based on Boltzmann machine for dialogue structure analysis. The model employs three types of units in the hidden layer to discovery dialogue latent structures: softmax units which represent latent states of utterances; binary units which represent latent topics specified by dialogues; and a binary unit that represents the global general topic shared across the whole dialogue corpus. In addition, the model contains extra connections between adjacent hidden softmax units to formulate the dependency between latent states. Two different kinds of real world dialogue corpora, Twitter-Post and AirTicketBooking, are utilized for extensive comparing experiments, and the results illustrate that the proposed model outperforms sate-ofthe-art popular approaches",
    "volume": "long",
    "checked": true,
    "id": "c900e916ff89813db4ada95cda0bb24bceda4341",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-1195": {
    "title": "Summarizing Source Code using a Neural Attention Model",
    "abstract": "High quality source code is often paired with high level summaries of the computation it performs, for example in code documentation or in descriptions posted in online forums. Such summaries are extremely useful for applications such as code search but are expensive to manually author, hence only done for a small fraction of all code that is produced. In this paper, we present the first completely datadriven approach for generating high level summaries of source code. Our model, CODE-NN , uses Long Short Term Memory (LSTM) networks with attention to produce sentences that describe C# code snippets and SQL queries. CODE-NN is trained on a new corpus that is automatically collected from StackOverflow, which we release. Experiments demonstrate strong performance on two tasks: (1) code summarization, where we establish the first end-to-end learning results and outperform strong baselines, and (2) code retrieval, where our learned model improves the state of the art on a recently introduced C# benchmark by a large margin",
    "volume": "long",
    "checked": true,
    "id": "32aa2517b03c871c11e521c2a3406f457833e2c3",
    "citation_count": 425
  },
  "https://aclanthology.org/P16-1196": {
    "title": "Continuous Profile Models in ASL Syntactic Facial Expression Synthesis",
    "abstract": "To create accessible content for deaf users, we investigate automatically synthesizing animations of American Sign Language (ASL), including grammatically important facial expressions and head movements. Based on recordings of humans performing various types of syntactic face and head movements (which include idiosyncratic variation), we evaluate the efficacy of Continuous Profile Models (CPMs) at identifying an essential \"latent trace\" of the performance, for use in producing ASL animations. A metric-based evaluation and a study with deaf users indicated that this approach was more effective than a prior method for producing animations",
    "volume": "long",
    "checked": true,
    "id": "52bb55ec9c47bfc4e57f470d611031653f11b0e8",
    "citation_count": 14
  },
  "https://aclanthology.org/P16-1197": {
    "title": "Evaluating Sentiment Analysis in the Context of Securities Trading",
    "abstract": "There are numerous studies suggesting that published news stories have an important effect on the direction of the stock market, its volatility, the volume of trades, and the value of individual stocks mentioned in the news. There is even some published research suggesting that automated sentiment analysis of news documents, quarterly reports, blogs and/or twitter data can be productively used as part of a trading strategy. This paper presents just such a family of trading strategies, and then uses this application to re-examine some of the tacit assumptions behind how sentiment analyzers are generally evaluated, in spite of the contexts of their application. This discrepancy comes at a cost",
    "volume": "long",
    "checked": true,
    "id": "e18fa8c8f402c483b2c3eaaa89192fe99e80abd5",
    "citation_count": 10
  },
  "https://aclanthology.org/P16-1198": {
    "title": "Edge-Linear First-Order Dependency Parsing with Undirected Minimum Spanning Tree Inference",
    "abstract": "The run time complexity of state-of-the-art inference algorithms in graph-based dependency parsing is super-linear in the number of input words (n). Recently, pruning algorithms for these models have shown to cut a large portion of the graph edges, with minimal damage to the resulting parse trees. Solving the inference problem in run time complexity determined solely by the number of edges (m) is hence of obvious importance.   We propose such an inference algorithm for first-order models, which encodes the problem as a minimum spanning tree (MST) problem in an undirected graph. This allows us to utilize state-of-the-art undirected MST algorithms whose run time is O(m) at expectation and with a very high probability. A directed parse tree is then inferred from the undirected MST and is subsequently improved with respect to the directed parsing model through local greedy updates, both steps running in O(n) time. In experiments with 18 languages, a variant of the first-order MSTParser (McDonald et al., 2005b) that employs our algorithm performs very similarly to the original parser that runs an O(n^2) directed MST inference",
    "volume": "long",
    "checked": true,
    "id": "d8b3315ddb2e29e3aecdf2a8cf00fcf47a9490f0",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-1199": {
    "title": "Topic Extraction from Microblog Posts Using Conversation Structures",
    "abstract": "Conventional topic models are ineffective for topic extraction from microblog messages since the lack of structure and context among the posts renders poor message-level word co-occurrence patterns. In this work, we organize microblog posts as conversation trees based on reposting and replying relations, which enrich context information to alleviate data sparseness. Our model generates words according to topic dependencies derived from the conversation structures. In specific, we differentiate messages as leader messages, which initiate key aspects of previously focused topics or shift the focus to different topics, and follower messages that do not introduce any new information but simply echo topics from the messages that they repost or reply. Our model captures the different extents that leader and follower messages may contain the key topical words, thus further enhances the quality of the induced topics. The results of thorough experiments demonstrate the effectiveness of our proposed model",
    "volume": "long",
    "checked": true,
    "id": "4336f0f58048e5ad46c2f84891bce8914a88a1cf",
    "citation_count": 30
  },
  "https://aclanthology.org/P16-1200": {
    "title": "Neural Relation Extraction with Selective Attention over Instances",
    "abstract": "Distant supervised relation extraction has been widely used to find novel relational facts from text. However, distant supervision inevitably accompanies with the wrong labelling problem, and these noisy data will substantially hurt the performance of relation extraction. To alleviate this issue, we propose a sentence-level attention-based model for relation extraction. In this model, we employ convolutional neural networks to embed the semantics of sentences. Afterwards, we build sentence-level attention over multiple instances, which is expected to dynamically reduce the weights of those noisy instances. Experimental results on real-world datasets show that, our model can make full use of all informative sentences and effectively reduce the influence of wrong labelled instances. Our model achieves significant and consistent improvements on relation extraction as compared with baselines. The source code of this paper can be obtained from https: //github.com/thunlp/NRE",
    "volume": "long",
    "checked": true,
    "id": "345ef9a7d9af0ac0816d76803ddcf9b6d19404d7",
    "citation_count": 811
  },
  "https://aclanthology.org/P16-1201": {
    "title": "Leveraging FrameNet to Improve Automatic Event Detection",
    "abstract": "Frames defined in FrameNet (FN) share highly similar structures with events in ACE event extraction program. An event in ACE is composed of an event trigger and a set of arguments. Analogously, a frame in FN is composed of a lexical unit and a set of frame elements, which play similar roles as triggers and arguments of ACE events respectively. Besides having similar structures, many frames in FN actually express certain types of events. The above observations motivate us to explore whether there exists a good mapping from frames to event-types and if it is possible to improve event detection by using FN. In this paper, we propose a global inference approach to detect events in FN. Further, based on the detected results, we analyze possible mappings from frames to event-types. Finally, we improve the performance of event detection and achieve a new state-of-the-art result by using the events automatically detected from FN",
    "volume": "long",
    "checked": true,
    "id": "191896dd48d01485ccfaa695e7e464b082974ef5",
    "citation_count": 94
  },
  "https://aclanthology.org/P16-1202": {
    "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
    "abstract": "Solving simple arithmetic word problems is one of the challenges in Natural Language Understanding. This paper presents a novel method to learn to use formulas to solve simple arithmetic word problems. Our system, analyzes each of the sentences to identify the variables and their attributes; and automatically maps this information into a higher level representation. It then uses that representation to recognize the presence of a formula along with its associated variables. An equation is then generated from the formal description of the formula. In the training phase, it learns to score the pair from the systematically generated higher level representation. It is able to solve 86.07% of the problems in a corpus of standard primary school test questions and beats the state-of-the-art by",
    "volume": "long",
    "checked": true,
    "id": "f6b5335f27b9583dd152d8cd4ea9134e24bd297b",
    "citation_count": 73
  },
  "https://aclanthology.org/P16-1203": {
    "title": "Unravelling Names of Fictional Characters",
    "abstract": "In this paper we explore the correlation between the sound of words and their meaning, by testing if the polarity ('good guy' or 'bad guy') of a character's role in a work of fiction can be predicted by the name of the character in the absence of any other context. Our approach is based on phonological and other features proposed in prior theoretical studies of fictional names. These features are used to construct a predictive model over a manually annotated corpus of characters from motion pictures. By experimenting with different mixtures of features, we identify phonological features as being the most discriminative by comparison to social and other types of features, and we delve into a discussion of specific phonological and phonotactic indicators of a character's role's polarity",
    "volume": "long",
    "checked": true,
    "id": "390cfe1e4f9f9c2560bd7919ff61e2de7db6d5bb",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-1204": {
    "title": "Most \"babies\" are \"little\" and most \"problems\" are \"huge\": Compositional Entailment in Adjective-Nouns",
    "abstract": "We examine adjective-noun (AN) composition in the task of recognizing textual entailment (RTE). We analyze behavior of ANs in large corpora and show that, despite conventional wisdom, adjectives do not always restrict the denotation of the nouns they modify. We use natural logic to characterize the variety of entailment relations that can result from AN composition. Predicting these relations depends on context and on commonsense knowledge, making AN composition especially challenging for current RTE systems. We demonstrate the inability of current stateof-the-art systems to handle AN composition in a simplified RTE task which involves the insertion of only a single word",
    "volume": "long",
    "checked": true,
    "id": "0d52a39509e3f65a14fa46c5cc2cf9458f8015fe",
    "citation_count": 40
  },
  "https://aclanthology.org/P16-1205": {
    "title": "Modeling Stance in Student Essays",
    "abstract": "Essay stance classification, the task of determining how much an essay's author agrees with a given proposition, is an important yet under-investigated subtask in understanding an argumentative essay's overall content. We introduce a new corpus of argumentative student essays annotated with stance information and propose a computational model for automatically predicting essay stance. In an evaluation on 826 essays, our approach significantly outperforms four baselines, one of which relies on features previously developed specifically for stance classification in student essays, yielding relative error reductions of at least 11.3% and 5.3%, in micro and macro F-score, respectively",
    "volume": "long",
    "checked": true,
    "id": "9776edb841aa5e7c4c237f1a02da5fcbf49d8dfc",
    "citation_count": 25
  },
  "https://aclanthology.org/P16-1206": {
    "title": "A New Psychometric-inspired Evaluation Metric for Chinese Word Segmentation",
    "abstract": "Word segmentation is a fundamental task for Chinese language processing. However, with the successive improvements, the standard metric is becoming hard to distinguish state-of-the-art word segmentation systems. In this paper, we propose a new psychometric-inspired evaluation metric for Chinese word segmentation, which addresses to balance the very skewed word distribution at different levels of difficulty 1 . The performance on a real evaluation shows that the proposed metric gives more reasonable and distinguishable scores and correlates well with human judgement. In addition, the proposed metric can be easily extended to evaluate other sequence labelling based NLP tasks",
    "volume": "long",
    "checked": true,
    "id": "04899bcf52aaf38d064290a399cf65d6287f2237",
    "citation_count": 12
  },
  "https://aclanthology.org/P16-1207": {
    "title": "Temporal Anchoring of Events for the TimeBank Corpus",
    "abstract": "Today's extraction of temporal information for events heavily depends on annotated temporal links. These so called TLINKs capture the relation between pairs of event mentions and time expressions. One problem is that the number of possible TLINKs grows quadratic with the number of event mentions, therefore most annotation studies concentrate on links for mentions in the same or in adjacent sentences. However, as our annotation study shows, this restriction results for 58% of the event mentions in a less precise information when the event took place. This paper proposes a new annotation scheme to anchor events in time. Not only is the annotation effort much lower as it scales linear with the number of events, it also gives a more precise anchoring when the events have happened as the complete document can be taken into account. Using this scheme, we annotated a subset of the TimeBank Corpus and compare our results to other annotation schemes. Additionally, we present some baseline experiments to automatically anchor events in time. Our annotation scheme, the automated system and the annotated corpus are publicly available.1",
    "volume": "long",
    "checked": true,
    "id": "b5ef007ba38d83b2446521a7ca786d9c11ef06ae",
    "citation_count": 32
  },
  "https://aclanthology.org/P16-1208": {
    "title": "Grammatical Error Correction: Machine Translation and Classifiers",
    "abstract": "We focus on two leading state-of-the-art approaches to grammatical error correction – machine learning classification and machine translation. Based on the comparative study of the two learning frameworks and through error analysis of the output of the state-of-the-art systems, we identify key strengths and weaknesses of each of these approaches and demonstrate their complementarity. In particular, the machine translation method learns from parallel data without requiring further linguistic input and is better at correcting complex mistakes. The classification approach possesses other desirable characteristics, such as the ability to easily generalize beyond what was seen in training, the ability to train without human-annotated data, and the flexibility to adjust knowledge sources for individual error types. Based on this analysis, we develop an algorithmic approach that combines the strengths of both methods. We present several systems based on resources used in previous work with a relative improvement of over 20% (and 7.4 F score points) over the previous state-of-the-art",
    "volume": "long",
    "checked": true,
    "id": "0f8361aa258ac81457dde0c04a041193c21afd50",
    "citation_count": 67
  },
  "https://aclanthology.org/P16-1209": {
    "title": "Recurrent neural network models for disease name recognition using domain invariant features",
    "abstract": "Hand-crafted features based on linguistic and domain-knowledge play crucial role in determining the performance of disease name recognition systems. Such methods are further limited by the scope of these features or in other words, their ability to cover the contexts or word dependencies within a sentence. In this work, we focus on reducing such dependencies and propose a domain-invariant framework for the disease name recognition task. In particular, we propose various end-to-end recurrent neural network (RNN) models for the tasks of disease name recognition and their classification into four pre-defined categories. We also utilize convolution neural network (CNN) in cascade of RNN to get character-based embedded features and employ it with word-embedded features in our model. We compare our models with the state-of-the-art results for the two tasks on NCBI disease dataset. Our results for the disease mention recognition task indicate that state-of-the-art performance can be obtained without relying on feature engineering. Further the proposed models obtained improved performance on the classification task of disease names",
    "volume": "long",
    "checked": true,
    "id": "6752e410f89d184376095f2682a36256d7738932",
    "citation_count": 56
  },
  "https://aclanthology.org/P16-1210": {
    "title": "Domain Adaptation for Authorship Attribution: Improved Structural Correspondence Learning",
    "abstract": "We present the first domain adaptation model for authorship attribution to leverage unlabeled data. The model includes extensions to structural correspondence learning needed to make it appropriate for the task. For example, we propose a median-based classification instead of the standard binary classification used in previous work. Our results show that punctuation-based character n-grams form excellent pivot features. We also show how singular value decomposition plays a critical role in achieving domain adaptation, and that replacing (instead of concatenating) non-pivot features with correspondence features yields better performance",
    "volume": "long",
    "checked": true,
    "id": "25312b9dfaff44ee6c41aaf3e3f3e4cf6677efc7",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-1211": {
    "title": "A Corpus-Based Analysis of Canonical Word Order of Japanese Double Object Constructions",
    "abstract": "The canonical word order of Japanese double object constructions has attracted considerable attention among linguists and has been a topic of many studies. However, most of these studies require either manual analyses or measurements of human characteristics such as brain activities or reading times for each example. Thus, while these analyses are reliable for the examples they focus on, they cannot be generalized to other examples. On the other hand, the trend of actual usage can be collected automatically from a large corpus. Thus, in this paper, we assume that there is a relationship between the canonical word order and the proportion of each word order in a large corpus and present a corpusbased analysis of canonical word order of Japanese double object constructions",
    "volume": "long",
    "checked": true,
    "id": "0b7c2711b9719a99081f37ae937d67585f749f85",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-1212": {
    "title": "Knowledge-Based Semantic Embedding for Machine Translation",
    "abstract": "In this paper, with the help of knowledge base, we build and formulate a semantic space to connect the source and target languages, and apply it to the sequence-to-sequence framework to propose a Knowledge-Based Semantic Embedding (KBSE) method. In our KBSE method, the source sentence is firstly mapped into a knowledge based semantic space, and the target sentence is generated using a recurrent neural network with the internal meaning preserved. Experiments are conducted on two translation tasks, the electric business data and movie data, and the results show that our proposed method can achieve outstanding performance, compared with both the traditional SMT methods and the existing encoder-decoder models",
    "volume": "long",
    "checked": true,
    "id": "bc852342b3fc6a0cee0ac50fbdbeabf57daccc76",
    "citation_count": 51
  },
  "https://aclanthology.org/P16-1213": {
    "title": "One for All: Towards Language Independent Named Entity Linking",
    "abstract": "Entity linking (EL) is the task of disambiguating mentions in text by associating them with entries in a predefined database of mentions (persons, organizations, etc). Most previous EL research has focused mainly on one language, English, with less attention being paid to other languages, such as Spanish or Chinese. In this paper, we introduce LIEL, a Language Independent Entity Linking system, which provides an EL framework which, once trained on one language, works remarkably well on a number of different languages without change. LIEL makes a joint global prediction over the entire document, employing a discriminative reranking framework with many domain and language-independent feature functions. Experiments on numerous benchmark datasets, show that the proposed system, once trained on one language, English, outperforms several state-of-the-art systems in English (by 4 points) and the trained model also works very well on Spanish (14 points better than a competitor system), demonstrating the viability of the approach",
    "volume": "long",
    "checked": true,
    "id": "b5290bf9c965007613c32d5ba764c79ce7d6bde8",
    "citation_count": 26
  },
  "https://aclanthology.org/P16-1214": {
    "title": "On Approximately Searching for Similar Word Embeddings",
    "abstract": "We discuss an approximate similarity search for word embeddings, which is an operation to approximately find embeddings close to a given vector. We compared several metric-based search algorithms with hash-, tree-, and graphbased indexing from different aspects. Our experimental results showed that a graph-based indexing exhibits robust performance and additionally provided useful information, e.g., vector normalization achieves an efficient search with cosine similarity",
    "volume": "long",
    "checked": true,
    "id": "11d5f6b0eae5b0cc3e839fd5d5761453c8bd0042",
    "citation_count": 27
  },
  "https://aclanthology.org/P16-1215": {
    "title": "Composing Distributed Representations of Relational Patterns",
    "abstract": "Learning distributed representations for relation instances is a central technique in downstream NLP applications. In order to address semantic modeling of relational patterns, this paper constructs a new dataset that provides multiple similarity ratings for every pair of relational patterns on the existing dataset. In addition, we conduct a comparative study of different encoders including additive composition, RNN, LSTM, and GRU for composing distributed representations of relational patterns. We also present Gated Additive Composition, which is an enhancement of additive composition with the gating mechanism. Experiments show that the new dataset does not only enable detailed analyses of the different encoders, but also provides a gauge to predict successes of distributed representations of relational patterns in the relation classification task",
    "volume": "long",
    "checked": true,
    "id": "7a371fb3935931a94bf8e26aae4b25e9bbcc7e29",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-1216": {
    "title": "The More Antecedents, the Merrier: Resolving Multi-Antecedent Anaphors",
    "abstract": "Anaphor resolution is an important task in NLP with many applications. Despite much research effort, it remains an open problem. The difficulty of the problem varies substantially across different sub-problems. One sub-problem, in particular, has been largely untouched by prior work despite occurring frequently throughout corpora: the anaphor that has multiple antecedents, which here we call multi-antecedent anaphors or manaphors. Current coreference resolvers restrict anaphors to at most a single antecedent. As we show in this paper, relaxing this constraint poses serious problems in coreference chain-building, where each chain is intended to refer to a single entity. This work provides a formalization of the new task with preliminary insights into multi-antecedent noun-phrase anaphors, and offers a method for resolving such cases that outperforms a number of baseline methods by a significant margin. Our system uses local agglomerative clustering on candidate antecedents and an existing coreference system to score clusters to determine which cluster of mentions is antecedent for a given anaphor. When we augment an existing coreference system with our proposed method, we observe a substantial increase in performance (0.6 absolute CoNLL F1) on an annotated",
    "volume": "long",
    "checked": true,
    "id": "4f0ddc1fa09ba8bd469cdcc66ae73da6872b7092",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-1217": {
    "title": "Automatic Labeling of Topic Models Using Text Summaries",
    "abstract": "Labeling topics learned by topic models is a challenging problem. Previous studies have used words, phrases and images to label topics. In this paper, we propose to use text summaries for topic labeling. Several sentences are extracted from the most related documents to form the summary for each topic. In order to obtain summaries with both high relevance, coverage and discrimination for all the topics, we propose an algorithm based on submodular optimization. Both automatic and manual analysis have been conducted on two real document collections, and we find 1) the summaries extracted by our proposed algorithm are superior over the summaries extracted by existing popular summarization methods; 2) the use of summaries as labels has obvious advantages over the use of words and phrases",
    "volume": "long",
    "checked": true,
    "id": "4cc4898e86c4e9d2a87bbb26f18ec6ebb79e9ded",
    "citation_count": 31
  },
  "https://aclanthology.org/P16-1218": {
    "title": "Graph-based Dependency Parsing with Bidirectional LSTM",
    "abstract": "In this paper, we propose a neural network model for graph-based dependency parsing which utilizes Bidirectional LSTM (BLSTM) to capture richer contextual information instead of using high-order factorization, and enable our model to use much fewer features than previous work. In addition, we propose an effective way to learn sentence segment embedding on sentence-level based on an extra forward LSTM network. Although our model uses only first-order factorization, experiments on English Peen Treebank and Chinese Penn Treebank show that our model could be competitive with previous higher-order graph-based dependency parsing models and state-of-the-art models",
    "volume": "long",
    "checked": true,
    "id": "6f35e6bd71741c5b416d623c2f6c219b6beffad7",
    "citation_count": 135
  },
  "https://aclanthology.org/P16-1219": {
    "title": "TransG : A Generative Model for Knowledge Graph Embedding",
    "abstract": "Recently, knowledge graph embedding, which projects symbolic entities and relations into continuous vector space, has become a new, hot topic in artificial intelligence. This paper proposes a novel generative model (TransG) to address the issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples. The new model can discover latent semantics for a relation and leverage a mixture of relationspecific component vectors to embed a fact triple. To the best of our knowledge, this is the first generative model for knowledge graph embedding, and at the first time, the issue of multiple relation semantics is formally discussed. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines",
    "volume": "long",
    "checked": true,
    "id": "67cab3bafc8fa9e1ae3ff89791ad43c81441d271",
    "citation_count": 215
  },
  "https://aclanthology.org/P16-1220": {
    "title": "Question Answering on Freebase via Relation Extraction and Textual Evidence",
    "abstract": "Existing knowledge-based question answering systems often rely on small annotated training data. While shallow methods like relation extraction are robust to data scarcity, they are less expressive than the deep meaning representation methods like semantic parsing, thereby failing at answering questions involving multiple constraints. Here we alleviate this problem by empowering a relation extraction method with additional evidence from Wikipedia. We first present a neural network based relation extractor to retrieve the candidate answers from Freebase, and then infer over Wikipedia to validate these answers. Experiments on the WebQuestions question answering dataset show that our method achieves an F_1 of 53.3%, a substantial improvement over the state-of-the-art",
    "volume": "long",
    "checked": true,
    "id": "e3919e94c811fd85f5038926fa354619861674f9",
    "citation_count": 248
  },
  "https://aclanthology.org/P16-1221": {
    "title": "Vector-space topic models for detecting Alzheimer's disease",
    "abstract": "Semantic deficit is a symptom of language impairment in Alzheimer's disease (AD). We present a generalizable method for automatic generation of information content units (ICUs) for a picture used in a standard clinical task, achieving high recall, 96.8%, of human-supplied ICUs. We use the automatically generated topic model to extract semantic features, and train a random forest classifier to achieve an F-score of 0.74 in binary classification of controls versus people with AD using a set of only 12 features. This is comparable to results (0.72 F-score) with a set of 85 manual features. Adding semantic information to a set of standard lexicosyntactic and acoustic features improves F-score to 0.80. While control and dementia subjects discuss the same topics in the same contexts, controls are more informative per second of speech",
    "volume": "long",
    "checked": true,
    "id": "360806c34ea0dcb5faab9824dababc094bb05c07",
    "citation_count": 46
  },
  "https://aclanthology.org/P16-1222": {
    "title": "Chinese Couplet Generation with Neural Network Structures",
    "abstract": "Part of the unique cultural heritage of China is the Chinese couplet. Given a sentence (namely an antecedent clause), people reply with another sentence (namely a subsequent clause) equal in length. Moreover, a special phenomenon is that corresponding characters from the same position in the two clauses match each other by following certain constraints on semantic and/or syntactic relatedness. Automatic couplet generation by computer is viewed as a difficult problem and has not been fully explored. In this paper, we formulate the task as a natural language generation problem using neural network structures. Given the issued antecedent clause, the system generates the subsequent clause via sequential language modeling. To satisfy special characteristics of couplets, we incorporate the attention mechanism and polishing schema into the encoding-decoding process. The couplet is generated incrementally and iteratively. A comprehensive evaluation, using perplexity and BLEU measurements as well as human judgments, has demonstrated the effectiveness of our proposed approach",
    "volume": "long",
    "checked": true,
    "id": "0bd85c60a9ebcee8072245ebe499c8e3b26651cf",
    "citation_count": 19
  },
  "https://aclanthology.org/P16-1223": {
    "title": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
    "abstract": "Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP. A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data. Hermann et al. (2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task. In this paper, we conduct a thorough examination of this new reading comprehension task. Our primary aim is to understand what depth of language understanding is required to do well on this task. We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 73.6% and 76.6% on these two datasets, exceeding current state-of-the-art results by 7-10% and approaching what we believe is the ceiling for performance on this task",
    "volume": "long",
    "checked": true,
    "id": "b1e20420982a4f923c08652941666b189b11b7fe",
    "citation_count": 518
  },
  "https://aclanthology.org/P16-1224": {
    "title": "Learning Language Games through Interaction",
    "abstract": "We introduce a new language learning setting relevant to building adaptive natural language interfaces. It is inspired by Wittgenstein's language games: a human wishes to accomplish some task (e.g., achieving a certain configuration of blocks), but can only communicate with a computer, who performs the actual actions (e.g., removing all red blocks). The computer initially knows nothing about language and therefore must learn it from scratch through interaction, while the human adapts to the computer's capabilities. We created a game in a blocks world and collected interactions from 100 people playing it. First, we analyze the humans' strategies, showing that using compositionality and avoiding synonyms correlates positively with task performance. Second, we compare computer strategies, showing how to quickly learn a semantic parsing model from scratch, and that modeling pragmatics further accelerates learning for successful players",
    "volume": "long",
    "checked": true,
    "id": "13d156f37ecea807706fd117547ac1b805d5c5aa",
    "citation_count": 162
  },
  "https://aclanthology.org/P16-1225": {
    "title": "Finding Non-Arbitrary Form-Meaning Systematicity Using String-Metric Learning for Kernel Regression",
    "abstract": "Arbitrariness of the sign—the notion that the forms of words are unrelated to their meanings—is an underlying assumption of many linguistic theories. Two lines of research have recently challenged this assumption, but they produce differing characterizations of non-arbitrariness in language. Behavioral and corpus studies have confirmed the validity of localized form-meaning patterns manifested in limited subsets of the lexicon. Meanwhile, global (lexicon-wide) statistical analyses instead find diffuse form-meaning systematicity across the lexicon as a whole. We bridge the gap with an approach that can detect both local and global formmeaning systematicity in language. In the kernel regression formulation we introduce, form-meaning relationships can be used to predict words' distributional semantic vectors from their forms. Furthermore, we introduce a novel metric learning algorithm that can learn weighted edit distances that minimize kernel regression error. Our results suggest that the English lexicon exhibits far more global form-meaning systematicity than previously discovered, and that much of this systematicity is focused in localized formmeaning patterns",
    "volume": "long",
    "checked": true,
    "id": "14a0a960c05ad064f0cd40ff81ee059772aaff8b",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-1226": {
    "title": "Improving Hypernymy Detection with an Integrated Path-based and Distributional Method",
    "abstract": "Detecting hypernymy relations is a key task in NLP, which is addressed in the literature using two complementary approaches. Distributional methods, whose supervised variants are the current best performers, and path-based methods, which received less research attention. We suggest an improved path-based algorithm, in which the dependency paths are encoded using a recurrent neural network, that achieves results comparable to distributional methods. We then extend the approach to integrate both path-based and distributional signals, significantly improving upon the state-of-the-art on this task",
    "volume": "long",
    "checked": true,
    "id": "a782d0fc34c0ed5cd94a1e4237cb40900a248836",
    "citation_count": 214
  },
  "https://aclanthology.org/P16-1227": {
    "title": "Multimodal Pivots for Image Caption Translation",
    "abstract": "We present an approach to improve statistical machine translation of image descriptions by multimodal pivots defined in visual space. The key idea is to perform image retrieval over a database of images that are captioned in the target language, and use the captions of the most similar images for crosslingual reranking of translation outputs. Our approach does not depend on the availability of large amounts of in-domain parallel data, but only relies on available large datasets of monolingually captioned images, and on state-of-the-art convolutional neural networks to compute image similarities. Our experimental evaluation shows improvements of 1 BLEU point over strong baselines",
    "volume": "long",
    "checked": true,
    "id": "dcf6ea33ab5f9af8019fab4bbbabba3b2231f03b",
    "citation_count": 84
  },
  "https://aclanthology.org/P16-1228": {
    "title": "Harnessing Deep Neural Networks with Logic Rules",
    "abstract": "Combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce uninterpretability of the neural models. We propose a general framework capable of enhancing various types of neural networks (e.g., CNNs and RNNs) with declarative first-order logic rules. Specifically, we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks. We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition. With a few highly intuitive rules, we obtain substantial improvements and achieve state-of-the-art or comparable results to previous best-performing systems",
    "volume": "long",
    "checked": true,
    "id": "a9de2fc7ae3230652f27fd95e7175da8cf44f075",
    "citation_count": 476
  },
  "https://aclanthology.org/P16-1229": {
    "title": "Case and Cause in Icelandic: Reconstructing Causal Networks of Cascaded Language Changes",
    "abstract": "Linguistic drift is a process that produces slow irreversible changes in the grammar and function of a language's constructions. Importantly, changes in a part of a language can have trickle down effects, triggering changes elsewhere in that language. Although such causally triggered chains of changes have long been hypothesized by historical linguists, no explicit demonstration of the actual causality has been provided. In this study, we use cooccurrence statistics and machine learning to demonstrate that the functions of morphological cases experience a slow, irreversible drift along history, even in a language as conservative as is Icelandic. Crucially, we then move on to demonstrate ‐using the notion of Granger-causality‐ that there are explicit causal connections between the changes in the functions of the different cases, which are consistent with documented processes in the history of Icelandic. Our technique provides a means for the quantitative reconstruction of connected networks of subtle linguistic changes",
    "volume": "long",
    "checked": true,
    "id": "2eafb41429dc4ddbc4bbdfea3d9a4f9565fb8db5",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-1230": {
    "title": "On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems",
    "abstract": "The ability to compute an accurate reward function is essential for optimising a dialogue policy via reinforcement learning. In real-world applications, using explicit user feedback as the reward signal is often unreliable and costly to collect. This problem can be mitigated if the user's intent is known in advance or data is available to pre-train a task success predictor off-line. In practice neither of these apply for most real world applications. Here we propose an on-line learning framework whereby the dialogue policy is jointly trained alongside the reward model via active learning with a Gaussian process model. This Gaussian process operates on a continuous space dialogue representation generated in an unsupervised fashion using a recurrent neural network encoder-decoder. The experimental results demonstrate that the proposed framework is able to significantly reduce data annotation costs and mitigate noisy user feedback in dialogue policy learning",
    "volume": "long",
    "checked": true,
    "id": "7a1e07a3c889a1e87270cc1bde855218c35db4ae",
    "citation_count": 143
  },
  "https://aclanthology.org/P16-1231": {
    "title": "Globally Normalized Transition-Based Neural Networks",
    "abstract": "We introduce a globally normalized transition-based neural network model that achieves state-of-the-art part-of-speech tagging, dependency parsing and sentence compression results. Our model is a simple feed-forward neural network that operates on a task-specific transition system, yet achieves comparable or better accuracies than recurrent models. We discuss the importance of global as opposed to local normalization: a key insight is that the label bias problem implies that globally normalized models can be strictly more expressive than locally normalized models",
    "volume": "long",
    "checked": true,
    "id": "4be0dd53aa1c751219fa6f19fed8a6324f6d2766",
    "citation_count": 542
  },
  "https://aclanthology.org/P16-2001": {
    "title": "Transition-based dependency parsing with topological fields",
    "abstract": "The topological field model is commonly used to describe the regularities in German word order. In this work, we show that topological fields can be predicted reliably using sequence labeling and that the predicted field labels can inform a transitionbased dependency parser",
    "volume": "short",
    "checked": true,
    "id": "53185de65b80c36ce2ce9817db673d65746384f4",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-2002": {
    "title": "Scalable Semi-Supervised Query Classification Using Matrix Sketching",
    "abstract": "The enormous scale of unlabeled text available today necessitates scalable schemes for representation learning in natural language processing. For instance, in this paper we are interested in classifying the intent of a user query. While our labeled data is quite limited, we have access to virtually an unlimited amount of unlabeled queries, which could be used to induce useful representations: for instance by principal component analysis (PCA). However, it is prohibitive to even store the data in memory due to its sheer size, let alone apply conventional batch algorithms. In this work, we apply the recently proposed matrix sketching algorithm to entirely obviate the problem with scalability (Liberty, 2013). This algorithm approximates the data within a specified memory bound while preserving the covariance structure necessary for PCA. Using matrix sketching, we significantly improve the user intent classification accuracy by leveraging large amounts of unlabeled queries",
    "volume": "short",
    "checked": true,
    "id": "6de7c8ccf1e952ef4145e9f71555811588023cb3",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-2003": {
    "title": "Learning Multiview Embeddings of Twitter Users",
    "abstract": "Low-dimensional vector representations are widely used as stand-ins for the text of words, sentences, and entire documents. These embeddings are used to identify similar words or make predictions about documents. In this work, we consider embeddings for social media users and demonstrate that these can be used to identify users who behave similarly or to predict attributes of users. In order to capture information from all aspects of a user's online life, we take a multiview approach, applying a weighted variant of Generalized Canonical Correlation Analysis (GCCA) to a collection of over 100,000 Twitter users. We demonstrate the utility of these multiview embeddings on three downstream tasks: user engagement, friend selection, and demographic attribute prediction",
    "volume": "short",
    "checked": true,
    "id": "bdb73be49c4fdcbd0c79ca62e5703155915fa4c4",
    "citation_count": 77
  },
  "https://aclanthology.org/P16-2004": {
    "title": "Implicit Polarity and Implicit Aspect Recognition in Opinion Mining",
    "abstract": "This paper deals with a double-implicit problem in opinion mining and sentiment analysis. We aim at identifying aspects and polarities of opinionated statements not consisting of opinion words and aspect terms. As a case study, opinion words and aspect terms are first extracted from Chinese hotel reviews, and then grouped into positive (negative) clusters and aspect term clusters. We observe that an implicit opinion and its neighbor explicit opinion tend to have the same aspect and polarity. Under the observation, we construct an implicit opinions corpus annotated with aspect class labels and polarity automatically. Aspect and polarity classifiers trained by using this corpus is used to recognize aspect and polarity of implicit opinions",
    "volume": "short",
    "checked": true,
    "id": "0d157be147051e30c11ebe396577ee202a89d799",
    "citation_count": 24
  },
  "https://aclanthology.org/P16-2005": {
    "title": "A Domain Adaptation Regularization for Denoising Autoencoders",
    "abstract": "Finding domain invariant features is critical for successful domain adaptation and transfer learning. However, in the case of unsupervised adaptation, there is a significant risk of overfitting on source training data. Recently, a regularization for domain adaptation was proposed for deep models by (Ganin and Lempitsky, 2015). We build on their work by suggesting a more appropriate regularization for denoising autoencoders. Our model remains unsupervised and can be computed in a closed form. On standard text classification adaptation tasks, our approach yields the state of the art results, with an important reduction of the learning cost",
    "volume": "short",
    "checked": true,
    "id": "8612ceb99dceeb74d7ca1aab26be3fb67568fdd0",
    "citation_count": 34
  },
  "https://aclanthology.org/P16-2006": {
    "title": "Incremental Parsing with Minimal Features Using Bi-Directional LSTM",
    "abstract": "Recently, neural network approaches for parsing have largely automated the combination of individual features, but still rely on (often a larger number of) atomic features created from human linguistic intuition, and potentially omitting important global context. To further reduce feature engineering to the bare minimum, we use bi-directional LSTM sentence representations to model a parser state with only three sentence positions, which automatically identifies important aspects of the entire sentence. This model achieves state-of-the-art results among greedy dependency parsers for English. We also introduce a novel transition system for constituency parsing which does not require binarization, and together with the above architecture, achieves state-of-the-art results among greedy parsers for both English and Chinese",
    "volume": "short",
    "checked": true,
    "id": "34added00bcdab4b0ea8539bd64d279350732764",
    "citation_count": 85
  },
  "https://aclanthology.org/P16-2007": {
    "title": "Improving Statistical Machine Translation Performance by Oracle-BLEU Model Re-estimation",
    "abstract": "We present a novel technique for training translation models for statistical machine translation by aligning source sentences to their oracle-BLEU translations. In contrast to previous approaches which are constrained to phrase training, our method also allows the re-estimation of reordering models along with the translation model. Experiments show an improvement of up to 0.8 BLEU for our approach over a competitive Arabic-English baseline trained directly on the word-aligned bitext using heuristic extraction. As an additional benefit, the phrase table size is reduced dramatically to only 3% of the original size",
    "volume": "short",
    "checked": true,
    "id": "fc452d9d926e14bca793e44c3ee8f8760521852e",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-2008": {
    "title": "Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings",
    "abstract": "We present a natural language generator based on the sequence-to-sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts, and we use it to directly compare two-step generation with separate sentence planning and surface realization stages to a joint, one-step approach. We were able to train both setups successfully using very little training data. The joint setup offers better performance, surpassing state-of-the-art with regards to n-gram-based scores while providing more relevant outputs",
    "volume": "short",
    "checked": true,
    "id": "663dc7723e1748f1e28ac18f3e1a4c1212f2385e",
    "citation_count": 160
  },
  "https://aclanthology.org/P16-2009": {
    "title": "On the Linearity of Semantic Change: Investigating Meaning Variation via Dynamic Graph Models",
    "abstract": "We consider two graph models of semantic change. The first is a time-series model that relates embedding vectors from one time period to embedding vectors of previous time periods. In the second, we construct one graph for each word: nodes in this graph correspond to time points and edge weights to the similarity of the word's meaning across two time points. We apply our two models to corpora across three different languages. We find that semantic change is linear in two senses. Firstly, today's embedding vectors (= meaning) of words can be derived as linear combinations of embedding vectors of their neighbors in previous time periods. Secondly, self-similarity of words decays linearly in time. We consider both findings as new laws/hypotheses of semantic change",
    "volume": "short",
    "checked": true,
    "id": "75f5359de3f131bb8a442b3730d3398fc90e91c0",
    "citation_count": 51
  },
  "https://aclanthology.org/P16-2010": {
    "title": "Joint Word Segmentation and Phonetic Category Induction",
    "abstract": "We describe a model which jointly performs word segmentation and induces vowel categories from formant values. Vowel induction performance improves slightly over a baseline model which does not segment; segmentation performance decreases slightly from a baseline using entirely symbolic input. Our high joint performance in this idealized setting implies that problems in unsupervised speech recognition reflect the phonetic variability of real speech sounds in context",
    "volume": "short",
    "checked": true,
    "id": "e93bd9379a732518c635f2e16bc5cb51db253b01",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-2011": {
    "title": "A Language-Independent Neural Network for Event Detection",
    "abstract": null,
    "volume": "short",
    "checked": true,
    "id": "38bda72a0653bdd868b2149de4798d50c7abf6b2",
    "citation_count": 159
  },
  "https://aclanthology.org/P16-2012": {
    "title": "Improved Parsing for Argument-Clusters Coordination",
    "abstract": "Syntactic parsers perform poorly in prediction of Argument-Cluster Coordination (ACC). We change the PTB representation of ACC to be more suitable for learning by a statistical PCFG parser, affecting 125 trees in the training set. Training on the modified trees yields a slight improvement in EVALB scores on sections 22 and 23. The main evaluation is on a corpus of 4th grade science exams, in which ACC structures are prevalent. On this corpus, we obtain an impressive x2.7 improvement in recovering ACC structures compared to a parser trained on the original PTB trees",
    "volume": "short",
    "checked": true,
    "id": "a032bbeb523215a9462afafc17a047fa37b7d735",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-2013": {
    "title": "Reference Bias in Monolingual Machine Translation Evaluation",
    "abstract": "In the translation industry, human translations are assessed by comparison with the source texts. In the Machine Translation (MT) research community, however, it is a common practice to perform quality assessment using a reference translation instead of the source text. In this paper we show that this practice has a serious issue - annotators are strongly biased by the reference translation provided, and this can have a negative impact on the assessment of MT quality",
    "volume": "short",
    "checked": true,
    "id": "24e20f330e72c3e98a5dfa1966ffc9dd374fc656",
    "citation_count": 24
  },
  "https://aclanthology.org/P16-2014": {
    "title": "Cross-lingual projection for class-based language models",
    "abstract": "This paper presents a cross-lingual projection technique for training class-based language models. We borrow from previous success in projecting POS tags and NER mentions to that of a trained classbased language model. We use a CRF to train a model to predict when a sequence of words is a member of a given class and use this to label our language model training data. We show that we can successfully project the contextual cues for these classes across pairs of languages and retain a high quality class model in languages with no supervised class data. We present empirical results that show the quality of the projected models as well as their effect on the down-stream speech recognition objective. We are able to achieve over 70% of the WER reduction when using the projected class models as compared to models trained on human annotations",
    "volume": "short",
    "checked": true,
    "id": "ffd76769eeb1d6ceb5601bc68d7a4bf73f677307",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-2015": {
    "title": "A Fast Approach for Semantic Similar Short Texts Retrieval",
    "abstract": "Retrieving semantic similar short texts is a crucial issue to many applications, e.g., web search, ads matching, questionanswer system, and so forth. Most of the traditional methods concentrate on how to improve the precision of the similarity measurement, while current real applications need to efficiently explore the top similar short texts semantically related to the query one. We address the efficiency issue in this paper by investigating the similarity strategies and incorporating them into the FAST framework (efficient FrAmework for semantic similar Short Texts retrieval). We conduct comprehensive performance evaluation on real-life data which shows that our proposed method outperforms the state-ofthe-art techniques",
    "volume": "short",
    "checked": true,
    "id": "590867686d95b9cd6893126780fca7f34125e6fe",
    "citation_count": 4
  },
  "https://aclanthology.org/P16-2016": {
    "title": "Empty element recovery by spinal parser operations",
    "abstract": "This paper presents a spinal parsing algorithm that can jointly detect empty elements. This method achieves state-of-theart performance on English and Japanese empty element recovery problems",
    "volume": "short",
    "checked": true,
    "id": "2f2037cb71842a15ccb5f5c20ca2b061e0ebca41",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-2017": {
    "title": "Semantic classifications for detection of verb metaphors",
    "abstract": "We investigate the effectiveness of semantic generalizations/classifications for capturing the regularities of the behavior of verbs in terms of their metaphoricity. Starting from orthographic word unigrams, we experiment with various ways of defining semantic classes for verbs (grammatical, resource-based, distributional) and measure the effectiveness of these classes for classifying all verbs in a running text as metaphor or non metaphor",
    "volume": "short",
    "checked": true,
    "id": "f708ad5789b721ab534d0341a762a6d8572e9de7",
    "citation_count": 49
  },
  "https://aclanthology.org/P16-2018": {
    "title": "Recognizing Salient Entities in Shopping Queries",
    "abstract": "Over the past decade, e-Commerce has rapidly grown enabling customers to purchase products with the click of a button. But to be able to do so, one has to understand the semantics of a user query and identify that in digital lifestyle tv, digital lifestyle is a brand and tv is a product. In this paper, we develop a series of structured prediction algorithms for semantic tagging of shopping queries with the product, brand, model and product family types. We model wide variety of features and show an alternative way to capture knowledge base information using embeddings. We conduct an extensive study over 37, 000 manually annotated queries and report performance of 90.92 F1 independent of the query length",
    "volume": "short",
    "checked": true,
    "id": "89f7ab5e812eee99bf1cac00dbdf977242121a3b",
    "citation_count": 20
  },
  "https://aclanthology.org/P16-2019": {
    "title": "Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data",
    "abstract": "Recent work in learning vector-space embeddings for multi-relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources, in conjunction with distributional semantics, in order to derive a better initialization for training relational models. Applying this initialization to the TransE model results in significant new state-of-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a trade-off between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models",
    "volume": "short",
    "checked": true,
    "id": "a7a75721c4ad21ac1ac1118de89690ebe2f99f0d",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-2020": {
    "title": "Multiplicative Representations for Unsupervised Semantic Role Induction",
    "abstract": "In unsupervised semantic role labeling, identifying the role of an argument is usually informed by its dependency relation with the predicate. In this work, we propose a neural model to learn argument embeddings from the context by explicitly incorporating dependency relations as multiplicative factors, which bias argument embeddings according to their dependency roles. Our model outperforms existing state-of-the-art embeddings in unsupervised semantic role induction on the CoNLL 2008 dataset and the SimLex999 word similarity task. Qualitative results demonstrate our model can effectively bias argument embeddings based on their dependency role",
    "volume": "short",
    "checked": true,
    "id": "81af4e14050c410e2afee226be583088a9791ddf",
    "citation_count": 17
  },
  "https://aclanthology.org/P16-2021": {
    "title": "Vocabulary Manipulation for Neural Machine Translation",
    "abstract": "In order to capture rich language phenomena, neural machine translation models have to use a large vocabulary size, which requires high computing time and large memory usage. In this paper, we alleviate this issue by introducing a sentence-level or batch-level vocabulary, which is only a very small sub-set of the full output vocabulary. For each sentence or batch, we only predict the target words in its sentence-level or batch-level vocabulary. Thus, we reduce both the computing time and the memory usage. Our method simply takes into account the translation options of each word or phrase in the source sentence, and picks a very small target vocabulary for each sentence based on a word-to-word translation model or a bilingual phrase library learned from a traditional machine translation model. Experimental results on the large-scale English-to-French task show that our method achieves better translation performance by 1 BLEU point over the large vocabulary neural machine translation system of Jean et al. (2015)",
    "volume": "short",
    "checked": true,
    "id": "cd0009c2819f9566930d520da46ca67e4ccf226d",
    "citation_count": 59
  },
  "https://aclanthology.org/P16-2022": {
    "title": "Natural Language Inference by Tree-Based Convolution and Heuristic Matching",
    "abstract": "In this paper, we propose the TBCNN-pair model to recognize entailment and contradiction between two sentences. In our model, a tree-based convolutional neural network (TBCNN) captures sentence-level semantics; then heuristic matching layers like concatenation, element-wise product/difference combine the information in individual sentences. Experimental results show that our model outperforms existing sentence encoding-based approaches by a large margin",
    "volume": "short",
    "checked": true,
    "id": "ea407573bfcd39f9a478fe33cf6ce0ee1780a5f0",
    "citation_count": 304
  },
  "https://aclanthology.org/P16-2023": {
    "title": "Improving cross-domain n-gram language modelling with skipgrams",
    "abstract": "In this paper we improve over the hierarchical Pitman-Yor processes language model in a cross-domain setting by adding skipgrams as features. We find that adding skipgram features reduces the perplexity. This reduction is substantial when models are trained on a generic corpus and tested on domain-specific corpora. We also find that within-domain testing and cross-domain testing require different backoff strategies. We observe a 30-40% reduction in perplexity in a cross-domain language modelling task, and up to 6% reduction in a within-domain experiment, for both English and Flemish-Dutch",
    "volume": "short",
    "checked": true,
    "id": "d5e1b1841da6e90ddd8d54e2375d01e3d7dd851b",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-2024": {
    "title": "Simple PPDB: A Paraphrase Database for Simplification",
    "abstract": "We release the Simple Paraphrase Database, a subset of of the Paraphrase Database (PPDB) adapted for the task of text simplification. We train a supervised model to associate simplification scores with each phrase pair, producing rankings competitive with state-of-theart lexical simplification models. Our new simplification database contains 4.5 million paraphrase rules, making it the largest available resource for lexical simplification",
    "volume": "short",
    "checked": true,
    "id": "bc273c2f3b705bac59af7b93b2f416460f72f980",
    "citation_count": 68
  },
  "https://aclanthology.org/P16-2025": {
    "title": "Improving Named Entity Recognition for Chinese Social Media with Word Segmentation Representation Learning",
    "abstract": "Named entity recognition, and other information extraction tasks, frequently use linguistic features such as part of speech tags or chunkings. For languages where word boundaries are not readily identified in text, word segmentation is a key first step to generating features for an NER system. While using word boundary tags as features are helpful, the signals that aid in identifying these boundaries may provide richer information for an NER system. New state-of-the-art word segmentation systems use neural models to learn representations for predicting word boundaries. We show that these same representations, jointly trained with an NER system, yield significant improvements in NER for Chinese social media. In our experiments, jointly training NER and word segmentation with an LSTM-CRF model yields nearly 5% absolute improvement over previously published results",
    "volume": "short",
    "checked": true,
    "id": "f40bcba9593fc266cdebf35a107c85c30983173f",
    "citation_count": 137
  },
  "https://aclanthology.org/P16-2026": {
    "title": "How Naked is the Naked Truth? A Multilingual Lexicon of Nominal Compound Compositionality",
    "abstract": "We introduce a new multilingual resource containing judgments about nominal compound compositionality in English, French and Portuguese. It covers 3 × 180 noun-noun and adjective-noun compounds for which we provide numerical compositionality scores for the head word, for the modifier and for the compound as a whole, along with possible paraphrases. This resource was constructed by native speakers via crowdsourcing. It can serve as basis for evaluating tasks such as lexical substitution and compositionality prediction",
    "volume": "short",
    "checked": true,
    "id": "29cde83675b32a1c76ab1e553583ccb4424a59b4",
    "citation_count": 26
  },
  "https://aclanthology.org/P16-2027": {
    "title": "An Open Web Platform for Rule-Based Speech-to-Sign Translation",
    "abstract": "We present an open web platform for developing, compiling, and running rulebased speech to sign language translation applications. Speech recognition is performed using the Nuance Recognizer 10.2 toolkit, and signed output, including both manual and non-manual components, is rendered using the JASigning avatar system. The platform is designed to make the component technologies readily accessible to sign language experts who are not necessarily computer scientists. Translation grammars are written in a version of Synchronous Context-Free Grammar adapted to the peculiarities of sign language. All processing is carried out on a remote server, with content uploaded and accessed through a web interface. Initial experiences show that simple translation grammars can be implemented on a time-scale of a few hours to a few days and produce signed output readily comprehensible to Deaf informants. Overall, the platform drastically lowers the barrier to entry for researchers interested in building applications that generate high-quality signed language",
    "volume": "short",
    "checked": true,
    "id": "dcf85ca26093d7e1d58f41aa032aeb06b83969f6",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-2028": {
    "title": "Word Alignment without NULL Words",
    "abstract": "In word alignment certain source words are only needed for fluency reasons and do not have a translation on the target side. Most word alignment models assume a target NULL word from which they generate these untranslatable source words. Hypothesising a target NULL word is not without problems, however. For example, because this NULL word has a position, it interferes with the distribution over alignment jumps. We present a word alignment model that accounts for untranslatable source words by generating them from preceding source words. It thereby removes the need for a target NULL word and only models alignments between word pairs that are actually observed in the data. Translation experiments on English paired with Czech, German, French and Japanese show that the model outperforms its traditional IBM counterparts in terms of BLEU score",
    "volume": "short",
    "checked": true,
    "id": "b8340b9c225960a38c81daabcac30d6a993e9424",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-2029": {
    "title": "Unsupervised morph segmentation and statistical language models for vocabulary expansion",
    "abstract": "This work explores the use of unsupervised morph segmentation along with statistical language models for the task of vocabulary expansion. Unsupervised vocabulary expansion has large potential for improving vocabulary coverage and performance in different natural language processing tasks, especially in lessresourced settings on morphologically rich languages. We propose a combination of unsupervised morph segmentation and statistical language models and evaluate on languages from the Babel corpus. The method is shown to perform well for all the evaluated languages when compared to the previous work on the task",
    "volume": "short",
    "checked": true,
    "id": "e45c4e6378631ff34c623c66a702aaaabe1d086f",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-2030": {
    "title": "Detecting Mild Cognitive Impairment by Exploiting Linguistic Information from Transcripts",
    "abstract": "Here we seek to automatically identify Hungarian patients suffering from mild cognitive impairment (MCI) based on linguistic features collected from their speech transcripts. Our system uses machine learning techniques and is based on several linguistic features like characteristics of spontaneous speech as well as features exploiting morphological and syntactic parsing. Our results suggest that it is primarily morphological and speechbased features that help distinguish MCI patients from healthy controls",
    "volume": "short",
    "checked": true,
    "id": "293659ba8044d46384d5c7552ae1315dd5b23dce",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-2031": {
    "title": "Multi-Modal Representations for Improved Bilingual Lexicon Learning",
    "abstract": "This work is supported by ERC Consolidator Grant LEXICAL (648909) and KU Leuven Grant PDMK/14/117. SC is supported by ERC Starting Grant DisCoTex (306920)",
    "volume": "short",
    "checked": true,
    "id": "945c7e44d9b016134d0fe6f591a76ec29d8dd854",
    "citation_count": 34
  },
  "https://aclanthology.org/P16-2032": {
    "title": "Is This Post Persuasive? Ranking Argumentative Comments in Online Forum",
    "abstract": "In this paper we study how to identify persuasive posts in the online forum discussions, using data from Change My View sub-Reddit. Our analysis confirms that the users' voting score for a comment is highly correlated with its metadata information such as published time and author reputation. In this work, we propose and evaluate other features to rank comments for their persuasive scores, including textual information in the comments and social interaction related features. Our experiments show that the surface textual features do not perform well compared to the argumentation based features, and the social interaction based features are effective especially when more users participate in the discussion",
    "volume": "short",
    "checked": true,
    "id": "7f08aa34ec46f0acbd98fb450f820ee01cbf4320",
    "citation_count": 93
  },
  "https://aclanthology.org/P16-2033": {
    "title": "The Value of Semantic Parse Labeling for Knowledge Base Question Answering",
    "abstract": "We demonstrate the value of collecting semantic parse labels for knowledge base question answering. In particular, (1) unlike previous studies on small-scale datasets, we show that learning from labeled semantic parses significantly improves overall performance, resulting in absolute 5 point gain compared to learning from answers, (2) we show that with an appropriate user interface, one can obtain semantic parses with high accuracy and at a cost comparable or lower than obtaining just answers, and (3) we have created and shared the largest semantic-parse labeled dataset to date in order to advance research in question answering",
    "volume": "short",
    "checked": true,
    "id": "c7fcaa13db8c89ff1f39b5687ba47f8beee107c4",
    "citation_count": 254
  },
  "https://aclanthology.org/P16-2034": {
    "title": "Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification",
    "abstract": "Relation classification is an important semantic processing task in the field of natural language processing (NLP). State-ofthe-art systems still rely on lexical resources such as WordNet or NLP systems like dependency parser and named entity recognizers (NER) to get high-level features. Another challenge is that important information can appear at any position in the sentence. To tackle these problems, we propose Attention-Based Bidirectional Long Short-Term Memory Networks(AttBLSTM) to capture the most important semantic information in a sentence. The experimental results on the SemEval-2010 relation classification task show that our method outperforms most of the existing methods, with only word vectors",
    "volume": "short",
    "checked": true,
    "id": "6b8b2075319accc23fef43e4cf76bc3682189d82",
    "citation_count": 1227
  },
  "https://aclanthology.org/P16-2035": {
    "title": "The red one!: On learning to refer to things based on discriminative properties",
    "abstract": "As a first step towards agents learning to communicate about their visual environment, we propose a system that, given visual representations of a referent (cat) and a context (sofa), identifies their discriminative attributes, i.e., properties that distinguish them (has_tail). Moreover, despite the lack of direct supervision at the attribute level, the model learns to assign plausible attributes to objects (sofa-has_cushion). Finally, we present a preliminary experiment confirming the referential success of the predicted discriminative attributes",
    "volume": "short",
    "checked": true,
    "id": "6bc459c548bba7a04e2e255845b28060ec390407",
    "citation_count": 17
  },
  "https://aclanthology.org/P16-2036": {
    "title": "Don't Count, Predict! An Automatic Approach to Learning Sentiment Lexicons for Short Text",
    "abstract": "We describe an efficient neural network method to automatically learn sentiment lexicons without relying on any manual resources. The method takes inspiration from the NRC method, which gives the best results in SemEval13 by leveraging emoticons in large tweets, using the PMI between words and tweet sentiments to define the sentiment attributes of words. We show that better lexicons can be learned by using them to predict the tweet sentiment labels. By using a very simple neural network, our method is fast and can take advantage of the same data volume as the NRC method. Experiments show that our lexicons give significantly better accuracies on multiple languages compared to the current best methods",
    "volume": "short",
    "checked": true,
    "id": "dde52e8312945770bfd98e1a59bed57d4a0be46e",
    "citation_count": 58
  },
  "https://aclanthology.org/P16-2037": {
    "title": "Dimensional Sentiment Analysis Using a Regional CNN-LSTM Model",
    "abstract": "Dimensional sentiment analysis aims to recognize continuous numerical values in multiple dimensions such as the valencearousal (VA) space. Compared to the categorical approach that focuses on sentiment classification such as binary classification (i.e., positive and negative), the dimensional approach can provide more fine-grained sentiment analysis. This study proposes a regional CNN-LSTM model consisting of two parts: regional CNN and LSTM to predict the VA ratings of texts. Unlike a conventional CNN which considers a whole text as input, the proposed regional CNN uses an individual sentence as a region, dividing an input text into several regions such that the useful affective information in each region can be extracted and weighted according to their contribution to the VA prediction. Such regional information is sequentially integrated across regions using LSTM for VA prediction. By combining the regional CNN and LSTM, both local (regional) information within sentences and long-distance dependency across sentences can be considered in the prediction process. Experimental results show that the proposed method outperforms lexicon-based, regression-based, and NN-based methods proposed in previous studies",
    "volume": "short",
    "checked": true,
    "id": "6f72ca2f58e4e7b0a4c21f99ee2fd5f6662ec5b2",
    "citation_count": 355
  },
  "https://aclanthology.org/P16-2038": {
    "title": "Deep multi-task learning with low level tasks supervised at lower layers",
    "abstract": "In all previous work on deep multi-task learning we are aware of, all task supervisions are on the same (outermost) layer. We present a multi-task learning architecture with deep bi-directional RNNs, where different tasks supervision can happen at different layers. We present experiments in syntactic chunking and CCG supertagging, coupled with the additional task of POS-tagging. We show that it is consistently better to have POS supervision at the innermost rather than the outermost layer. We argue that this is because \"lowlevel\" tasks are better kept at the lower layers, enabling the higher-level tasks to make use of the shared representation of the lower-level tasks. Finally, we also show how this architecture can be used for domain adaptation",
    "volume": "short",
    "checked": true,
    "id": "03ad06583c9721855ccd82c3d969a01360218d86",
    "citation_count": 406
  },
  "https://aclanthology.org/P16-2039": {
    "title": "Domain Specific Named Entity Recognition Referring to the Real World by Deep Neural Networks",
    "abstract": "In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real world information, then the entire deep neural network from sentences annotated with NEs and accompanied by real world information. In our experiments, we took Japanese chess as the example. The dataset consists of pairs of a game state and commentary sentences about it annotated with gamespecific NE tags. We conducted NER experiments and showed that referring to the real world improves the NER accuracy",
    "volume": "short",
    "checked": true,
    "id": "b616c6a2c50100d49184a8c5676965f8fd9dc4eb",
    "citation_count": 23
  },
  "https://aclanthology.org/P16-2040": {
    "title": "An Entity-Focused Approach to Generating Company Descriptions",
    "abstract": "Finding quality descriptions on the web, such as those found in Wikipedia articles, of newer companies can be difficult: search engines show many pages with varying relevance, while multi-document summarization algorithms find it difficult to distinguish between core facts and other information such as news stories. In this paper, we propose an entity-focused, hybrid generation approach to automatically produce descriptions of previously unseen companies, and show that it outperforms a strong summarization baseline",
    "volume": "short",
    "checked": true,
    "id": "b9b220d2939366847fe55d92a32db8c245ec2c92",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-2041": {
    "title": "Annotating Relation Inference in Context via Question Answering",
    "abstract": "We present a new annotation method for collecting data on relation inference in context. We convert the inference task to one of simple factoid question answering, allowing us to easily scale up to 16,000 high-quality examples. Our method corrects a major bias in previous evaluations, making our dataset much more realistic",
    "volume": "short",
    "checked": true,
    "id": "8b336cacfcc0eb1c18174f8fb264ce0eb5d0307c",
    "citation_count": 26
  },
  "https://aclanthology.org/P16-2042": {
    "title": "Automatic Semantic Classification of German Preposition Types: Comparing Hard and Soft Clustering Approaches across Features",
    "abstract": "This paper addresses an automatic classification of preposition types in German, comparing hard and soft clustering approaches and various window- and syntax-based co-occurrence features. We show that (i) the semantically most salient preposition features (i.e., subcategorised nouns) are the most successful, and that (ii) soft clustering approaches are required for the task but reveal quite different attitudes towards predicting ambiguity",
    "volume": "short",
    "checked": true,
    "id": "2a5f0b61c45729bda810f22ccaf1ba8692b84e90",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-2043": {
    "title": "Natural Language Generation enhances human decision-making with uncertain information",
    "abstract": "Decision-making is often dependent on uncertain data, e.g. data associated with confidence scores or probabilities. We present a comparison of different information presentations for uncertain data and, for the first time, measure their effects on human decision-making. We show that the use of Natural Language Generation (NLG) improves decision-making under uncertainty, compared to state-of-the-art graphical-based representation methods. In a task-based study with 442 adults, we found that presentations using NLG lead to 24% better decision-making on average than the graphical presentations, and to 44% better decision-making when NLG is combined with graphics. We also show that women achieve significantly better results when presented with NLG output (an 87% increase on average compared to graphical presentations)",
    "volume": "short",
    "checked": true,
    "id": "43aeeb874c007a26c03411111207a42ed4a2dfcd",
    "citation_count": 42
  },
  "https://aclanthology.org/P16-2044": {
    "title": "Tweet2Vec: Character-Based Distributed Representations for Social Media",
    "abstract": "Text from social media provides a set of challenges that can cause traditional NLP approaches to fail. Informal language, spelling errors, abbreviations, and special characters are all commonplace in these posts, leading to a prohibitively large vocabulary size for word-level approaches. We propose a character composition model, tweet2vec, which finds vector-space representations of whole tweets by learning complex, non-local dependencies in character sequences. The proposed model outperforms a word-level baseline at predicting user-annotated hashtags associated with the posts, doing significantly better when the input contains many out-of-vocabulary words or unusual character sequences. Our tweet2vec encoder is publicly available",
    "volume": "short",
    "checked": true,
    "id": "b575d272036740e03fcf67d64db969557843f629",
    "citation_count": 167
  },
  "https://aclanthology.org/P16-2045": {
    "title": "Phrase-Level Combination of SMT and TM Using Constrained Word Lattice",
    "abstract": "Constrained translation has improved statistical machine translation (SMT) by combining it with translation memory (TM) at sentence-level. In this paper, we propose using a constrained word lattice, which encodes input phrases and TM constraints together, to combine SMT and TM at phrase-level. Experiments on English‐ Chinese and English‐French show that our approach is significantly better than previous combination methods, including sentence-level constrained translation and a recent phrase-level combination",
    "volume": "short",
    "checked": true,
    "id": "80d974ef6a91178a0efaa07ab4f62859b1d1b48b",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-2046": {
    "title": "A Neural Network based Approach to Automatic Post-Editing",
    "abstract": "We present a neural network based automatic post-editing (APE) system to improve raw machine translation (MT) output. Our neural model of APE (NNAPE) is based on a bidirectional recurrent neural network (RNN) model and consists of an encoder that encodes an MT output into a fixed-length vector from which a decoder provides a post-edited (PE) translation. APE translations produced by NNAPE show statistically significant improvements of 3.96, 2.68 and 1.35 BLEU points absolute over the original MT, phrase-based APE and hierarchical APE outputs, respectively. Furthermore, human evaluation shows that the NNAPE generated PE translations are much better than the original MT output",
    "volume": "short",
    "checked": true,
    "id": "5060f52fb1b8241f8bca8c0e5c563193d2c69bf5",
    "citation_count": 42
  },
  "https://aclanthology.org/P16-2047": {
    "title": "An Unsupervised Method for Automatic Translation Memory Cleaning",
    "abstract": "We address the problem of automatically cleaning a large-scale Translation Memory (TM) in a fully unsupervised fashion, i.e. without human-labelled data. We approach the task by: i) designing a set of features that capture the similarity between two text segments in different languages, ii) use them to induce reliable training labels for a subset of the translation units (TUs) contained in the TM, and iii) use the automatically labelled data to train an ensemble of binary classifiers. We apply our method to clean a test set composed of 1,000 TUs randomly extracted from the English-Italian version of MyMemory, the world's largest public TM. Our results show competitive performance not only against a strong baseline that exploits machine translation, but also against a state-of-the-art method that relies on human-labelled data",
    "volume": "short",
    "checked": true,
    "id": "2bfd42435b576a552ffebe597406ff0760203cc5",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-2048": {
    "title": "Exponentially Decaying Bag-of-Words Input Features for Feed-Forward Neural Network in Statistical Machine Translation",
    "abstract": "Recently, neural network models have achieved consistent improvements in statistical machine translation. However, most networks only use one-hot encoded input vectors of words as their input. In this work, we investigated the exponentially decaying bag-of-words input features for feed-forward neural network translation models and proposed to train the decay rates along with other weight parameters. This novel bag-of-words model improved our phrase-based state-of-the-art system, which already includes a neural network translation model, by up to 0.5% BLEU and 0.6% TER on three different translation tasks and even achieved a similar performance to the bidirectional LSTM translation model",
    "volume": "short",
    "checked": true,
    "id": "647fb472ea5fa3842f233df9a15eb83f115f792c",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-2049": {
    "title": "Syntactically Guided Neural Machine Translation",
    "abstract": "We investigate the use of hierarchical phrase-based SMT lattices in end-to-end neural machine translation (NMT). Weight pushing transforms the Hiero scores for complete translation hypotheses, with the full translation grammar score and full n-gram language model score, into posteriors compatible with NMT predictive probabilities. With a slightly modified NMT beam-search decoder we find gains over both Hiero and NMT decoding alone, with practical advantages in extending NMT to very large input and output vocabularies",
    "volume": "short",
    "checked": true,
    "id": "c767849ab921c9983b0c00712902954b833df524",
    "citation_count": 65
  },
  "https://aclanthology.org/P16-2050": {
    "title": "Very quaffable and great fun: Applying NLP to wine reviews",
    "abstract": "People find it difficult to name odors and flavors. In blind tests with everyday smells and tastes like orange or chocolate, only 50% is recognized and described correctly. Certain experts like wine reviewers are trained in recognizing and reporting on odor and flavor on a daily basis and they have a much larger vocabulary than lay people. In this research, we want to examine whether expert wine tasters provide consistent descriptions in terms of perceived sensory attributes of wine, both across various wine types and colors. We collected a corpus of wine reviews and performed preliminary experiments to analyse the semantic fields of „flavor\" and „odor\" in wine reviews. To do so, we applied distributional methods as well as pattern-based approaches. In addition, we show the first results of automatically predicting „color\" and „region\" of a particular wine, solely based on the reviewer's text. Our classifiers perform very well when predicting red and white wines, whereas it seems more challenging to distinguish rose wines",
    "volume": "short",
    "checked": true,
    "id": "ade7170dd9bcd4dd006f819d429e73bf69192393",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-2051": {
    "title": "Exploring Stylistic Variation with Age and Income on Twitter",
    "abstract": "Writing style allows NLP tools to adjust to the traits of an author. In this paper, we explore the relation between stylistic and syntactic features and authors' age and income. We confirm our hypothesis that for numerous feature types writing style is predictive of income even beyond age. We analyze the predictive power of writing style features in a regression task on two data sets of around 5,000 Twitter users each. Additionally, we use our validated features to study daily variations in writing style of users from distinct income groups. Temporal stylistic patterns not only provide novel psychological insight into user behavior, but are useful for future research and applications in social media",
    "volume": "short",
    "checked": true,
    "id": "56bf47172aa2ecc5d34cacd081befff03288b5d8",
    "citation_count": 45
  },
  "https://aclanthology.org/P16-2052": {
    "title": "Finding Optimists and Pessimists on Twitter",
    "abstract": "Optimism is linked to various personality factors as well as both psychological and physical health, but how does it relate to the way a person tweets? We analyze the online activity of a set of Twitter users in order to determine how well machine learning algorithms can detect a person's outlook on life by reading their tweets. A sample of tweets from each user is manually annotated in order to establish ground truth labels, and classifiers are trained to distinguish between optimistic and pessimistic users. Our results suggest that the words in people's tweets provide ample evidence to identify them as optimists, pessimists, or somewhere in between. Additionally, several applications of these trained models are explored",
    "volume": "short",
    "checked": true,
    "id": "7e94ca389b921260f68d2886533aa3485e14ad1f",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-2053": {
    "title": "Transductive Adaptation of Black Box Predictions",
    "abstract": "Access to data is critical to any machine learning component aimed at training an accurate predictive model. In reality, data is often a subject of technical and legal constraints. Data may contain sensitive topics and data owners are often reluctant to share them. Instead of access to data, they make available decision making procedures to enable predictions on new data. Under the black box classifier constraint, we build an effective domain adaptation technique which adapts classifier predictions in a transductive setting. We run experiments on text categorization datasets and show that significant gains can be achieved, especially in the unsupervised case where no labels are available in the target domain",
    "volume": "short",
    "checked": true,
    "id": "0ed19f1d828e3329af7b526b8fb3e68d8a50d878",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-2054": {
    "title": "Which Tumblr Post Should I Read Next?",
    "abstract": "Microblogging sites have emerged as major platforms for bloggers to create and consume posts as well as to follow other bloggers and get informed of their updates. Due to the large number of users, and the huge amount of posts they create, it becomes extremely difficult to identify relevant and interesting blog posts. In this paper, we propose a novel convex collective matrix completion (CCMC) method that effectively utilizes user-item matrix and incorporates additional user activity and topic-based signals to recommend relevant content. The key advantage of CCMC over existing methods is that it can obtain a globally optimal solution and can easily scale to large-scale matrices using Hazan's algorithm. To the best of our knowledge, this is the first work which applies and studies CCMC as a recommendation method in social media. We conduct a large scale study and show significant improvement over existing state-ofthe-art approaches",
    "volume": "short",
    "checked": true,
    "id": "7ad914492f10621f4917e62d229aa749ab84f2d4",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-2055": {
    "title": "Text Simplification as Tree Labeling",
    "abstract": "We present a new, structured approach to text simplification using conditional random fields over top-down traversals of dependency graphs that jointly predicts possible compressions and paraphrases. Our model reaches readability scores comparable to word-based compression approaches across a range of metrics and human judgements while maintaining more of the important information",
    "volume": "short",
    "checked": true,
    "id": "104cea0e2cce1e47f8541902266c7e119eb06c69",
    "citation_count": 19
  },
  "https://aclanthology.org/P16-2056": {
    "title": "Bootstrapped Text-level Named Entity Recognition for Literature",
    "abstract": "We present a named entity recognition (NER) system for tagging fiction: LitNER. Relative to more traditional approaches, LitNER has two important properties: (1) it makes no use of handtagged data or gazetteers, instead it bootstraps a model from term clusters; and (2) it leverages multiple instances of the same name in a text. Our experiments show it to substantially outperform off-the-shelf supervised NER systems",
    "volume": "short",
    "checked": true,
    "id": "6115699ee0b8c3cf797be394382f84a17fa9c473",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-2057": {
    "title": "The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake Reviews – An Adversarial Study",
    "abstract": "Online reviews are a growing market, but it is struggling with fake reviews. They undermine both the value of reviews to the user, and their trust in the review sites. However, fake positive reviews can boost a business, and so a small industry producing fake reviews has developed. The two sides are facing an arms race that involves more and more natural language processing (NLP). So far, NLP has been used mostly for detection, and works well on human-generated reviews. But what happens if NLP techniques are used to generate fake reviews as well? We investigate the question in an adversarial setup, by assessing the detectability of different fake-review generation strategies. We use generative models to produce reviews based on meta-information, and evaluate their effectiveness against deceptiondetection models and human judges. We find that meta-information helps detection, but that NLP-generated reviews conditioned on such information are also much harder to detect than conventional ones",
    "volume": "short",
    "checked": true,
    "id": "648c0a6d5023374c0c93fafb571b782da1dfbeed",
    "citation_count": 34
  },
  "https://aclanthology.org/P16-2058": {
    "title": "Character-based Neural Machine Translation",
    "abstract": "Neural Machine Translation (MT) has reached state-of-the-art results. However, one of the main challenges that neural MT still faces is dealing with very large vocabularies and morphologically rich languages. In this paper, we propose a neural MT system using character-based embeddings in combination with convolutional and highway layers to replace the standard lookup-based word representations. The resulting unlimited-vocabulary and affix-aware source word embeddings are tested in a state-of-the-art neural MT based on an attention-based bidirectional recurrent neural network. The proposed MT scheme provides improved results even when the source language is not morphologically rich. Improvements up to 3 BLEU points are obtained in the German-English WMT task",
    "volume": "short",
    "checked": true,
    "id": "4d070993cb75407b285e14cb8aac0077624ef4d9",
    "citation_count": 285
  },
  "https://aclanthology.org/P16-2059": {
    "title": "Learning Monolingual Compositional Representations via Bilingual Supervision",
    "abstract": "Bilingual models that capture the semantics of sentences are typically only evaluated on cross-lingual transfer tasks such as cross-lingual document categorization or machine translation. In this work, we evaluate the quality of the monolingual representations learned with a variant of the bilingual compositional model of Hermann and Blunsom (2014), when viewing translations in a second language as a semantic annotation as the original language text. We show that compositional objectives based on phrase translation pairs outperform compositional objectives based on bilingual sentences and on monolingual paraphrases",
    "volume": "short",
    "checked": true,
    "id": "7770d13fe9dd51081e28667f0034358c9e4d84e7",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-2060": {
    "title": "Event Nugget Detection with Forward-Backward Recurrent Neural Networks",
    "abstract": "Traditional event detection methods heavily rely on manually engineered rich features. Recent deep learning approaches alleviate this problem by automatic feature engineering. But such efforts, like tradition methods, have so far only focused on single-token event mentions, whereas in practice events can also be a phrase. We instead use forward-backward recurrent neural networks (FBRNNs) to detect events that can be either words or phrases. To the best our knowledge, this is one of the first efforts to handle multi-word events and also the first attempt to use RNNs for event detection. Experimental results demonstrate that FBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the Rich ERE 2015 event detection tasks",
    "volume": "short",
    "checked": true,
    "id": "f175743906008704b3cec4beee068bd464bd529a",
    "citation_count": 47
  },
  "https://aclanthology.org/P16-2061": {
    "title": "IBC-C: A Dataset for Armed Conflict Analysis",
    "abstract": "We describe the Iraq Body Count Corpus (IBC-C) dataset, the first substantial armed conflict-related dataset which can be used for conflict analysis. IBCC provides a ground-truth dataset for conflict specific named entity recognition, slot filling, and event de-duplication. IBCC is constructed using data collected by the Iraq Body Count project which has been recording incidents from the ongoing war in Iraq since 2003. We describe the dataset's creation, how it can be used for the above three tasks and provide initial baseline results for the first task (named entity recognition) using Hidden Markov Models, Conditional Random Fields, and Recursive Neural Networks",
    "volume": "short",
    "checked": true,
    "id": "33d8958a2135aa922685c20e4a08c435944ad55e",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-2062": {
    "title": "A Latent Concept Topic Model for Robust Topic Inference Using Word Embeddings",
    "abstract": "Uncovering thematic structures of SNS and blog posts is a crucial yet challenging task, because of the severe data sparsity induced by the short length of texts and diverse use of vocabulary. This hinders effective topic inference of traditional LDA because it infers topics based on document-level co-occurrence of words. To robustly infer topics in such contexts, we propose a latent concept topic model (LCTM). Unlike LDA, LCTM reveals topics via co-occurrence of latent concepts, which we introduce as latent variables to capture conceptual similarity of words. More specifically, LCTM models each topic as a distribution over the latent concepts, where each latent concept is a localized Gaussian distribution over the word embedding space. Since the number of unique concepts in a corpus is often much smaller than the number of unique words, LCTM is less susceptible to the data sparsity. Experiments on the 20Newsgroups show the effectiveness of LCTM in dealing with short texts as well as the capability of the model in handling held-out documents with a high degree of OOV words",
    "volume": "short",
    "checked": true,
    "id": "c972a46961c6a62b91f37998c4b07cc8d8675c7b",
    "citation_count": 28
  },
  "https://aclanthology.org/P16-2063": {
    "title": "Word Embeddings with Limited Memory",
    "abstract": "This paper studies the effect of limited precision data representation and computation on word embeddings. We present a systematic evaluation of word embeddings with limited memory and discuss methods that directly train the limited precision representation with limited memory. Our results show that it is possible to use and train an 8-bit fixed-point value for word embedding without loss of performance in word/phrase similarity and dependency",
    "volume": "short",
    "checked": true,
    "id": "27512a494a14aedda3dc246e28583296b1461a31",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-2064": {
    "title": "Hawkes Processes for Continuous Time Sequence Classification: an Application to Rumour Stance Classification in Twitter",
    "abstract": "Classification of temporal textual data sequences is a common task in various domains such as social media and the Web. In this paper we propose to use Hawkes Processes for classifying sequences of temporal textual data, which exploit both temporal and textual information. Our experiments on rumour stance classification on four Twitter datasets show the importance of using the temporal information of tweets along with the textual content",
    "volume": "short",
    "checked": true,
    "id": "5a7ec6a26b8a703af06cc6c528217452ba0d23c4",
    "citation_count": 122
  },
  "https://aclanthology.org/P16-2065": {
    "title": "Hunting for Troll Comments in News Community Forums",
    "abstract": "There are different definitions of what a troll is. Certainly, a troll can be somebody who teases people to make them angry, or somebody who offends people, or somebody who wants to dominate any single discussion, or somebody who tries to manipulate people's opinion (sometimes for money), etc. The last definition is the one that dominates the public discourse in Bulgaria and Eastern Europe, and this is our   focus in this paper.   In our work, we examine two types of opinion manipulation trolls: paid trolls that have been revealed from leaked \"reputation management contracts\" and \"mentioned trolls\" that have been called such by several different people. We show that these definitions are sensible: we build two classifiers that can distinguish a post by such a paid troll from one by a non-troll with 81-82% accuracy; the same classifier achieves 81-82% accuracy on so called mentioned troll vs. non-troll posts",
    "volume": "short",
    "checked": true,
    "id": "bd9484c4c76013ed4a1c2d9adcea773dc2dccf60",
    "citation_count": 75
  },
  "https://aclanthology.org/P16-2066": {
    "title": "Phrase Table Pruning via Submodular Function Maximization",
    "abstract": "Phrase table pruning is the act of removing phrase pairs from a phrase table to make it smaller, ideally removing the least useful phrases first. We propose a phrase table pruning method that formulates the task as a submodular function maximization problem, and solves it by using a greedy heuristic algorithm. The proposed method can scale with input size and long phrases, and experiments show that it achieves higher BLEU scores than state-of-the-art pruning methods",
    "volume": "short",
    "checked": true,
    "id": "5a3306b117a725d8d10abb558d91974d68d643f1",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-2067": {
    "title": "Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss",
    "abstract": "Bidirectional long short-term memory (bi-LSTM) networks have recently proven successful for various NLP sequence modeling tasks, but little is known about their reliance to input representations, target languages, data set size, and label noise. We address these issues and evaluate bi-LSTMs with word, character, and unicode byte embeddings for POS tagging. We compare bi-LSTMs to traditional POS taggers across languages and data sizes. We also present a novel bi-LSTM model, which combines the POS tagging loss function with an auxiliary loss function that accounts for rare words. The model obtains state-of-the-art performance across 22 languages, and works especially well for morphologically complex languages. Our analysis suggests that bi-LSTMs are less sensitive to training data size and label corruptions (at small noise levels) than previously assumed",
    "volume": "short",
    "checked": true,
    "id": "acd87e4f672f0b92ea4164414c213560c23bee52",
    "citation_count": 369
  },
  "https://aclanthology.org/P16-2068": {
    "title": "Matrix Factorization using Window Sampling and Negative Sampling for Improved Word Representations",
    "abstract": "In this paper, we propose LexVec, a new method for generating distributed word representations that uses low-rank, weighted factorization of the Positive Point-wise Mutual Information matrix via stochastic gradient descent, employing a weighting scheme that assigns heavier penalties for errors on frequent co-occurrences while still accounting for negative co-occurrence. Evaluation on word similarity and analogy tasks shows that LexVec matches and often outperforms state-of-the-art methods on many of these tasks",
    "volume": "short",
    "checked": true,
    "id": "6bdd4b7d879a68a143edba8f7f35839bfa5241f6",
    "citation_count": 73
  },
  "https://aclanthology.org/P16-2069": {
    "title": "One model, two languages: training bilingual parsers with harmonized treebanks",
    "abstract": "We introduce an approach to train lexicalized parsers using bilingual corpora obtained by merging harmonized treebanks of different languages, producing parsers that can analyze sentences in either of the learned languages, or even sentences that mix both. We test the approach on the Universal Dependency Treebanks, training with MaltParser and MaltOptimizer. The results show that these bilingual parsers are more than competitive, as most combinations not only preserve accuracy, but some even achieve significant improvements over the corresponding monolingual parsers. Preliminary experiments also show the approach to be promising on texts with code-switching and when more languages are added",
    "volume": "short",
    "checked": true,
    "id": "df0a023bed974da8eafe59dc0df74bcf49f5e72c",
    "citation_count": 33
  },
  "https://aclanthology.org/P16-2070": {
    "title": "Using mention accessibility to improve coreference resolution",
    "abstract": "Modern coreference resolution systems require linguistic and general knowledge typically sourced from costly, manually curated resources. Despite their intuitive appeal, results have been mixed. In this work, we instead implement fine-grained surface-level features motivated by cognitive theory. Our novel fine-grained feature specialisation approach significantly improves the performance of a strong baseline, achieving state-of-the-art results of 65.29 and 61.13% on CoNLL-2012 using gold and automatic preprocessing, with system extracted mentions",
    "volume": "short",
    "checked": true,
    "id": "f12ecc7e9f8e61a586ae3b3b07d03382bc640998",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-2071": {
    "title": "Exploiting Linguistic Features for Sentence Completion",
    "abstract": "This paper presents a novel approach to automated sentence completion based on pointwise mutual information (PMI). Feature sets are created by fusing the various types of input provided to other classes of language models, ultimately allowing multiple sources of both local and distant information to be considered. Furthermore, it is shown that additional precision gains may be achieved by incorporating feature sets of higher-order n-grams. Experimental results demonstrate that the PMI model outperforms all prior models and establishes a new state-of-the-art result on the Microsoft Research Sentence Completion Challenge",
    "volume": "short",
    "checked": true,
    "id": "8cbdaae62fb05a28f546e26e1f0815ab794b6b21",
    "citation_count": 12
  },
  "https://aclanthology.org/P16-2072": {
    "title": "Convergence of Syntactic Complexity in Conversation",
    "abstract": "Using corpus data of spoken dialogue, we examine the convergence of syntactic complexity levels between interlocutors in natural conversations, as it occurs within spans of topic episodes. The findings of general convergence in the Switchboard and BNC corpora are compatible with an information-theoretic model of dialogue and with Interactive Alignment Theory",
    "volume": "short",
    "checked": true,
    "id": "70b4380ffc161f26ef98881d499c2ee33c7df858",
    "citation_count": 14
  },
  "https://aclanthology.org/P16-2073": {
    "title": "User Embedding for Scholarly Microblog Recommendation",
    "abstract": "Nowadays, many scholarly messages are posted on Chinese microblogs and more and more researchers tend to find scholarly information on microblogs. In order to exploit microblogging to benefit scientific research, we propose a scholarly microblog recommendation system in this study. It automatically collects and mines scholarly information from Chinese microblogs, and makes personalized recommendations to researchers. We propose two different neural network models which learn the vector representations for both users and microblog texts. Then the recommendation is accomplished based on the similarity between a user's vector and a microblog text's vector. We also build a dataset for this task. The two embedding models are evaluated on the dataset and show good results compared to several baselines",
    "volume": "short",
    "checked": true,
    "id": "00d19c8036d1a09bd9832ab0429013bba2da5151",
    "citation_count": 39
  },
  "https://aclanthology.org/P16-2074": {
    "title": "Integrating Distributional Lexical Contrast into Word Embeddings for Antonym-Synonym Distinction",
    "abstract": "We propose a novel vector representation that integrates lexical contrast into distributional vectors and strengthens the most salient features for determining degrees of word similarity. The improved vectors significantly outperform standard models and distinguish antonyms from synonyms with an average precision of 0.66-0.76 across word classes (adjectives, nouns, verbs). Moreover, we integrate the lexical contrast vectors into the objective function of a skip-gram model. The novel embedding outperforms state-of-the-art models on predicting word similarities in SimLex-999, and on distinguishing antonyms from synonyms",
    "volume": "short",
    "checked": true,
    "id": "2a0d8a3b1dfb06f584931fbbcf872a804b30c360",
    "citation_count": 123
  },
  "https://aclanthology.org/P16-2075": {
    "title": "Machine Translation Evaluation Meets Community Question Answering",
    "abstract": "We explore the applicability of machine translation evaluation (MTE) methods to a very different problem: answer ranking in community Question Answering. In particular, we adopt a pairwise neural network (NN) architecture, which incorporates MTE features, as well as rich syntactic and semantic embeddings, and which efficiently models complex non-linear interactions. The evaluation results show state-of-the-art performance, with sizeable contribution from both the MTE features and from the pairwise NN architecture",
    "volume": "short",
    "checked": true,
    "id": "fda51c3af409605191823d8ac5de37c1bda0e75c",
    "citation_count": 30
  },
  "https://aclanthology.org/P16-2076": {
    "title": "Science Question Answering using Instructional Materials",
    "abstract": "We provide a solution for elementary science test using instructional materials. We posit that there is a hidden structure that explains the correctness of an answer given the question and instructional materials and present a unified max-margin framework that learns to find these hidden structures (given a corpus of question-answer pairs and instructional materials), and uses what it learns to answer novel elementary science questions. Our evaluation shows that our framework outperforms several strong baselines",
    "volume": "short",
    "checked": true,
    "id": "30e1e2b4cbfa31d79492bb17b01502693c43a8d9",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-2077": {
    "title": "Specifying and Annotating Reduced Argument Span Via QA-SRL",
    "abstract": "Prominent semantic annotations take an inclusive approach to argument span annotation, marking arguments as full constituency subtrees. Some works, however, showed that identifying a reduced argument span can be beneficial for various semantic tasks. While certain practical methods do extract reduced argument spans, such as in Open-IE , these solutions are often ad-hoc and system-dependent, with no commonly accepted standards. In this paper we propose a generic argument reduction criterion, along with an annotation procedure, and show that it can be consistently and intuitively annotated using the recent QA-SRL paradigm",
    "volume": "short",
    "checked": true,
    "id": "bcc87681c8898bc631502509bef63d62ce0f86fa",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-2078": {
    "title": "Improving Argument Overlap for Proposition-Based Summarisation",
    "abstract": "The CSC Cambridge International Scholarship for the first author is gratefully acknowledged",
    "volume": "short",
    "checked": true,
    "id": "6db9c5894615788d9440f23ec320303e40bb1353",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-2079": {
    "title": "Machine Comprehension using Rich Semantic Representations",
    "abstract": "Machine comprehension tests the system's ability to understand a piece of text through a reading comprehension task. For this task, we propose an approach using the Abstract Meaning Representation (AMR) formalism. We construct meaning representation graphs for the given text and for each question-answer pair by merging the AMRs of comprising sentences using cross-sentential phenomena such as coreference and rhetorical structures. Then, we reduce machine comprehension to a graph containment problem. We posit that there is a latent mapping of the question-answer meaning representation graph onto the text meaning representation graph that explains the answer. We present a unified max-margin framework that learns to find this mapping (given a corpus of texts and question-answer pairs), and uses what it learns to answer questions on novel texts. We show that this approach leads to state of the art results on the task",
    "volume": "short",
    "checked": true,
    "id": "2e107b544461cc10bcdaf39e506e35faf1af172b",
    "citation_count": 36
  },
  "https://aclanthology.org/P16-2080": {
    "title": "Cross-Lingual Word Representations via Spectral Graph Embeddings",
    "abstract": "Cross-lingual word embeddings are used for cross-lingual information retrieval or domain adaptations. In this paper, we extend Eigenwords, spectral monolingual word embeddings based on canonical correlation analysis (CCA), to crosslingual settings with sentence-alignment. For incorporating cross-lingual information, CCA is replaced with its generalization based on the spectral graph embeddings. The proposed method, which we refer to as Cross-Lingual Eigenwords (CL-Eigenwords), is fast and scalable for computing distributed representations of words via eigenvalue decomposition. Numerical experiments of English-Spanish word translation tasks show that CLEigenwords is competitive with stateof-the-art cross-lingual word embedding methods",
    "volume": "short",
    "checked": true,
    "id": "cff628c0f701bcb564f8ef3469ba8646655cc43c",
    "citation_count": 10
  },
  "https://aclanthology.org/P16-2081": {
    "title": "Semantics-Driven Recognition of Collocations Using Word Embeddings",
    "abstract": "L2 learners often produce \"ungrammatical\" word combinations such as, e.g., *give a suggestion or *make a walk. This is because of the \"collocationality\" of one of their items (the base) that limits the acceptance of collocates to express a specific meaning ('perform' above). We propose an algorithm that delivers, for a given base and the intended meaning of a collocate, the actual collocate lexeme(s) (make / take above). The algorithm exploits the linear mapping between bases and collocates from examples and generates a collocation transformation matrix which is then applied to novel unseen cases. The evaluation shows a promising line of research in collocation discovery",
    "volume": "short",
    "checked": true,
    "id": "d505e1fee7a1183b78a0c26b2407c307e9858853",
    "citation_count": 17
  },
  "https://aclanthology.org/P16-2082": {
    "title": "Incorporating Relational Knowledge into Word Representations using Subspace Regularization",
    "abstract": "Incorporating lexical knowledge from semantic resources (e.g., WordNet ) has been shown to improve the quality of distributed word representations. This knowledge often comes in the form of relational triplets (x, r, y) where words x and y are connected by a relation type r. Existing methods either ignore the relation types, essentially treating the word pairs as generic related words, or employ rather restrictive assumptions to model the relational knowledge. We propose a novel approach to model relational knowledge based on low-rank subspace regularization, and conduct experiments on standard tasks to evaluate its effectiveness",
    "volume": "short",
    "checked": true,
    "id": "ec3105fdba61e13886f8fb62092435ebd5010ef6",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-2083": {
    "title": "Word Embedding Calculus in Meaningful Ultradense Subspaces",
    "abstract": "We decompose a standard embedding space into interpretable orthogonal subspaces and a \"remainder\" subspace. We consider four interpretable subspaces in this paper: polarity, concreteness, frequency and part-of-speech (POS) subspaces. We introduce a new calculus for subspaces that supports operations like \"−1 × hate = love\" and \"give me a neutral word for greasy\" (i.e., oleaginous). This calculus extends analogy computations like \"king−man+woman = queen\". For the tasks of Antonym Classification and POS Tagging our method outperforms the state of the art. We create test sets for Morphological Analogies and for the new task of Polarity Spectrum Creation",
    "volume": "short",
    "checked": true,
    "id": "945d67bb0e1f2f908a7221cb806904b31b8feec9",
    "citation_count": 43
  },
  "https://aclanthology.org/P16-2084": {
    "title": "Is \"Universal Syntax\" Universally Useful for Learning Distributed Word Representations?",
    "abstract": "Recent comparative studies have demonstrated the usefulness of dependencybased contexts (DEPS) for learning distributed word representations for similarity tasks. In English, DEPS tend to perform better than the more common, less informed bag-of-words contexts (BOW). In this paper, we present the first crosslinguistic comparison of different context types for three different languages. DEPS are extracted from \"universal parses\" without any language-specific optimization. Our results suggest that the universal DEPS (UDEPS) are useful for detecting functional similarity (e.g., verb similarity, solving syntactic analogies) among languages, but their advantage over BOW is not as prominent as previously reported on English. We also show that simple \"post-parsing\" filtering of useful UDEPS contexts leads to consistent improvements across languages",
    "volume": "short",
    "checked": true,
    "id": "2d72dafd3f49d32a40f66ab0d04acaf5fb2543ba",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-2085": {
    "title": "Claim Synthesis via Predicate Recycling",
    "abstract": "Computational Argumentation has two main goals the detection and analysis of arguments on the one hand, and the synthesis of arguments on the other. Much attention has been given to the former, but considerably less to the latter. A key component in synthesizing arguments is the synthesis of claims. One way to do so is by employing argumentation mining to detect claims within an appropriate corpus. In general, this appears to be a hard problem. Thus, it is interesting to explore if for the sake of synthesis there may be other ways to generate claims. Here we explore such a method: we extract the predicate of simple, manuallydetected, claims, and attempt to generate novel claims from them. Surprisingly, this simple method yields fairly good results",
    "volume": "short",
    "checked": true,
    "id": "0359d8715a05429576f1da3d5bdfe02dc86ca85d",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-2086": {
    "title": "Modelling the Interpretation of Discourse Connectives by Bayesian Pragmatics",
    "abstract": "We propose a framework to model human comprehension of discourse connectives. Following the Bayesian pragmatic paradigm, we advocate that discourse connectives are interpreted based on a simulation of the production process by the speaker, who, in turn, considers the ease of interpretation for the listener when choosing connectives. Evaluation against the sense annotation of the Penn Discourse Treebank confirms the superiority of the model over literal comprehension. A further experiment demonstrates that the proposed model also improves automatic discourse parsing",
    "volume": "short",
    "checked": true,
    "id": "bdf04f3505eab44a2e69a8cd2a01dd68ebe70123",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-2087": {
    "title": "Nonparametric Spherical Topic Modeling with Word Embeddings",
    "abstract": "Traditional topic models do not account for semantic regularities in language. Recent distributional representations of words exhibit semantic consistency over directional metrics such as cosine similarity. However, neither categorical nor Gaussian observational distributions used in existing topic models are appropriate to leverage such correlations. In this paper, we propose to use the von Mises-Fisher distribution to model the density of words over a unit sphere. Such a representation is well-suited for directional data. We use a Hierarchical Dirichlet Process for our base topic model and propose an efficient inference algorithm based on Stochastic Variational Inference. This model enables us to naturally exploit the semantic structures of word embeddings while flexibly discovering the number of topics. Experiments demonstrate that our method outperforms competitive approaches in terms of topic coherence on two different text corpora while offering efficient inference",
    "volume": "short",
    "checked": true,
    "id": "129face5f40d05de412e5ccabba726129f4020fc",
    "citation_count": 73
  },
  "https://aclanthology.org/P16-2088": {
    "title": "A Novel Measure for Coherence in Statistical Topic Models",
    "abstract": "Big data presents new challenges for understanding large text corpora. Topic modeling algorithms help understand the underlying patterns, or \"topics\", in data. Researchersauthor often read these topics in order to gain an understanding of the underlying corpus. It is important to evaluate the interpretability of these automatically generated topics. Methods have previously been designed to use crowdsourcing platforms to measure interpretability. In this paper, we demonstrate the necessity of a key concept, coherence, when assessing the topics and propose an effective method for its measurement. We show that the proposed measure of coherence captures a different aspect of the topics than existing measures. We further study the automation of these topic measures for scalability and reproducibility, showing that these measures can be automated",
    "volume": "short",
    "checked": true,
    "id": "89832cef8a5a1aa2bfca6f2d732cba37c73fec8e",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-2089": {
    "title": "Coarse-grained Argumentation Features for Scoring Persuasive Essays",
    "abstract": "Scoring the quality of persuasive essays is an important goal of discourse analysis, addressed most recently with highlevel persuasion-related features such as thesis clarity, or opinions and their targets. We investigate whether argumentation features derived from a coarse-grained argumentative structure of essays can help predict essays scores. We introduce a set of argumentation features related to argument components (e.g., the number of claims and premises), argument relations (e.g., the number of supported claims) and typology of argumentative structure (chains, trees). We show that these features are good predictors of human scores for TOEFL essays, both when the coarsegrained argumentative structure is manually annotated and automatically predicted",
    "volume": "short",
    "checked": true,
    "id": "f03db7024fd7f5aeb54fb6e74a148d3ce09b201d",
    "citation_count": 54
  },
  "https://aclanthology.org/P16-2090": {
    "title": "Single-Model Encoder-Decoder with Explicit Morphological Representation for Reinflection",
    "abstract": "Morphological reinflection is the task of generating a target form given a source form, a source tag and a target tag. We propose a new way of modeling this task with neural encoder-decoder models. Our approach reduces the amount of required training data for this architecture and achieves state-of-the-art results, making encoder-decoder models applicable to morphological reinflection even for low-resource languages. We further present a new automatic correction method for the outputs based on edit trees",
    "volume": "short",
    "checked": true,
    "id": "25e811243bd02503a4aa33bffc0c9956128de388",
    "citation_count": 82
  },
  "https://aclanthology.org/P16-2091": {
    "title": "Joint part-of-speech and dependency projection from multiple sources",
    "abstract": "Most previous work on annotation projection has been limited to a subset of IndoEuropean languages, using only a single source language, and projecting annotation for one task at a time. In contrast, we present an Integer Linear Programming (ILP) algorithm that simultaneously projects annotation for multiple tasks from multiple source languages, relying on parallel corpora available for hundreds of languages. When training POS taggers and dependency parsers on jointly projected POS tags and syntactic dependencies using our algorithm, we obtain better performance than a standard approach on 20/23 languages using one parallel corpus; and 18/27 languages using another",
    "volume": "short",
    "checked": true,
    "id": "863b2b38b33ffc4e5462adbc7aaf84aeb93adda8",
    "citation_count": 13
  },
  "https://aclanthology.org/P16-2092": {
    "title": "Dependency-based Gated Recursive Neural Network for Chinese Word Segmentation",
    "abstract": "Recently, many neural network models have been applied to Chinese word segmentation. However, such models focus more on collecting local information while long distance dependencies are not well learned. To integrate local features with long distance dependencies, we propose a dependency-based gated recursive neural network. Local features are first collected by bi-directional long short term memory network, then combined and refined to long distance dependencies via gated recursive neural network. Experimental results show that our model is a competitive model for Chinese word segmentation",
    "volume": "short",
    "checked": true,
    "id": "8b08bfe5cd3e2ddcb34fc387745c84c4d35fd020",
    "citation_count": 69
  },
  "https://aclanthology.org/P16-2093": {
    "title": "Deep Neural Networks for Syntactic Parsing of Morphologically Rich Languages",
    "abstract": "Morphologically rich languages (MRL) are languages in which much of the structural information is contained at the wordlevel, leading to high level word-form variation. Historically, syntactic parsing has been mainly tackled using generative models. These models assume input features to be conditionally independent, making difficult to incorporate arbitrary features. In this paper, we investigate the greedy discriminative parser described in (Legrand and Collobert, 2015), which relies on word embeddings, in the context of MRL. We propose to learn morphological embeddings and propagate morphological information through the tree using a recursive composition procedure. Experiments show that such embeddings can dramatically improve the average performance on different languages. Moreover, it yields state-of-the art performance for a majority of languages",
    "volume": "short",
    "checked": true,
    "id": "d10407b86c6f125571322d81777b74a4ef26c4ba",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-2094": {
    "title": "Weakly Supervised Part-of-speech Tagging Using Eye-tracking Data",
    "abstract": "For many of the world's languages, there are no or very few linguistically annotated resources. On the other hand, raw text, and often also dictionaries, can be harvested from the web for many of these languages, and part-of-speech taggers can be trained with these resources. At the same time, previous research shows that eye-tracking data, which can be obtained without explicit annotation, contains clues to part-of-speech information. In this work, we bring these two ideas together and show that given raw text, a dictionary, and eye-tracking data obtained from naive participants reading text, we can train a weakly supervised PoS tagger using a second-order HMM with maximum entropy emissions. The best model use type-level ag-gregates of eye-tracking data and signiﬁ-cantly outperforms a baseline that does not have access to eye-tracking data",
    "volume": "short",
    "checked": true,
    "id": "cfef9993443f08f246fdea42a468918df63ed4f8",
    "citation_count": 62
  },
  "https://aclanthology.org/P16-2095": {
    "title": "Metrics for Evaluation of Word-level Machine Translation Quality Estimation",
    "abstract": "The aim of this paper is to investigate suitable evaluation strategies for the task of word-level quality estimation of machine translation. We suggest various metrics to replace F1-score for the \"BAD\" class, which is currently used as main metric. We compare the metrics' performance on real system outputs and synthetically generated datasets and suggest a reliable alternative to the F1-BAD score — the multiplication of F1-scores for different classes. Other metrics have lower discriminative power and are biased by unfair labellings",
    "volume": "short",
    "checked": true,
    "id": "b62d42470c4bda549e1c0c99cfea3a0dede8ea50",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-2096": {
    "title": "The Social Impact of Natural Language Processing",
    "abstract": "Medical sciences have long since established an ethics code for experiments, to minimize the risk of harm to subjects. Natural language processing (NLP) used to involve mostly anonymous corpora, with the goal of enriching linguistic analysis, and was therefore unlikely to raise ethical concerns. As NLP becomes increasingly wide-spread and uses more data from social media, however, the situation has changed: the outcome of NLP experiments and applications can now have a direct effect on individual users' lives. Until now, the discourse on this topic in the field has not followed the technological development, while public discourse was often focused on exaggerated dangers. This position paper tries to take back the initiative and start a discussion. We identify a number of social implications of NLP and discuss their ethical significance, as well as ways to address them",
    "volume": "short",
    "checked": true,
    "id": "6a0388c46f2aff013343fdafaaffacf56a315915",
    "citation_count": 218
  },
  "https://aclanthology.org/P16-2097": {
    "title": "Using Sequence Similarity Networks to Identify Partial Cognates in Multilingual Wordlists",
    "abstract": "Increasing amounts of digital data in historical linguistics necessitate the development of automatic methods for the detection of cognate words across languages. Recently developed methods work well on language families with moderate time depths, but they are not capable of identifying cognate morphemes in words which are only partially related. Partial cognacy, however, is a frequently recurring phenomenon, especially in language families with productive derivational morphology. This paper presents a pilot approach for partial cognate detection in which networks are used to represent similarities between word parts and cognate morphemes are identified with help of state-of-theart algorithms for network partitioning. The approach is tested on a newly created benchmark dataset with data from three sub-branches of Sino-Tibetan and yields very promising results, outperforming all algorithms which are not sensible to partial cognacy",
    "volume": "short",
    "checked": true,
    "id": "ca7572f4ebb6073907680bb27f8a8ea23bcf3fee",
    "citation_count": 41
  },
  "https://aclanthology.org/P16-3001": {
    "title": "Controlled and Balanced Dataset for Japanese Lexical Simplification",
    "abstract": "We propose a new dataset for evaluating a Japanese lexical simplification method. Previous datasets have several deficiencies. All of them substitute only a single target word, and some of them extract sentences only from newswire corpus. In addition, most of these datasets do not allow ties and integrate simplification ranking from all the annotators without considering the quality. In contrast, our dataset has the following advantages: (1) it is the first controlled and balanced dataset for Japanese lexical simplification with high correlation with human judgment and (2) the consistency of the simplification ranking is improved by allowing candidates to have ties and by considering the reliability of annotators",
    "volume": "student",
    "checked": true,
    "id": "5893320b326a64758005ca41869030307c1a8eec",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-3002": {
    "title": "Dependency Forest based Word Alignment",
    "abstract": "A hierarchical word alignment model that searches for k-best partial alignments on target constituent 1-best parse trees has been shown to outperform previous models. However, relying solely on 1-best parses trees might hinder the search for good alignments because 1-best trees are not necessarily the best for word alignment tasks in practice. This paper introduces a dependency forest based word alignment model, which utilizes target dependency forests in an attempt to minimize the impact on limitations attributable to 1-best parse trees. We present how k-best alignments are constructed over target-side dependency forests. Alignment experiments on the Japanese-English language pair show a relative error reduction of 4% of the alignment score compared to a model with 1-best parse trees",
    "volume": "student",
    "checked": true,
    "id": "3f0d4e3d0546e291c8d0ecd967f54f41bc23a385",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-3003": {
    "title": "Identifying Potential Adverse Drug Events in Tweets Using Bootstrapped Lexicons",
    "abstract": "Adverse drug events (ADEs) are medical complications co-occurring with a period of drug usage. Identification of ADEs is a primary way of evaluating available quality of care. As more social media users begin discussing their drug experiences online, public data becomes available for researchers to expand existing electronic ADE reporting systems, though non-standard language inhibits ease of analysis. In this study, portions of a new corpus of approximately 160,000 tweets were used to create a lexicon-driven ADE detection system using semi-supervised, pattern-based bootstrapping. This method was able to identify misspellings, slang terms, and other non-standard language features of social media data to drive a competitive ADE detection system",
    "volume": "student",
    "checked": true,
    "id": "3ffefe237ec9e8ac4757580204d64f3288bd753a",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-3004": {
    "title": "Generating Natural Language Descriptions for Semantic Representations of Human Brain Activity",
    "abstract": "Quantitative analysis of human brain activity based on language representations, such as the semantic categories of words, have been actively studied in the field of brain and neuroscience. Our study aims to generate natural language descriptions for human brain activation phenomena caused by visual stimulus by employing deep learning methods, which have gained interest as an effective approach to automatically describe natural language expressions for various type of multi-modal information, such as images. We employed an image-captioning system based on a deep learning framework as the basis for our method by learning the relationship between the brain activity data and the features of an intermediate expression of the deep neural network owing to lack of training brain data. We conducted three experiments and were able to generate natural language sentences which enabled us to quantitatively interpret brain activity",
    "volume": "student",
    "checked": true,
    "id": "8d783b56a3d17f95a9a0b2bf76f3ebf285e16ca8",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-3005": {
    "title": "Improving Twitter Community Detection through Contextual Sentiment Analysis",
    "abstract": "Works on Twitter community detection have yielded new ways to extract valuable insights from social media. Through this technique, Twitter users can be grouped into different types of communities such as those who have the same interests, those who interact a lot, or those who have similar sentiments about certain topics. Computationally, information is represented as a graph, and community detection is the problem of partitioning the graph such that each community is more densely connected to each other than to the rest of the network. It has been shown that incorporating sentiment analysis can improve community detection when looking for sentiment-based communities. However, such works only perform sentiment analysis in isolation without considering the tweet's various contextual information. Examples of these contextual information are social network structure, and conversational, author, and topic contexts. Disregarding these information poses a problem because at times, context is needed to clearly infer the sentiment of a tweet. Thus, this research aims to improve detection of sentiment-based communities on Twitter by performing contextual sentiment analysis",
    "volume": "student",
    "checked": true,
    "id": "652f7d3fba5d13d5f760e2eab4889faeefb53ab8",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-3006": {
    "title": "Significance of an Accurate Sandhi-Splitter in Shallow Parsing of Dravidian Languages",
    "abstract": "This paper evaluates the challenges involved in shallow parsing of Dravidian languages which are highly agglutinative and morphologically rich. Text processing tasks in these languages are not trivial because multiple words concatenate to form a single string with morpho-phonemic changes at the point of concatenation. This phenomenon known as Sandhi, in turn complicates the individual word identification. Shallow parsing is the task of identification of correlated group of words given a raw sentence. The current work is an attempt to study the effect of Sandhi in building shallow parsers for Dravidian languages by evaluating its effect on Malayalam, one of the main languages from Dravidian family. We provide an in-depth analysis of effect ofSandhi in developing a robust shallow parser pipeline with experimental results emphasizing on how sensitive the individual components of shallow parser are, towards the accuracy of a sandhi splitter. Our work can serve as a guiding light for building robust text processing systems in Dravidian languages",
    "volume": "student",
    "checked": true,
    "id": "0e07b3f67402d48dd334189793af9573f2b4cb47",
    "citation_count": 9
  },
  "https://aclanthology.org/P16-3007": {
    "title": "Improving Topic Model Clustering of Newspaper Comments for Summarisation",
    "abstract": "Online newspaper articles can accumulate comments at volumes that prevent close reading. Summarisation of the comments allows interaction at a higher level and can lead to an understanding of the over-all discussion. Comment summarisation requires topic clustering, comment ranking and extraction. Clustering must be robust as the subsequent extraction relies on a good set of clusters. Comment data, as with many social media datasets, contains very short documents and the number of words in the documents is a limiting factors on the performance of LDA clustering. We evaluate whether we can combine comments to form larger documents to improve the quality of clusters. We ﬁnd that combining comments with comments that reply to them produce the highest quality clusters",
    "volume": "student",
    "checked": true,
    "id": "3073bfd2e88dfe454738c74a1bdd538c9868384b",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-3008": {
    "title": "Arabizi Identification in Twitter Data",
    "abstract": "In this work we explore some challenges related to analysing one form of the Arabic language called Arabizi. Arabizi, a portmanteau of Araby-Englizi, meaning Arabic-English, is a digital trend in texting Non-Standard Arabic using Latin script. Arabizi users express their natural dialectal Arabic in text without following a unified orthography. We address the challenge of identifying Arabizi from multi-lingual data in Twitter, a preliminary step for analysing sentiment from Arabizi data. We annotated a corpus of Twitter data streamed across two Arab countries, extracted linguistic features and trained a classifier achieving an average Arabizi identification accuracy of 94.5%. We also present the percentage of Arabizi usage on Twitter across both countries providing important insights for researchers in NLP and sociolinguistics",
    "volume": "student",
    "checked": true,
    "id": "0a2d123a7e8936b5a366a32be286885dd7b8e396",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-3009": {
    "title": "Robust Co-occurrence Quantification for Lexical Distributional Semantics",
    "abstract": "Previous optimisations of parameters affecting the word-context association measure used in distributional vector space models have focused either on highdimensional vectors with hundreds of thousands of dimensions, or dense vectors with dimensionality of a few hundreds; but dimensionality of a few thousands is often applied in compositional tasks as it is still computationally feasible and does not require the dimensionality reduction step. We present a systematic study of the interaction of the parameters of the association measure and vector dimensionality, and derive parameter selection heuristics that achieve performance across word similarity and relevance datasets competitive with the results previously reported in the literature achieved by highly dimensional or dense models",
    "volume": "student",
    "checked": true,
    "id": "3eac1268426825f55b80026487fa921237abfaad",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-3010": {
    "title": "Singleton Detection using Word Embeddings and Neural Networks",
    "abstract": "Singleton (or non-coreferential) mentions are a problem for coreference resolution systems, and identifying singletons before mentions are linked improves resolution performance. Here, a singleton detection system based on word embeddings and neural networks is presented, which achieves state-of-the-art performance (79.6% accuracy) on the CoNLL-2012 shared task development set. Extrinsic evaluation with the Stanford and Berkeley coreference resolution systems shows significant improvement for the first, but not for the latter. The results show the potential of using neural networks and word embeddings for improving both singleton detection and coreference resolution",
    "volume": "student",
    "checked": true,
    "id": "f75cf20b3792044b424d0363b6e2efeea3ce1082",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-3011": {
    "title": "A Dataset for Joint Noun-Noun Compound Bracketing and Interpretation",
    "abstract": "We present a new, sizeable dataset of noun– noun compounds with their syntactic analysis (bracketing) and semantic relations. Derived from several established linguistic resources, such as the Penn Treebank, our dataset enables experimenting with new approaches towards a holistic analysis of noun–noun compounds, such as jointlearning of noun–noun compounds bracketing and interpretation, as well as integrating compound analysis with other tasks such as syntactic parsing",
    "volume": "student",
    "checked": true,
    "id": "01a5f4cd979da8b7583d6667722810ee2b122063",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-3012": {
    "title": "An Investigation on The Effectiveness of Employing Topic Modeling Techniques to Provide Topic Awareness For Conversational Agents",
    "abstract": "The idea behind this proposal is to investigate the possibility of utilizing NLP tools, statistical topic modeling techniques and freely available online resources to propose a system able to provide dialogue contribution suggestions which are relevant to the context, yet out of the main activity of the dialogue (i.e. off-activity talk). The aim is to evaluate the effects of a tool that automatically suggests offactivity talks in form of some sentences relevant to the dialogue context. The evaluation is to be done over two test-sets of open domain and closed-domain in a conversational quiz-like setting. The outcome of this work will be a satisfactory point of entry to investigate the hypothesis that adding automatically generated offactivity talks feature to a conversational agent can lead to building up engagement of the dialogue partner(s)",
    "volume": "student",
    "checked": true,
    "id": "621c0b6df804acdf6bc5b3c9ff70eb5e13762e0c",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-3013": {
    "title": "Improving Dependency Parsing Using Sentence Clause Charts",
    "abstract": "We propose a method for improving the dependency parsing of complex sentences. This method assumes segmentation of input sentences into clauses and does not require to re-train a parser of one's choice. We represent a sentence clause structure using clause charts that provide a layer of embedding for each clause in the sentence. Then we formulate a parsing strategy as a two-stage process where (i) coordinated and subordinated clauses of the sentence are parsed separately with respect to the sentence clause chart and (ii) their dependency trees become subtrees of the final tree of the sentence. The object language is Czech and the parser used is a maximum spanning tree parser trained on the Prague Dependency Treebank. We have achieved an average 0.97% improvement in the unlabeled attachment score. Although the method has been designed for the dependency parsing of Czech, it is useful for other parsing techniques and languages",
    "volume": "student",
    "checked": true,
    "id": "49a34ffb816997c8d8d20225e293004f7d643d81",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-3014": {
    "title": "Graph- and surface-level sentence chunking",
    "abstract": "The computing cost of many NLP tasks increases faster than linearly with the length of the representation of a sentence. For parsing the representation is tokens, while for operations on syntax and semantics it will be more complex. In this paper we propose a new task of sentence chunking: splitting sentence representations into coherent substructures. Its aim is to make further processing of long sentences more tractable. We investigate this idea experimentally using the Dependency Minimal Recursion Semantics (DMRS) representation",
    "volume": "student",
    "checked": true,
    "id": "6fd5b1f6350a45fa00cc87372815af01eb9746ff",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-3015": {
    "title": "From Extractive to Abstractive Summarization: A Journey",
    "abstract": null,
    "volume": "student",
    "checked": true,
    "id": "edff94f4699a773a59f7ea58232cd22bc91b3c43",
    "citation_count": 21
  },
  "https://aclanthology.org/P16-3016": {
    "title": "Putting Sarcasm Detection into Context: The Effects of Class Imbalance and Manual Labelling on Supervised Machine Classification of Twitter Conversations",
    "abstract": "Sarcasm can radically alter or invert a phrase's meaning. Sarcasm detection can therefore help improve natural language processing (NLP) tasks. The majority of prior research has modeled sarcasm detection as classification, with two important limitations: 1. Balanced datasets, when sarcasm is actually rather rare. 2. Using Twitter users' self-declarations in the form of hashtags to label data, when sarcasm can take many forms. To address these issues, we create an unbalanced corpus of manually annotated Twitter conversations. We compare human and machine ability to recognize sarcasm on this data under varying amounts of context. Our results indicate that both class imbalance and labelling method affect performance, and should both be considered when designing automatic sarcasm detection systems. We conclude that for progress to be made in real-world sarcasm detection, we will require a new class labelling scheme that is able to access the 'common ground' held between conversational parties",
    "volume": "student",
    "checked": true,
    "id": "f77bddcb22673dfbab6b0e95f324fc361dc08cad",
    "citation_count": 42
  },
  "https://aclanthology.org/P16-3017": {
    "title": "Unsupervised Authorial Clustering Based on Syntactic Structure",
    "abstract": "This paper proposes a new unsupervised technique for clustering a collection of documents written by distinct individuals into authorial components. We highlight the importance of utilizing syntactic structure to cluster documents by author, and demonstrate experimental results that show the method we outline performs on par with state-of-the-art techniques. Additionally, we argue that this feature set outperforms previous methods in cases where authors consciously emulate each other's style or are otherwise rhetorically similar",
    "volume": "student",
    "checked": true,
    "id": "3e3701c613aab0a531a792e1c5ff27515c86aa37",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-3018": {
    "title": "Suggestion Mining from Opinionated Text",
    "abstract": "Abstract Products and services are heavily discussed on social media, which are conventionally used by brand owners, as well as consumers, to acquire consumer opinions. State-of-the-art opinion mining systems provide summaries of positive and negative sentiments toward a service/product and its various aspects. On a closer look, it is observed that these opinions also contain suggestions, tips, and advice, which are often explicitly sought by both brand owners and consumers. This chapter presents a comprehensive overview of the task of mining suggestions from the opinionated text on social media. Various aspects of the task are discussed, which includes an analysis of suggestions appearing in reviews, the relation between sentiments and suggestions, relevant datasets, and existing methods. The problem has been identified only recently as a viable task, and there is limited availability of existing approaches and datasets",
    "volume": "student",
    "checked": true,
    "id": "181cdc8a57dfa0b07b59da1d4b43c105bb5207cb",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-3019": {
    "title": "An Efficient Cross-lingual Model for Sentence Classification Using Convolutional Neural Network",
    "abstract": "In this paper, we propose a cross-lingual convolutional neural network (CNN) model that is based on word and phrase embeddings learned from unlabeled data in two languages and dependency grammar. Compared to traditional machine translation (MT) based methods for cross lingual sentence modeling, our model is much simpler and does not need parallel corpora or language specific features. We only use a bilingual dictionary and dependency parser. This makes our model particularly appealing for resource poor languages. We evaluate our model using English and Chinese data on several sentence classification tasks. We show that our model achieves a comparable and even better performance than the traditional MT-based method",
    "volume": "student",
    "checked": true,
    "id": "e9d11e7d2c27d95edd38596d1d6187e12c66266b",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-3020": {
    "title": "QA-It: Classifying Non-Referential It for Question Answer Pairs",
    "abstract": "This paper introduces a new corpus, QA-It, for the classification of non-referential it. Our dataset is unique in a sense that it is annotated on question answer pairs collected from multiple genres, useful for developing advanced QA systems. Our annotation scheme makes clear distinctions between 4 types of it, providing guidelines for many erroneous cases. Several statistical models are built for the classification of it, showing encouraging results. To the best of our knowledge, this is the first time that such a corpus is created for question answering",
    "volume": "student",
    "checked": true,
    "id": "2edb6575fda3a18db72b34a99702886826cd7093",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-3021": {
    "title": "Building a Corpus for Japanese Wikification with Fine-Grained Entity Classes",
    "abstract": "In this research, we build a Wikification corpus for advancing Japanese Entity Linking. This corpus consists of 340 Japanese newspaper articles with 25,675 entity mentions. All entity mentions are labeled by a fine-grained semantic classes (200 classes), and 19,121 mentions were successfully linked to Japanese Wikipedia articles. Even with the fine-grained semantic classes, we found it hard to define the target of entity linking annotations and to utilize the fine-grained semantic classes to improve the accuracy of entity linking",
    "volume": "student",
    "checked": true,
    "id": "b16c7c0a49fd7078ad0b60b662a3ef965d63bf76",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-3022": {
    "title": "A Personalized Markov Clustering and Deep Learning Approach for Arabic Text Categorization",
    "abstract": "Text categorization has become a key research field in the NLP community. However, most works in this area are focused on Western languages ignoring other Semitic languages like Arabic. These languages are of immense political and social importance necessitating robust categorization techniques. In this paper, we present a novel three-stage technique to efficiently classify Arabic documents into different categories based on the words they contain. We leverage the significance of root-words in Arabic and incorporate a combination of Markov clustering and Deep Belief Networks to classify Arabic words into separate groups (clusters). Our approach is tested on two public datasets giving a F-Measure of 91.02%",
    "volume": "student",
    "checked": true,
    "id": "6d461ac9c8df76b338465c6630c70476c9f9b019",
    "citation_count": 12
  },
  "https://aclanthology.org/P16-4001": {
    "title": "POLYGLOT: Multilingual Semantic Role Labeling with Unified Labels",
    "abstract": "Semantic role labeling (SRL) identifies the predicate-argument structure in text with semantic labels. It plays a key role in understanding natural language. In this paper, we present POLYGLOT, a multilingual semantic role labeling system capable of semantically parsing sentences in 9 different languages from 4 different language groups. The core of POLYGLOT are SRL models for individual languages trained with automatically generated Proposition Banks (Akbik et al., 2015). The key feature of the system is that it treats the semantic labels of the English Proposition Bank as \"universal semantic labels\": Given a sentence in any of the supported languages, POLYGLOT applies the corresponding SRL and predicts English PropBank frame and role annotation. The results are then visualized to facilitate the understanding of multilingual SRL with this unified semantic representation",
    "volume": "demo",
    "checked": true,
    "id": "c37909ab29f250e1fb316e886d715e1a76ea9693",
    "citation_count": 18
  },
  "https://aclanthology.org/P16-4002": {
    "title": "Online Information Retrieval for Language Learning",
    "abstract": "The reading material used in a language learning classroom should ideally be rich in terms of the grammatical constructions and vocabulary to be taught and in line with the learner's interests. We developed an online Information Retrieval system that helps teachers search for texts appropriate in form, content, and reading level. It identifies the 87 grammatical constructions spelled out in the official English language curriculum of schools in Baden-Wurttemberg, Germany. The tool incorporates a classical efficient algorithm for reranking the results by assigning weights to selected constructions and prioritizing the documents containing them. Supplemented by an interactive visualization module, it allows for a multifaceted presentation and analysis of the retrieved documents",
    "volume": "demo",
    "checked": true,
    "id": "693e0f880cdcfbd81f7825d0051e42dd8ee88fb0",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-4003": {
    "title": "Terminology Extraction with Term Variant Detection",
    "abstract": "We introduce, TermSuite, a JAVA and UIMA-based toolkit to build terminologies from corpora. TermSuite follows the classic two steps of terminology extraction tools, the identification of term candidates and their ranking, but implements new features. It is multilingually designed, scalable, and handles term variants. We focus on the main components: UIMA Tokens Regex for defining term and variant patterns over word annotations, and the grouping component for clustering terms and variants that works both at morphological and syntactic levels",
    "volume": "demo",
    "checked": true,
    "id": "128cad773ea50f2d858d55ffb1f9f31100a78b4b",
    "citation_count": 39
  },
  "https://aclanthology.org/P16-4004": {
    "title": "DeepLife: An Entity-aware Search, Analytics and Exploration Platform for Health and Life Sciences",
    "abstract": "Despite the abundance of biomedical literature and health discussions in online communities, it is often tedious to retrieve informative contents for health-centric information needs. Users can query scholarly work in PubMed by keywords and MeSH terms, and resort to Google for everything else. This demo paper presents the DeepLife system, to overcome the limitations of existing search engines for life science and health topics. DeepLife integrates large knowledge bases and harnesses entity linking methods, to support search and exploration of scientific literature, newspaper feeds, and social media, in terms of keywords and phrases, biomedical entities, and taxonomic categories. It also provides functionality for entityaware text analytics over health-centric contents",
    "volume": "demo",
    "checked": true,
    "id": "7cd6ec51e7eb401d3547456c2b9027068f8073ab",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-4005": {
    "title": "Visualizing and Curating Knowledge Graphs over Time and Space",
    "abstract": "Publicly available knowledge repositories, such as Wikipedia and Freebase, benefit significantly from volunteers, whose contributions ensure that the knowledge keeps expanding and is kept up-to-date and accurate. User interactions are often limited to hypertext, tabular, or graph visualization interfaces. For spatio-temporal information, however, other interaction paradigms may be better-suited. We present an integrated system that combines crowdsourcing, automatic or semi-automatic knowledge harvesting from text, and visual analytics. It enables users to analyze large quantities of structured data and unstructured textual data from a spatio-temporal perspective and gain deep insights that are not easily observed in individual facts",
    "volume": "demo",
    "checked": true,
    "id": "44657edc9ade2fdbf6636e6f0d56e7d1e5c2feef",
    "citation_count": 9
  },
  "https://aclanthology.org/P16-4006": {
    "title": "A Web-framework for ODIN Annotation",
    "abstract": "The current release of the ODIN (Online Database of Interlinear Text) database contains over 150,000 linguistic examples, from nearly 1,500 languages, extracted from PDFs found on the web, representing a significant source of data for language research, particularly for low-resource languages. Errors introduced during PDF-totext conversion or poorly formatted examples can make the task of automatically analyzing the data more difficult, so we aim to clean and normalize the examples in order to maximize accuracy during analysis. In this paper we describe a system that allows users to automatically and manually correct errors in the source data in order to get the best possible analysis of the data. We also describe a RESTful service for managing collections of linguistic examples on the web. All software is distributed under an open-source license",
    "volume": "demo",
    "checked": true,
    "id": "37b3797866d4c3cddd01706e30c6d92537737a63",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-4007": {
    "title": "Real-Time Discovery and Geospatial Visualization of Mobility and Industry Events from Large-Scale, Heterogeneous Data Streams",
    "abstract": "Monitoring mobility- and industryrelevant events is important in areas such as personal travel planning and supply chain management, but extracting events pertaining to specific companies, transit routes and locations from heterogeneous, high-volume text streams remains a significant challenge. We present Spree, a scalable system for real-time, automatic event extraction from social media, news and domain-specific RSS feeds. Our system is tailored to a range of mobilityand industry-related events, and processes German texts within a distributed linguistic analysis pipeline implemented in Apache Flink. The pipeline detects and disambiguates highly ambiguous domain-relevant entities, such as street names, and extracts various events with their geo-locations. Event streams are visualized on a dynamic, interactive map for monitoring and analysis",
    "volume": "demo",
    "checked": true,
    "id": "b8416392c103154c098c266b4c9f2fd33c0fd82e",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-4008": {
    "title": "TranscRater: a Tool for Automatic Speech Recognition Quality Estimation",
    "abstract": "We present TranscRater, an open-source tool for automatic speech recognition (ASR) quality estimation (QE). The tool allows users to perform ASR evaluation bypassing the need of reference transcripts and confidence information, which is common to current assessment protocols. TranscRater includes: i) methods to extract a variety of quality indicators from (signal, transcription) pairs and ii) machine learning algorithms which make possible to build ASR QE models exploiting the extracted features. Confirming the positive results of previous evaluations, new experiments with TranscRater indicate its effectiveness both in WER prediction and transcription ranking tasks",
    "volume": "demo",
    "checked": true,
    "id": "dca6a3371ed9daa59cc0fcce4008f58384a299e7",
    "citation_count": 15
  },
  "https://aclanthology.org/P16-4009": {
    "title": "TMop: a Tool for Unsupervised Translation Memory Cleaning",
    "abstract": "We present TMop, the first open-source tool for automatic Translation Memory (TM) cleaning. The tool implements a fully unsupervised approach to the task, which allows spotting unreliable translation units (sentence pairs in different languages, which are supposed to be translations of each other) without requiring labeled training data. TMop includes a highly configurable and extensible set of filters capturing different aspects of translation quality. It has been evaluated on a test set composed of 1,000 translation units (TUs) randomly extracted from the English-Italian version of MyMemory, a large-scale public TM. Results indicate its effectiveness in automatic removing \"bad\" TUs, with comparable performance to a state-of-the-art supervised method (76.3 vs. 77.7 balanced accuracy)",
    "volume": "demo",
    "checked": true,
    "id": "a14b34abc1d37d215b1f3ebd633bb9d410e857a4",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-4010": {
    "title": "MMFeat: A Toolkit for Extracting Multi-Modal Features",
    "abstract": "Research at the intersection of language and other modalities, most notably vision, is becoming increasingly important in natural language processing. We introduce a toolkit that can be used to obtain feature representations for visual and auditory information. MMFEAT is an easy-to-use Python toolkit, which has been developed with the purpose of making non-linguistic modalities more accessible to natural language processing researchers",
    "volume": "demo",
    "checked": true,
    "id": "db7f0385b21a66b80345085e24d87803bc353a54",
    "citation_count": 19
  },
  "https://aclanthology.org/P16-4011": {
    "title": "JEDI: Joint Entity and Relation Detection using Type Inference",
    "abstract": "FREEBASE contains entities and relation information but is highly incomplete. Relevant information is ubiquitous in web text, but extraction deems challenging. We present JEDI, an automated system to jointly extract typed named entities and FREEBASE relations using dependency pattern from text. An innovative method for constraint solving on entity types of multiple relations is used to disambiguate pattern. The high precision in the evaluation supports our claim that we can detect entities and relations together, alleviating the need to train a custom classifier for an entity type1",
    "volume": "demo",
    "checked": true,
    "id": "ced192d0efd0b2bcfe069bdd740fce9ec391656d",
    "citation_count": 11
  },
  "https://aclanthology.org/P16-4012": {
    "title": "OpenDial: A Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules",
    "abstract": "We present a new release of OpenDial, an open-source toolkit for building and evaluating spoken dialogue systems. The toolkit relies on an information-state architecture where the dialogue state is represented as a Bayesian network and acts as a shared memory for all system modules. The domain models are specified via probabilistic rules encoded in XML. OpenDial has been deployed in several application domains such as human‐robot interaction, intelligent tutoring systems and multi-modal in-car driver assistants",
    "volume": "demo",
    "checked": true,
    "id": "cfbd206752ed7552b1f334afc7bdf9b0bf8e1589",
    "citation_count": 65
  },
  "https://aclanthology.org/P16-4013": {
    "title": "MUSEEC: A Multilingual Text Summarization Tool",
    "abstract": "The MUSEEC (MUltilingual SEntence Extraction and Compression) summarization tool implements several extractive summarization techniques – at the level of complete and compressed sentences – that can be applied, with some minor adaptations, to documents in multiple languages. The current version of MUSEEC provides the following summarization methods: (1) MUSE – a supervised summarizer, based on a genetic algorithm (GA), that ranks document sentences and extracts top–ranking sentences into a summary, (2) POLY – an unsupervised summarizer, based on linear programming (LP), that selects the best extract of document sentences, and (3) WECOM – an unsupervised extension of POLY that compiles a document summary from compressed sentences. In this paper, we provide an overview of MUSEEC methods and its architecture in general",
    "volume": "demo",
    "checked": true,
    "id": "0b88101ae68dcd4e1284aab1dc6e223569d8fa8c",
    "citation_count": 22
  },
  "https://aclanthology.org/P16-4014": {
    "title": "Language Muse: Automated Linguistic Activity Generation for English Language Learners",
    "abstract": "Current education standards in the U.S. require school students to read and understand complex texts from different subject areas (e.g., social studies). However, such texts usually contain figurative language, complex phrases and sentences, as well as unfamiliar discourse relations. This may present an obstacle to students whose native language is not English — a growing sub-population in the US. 1 One way to help such students is to create classroom activities centered around linguistic elements found in subject area texts (DelliCarpini, 2008). We present a web-based tool that uses NLP algorithms to automatically generate customizable linguistic activities that are grounded in language learning research",
    "volume": "demo",
    "checked": true,
    "id": "fef3fabee3ff1a2cfe70a524a33fdfb4e3bb6a94",
    "citation_count": 9
  },
  "https://aclanthology.org/P16-4015": {
    "title": "ccg2lambda: A Compositional Semantics System",
    "abstract": "We demonstrate a simple and easy-to-use system to produce logical semantic representations of sentences. Our software operates by composing semantic formulas bottom-up given a CCG parse tree. It uses flexible semantic templates to specify semantic patterns. Templates for English and Japanese accompany our software, and they are easy to understand, use and extend to cover other linguistic phenomena or languages. We also provide scripts to use our semantic representations in a textual entailment task, and a visualization tool to display semantically augmented CCG trees in HTML",
    "volume": "demo",
    "checked": true,
    "id": "60ab817f02beddf422908f0e2f24b7da8be2efcb",
    "citation_count": 30
  },
  "https://aclanthology.org/P16-4016": {
    "title": "MeTA: A Unified Toolkit for Text Retrieval and Analysis",
    "abstract": "META is developed to unite machine learning, information retrieval, and natural language processing in one easy-to-use toolkit. Its focus on indexing allows it to perform well on large datasets, supporting online classification and other out-of-core algorithms. META's liberal open source license encourages contributions, and its extensive online documentation, forum, and tutorials make this process straightforward. We run experiments and show META's performance is competitive with or better than existing software. 1 A Unified Framework As NLP techniques become more and more mature, we have great opportunities to use them to develop and support many applications, such as search engines, classifiers, and integrative applications that involve multiple components. It's possible to develop each application from scratch, but it's much more efficient to have a general toolkit that supports multiple application types. Existing tools tend to specialize on one particular area, and as such there is a wide variety of tools one must sample when performing different data science tasks. For text-mining tasks, this is even more apparent; it is extremely difficult (if not impossible) to find tools that support both traditional information retrieval tasks (like tokenization, indexing, and search) alongside traditional machine learning tasks (like document classification, regression, and topic modeling). Table 1 compares META's many features across various dimensions. Note that only META satisfies all the areas while other toolkits focus on a particular area. In the case where the desired functionality is scattered, data science students, researchers, and practitioners must find the appropriate software packages for their needs and compile and configure each appropriate tool. Then, there is the problem of data formatting—it is unlikely that the tools all have standardized upon a single input format, so a certain amount of \"data munging\" is required. All of this detracts from the actual task at hand, which has a marked impact on productivity. The goal of the META project is to address these issues. In particular, we provide a unifying framework for existing machine learning and natural language processing algorithms, allowing researchers to quickly run controlled experiments. We have modularized the feature generation, instance representation, data storage formats, and algorithm implementations; this allows users to make seamless transitions along any of these dimensions with minimal effort. Finally, META is dual-licensed under the University of Illinois/NCSA Open Source Licence and the MIT License to reach the broadest audience possible. Due to space constraints, in this paper, we only delve into META's natural language processing (NLP), information retrieval (IR), and machine learning (ML) components in section 3. However, we briefly outline all of its components here: Feature generation. META has a collection of tokenizers, filters, and analyzers that convert raw text into a feature representation. Basic features are n-gram words, but other analyzers make use of different parts of the toolkit, such as POS tag ngrams and parse tree features. An arbitrary number of feature representations may be combined; for example, a document could be represented as unigram words, bigram POS tags, and parse tree rewrite rules. Users can easily add their own feature types as well, such as sentence length distribution in a document. Search. The META search engine can store",
    "volume": "demo",
    "checked": true,
    "id": "8ed1a7317a727dd47ae1f182c5caeeb484a76599",
    "citation_count": 15
  },
  "https://aclanthology.org/P16-4017": {
    "title": "MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora",
    "abstract": "In this paper, we present MDSWriter, a novel open-source annotation tool for creating multi-document summarization corpora. A major innovation of our tool is that we divide the complex summarization task into multiple steps which enables us to efficiently guide the annotators, to store all their intermediate results, and to record user-system interaction data. This allows for evaluating the individual components of a complex summarization system and learning from the human writing process. MDSWriter is highly flexible and can be adapted to various other tasks",
    "volume": "demo",
    "checked": true,
    "id": "2e8bdf474deed156685ffe63bdc0ecf7617d0135",
    "citation_count": 6
  },
  "https://aclanthology.org/P16-4018": {
    "title": "Jigg: A Framework for an Easy Natural Language Processing Pipeline",
    "abstract": "We present Jigg, a Scala (or JVMbased) NLP annotation pipeline framework, which is easy to use and is extensible. Jigg supports a very simple interface similar to Stanford CoreNLP, the most successful NLP pipeline toolkit, but has more flexibility to adapt to new types of annotation. On this framework, system developers can easily integrate their downstream system into a NLP pipeline from a raw text by just preparing a wrapper of it",
    "volume": "demo",
    "checked": true,
    "id": "d0356e790cf57b78ea150ac4edfcfc0c8a2ea73c",
    "citation_count": 10
  },
  "https://aclanthology.org/P16-4019": {
    "title": "An Advanced Press Review System Combining Deep News Analysis and Machine Learning Algorithms",
    "abstract": "In our media-driven world the perception of companies and institutions in the media is of major importance. The creation of press reviews analyzing the media response to company-related events is a complex and time-consuming task. In this demo we present a system that combines advanced text mining and machine learning approaches in an extensible press review system. The system collects documents from heterogeneous sources and enriches the documents applying different mining, filtering, classification, and aggregation algorithms. We present a system tailored to the needs of the press department of a major German University. We explain how the different components have been trained and evaluated. The system enables us demonstrating the live analyzes of news and social media streams as well as the strengths of advanced text mining algorithms for creating a comprehensive media analysis",
    "volume": "demo",
    "checked": true,
    "id": "da619517557b2d81da882a71f8b043af01818b7c",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-4020": {
    "title": "Personalized Exercises for Preposition Learning",
    "abstract": "We present a computer-assisted language learning (CALL) system that generates fill-in-the-blank items for preposition usage. The system takes a set of carrier sentences as input, chooses a preposition in each sentence as the key, and then automatically generates distractors. It personalizes item selection for the user in two ways. First, it logs items to which the user previously gave incorrect answers, and offers similar items in a future session as review. Second, it progresses from easier to harder sentences, to minimize any hindrance on preposition learning that might be posed by difficult vocabulary",
    "volume": "demo",
    "checked": true,
    "id": "87c73705a1e73bd297b5102fa36740538558fa49",
    "citation_count": 7
  },
  "https://aclanthology.org/P16-4021": {
    "title": "My Science Tutor—Learning Science with a Conversational Virtual Tutor",
    "abstract": "This paper presents a conversational, multimedia, virtual science tutor for elementary school students. It is built using state of the art speech recognition and spoken language understanding technology. This virtual science tutor is unique in that it elicits self-explanations from students for various science phenomena by engaging them in spoken dialogs and guided by illustrations, animations and interactive simulations. There is a lot of evidence that self-explanation works well as a tutorial paradigm, Summative evaluations indicate that students are highly engaged in the tutoring sessions, and achieve learning outcomes equivalent to expert human tutors. Tutorials are developed through a process of recording and annotating data from sessions with students, and then updating tutor models. It enthusiastically supported by students and teachers. Teachers report that it is feasible to integrate into their curriculum",
    "volume": "demo",
    "checked": true,
    "id": "b25ee500f130002ede375ac16b4462b69629b6f9",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-4022": {
    "title": "pigeo: A Python Geotagging Tool",
    "abstract": "We present pigeo, a Python geolocation prediction tool that predicts a location for a given text input or Twitter user. We discuss the design, implementation and application of pigeo, and empirically evaluate it. pigeo is able to geolocate informal text and is a very useful tool for users who require a free and easy-to-use, yet accurate geolocation service based on pre-trained models. Additionally, users can train their own models easily using pigeo's API",
    "volume": "demo",
    "checked": true,
    "id": "89f4e3c33d74e394b6c19a7d5b12ae27a4558bad",
    "citation_count": 27
  },
  "https://aclanthology.org/P16-4023": {
    "title": "Creating Interactive Macaronic Interfaces for Language Learning",
    "abstract": "We present a prototype of a novel technology for second language instruction. Our learn-by-reading approach lets a human learner acquire new words and constructions by encountering them in context. To facilitate reading comprehension, our technology presents mixed native language (L1) and second language (L2) sentences to a learner and allows them to interact with the sentences to make the sentences easier (more L1-like) or harder (more L2-like) to read. Eventually, our system should continuously track a learner's knowledge and learning style by modeling their interactions, including performance on a pop quiz feature. This will allow our system to generate personalized mixed-language texts for learners",
    "volume": "demo",
    "checked": true,
    "id": "3f513ad5f5006c21ebb165e738727c24fe00dfd0",
    "citation_count": 8
  },
  "https://aclanthology.org/P16-4024": {
    "title": "Roleo: Visualising Thematic Fit Spaces on the Web",
    "abstract": "In this paper, we present Roleo, a web tool for visualizing the vector spaces generated by the evaluation of distributional memory (DM) models over thematic fit judgements. A thematic fit judgement is a rating of the selectional preference of a verb for an argument that fills a given thematic role. The DM approach to thematic fit judgements involves the construction of a sub-space in which a prototypical role-filler can be built for comparison to the noun being judged. We describe a publicly-accessible web tool that allows for querying and exploring these spaces as well as a technique for visualizing thematic fit sub-spaces efficiently for web use",
    "volume": "demo",
    "checked": true,
    "id": "3f3624eb40e92706f183de94e385940c60f1d75b",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-4025": {
    "title": "MediaGist: A Cross-lingual Analyser of Aggregated News and Commentaries",
    "abstract": "We introduce MediaGist, an online system for crosslingual analysis of aggregated news and commentaries based on summarization and sentiment analysis technologies. It is designed to assist journalists to detect and explore news topics, which are controversially reported or discussed in different countries. News articles from current week are clustered separately in currently 5 languages and the clusters are then linked across languages. Sentiment analysis provides a basis to compute controversy scores and summaries help to explore the differences. Recognized entities play an important role in most of the system's modules and provide another way to explore the data. We demonstrate the capabilities of MediaGist by listing highlights from the last week and present a rough evaluation of the system",
    "volume": "demo",
    "checked": true,
    "id": "79b548c5ec14d604570c9da29b8e86a3d22b7a0e",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-4026": {
    "title": "GoWvis: A Web Application for Graph-of-Words-based Text Visualization and Summarization",
    "abstract": "We introduce GoWvis1, an interactive web application that represents any piece of text inputted by the user as a graph-ofwords and leverages graph degeneracy and community detection to generate an extractive summary (keyphrases and sentences) of the inputted text in an unsupervised fashion. The entire analysis can be fully customized via the tuning of many text preprocessing, graph building, and graph mining parameters. Our system is thus well suited to educational purposes, exploration and early research experiments. The new summarization strategy we propose also shows promise",
    "volume": "demo",
    "checked": true,
    "id": "a64dd87d40cfc1dae7a976ac772b66739171361b",
    "citation_count": 23
  },
  "https://aclanthology.org/P16-4027": {
    "title": "LiMoSINe Pipeline: Multilingual UIMA-based NLP Platform",
    "abstract": "We present a robust and efficient parallelizable multilingual UIMA-based platform for automatically annotating textual inputs with different layers of linguistic description, ranging from surface level phenomena all the way down to deep discourse-level information. In particular, given an input text, the pipeline extracts: sentences and tokens; entity mentions; syntactic information; opinionated expressions; relations between entity mentions; co-reference chains and wikified entities. The system is available in two versions: a standalone distribution enables design and optimization of userspecific sub-modules, whereas a server-client distribution allows for straightforward highperformance NLP processing, reducing the engineering cost for higher-level tasks",
    "volume": "demo",
    "checked": true,
    "id": "8ab47dcc8ae0922a51af45c5648291b73020ecf8",
    "citation_count": 2
  },
  "https://aclanthology.org/P16-4028": {
    "title": "new/s/leak – Information Extraction and Visualization for Investigative Data Journalists",
    "abstract": "We present new/s/leak, a novel tool developed for and with the help of journalists, which enables the automatic analysis and discovery of newsworthy stories from large textual datasets. We rely on different NLP preprocessing steps such named entity tagging, extraction of time expressions, entity networks, relations and metadata. The system features an intuitive web-based user interface based on network visualization combined with data exploring methods and various search and faceting mechanisms. We report the current state of the software and exemplify it with the WikiLeaks PlusD (Cablegate) data",
    "volume": "demo",
    "checked": true,
    "id": "4b9f560cfdc63aa4a71ae54db05ecff74910a6d5",
    "citation_count": 13
  },
  "https://aclanthology.org/P16-5001": {
    "title": "Multimodal Learning and Reasoning",
    "abstract": "Natural Language Processing has broadened in scope to tackle more and more challenging language understanding and reasoning tasks. The core NLP tasks remain predominantly unimodal, focusing on linguistic input, despite the fact that we, humans, acquire and use language while communicating in perceptually rich environments. Moving towards human-level AI will require the integration and modeling of multiple modalities beyond language. With this tutorial, our aim is to introduce researchers to the areas of NLP that have dealt with multimodal signals. The key advantage of using multimodal signals in NLP tasks is the complementarity of the data in different modalities. For example, we are less likely to nd descriptions of yellow bananas or wooden chairs in text corpora, but these visual attributes can be readily extracted directly from images. Multimodal signals, such as visual, auditory or olfactory data, have proven useful for models of word similarity and relatedness, automatic image and video description, and even predicting the associated smells of words. Finally, multimodality offers a practical opportunity to study and apply multitask learning, a general machine learning paradigm that improves generalization performance of a task by using training signals of other related tasks.All material associated to the tutorial will be available at http://multimodalnlp.github.io/",
    "volume": "tutorial",
    "checked": true,
    "id": "865ab406a0a8a09112010cbd5ece1312112f4e24",
    "citation_count": 5
  },
  "https://aclanthology.org/P16-5002": {
    "title": "NLP Approaches to Computational Argumentation",
    "abstract": "Argumentation and debating represent primary intellectual activities of the human mind. People in all societies argue and debate, not only to convince others of their own opinions but also in order to explore the differences between multiple perspectives and conceptualizations, and to learn from this exploration. The process of reaching a resolution on controversial topics typically does not follow a simple sequence of purely logical steps. Rather it involves a wide variety of complex and interwoven actions. Presumably, pros and cons are identified, considered, and weighed, via cognitive processes that often involve persuasion and emotions, which are inherently harder to formalize from a computational perspective.This wide range of conceptual capabilities and activities, have only in part been studied in fields like CL and NLP, and typically within relatively small sub-communities that overlap the ACL audience. The new field of Computational Argumentation has very recently seen significant expansion within the CL and NLP community as new techniques and datasets start to become available, allowing for the first time investigation of the computational aspects of human argumentation in a holistic manner.The main goal of this tutorial would be to introduce this rapidly evolving field to the CL community. Specifically, we will aim to review recent advances in the field and to outline the challenging research questions - that are most relevant to the ACL audience - that naturally arise when trying to model human argumentation.We will further emphasize the practical value of this line of study, by considering real-world CL and NLP applications that are expected to emerge from this research, and to impact various industries, including legal, finance, healthcare, media, and education, to name just a few examples.The first part of the tutorial will provide introduction to the basics of argumentation and rhetoric. Next, we will cover fundamental analysis tasks in Computational Argumentation, including argumentation mining, revealing argument relations, assessing arguments quality, stance classification, polarity analysis, and more. After the coffee break, we will first review existing resources and recently introduced benchmark data. In the following part we will cover basic synthesis tasks in Computational Argumentation, including the relation to NLG and dialogue systems, and the evolving area of Debate Technologies, defined as technologies developed directly to enhance, support, and engage with human debating. Finally, we will present relevant demos, review potential applications, and discuss the future of this emerging field",
    "volume": "tutorial",
    "checked": true,
    "id": "8af99818f2aa0f0a32741a9a6f345064c664bd5f",
    "citation_count": 3
  },
  "https://aclanthology.org/P16-5003": {
    "title": "Computer Aided Translation",
    "abstract": "Moving beyond post-editing machine translation, a number of recent research efforts have advanced computer aided translation methods that allow for more interactivity, richer information such as confidence scores, and the completed feedback loop of instant adaptation of machine translation models to user translations.This tutorial will explain the main techniques for several aspects of computer aided translation: confidence measures;interactive machine translation (interactive translation prediction);bilingual concordancers;translation option display;paraphrasing (alternative translation suggestions);visualization of word alignment;online adaptation;automatic reviewing;integration of translation memory;eye tracking, logging, and cognitive user models;For each of these, the state of the art and open challenges are presented. The tutorial will also look under the hood of the open source CASMACAT toolkit that is based on MATECAT, and available as a \"Home Edition\" to be installed on a desktop machine. The target audience of this tutorials are researchers interested in computer aided machine translation and practitioners who want to use or deploy advanced CAT technology",
    "volume": "tutorial",
    "checked": true,
    "id": "5f29eef86a8b37f02e4e4ca779652c506ac70c20",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-5004": {
    "title": "Semantic Representations of Word Senses and Concepts",
    "abstract": "Representing the semantics of linguistic items in a machine interpretable form has been a major goal of Natural Language Processing since its earliest days. Among the range of different linguistic items, words have attracted the most research attention. However, word representations have an important limitation: they conflate different meanings of a word into a single vector. Representations of word senses have the potential to overcome this inherent limitation. Indeed, the representation of individual word senses and concepts has recently gained in popularity with several experimental results showing that a considerable performance improvement can be achieved across different NLP applications upon moving from word level to the deeper sense and concept levels. Another interesting point regarding the representation of concepts and word senses is that these models can be seamlessly applied to other linguistic items, such as words, phrases, sentences, etc. This tutorial will first provide a brief overview of the recent literature concerning word representation (both count based and neural network based). It will then describe the advantages of moving from the word level to the deeper level of word senses and concepts, providing an extensive review of state of the art systems. Approaches covered will not only include those which draw upon knowledge resources such as WordNet, Wikipedia, BabelNet or FreeBase as reference, but also the so called multi prototype approaches which learn sense distinctions by using different clustering techniques. Our tutorial will discuss the advantages and potential limitations of all approaches, showing their most successful applications to date. We will conclude by presenting current open problems and lines of future work",
    "volume": "tutorial",
    "checked": true,
    "id": "9099919348ba85a4b5ec6fef022dbc5bfd6e1ca7",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-5005": {
    "title": "Neural Machine Translation",
    "abstract": "Neural Machine Translation (NMT) is a simple new architecture for getting machines to learn to translate. Despite being relatively new (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014), NMT has already shown promising results, achieving state-of-the-art performances for various language pairs (Luong et al, 2015a; Jean et al, 2015; Luong et al, 2015b; Sennrich et al., 2016; Luong and Manning, 2016). While many of these NMT papers were presented to the ACL community, research and practice of NMT are only at their beginning stage. This tutorial would be a great opportunity for the whole community of machine translation and natural language processing to learn more about a very promising new approach to MT. This tutorial has four parts. In the first part, we start with an overview of MT approaches, including: (a) traditional methods that have been dominant over the past twenty years and (b) recent hybrid models with the use of neural network components. From these, we motivate why an end-to-end approach like neural machine translation is needed. The second part introduces a basic instance of NMT. We start out with a discussion of recurrent neural networks, including the back-propagation-through-time algorithm and stochastic gradient descent optimizers, as these are the foundation on which NMT builds. We then describe in detail the basic sequence-to-sequence architecture of NMT (Cho et al., 2014; Sutskever et al., 2014), the maximum likelihood training approach, and a simple beam-search decoder to produce translations. The third part of our tutorial describes techniques to build state-of-the-art NMT. We start with approaches to extend the vocabulary coverage of NMT (Luong et al., 2015a; Jean et al., 2015; Chitnis and DeNero, 2015). We then introduce the idea of jointly learning both translations and alignments through an attention mechanism (Bahdanau et al., 2015); other variants of attention (Luong et al., 2015b; Tu et al., 2016) are discussed too. We describe a recent trend in NMT, that is to translate at the sub-word level (Chung et al., 2016; Luong and Manning, 2016; Sennrich et al., 2016), so that language variations can be effectively handled. We then give tips on training and testing NMT systems such as batching and ensembling. In the final part of the tutorial, we briefly describe promising approaches, such as (a) how to combine multiple tasks to help translation (Dong et al., 2015; Luong et al., 2016; Firat et al., 2016; Zoph and Knight, 2016) and (b) how to utilize monolingual corpora (Sennrich et al., 2016). Lastly, we conclude with challenges remained to be solved for future NMT. PS: we would also like to acknowledge the very first paper by Forcada and Ñeco (1997) on sequence-to-sequence models for translation!",
    "volume": "tutorial",
    "checked": true,
    "id": "c6841dfc5e62af9a63efaf396ca7969677d6fc03",
    "citation_count": 16
  },
  "https://aclanthology.org/P16-5006": {
    "title": "Game Theory and Natural Language: Origin, Evolution and Processing",
    "abstract": "The development of game theory in the early 1940's by John von Neumann was a reaction against the then dominant view that problems in economic theory can be formulated using standard methods from optimization theory. Indeed, most real-world economic problems involve conflicting interactions among decision-making agents that cannot be adequately captured by a single (global) objective function. The main idea behind game theory is to shift the emphasis from optimality criteria to equilibrium conditions. Game theory provides a framework to model complex scenarios, with applications in economics and social science but also in different fields of information technology. With the recent development of algorithmic game theory, it has been used to solve problems in computer vision, pattern recognition, machine learning and natural language processing.Game-theoretic frameworks have been used in different ways to study language origin and evolution. Furthermore, the so-called game metaphor has been used by philosophers and linguists to explain how language evolved and how it works. Ludwig Wittgenstein, for example, famously introduced the concept of a language game to explain the conventional nature of language, and put forward the idea of the spontaneous formation of a common language that gradually emerges from the interactions among the speakers within a population.This concept opens the way to the interpretation of language as a complex adaptive system composed of linguistic units and their interactions, which gives rise to the emergence of structural properties. It is the core part of many computational models of language that are based on classical game theory and evolutionary game theory. With the former it is possible to model how speakers form a signaling system in which the ambiguity of the symbols is minimized; with the latter it is possible to model how speakers coordinate their linguistic choices according to the satisfaction that they have about the outcome of a communication act, converging to a common language. In the same vein, many other attempts have been proposed to explain how other characteristics of language follow similar dynamics.Game theory, and in particular evolutionary game theory, thanks to their ability to model interactive situations and to integrate information from multiple sources, have also been used to solve specific problems in natural language processing and information retrieval, such as language generation, word sense disambiguation and document and text clustering.The goal of this tutorial is to offer an introduction to the basic concepts of game theory and to show its main applications in the study of language, from different perspectives. We shall assume no pre-existing knowledge of game theory by the audience, thereby making the tutorial self-contained and understandable by a non-expert",
    "volume": "tutorial",
    "checked": true,
    "id": "c33d30d3c59aa46418d5a6518e66631b4b38ca7c",
    "citation_count": 0
  },
  "https://aclanthology.org/P16-5007": {
    "title": "Understanding Short Texts",
    "abstract": null,
    "volume": "tutorial",
    "checked": true,
    "id": "993c9001a752cf6a8b3638580a4487a8c209a793",
    "citation_count": 34
  },
  "https://aclanthology.org/P16-5008": {
    "title": "MetaNet: Repository, Identification System, and Applications",
    "abstract": "The ubiquity of metaphor in language (Lakoff and Johnson 1980) has served as impetus for cognitive linguistic approaches to the study of language, mind, and the study of mind (e.g. Thibodeau & Boroditsky 2011). While native speakers use metaphor naturally and easily, the treatment and interpretation of metaphor in computational systems remains challenging because such systems have not succeeded in developing ways to recognize the semantic elements that define metaphor. This tutorial demonstrates MetaNet's frame-based semantic analyses, and their informing of MetaNet's automatic metaphor identification system. Participants will gain a complete understanding of the theoretical basis and the practical workings of MetaNet, and acquire relevant information about the Frame Semantics basis of that knowledge base and the way that FrameNet handles the widespread phenomenon of metaphor in language. The tutorial is geared to researchers and practitioners of language technology, not necessarily experts in metaphor analysis or knowledgeable about either FrameNet or MetaNet, but who are interested in natural language processing tasks that involve automatic metaphor processing, or could benefit from exposure to tools and resources that support frame-based deep semantic, analyses of language, including metaphor as a widespread phenomenon in human language",
    "volume": "tutorial",
    "checked": true,
    "id": "f335e99bb2468f758f21a820e3d4ef3c074ec370",
    "citation_count": 1
  },
  "https://aclanthology.org/P16-1106": {
    "title": "A short proof that O_2 is an MCFL",
    "abstract": "We present a new proof that $O_2$ is a multiple context-free language. It contrasts with a recent proof by Salvati (2015) in its avoidance of concepts that seem specific to two-dimensional geometry, such as the complex exponential function. Our simple proof creates realistic prospects of widening the results to higher dimensions. This finding is of central importance to the relation between extreme free word order and classes of grammars used to describe the syntax of natural language",
    "volume": "long",
    "checked": true,
    "id": "1aab44b1d467e14d38cb6d176fb88e24d82bc97f",
    "citation_count": 3
  }
}