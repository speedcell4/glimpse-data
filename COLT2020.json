{
  "https://proceedings.mlr.press/v125/acharya20a.html": {
    "title": "Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit",
    "abstract": "We study goodness-of-fit of discrete distributions in the distributed setting, where samples are divided between multiple users who can only release a limited amount of information about their samples due to various information constraints. Recently, a subset of the authors showed that having access to a common random seed (i.e., shared randomness) leads to a significant reduction in the sample complexity of this problem. In this work, we provide a complete understanding of the interplay between the amount of shared randomness available, the stringency of information constraints, and the sample complexity of the testing problem by characterizing a tight trade-off between these three parameters. We provide a general distributed goodness-of-fit protocol that as a function of the amount of shared randomness interpolates smoothly between the private- and public-coin sample complexities. We complement our upper bound with a general framework to prove lower bounds on the sample complexity of this testing problems under limited shared randomness. Finally, we instantiate our bounds for the two archetypal information constraints of communication and local privacy, and show that our sample complexity bounds are optimal as a function of all the parameters of the problem, including the amount of shared randomness. A key component of our upper bounds is a new primitive of \\textit{domain compression}, a tool that allows us to map distributions to a much smaller domain size while preserving their pairwise distances, using a limited amount of randomness",
    "volume": "main",
    "checked": true,
    "id": "d9652365cca4a0373e21949648ac062df1361cfa",
    "citation_count": 18
  },
  "https://proceedings.mlr.press/v125/acharya20b.html": {
    "title": "Distributed Signal Detection under Communication Constraints",
    "abstract": "Independent draws from a $d$-dimensional spherical Gaussian distribution are distributed across users, each holding one sample. A central server seeks to distinguish between the two hypotheses: the distribution has zero mean, or the mean has $\\ell_2$-norm at least $\\varepsilon$, a pre-specified threshold. However, the users can each transmit at most $\\ell$ bits to the server.  This is the problem of detecting whether an observed signal is simply white noise in a distributed setting. We study this distributed testing problem with and without the availability of a common randomness shared by the users. We design schemes with and without such shared randomness which achieve sample complexities. We then obtain lower bounds for protocols with public randomness, tight when $\\ell=O(1)$. We finally conclude with several conjectures and open problems",
    "volume": "main",
    "checked": true,
    "id": "eaa65622ea83709f28fa2fb1adf7fe62a67e8bdc",
    "citation_count": 12
  },
  "https://proceedings.mlr.press/v125/agarwal20a.html": {
    "title": "Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes",
    "abstract": "Policy gradient (PG) methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including:  if and how fast they converge to a globally optimal solution (say with a sufficiently rich policy class);  how they cope with approximation error due to using a restricted class of parametric policies; or  their finite sample behavior.  Such characterizations are important not only to compare these methods to their approximate value function counterparts (where such issues are relatively well understood, at least in the worst case), but also to help with more principled approaches to algorithm design. This work provides provable characterizations of computational, approximation, and sample size issues with regards to policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: 1) “tabular” policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy, and 2) restricted policy classes, which may not contain the optimal policy and where we provide agnostic learning results.  In the \\emph{tabular setting}, our main results are: 1) convergence rate to global optimum for direct parameterization and projected gradient ascent  2) an asymptotic convergence to global optimum for softmax policy parameterization and PG; and a convergence rate with additional entropy regularization, and 3) dimension-free convergence to global optimum for softmax policy parameterization and Natural Policy Gradient (NPG) method with exact gradients. In \\emph{function approximation}, we further analyze NPG with exact as well as inexact gradients under certain smoothness assumptions on the policy parameterization and establish rates of convergence in terms of the quality of the initial state distribution. One insight of this work is in formalizing how a favorable initial state distribution provides a means to circumvent worst-case exploration issues.  Overall, these results place PG methods under a solid theoretical footing, analogous to the global convergence guarantees of iterative value function based algorithms",
    "volume": "main",
    "checked": true,
    "id": "6509486691e16dbe6cbe13a4fffa8112acae1af3",
    "citation_count": 225
  },
  "https://proceedings.mlr.press/v125/agarwal20b.html": {
    "title": "Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal",
    "abstract": "This work considers the sample and computational complexity of obtaining an $\\epsilon$-optimal policy in a discounted Markov Decision Process (MDP), given only access to a generative model. In this model, the learner accesses the underlying transition model via a sampling oracle that provides a sample of the next state, when given any state-action pair as input. We are interested in a basic and unresolved question in model based planning: is this naïve “plug-in” approach — where we build the maximum likelihood estimate of the transition model in the MDP from observations and then find an optimal policy in this empirical MDP — non-asymptotically, minimax optimal? Our main result answers this question positively. With regards to computation, our result provides a simpler approach towards minimax optimal planning: in comparison to prior model-free results,  we show that using \\emph{any} high accuracy, black-box planning oracle in the empirical model suffices to obtain the minimax error rate. The key proof technique uses a leave-one-out analysis, in a novel “absorbing MDP” construction, to decouple the statistical dependency issues that arise in the analysis of model-based planning; this construction may be helpful more generally",
    "volume": "main",
    "checked": true,
    "id": "10f2b0f9744aec689b2fc75740bf8d9d9c1896e3",
    "citation_count": 99
  },
  "https://proceedings.mlr.press/v125/ahn20a.html": {
    "title": "From Nesterov's Estimate Sequence to Riemannian Acceleration",
    "abstract": "We propose the first global accelerated gradient method for Riemannian manifolds. Toward establishing our results, we revisit Nesterov’s estimate sequence technique and develop a conceptually simple alternative from first principles. We then extend our analysis to Riemannian acceleration, localizing the key difficulty into “metric distortion.” We control this distortion via a novel geometric inequality, which enables us to formulate and analyze global Riemannian acceleration",
    "volume": "main",
    "checked": true,
    "id": "5d22f63ff5087e31dacab12019416b5d390cce0c",
    "citation_count": 45
  },
  "https://proceedings.mlr.press/v125/alon20a.html": {
    "title": "Closure Properties for Private Classification and Online Prediction",
    "abstract": "Let H be a class of boolean functions and consider a composed class H’ that is derived from H using some arbitrary aggregation rule (for example, H’ may be the class of all 3-wise majority-votes of functions in H). We upper bound the Littlestone dimension of H’ in terms of that of H. As a corollary, we derive closure properties for online learning and private PAC learning. The derived bounds on the Littlestone dimension exhibit an undesirable exponential dependence. For private learning, we  prove close to optimal bounds that circumvents this suboptimal dependency. The improved bounds on the sample complexity of private learning are derived algorithmically via transforming a private learner for the original class H to a private learner for the composed class H’. Using the same ideas we show that any (proper or improper) private algorithm that learns a class of functions H in the realizable case (i.e., when the examples are labeled by some function in the class) can be transformed to a private algorithm that learns the class H in the agnostic case",
    "volume": "main",
    "checked": true,
    "id": "4927ee60f3f7f348a6fa350d63ed5d7259effe78",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v125/alon20b.html": {
    "title": "Hierarchical Clustering: A 0.585 Revenue Approximation",
    "abstract": "Hierarchical Clustering trees have been widely accepted as a useful form of clustering data, resulting in a prevalence of adopting fields including phylogenetics, image analysis, bioinformatics and more.  Recently, Dasgupta (STOC 16’) initiated the analysis of these types of algorithms through the lenses of approximation. Later, the dual problem was considered by Moseley and Wang (NIPS 17’) dubbing it the Revenue goal function. In this problem, given a nonnegative weight $w_{ij}$ for each pair $i,j \\in [n]=\\{1,2, \\ldots ,n\\}$, the objective is to find a tree $T$ whose set of leaves is $[n]$ that maximizes the function $\\sum_{i\n  Cite this Paper\n\n\n BibTeX \n  \n@InProceedings{pmlr-v125-alon20b,\n  title = \t {Hierarchical Clustering: A 0.585 Revenue Approximation},\n  author =       {Alon, Noga and Azar, Yossi and Vainstein, Danny},\n  booktitle = \t {Proceedings of Thirty Third Conference on Learning Theory},\n  pages = \t {153--162},\n  year = \t {2020},\n  editor = \t {Abernethy, Jacob and Agarwal, Shivani},\n  volume = \t {125},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {09--12 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v125/alon20b/alon20b.pdf},\n  url = \t {https://proceedings.mlr.press/v125/alon20b.html},\n  abstract = \t { Hierarchical Clustering trees have been widely accepted as a useful form of clustering data, resulting in a prevalence of adopting fields including phylogenetics, image analysis, bioinformatics and more.  Recently, Dasgupta (STOC 16’) initiated the analysis of these types of algorithms through the lenses of approximation. Later, the dual problem was considered by Moseley and Wang (NIPS 17’) dubbing it the Revenue goal function. In this problem, given a nonnegative weight $w_{ij}$ for each pair $i,j \\in [n]=\\{1,2, \\ldots ,n\\}$, the objective is to find a tree $T$ whose set of leaves is $[n]$ that maximizes the function $\\sum_{i\nCopy to ClipboardDownload\n\n\n Endnote \n  %0 Conference Paper\n%T Hierarchical Clustering: A 0.585 Revenue Approximation\n%A Noga Alon\n%A Yossi Azar\n%A Danny Vainstein\n%B Proceedings of Thirty Third Conference on Learning Theory\n%C Proceedings of Machine Learning Research\n%D 2020\n%E Jacob Abernethy\n%E Shivani Agarwal\t\n%F pmlr-v125-alon20b\n%I PMLR\n%P 153--162\n%U https://proceedings.mlr.press/v125/alon20b.html\n%V 125\n%X  Hierarchical Clustering trees have been widely accepted as a useful form of clustering data, resulting in a prevalence of adopting fields including phylogenetics, image analysis, bioinformatics and more.  Recently, Dasgupta (STOC 16’) initiated the analysis of these types of algorithms through the lenses of approximation. Later, the dual problem was considered by Moseley and Wang (NIPS 17’) dubbing it the Revenue goal function. In this problem, given a nonnegative weight $w_{ij}$ for each pair $i,j \\in [n]=\\{1,2, \\ldots ,n\\}$, the objective is to find a tree $T$ whose set of leaves is $[n]$ that maximizes the function $\\sum_{i\nCopy to ClipboardDownload\n\n\n\n APA \n  \nAlon, N., Azar, Y. & Vainstein, D.. (2020). Hierarchical Clustering: A 0.585 Revenue Approximation. Proceedings of Thirty Third Conference on Learning Theory, in Proceedings of Machine Learning Research 125:153-162 Available from https://proceedings.mlr.press/v125/alon20b.html.\n\n\nCopy to ClipboardDownload\n\n\n\n\n  \n  Related Material\n  \n    \n      Download PDF",
    "volume": "main",
    "checked": false,
    "id": "c7892d8a02606911542f042cf858a74719c81838",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v125/amid20a.html": {
    "title": "Winnowing with Gradient Descent",
    "abstract": "The performance of multiplicative updates is typically logarithmic in the number of features when the targets are sparse. Strikingly, we show that the same property can also be achieved with gradient descent updates. We obtain this result by rewriting the non-negative weights $w_i$ of multiplicative updates by $u_i^2$ and then performing a gradient descent step w.r.t. the new $u_i$ parameters. We apply this method to the Winnow update, the Hedge update, and the unnormalized and normalized exponentiated gradient (EG) updates for linear regression. When the original weights $w_i$ are scaled to sum to one (as done for Hedge and normalized EG), then in the corresponding reparameterized update, the $u_i$ parameters are now divided by $\\Vert\\mathbf{u}\\Vert_2$ after the gradient descent step. We show that these reparameterizations closely track the original multiplicative updates by proving in each case the same online regret bounds (albeit in some cases, with slightly different constants). As a side, our work exhibits a simple two-layer linear neural network that, when trained with gradient descent, can experimentally solve a certain sparse linear problem (known as the Hadamard problem) with exponentially fewer examples than any kernel method",
    "volume": "main",
    "checked": true,
    "id": "a75494dfe490b82f27ef99c077caeafc6d312f42",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v125/amin20a.html": {
    "title": "Pan-Private Uniformity Testing",
    "abstract": "A centrally differentially private algorithm maps raw data to differentially private outputs. In contrast, a locally differentially private algorithm may only access data through public interaction with data holders, and this interaction must be a differentially private function of the data. We study the intermediate model of \\emph{pan-privacy}. Unlike a locally private algorithm, a pan-private algorithm receives data in the clear. Unlike a centrally private algorithm, the algorithm receives data one element at a time and must maintain a differentially private internal state while processing this stream. First, we show that pan-privacy against multiple intrusions on the internal state is equivalent to sequentially interactive local privacy. Next, we contextualize pan-privacy against a single intrusion by analyzing the sample complexity of uniformity testing over domain $[k]$. Focusing on the dependence on $k$, centrally private uniformity testing has sample complexity $\\Theta(\\sqrt{k})$, while noninteractive locally private uniformity testing has sample complexity $\\Theta(k)$. We show that the sample complexity of pan-private uniformity testing is $\\Theta(k^{2/3})$. By a new $\\Omega(k)$ lower bound for the sequentially interactive setting, we also separate pan-private from sequentially interactive locally private and multi-intrusion pan-private uniformity testing",
    "volume": "main",
    "checked": true,
    "id": "5b74dfb3dc36e2426a22361eaebe5b3cd3e6191e",
    "citation_count": 18
  },
  "https://proceedings.mlr.press/v125/argue20a.html": {
    "title": "Dimension-Free Bounds for Chasing Convex Functions",
    "abstract": "We consider the problem of chasing convex functions, where functions arrive over time. The player takes actions after seeing the function, and the goal is to achieve a small function cost for these actions, as well as a small cost for moving between actions. While the general problem requires a polynomial dependence on the dimension, we show how to get dimension-independent bounds for well-behaved functions. In particular, we consider the case where the convex functions are $\\kappa$-well-conditioned, and give an algorithm that achieves an $O(\\sqrt \\kappa)$-competitiveness. Moreover, when the functions are supported on $k$-dimensional affine subspaces—e.g., when the function are the indicators of some affine subspaces—we get $O(\\min(k, \\sqrt{k \\log T}))$-competitive algorithms for request sequences of length $T$. We also show some lower bounds, that well-conditioned functions require $\\Omega(\\kappa^{1/3})$-competitiveness, and $k$-dimensional functions require $\\Omega(\\sqrt{k})$-competitiveness",
    "volume": "main",
    "checked": false,
    "id": "fbc8c8bb407ec5ec2c59b910a97932b8d0803a50",
    "citation_count": 6
  },
  "https://proceedings.mlr.press/v125/arjevani20a.html": {
    "title": "Second-Order Information in Non-Convex Stochastic Optimization: Power and Limitations",
    "abstract": "We design an algorithm which finds an $\\epsilon$-approximate stationary point (with $\\|\\nabla F(x)\\|\\le \\epsilon$) using $O(\\epsilon^{-3})$ stochastic gradient and Hessian-vector products, matching guarantees that were previously available only under a stronger assumption of access to multiple queries with the same random seed. We prove a lower bound which establishes that this rate is optimal and—surprisingly—that it cannot be improved using stochastic $p$th order methods for any $p\\ge 2$, even when the first $p$ derivatives of the objective are Lipschitz. Together, these results characterize the complexity of non-convex stochastic optimization with second-order methods and beyond. Expanding our scope to the oracle complexity of finding $(\\epsilon,\\gamma)$-approximate second-order stationary points, we establish nearly matching upper and lower bounds for stochastic second-order methods. Our lower bounds here are novel even in the noiseless case",
    "volume": "main",
    "checked": true,
    "id": "3e9a102d175b226951760a90c27bbdaacb2ea5c4",
    "citation_count": 25
  },
  "https://proceedings.mlr.press/v125/avanesov20a.html": {
    "title": "Data-driven confidence bands for distributed nonparametric regression",
    "abstract": "Gaussian Process Regression and Kernel Ridge Regression are popular nonparametric regression approaches. Unfortunately, they suffer from high computational complexity rendering them inapplicable to the modern massive datasets. To that end a number of approximations have been suggested, some of them allowing for a distributed implementation. One of them is the divide and conquer approach, splitting the data into a number of partitions, obtaining the local estimates and finally averaging them. In this paper we suggest a novel computationally efficient fully data-driven algorithm, quantifying uncertainty of this method, yielding frequentist $L_2$-confidence bands. We rigorously demonstrate validity of the algorithm. Another contribution of the paper is a minimax-optimal high-probability bound for the averaged estimator, complementing and generalizing the known risk bounds",
    "volume": "main",
    "checked": true,
    "id": "8927d7a9540c4115eaf618833cb8583a0be05019",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v125/awasthi20a.html": {
    "title": "Estimating Principal Components under Adversarial Perturbations",
    "abstract": "Robustness is a key requirement for widespread deployment of machine learning algorithms, and has received much attention in both statistics and computer science. We study a natural model of robustness for high-dimensional statistical estimation problems that we call the {\\em adversarial perturbation model}. An adversary can perturb {\\em every} sample arbitrarily up to a specified magnitude $\\delta$ measured in some $\\ell_q$ norm, say $\\ell_\\infty$. Our model is motivated by emerging paradigms such as {\\em low precision machine learning} and {\\em adversarial training}. We study the classical problem of estimating the top-$r$ principal subspace of the Gaussian covariance matrix in high dimensions, under the adversarial perturbation model. We design a computationally efficient algorithm that given corrupted data, recovers an estimate of the top-$r$ principal subspace with error that depends on a robustness parameter $\\kappa$ that we identify. This parameter corresponds to the $q \\to 2$ operator norm of the projector onto the principal subspace, and generalizes well-studied analytic notions of sparsity. Additionally, in the absence of corruptions, our algorithmic guarantees recover existing bounds for problems such as sparse PCA and its higher rank analogs. We also prove that the above dependence on the parameter $\\kappa$ is almost optimal asymptotically, not just in a minimax sense, but remarkably for {\\em every} instance of the problem. This  {\\em instance-optimal} guarantee shows that the $q \\to 2$ operator norm of the subspace essentially {\\em characterizes} the estimation error under adversarial perturbations",
    "volume": "main",
    "checked": true,
    "id": "2e227dd6892fb34fbcd2af7e59c1d2c459f86e9a",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v125/backurs20a.html": {
    "title": "Active Local Learning",
    "abstract": "In this work we consider active {\\em local learning}: given a query point $x$, and active access to an unlabeled training set $S$, output the prediction $h(x)$ of a near-optimal $h \\in H$ using significantly fewer labels than would be needed to actually learn $h$ fully. In particular, the number of label queries should be independent of the complexity of $H$, and the function $h$ should be well-defined, independent of $x$.  This immediately also implies an algorithm for {\\em distance estimation}: estimating the value $opt(H)$ from many fewer labels than needed to actually learn a near-optimal $h \\in H$, by running local learning on a few random query points and computing the average error. For the hypothesis class consisting of functions supported on the interval $[0,1]$ with Lipschitz constant bounded by $L$, we present an algorithm that makes $O(({1 / \\epsilon^6}) \\log(1/\\epsilon))$ label queries from an unlabeled pool of $O(({L / \\epsilon^4})\\log(1/\\epsilon))$ samples. It estimates the distance to the best hypothesis in the class to an additive error of $\\epsilon$ for an arbitrary underlying distribution. We further generalize our algorithm to more than one dimensions. We emphasize that the number of labels used is independent of the complexity of the hypothesis class which is linear in $L$ in the one-dimensional case. Furthermore, we give an algorithm to locally estimate the values of a near-optimal function at a few query points of interest with number of labels independent of $L$. We also consider the related problem of approximating the minimum error that can be achieved by the Nadaraya-Watson estimator under a linear diagonal transformation with eigenvalues coming from a small range. For a $d$-dimensional pointset of size $N$, our algorithm achieves an additive approximation of $\\epsilon$, makes $\\tilde{O}({d}/{\\epsilon^2})$ queries and runs in $\\tilde{O}({d^2}/{\\epsilon^{d+4}}+{dN}/{\\epsilon^2})$ time",
    "volume": "main",
    "checked": true,
    "id": "604d2d68ae5ac653dc7ad67cb1e4aa73493204bb",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v125/bailey20a.html": {
    "title": "Finite Regret and Cycles with Fixed Step-Size via Alternating Gradient Descent-Ascent",
    "abstract": "Gradient descent is arguably one of the most popular online optimization methods with a wide array of applications.  However, the standard implementation where agents simultaneously update their strategies yields several undesirable properties; strategies diverge  away from equilibrium and regret grows over time. In this paper, we eliminate these negative properties by considering a different implementation to obtain $O\\left( \\nicefrac{1}{T}\\right)$ time-average regret via arbitrary fixed step-size. We obtain this surprising property by having agents take turns when updating their strategies. In this setting, we show that an agent  that uses gradient descent with any linear loss function obtains bounded regret – regardless of how their opponent updates their strategies.  Furthermore, we show that in adversarial settings that agents’ strategies are bounded and cycle when both are using the alternating gradient descent algorithm",
    "volume": "main",
    "checked": true,
    "id": "0bfca3521c23798753d84549be6fdf9fb41a2a31",
    "citation_count": 48
  },
  "https://proceedings.mlr.press/v125/bao20a.html": {
    "title": "Calibrated Surrogate Losses for Adversarially Robust Classification",
    "abstract": "Adversarially robust classification seeks a classifier that is insensitive to adversarial perturbations of test patterns. This problem is often formulated via a minimax objective, where the target loss is the worst-case value of the 0-1 loss subject to a bound on the size of perturbation. Recent work has proposed convex surrogates for the adversarial 0-1 loss, in an effort to make optimization more tractable. In this work, we consider the question of which surrogate losses are \\emph{calibrated} with respect to the adversarial 0-1 loss, meaning that minimization of the former implies minimization of the latter. We show that no convex surrogate loss is calibrated with respect to the adversarial 0-1 loss when restricted to the class of linear models. We further introduce a class of nonconvex losses and offer necessary and sufficient conditions for losses in this class to be calibrated",
    "volume": "main",
    "checked": true,
    "id": "730bb754e8bf51e6faf1e10062e1bd4f4c653875",
    "citation_count": 21
  },
  "https://proceedings.mlr.press/v125/barre20a.html": {
    "title": "Complexity Guarantees for Polyak Steps with Momentum",
    "abstract": "In smooth strongly convex optimization, knowledge of the strong convexity parameter is critical for obtaining simple methods with accelerated rates. In this work, we study a class of methods, based on Polyak steps, where this knowledge is substituted by that of the optimal value, $f_*$. We first show slightly improved convergence bounds than previously known for the classical case of simple gradient descent with Polyak steps, we then derive an accelerated gradient method with Polyak steps and momentum, along with convergence guarantees",
    "volume": "main",
    "checked": true,
    "id": "030fe8fd1ecacc10315ee0793c3a5d55f8f92684",
    "citation_count": 8
  },
  "https://proceedings.mlr.press/v125/ben-arous20a.html": {
    "title": "Free Energy Wells and Overlap Gap Property in Sparse PCA",
    "abstract": "We study a variant of the sparse PCA (principal component analysis) problem in the “hard” regime, where the inference task is possible yet no polynomial-time algorithm is known to exist. Prior work, based on the low-degree likelihood ratio, has conjectured a precise expression for the best possible (sub-exponential) runtime throughout the hard regime. Following instead a statistical physics inspired point of view, we show bounds on the depth of free energy wells for various Gibbs measures naturally associated to the problem. These free energy wells imply hitting time lower bounds that corroborate the low-degree conjecture: we show that a class of natural MCMC (Markov chain Monte Carlo) methods (with worst-case initialization) cannot solve sparse PCA with less than the conjectured runtime. These lower bounds apply to a wide range of values for two tuning parameters: temperature and sparsity misparametrization. Finally, we prove that the Overlap Gap Property (OGP), a structural property that implies failure of certain local search algorithms, holds in a significant part of the hard regime",
    "volume": "main",
    "checked": true,
    "id": "55a248446aa1ce51d93f50c88db6d98716f5f799",
    "citation_count": 20
  },
  "https://proceedings.mlr.press/v125/blanc20a.html": {
    "title": "Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process",
    "abstract": "We consider networks, trained via stochastic gradient descent to minimize $\\ell_2$ loss, with the training labels perturbed by independent noise at each iteration. We characterize the behavior of the training dynamics near any parameter vector that achieves zero training error, in terms of an implicit regularization term corresponding to the sum over the data points, of the squared $\\ell_2$ norm of the gradient of the model with respect to the parameter vector, evaluated at each data point.  This holds for networks of any connectivity, width, depth, and choice of activation function.  We interpret this implicit regularization term for three simple settings: matrix sensing, two layer ReLU networks trained on one-dimensional data, and two layer networks with sigmoid activations trained on a single datapoint.  For these settings, we show why this new and general implicit regularization effect drives the networks towards “simple” models",
    "volume": "main",
    "checked": true,
    "id": "bcf397d57dbcb5d423a341bfadef8dfc09d0cfb8",
    "citation_count": 61
  },
  "https://proceedings.mlr.press/v125/blanca20a.html": {
    "title": "Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models",
    "abstract": "We study identity testing for restricted Boltzmann machines (RBMs), and more generally for undirected graphical models. Given sample access to the Gibbs distribution corresponding to an unknown or hidden model $M^*$  and given an explicit model $M$, can we distinguish if either $M = M^*$ or if they are (statistically) far apart? Daskalakis et al. (2018) presented a polynomial-time algorithm for identity testing for the ferromagnetic (attractive) Ising model. In contrast, for the antiferromagnetic (repulsive) Ising model, Bezáková et al. (2019) proved that unless $RP=NP$ there is no identity testing algorithm when $\\beta d=\\omega(\\log{n})$, where $d$ is the maximum degree of the visible graph and $\\beta$ is the largest edge weight (in absolute value). We prove analogous hardness results for RBMs (i.e., mixed Ising models on bipartite graphs), even when there are no latent variables or an external field. Specifically, we show that if $RP\\neq NP$, then when $\\beta d=\\omega(\\log{n})$ there is no polynomial-time algorithm for identity testing for RBMs; when $\\beta d =O(\\log{n})$ there is an efficient identity testing algorithm that utilizes the structure learning algorithm of Klivans and Meka (2017). In addition, we prove similar lower bounds for purely ferromagnetic RBMs with inconsistent external fields, and for the ferromagnetic Potts model. Previous hardness results for identity testing of Bezáková et al. (2019) utilized the hardness of finding the maximum cuts, which corresponds to the ground states of the antiferromagnetic Ising model. Since RBMs are on bipartite graphs such an approach is not feasible. We instead introduce a novel methodology to reduce from the corresponding approximate counting problem and utilize the phase transition that is exhibited by RBMs and the mean-field Potts model. We believe that our method is general, and that it can be used to establish the hardness of identity testing for other spin systems",
    "volume": "main",
    "checked": true,
    "id": "a06b3842a347ffeb8602753d2991ac853217ad1f",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v125/boursier20a.html": {
    "title": "Selfish Robustness and Equilibria in Multi-Player Bandits",
    "abstract": "Motivated by cognitive radios, stochastic multi-player multi-armed bandits gained a lot of  interest recently. In this class of problems, several players simultaneously pull arms and encounter a collision  – with 0 reward – if some of them pull the same arm at the same time. While the cooperative case where players maximize the collective reward (obediently following some fixed protocol) has been mostly considered, robustness  to malicious players is a crucial  and challenging concern. Existing approaches consider only the case of adversarial jammers whose objective is to blindly minimize the collective reward. We shall consider instead the more natural class of selfish players whose incentives are to maximize their individual rewards, potentially at the expense of the social welfare. We provide the first algorithm robust to selfish players (a.k.a. Nash equilibrium) with a logarithmic regret, when the arm performance is observed.  When collisions are also observed, Grim Trigger type of strategies enable some  implicit communication-based algorithms and we construct robust algorithms in two different settings: the homogeneous (with a regret comparable to the centralized optimal one) and heterogeneous cases (for an adapted and relevant notion of regret). We also provide impossibility results when only the reward is observed or when arm means vary arbitrarily among players",
    "volume": "main",
    "checked": true,
    "id": "2e0f113da96c69ea2d45db94e3c194033301268e",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v125/bousquet20a.html": {
    "title": "Proper Learning, Helly Number, and an Optimal SVM Bound",
    "abstract": "The classical PAC sample complexity bounds are stated for any Empirical Risk Minimizer (ERM) and contain an extra logarithmic factor $\\log(1/\\epsilon)$ which is known to be necessary for ERM in general. It has been recently shown by Hanneke (2016) that the optimal sample complexity of PAC learning for any VC class C does not include this log factor and is achieved by a particular improper learning algorithm, which outputs a specific majority-vote of hypotheses in C. This leaves the question of when this bound can be achieved by proper learning algorithms, which are restricted to always output a hypothesis from C. In this paper we aim to characterize the classes for which the optimal sample complexity can be achieved by a proper learning algorithm. We identify that these classes can be characterized by the dual Helly number, which is a combinatorial parameter that arises in discrete geometry and abstract convexity. In particular, under general conditions on C, we show that the dual Helly number is bounded if and only if there is a proper learner that obtains the optimal dependence on $\\epsilon$. As further implications of our techniques we resolve a long-standing open problem posed by Vapnik and Chervonenkis (1974) on the performance of the Support Vector Machine by proving that the sample complexity of SVM in the realizable case is $\\Theta((n/\\epsilon)+(1/\\epsilon)\\log(1/\\delta))$, where $n$ is the dimension. This gives the first optimal PAC bound for Halfspaces achieved by a proper learning algorithm, and moreover is computationally efficient",
    "volume": "main",
    "checked": true,
    "id": "f48e41c4adf8d411a4fb7edea9176329c7d4fbfe",
    "citation_count": 18
  },
  "https://proceedings.mlr.press/v125/bousquet20b.html": {
    "title": "Sharper Bounds for Uniformly Stable Algorithms",
    "abstract": "Deriving generalization bounds for stable algorithms is a classical question in learning theory taking its roots in the early works by Vapnik and Chervonenkis (1974) and Rogers and Wagner (1978). In a series of recent breakthrough papers by Feldman and Vondrak (2018, 2019), it was shown that the best known high probability upper bounds for uniformly stable learning algorithms due to Bousquet and Elisseef (2002) are sub-optimal in some natural regimes. To do so, they proved two generalization bounds that significantly outperform the simple generalization bound of Bousquet and Elisseef (2002). Feldman and Vondrak also asked if it is possible to provide sharper bounds and prove corresponding high probability lower bounds. This paper is devoted to these questions: firstly, inspired by  the original arguments of Feldman and Vondrak (2019), we provide a short proof of the moment bound that implies the generalization bound stronger than both recent results in Feldman and Vondrak (2018, 2019). Secondly, we prove general lower bounds, showing that our moment bound is sharp (up to a logarithmic factor) unless some additional properties of the corresponding random variables are used. Our main probabilistic result is a general concentration inequality for weakly correlated random variables, which may be of independent interest",
    "volume": "main",
    "checked": true,
    "id": "d8b22446a001a90e9a1d1c4cbe81a9e6dad4f88b",
    "citation_count": 69
  },
  "https://proceedings.mlr.press/v125/braverman20a.html": {
    "title": "The Gradient Complexity of Linear Regression",
    "abstract": "We investigate the computational complexity of several basic linear algebra primitives, including largest eigenvector computation and linear regression, in the computational model that allows access to the data via a matrix-vector product oracle. We show that for polynomial accuracy, $\\Theta(d)$ calls to the oracle are necessary and sufficient even for a randomized algorithm. Our lower bound is based on a reduction to estimating the least eigenvalue of a random Wishart matrix. This simple distribution enables a concise proof, leveraging a few key properties of the random Wishart ensemble",
    "volume": "main",
    "checked": true,
    "id": "279dfe8c6c0ad3038397991cc2784ef3ef6483b6",
    "citation_count": 15
  },
  "https://proceedings.mlr.press/v125/brennan20a.html": {
    "title": "Reducibility and Statistical-Computational Gaps from Secret Leakage",
    "abstract": "Inference problems with conjectured statistical-computational gaps are ubiquitous throughout modern statistics, computer science, statistical physics and discrete probability. While there has been success evidencing these gaps from the failure of restricted classes of algorithms, progress towards a more traditional reduction-based approach to computational complexity in statistical inference has been limited. These average-case problems are each tied to a different natural distribution, high-dimensional structure and conjecturally hard parameter regime, leaving reductions among them technically challenging. Despite a flurry of recent success in developing such techniques, existing reductions have largely been limited to inference problems with similar structure – primarily mapping among problems representable as a sparse submatrix signal plus a noise matrix, which is similar to the common starting hardness assumption of planted clique ($\\textsc{pc}$). The insight in this work is that a slight generalization of the planted clique conjecture – secret leakage planted clique ($\\textsc{pc}_\\rho$), wherein a small amount of information about the hidden clique is revealed – gives rise to a variety of new average-case reduction techniques, yielding a web of reductions relating statistical problems with very different structure. Based on generalizations of the planted clique conjecture to specific forms of $\\textsc{pc}_\\rho$, we deduce tight statistical-computational tradeoffs for a diverse range of problems including robust sparse mean estimation, mixtures of sparse linear regressions, robust sparse linear regression, tensor PCA, variants of dense $k$-block stochastic block models, negatively correlated sparse PCA, semirandom planted dense subgraph, detection in hidden partition models and a universality principle for learning sparse mixtures. This gives the first reduction-based evidence for a number of conjectured statistical-computational gaps. We introduce a number of new average-case reduction techniques that also reveal novel connections to combinatorial designs based on the incidence geometry of $\\mathbb{F}_r^t$ and to random matrix theory. In particular, we show a convergence result between Wishart and inverse Wishart matrices that may be of independent interest. The specific hardness conjectures for $\\textsc{pc}_\\rho$ implying our statistical-computational gaps all are in correspondence with natural graph problems such as $k$-partite, bipartite and hypergraph variants of $\\textsc{pc}$. Hardness in a $k$-partite hypergraph variant of $\\textsc{pc}$ is the strongest of these conjectures and sufficient to establish all of our computational lower bounds. We also give evidence for our $\\textsc{pc}_\\rho$ hardness conjectures from the failure of low-degree polynomials and statistical query algorithms. Our work raises a number of open problems and suggests that previous technical obstacles to average-case reductions may have arisen because planted clique is not the right starting point. An expanded set of hardness assumptions, such as $\\textsc{pc}_\\rho$, may be a key first step towards a more complete theory of reductions among statistical problems",
    "volume": "main",
    "checked": true,
    "id": "7495463f40e0d12e425fe5ad44fb97a4e13d702b",
    "citation_count": 46
  },
  "https://proceedings.mlr.press/v125/bresler20a.html": {
    "title": "A Corrective View of Neural Networks: Representation, Memorization and Learning",
    "abstract": "We develop a \\emph{corrective mechanism} for neural network approximation: the total available non-linear units are divided into multiple groups and the first group approximates the function under consideration, the second approximates the error in approximation produced by the first group and corrects it, the third group approximates the error produced by the first and second groups together and so on. This technique yields several new representation and learning results for neural networks: 1.  Two-layer neural networks in the random features regime (RF) can memorize arbitrary labels for $n$ arbitrary points in $\\mathbb{R}^d$ with $\\tilde{O}(\\tfrac{n}{\\theta^4})$ ReLUs, where $\\theta$ is the minimum distance between two different points. This bound can be shown to be optimal in $n$ up to logarithmic factors. 2.  Two-layer neural networks with ReLUs and smoothed ReLUs can represent functions with an error of at most $\\epsilon$ with $O(C(a,d)\\epsilon^{-1/(a+1)})$ units for $a \\in \\mathbb{N}\\cup\\{0\\}$ when the function has $\\Theta(ad)$ bounded derivatives. In certain cases $d$ can be replaced with effective dimension $q \\ll d$. Our results indicate that neural networks with only a single nonlinear layer are surprisingly powerful with regards to representation, and show that in contrast to what is suggested in recent work, depth is not needed in order to represent highly smooth functions. 3. Gradient Descent on the recombination weights of a two-layer random features network with ReLUs and smoothed ReLUs can learn low degree polynomials up to squared error $\\epsilon$ with  $\\mathrm{subpoly}(1/\\epsilon)$ units. Even though deep networks can approximate these polynomials with $\\mathrm{polylog}(1/\\epsilon)$ units, existing \\emph{learning} bounds for this problem require $\\mathrm{poly}(1/\\epsilon)$ units.  To the best of our knowledge, our results give the first sub-polynomial learning guarantees for this problem",
    "volume": "main",
    "checked": true,
    "id": "ca6483b09870dd79082835e2608617bb0343016e",
    "citation_count": 14
  },
  "https://proceedings.mlr.press/v125/brutzkus20a.html": {
    "title": "ID3 Learns Juntas for Smoothed Product Distributions",
    "abstract": "In recent years, there are many attempts to understand popular heuristics. An example of such heuristic algorithm is the ID3 algorithm for learning decision trees. This algorithm is commonly used in practice, but there are very few theoretical works studying its behavior. In this paper, we analyze the ID3 algorithm, when the target function is a $k$-Junta, a function that depends on $k$ out of $n$ variables of the input. We prove that when $k = \\log n$, the ID3 algorithm learns in polynomial time $k$-Juntas, in the smoothed analysis model of Kalai and Teng (2008). That is, we show a learnability result  when the observed distribution is a “noisy” variant of the original distribution",
    "volume": "main",
    "checked": true,
    "id": "7f1ca30a575fcf0d240bbd70fe49b12185a53e61",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v125/bubeck20a.html": {
    "title": "Coordination without communication: optimal regret in two players multi-armed bandits",
    "abstract": "We consider two agents playing simultaneously the same stochastic three-armed bandit problem. The two agents are cooperating but they cannot communicate. Under the assumption that shared randomness is available, we propose a strategy with no collisions at all between the players (with very high probability), and with near-optimal regret $O(\\sqrt{T \\log(T)})$. We also argue that the extra logarithmic term $\\sqrt{\\log(T)}$ should be necessary by proving a lower bound for a full information variant of the problem",
    "volume": "main",
    "checked": true,
    "id": "bae08a0b0fe1f6df95bbc0378f747d39675fc5af",
    "citation_count": 12
  },
  "https://proceedings.mlr.press/v125/bubeck20b.html": {
    "title": "How to Trap a Gradient Flow",
    "abstract": "We consider the problem of finding an $\\varepsilon$-approximate stationary point of a smooth function on a compact domain of $\\R^d$. In contrast with dimension-free approaches such as gradient descent, we focus here on the case where $d$ is finite, and potentially small. This viewpoint was explored in 1993 by Vavasis, who proposed an algorithm which, for {\\em any fixed finite dimension $d$}, improves upon the $O(1/\\varepsilon^2)$ oracle complexity of gradient descent. For example for $d=2$, Vavasis’ approach obtains the complexity $O(1/\\varepsilon)$. Moreover for $d=2$ he also proved a lower bound of $\\Omega(1/\\sqrt{\\varepsilon})$ for deterministic algorithms (we extend this result to randomized algorithms). Our main contribution is an algorithm, which we call {\\em gradient flow trapping} (GFT), and the analysis of its oracle complexity. In dimension $d=2$, GFT closes the gap with Vavasis’ lower bound (up to a logarithmic factor), as we show that it has complexity $O\\left(\\sqrt{\\frac{\\log(1/\\varepsilon)}{\\varepsilon}}\\right)$. In dimension $d=3$, we show a complexity of $O\\left(\\frac{\\log(1/\\varepsilon)}{\\varepsilon}\\right)$, improving upon Vavasis’ $O\\left(1 / \\varepsilon^{1.2} \\right)$. In higher dimensions, GFT has the remarkable property of being a {\\em logarithmic parallel depth} strategy, in stark contrast with the polynomial depth of gradient descent or Vavasis’ algorithm. In this higher dimensional regime, the total work of GFT improves quadratically upon the only other known polylogarithmic depth strategy for this problem, namely naive grid search",
    "volume": "main",
    "checked": true,
    "id": "6e76c2755fe81bb007ea013bd9f7db1cc8d100d9",
    "citation_count": 8
  },
  "https://proceedings.mlr.press/v125/bubeck20c.html": {
    "title": "Non-Stochastic Multi-Player Multi-Armed Bandits: Optimal Rate With Collision Information, Sublinear Without",
    "abstract": "We consider the non-stochastic version of the (cooperative) multi-player multi-armed bandit problem. The model assumes no communication and no shared randomness at all between the players, and furthermore when two (or more) players select the same action this results in a maximal loss. We prove the first $\\sqrt{T}$-type regret guarantee for this problem, assuming only two players, and under the feedback model where collisions are announced to the colliding players. We also prove the first sublinear regret guarantee for the feedback model where collision information is not available, namely $T^{1-\\frac{1}{2m}}$ where $m$ is the number of players",
    "volume": "main",
    "checked": true,
    "id": "c3a54f7f7628c7f11537c2b32fefb8e121a98a06",
    "citation_count": 29
  },
  "https://proceedings.mlr.press/v125/bullins20a.html": {
    "title": "Highly smooth minimization of non-smooth problems",
    "abstract": "We establish improved rates for structured \\emph{non-smooth} optimization problems by means of near-optimal higher-order accelerated methods. In particular, given access to a standard oracle model that provides a $p^{th}$ order Taylor expansion of a \\emph{smoothed} version of the function, we show how to achieve $\\eps$-optimality for the \\emph{original} problem in $\\tilde{O}_p\\pa{\\eps^{-\\frac{2p+2}{3p+1}}}$ calls to the oracle. Furthermore, when $p=3$, we provide an efficient implementation of the near-optimal accelerated scheme that achieves an $O(\\eps^{-4/5})$ iteration complexity, where each iteration requires $\\tilde{O}(1)$ calls to a linear system solver. Thus, we go beyond the previous $O(\\eps^{-1})$ barrier in terms of $\\eps$ dependence, and in the case of $\\ell_\\infty$ regression and $\\ell_1$-SVM, we establish overall improvements for some parameter settings in the moderate-accuracy regime. Our results also lead to improved high-accuracy rates for minimizing a large class of convex quartic polynomials",
    "volume": "main",
    "checked": true,
    "id": "fca8ae20ff480bc7df9494b4a8b2a57f26656f64",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v125/bun20a.html": {
    "title": "Efficient, Noise-Tolerant, and Private Learning via Boosting",
    "abstract": "We introduce a simple framework for designing private boosting algorithms. We give natural conditions under which these algorithms are differentially private, efficient, and noise-tolerant PAC learners. To demonstrate our framework, we use it to construct noise-tolerant and private PAC learners for large-margin halfspaces whose sample complexity does not depend on the dimension. We give two sample complexity bounds for our large-margin halfspace learner. One bound is based only on differential privacy, and uses this guarantee as an asset for ensuring generalization. This first bound illustrates a general methodology for obtaining PAC learners from privacy, which may be of independent interest. The second bound uses standard techniques from the theory of large-margin classification (the fat-shattering dimension) to match the best known sample complexity for differentially private learning of large-margin halfspaces, while additionally tolerating random label noise",
    "volume": "main",
    "checked": true,
    "id": "7f29b7e1bf99912ee6ad32ede3c110310e02553a",
    "citation_count": 11
  },
  "https://proceedings.mlr.press/v125/celentano20a.html": {
    "title": "The estimation error of general first order methods",
    "abstract": "Modern large-scale statistical models require the estimation of thousands to millions of parameters. This is often accomplished by iterative algorithms such as gradient descent, projected gradient descent or their accelerated versions. What are the fundamental limits of these approaches? This question is well understood from an optimization viewpoint when the underlying objective is convex. Work in this area characterizes the gap to global optimality as a function of the number of iterations. However, these results have only indirect implications on the gap to \\emph{statistical} optimality. Here we consider two families of high-dimensional estimation problems: high-dimensional regression and low-rank matrix estimation, and introduce a class of ‘general first order methods’ that aim at efficiently estimating the underlying parameters. This class of algorithms is broad enough to include classical first order optimization (for convex and non-convex objectives), but also other types of algorithms. Under a random design assumption,  we derive lower bounds on the estimation error that hold in the high-dimensional asymptotics in which both the number of observations and the number of parameters diverge. These lower bounds are optimal in the sense that there exist algorithms in this class whose estimation  error matches the lower bounds up to asymptotically negligible terms. We illustrate our general results through applications to sparse phase retrieval and sparse principal component analysis",
    "volume": "main",
    "checked": true,
    "id": "b4bbc8f15bea43dafc9704b7ea380093365e3c8d",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v125/chase20a.html": {
    "title": "Bounds in query learning",
    "abstract": "We introduce new combinatorial quantities for concept classes, and prove lower and upper bounds for learning complexity in several models of learning in terms of various combinatorial quantities. In the setting of equivalence plus membership queries, we give an algorithm which learns a class in polynomially many queries whenever any such algorithm exists. Our approach is flexible and powerful enough to give new and very short proofs of the efficient learnability of several prominent examples (e.g. regular languages and regular $\\omega$-languages), in some cases also producing new bounds on the number of queries",
    "volume": "main",
    "checked": true,
    "id": "310d2a3ae7e278174ce9e2f7f7040992ee5c369f",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v125/chen20a.html": {
    "title": "Learning Polynomials in Few Relevant Dimensions",
    "abstract": "Polynomial regression is a basic primitive in learning and statistics. In its most basic form the goal is to fit a degree $d$ polynomial  to a response variable $y$ in terms of an $n$-dimensional input vector $x$. This is extremely well-studied with many applications and has sample and runtime complexity $\\Theta(n^d)$. Can one achieve better runtime if the intrinsic dimension of the data is much smaller than the ambient dimension $n$? Concretely, we are given samples $(x,y)$ where $y$ is a degree at most $d$ polynomial in an unknown $r$-dimensional projection (the relevant dimensions) of $x$. This can be seen both as a generalization of phase retrieval and as a special case of learning multi-index models where the link function is an unknown low-degree polynomial. Note that without distributional assumptions, this is at least as hard as junta learning. In this work we consider the important case where the covariates are Gaussian. We give an algorithm that learns the polynomial within accuracy $\\epsilon$ with sample complexity that is roughly $N = O_{r,d}(n \\log^2(1/\\epsilon) (\\log n)^d)$ and runtime $O_{r,d}(N n^2)$. Prior to our work, no such results were known even for the case of $r=1$. We introduce a new \\emph{filtered PCA} approach to get a warm start for the true subspace and use \\emph{geodesic SGD} to boost to arbitrary accuracy; our techniques may be of independent interest, especially for problems dealing with subspace recovery or analyzing SGD on manifolds",
    "volume": "main",
    "checked": false,
    "id": "68f6f9aacdda2b90f3e699221091389085293f02",
    "citation_count": 9
  },
  "https://proceedings.mlr.press/v125/cheshire20a.html": {
    "title": "The Influence of Shape Constraints on the Thresholding Bandit Problem",
    "abstract": "We investigate the stochastic \\emph{Thresholding Bandit problem} (\\textit{TBP}) under several \\emph{shape constraints}. On top of (i) the vanilla, unstructured \\textit{TBP}, we consider the case where (ii) the sequence of arm’s means $(\\mu_k)_k$ is monotonically increasing \\textit{MTBP}, (iii) the case where $(\\mu_k)_k$ is unimodal \\textit{UTBP} and (iv) the case where $(\\mu_k)_k$ is concave \\textit{CTBP}. In the \\textit{TBP} problem the aim is to output, at the end of the sequential game, the set of arms whose means are above a given threshold. The regret is the highest gap between a misclassified arm and the threshold. In the fixed budget setting, we provide \\emph{problem independent} minimax rates for the expected regret in all settings, as well as associated algorithms. We prove that the minimax rates for the regret are (i) $\\sqrt{\\log(K)K/T}$ for \\textit{TBP}, (ii) $\\sqrt{\\log(K)/T}$ for \\textit{MTBP}, (iii) $\\sqrt{K/T}$ for \\textit{UTBP} and (iv) $\\sqrt{\\log\\log K/T}$ for \\textit{CTBP}, where $K$ is the number of arms and $T$ is the budget. These rates demonstrate that \\textit{the dependence on $K$} of the minimax regret varies significantly depending on the shape constraint. This highlights the fact that the shape constraints modify fundamentally the nature of the \\textit{TBP}",
    "volume": "main",
    "checked": true,
    "id": "6f7f17d3dc1f5f720dbf353a557db5c395258230",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v125/chewi20a.html": {
    "title": "Gradient descent algorithms for Bures-Wasserstein barycenters",
    "abstract": "We study first order methods to compute the barycenter of a probability distribution $P$ over the space of probability measures with finite second moment. We develop a framework to derive global rates of convergence for both gradient descent and stochastic gradient descent despite the fact that the barycenter functional is not geodesically convex. Our analysis overcomes this technical hurdle by employing a Polyak-Ł{}ojasiewicz (PL) inequality and relies on tools from optimal transport and metric geometry. In turn, we establish a PL inequality when $P$ is supported on the Bures-Wasserstein manifold of Gaussian probability measures. It leads to the first global rates of convergence for first order methods in this context",
    "volume": "main",
    "checked": true,
    "id": "6a8c3d43f44ff4c99e775b294e85fe4c57a7fb63",
    "citation_count": 48
  },
  "https://proceedings.mlr.press/v125/chizat20a.html": {
    "title": "Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss",
    "abstract": "Neural networks trained to minimize the logistic (a.k.a. cross-entropy) loss with gradient-based methods are observed to perform well in many supervised classification tasks. Towards understanding this phenomenon, we analyze the training and generalization behavior of infinitely wide two-layer neural networks with homogeneous activations. We show that the limits of the gradient flow on exponentially tailed losses can be fully characterized as a max-margin classifier in a certain non-Hilbertian space of functions. In presence of hidden low-dimensional structures, the resulting margin is independent of the ambiant dimension, which leads to strong generalization bounds. In contrast, training only the output layer implicitly solves a kernel support vector machine, which a priori does not enjoy such an adaptivity. Our analysis of training is non-quantitative in terms of running time but we prove computational guarantees in simplified settings by showing equivalences with online mirror descent. Finally, numerical experiments suggest that our analysis describes well the practical behavior of two-layer neural networks with ReLU activation and confirm the statistical benefits of this implicit bias",
    "volume": "main",
    "checked": true,
    "id": "58eee79dd9e1e9aa482656fa3d256b64620dd30a",
    "citation_count": 201
  },
  "https://proceedings.mlr.press/v125/chou20a.html": {
    "title": "ODE-Inspired Analysis for the Biological Version of Oja's Rule in Solving Streaming PCA",
    "abstract": "Oja’s rule [Oja, Journal of mathematical biology 1982] is a well-known biologically-plausible algorithm using a Hebbian-type synaptic update rule to solve streaming principal component analysis (PCA). Computational neuroscientists have known that this biological version of Oja’s rule converges to the top eigenvector of the covariance matrix of the input in the limit. However, prior to this work, it was open to prove any convergence rate guarantee. In this work, we give the first convergence rate analysis for the biological version of Oja’s rule in solving streaming PCA. Moreover, our convergence rate matches the information theoretical lower bound up to logarithmic factors and outperforms the state-of-the-art upper bound for streaming PCA. Furthermore, we develop a novel framework inspired by ordinary differential equations (ODE) to analyze general stochastic dynamics. The framework abandons the traditional \\textit{step-by-step} analysis and instead analyzes a stochastic dynamic in \\textit{one-shot} by giving a closed-form solution to the entire dynamic. The one-shot framework allows us to apply stopping time and martingale techniques to have a flexible and precise control on the dynamic. We believe that this general framework is powerful and should lead to effective yet simple analysis for a large class of problems with stochastic dynamics",
    "volume": "main",
    "checked": true,
    "id": "114e2f520f318c6cf0a48050d008cd19232db672",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v125/cohen20a.html": {
    "title": "Pessimism About Unknown Unknowns Inspires Conservatism",
    "abstract": "If we could define the set of all bad outcomes, we could hard-code an agent which avoids them; however, in sufficiently complex environments, this is infeasible. We do not know of any general-purpose approaches in the literature to avoiding novel failure modes. Motivated by this, we define an idealized Bayesian reinforcement learner which follows a policy that maximizes the worst-case expected reward over a set of world-models. We call this agent pessimistic, since it optimizes assuming the worst case. A scalar parameter tunes the agent’s pessimism by changing the size of the set of world-models taken into account. Our first main contribution is: given an assumption about the agent’s model class, a sufficiently pessimistic agent does not cause “unprecedented events” with probability $1-\\delta$, whether or not designers know how to precisely specify those precedents they are concerned with. Since pessimism discourages exploration, at each timestep, the agent may defer to a mentor, who may be a human or some known-safe policy we would like to improve. Our other main contribution is that the agent’s policy’s value approaches at least that of the mentor, while the probability of deferring to the mentor goes to 0. In high-stakes environments, we might like advanced artificial agents to pursue goals cautiously, which is a non-trivial problem even if the agent were allowed arbitrary computing power; we present a formal solution",
    "volume": "main",
    "checked": true,
    "id": "cecebc0c325a9fc58e78d82a42c8b3f2d9bce769",
    "citation_count": 7
  },
  "https://proceedings.mlr.press/v125/coja-oghlan20a.html": {
    "title": "Optimal Group Testing",
    "abstract": "In the group testing problem, which goes back to the work of Dorfman (1943), we aim to identify a small set of $k\\sim n^\\theta$ infected individuals out of a population size $n$, $0<\\theta<1$.We avail ourselves to a test procedure that can test a group of individuals, with the test returning a positive result iff at least one individual in the group is infected. All tests are conducted in parallel. The aim is to devise a test design with as few tests as possible so that the infected individuals can be identified with high probability. We establish an explicit sharp information-theoretic/algorithmic phase transition $m_{inf}$, showing that with more than $\\minf$ tests the infected individuals can be identified in polynomial time, while this is impossible with fewer tests. In addition, we obtain an optimal two-stage adaptive group testing scheme. These results resolve problems prominently posed in [Aldridge et al. 2019, Johnson et al. 2018, Mézard and Toninelli 2011]",
    "volume": "main",
    "checked": false,
    "id": "630c1e90c3cef1fa4d3da1307ca0612e840dd152",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v125/dagan20a.html": {
    "title": "PAC learning with stable and private predictions",
    "abstract": "We study binary classification algorithms for which the prediction on any point is not too sensitive to individual examples in the dataset. Specifically, we consider the notions of uniform stability (Bousquet and Elisseeff, 2001) and prediction privacy (Dwork and Feldman, 2018). Previous work on these notions shows how they can be achieved in the standard PAC model via simple aggregation of models trained on disjoint subsets of data. Unfortunately, this approach leads to a significant overhead in terms of sample complexity. Here we demonstrate several general approaches to stable and private prediction that either eliminate or significantly reduce the overhead. Specifically, we demonstrate that for any class $C$ of VC dimension $d$ there exists a $\\gamma$-uniformly stable algorithm for learning $C$ with excess error $\\alpha$ using $\\tilde O(d/(\\alpha\\gamma) + d/\\alpha^2)$ samples. We also show that this bound is nearly tight. For $\\eps$-differentially private prediction we give two new algorithms: one using $\\tilde O(d/(\\alpha^2\\eps))$ samples and another one using $\\tilde O(d^2/(\\alpha\\eps) + d/\\alpha^2)$ samples. The best previously  known  bounds for these problems are $O(d/(\\alpha^2\\gamma))$ and $O(d/(\\alpha^3\\eps))$, respectively",
    "volume": "main",
    "checked": true,
    "id": "28d92407d200c9d562bdfd95b6bebca307299f1e",
    "citation_count": 7
  },
  "https://proceedings.mlr.press/v125/davis20a.html": {
    "title": "High probability guarantees for stochastic convex optimization",
    "abstract": "Standard results in stochastic convex optimization bound the number of samples that an algorithm needs to generate a point with small function value in expectation. More nuanced high probability guarantees are rare, and typically either rely on “light-tail” noise assumptions or exhibit worse sample complexity. In this work, we show that a wide class of stochastic optimization algorithms for strongly convex problems can be augmented with high confidence bounds at an overhead cost that is only logarithmic in the confidence level and polylogarithmic in the condition number. The procedure we propose, called proxBoost, is elementary and builds on two well-known ingredients: robust distance estimation and the proximal point method. We discuss consequences for both streaming (online) algorithms and offline algorithms based on empirical risk minimization",
    "volume": "main",
    "checked": true,
    "id": "a897362179549a0a82500e36610f762cc7d30f6a",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v125/diakonikolas20a.html": {
    "title": "Halpern Iteration for Near-Optimal and Parameter-Free Monotone Inclusion and Strong Solutions to Variational Inequalities",
    "abstract": "We leverage the connections between nonexpansive maps, monotone Lipschitz operators, and proximal mappings to obtain near-optimal (i.e., optimal up to poly-log factors in terms of iteration complexity) and parameter-free methods for solving monotone inclusion problems. These results immediately translate into near-optimal guarantees for approximating strong solutions to variational inequality problems, approximating convex-concave min-max optimization problems, and minimizing the norm of the gradient in min-max optimization problems. Our analysis is based on a novel and simple potential-based proof of convergence of Halpern iteration, a classical iteration for finding fixed points of nonexpansive maps.  Additionally, we provide a series of algorithmic reductions that highlight connections between different problem classes and lead to lower bounds that certify near-optimality of the studied methods",
    "volume": "main",
    "checked": true,
    "id": "3c2eb96034409c4bfdd182f2dd09b57a431ddf27",
    "citation_count": 36
  },
  "https://proceedings.mlr.press/v125/diakonikolas20b.html": {
    "title": "Approximation Schemes for ReLU Regression",
    "abstract": "We consider the fundamental problem of ReLU regression, where the goal is to output the best fitting ReLU with respect to square loss given access to draws from some unknown distribution.  We give the first efficient, constant-factor approximation algorithm for this problem assuming the underlying distribution satisfies some weak concentration and anti-concentration conditions (and includes, for example, all log-concave distributions).  This solves the main open problem of Goel et al., who proved hardness results for any exact algorithm for ReLU regression (up to an additive $\\epsilon$). Using more sophisticated techniques, we can improve our results and obtain a polynomial-time approximation scheme for any subgaussian distribution.  Given the aforementioned hardness results, these guarantees can not be substantially improved. Our main insight is a new characterization of {\\em surrogate losses} for nonconvex activations.  While prior work had established the existence of convex surrogates for monotone activations, we show that properties of the underlying distribution actually induce strong convexity for the loss, allowing us to relate the global minimum to the activation’s {\\em Chow parameters}",
    "volume": "main",
    "checked": true,
    "id": "12a90410a1bc893a7b3d68e35e8ec13b9a6a7246",
    "citation_count": 26
  },
  "https://proceedings.mlr.press/v125/diakonikolas20c.html": {
    "title": "Learning Halfspaces with Massart Noise Under Structured Distributions",
    "abstract": "We study the problem of learning halfspaces with Massart noise in the distribution-specific PAC model. We give the first computationally efficient algorithm for this problem with respect to a broad family of distributions, including log-concave distributions. This resolves an open question posed in a number of prior works. Our approach is extremely simple: We identify a smooth {\\em non-convex} surrogate loss with the property that any approximate stationary point of this loss defines a halfspace that is close to the target halfspace. Given this structural result, we can use SGD to solve the underlying learning problem",
    "volume": "main",
    "checked": true,
    "id": "899847e89953d66c5d8e0bb3722bed7c264d1fb1",
    "citation_count": 40
  },
  "https://proceedings.mlr.press/v125/diakonikolas20d.html": {
    "title": "Algorithms and SQ Lower Bounds for PAC Learning One-Hidden-Layer ReLU Networks",
    "abstract": "We study the problem of PAC learning one-hidden-layer ReLU networks with $k$ hidden units on $\\mathbb{R}^d$ under Gaussian marginals in the presence of additive label noise. For the case of positive coefficients, we give the first polynomial-time algorithm for this learning problem for $k$ up to $\\tilde{O}(\\sqrt{\\log d})$. Previously, no polynomial time algorithm was known, even for $k=3$. This answers an open question posed by Klivans (2017). Importantly, our algorithm does not require any assumptions about the rank of the weight matrix and its complexity is independent of its condition number. On the negative side, for the more general task of PAC learning one-hidden-layer ReLU networks with arbitrary real coefficients, we prove a Statistical Query lower bound of $d^{\\Omega(k)}$. Thus, we provide a separation between the two classes in terms of efficient learnability. Our upper and lower bounds are general, extending to broader families of activation functions",
    "volume": "main",
    "checked": true,
    "id": "ae89d2c48ad15b2d29de51d67a381451d1f3a356",
    "citation_count": 37
  },
  "https://proceedings.mlr.press/v125/ding20a.html": {
    "title": "Consistent recovery threshold of hidden nearest neighbor graphs",
    "abstract": "Motivated by applications such as discovering strong ties in social networks and assembling genome subsequences in biology, we study the problem of recovering a hidden $2k$-nearest neighbor (NN) graph in an $n$-vertex complete graph, whose edge weights are independent and distributed according to $P_n$ for edges in the hidden $2k$-NN graph and $Q_n$ otherwise. The special case of Bernoulli distributions corresponds to a variant of the Watts-Strogatz small-world graph. We focus on two types of asymptotic recovery guarantees as $n\\to \\infty$: (1) exact recovery: all edges are classified correctly with probability tending to one; (2) almost exact recovery: the expected number of misclassified edges is $o(nk)$. We show that the maximum likelihood estimator achieves (1) exact recovery for $2 \\le k \\le n^{o(1)}$ if $ \\liminf \\frac{2\\alpha_n}{\\log n}>1$; (2) almost exact recovery for $ 1 \\le k \\le o\\left( \\frac{\\log n}{\\log \\log n} \\right)$ if $ \\liminf \\frac{kD(P_n||Q_n)}{\\log n}>1, $ where $\\alpha_n \\triangleq -2 \\log \\int \\sqrt{d P_n d Q_n}$ is the Rényi divergence of order $\\frac{1}{2}$ and $D(P_n||Q_n)$ is the Kullback-Leibler divergence. Under mild distributional assumptions, these conditions are shown to be information-theoretically necessary for any algorithm to succeed. A key challenge in the analysis is the enumeration of $2k$-NN graphs that differ from the hidden one by a given number of edges. We also analyze several computationally efficient algorithms and provide sufficient conditions under which they achieve exact/almost exact recovery. In particular, we develop a polynomial-time algorithm that attains the threshold for exact recovery under the small-world model",
    "volume": "main",
    "checked": true,
    "id": "0d11c72d6e4bacd2af5f38558967486f53a5138d",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v125/dong20a.html": {
    "title": "Root-n-Regret for Learning in Markov Decision Processes with Function Approximation and Low Bellman Rank",
    "abstract": "In this paper, we consider the problem of online learning of Markov decision processes (MDPs) with very large state spaces. Under the assumptions of realizable function approximation and low Bellman ranks, we develop an online learning algorithm that learns the optimal value function while at the same time achieving very low cumulative regret during the learning process. Our learning algorithm, Adaptive Value-function Elimination (AVE), is inspired by the policy elimination algorithm proposed in (Jiang et al., 2017), known as OLIVE. One of our key technical contributions in AVE is to formulate the elimination steps in OLIVE as contextual bandit problems. This technique enables us to apply the active elimination and expert weighting methods from (Dudik et al., 2011), instead of the random action exploration scheme used in the original OLIVE algorithm, for more efficient exploration and better control of the regret incurred in each policy elimination step. To the best of our knowledge, this is the first root-n-regret result for reinforcement learning in stochastic MDPs with general value function approximation",
    "volume": "main",
    "checked": false,
    "id": "75a285cc476240040111cb608d038c7480b25ad8",
    "citation_count": 27
  },
  "https://proceedings.mlr.press/v125/finocchiaro20a.html": {
    "title": "Embedding Dimension of Polyhedral Losses",
    "abstract": "A common technique in supervised learning with discrete losses, such as 0-1 loss, is to optimize a convex surrogate loss over Rd, calibrated with respect to the original loss. In particular, recent work has investigated embedding the original predictions (e.g. labels) as points in Rd, showing an equivalence to using polyhedral surrogates. In this work, we study the notion of the embedding dimension of a given discrete loss: the minimum dimension d such that an embedding exists. We characterize d-embeddability for all d, with a particularly tight characterization for d=1 (embedding into the real line), and useful necessary conditions for d>1 in the form of a quadratic feasibility program. We illustrate our results with novel lower bounds for abstain loss",
    "volume": "main",
    "checked": true,
    "id": "4a69ac8bd0ce5dc2e66f883c837e5ed844ec3364",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v125/fotakis20a.html": {
    "title": "Efficient Parameter Estimation of Truncated Boolean Product Distributions",
    "abstract": "We study the problem of estimating the parameters of a Boolean product distribution in $d$ dimensions, when the samples are truncated by a set $S \\subset \\{0, 1\\}^d$ accessible through a membership oracle. This is the first time that the computational and statistical complexity of learning from truncated samples is considered in a discrete setting. We introduce a natural notion of \\emph{fatness} of the truncation set $S$, under which truncated samples reveal enough information about the true distribution. We show that if the truncation set is sufficiently fat, samples from the true distribution can be generated from truncated samples. A stunning consequence is that virtually any statistical task (e.g., learning in total variation distance, parameter estimation, uniformity or identity testing) that can be performed efficiently for Boolean product distributions, can also be performed from truncated samples, with a small increase in sample complexity. We generalize our approach to ranking distributions over $d$ alternatives, where we show how fatness implies efficient parameter estimation of Mallows models from truncated samples. Exploring the limits of learning discrete models from truncated samples, we identify three natural conditions that are necessary for efficient identifiability: (i) the truncation set $S$ should be rich enough; (ii) $S$ should be accessible through membership queries; and (iii) the truncation by $S$ should leave enough randomness in all directions. By carefully adapting the Stochastic Gradient Descent approach of (Daskalakis et al., FOCS 2018), we show that these conditions are also sufficient for efficient learning of truncated Boolean product distributions",
    "volume": "main",
    "checked": true,
    "id": "19d266777a740cd19df5ce66044cdc4515422932",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v125/franks20a.html": {
    "title": "Rigorous Guarantees for Tyler's M-Estimator via Quantum Expansion",
    "abstract": "Estimating the shape of an elliptical distribution is a fundamental problem in statistics. One estimator for the shape matrix, Tyler’s M-estimator, has been shown to have many appealing asymptotic properties. It performs well in numerical experiments and can be quickly computed in practice by a simple iterative procedure. Despite the many years the estimator has been studied in the statistics community, there was neither a non-asymptotic bound on the rate of the estimator nor a proof that the iterative procedure converges in polynomially many steps. Here we observe a surprising connection between Tyler’s M-estimator and operator scaling, which has been intensively studied in recent years in part because of its connections to the Brascamp-Lieb inequality in analysis. We use this connection, together with novel results on quantum expanders, to show that Tyler’s M-estimator has the optimal rate up to factors logarithmic in the dimension, and that in the generative model the iterative procedure has a linear convergence rate even without regularization",
    "volume": "main",
    "checked": true,
    "id": "dcf3772f870938194bb4cf2273b047f72e04de61",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v125/ganassali20a.html": {
    "title": "From tree matching to sparse graph alignment",
    "abstract": "In this paper we consider alignment of sparse graphs, for which we introduce the Neighborhood Tree Matching Algorithm (NTMA). For correlated Erdős-R{é}nyi random graphs, we prove that the algorithm returns – in polynomial time – a positive fraction of correctly matched vertices, and a vanishing fraction of mismatches. This result holds with average degree of the graphs in $O(1)$ and correlation parameter $s$ that can be bounded away from $1$, conditions under which random graph alignment is particularly challenging. As a byproduct of the analysis we introduce a matching metric between trees and characterize it for several models of correlated random trees. These results may be of independent interest, yielding for instance efficient tests for determining whether two random trees are correlated or independent",
    "volume": "main",
    "checked": true,
    "id": "15291d351c402c2fa784c209e18654eccea3e226",
    "citation_count": 24
  },
  "https://proceedings.mlr.press/v125/garber20a.html": {
    "title": "On the Convergence of Stochastic Gradient Descent with Low-Rank Projections for Convex Low-Rank Matrix Problems",
    "abstract": "We revisit the use of Stochastic Gradient Descent (SGD) for solving convex optimization problems that serve as highly popular convex relaxations for many important low-rank matrix recovery problems such as matrix completion, phase retrieval, and more. The computational limitation of applying SGD to solving these relaxations in large-scale is the need to compute a potentially high-rank singular value decomposition (SVD) on each iteration in order to enforce the low-rank-promoting constraint. We begin by considering a simple and natural sufficient condition so that these relaxations indeed admit low-rank solutions. This condition is also necessary for a certain notion of low-rank-robustness to hold. Our main result shows that under this condition which involves the eigenvalues of the gradient vector at optimal points, SGD with mini-batches, when initialized with a “warm-start\" point, produces iterates that are low-rank with high probability, and hence only a low-rank SVD computation is required on each iteration. This suggests that SGD may indeed be practically applicable to solving large-scale convex relaxations of low-rank matrix recovery problems. Our theoretical results are accompanied with supporting preliminary empirical evidence. As a side benefit, our analysis is quite simple and short",
    "volume": "main",
    "checked": true,
    "id": "8f0ce2b916657c0e414417f4634ae9ea7d14cf83",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v125/gerbelot20a.html": {
    "title": "Asymptotic Errors for High-Dimensional Convex Penalized Linear Regression beyond Gaussian Matrices",
    "abstract": "We consider the problem of learning a coefficient vector $\\bf x_0 \\in \\mathbb R^N$ from noisy linear observations $\\mathbf{y} = \\mathbf{F}{\\mathbf{x}_{0}}+\\mathbf{w} \\in \\mathbb R^M$ in high dimensional limit $M,N \\to \\infty$ with $\\alpha \\equiv M/N$ fixed. We provide a rigorous derivation of an explicit formula —first conjectured using heuristics method from statistical physics— for the asymptotic mean squared error obtained by penalized convex estimators such as the LASSO or the elastic net, for a sequence of very generic random matrix $\\mathbf{F}$ corresponding to rotationally invariant data matrices of arbitrary spectrum.  The proof is based on a convergence analysis of an oracle version of vector approximate message-passing (oracle-VAMP) and on the properties of its state evolution equations. Our method leverages on and highlights the link between vector approximate message-passing, Douglas-Rachford splitting and proximal descent algorithms, extending previous results obtained with i.i.d. matrices for a large class of problems. We illustrate our results on some concrete examples and show that even though they are asymptotic, our predictions agree remarkably well with numerics even for very moderate sizes",
    "volume": "main",
    "checked": true,
    "id": "e6594d56fe8a8965b790afce5810a50da7bd93a2",
    "citation_count": 15
  },
  "https://proceedings.mlr.press/v125/ghai20a.html": {
    "title": "No-Regret Prediction in Marginally Stable Systems",
    "abstract": "We consider the problem of online prediction in a marginally stable linear dynamical system subject to bounded adversarial or (non-isotropic) stochastic perturbations. This poses two challenges. Firstly, the system is in general unidentifiable, so recent and classical results on parameter recovery do not apply. Secondly, because we allow the system to be marginally stable, the state can grow polynomially with time; this causes standard regret bounds in online convex optimization to be vacuous. In spite of these challenges, we show that the online least-squares algorithm achieves sublinear regret (improvable to polylogarithmic in the stochastic setting), with polynomial dependence on the system’s parameters. This requires a refined regret analysis, including a structural lemma showing the current state of the system to be a small linear combination of past states, even if the state grows polynomially. By applying our techniques to learning an autoregressive filter, we also achieve logarithmic regret in the partially observed setting under Gaussian noise, with polynomial dependence on the memory of the associated Kalman filter",
    "volume": "main",
    "checked": true,
    "id": "0d0741b0a4d9295b0bcc3ea13733cbc963604230",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v125/golowich20a.html": {
    "title": "Last Iterate is Slower than Averaged Iterate in Smooth Convex-Concave Saddle Point Problems",
    "abstract": "In this paper we study the smooth convex-concave saddle point problem. Specifically, we analyze the last iterate convergence properties of the Extragradient (EG) algorithm. It is well known that the ergodic (averaged) iterates of EG converge at a rate of $O(1/T)$ (Nemirovski, 2004). In this paper, we show that the last iterate of EG converges at a rate of $O(1/\\sqrt{T})$. To the best of our knowledge, this is the first paper to provide a convergence rate guarantee for the last iterate of EG for the smooth convex-concave saddle point problem. Moreover, we show that this rate is tight by proving a lower bound of $\\Omega(1/\\sqrt{T})$ for the last iterate. This lower bound therefore shows a quadratic separation of the convergence rates of ergodic and last iterates in smooth convex-concave saddle point problems",
    "volume": "main",
    "checked": true,
    "id": "16754adf25bac04161ba9db653935609bf058623",
    "citation_count": 57
  },
  "https://proceedings.mlr.press/v125/gopi20a.html": {
    "title": "Locally Private Hypothesis Selection",
    "abstract": "We initiate the study of hypothesis selection under local differential privacy. Given samples from an unknown probability distribution $p$ and a set of $k$ probability distributions $\\mathcal{Q}$, we aim to output, under the constraints of $\\varepsilon$-differential privacy, a distribution from $\\mathcal{Q}$ whose total variation distance to $p$ is comparable to the best such distribution. This is a generalization of the classic problem of $k$-wise simple hypothesis testing, which corresponds to when $p \\in \\mathcal{Q}$, and we wish to identify $p$. Absent privacy constraints, this problem requires $O(\\log k)$ samples from $p$, and it was recently shown that the same complexity is achievable under (central) differential privacy. However, the naive approach to this problem under local differential privacy would require $\\tilde O(k^2)$ samples. We first show that the constraint of local differential privacy incurs an exponential increase in cost: any algorithm for this problem requires at least $\\Omega(k)$ samples. Second, for the special case of $k$-wise simple hypothesis testing, we provide a non-interactive algorithm which nearly matches this bound, requiring $\\tilde O(k)$ samples. Finally, we provide sequentially interactive algorithms for the general case, requiring $\\tilde O(k)$ samples and only $O(\\log \\log k)$ rounds of interactivity. Our algorithms are achieved through a reduction to maximum selection with adversarial comparators, a problem of independent interest for which we initiate study in the parallel setting. For this problem, we provide a family of algorithms for each number of allowed rounds of interaction $t$, as well as lower bounds showing that they are near-optimal for every $t$. Notably, our algorithms result in exponential improvements on the round complexity of previous methods",
    "volume": "main",
    "checked": true,
    "id": "5b685358c98593f29bebd4903dbab43bc262428e",
    "citation_count": 12
  },
  "https://proceedings.mlr.press/v125/hao20a.html": {
    "title": "Bessel Smoothing and Multi-Distribution Property Estimation",
    "abstract": "We consider a basic problem in statistical learning: estimating properties of multiple discrete distributions. Denoting by $\\Delta_k$ the standard simplex over $[k]:=\\{0,1,\\ldots, k\\}$, a property of $d$ distributions is a mapping from $\\Delta_k^d$ to $\\mathbb R$. These properties include well-known distribution characteristics such as Shannon entropy and support size  ($d=1$), and many important divergence measures between distributions ($d=2$). The primary problem being considered is to learn the property value of an $\\emph{unknown}$ $d$-tuple of distributions from its sample. The study of such problems dates back to the works of Efron and Thisted (1976b); Thisted and Efron (1987); Good (1953b); Carlton (1969), and has been pushed forward steadily during the past decades. Surprisingly, before our work, the general landscape of this fundamental learning problem was insufficiently understood, and nearly all the existing results are for the special case $d\\le 2$. Our first main result provides a near-linear-time computable algorithm that, given independent samples from any collection of distributions and for a broad class of multi-distribution properties, learns the property as well as the empirical plug-in estimator that uses samples with logarithmic-factor larger sizes. As a corollary of this, for any $\\varepsilon>0$ and fixed $d\\in \\mathbb Z^+$, a $d$-distribution property over $[k]$ that is Lipschitz and additively separable can be learned to an accuracy of $\\varepsilon$ using a sample of size $\\mathcal{O}(k/(\\varepsilon^3\\sqrt{\\log k}))$, with high probability. Our second result addresses a closely related problem– tolerant independence testing: One receives samples from the unknown joint and marginal distributions, and attempts to infer the $\\ell_1$ distance between the joint distribution and the product distribution of the marginals. We show that this testing problem also admits a sample complexity sub-linear in the alphabet sizes, demonstrating the broad applicability of our approach",
    "volume": "main",
    "checked": true,
    "id": "3d95da6375fd4c43449e04159f5f02c99dd00dab",
    "citation_count": 7
  },
  "https://proceedings.mlr.press/v125/hazan20a.html": {
    "title": "Faster Projection-free Online Learning",
    "abstract": "In many online learning problems the computational bottleneck for gradient-based methods is the  projection operation. For this reason, in many problems the most efficient algorithms are based on the Frank-Wolfe method, which replaces projections by linear optimization. In the general case, however, online projection-free methods require more iterations than projection-based methods: the best known regret bound scales as $T^{3/4}$. Despite significant work on various variants of the Frank-Wolfe method, this bound has remained unchanged for a decade. In this paper we give an efficient projection-free algorithm that guarantees $T^{2/3}$ regret for general online convex optimization with smooth cost functions and one linear optimization computation per iteration. As opposed to previous Frank-Wolfe approaches, our algorithm is derived using the Follow-the-Perturbed-Leader method and is analyzed using an online primal-dual framework",
    "volume": "main",
    "checked": true,
    "id": "2db8d117ac352b00f8d5176bba6bc8bacddecba3",
    "citation_count": 26
  },
  "https://proceedings.mlr.press/v125/hinder20a.html": {
    "title": "Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond",
    "abstract": "In this paper, we provide near-optimal accelerated first-order methods for minimizing a broad class of smooth nonconvex functions that are unimodal on all lines through a minimizer. This function class, which we call the class of smooth quasar-convex functions, is parameterized by a constant $$\\gamma \\in (0,1]$$: $$\\gamma = 1$$ encompasses the classes of smooth convex and star-convex functions, and smaller values of $$\\gamma$$ indicate that the function can be \"more nonconvex.\" We develop a variant of accelerated gradient descent that computes an $$\\epsilon$$-approximate minimizer of a smooth $$\\gamma$$-quasar-convex function with at most $$O(\\gamma^{-1} \\epsilon^{-1/2} \\log(\\gamma^{-1} \\epsilon^{-1}))$$ total function and gradient evaluations. We also derive a lower bound of $$\\Omega(\\gamma^{-1} \\epsilon^{-1/2})$$ on the worst-case number of gradient evaluations required by any deterministic first-order method, showing that, up to a logarithmic factor, no deterministic first-order method can improve upon ours",
    "volume": "main",
    "checked": true,
    "id": "ae23404f805bcbe6335082dcc65a46c1e961b163",
    "citation_count": 39
  },
  "https://proceedings.mlr.press/v125/holtzman20a.html": {
    "title": "A Greedy Anytime Algorithm for Sparse PCA",
    "abstract": "The taxing computational effort that is involved in solving some high-dimensional statistical problems, in particular problems involving non-convex optimization, has popularized the development and analysis of algorithms that run efficiently (polynomial-time) but with no general guarantee on statistical consistency. In light of the ever-increasing compute power and decreasing costs, a more useful characterization of algorithms is by their ability to  calibrate the invested computational effort with various characteristics of the input at hand and with the available computational resources. We propose a new greedy algorithm for the $\\ell_0$-sparse PCA problem which supports the calibration principle. We provide both a rigorous analysis of our algorithm in the spiked covariance model, as well as simulation results and comparison with other existing methods. Our findings show that our algorithm recovers the spike in SNR regimes where all polynomial-time algorithms fail while running in a reasonable parallel-time on a cluster",
    "volume": "main",
    "checked": true,
    "id": "3f1dfc92ff58da0cfb2824e3dda7407a099f7d72",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v125/hopkins20a.html": {
    "title": "Noise-tolerant, Reliable Active Classification with Comparison Queries",
    "abstract": "With the explosion of massive, widely available unlabeled data in the past years, finding label and time efficient, robust learning algorithms has become ever more important in theory and in practice. We study the paradigm of active learning, in which algorithms with access to large pools of data may adaptively choose what samples to label in the hope of exponentially increasing efficiency. By introducing comparisons, an additional type of query comparing two points, we provide the first time and query efficient algorithms for learning non-homogeneous linear separators robust to bounded (Massart) noise. We further provide algorithms for a generalization of the popular Tsybakov low noise condition, and show how comparisons provide a strong reliability guarantee that is often impractical or impossible with only labels - returning a classifier that makes no errors with high probability",
    "volume": "main",
    "checked": true,
    "id": "be62c8d867d2b717e0c8fa3366216f46658d9795",
    "citation_count": 17
  },
  "https://proceedings.mlr.press/v125/hu20a.html": {
    "title": "Smooth Contextual Bandits: Bridging the Parametric and Non-differentiable Regret Regimes",
    "abstract": "We study a nonparametric contextual bandit problem where the expected reward functions belong to a Hölder class with smoothness parameter $\\beta$. We show how this interpolates between two extremes that were previously studied in isolation: non-differentiable bandits ($\\beta\\leq1$), where rate-optimal regret is achieved by running separate non-contextual bandits in different context regions, and parametric-response bandits (satisfying $\\beta=\\infty$), where rate-optimal regret can be achieved with minimal or no exploration due to infinite extrapolatability. We develop a novel algorithm that carefully adjusts to all smoothness settings and we prove its regret is rate-optimal by establishing matching upper and lower bounds, recovering the existing results at the two extremes. In this sense, our work bridges the gap between the existing literature on parametric and non-differentiable contextual bandit problems and between bandit algorithms that exclusively use global or local information, shedding light on the crucial interplay of complexity and regret in contextual bandits",
    "volume": "main",
    "checked": true,
    "id": "2aa1d573b3b49ca89e719c05a70ef43cd3ce4642",
    "citation_count": 18
  },
  "https://proceedings.mlr.press/v125/jana20a.html": {
    "title": "Extrapolating the profile of a finite population",
    "abstract": "We study a prototypical problem in empirical Bayes. Namely, consider a population consisting of $k$ individuals each belonging to one of $k$ types (some types can be empty). Without any structural restrictions, it is impossible to learn the composition of the full population having observed only a small (random) subsample of size $m = o(k)$. Nevertheless, we show that in the sublinear regime of $m =\\omega(k/\\log k)$, it is possible to consistently estimate in total variation the \\emph{profile} of the population, defined as the empirical distribution of the sizes of each type, which determines many symmetric properties of the population. We also prove that in the linear regime of $m=c k$ for any constant $c$ the optimal rate is $\\Theta(1/\\log k)$. Our estimator is based on Wolfowitz’s minimum distance method, which entails solving a linear program (LP) of size $k$. We show that there is a single infinite-dimensional LP whose value simultaneously characterizes the risk of the minimum distance estimator and certifies its minimax optimality. The sharp convergence rate is obtained by evaluating this LP using complex-analytic techniques",
    "volume": "main",
    "checked": true,
    "id": "9ff2cfa264e6a17500d6380294c36ca579d11954",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v125/javanmard20a.html": {
    "title": "Precise Tradeoffs in Adversarial Training for Linear Regression",
    "abstract": "Despite breakthrough performance, modern learning models are known to be highly vulnerable to small adversarial perturbations in their inputs. While a wide variety of recent \\emph{adversarial training} methods have been effective at improving robustness to perturbed inputs (robust accuracy), often this benefit is accompanied by a decrease in accuracy on benign inputs (standard accuracy), leading to a tradeoff between often competing objectives. Complicating matters further, recent empirical evidence suggest that a variety of other factors (size and quality of training data, model size, etc.) affect this tradeoff in somewhat surprising ways. In this paper we provide a precise and comprehensive understanding of the role of adversarial training in the context of linear regression with Gaussian features. In particular, we characterize the fundamental tradeoff between the accuracies achievable by any algorithm regardless of computational power or size of the training data. Furthermore, we precisely characterize the standard/robust accuracy and the corresponding tradeoff achieved by a contemporary mini-max adversarial training approach in a high-dimensional regime where the number of data points and the parameters of the model grow in proportion to each other. Our theory for adversarial training algorithms also facilitates the rigorous study of how a variety of factors (size and quality of training data, model overparametrization etc.) affect the tradeoff between these two competing accuracies",
    "volume": "main",
    "checked": true,
    "id": "bff4ae911351a5c7dd9af394aa7f2647bf42dd4a",
    "citation_count": 54
  },
  "https://proceedings.mlr.press/v125/jeong20a.html": {
    "title": "Robust causal inference under covariate shift via worst-case subpopulation treatment effects",
    "abstract": "We propose a notion of worst-case treatment effect (WTE) across all subpopulations of a given size, a conservative notion of topline treatment effect. Compared to the average treatment effect (ATE) that solely relies on the covariate distribution of collected data, WTE is robust to unanticipated covariate shifts, and ensures reliable inference uniformly over underrepresented minority groups. We develop a semiparametrically efficient estimator for the WTE, leveraging machine learning-based estimates of heterogenous treatment effects and propensity scores. By virtue of satisfying a key (Neyman) orthogonality property, our estimator enjoys central limit behavior—oracle rates with true nuisance parameters—even when estimates of nuisance parameters converge at slower-than-parameteric rates.  In particular, this allows using black-box machine learning methods to construct asymptotically exact confidence intervals for the WTE.  For both observational and randomized studies, we prove that our estimator achieves the \\emph{optimal} asymptotic variance, by establishing a semiparametric efficiency lower bound. On real datasets, we illustrate the non-robustness of ATE under even small amounts distributional shift, and demonstrate that WTE allows us to guard against brittle findings that are invalidated by unanticipated covariate shifts",
    "volume": "main",
    "checked": true,
    "id": "7b65c87f90413353e1b095a977d7ad25bc1beab1",
    "citation_count": 11
  },
  "https://proceedings.mlr.press/v125/jezequel20a.html": {
    "title": "Efficient improper learning for online logistic regression",
    "abstract": "We consider the setting of online  logistic regression and consider the regret with respect to the $\\ell_2$-ball of radius $B$. It is known (see Hazan et al. (2014)) that any proper algorithm which has logarithmic regret in the number of samples (denoted $n$) necessarily suffers an exponential multiplicative constant in $B$. In this work, we design an efficient improper algorithm that avoids this exponential constant while preserving a logarithmic regret. Indeed, Foster et al. (2018) showed that the lower bound  does not apply to improper algorithms and proposed a strategy based on exponential weights with prohibitive computational complexity. Our new algorithm based on regularized empirical risk minimization with surrogate losses satisfies a regret scaling as $O(B\\log(Bn))$ with a per-round time-complexity of order $O(d^2 + \\log(n))$",
    "volume": "main",
    "checked": true,
    "id": "27230bc04310a876cc087d7891d02d44e0c04bf0",
    "citation_count": 14
  },
  "https://proceedings.mlr.press/v125/ji20a.html": {
    "title": "Gradient descent follows the regularization path for general losses",
    "abstract": "Recent work across many machine learning disciplines has highlighted that standard descent methods, even without explicit regularization, do not merely minimize the training error, but also exhibit an \\emph{implicit bias}. This bias is typically towards a certain regularized solution, and relies upon the details of the learning process, for instance the use of the cross-entropy loss. In this work, we show that for empirical risk minimization over linear predictors with \\emph{arbitrary} convex, strictly decreasing losses, if the risk does not attain its infimum, then the gradient-descent path and the \\emph{algorithm-independent} regularization path converge to the same direction (whenever either converges to a direction). Using this result, we provide a justification for the widely-used exponentially-tailed losses (such as the exponential loss or the logistic loss): while this convergence to a direction for exponentially-tailed losses is necessarily to the maximum-margin direction, other losses such as polynomially-tailed losses may induce convergence to a direction with a poor margin",
    "volume": "main",
    "checked": true,
    "id": "799a6f18c79b56c04c42bd96e4e39f8119b57843",
    "citation_count": 30
  },
  "https://proceedings.mlr.press/v125/jin20a.html": {
    "title": "Provably efficient reinforcement learning with linear function approximation",
    "abstract": "Modern Reinforcement Learning (RL) is commonly applied to practical problems with an enormous number of states, where \\emph{function approximation} must be deployed to approximate either the value function or the policy. The introduction of function approximation raises a fundamental set of challenges involving computational and statistical efficiency, especially given the need to manage the exploration/exploitation tradeoff. As a result, a core RL question remains open: how can we design provably efficient RL algorithms that incorporate function approximation? This question persists even in a basic setting with linear dynamics and linear rewards, for which only linear function approximation is needed. This paper presents the first provable RL algorithm with both polynomial runtime and polynomial sample complexity in this linear setting, without requiring a “simulator” or additional assumptions. Concretely, we prove that an optimistic modification of Least-Squares Value Iteration (LSVI)—a classical algorithm frequently studied in the linear setting—achieves $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret, where $d$ is the ambient dimension of feature space, $H$ is the length of each episode, and $T$ is the total number of steps. Importantly, such regret is independent of the number of states and actions",
    "volume": "main",
    "checked": true,
    "id": "533a2e4a57a557c85bece2b363ab8be273eb33d0",
    "citation_count": 370
  },
  "https://proceedings.mlr.press/v125/kaledin20a.html": {
    "title": "Finite Time Analysis of Linear Two-timescale Stochastic Approximation with Markovian Noise",
    "abstract": "Linear two-timescale stochastic approximation (SA) scheme is an important class of algorithms which has become popular in reinforcement learning (RL), particularly for the policy evaluation problem. Recently, a number of works have been devoted to establishing the finite time analysis of the scheme, especially under the Markovian (non-i.i.d.) noise settings that are ubiquitous in practice. In this paper, we provide a finite-time  analysis for linear two timescale SA. Our bounds show that there is no discrepancy in the convergence rate between Markovian and martingale noise, only the constants are affected by the mixing time of the Markov chain. With an appropriate step size schedule, the transient term in the expected error bound is $o(1/k^c)$ and the steady-state term is ${\\cal O}(1/k)$, where $c>1$ and $k$ is the iteration number. Furthermore, we present an asymptotic expansion of the expected error with a matching lower bound of $\\Omega(1/k)$. A simple numerical experiment is presented to support our theory",
    "volume": "main",
    "checked": true,
    "id": "085e3dbc43a8a24f358fc659d435f82b043f5c54",
    "citation_count": 48
  },
  "https://proceedings.mlr.press/v125/kamath20a.html": {
    "title": "Private Mean Estimation of Heavy-Tailed Distributions",
    "abstract": "We give new upper and lower bounds on the minimax sample complexity of differentially private mean estimation of distributions with bounded $k$-th moments. Roughly speaking, in the univariate case, we show that $$n = \\Theta\\left(\\frac{1}{\\alpha^2} + \\frac{1}{\\alpha^{\\frac{k}{k-1}}\\varepsilon}\\right)$$ samples are necessary and sufficient to estimate the mean to $\\alpha$-accuracy under $\\varepsilon$-differential privacy, or any of its common relaxations. This result demonstrates a qualitatively different behavior compared to estimation absent privacy constraints, for which the sample complexity is identical for all $k \\geq 2$. We also give algorithms for the multivariate setting whose sample complexity is a factor of $O(d)$ larger than the univariate case",
    "volume": "main",
    "checked": true,
    "id": "32dcc4bb78bdb11563414e67357b44d2c33512af",
    "citation_count": 52
  },
  "https://proceedings.mlr.press/v125/kamath20b.html": {
    "title": "Approximate is Good Enough: Probabilistic Variants of Dimensional and Margin Complexity",
    "abstract": "We present and study approximate notions of dimensional and margin complexity, which correspond to the minimal dimension or norm of an embedding required to {\\em approximate}, rather then exactly represent, a given hypothesis class.  We show that such notions are not only sufficient for learning using linear predictors or a kernel, but unlike the exact variants, are also necessary. Thus they are better suited for discussing limitations of linear or kernel methods",
    "volume": "main",
    "checked": true,
    "id": "fff44932f8d962f5127bd0b8f73be0aa4bb39b28",
    "citation_count": 17
  },
  "https://proceedings.mlr.press/v125/kaplan20a.html": {
    "title": "Privately Learning Thresholds: Closing the Exponential Gap",
    "abstract": "We study the sample complexity of learning threshold functions under the constraint of differential privacy. It is assumed that each labeled example in the training data is the information of one individual and we would like to come up with a generalizing hypothesis $h$ while guaranteeing differential privacy for the individuals. Intuitively, this means that any single labeled example in the training data should not have a significant effect on the choice of the hypothesis. This problem has received much attention recently; unlike the non-private case, where the sample complexity is independent of the domain size and just depends on the desired accuracy and confidence, for private learning the sample complexity must depend on the domain size $X$ (even for approximate differential privacy). Alon et al. (STOC 2019) showed a lower bound of $\\Omega(\\log^*|X|)$  on the sample complexity and Bun et al. (FOCS 2015) presented an approximate-private learner with sample complexity $\\tilde{O}\\left(2^{\\log^*|X|}\\right)$. In this work we reduce this gap significantly, almost settling the sample complexity. We first present a new upper bound (algorithm) of $\\tilde{O}\\left(\\left(\\log^*|X|\\right)^2\\right)$ on the sample complexity  and then present an improved version with sample complexity $\\tilde{O}\\left(\\left(\\log^*|X|\\right)^{1.5}\\right)$. Our algorithm is constructed for the related interior point problem, where the goal is to find a point between the largest and smallest input elements. It is based on selecting an input-dependent hash function and using it to embed the database into a domain whose size is reduced logarithmically; this results in a new database, an interior point of which can be used to generate an interior point of the original database in a differentially private manner",
    "volume": "main",
    "checked": true,
    "id": "c764f5dc1c63f201e25c744601534bba5e60b360",
    "citation_count": 34
  },
  "https://proceedings.mlr.press/v125/kesselheim20a.html": {
    "title": "Online Learning with Vector Costs and Bandits with Knapsacks",
    "abstract": "We introduce online learning with vector costs ($OLVC_p$)  where in each time step $t \\in \\{1,\\ldots, T\\}$, we need to play an action $i \\in \\{1,\\ldots,n\\}$ that incurs an unknown vector cost in $[0,1]^d$. The goal of the online algorithm is to minimize the $\\ell_p$ norm of the sum of its cost vectors. This captures the classical online learning setting for $d=1$, and is interesting for general $d$ because of applications like online scheduling where we want to balance the load between different machines (dimensions). We study $OLVC_p$ in both stochastic and adversarial arrival settings, and give a general procedure to reduce the  problem from $d$ dimensions to  a single dimension. This allows us to use classical online learning algorithms in both full and bandit feedback models to obtain (near) optimal results. In particular, we obtain a single algorithm   (up to the choice of learning rate) that gives sublinear regret for stochastic arrivals and a tight $O(\\min\\{p, \\log d\\})$ competitive ratio for adversarial arrivals. The $OLVC_p$ problem also occurs as a natural subproblem when trying to solve the popular Bandits with Knapsacks (BWK) problem. This connection allows us to use our $OLVC_p$ techniques to obtain (near) optimal results for BWK in both stochastic and adversarial settings. In particular, we obtain a tight $O(\\log d \\cdot \\log T)$ competitive ratio algorithm for adversarial BWK, which improves over the $O(d \\cdot \\log T)$ competitive ratio algorithm  of Immorlica et al. (2019)",
    "volume": "main",
    "checked": true,
    "id": "10736299368ab9cae98e75cbcb25cf9fa2512dfe",
    "citation_count": 12
  },
  "https://proceedings.mlr.press/v125/kidger20a.html": {
    "title": "Universal Approximation with Deep Narrow Networks",
    "abstract": "The classical Universal Approximation Theorem holds for neural networks of arbitrary width and bounded depth. Here we consider the natural ‘dual’ scenario for networks of bounded width and arbitrary depth. Precisely, let $n$ be the number of inputs neurons, $m$ be the number of output neurons, and let $\\rho$ be any nonaffine continuous function, with a continuous nonzero derivative at some point. Then we show that the class of neural networks of arbitrary depth, width $n + m + 2$, and activation function $\\rho$, is dense in $C(K; \\mathbb{R}^m)$ for $K \\subseteq \\mathbb{R}^n$ with $K$ compact. This covers every activation function possible to use in practice, and also includes polynomial activation functions, which is unlike the classical version of the theorem, and provides a qualitative difference between deep narrow networks and shallow wide networks. We then consider several extensions of this result. In particular we consider nowhere differentiable activation functions, density in noncompact domains with respect to the $L^p$-norm, and how the width may be reduced to just $n + m + 1$ for ‘most’ activation functions",
    "volume": "main",
    "checked": true,
    "id": "dcfa6d2a1e09a388fc3c1db2a03a3a2916bd9b5b",
    "citation_count": 150
  },
  "https://proceedings.mlr.press/v125/kirschner20a.html": {
    "title": "Information Directed Sampling for Linear Partial Monitoring",
    "abstract": "Partial monitoring is a rich framework for sequential decision making under uncertainty that generalizes many well known bandit models, including linear, combinatorial  and dueling bandits. We introduce {\\em information directed sampling} (IDS) for stochastic partial monitoring with a linear reward and observation structure. IDS achieves adaptive worst-case regret rates that depend on precise observability conditions of the game. Moreover, we prove lower bounds that classify the minimax regret of all finite games into four possible regimes. IDS achieves the optimal rate in all cases  up to logarithmic factors, without tuning any hyper-parameters. We further extend our results to the contextual and the kernelized setting, which significantly increases the range of possible applications",
    "volume": "main",
    "checked": true,
    "id": "9cdc3e333e583df3c6059ba41efcffa7fcf2a28e",
    "citation_count": 26
  },
  "https://proceedings.mlr.press/v125/kobzar20a.html": {
    "title": "New Potential-Based Bounds for Prediction with Expert Advice",
    "abstract": "This work addresses the classic machine learning problem of online prediction with expert advice. We consider the finite-horizon version of this zero-sum, two-person game. Using verification  arguments  from optimal control theory, we view the task of finding  better lower and upper bounds on the value of the game (regret) as the problem of finding better sub- and supersolutions of certain partial differential equations (PDEs). These sub- and supersolutions serve as the potentials for player and adversary strategies, which lead to the corresponding bounds. To get explicit bounds, we use closed-form solutions of specific PDEs. Our bounds hold for any given number of experts and horizon; in certain regimes (which we identify) they improve upon the previous state of the art. For two and three experts, our bounds provide the optimal leading order term",
    "volume": "main",
    "checked": true,
    "id": "70367fe01dad27f8e4c6276d631db8c46ad2aeff",
    "citation_count": 17
  },
  "https://proceedings.mlr.press/v125/kur20a.html": {
    "title": "On Suboptimality of Least Squares with Application to Estimation of Convex Bodies",
    "abstract": "We develop a technique for establishing lower bounds on the sample complexity of Least Squares (or, Empirical Risk Minimization) for large classes of functions. As an application, we settle an open problem regarding optimality of Least Squares in estimating a convex set from noisy support function measurements in dimension $d\\geq 6$. Specifically, we establish that Least Squares is mimimax sub-optimal, and achieves a rate of $\\tilde{\\Theta}_d(n^{-2/(d-1)})$ whereas the minimax rate is $\\Theta_d(n^{-4/(d+3)})$",
    "volume": "main",
    "checked": true,
    "id": "7a22c6d8a31058de10c1b79510136c24a432bede",
    "citation_count": 6
  },
  "https://proceedings.mlr.press/v125/kwon20a.html": {
    "title": "The EM Algorithm gives Sample-Optimality for Learning Mixtures of Well-Separated Gaussians",
    "abstract": "We consider the problem of spherical Gaussian Mixture models with $k \\geq 3$ components when the components are well separated. A fundamental previous result established that separation of $\\Omega(\\sqrt{\\log k})$ is necessary and sufficient for identifiability of the parameters with \\textit{polynomial} sample complexity (Regev and Vijayaraghavan, 2017). In the same context, we show that $\\tilde{O} (kd/\\epsilon^2)$ samples suffice for any $\\epsilon \\lesssim 1/k$, closing the gap from polynomial to linear, and thus giving the first optimal sample upper bound for the parameter estimation of well-separated Gaussian mixtures. We accomplish this by proving a new result for the Expectation-Maximization (EM) algorithm: we show that EM converges locally, under separation $\\Omega(\\sqrt{\\log k})$. The previous best-known guarantee required $\\Omega(\\sqrt{k})$ separation (Yan, et al., 2017). Unlike prior work, our results do not assume or use prior knowledge of the (potentially different) mixing weights or variances of the Gaussian components. Furthermore, our results show that the finite-sample error of EM does not depend on non-universal quantities such as pairwise distances between means of Gaussian components",
    "volume": "main",
    "checked": true,
    "id": "73df1184a2a4b2f95c59396cf747a1870bf2f908",
    "citation_count": 15
  }
}