{
  "https://aclanthology.org/2024.naacl-long.1": {
    "title": "Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences",
    "volume": "long",
    "abstract": "Named entity recognition is a key component of Information Extraction (IE), particularly in scientific domains such as biomedicine and chemistry, where large language models (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of transfer learning for enhancing a named entity recognition model trained in the biomedical domain (the source domain) to be used in the chemical domain (the target domain). A common practice for training such a model in a few-shot learning setting is to pretrain the model on the labeled source data, and then, to finetune it on a hand-full of labeled target examples. In our experiments, we observed that such a model is prone to mislabeling the source entities, which can often appear in the text, as the target entities. To alleviate this problem, we propose a model to transfer the knowledge from the source domain to the target domain, but, at the same time, to project the source entities and target entities into separate regions of the feature space. This diminishes the risk of mislabeling the source entities as the target entities. Our model consists of two stages: 1) entity grouping in the source domain, which incorporates knowledge from annotated events to establish relations between entities, and 2) entity discrimination in the target domain, which relies on pseudo labeling and contrastive learning to enhance discrimination between the entities in the two domains. We conduct our extensive experiments across three source and three target datasets, demonstrating that our method outperforms the baselines by up to 5% absolute value. Code, data, and resources are publicly available for research purposes: https://github.com/Lhtie/Bio-Domain-Transfer",
    "checked": true,
    "id": "676fcd2ca5419fa17251230abaef84ec70618e94",
    "semantic_title": "named entity recognition under domain shift via metric learning for life sciences",
    "citation_count": 0,
    "authors": [
      "Hongyi Liu",
      "Qingyun Wang",
      "Payam Karisani",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.2": {
    "title": "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
    "volume": "long",
    "abstract": "The diffusion model, a new generative modeling paradigm, has achieved great success in image, audio, and video generation.However, considering the discrete categorical nature of the text, it is not trivial to extend continuous diffusion models to natural language. In this work, we propose SeqDiffuSeq, a text diffusion model, to approach sequence-to-sequence text generation with an encoder-decoder Transformer architecture.To improve the generation performance, SeqDiffuSeq is equipped with the self-conditioning technique and our newly proposed adaptive noise schedule technique. Self-conditioning enables SeqDiffuSeq to better use the predicted sequence information during the generation process.The adaptive noise schedule balances the difficulty of denoising across time steps at the token level.Experiment results illustrate the improved performance on five sequence-to-sequence generation tasks compared to other diffusion-based models regarding text quality and inference time",
    "checked": true,
    "id": "47e40c4c8d291f6d326ccef7313aba7d98dbf283",
    "semantic_title": "text diffusion model with encoder-decoder transformers for sequence-to-sequence generation",
    "citation_count": 0,
    "authors": [
      "Hongyi Yuan",
      "Zheng Yuan",
      "Chuanqi Tan",
      "Fei Huang",
      "Songfang Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.3": {
    "title": "An Interactive Framework for Profiling News Media Sources",
    "volume": "long",
    "abstract": "The recent rise of social media has led to the spread of large amounts of fake and biased news, content published with the intent to sway beliefs. While detecting and profiling the sources that spread this news is important to maintain a healthy society, it is challenging for automated systems.In this paper, we propose an interactive framework for news media profiling. It combines the strengths of graph based news media profiling models, Pre-trained Large Language Models, and human insight to characterize the social context on social media. Experimental results show that with as little as 5 human interactions, our framework can rapidly detect fake and biased news media, even in the most challenging settings of emerging news events, where test data is unseen",
    "checked": true,
    "id": "7adc93b4e1423fbe092e5ded2b932d27b376f8c7",
    "semantic_title": "an interactive framework for profiling news media sources",
    "citation_count": 1,
    "authors": [
      "Nikhil Mehta",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.4": {
    "title": "Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown remarkable proficiency in language understanding and have been successfully applied to a variety of real-world tasks through task-specific fine-tuning or prompt engineering. Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data. In our research, we introduce a novel task—Minesweeper—specifically designed in a format unfamiliar to LLMs and absent from their training datasets. This task challenges LLMs to identify the locations of mines based on numerical clues provided by adjacent opened cells. Successfully completing this task requires an understanding of each cell's state, discerning spatial relationships between the clues and mines, and strategizing actions based on logical deductions drawn from the arrangement of the cells. Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent, multi-step logical reasoning process needed to solve Minesweeper. These findings highlight the need for further research to understand the nature of reasoning capabilities in LLMs under similar circumstances, and to explore pathways towards more sophisticated AI reasoning and planning models",
    "checked": true,
    "id": "00ac2b2f4a991c798be54b96b35f520a7fe8e64d",
    "semantic_title": "assessing logical puzzle solving in large language models: insights from a minesweeper case study",
    "citation_count": 4,
    "authors": [
      "Yinghao Li",
      "Haorui Wang",
      "Chao Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.5": {
    "title": "TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation",
    "volume": "long",
    "abstract": "Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue sys- tems to effectively respond to user requests. The emotions in a conversation can be identi- fied by the representations from various modal- ities, such as audio, visual, and text. How- ever, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a lan- guage model acting as the teacher to the non- verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multi- modal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effec- tiveness of our components through additional experiments",
    "checked": true,
    "id": "fc47b02c2df4fba11dc8355c46455d6100a92cb1",
    "semantic_title": "telme: teacher-leading multimodal fusion network for emotion recognition in conversation",
    "citation_count": 0,
    "authors": [
      "Taeyang Yun",
      "Hyunkuk Lim",
      "Jeonghwan Lee",
      "Min Song"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.6": {
    "title": "Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries",
    "volume": "long",
    "abstract": "Few-shot dialogue state tracking (DST) with Large Language Models (LLM) relies on an effective and efficient conversation retriever to find similar in-context examples for prompt learning. Previous works use raw dialogue context as search keys and queries, and a retriever is fine-tuned with annotated dialogues to achieve superior performance. However, the approach is less suited for scaling to new domains or new annotation languages, where fine-tuning data is unavailable. To address this problem, we handle the task of conversation retrieval based on text summaries of the conversations.A LLM-based conversation summarizer is adopted for query and key generation, which enables effective maximum inner product search. To avoid the extra inference cost brought by LLM-based conversation summarization, we further distill a light-weight conversation encoder which produces query embeddings without decoding summaries for test conversations. We validate our retrieval approach on MultiWOZ datasets with GPT-Neo-2.7B and LLaMA-7B/30B. The experimental results show a significant improvement over relevant baselines in real few-shot DST settings",
    "checked": true,
    "id": "59de4703ca458ed416fbf9aa7219658e94aef9bc",
    "semantic_title": "effective and efficient conversation retrieval for dialogue state tracking with implicit text summaries",
    "citation_count": 0,
    "authors": [
      "Seanie Lee",
      "Jianpeng Cheng",
      "Joris Driesen",
      "Alexandru Coca",
      "Anders Johannsen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.7": {
    "title": "Promptly Predicting Structures: The Return of Inference",
    "volume": "long",
    "abstract": "Prompt-based methods have been used extensively across NLP to build zero- and few-shot label predictors. Many NLP tasks are naturally structured: that is, their outputs consist of multiple labels which constrain each other. Annotating data for such tasks can be cumbersome. Can the promise of the prompt-based paradigm be extended to such structured outputs? In this paper, we present a framework for constructing zero- and few-shot linguistic structure predictors. Our key insight is that we can use structural constraints—and combinatorial inference derived from them—to filter out inconsistent structures predicted by large language models. We instantiated this framework on two structured prediction tasks, and five datasets. Across all cases, our results show that enforcing consistency not only constructs structurally valid outputs, but also improves performance over the unconstrained variants",
    "checked": true,
    "id": "27494f35c4e3f31c5fb9e18ad289144ec0532373",
    "semantic_title": "promptly predicting structures: the return of inference",
    "citation_count": 2,
    "authors": [
      "Maitrey Mehta",
      "Valentina Pyatkin",
      "Vivek Srikumar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.8": {
    "title": "On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL",
    "volume": "long",
    "abstract": "Structured data, prevalent in tables, databases, and knowledge graphs, poses a significant challenge in its representation. With the advent of large language models (LLMs), there has been a shift towards linearization-based methods, which process structured data as sequential token streams, diverging from approaches that explicitly model structure, often as a graph. Crucially, there remains a gap in our understanding of how these linearization-based methods handle structured data, which is inherently non-linear.This work investigates the linear handling of structured data in encoder-decoder language models, specifically T5. Our findings reveal the model's ability to mimic human-designed processes such as schema linking and syntax prediction, indicating a deep, meaningful learning of structure beyond simple token sequencing. We also uncover insights into the model's internal mechanisms, including the ego-centric nature of structure node encodings and the potential for model compression due to modality fusion redundancy. Overall, this work sheds light on the inner workings of linearization-based methods and could potentially provide guidance for future research",
    "checked": true,
    "id": "80239c45d67d7616cc341c16e5cbd456eccca302",
    "semantic_title": "on linearizing structured data in encoder-decoder language models: insights from text-to-sql",
    "citation_count": 0,
    "authors": [
      "Yutong Shao",
      "Ndapa Nakashole"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.9": {
    "title": "Extractive Summarization with Text Generator",
    "volume": "long",
    "abstract": "Standard extractive systems suffer from the lack of gold training signals since existing corpora solely provide document and human-written summary pairs while disregarding extractive labels. As a result, existing methods resort to imperfect pseudo-labels that are both biased and error-prone, thereby hindering the learning process of extractive models. In contrast, text generators which are commonly employed in abstractive summarization can effortlessly overcome this predicament on account of flexible sequence-to-sequence architectures. Motivated to bypass this inherent limitation, we investigate the possibility of conducting extractive summarization with text generators. Through extensive experiments covering six summarization benchmarks, we show that high-quality extractive summaries can be assembled via approximating the outputs (abstractive summaries) of these generators. Moreover, we find that the approximate summaries correlate positively with the auxiliary summaries (i.e. a better generator enables the production of better extractive summaries). Our results signify a new paradigm for training extractive summarizers i.e. learning with generation (abstractive) objectives rather than extractive schemes",
    "checked": true,
    "id": "3f39e703f522f45d6b3de76a7d373679826602d6",
    "semantic_title": "extractive summarization with text generator",
    "citation_count": 0,
    "authors": [
      "Thang Le",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.10": {
    "title": "Self-generated Replay Memories for Continual Neural Machine Translation",
    "volume": "long",
    "abstract": "Modern Neural Machine Translation systems exhibit strong performance in several different languages and are constantly improving. Their ability to learn continuously is, however, still severely limited by the catastrophic forgetting issue. In this work, we leverage a key property of encoder-decoder Transformers, i.e. their generative ability, to propose a novel approach to continually learning Neural Machine Translation systems. We show how this can effectively learn on a stream of experiences comprising different languages, by leveraging a replay memory populated by using the model itself as a generator of parallel sentences. We empirically demonstrate that our approach can counteract catastrophic forgetting without requiring explicit memorization of training data. Code will be publicly available upon publication",
    "checked": true,
    "id": "dc368b5bc1887574291380ed66c8c42b77d199e3",
    "semantic_title": "self-generated replay memories for continual neural machine translation",
    "citation_count": 0,
    "authors": [
      "Michele Resta",
      "Davide Bacciu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.11": {
    "title": "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models",
    "volume": "long",
    "abstract": "Vision-language models (VLMs) have recently demonstrated strong efficacy as visual assistants that can parse natural queries about the visual content and generate human-like outputs. In this work, we explore the ability of these models to demonstrate human-like reasoning based on the perceived information. To address a crucial concern regarding the extent to which their reasoning capabilities are fully consistent and grounded, we also measure the reasoning consistency of these models. We achieve this by proposing a chain-of-thought (CoT) based consistency measure. However, such an evaluation requires a benchmark that encompasses both high-level inference and detailed reasoning chains, which is costly. We tackle this challenge by proposing an LLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously ensuring the generation of a high-quality dataset. Based on this pipeline and the existing coarse-grained annotated dataset, we build the CURE benchmark to measure both the zero-shot reasoning performance and consistency of VLMs. We evaluate existing state-of-the-art VLMs, and find that even the best-performing model is unable to demonstrate strong visual reasoning capabilities and consistency, indicating that substantial efforts are required to enable VLMs to perform visual reasoning as systematically and consistently as humans. As an early step, we propose a two-stage training framework aimed at improving both the reasoning performance and consistency of VLMs. The first stage involves employing supervised fine-tuning of VLMs using step-by-step reasoning samples automatically generated by LLMs. In the second stage, we further augment the training process by incorporating feedback provided by LLMs to produce reasoning chains that are highly consistent and grounded. We empirically highlight the effectiveness of our framework in both reasoning performance and consistency",
    "checked": true,
    "id": "280353fd7a7a3e49c415c443e1b7ccf7de9c2b4e",
    "semantic_title": "measuring and improving chain-of-thought reasoning in vision-language models",
    "citation_count": 9,
    "authors": [
      "Yangyi Chen",
      "Karan Sikka",
      "Michael Cogswell",
      "Heng Ji",
      "Ajay Divakaran"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.12": {
    "title": "Building Knowledge-Guided Lexica to Model Cultural Variation",
    "volume": "long",
    "abstract": "Cultural variation exists between nations (e.g., the United States vs. China), but also within regions (e.g., California vs. Texas, Los Angeles vs. San Francisco). Measuring this regional cultural variation can illuminate how and why people think and behave differently. Historically, it has been difficult to computationally model cultural variation due to a lack of training data and scalability constraints. In this work, we introduce a new research problem for the NLP community: How do we measure variation in cultural constructs across regions using language? We then provide a scalable solution: building knowledge-guided lexica to model cultural variation, encouraging future work at the intersection of NLP and cultural understanding. We also highlight modern LLMs' failure to measure cultural variation or generate culturally varied language",
    "checked": true,
    "id": "a67c8f49509e81656651a221bac5b1b87a6291f5",
    "semantic_title": "building knowledge-guided lexica to model cultural variation",
    "citation_count": 0,
    "authors": [
      "Shreya Havaldar",
      "Salvatore Giorgi",
      "Sunny Rai",
      "Thomas Talhelm",
      "Sharath Chandra Guntuku",
      "Lyle Ungar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.13": {
    "title": "Adaptive Rank Selections for Low-Rank Approximation of Language Models",
    "volume": "long",
    "abstract": "Singular Value Decomposition (SVD) or its weighted variants has significantly progressed in compressing language models. Previous works assume the same importance for all operations and assign the same number of ranks for different layers in a language model. However, such a uniform rank selection is sub-optimal since different operations (layers) have non-uniform demand in capacity. In other words, a desired SVD strategy should allocate more ranks for important operations and vice versa. However, a globally-optimized selection of ranks for neural networks is still an open problem, and this is a non-trivial challenge since the selection is discrete. In this work, we propose a novel binary masking mechanism for optimizing the number of ranks in a differentiable framework. Our strategy uses a novel regularization to enable the masking to comply with the SVD property where the ranks have sorted singular values. The experiments examined both types of language models, encoder-only and decoder-only models, including large language models like LLaMA. Our compressed model achieves much better accuracy than previous SVD and their SOTA variants. More interestingly, our method retains significantly better accuracy with zero or limited fine-tuning, proving the substantial advantage of adaptive rank selection",
    "checked": true,
    "id": "01cbb338f1acbdc94e5425b811ae6df0737baac6",
    "semantic_title": "adaptive rank selections for low-rank approximation of language models",
    "citation_count": 0,
    "authors": [
      "Shangqian Gao",
      "Ting Hua",
      "Yen-Chang Hsu",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.14": {
    "title": "An Empirical Study of Consistency Regularization for End-to-End Speech-to-Text Translation",
    "volume": "long",
    "abstract": "Consistency regularization methods, such as R-Drop (Liang et al., 2021) and CrossConST (Gao et al., 2023), have achieved impressive supervised and zero-shot performance in the neural machine translation (NMT) field. Can we also boost end-to-end (E2E) speech-to-text translation (ST) by leveraging consistency regularization? In this paper, we conduct empirical studies on intra-modal and cross-modal consistency and propose two training strategies, SimRegCR and SimZeroCR, for E2E ST in regular and zero-shot scenarios. Experiments on the MuST-C benchmark show that our approaches achieve state-of-the-art (SOTA) performance in most translation directions. The analyses prove that regularization brought by the intra-modal consistency, instead of the modality gap, is crucial for the regular E2E ST, and the cross-modal consistency could close the modality gap and boost the zero-shot E2E ST performance",
    "checked": true,
    "id": "486aa9501bf3a42a7c5c8871f92e6285408d1d46",
    "semantic_title": "an empirical study of consistency regularization for end-to-end speech-to-text translation",
    "citation_count": 1,
    "authors": [
      "Pengzhi Gao",
      "Ruiqing Zhang",
      "Zhongjun He",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.15": {
    "title": "Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
    "volume": "long",
    "abstract": "Human intelligence thrives on cognitive synergy, where collaboration among different minds yield superior outcomes compared to isolated individuals. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist is an intelligent agent that collaboratively combines multiple minds' strengths and knowledge to enhance problem-solving in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. Our in-depth analysis shows that assigning multiple fine-grained personas in LLMs improves problem-solving abilities compared to using a single or fixed number of personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledge-intensive and reasoning-intensive types. Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, experimental results demonstrate that SPP effectively reduces factual hallucination, and maintains strong reasoning capabilities. Additionally, comparative experiments show that cognitive synergy only emerges in GPT-4 and does not appear in less capable models, such as GPT-3.5-turbo and Llama2-13b-chat, which draws an interesting analogy to human development. Code, data, and prompts can be found at: https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git",
    "checked": true,
    "id": "434b9f9bc71c935e4a46a1aff36a8cc4c22d9afa",
    "semantic_title": "unleashing the emergent cognitive synergy in large language models: a task-solving agent through multi-persona self-collaboration",
    "citation_count": 43,
    "authors": [
      "Zhenhailong Wang",
      "Shaoguang Mao",
      "Wenshan Wu",
      "Tao Ge",
      "Furu Wei",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.16": {
    "title": "FPT: Feature Prompt Tuning for Few-shot Readability Assessment",
    "volume": "long",
    "abstract": "Prompt-based methods have achieved promising results in most few-shot text classification tasks. However, for readability assessment tasks, traditional prompt methods lack crucial linguistic knowledge, which has already been proven to be essential.Moreover, previous studies on utilizing linguistic features have shown non-robust performance in few-shot settings and may even impair model performance.To address these issues, we propose a novel prompt-based tuning framework that incorporates rich linguistic knowledge, called Feature Prompt Tuning (FPT). Specifically, we extract linguistic features from the text and embed them into trainable soft prompts. Further, we devise a new loss function to calibrate the similarity ranking order between categories. Experimental results demonstrate that our proposed method FTPnot only exhibits a significant performance improvement over the prior best prompt-based tuning approaches, but also surpasses the previous leading methods that incorporate linguistic features. Also, our proposed model significantly outperforms the large language model gpt-3.5-turbo-16k in most cases. Our proposed method establishes a new architecture for prompt tuning that sheds light on how linguistic features can be easily adapted to linguistic-related tasks",
    "checked": true,
    "id": "e51b19f1465e9ddbfd3883696ad49dcf2bc671b2",
    "semantic_title": "fpt: feature prompt tuning for few-shot readability assessment",
    "citation_count": 0,
    "authors": [
      "Ziyang Wang",
      "Sanwoo Lee",
      "Hsiu-Yuan Huang",
      "Yunfang Wu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.17": {
    "title": "Self-Prompting Large Language Models for Zero-Shot Open-Domain QA",
    "volume": "long",
    "abstract": "Open-Domain Question Answering (ODQA) aims to answer questions without explicitly providing specific background documents. This task becomes notably challenging in a zero-shot setting where no data is available to train tailored retrieval-reader models.While recent Large Language Models (LLMs) like GPT-3 have demonstrated their effectiveness in zero-shot ODQA using direct prompting methods, these methods still fall short of fully harnessing the potential of LLMs when implicitly invoked.In this paper, we propose a Self-Prompting framework to explicitly utilize the massive knowledge encoded in the parameters of LLMs and their strong instruction understanding abilities. Concretely, we prompt LLMs step by step to generate multiple pseudo QA pairs with background passages and explanations entirely from scratch.These generated elements are then utilized for in-context learning. Experimental results show that our method significantly surpasses previous state-of-the-art zero-shot methods on three widely-used ODQA datasets and even achieves comparable performance with various customized fine-tuned models on full training data. Our code is available at https://github.com/lockon-n/self-prompting",
    "checked": true,
    "id": "9cd329e3b86e6869e73a91c467459b1947655b07",
    "semantic_title": "self-prompting large language models for zero-shot open-domain qa",
    "citation_count": 12,
    "authors": [
      "Junlong Li",
      "Jinyuan Wang",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.18": {
    "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?",
    "volume": "long",
    "abstract": "Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, we try to answer these questions from a new angle: How knowledgeable are LLMs?To answer this question, we constructed Head-to-Tail, a benchmark that consists of 18K question-answer (QA) pairs regarding head, torso, and tail facts in terms of popularity. We designed an automated evaluation method and a set of metrics that closely approximate the knowledge an LLM confidently internalizes. Through a comprehensive evaluation of 16 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities",
    "checked": true,
    "id": "fb00016c1e048b9373803add001c1ec7e877cb23",
    "semantic_title": "head-to-tail: how knowledgeable are large language models (llms)? a.k.a. will llms replace knowledge graphs?",
    "citation_count": 66,
    "authors": [
      "Kai Sun",
      "Yifan Xu",
      "Hanwen Zha",
      "Yue Liu",
      "Xin Luna Dong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.19": {
    "title": "kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning",
    "volume": "long",
    "abstract": "Task-Oriented Parsing (TOP) enables conversational assistants to interpret user commands expressed in natural language, transforming them into structured outputs that combine elements of both natural language and intent/slot tags. Recently, Large Language Models (LLMs) have achieved impressive performance in synthesizing computer programs based on a natural-language prompt, mitigating the gap between natural language and structured programs. Our paper focuses on harnessing the capabilities of LLMs for semantic parsing tasks, addressing the following three key research questions: 1) How can LLMs be effectively utilized for semantic parsing tasks? 2) What defines an effective prompt? and 3) How can LLM overcome the length constraint and streamline prompt design by including all examples as prompts? We introduce k Nearest Neighbor In-Context Learning (kNN-ICL), which simplifies prompt engineering by allowing it to be built on top of any design strategy while providing access to all demo examples. Extensive experiments show that: 1) Simple ICL without kNN search can achieve a comparable performance with strong supervised models on the TOP tasks, and 2) kNN-ICL significantly improves the comprehension of complex requests by seamlessly integrating ICL with a nearest-neighbor approach. Notably, this enhancement is achieved without the need for additional data or specialized prompts",
    "checked": true,
    "id": "218a9c9f836e31be1e71ba50728d24a478ebcddd",
    "semantic_title": "knn-icl: compositional task-oriented parsing generalization with nearest neighbor in-context learning",
    "citation_count": 5,
    "authors": [
      "Wenting Zhao",
      "Ye Liu",
      "Yao Wan",
      "Yibo Wang",
      "Qingyang Wu",
      "Zhongfen Deng",
      "Jiangshu Du",
      "Shuaiqi Liu",
      "Yunlong Xu",
      "Philip Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.20": {
    "title": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
    "volume": "long",
    "abstract": "Evaluating retrieval-augmented generation (RAG) systems traditionally relies on hand annotations for input queries, passages to retrieve, and responses to generate. We introduce ARES, an Automated RAG Evaluation System, for evaluating RAG systems along the dimensions of context relevance, answer faithfulness, and answer relevance. By creating its own synthetic training data, ARES finetunes lightweight LM judges to assess the quality of individual RAG components. To mitigate potential prediction errors, ARES utilizes a small set of human-annotated datapoints for prediction-powered inference (PPI). Across eight different knowledge-intensive tasks in KILT, SuperGLUE, and AIS, ARES accurately evaluates RAG systems while using only a few hundred human annotations during evaluation. Furthermore, ARES judges remain effective across domain shifts, proving accurate even after changing the type of queries and/or documents used in the evaluated RAG systems. We make our code and datasets publicly available on Github",
    "checked": true,
    "id": "4df2b1e7d54fe5ad81dc2ed6774b93ef7891b3c8",
    "semantic_title": "ares: an automated evaluation framework for retrieval-augmented generation systems",
    "citation_count": 27,
    "authors": [
      "Jon Saad-Falcon",
      "Omar Khattab",
      "Christopher Potts",
      "Matei Zaharia"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.21": {
    "title": "DEMO: A Statistical Perspective for Efficient Image-Text Matching",
    "volume": "long",
    "abstract": "Image-text matching has been a long-standing problem, which seeks to connect vision and language through semantic understanding. Due to the capability to manage large-scale raw data, unsupervised hashing-based approaches have gained prominence recently. They typically construct a semantic similarity structure using the natural distance, which subsequently guides the optimization of the hashing network. However, the similarity structure could be biased at the boundaries of semantic distributions, causing error accumulation during sequential optimization. To tackle this, we introduce a novel hashing approach termed Distribution-based Structure Mining with Consistency Learning (DEMO) for efficient image-text matching. From a statistical view, DEMO characterizes each image using multiple augmented views, which are considered as samples drawn from its intrinsic semantic distribution. Then, we employ a non-parametric distribution divergence to ensure a robust and precise similarity structure. In addition, we introduce collaborative consistency learning which not only preserves the similarity structure in the Hamming space but also encourages consistency between retrieval distribution from different directions in a self-supervised manner. Extensive experiments on several widely used datasets demonstrate that DEMO achieves superior performance compared with various state-of-the-art methods",
    "checked": true,
    "id": "fc10ef4c76b4eeb82f48b3ea58875b40fbf6ec4e",
    "semantic_title": "demo: a statistical perspective for efficient image-text matching",
    "citation_count": 0,
    "authors": [
      "Fan Zhang",
      "Xian-Sheng Hua",
      "Chong Chen",
      "Xiao Luo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.22": {
    "title": "SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning",
    "volume": "long",
    "abstract": "We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Many models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingually-trained models have not attained \"balanced multilingual\" capabilities. Our endeavors underscore the need for more generalizable semantic representations and enhanced multilingual contextualization. SeaEval can serve as a launchpad for more thorough investigations and evaluations for multilingual and multicultural scenarios",
    "checked": true,
    "id": "05be16afbd1dec2f5dad0949686c3fbe9d44f466",
    "semantic_title": "seaeval for multilingual foundation models: from cross-lingual alignment to cultural reasoning",
    "citation_count": 27,
    "authors": [
      "Bin Wang",
      "Zhengyuan Liu",
      "Xin Huang",
      "Fangkai Jiao",
      "Yang Ding",
      "AiTi Aw",
      "Nancy Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.23": {
    "title": "Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision",
    "volume": "long",
    "abstract": "Large multimodal models suffer from multimodal hallucination, where they provide incorrect responses misaligned with the given visual information. Recent works have conjectured that one of the reasons behind multimodal hallucination is due to the vision encoder failing to ground on the image properly. To mitigate this issue, we propose a novel approach that leverages self-feedback as visual cues. Building on this approach, we introduce Volcano, a multimodal self-feedback guided revision model. Volcano generates natural language feedback to its initial response based on the provided visual information and utilizes this feedback to self-revise its initial response. Volcano effectively reduces multimodal hallucination and achieves state-of-the-art on MMHal-Bench, POPE, and GAVIE. It also improves on general multimodal abilities and outperforms previous models on MM-Vet and MMBench. Through qualitative analysis, we show that Volcano's feedback is properly grounded on the image than the initial response. This indicates that Volcano can provide itself with richer visual information through feedback generation, leading to self-correct hallucinations. We publicly release our model, data, and code at https://github.com/kaistAI/Volcanogithub.com/kaistAI/Volcano",
    "checked": true,
    "id": "de1894742b7f2e4fe02d9ff94761d6178e0a5d3c",
    "semantic_title": "volcano: mitigating multimodal hallucination through self-feedback guided revision",
    "citation_count": 13,
    "authors": [
      "Seongyun Lee",
      "Sue Park",
      "Yongrae Jo",
      "Minjoon Seo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.24": {
    "title": "LLMs Are Few-Shot In-Context Low-Resource Language Learners",
    "volume": "long",
    "abstract": "In-context learning (ICL) empowers large language models (LLMs) to perform diverse tasks in underrepresented languages using only short in-context information, offering a crucial avenue for narrowing the gap between high-resource and low-resource languages.Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish. In this work, we extensively study ICL and its cross-lingual variation (X-ICL) on 25 low-resource and 7 relatively higher-resource languages.Our study not only assesses the effectiveness of ICL with LLMs in low-resource languages but also identifies the shortcomings of in-context label alignment, and introduces a more effective alternative: query alignment. Moreover, we provide valuable insights into various facets of ICL for low-resource languages.Our study concludes the significance of few-shot in-context information on enhancing the low-resource understanding quality of LLMs through semantically relevant information by closing the language gap in the target language and aligning the semantics between the targeted low-resource and the high-resource language that the model is proficient in. Our work highlights the importance of advancing ICL research, particularly for low-resource languages",
    "checked": true,
    "id": "4c01dfec69f5d55daae00b668665e94eb9da7f39",
    "semantic_title": "llms are few-shot in-context low-resource language learners",
    "citation_count": 4,
    "authors": [
      "Samuel Cahyawijaya",
      "Holy Lovenia",
      "Pascale Fung"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.25": {
    "title": "Simple and effective data augmentation for compositional generalization",
    "volume": "long",
    "abstract": "Compositional generalization, the ability to predict complex meanings from training on simpler sentences, poses challenges for powerful pretrained seq2seq models. In this paper, we show that data augmentation methods that sample MRs and backtranslate them can be effective for compositional generalization, but only if we sample from the right distribution. Remarkably, sampling from a uniform distribution performs almost as well as sampling from the test distribution, and greatly outperforms earlier methods that sampled from the training distribution.We further conduct experiments to investigate the reason why this happens and where the benefit of such data augmentation methods come from",
    "checked": false,
    "id": "73a7772f3cc4bd0986637ef6479789be4799a8c5",
    "semantic_title": "exploiting transformation invariance and equivariance for self-supervised sound localisation",
    "citation_count": 20,
    "authors": [
      "Yuekun Yao",
      "Alexander Koller"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.26": {
    "title": "Rethinking Tabular Data Understanding with Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown to be capable of various tasks, yet their capability in interpreting and reasoning over tabular data remains an underexplored area. In this context, this study investigates from three core perspectives: the robustness of LLMs to structural perturbations in tables, the comparative analysis of textual and symbolic reasoning on tables, and the potential of boosting model performance through the aggregation of multiple reasoning pathways. We discover that structural variance of tables presenting the same content reveals a notable performance decline, particularly in symbolic reasoning tasks. This prompts the proposal of a method for table structure normalization. Moreover, textual reasoning slightly edges out symbolic reasoning, and a detailed error analysis reveals that each exhibits different strengths depending on the specific tasks. Notably, the aggregation of textual and symbolic reasoning pathways, bolstered by a mix self-consistency mechanism, resulted in achieving SOTA performance, with an accuracy of 73.6% on WikiTableQuestions, representing a substantial advancement over previous existing table processing paradigms of LLMs",
    "checked": true,
    "id": "60f35bfe967dbce2c8694de8d283de01cc3766c2",
    "semantic_title": "rethinking tabular data understanding with large language models",
    "citation_count": 1,
    "authors": [
      "Tianyang Liu",
      "Fei Wang",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.27": {
    "title": "From Shortcuts to Triggers: Backdoor Defense with Denoised PoE",
    "volume": "long",
    "abstract": "Language models are often at risk of diverse backdoor attacks, especially data poisoning. Thus, it is important to investigate defense solutions for addressing them. Existing backdoor defense methods mainly focus on backdoor attacks with explicit triggers, leaving a universal defense against various backdoor attacks with diverse triggers largely unexplored. In this paper, we propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised Product-of-Experts), which is inspired by the shortcut nature of backdoor attacks, to defend various backdoor attacks. DPoE consists of two models: a shallow model that captures the backdoor shortcuts and a main model that is prevented from learning the shortcuts. To address the label flip caused by backdoor attackers, DPoE incorporates a denoising design. Experiments on three NLP tasks show that DPoE significantly improves the defense performance against various types of backdoor triggers including word-level, sentence-level, and syntactic triggers. Furthermore, DPoE is also effective under a more challenging but practical setting that mixes multiple types of triggers",
    "checked": true,
    "id": "7264958c138579270ae79487985d5ac3b199f715",
    "semantic_title": "from shortcuts to triggers: backdoor defense with denoised poe",
    "citation_count": 10,
    "authors": [
      "Qin Liu",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.28": {
    "title": "BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain",
    "volume": "long",
    "abstract": "Several large-scale datasets (e.g., WikiSQL, Spider) for developing natural language interfaces to databases have recently been proposed. These datasets cover a wide breadth of domains but fall short on some essential domains, such as finance and accounting. Given that accounting databases are used worldwide, particularly by non-technical people, there is an imminent need to develop models that could help extract information from accounting databases via natural language queries. In this resource paper, we aim to fill this gap by proposing a new large-scale Text-to-SQL dataset for the accounting and financial domain: BookSQL. The dataset consists of 100k natural language queries-SQL pairs, and accounting databases of 1 million records. We experiment with and analyze existing state-of-the-art models (including GPT-4) for the Text-to-SQL task on BookSQL. We find significant performance gaps, thus pointing towards developing more focused models for this domain",
    "checked": true,
    "id": "dc21a83c0b1c8002065b18ef2f90c7e53d9d1a17",
    "semantic_title": "booksql: a large scale text-to-sql dataset for accounting domain",
    "citation_count": 0,
    "authors": [
      "Rahul Kumar",
      "Amar Raja Dibbu",
      "Shrutendra Harsola",
      "Vignesh Subrahmaniam",
      "Ashutosh Modi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.29": {
    "title": "FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs",
    "volume": "long",
    "abstract": "Planning is a crucial task for agents in task oriented dialogs (TODs). Human agents typically resolve user issues by following predefined workflows, decomposing workflow steps into actionable items, and performing actions by executing APIs in order; all of which require reasoning and planning. With the recent advances in LLMs, there have been increasing attempts to use them for task planning and API usage. However, the faithfulness of the plans to predefined workflows and API dependencies, is not guaranteed with LLMs. Moreover, workflows in real life are often custom-defined and prone to changes; hence, adaptation is desirable. To study this, we propose the problem of faithful planning in TODs that needs to resolve user intents by following predefined flows and preserving API dependencies. To solve this problem, we propose FLAP, a Flow-Adhering Planning algorithm based on constrained decoding with lookahead heuristic for LLMs. Our algorithm alleviates the need for finetuning LLMs using domain specific (plan/dependency) data, enables quick adaptation to predefined flows, and outperforms other decoding and prompting-based baselines. Further, our algorithm empowers smaller LLMs (≈7B) to perform at par larger LLMs (≈30B-40B)",
    "checked": true,
    "id": "3d6300263adb1a1e8000fd0eda55518a3642afa9",
    "semantic_title": "flap: flow-adhering planning with constrained decoding in llms",
    "citation_count": 2,
    "authors": [
      "Shamik Roy",
      "Sailik Sengupta",
      "Daniele Bonadiman",
      "Saab Mansour",
      "Arshit Gupta"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.30": {
    "title": "DuRE: Dual Contrastive Self Training for Semi-Supervised Relation Extraction",
    "volume": "long",
    "abstract": "Document-level Relation Extraction (RE) aims to extract relation triples from documents. Existing document-RE models typically rely on supervised learning which requires substantial labeled data. To alleviate the amount of human supervision, Self-training (ST) has prospered again in language understanding by augmenting the fine-tuning of big pre-trained models whenever labeled data is insufficient. However, existing ST methods in RE fail to tackle the challenge of long-tail relations. In this work, we propose DuRE, a novel ST framework to tackle these problems. DuRE jointly models RE classification and text generation as a dual process. In this way, our model could construct and utilize both pseudo text generated from given labels and pseudo labels predicted from available unlabeled text, which are gradually refined during the ST phase. We proposed a contrastive loss to leverage the signal of the RE classifier to improve generation quality. In addition, we propose a self-adaptive way to sample pseudo text from different relation classes. Experiments on two document-level RE tasks show that DuRE significantly boosts recall and F1 score with comparable precision, especially for long-tail relations against several strong baselines",
    "checked": true,
    "id": "df7bcd2a81f93ed29a65b3ecd8179b8ef3171803",
    "semantic_title": "dure: dual contrastive self training for semi-supervised relation extraction",
    "citation_count": 0,
    "authors": [
      "Yuxi Feng",
      "Laks Lakshmanan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.31": {
    "title": "Query-Efficient Textual Adversarial Example Generation for Black-Box Attacks",
    "volume": "long",
    "abstract": "Deep neural networks for Natural Language Processing (NLP) have been demonstrated to be vulnerable to textual adversarial examples. Existing black-box attacks typically require thousands of queries on the target model, making them expensive in real-world applications. In this paper, we propose a new approach that guides the word substitutions using prior knowledge from the training set to improve the attack efficiency. Specifically, we introduce Adversarial Boosting Preference (ABP), a metric that quantifies the importance of words and guides adversarial word substitutions. We then propose two query-efficient attack strategies based on ABP: query-free attack (ABPfree) and guided search attack (ABPguide). Extensive evaluations for text classification demonstrate that ABPfree generates more natural adversarial examples than existing universal attacks, ABPguide significantly reduces the number of queries by a factor of 10 500 while achieving comparable or even better performance than black-box attack baselines. Furthermore, we introduce the first ensemble attack ABPens in NLP, which gains further performance improvements and achieves better transferability and generalization by the ensemble of the ABP across different models and domains. Code is available at https://github.com/BaiDingHub/ABP",
    "checked": true,
    "id": "eabc9976605d6fe7dfae895fd0f522a0ec5aa149",
    "semantic_title": "query-efficient textual adversarial example generation for black-box attacks",
    "citation_count": 0,
    "authors": [
      "Zhen Yu",
      "Zhenhua Chen",
      "Kun He"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.32": {
    "title": "Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles",
    "volume": "long",
    "abstract": "Previous research in multi-document news summarization has typically concentrated on collating information that all sources agree upon. However, the summarization of diverse information dispersed across multiple articles about an event remains underexplored. In this paper, we propose a new task of summarizing diverse information encountered in multiple news articles encompassing the same event. To facilitate this task, we outlined a data collection schema for identifying diverse information and curated a dataset named DiverseSumm. The dataset includes 245 news stories, with each story comprising 10 news articles and paired with a human-validated reference. Next, to enable consistent automatic evaluation, we conducted a comprehensive analysis to pinpoint the position and verbosity biases when utilizing Large Language Model (LLM)-based metrics for evaluating the coverage and faithfulness of summaries. Through correlation analyses, we outline the best practices for effectively using automatic LLM-based metrics on the DiverseSumm dataset. Finally, we study how LLMs summarize multiple news articles by analyzing which type of diverse information LLMs are capable of identifying. Our analyses suggest that despite the extraordinary capabilities of LLMs in single-document summarization, the proposed task remains a complex challenge for them mainly due to their limited coverage, with GPT-4 only able to cover under 40% of the diverse information on average",
    "checked": true,
    "id": "1221aa62d85770e1712c98fbe2fbaf8bad512861",
    "semantic_title": "embrace divergence for richer insights: a multi-document summarization benchmark and a case study on summarizing diverse information from news articles",
    "citation_count": 11,
    "authors": [
      "Kung-Hsiang Huang",
      "Philippe Laban",
      "Alexander Fabbri",
      "Prafulla Kumar Choubey",
      "Shafiq Joty",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.33": {
    "title": "AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation",
    "volume": "long",
    "abstract": "Ensuring factual consistency is crucial for natural language generation tasks, particularly in abstractive summarization, where preserving the integrity of information is paramount. Prior works on evaluating factual consistency of summarization often take the entailment-based approaches that first generate perturbed (factual inconsistent) summaries and then train a classifier on the generated data to detect the factually inconsistencies during testing time. However, previous approaches generating perturbed summaries are either of low coherence or lack error-type coverage. To address these issues, we propose AMRFact, a framework that generates perturbed summaries using Abstract Meaning Representations (AMRs). Our approach parses factually consistent summaries into AMR graphs and injects controlled factual inconsistencies to create negative examples, allowing for coherent factually inconsistent summaries to be generated with high error-type coverage. Additionally, we present a data selection module NegFilter based on natural language inference and BARTScore to ensure the quality of the generated negative samples. Experimental results demonstrate our approach significantly outperforms previous systems on the AggreFact-SOTA benchmark, showcasing its efficacy in evaluating factuality of abstractive summarization",
    "checked": true,
    "id": "4e444759dc61f26dee627fbb909a15a5ad32b184",
    "semantic_title": "amrfact: enhancing summarization factuality evaluation with amr-driven negative samples generation",
    "citation_count": 1,
    "authors": [
      "Haoyi Qiu",
      "Kung-Hsiang Huang",
      "Jingnong Qu",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.34": {
    "title": "PILOT: Legal Case Outcome Prediction with Case Law",
    "volume": "long",
    "abstract": "Machine learning shows promise in predicting the outcome of legal cases, but most research has concentrated on civil law cases rather than case law systems. We identified two unique challenges in making legal case outcome predictions with case law. First, it is crucial to identify relevant precedent cases that serve as fundamental evidence for judges during decision-making. Second, it is necessary to consider the evolution of legal principles over time, as early cases may adhere to different legal contexts. In this paper, we proposed a new framework named PILOT (PredictIng Legal case OuTcome) for case outcome prediction. It comprises two modules for relevant case retrieval and temporal pattern handling, respectively. To benchmark the performance of existing legal case outcome prediction models, we curated a dataset from a large-scale case law database. We demonstrate the importance of accurately identifying precedent cases and mitigating the temporal shift when making predictions for case law, as our method shows a significant improvement over the prior methods that focus on civil law case outcome predictions",
    "checked": true,
    "id": "50985d2fa9f31221b080e725dcf63278e9b62b73",
    "semantic_title": "pilot: legal case outcome prediction with case law",
    "citation_count": 0,
    "authors": [
      "Lang Cao",
      "Zifeng Wang",
      "Cao Xiao",
      "Jimeng Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.35": {
    "title": "ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models",
    "volume": "long",
    "abstract": "Parameter-efficient fine-tuning (PEFT) is widely studied for its effectiveness and efficiency in the era of large language models. Low-rank adaptation (LoRA) has demonstrated commendable performance as a popular and representative method. However, it is implemented with a fixed intrinsic rank that might not be the ideal setting for the downstream tasks. Recognizing the need for more flexible downstream task adaptation, we extend the methodology of LoRA to an innovative approach we call allocating low-rank adaptation (ALoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. First, we propose a novel method, AB-LoRA, that can effectively estimate the importance score of each LoRA rank. Second, guided by AB-LoRA, we gradually prune abundant and negatively impacting LoRA ranks and allocate the pruned LoRA budgets to important Transformer modules needing higher ranks. We have conducted experiments on various tasks, and the experimental results demonstrate that our ALoRA method can outperform the recent baselines with comparable tunable parameters",
    "checked": true,
    "id": "e4d913a4a1e5286b93e4dca0e032c58c3794e873",
    "semantic_title": "alora: allocating low-rank adaptation for fine-tuning large language models",
    "citation_count": 2,
    "authors": [
      "Zequan Liu",
      "Jiawen Lyn",
      "Wei Zhu",
      "Xing Tian"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.36": {
    "title": "R-Spin: Efficient Speaker and Noise-invariant Representation Learning with Acoustic Pieces",
    "volume": "long",
    "abstract": "This paper introduces Robust Spin (R-Spin), a data-efficient domain-specific self-supervision method for speaker and noise-invariant speech representations by learning discrete acoustic units with speaker-invariant clustering (Spin). R-Spin resolves Spin's issues and enhances content representations by learning to predict acoustic pieces. R-Spin offers a 12X reduction in computational resources compared to previous state-of-the-art methods while outperforming them in severely distorted speech scenarios. This paper provides detailed analyses to show how discrete units contribute to speech encoder training and improving robustness in diverse acoustic environments",
    "checked": true,
    "id": "599098b25424443ddf4df475659cc7624703f7ee",
    "semantic_title": "r-spin: efficient speaker and noise-invariant representation learning with acoustic pieces",
    "citation_count": 0,
    "authors": [
      "Heng-Jui Chang",
      "James Glass"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.37": {
    "title": "InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions",
    "volume": "long",
    "abstract": "Instruction tuning effectively optimizes Large Language Models (LLMs) for downstream tasks. Due to the changing environment in real-life applications, LLMs necessitate continual task-specific adaptation without catastrophic forgetting. Considering the heavy computational cost, replay-based Continual Learning (CL) methods are the simplest and most widely used for LLMs to address the forgetting issue. However, traditional replay-based methods do not fully utilize instructions to customize the replay strategy. In this work, we propose a novel paradigm called Instruction-based Continual Learning (InsCL). InsCL dynamically replays previous data based on task similarity, calculated by Wasserstein Distance with instructions. Moreover, we further introduce an Instruction Information Metric (InsInfo) to quantify the complexity and diversity of instructions. According to InsInfo, InsCL guides the replay process more inclined to high-quality data. We conduct extensive experiments over 16 tasks with different training orders, observing consistent performance improvements of InsCL. When all tasks have been trained, InsCL achieves performance gains of 3.0 Relative Gain compared with Random Replay, and 27.96 Relative Gain compared with No Replay",
    "checked": true,
    "id": "76b65c248677314865a110424542c220886dbb67",
    "semantic_title": "inscl: a data-efficient continual learning paradigm for fine-tuning large language models with instructions",
    "citation_count": 4,
    "authors": [
      "Yifan Wang",
      "Yafei Liu",
      "Chufan Shi",
      "Haoling Li",
      "Chen Chen",
      "Haonan Lu",
      "Yujiu Yang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.38": {
    "title": "Language Agnostic Code Embeddings",
    "volume": "long",
    "abstract": "Recently, code language models have achieved notable advancements in addressing a diverse array of essential code comprehension and generation tasks. Yet, the field lacks a comprehensive deep dive and understanding of the code embeddings of multilingual code models. In this paper, we present a comprehensive study on multilingual code embeddings, focusing on the cross-lingual capabilities of these embeddings across different programming languages. Through probing experiments, we demonstrate that code embeddings comprise two distinct components: one deeply tied to the nuances and syntax of a specific language, and the other remaining agnostic to these details, primarily focusing on semantics. Further, we show that when we isolate and eliminate this language-specific component, we witness significant improvements in downstream code retrieval tasks, leading to an absolute increase of up to +17 in the Mean Reciprocal Rank (MRR)",
    "checked": true,
    "id": "e0c2c9b11dc27932be2235b52e6da372105e5ed5",
    "semantic_title": "language agnostic code embeddings",
    "citation_count": 0,
    "authors": [
      "Saiteja Utpala",
      "Alex Gu",
      "Pin-Yu Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.39": {
    "title": "An Examination of the Compositionality of Large Generative Vision-Language Models",
    "volume": "long",
    "abstract": "With the success of Large Language Models (LLMs), many Generative Vision-Language Models (GVLMs) have been constructed via multimodal instruction tuning. However, the performance of GVLMs in multimodal compositional reasoning remains under-explored. In this paper, we examine both the evaluation metrics ( VisualGPTScore, etc.) and current benchmarks for evaluating the compositionality of GVLMs. We identify the syntactical bias in current benchmarks, which is exploited by the linguistic capability of GVLMs. The bias renders VisualGPTScore an insufficient metric for assessing GVLMs. To combat this, we first introduce a **SyntaxBias Score**, leveraging LLMs to quantify such bias for mitigation. A challenging new task is subsequently added to evaluate the robustness of GVLMs against inherent inclination toward syntactical correctness. Using the bias-mitigated datasets and the new task, we propose a novel benchmark, namely **S**ynt**A**ctically **DE**-biased benchmark (SADE). Our study provides an unbiased benchmark for the compositionality of GVLMs, facilitating future research in this direction. Code and dataset are available at https://github.com/TeleeMa/SADE",
    "checked": true,
    "id": "66d3b7a6561148fd21c364315e67bf9373f50ef7",
    "semantic_title": "an examination of the compositionality of large generative vision-language models",
    "citation_count": 2,
    "authors": [
      "Teli Ma",
      "Rong Li",
      "Junwei Liang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.40": {
    "title": "Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors",
    "volume": "long",
    "abstract": "Data poisoning backdoor attacks can cause undesirable behaviors in large language models (LLMs), and defending against them is of increasing importance. Existing defense mechanisms often assume that only one type of trigger is adopted by the attacker, while defending against multiple simultaneous and independent trigger types necessitates general defense frameworks and is relatively unexplored. In this paper, we propose Nested Product of Experts (NPoE) defense framework, which involves a mixture of experts (MoE) as a trigger-only ensemble within the PoE defense framework to simultaneously defend against multiple trigger types. During NPoE training, the main modelis trained in an ensemble with a mixture of smaller expert models that learn the features of backdoor triggers. At inference time, only the main model is used. Experimental results on sentiment analysis, hate speech detection, and question classification tasks demonstrate that NPoE effectively defends against a variety of triggers both separately and in trigger mixtures. Due to the versatility of the MoE structure in NPoE, this framework can be further expanded to defend against other attack settings",
    "checked": true,
    "id": "a437c4842b4a11feda920329250b828586825f35",
    "semantic_title": "two heads are better than one: nested poe for robust defense against multi-backdoors",
    "citation_count": 1,
    "authors": [
      "Victoria Graf",
      "Qin Liu",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.41": {
    "title": "VertAttack: Taking Advantage of Text Classifiers' Horizontal Vision",
    "volume": "long",
    "abstract": "Text classification systems have continuouslyimproved in performance over the years. How-ever, nearly all current SOTA classifiers have asimilar shortcoming, they process text in a hor-izontal manner. Vertically written words willnot be recognized by a classifier. In contrast,humans are easily able to recognize and readwords written both horizontally and vertically.Hence, a human adversary could write problem-atic words vertically and the meaning wouldstill be preserved to other humans. We simulatesuch an attack, VertAttack. VertAttack identifieswhich words a classifier is reliant on and thenrewrites those words vertically. We find thatVertAttack is able to greatly drop the accuracyof 4 different transformer models on 5 datasets.For example, on the SST2 dataset, VertAttackis able to drop RoBERTa's accuracy from 94 to13%. Furthermore, since VertAttack does notreplace the word, meaning is easily preserved.We verify this via a human study and find thatcrowdworkers are able to correctly label 77%perturbed texts perturbed, compared to 81% ofthe original texts. We believe VertAttack offersa look into how humans might circumvent clas-sifiers in the future and thus inspire a look intomore robust algorithms",
    "checked": true,
    "id": "0f6180111c7658d1bc01ac8831dd9ad1a6af3f12",
    "semantic_title": "vertattack: taking advantage of text classifiers' horizontal vision",
    "citation_count": 0,
    "authors": [
      "Jonathan Rusert"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.42": {
    "title": "KDMCSE: Knowledge Distillation Multimodal Sentence Embeddings with Adaptive Angular margin Contrastive Learning",
    "volume": "long",
    "abstract": "Previous work on multimodal sentence embedding has proposed multimodal contrastive learning and achieved promising results. However, by taking the rest of the batch as negative samples without reviewing when forming contrastive pairs, those studies encountered many suspicious and noisy negative examples, significantly affecting the methods' overall performance. In this work, we propose KDMCSE (Knowledge Distillation Multimodal contrastive learning of Sentence Embeddings), a novel approach that enhances the discrimination and generalizability of multimodal representation and inherits the knowledge from the teacher model to learn the difference between positive and negative instances and via that, can detect noisy and wrong negative samples effectively before they are calculated in the contrastive objective. Furthermore, to overcome the limitation of modeling the variation within negative pairs, we introduce a new contrastive objective, AdapACSE (Adaptive Angular Margin Supervised Contrastive Learning for Multimodal sentence embeddings), that enhances the discriminative representation by strengthening the margin within the angular space while capturing varying semantics within the negative. Experimental results on widely used Semantic Textual Similarity (STS) benchmarks demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "debe3714ddd57432f0017e1eb8a4e42730801f5f",
    "semantic_title": "kdmcse: knowledge distillation multimodal sentence embeddings with adaptive angular margin contrastive learning",
    "citation_count": 1,
    "authors": [
      "Cong-Duy Nguyen",
      "Thong Nguyen",
      "Xiaobao Wu",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.43": {
    "title": "The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language",
    "volume": "long",
    "abstract": "In this project, we demonstrate that phoneme-based models for speech processing can achieve strong crosslinguistic generalizability to unseen languages. We curated the IPAPACK, a massively multilingual speech corpora with phonemic transcriptions, encompassing more than 115 languages from diverse language families, selectively checked by linguists. Based on the IPAPACK, we propose CLAP-IPA, a multi-lingual phoneme-speech contrastive embedding model capable of open-vocabulary matching between arbitrary speech signals and phonemic sequences. The proposed model was tested on 95 unseen languages, showing strong generalizability across languages. Temporal alignments between phonemes and speech signals also emerged from contrastive training, enabling zeroshot forced alignment in unseen languages. We further introduced a neural forced aligner IPA-ALIGNER by finetuning CLAP-IPA with the Forward-Sum loss to learn better phone-to-audio alignment. Evaluation results suggest that IPA-ALIGNER can generalize to unseen languages without adaptation",
    "checked": true,
    "id": "35f3f631339bd2f9fcb898db9fbb0a364cbf3c06",
    "semantic_title": "the taste of ipa: towards open-vocabulary keyword spotting and forced alignment in any language",
    "citation_count": 0,
    "authors": [
      "Jian Zhu",
      "Changbing Yang",
      "Farhan Samir",
      "Jahurul Islam"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.44": {
    "title": "Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks",
    "volume": "long",
    "abstract": "Gender bias in vision-language models (VLMs) can reinforce harmful stereotypes and discrimination. In this paper, we focus on mitigating gender bias towards vision-language tasks. We identify object hallucination as the essence of gender bias in VLMs. Existing VLMs tend to focus on salient or familiar attributes in images but ignore contextualized nuances. Moreover, most VLMs rely on the co-occurrence between specific objects and gender attributes to infer the ignored features, ultimately resulting in gender bias. We propose GAMA, a task-agnostic generation framework to mitigate gender bias. GAMA consists of two stages: narrative generation and answer inference. During narrative generation, GAMA yields all-sided but gender-obfuscated narratives, which prevents premature concentration on localized image features, especially gender attributes. During answer inference, GAMA integrates the image, generated narrative, and a task-specific question prompt to infer answers for different vision-language tasks. This approach allows the model to rethink gender attributes and answers. We conduct extensive experiments on GAMA, demonstrating its debiasing and generalization ability",
    "checked": true,
    "id": "5c35f33b87780c47777be39284ea14929cb0f1bf",
    "semantic_title": "think before you act: a two-stage framework for mitigating gender bias towards vision-language tasks",
    "citation_count": 0,
    "authors": [
      "Yunqi Zhang",
      "Songda Li",
      "Chunyuan Deng",
      "Luyi Wang",
      "Hui Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.45": {
    "title": "BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings",
    "volume": "long",
    "abstract": "Sentence embeddings are crucial in measuring semantic similarity. Most recent studies employed large language models (LLMs) to learn sentence embeddings. Existing LLMs mainly adopted autoregressive architecture without explicit backward dependency modeling. Therefore, we examined the effects of backward dependencies in LLMs for semantic similarity measurements. Concretely, we propose a novel model: backward dependency enhanced large language model (BeLLM). It learns sentence embeddings via transforming specific attention layers from uni- to bi-directional. We extensively experiment across various semantic textual similarity (STS) tasks and downstream applications. BeLLM achieves state-of-the-art performance in varying scenarios. It shows that autoregressive LLMs benefit from backward dependencies for sentence embeddings",
    "checked": true,
    "id": "441fbfe5bc465dbceb7595be30cfc6b013434295",
    "semantic_title": "bellm: backward dependency enhanced large language model for sentence embeddings",
    "citation_count": 0,
    "authors": [
      "Xianming Li",
      "Jing Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.46": {
    "title": "Assessing Factual Reliability of Large Language Model Knowledge",
    "volume": "long",
    "abstract": "The factual knowledge of LLMs is typically evaluated using accuracy, yet this metric does not capture the vulnerability of LLMs to hallucination-inducing factors like prompt and context variability. How do we evaluate the capabilities of LLMs to consistently produce factually correct answers? In this paper, we propose MOdel kNowledge relIabiliTy scORe (MONITOR), a novel metric designed to directly measure LLMs' factual reliability. MONITOR is designed to compute the distance between the probability distributions of a valid output and its counterparts produced by the same LLM probing the same fact using different styles of prompts and contexts. Experiments on a comprehensive range of 12 LLMs demonstrate the effectiveness of MONITOR in evaluating the factual reliability of LLMs while maintaining a low computational overhead. In addition, we release the FKTC (Factual Knowledge Test Corpus) to foster research along this line https://github.com/Vicky-Wil/MONITOR",
    "checked": true,
    "id": "9f2a3564b9b3053b93121a5cb9e30424b9058e99",
    "semantic_title": "assessing factual reliability of large language model knowledge",
    "citation_count": 0,
    "authors": [
      "Weixuan Wang",
      "Barry Haddow",
      "Alexandra Birch",
      "Wei Peng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.47": {
    "title": "Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems",
    "volume": "long",
    "abstract": "Dialogue response selection aims to select an appropriate response from several candidates based on a given user and system utterance history. Most existing works primarily focus on post-training and fine-tuning tailored for cross-encoders. However, there are no post-training methods tailored for dense encoders in dialogue response selection. We argue that when the current language model, based on dense dialogue systems (such as BERT), is employed as a dense encoder, it separately encodes dialogue context and response, leading to a struggle to achieve the alignment of both representations. Thus, we propose Dial-MAE (Dialogue Contextual Masking Auto-Encoder), a straightforward yet effective post-training technique tailored for dense encoders in dialogue response selection. Dial-MAE uses an asymmetric encoder-decoder architecture to compress the dialogue semantics into dense vectors, which achieves better alignment between the features of the dialogue context and response. Our experiments have demonstrated that Dial-MAE is highly effective, achieving state-of-the-art performance on two commonly evaluated benchmarks",
    "checked": true,
    "id": "8bc108958c38643a7ecab81a5f56620c00dbf69f",
    "semantic_title": "dial-mae: contextual masked auto-encoder for retrieval-based dialogue systems",
    "citation_count": 0,
    "authors": [
      "Zhenpeng Su",
      "Xing W",
      "Wei Zhou",
      "Guangyuan Ma",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.48": {
    "title": "Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities. Evaluation of diverse tasks from BIG-bench demonstrates its CoS ability matches that of ChatGPT while its performance surpasses the chain-of-thought approach. Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released",
    "checked": true,
    "id": "b9e8b62bcc019f47a0a015568f70039b3b7c1196",
    "semantic_title": "toolink: linking toolkit creation and using through chain-of-solving on open-source model",
    "citation_count": 5,
    "authors": [
      "Cheng Qian",
      "Chenyan Xiong",
      "Zhenghao Liu",
      "Zhiyuan Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.49": {
    "title": "Create! Don't Repeat: A Paradigm Shift in Multi-Label Augmentation through Label Creative Generation",
    "volume": "long",
    "abstract": "We propose Label Creative Generation (LCG), a new paradigm in multi-label data augmentation. Beyond repeating data points with fixed labels, LCG creates new data by exploring innovative label combinations. Within LCG, we introduce Tail-Driven Conditional Augmentation (TDCA), combining tail-driven label sampling and label-conditioned text generation for balanced, consistent data augmentation. Our approach has demonstrated a **100.21%** increase in PSP@1 across three datasets, successfully mitigating the long-tail effect in MLTC and markedly enhancing model performance",
    "checked": true,
    "id": "a6f79da60acbc983612eab43e4d7432d50298e62",
    "semantic_title": "create! don't repeat: a paradigm shift in multi-label augmentation through label creative generation",
    "citation_count": 0,
    "authors": [
      "Letian Wang",
      "Xianggen Liu",
      "Jiancheng Lv"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.50": {
    "title": "Neurocache: Efficient Vector Retrieval for Long-range Language Modeling",
    "volume": "long",
    "abstract": "This paper introduces Neurocache, an approach to extend the effective context size of large language models (LLMs) using an external vector cache to store its past states. Like recent vector retrieval approaches, Neurocache uses an efficient k-nearest-neighbor (kNN) algorithm to retrieve relevant past states and incorporate them into the attention process. Neurocache improves upon previous methods by (1) storing compressed states, which reduces cache size; (2) performing a single retrieval operation per token which increases inference speed; and (3) extending the retrieval window to neighboring states, which improves both language modeling and downstream task accuracy. Our experiments show the effectiveness of Neurocache both for models trained from scratch and for pre-trained models such as Llama2-7B and Mistral-7B when enhanced with the cache mechanism. We also compare Neurocache with text retrieval methods and show improvements in single-document question-answering and few-shot learning tasks. We made the source code available under: https://github.com/alisafaya/neurocache",
    "checked": true,
    "id": "0ea22780c42536f488c097431c037aa45aac0b2d",
    "semantic_title": "neurocache: efficient vector retrieval for long-range language modeling",
    "citation_count": 0,
    "authors": [
      "Ali Safaya",
      "Deniz Yuret"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.51": {
    "title": "Unveiling the Generalization Power of Fine-Tuned Large Language Models",
    "volume": "long",
    "abstract": "While Large Language Models (LLMs) have demonstrated exceptional multitasking abilities, fine-tuning these models on downstream, domain-specific datasets is often necessary to yield superior performance on test sets compared to their counterparts without fine-tuning. However, the comprehensive effects of fine-tuning on the LLMs' generalization ability are not fully understood.This paper delves into the differences between original, unmodified LLMs and their fine-tuned variants. Our primary investigation centers on whether fine-tuning affects the generalization ability intrinsic to LLMs. To elaborate on this, we conduct extensive experiments across five distinct language tasks on various datasets.Our main findings reveal that models fine-tuned on generation and classification tasks exhibit dissimilar behaviors in generalizing to different domains and tasks.Intriguingly, we observe that integrating the in-context learning strategy during fine-tuning on generation tasks can enhance the model's generalization ability.Through this systematic investigation, we aim to contribute valuable insights into the evolving landscape of fine-tuning practices for LLMs",
    "checked": true,
    "id": "6edf144fb397afde80d9acf9472dfaffd22c8072",
    "semantic_title": "unveiling the generalization power of fine-tuned large language models",
    "citation_count": 2,
    "authors": [
      "Haoran Yang",
      "Yumeng Zhang",
      "Jiaqi Xu",
      "Hongyuan Lu",
      "Pheng-Ann Heng",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.52": {
    "title": "A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning",
    "volume": "long",
    "abstract": "Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods",
    "checked": true,
    "id": "6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
    "semantic_title": "a closer look at the self-verification abilities of large language models in logical reasoning",
    "citation_count": 10,
    "authors": [
      "Ruixin Hong",
      "Hongming Zhang",
      "Xinyu Pang",
      "Dong Yu",
      "Changshui Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.53": {
    "title": "Exploring Self-supervised Logic-enhanced Training for Large Language Models",
    "volume": "long",
    "abstract": "Traditional attempts to enhance the logical reasoning abilities of language models often rely on supervised fine-tuning, limiting their generalization to new tasks or domains. Large Language Models (LLMs), with their capacity to condense vast knowledge, can effectively tackle many tasks. Yet, our experiments reveal a gap in their performance on logical reasoning benchmarks when compared to state-of-the-art fine-tuning based models. To bridge this gap, we present LogicLLM, a first-of-its-kind, fully self-supervised framework for integrating logical reasoning capabilities into LLMs, and activating them via in-context learning. We apply this to two LLM series, FLAN-T5 and LLaMA, with parameter sizes from 3 billion to 33 billion. LogicLLM demonstrates its effectiveness through successful improvements on two logical reasoning benchmarks (ReClor and LogiQA-v2). Additionally, LogicLLM based on FLAN-T5-11B attains comparable results to ChatGPT, and evaluations with LLaMA-based models on three language understanding benchmarks (RACE, MMLU and Big-Bench-Hard) confirm that the improvements come without compromising the model's general language understanding capabilities",
    "checked": true,
    "id": "74cbfe5b9331ecc717cc47913ec43e707badcf97",
    "semantic_title": "exploring self-supervised logic-enhanced training for large language models",
    "citation_count": 0,
    "authors": [
      "Fangkai Jiao",
      "Zhiyang Teng",
      "Bosheng Ding",
      "Zhengyuan Liu",
      "Nancy Chen",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.54": {
    "title": "MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning",
    "volume": "long",
    "abstract": "Tool-augmented Large Language Models (TALMs) are known to enhance the skillset of large language models (LLMs), thereby, leading to their improved reasoning abilities across many tasks. While, TALMs have been successfully employed in different question-answering benchmarks, their efficacy on complex mathematical reasoning benchmarks, and the potential complementary benefits offered by tools for knowledge retrieval and mathematical equation solving are open research questions. In this work, we present MathSensei, a tool-augmented large language model for mathematical reasoning. We study the complementary benefits of the tools - knowledge retriever (Bing Web Search), program generator + executor (Python), and symbolic equation solver (Wolfram-Alpha API) through evaluations on mathematical reasoning datasets. We perform exhaustive ablations on MATH, a popular dataset for evaluating mathematical reasoning on diverse mathematical disciplines. We also conduct experiments involving well-known tool planners to study the impact of tool sequencing on the model performance. MathSensei achieves 13.5% better accuracy over gpt-3.5-turbo with Chain-of-Thought on the MATH dataset. We further observe that TALMs are not as effective for simpler math word problems (in GSM-8K), and the benefit increases as the complexity and required knowledge increases (progressively over AQuA, MMLU-Math, and higher level complex questions in MATH). The code and data are available at https://github.com/Debrup-61/MathSensei",
    "checked": true,
    "id": "2c4bf56c5b1a1f06ee3ca21ce964ba2c8c66cb2c",
    "semantic_title": "mathsensei: a tool-augmented large language model for mathematical reasoning",
    "citation_count": 2,
    "authors": [
      "Debrup Das",
      "Debopriyo Banerjee",
      "Somak Aditya",
      "Ashish Kulkarni"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.55": {
    "title": "CoUDA: Coherence Evaluation via Unified Data Augmentation",
    "volume": "long",
    "abstract": "Coherence evaluation aims to assess the organization and structure of a discourse, which remains challenging even in the era of large language models. Due to the scarcity of annotated data, data augmentation is commonly used for training coherence evaluation models. However, previous augmentations for this task primarily rely on heuristic rules, lacking designing criteria as guidance.In this paper, we take inspiration from linguistic theory of discourse structure, and propose a data augmentation framework named CoUDA. CoUDA breaks down discourse coherence into global and local aspects, and designs augmentation strategies for both aspects, respectively.Especially for local coherence, we propose a novel generative strategy for constructing augmentation samples, which involves post-pretraining a generative model and applying two controlling mechanisms to control the difficulty of generated samples. During inference, CoUDA also jointly evaluates both global and local aspects to comprehensively assess the overall coherence of a discourse.Extensive experiments in coherence evaluation show that, with only 233M parameters, CoUDA achieves state-of-the-art performance in both pointwise scoring and pairwise ranking tasks, even surpassing recent GPT-3.5 and GPT-4 based metrics",
    "checked": true,
    "id": "5ffd59819bfd3bd908056e45c4ce2f932b70ecdf",
    "semantic_title": "couda: coherence evaluation via unified data augmentation",
    "citation_count": 0,
    "authors": [
      "Dawei Zhu",
      "Wenhao Wu",
      "Yifan Song",
      "Fangwei Zhu",
      "Ziqiang Cao",
      "Sujian Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.56": {
    "title": "mEdIT: Multilingual Text Editing via Instruction Tuning",
    "volume": "long",
    "abstract": "We introduce mEdIT, a multi-lingual extension to CoEdIT – the recent state-of-the-art text editing models for writing assistance. mEdIT models are trained by fine-tuning multi-lingual large, pre-trained language models (LLMs) via instruction tuning. They are designed to take instructions from the user specifying the attributes of the desired text in the form of natural language instructions, such as \"Grammatik korrigieren\" (German) or \"이 텍스 트를 단순화\" (Korean). We build mEdIT by curating data from multiple publicly available human-annotated text editing datasets for three text editing tasks (Grammatical Error Correction (GEC), Text Simplification, and Paraphrasing) across diverse languages belonging to six different language families. We detail the design and training of mEdIT models and demonstrate their strong performance on many multi-lingual text editing benchmarks against other multilingual LLMs. We also find that mEdIT generalizes effectively to new languages over multilingual baselines. We publicly release our data, code, and trained models",
    "checked": true,
    "id": "038937be80c561740a47c68157eed3a02548abfe",
    "semantic_title": "medit: multilingual text editing via instruction tuning",
    "citation_count": 1,
    "authors": [
      "Vipul Raheja",
      "Dimitris Alikaniotis",
      "Vivek Kulkarni",
      "Bashar Alhafni",
      "Dhruv Kumar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.57": {
    "title": "Navigation as Attackers Wish? Towards Building Robust Embodied Agents under Federated Learning",
    "volume": "long",
    "abstract": "Federated embodied agent learning protects the data privacy of individual visual environments by keeping data locally at each client (the individual environment) during training. However, since the local data is inaccessible to the server under federated learning, attackers may easily poison the training data of the local client to build a backdoor in the agent without notice. Deploying such an agent raises the risk of potential harm to humans, as the attackers may easily navigate and control the agent as they wish via the backdoor. Towards Byzantine-robust federated embodied agent learning, in this paper, we study the attack and defense for the task of vision-and-language navigation (VLN), where the agent is required to follow natural language instructions to navigate indoor environments. First, we introduce a simple but effective attack strategy, Navigation as Wish (NAW), in which the malicious client manipulates local trajectory data to implant a backdoor into the global model. Results on two VLN datasets (R2R and RxR) show that NAW can easily navigate the deployed VLN agent regardless of the language instruction, without affecting its performance on normal test sets. Then, we propose a new Prompt-Based Aggregation (PBA) to defend against the NAW attack in federated VLN, which provides the server with a \"prompt\" of the vision-and-language alignment variance between the benign and malicious clients so that they can be distinguished during training. We validate the effectiveness of the PBA method on protecting the global model from the NAW attack, which outperforms other state-of-the-art defense methods by a large margin in the defense metrics on R2R and RxR",
    "checked": true,
    "id": "f32e092c0b9ef748efbc69350e5e6c756e74b752",
    "semantic_title": "navigation as attackers wish? towards building robust embodied agents under federated learning",
    "citation_count": 0,
    "authors": [
      "Yunchao Zhang",
      "Zonglin Di",
      "Kaiwen Zhou",
      "Cihang Xie",
      "Xin Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.58": {
    "title": "In-context Learning and Gradient Descent Revisited",
    "volume": "long",
    "abstract": "In-context learning (ICL) has shown impressive results in few-shot learning tasks, yet its underlying mechanism is still not fully understood. A recent line of work suggests that ICL performs gradient descent (GD)-based optimization implicitly. While appealing, much of the research focuses on simplified settings, where the parameters of a shallow model are optimized. In this work, we revisit evidence for ICL-GD correspondence on realistic NLP tasks and models. We find gaps in evaluation, both in terms of problematic metrics and insufficient baselines. We show that surprisingly, even untrained models achieve comparable ICL-GD similarity scores despite not exhibiting ICL.Next, we explore a major discrepancy in the flow of information throughout the model between ICL and GD, which we term Layer Causality. We propose a simple GD-based optimization procedure that respects layer causality, and show it improves similarity scores significantly",
    "checked": true,
    "id": "4720228f91c9e48442958de264ce24ed26fb6f6b",
    "semantic_title": "in-context learning and gradient descent revisited",
    "citation_count": 2,
    "authors": [
      "Gilad Deutch",
      "Nadav Magar",
      "Tomer Natan",
      "Guy Dar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.59": {
    "title": "Corpus Considerations for Annotator Modeling and Scaling",
    "volume": "long",
    "abstract": "Recent trends in natural language processing research and annotation tasks affirm a paradigm shift from the traditional reliance on a single ground truth to a focus on individual perspectives, particularly in subjective tasks. In scenarios where annotation tasks are meant to encompass diversity, models that solely rely on the majority class labels may inadvertently disregard valuable minority perspectives. This oversight could result in the omission of crucial information and, in a broader context, risk disrupting the balance within larger ecosystems. As the landscape of annotator modeling unfolds with diverse representation techniques, it becomes imperative to investigate their effectiveness with the fine-grained features of the datasets in view. This study systematically explores various annotator modeling techniques and compares their performance across seven corpora. From our findings, we show that the commonly used user token model consistently outperforms more complex models. We introduce a composite embedding approach and show distinct differences in which model performs best as a function of the agreement with a given dataset. Our findings shed light on the relationship between corpus statistics and annotator modeling performance, which informs future work on corpus construction and perspectivist NLP",
    "checked": true,
    "id": "efb1f5ad5715cdff23dc5841ae9db853d901dd4a",
    "semantic_title": "corpus considerations for annotator modeling and scaling",
    "citation_count": 0,
    "authors": [
      "Sarumi Oluyemi",
      "Béla Neuendorf",
      "Joan Plepi",
      "Lucie Flek",
      "Jörg Schlötterer",
      "Charles Welch"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.60": {
    "title": "On Large Language Models' Hallucination with Regard to Known Facts",
    "volume": "long",
    "abstract": "Large language models are successful in answering factoid questions but are also prone to hallucination.We investigate the phenomenon of LLMs possessing correct answer knowledge yet still hallucinating from the perspective of inference dynamics, an area not previously covered in studies on hallucinations.We are able to conduct this analysis via two key ideas.First, we identify the factual questions that query the same triplet knowledge but result in different answers. The difference between the model behaviors on the correct and incorrect outputs hence suggests the patterns when hallucinations happen.Second, to measure the pattern, we utilize mappings from the residual streams to vocabulary space.We reveal the different dynamics of the output token probabilities along the depths of layers between the correct and hallucinated cases. In hallucinated cases, the output token's information rarely demonstrates abrupt increases and consistent superiority in the later stages of the model.Leveraging the dynamic curve as a feature, we build a classifier capable of accurately detecting hallucinatory predictions with an 88% success rate. Our study shed light on understanding the reasons for LLMs' hallucinations on their known facts, and more importantly, on accurately predicting when they are hallucinating",
    "checked": true,
    "id": "d48c56dbce88580736c037797666060cb3b03bf7",
    "semantic_title": "on large language models' hallucination with regard to known facts",
    "citation_count": 3,
    "authors": [
      "Che Jiang",
      "Biqing Qi",
      "Xiangyu Hong",
      "Dayuan Fu",
      "Yang Cheng",
      "Fandong Meng",
      "Mo Yu",
      "Bowen Zhou",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.61": {
    "title": "One-Size-Fits-All\"? Examining Expectations around What Constitute \"Fair\" or \"Good\" NLG System Behaviors",
    "volume": "long",
    "abstract": "Fairness-related assumptions about what constitute appropriate NLG system behaviors range from invariance, where systems are expected to behave identically for social groups, to adaptation, where behaviors should instead vary across them. To illuminate tensions around invariance and adaptation, we conduct five case studies, in which we perturb different types of identity-related language features (names, roles, locations, dialect, and style) in NLG system inputs. Through these cases studies, we examine people's expectations of system behaviors, and surface potential caveats of these contrasting yet commonly held assumptions. We find that motivations for adaptation include social norms, cultural differences, feature-specific information, and accommodation; in contrast, motivations for invariance include perspectives that favor prescriptivism, view adaptation as unnecessary or too difficult for NLG systems to do appropriately, and are wary of false assumptions. Our findings highlight open challenges around what constitute \"fair\" or \"good\" NLG system behaviors",
    "checked": true,
    "id": "33ba6ff1d2b599178e60d029da10b41f7a3c4729",
    "semantic_title": "one-size-fits-all\"? examining expectations around what constitute \"fair\" or \"good\" nlg system behaviors",
    "citation_count": 0,
    "authors": [
      "Li Lucy",
      "Su Lin Blodgett",
      "Milad Shokouhi",
      "Hanna Wallach",
      "Alexandra Olteanu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.62": {
    "title": "Language Models Hallucinate, but May Excel at Fact Verification",
    "volume": "long",
    "abstract": "Recent progress in natural language processing (NLP) owes much to remarkable advances in large language models (LLMs). Nevertheless, LLMs frequently \"hallucinate,\" resulting in non-factual outputs. Our carefully-designed human evaluation substantiates the serious hallucination issue, revealing that even GPT-3.5 produces factual outputs less than 25% of the time. This underscores the importance of fact verifiers in order to measure and incentivize progress. Our systematic investigation affirms that LLMs can be repurposed as effective fact verifiers with strong correlations with human judgments. Surprisingly, FLAN-T5-11B , the least factual generator in our study, performs the best as a fact verifier, even outperforming more capable LLMs like GPT3.5 and ChatGPT. Delving deeper, we analyze the reliance of these LLMs on high-quality evidence, as well as their deficiencies in robustness and generalization ability. Our study presents insights for developing trustworthy generation models",
    "checked": true,
    "id": "45653ad43124f02dc2cf2db3357be1d1d78ddb18",
    "semantic_title": "language models hallucinate, but may excel at fact verification",
    "citation_count": 9,
    "authors": [
      "Jian Guan",
      "Jesse Dodge",
      "David Wadden",
      "Minlie Huang",
      "Hao Peng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.63": {
    "title": "A Rationale-centric Counterfactual Data Augmentation Method for Cross-Document Event Coreference Resolution",
    "volume": "long",
    "abstract": "Based on Pre-trained Language Models (PLMs), event coreference resolution (ECR) systems have demonstrated outstanding performance in clustering coreferential events across documents. However, the state-of-the-art system exhibits an excessive reliance on the ‘triggers lexical matching' spurious pattern in the input mention pair text. We formalize the decision-making process of the baseline ECR system using a Structural Causal Model (SCM), aiming to identify spurious and causal associations (i.e., rationales) within the ECR task. Leveraging the debiasing capability of counterfactual data augmentation, we develop a rationale-centric counterfactual data augmentation method with LLM-in-the-loop. This method is specialized for pairwise input in the ECR system, where we conduct direct interventions on triggers and context to mitigate the spurious association while emphasizing the causation. Our approach achieves state-of-the-art performance on three popular cross-document ECR benchmarks and demonstrates robustness in out-of-domain scenarios",
    "checked": true,
    "id": "b6d534c8e49f7a9b167ce35facba0b1a907e4a85",
    "semantic_title": "a rationale-centric counterfactual data augmentation method for cross-document event coreference resolution",
    "citation_count": 0,
    "authors": [
      "Bowen Ding",
      "Qingkai Min",
      "Shengkun Ma",
      "Yingjie Li",
      "Linyi Yang",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.64": {
    "title": "TrojFSP: Trojan Insertion in Few-shot Prompt Tuning",
    "volume": "long",
    "abstract": "Prompt tuning is one of the most effective solutions to adapting a fixed pre-trained language model (PLM) for various downstream tasks, especially with only a few input samples. However, the security issues, e.g., Trojan attacks, of prompt tuning on a few data samples are not well-studied. Transferring established data poisoning attacks directly to few-shot prompt tuning presents multiple challenges. One significant issue is the _poisoned imbalance issue_, where non-target class samples are added to the target class, resulting in a greater number of target-class samples compared to non-target class. While this issue is not critical in regular tuning, it significantly hampers the few-shot prompt tuning, making it difficult to simultaneously achieve a high attack success rate (ASR) and maintain clean data accuracy (CDA). Additionally, few-shot prompting is prone to overfitting in terms of both ASR and CDA. In this paper, we introduce _TrojFSP_, a method designed to address the challenges. To solve the poisoned imbalance issue, we develop a _Target-Class Shrink (TC-Shrink)_ technique, which aims to equalize the number of poisoning samples. To combat overfitting, we employ a _Selective Token Poisoning_ technique to boost attack performance. Furthermore, we introduce a _Trojan-Trigger Attention_ objective function to amplify the attention of the poisoned trojan prompt on triggers. Experiments show that our TrojFSP achieves an ASR of over 99% while maintaining negligible decreases in CDA across various PLMs and datasets. The source code of TrojFSP is available at _https://github.com/UCF-ML-Research/TrojFSP_",
    "checked": true,
    "id": "7f250f2a3cf353ef77e45af55bd8a1b10dc55360",
    "semantic_title": "trojfsp: trojan insertion in few-shot prompt tuning",
    "citation_count": 2,
    "authors": [
      "Mengxin Zheng",
      "Jiaqi Xue",
      "Xun Chen",
      "Yanshan Wang",
      "Qian Lou",
      "Lei Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.65": {
    "title": "Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) exhibit impressive capabilities but also present risks such as biased content generation and privacy issues. One of the current alignment techniques includes principle-driven integration, but it faces challenges arising from the imprecision of manually crafted rules and inadequate risk perception in models without safety training. To address these, we introduce Guide-Align, a two-stage approach. Initially, a safety-trained model identifies potential risks and formulates specific guidelines for various inputs, establishing a comprehensive library of guidelines and a model for input-guidelines retrieval. Subsequently, the retrieval model correlates new inputs with relevant guidelines, which guide LLMs in response generation to ensure safe and high-quality outputs, thereby aligning with human values. An additional optional stage involves fine-tuning a model with well-aligned datasets generated through the process implemented in the second stage.Our method customizes guidelines to accommodate diverse inputs, thereby enhancing the fine-grainedness and comprehensiveness of the guideline library. Furthermore, it incorporates safety expertise from a safety-trained LLM through a lightweight retrieval model.We evaluate our approach on three benchmarks, demonstrating significant improvements in LLM security and quality. Notably, our fine-tuned model, Labrador, even at 13 billion parameters, outperforms GPT-3.5-turbo and surpasses GPT-4 in alignment capabilities",
    "checked": true,
    "id": "cef1e2542bd47e5e9ba7100835d383693428ca20",
    "semantic_title": "ensuring safe and high-quality outputs: a guideline library approach for language models",
    "citation_count": 0,
    "authors": [
      "Yi Luo",
      "Zhenghao Lin",
      "YuHao Zhang",
      "Jiashuo Sun",
      "Chen Lin",
      "Chengjin Xu",
      "Xiangdong Su",
      "Yelong Shen",
      "Jian Guo",
      "Yeyun Gong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.66": {
    "title": "X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs",
    "volume": "long",
    "abstract": "Understanding when two pieces of text convey the same information is a goal touching many subproblems in NLP, including textual entailment and fact-checking. This problem becomes more complex when those two pieces of text are in different languages. Here, we introduce X-PARADE (Cross-lingual Paragraph-level Analysis of Divergences and Entailments), the first cross-lingual dataset of paragraph-level information divergences. Annotators label a paragraph in a target language at the span level and evaluate it with respect to a corresponding paragraph in a source language, indicating whether a given piece of information is the same, new, or new but can be inferred. This last notion establishes a link with cross-language NLI. Aligned paragraphs are sourced from Wikipedia pages in different languages, reflecting real information divergences observed in the wild. Armed with our dataset, we investigate a diverse set of approaches for this problem, including classic token alignment from machine translation, textual entailment methods that localize their decisions, and prompting LLMs. Our results show that these methods vary in their capability to handle inferable information, but they all fall short of human performance",
    "checked": true,
    "id": "300b01dc726fe8acbededd805501811d427920bd",
    "semantic_title": "x-parade: cross-lingual textual entailment and information divergence across paragraphs",
    "citation_count": 2,
    "authors": [
      "Juan Rodriguez",
      "Katrin Erk",
      "Greg Durrett"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.67": {
    "title": "Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers",
    "volume": "long",
    "abstract": "Large language models (LLMs) are dramatically influencing AI research, spurring discussions on what has changed so far and how to shape the field's future. To clarify such questions, we analyze a new dataset of 16,979 LLM-related arXiv papers, focusing on recent trends in 2023 vs. 2018-2022. First, we study disciplinary shifts: LLM research increasingly considers societal impacts, evidenced by 20× growth in LLM submissions to the Computers and Society sub-arXiv. An influx of new authors – half of all first authors in 2023 – are entering from non-NLP fields of CS, driving disciplinary expansion. Second, we study industry and academic publishing trends. Surprisingly, industry accounts for a smaller publication share in 2023, largely due to reduced output from Google and other Big Tech companies; universities in Asia are publishing more. Third, we study institutional collaboration: while industry-academic collaborations are common, they tend to focus on the same topics that industry focuses on rather than bridging differences. The most prolific institutions are all US- or China-based, but there is very little cross-country collaboration. We discuss implications around (1) how to support the influx of new authors, (2) how industry trends may affect academics, and (3) possible effects of (the lack of) collaboration",
    "checked": true,
    "id": "0abe8833b6901d33a16d0f4176e4180bf24bed16",
    "semantic_title": "topics, authors, and institutions in large language model research: trends from 17k arxiv papers",
    "citation_count": 0,
    "authors": [
      "Rajiv Movva",
      "Sidhika Balachandar",
      "Kenny Peng",
      "Gabriel Agostini",
      "Nikhil Garg",
      "Emma Pierson"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.68": {
    "title": "E5: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit and Extrapolate",
    "volume": "long",
    "abstract": "Analyzing large hierarchical tables with multi-level headers presents challenges due to their complex structure, implicit semantics, and calculation relationships. While recent advancements in large language models (LLMs) have shown promise in flat table analysis, their application to hierarchical tables is constrained by the reliance on manually curated exemplars and the model's token capacity limitations. Addressing these challenges, we introduce a novel code-augmented LLM-based framework, E5, for zero-shot hierarchical table question answering. This approach encompasses self-explaining the table's hierarchical structures, code generation to extract relevant information and apply operations, external code execution to prevent hallucinations, and leveraging LLMs' reasoning for final answer derivation. Empirical results indicate that our method, based on GPT-4, outperforms state-of-the-art fine-tuning methods with a 44.38 Exact Match improvement. Furthermore, we present F3, an adaptive algorithm designed for token-limited scenarios, effectively condensing large tables while maintaining useful information. Our experiments prove its efficiency, enabling the processing of large tables even with models having limited context lengths. The code is available at https://github.com/zzh-SJTU/E5-Hierarchical-Table-Analysis",
    "checked": false,
    "id": "d58f4d7eec0ffdc8f0b1b1ca61dd1586073553ee",
    "semantic_title": "e^5: zero-shot hierarchical table analysis using augmented llms via explain, extract, execute, exhibit and extrapolate",
    "citation_count": 0,
    "authors": [
      "Zhehao Zhang",
      "Yan Gao",
      "Jian-Guang Lou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.69": {
    "title": "S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model",
    "volume": "long",
    "abstract": "The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like long-context understanding and reasoning.However, as LLMs are able to process longer contexts, it becomes more challenging to evaluate whether they have acquired certain capabilities, since the length of text (e.g., 200K tokens) they can process far exceeds what humans can reliably assess in a reasonable duration.In this paper, we propose using complex synthetic tasks as a proxy evaluation method, and present S3Eval, a Synthetic, Scalable, Systematic evaluation suite for LLMs evaluation.The synthetic nature of S3Eval provides users full control over the dataset, allowing them to systematically probe LLM capabilities by scaling text length and varying task difficulty across diverse scenarios.The strong correlation between S3Eval and real-world benchmarks demonstrates the soundness of using S3Eval for evaluation of LLMs.S3Eval provides a flexible and infinite long-context data generation method. We have generated a comprehensive dataset called S3Eval-Standard, and experimental results have shown that it poses significant challenges for all existing LLMs",
    "checked": true,
    "id": "9015c9813b6ef8f05040a7b1340909c57d600e38",
    "semantic_title": "s3eval: a synthetic, scalable, systematic evaluation suite for large language model",
    "citation_count": 6,
    "authors": [
      "Fangyu Lei",
      "Qian Liu",
      "Yiming Huang",
      "Shizhu He",
      "Jun Zhao",
      "Kang Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.70": {
    "title": "MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning",
    "volume": "long",
    "abstract": "With the rapid development of large language models (LLMs) and their integration into large multimodal models (LMMs), there has beenimpressive progress in zero-shot completion of user-oriented vision-language tasks. However, a gap remains in the domain of chartimage understanding due to the distinct abstract components in charts. To address this, we introduce a large-scale MultiModal ChartInstruction (MMC-Instruction) dataset comprising 600k instances supporting diverse tasks and chart types. Leveraging this data, we de-velop MultiModal Chart Assistant (MMCA), an LMM that achieves state-of-the-art performance on existing chart QA benchmarks. Recognizing the need for a comprehensive evaluation of LMM chart understanding, we also propose a MultiModal Chart Benchmark (MMC-Benchmark), a comprehensive human-annotated benchmark with nine distinct tasks evaluating reasoning capabilities over charts.Extensive experiments on MMC-Benchmark reveal the limitations of existing LMMs on correctly interpreting charts, even for the mostrecent GPT-4V model. Our work provides an instruction-tuning methodology and benchmark to advance multimodal understanding ofcharts. Code and data are available at https://github.com/FuxiaoLiu/MMC",
    "checked": true,
    "id": "0f993809c1fe00403ecea66d8f572832f075cfe4",
    "semantic_title": "mmc: advancing multimodal chart understanding with large-scale instruction tuning",
    "citation_count": 32,
    "authors": [
      "Fuxiao Liu",
      "Xiaoyang Wang",
      "Wenlin Yao",
      "Jianshu Chen",
      "Kaiqiang Song",
      "Sangwoo Cho",
      "Yaser Yacoob",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.71": {
    "title": "Visual Grounding Helps Learn Word Meanings in Low-Data Regimes",
    "volume": "long",
    "abstract": "Modern neural language models (LMs) are powerful tools for modeling human sentence production and comprehension, and their internal representations are remarkably well-aligned with representations of language in the human brain. But to achieve these results, LMs must be trained in distinctly un-human-like ways — requiring orders of magnitude more language data than children receive during development, and without perceptual or social context. Do models trained more naturalistically — with grounded supervision — exhibit more humanlike language learning? We investigate this question in the context of word learning, a key sub-task in language acquisition. We train a diverse set of LM architectures, with and without auxiliary visual supervision, on datasets of varying scales. We then evaluate these models' learning of syntactic categories, lexical relations, semantic features, word similarity, and alignment with human neural representations. We find that visual supervision can indeed improve the efficiency of word learning. However, these improvements are limited: they are present almost exclusively in the low-dataregime, and sometimes canceled out by the inclusion of rich distributional signals from text. The information conveyed by text and images isnot redundant—models mainly driven by visual information yield qualitatively different from those mainly driven by word co-occurrences. However, our results suggest that current multimodal modeling approaches fail to effectively leverage visual information to build human-like word representations from human-scale data",
    "checked": true,
    "id": "2d7df7c4632c757218009973200418346dc80fa4",
    "semantic_title": "visual grounding helps learn word meanings in low-data regimes",
    "citation_count": 3,
    "authors": [
      "Chengxu Zhuang",
      "Evelina Fedorenko",
      "Jacob Andreas"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.72": {
    "title": "Accurate Knowledge Distillation via n-best Reranking",
    "volume": "long",
    "abstract": "We propose utilizing n-best reranking to enhance Sequence-Level Knowledge Distillation (Kim and Rush, 2016) where we extract pseudo-labels for student model's training data from top n-best hypotheses and leverage a diverse set of models with different inductive biases, objective functions or architectures, including some publicly-available large language models, to pick the highest-quality hypotheses as labels. The effectiveness of our proposal is validated through experiments on the WMT'21 German ↔ English and Chinese ↔ English translation tasks. Our results demonstrate that utilizing pseudo-labels generated by our n-best reranker leads to a significantly more accurate student model. In fact, our best student model achieves comparable accuracy to a large translation model from (Tran et al., 2021) with 4.7 billion parameters, while having two orders of magnitude fewer parameters",
    "checked": true,
    "id": "a04628d231295627708074b36c45217e9d9eebcf",
    "semantic_title": "accurate knowledge distillation via n-best reranking",
    "citation_count": 0,
    "authors": [
      "Hendra Setiawan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.73": {
    "title": "AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition",
    "volume": "long",
    "abstract": "Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment. To address this challenge, in this paper, we propose a novel self-supervised framework **AutoPRM** that efficiently enhances the fine-tuning of LLMs for intricate reasoning challenges. Specifically, **AutoPRM** first decomposes complex problems into more manageable subquestions with a controllable granularity switch, then sequentially apply reinforcement learning to iteratively improve the subquestion solver. Additionally, we propose context-guided decoding to avoid reward tampering and guide the subquestion solver towards the solution of the holistic problem. Extensive experiments show that **AutoPRM** significantly improves performance on mathematical and commonsense reasoning tasks over SOTA. More encouragingly, **AutoPRM** can be easily integrated with other orthogonal reasoning pipelines",
    "checked": true,
    "id": "f346290ddd6f74c4cd4be04f323d90cd8b68f76f",
    "semantic_title": "autoprm: automating procedural supervision for multi-step reasoning via controllable question decomposition",
    "citation_count": 7,
    "authors": [
      "Zhaorun Chen",
      "Zhuokai Zhao",
      "Zhihong Zhu",
      "Ruiqi Zhang",
      "Xiang Li",
      "Bhiksha Raj",
      "Huaxiu Yao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.74": {
    "title": "SEMQA: Semi-Extractive Multi-Source Question Answering",
    "volume": "long",
    "abstract": "Recently proposed long-form question answering (QA) systems, supported by large language models (LLMs), have shown promising capabilities. Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.In this work, we introduce a new QA task for answering multi-answer questions by summarizing multiple diverse sources in a semi-extractive fashion. Specifically, Semi-extractive Multi-source QA (SEMQA) requires models to output a comprehensive answer, while mixing factual quoted spans—copied verbatim from given input sources—and non-factual free-text connectors that glue these spans together into a single cohesive passage. This setting bridges the gap between the outputs of well-grounded but constrained extractive QA systems and more fluent but harder to attribute fully abstractive answers. Particularly, it enables a new mode for language models that leverages their advanced language generation capabilities, while also producing fine in-line attributions by-design that are easy to verify, interpret, and evaluate. To study this task, we create the first dataset of this kind, QuoteSum, with human-written semi-extractive answers to natural and generated questions, and define text-based evaluation metrics. Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging, demonstrating the importance of QuoteSum for developing and studying such consolidation capabilities",
    "checked": true,
    "id": "8675a165b77b02859bdb27685004c58c7041c753",
    "semantic_title": "semqa: semi-extractive multi-source question answering",
    "citation_count": 5,
    "authors": [
      "Tal Schuster",
      "Adam Lelkes",
      "Haitian Sun",
      "Jai Gupta",
      "Jonathan Berant",
      "William Cohen",
      "Donald Metzler"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.75": {
    "title": "Fine-Tuning Language Models with Reward Learning on Policy",
    "volume": "long",
    "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as an effective approach to aligning large language models (LLMs) to human preferences.RLHF contains three steps, i.e., human preference collecting, reward learning, and policy optimization, which are usually performed serially.Despite its popularity, however, (fixed) reward models may suffer from inaccurate off-distribution, since policy optimization continuously shifts LLMs' data distribution.Repeatedly collecting new preference data from the latest LLMs may alleviate this issue, which unfortunately makes the resulting system more complicated and difficult to optimize.In this paper, we propose reward learning on policy (RLP), an unsupervised framework that refines a reward model using policy samples to keep it on-distribution.Specifically, an unsupervised multi-view learning method is introduced to learn robust representations of policy samples.Meanwhile, a synthetic preference generation approach is developed to simulate high-quality preference data with policy outputs.Extensive experiments on three benchmark datasets show that RLP consistently outperforms the state-of-the-art.Our code is available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/rlp",
    "checked": true,
    "id": "969c1dc38c98f2dbfb981a542880559890366494",
    "semantic_title": "fine-tuning language models with reward learning on policy",
    "citation_count": 0,
    "authors": [
      "Hao Lang",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.76": {
    "title": "A Universal Dependencies Treebank for Highland Puebla Nahuatl",
    "volume": "long",
    "abstract": "We present a Universal Dependencies (UD) treebank for Highland Puebla Nahuatl. The treebank is only the second such UD corpus for a Mexican language, and supplements an existing treebank for another Nahuatl variant. We describe the process of data collection, annotation decisions and interesting syntactic constructions, and discuss some similarities and differences between the Highland Puebla Nahuatl treebank and the existing Western Sierra Puebla Nahuatl treebank",
    "checked": true,
    "id": "7890d1a14da5f83504c25b003c3ac62beb507545",
    "semantic_title": "a universal dependencies treebank for highland puebla nahuatl",
    "citation_count": 0,
    "authors": [
      "Robert Pugh",
      "Francis Tyers"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.77": {
    "title": "COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances",
    "volume": "long",
    "abstract": "We present COPAL-ID, a novel, public Indonesian language common sense reasoning dataset. Unlike the previous Indonesian COPA dataset (XCOPA-ID), COPAL-ID incorporates Indonesian local and cultural nuances, and therefore, provides a more natural portrayal of day-to-day causal reasoning within the Indonesian cultural sphere. Professionally written by natives from scratch, COPAL-ID is more fluent and free from awkward phrases, unlike the translated XCOPA-ID. In addition, we present COPALID in both standard Indonesian and in Jakartan Indonesian–a dialect commonly used in daily conversation. COPAL-ID poses a greater challenge for existing open-sourced and closedstate-of-the-art multilingual language models, yet is trivially easy for humans. Our findings suggest that general multilingual models struggle to perform well, achieving 66.91% accuracy on COPAL-ID. South-East Asian-specific models achieve slightly better performance of 73.88% accuracy. Yet, this number still falls short of near-perfect human performance. This shows that these language models are still way behind in comprehending the local nuances of Indonesian",
    "checked": true,
    "id": "e1c7e3e6d81e41a5bb804337fe16346103051b56",
    "semantic_title": "copal-id: indonesian language reasoning with local culture and nuances",
    "citation_count": 9,
    "authors": [
      "Haryo Wibowo",
      "Erland Fuadi",
      "Made Nityasya",
      "Radityo Eko Prasojo",
      "Alham Aji"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.78": {
    "title": "IterAlign: Iterative Constitutional Alignment of Large Language Models",
    "volume": "long",
    "abstract": "With the rapid development of large language models (LLMs), aligning LLMs with human values and societal norms to ensure their reliability and safety has become crucial. Reinforcement learning with human feedback (RLHF) and Constitutional AI (CAI) have been proposed for LLM alignment. However, these methods require either heavy human annotations or explicitly pre-defined constitutions, which are labor-intensive and resource-consuming. To overcome these drawbacks, we study constitution-based LLM alignment and propose a data-driven constitution discovery and self-alignment framework called IterAlign. IterAlign leverages red teaming to unveil the weaknesses of an LLM and automatically discovers new constitutions using a stronger LLM. These constitutions are then used to guide self-correction of the base LLM. Such a constitution discovery pipeline can be run iteratively and automatically to discover new constitutions that specifically target the alignment gaps in the current LLM. Empirical results on several safety benchmark datasets and multiple base LLMs show that IterAlign successfully improves truthfulness, helpfulness, harmlessness and honesty, improving the LLM alignment by up to 13.5% in harmlessness",
    "checked": true,
    "id": "d7bc3fecc6372c9b3fe2d0581167f00caaf05f36",
    "semantic_title": "iteralign: iterative constitutional alignment of large language models",
    "citation_count": 0,
    "authors": [
      "Xiusi Chen",
      "Hongzhi Wen",
      "Sreyashi Nag",
      "Chen Luo",
      "Qingyu Yin",
      "Ruirui Li",
      "Zheng Li",
      "Wei Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.79": {
    "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking",
    "volume": "long",
    "abstract": "Large language models (LLMs) have revolutionized the landscape of Natural Language Processing, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Smaller Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. In dialogue state tracking tasks, the proposed routing framework enhances performance substantially compared to relying solely on LLMs, while reducing the computational costs by over 50%",
    "checked": true,
    "id": "0f5245e3a53f69f66b876173affe9309ee31e7d6",
    "semantic_title": "orchestrallm: efficient orchestration of language models for dialogue state tracking",
    "citation_count": 1,
    "authors": [
      "Chia-Hsuan Lee",
      "Hao Cheng",
      "Mari Ostendorf"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.80": {
    "title": "Multi-Operational Mathematical Derivations in Latent Space",
    "volume": "long",
    "abstract": "This paper investigates the possibility of approximating multiple mathematical operations in latent space for expression derivation. To this end, we introduce different multi-operational representation paradigms, modelling mathematical operations as explicit geometric transformations. By leveraging a symbolic engine, we construct a large-scale dataset comprising 1.7M derivation steps stemming from 61K premises and 6 operators, analysing the properties of each paradigm when instantiated with state-of-the-art neural encoders.Specifically, we investigate how different encoding mechanisms can approximate expression manipulation in latent space, exploring the trade-off between learning different operators and specialising within single operations, as well as the ability to support multi-step derivations and out-of-distribution generalisation. Our empirical analysis reveals that the multi-operational paradigm is crucial for disentangling different operators, while discriminating the conclusions for a single operation is achievable in the original expression encoder. Moreover, we show that architectural choices can heavily affect the training dynamics, structural organisation, and generalisation of the latent space, resulting in significant variations across paradigms and classes of encoders",
    "checked": true,
    "id": "c22cc4e2eed78b4b31e50d94ea35da0405aabb87",
    "semantic_title": "multi-operational mathematical derivations in latent space",
    "citation_count": 5,
    "authors": [
      "Marco Valentino",
      "Jordan Meadows",
      "Lan Zhang",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.81": {
    "title": "Large Language Models Help Humans Verify Truthfulness – Except When They Are Convincingly Wrong",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are increasingly used for accessing information on the web. Their truthfulness and factuality are thus of great interest. To help users make the right decisions about the information they get, LLMs should not only provide information but also help users fact-check it. We conduct human experiments with 80 crowdworkers to compare language models with search engines (information retrieval systems) at facilitating fact-checking. We prompt LLMs to validate a given claim and provide corresponding explanations. Users reading LLM explanations are significantly more efficient than those using search engines while achieving similar accuracy. However, they over-rely on the LLMs when the explanation is wrong. To reduce over-reliance on LLMs, we ask LLMs to provide contrastive information—explain both why the claim is true and false, and then we present both sides of the explanation to users. This contrastive explanation mitigates users' over-reliance on LLMs, but cannot significantly outperform search engines. Further, showing both search engine results and LLM explanations offers no complementary benefits compared to search engines alone. Taken together, our study highlights that natural language explanations by LLMs may not be a reliable replacement for reading the retrieved passages, especially in high-stakes settings where over-relying on wrong AI explanations could lead to critical consequences",
    "checked": true,
    "id": "4bc486c6489fd4cdf8fc9d9c6e77279366824b49",
    "semantic_title": "large language models help humans verify truthfulness – except when they are convincingly wrong",
    "citation_count": 12,
    "authors": [
      "Chenglei Si",
      "Navita Goyal",
      "Tongshuang Wu",
      "Chen Zhao",
      "Shi Feng",
      "Hal Daumé Iii",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.82": {
    "title": "XferBench: a Data-Driven Benchmark for Emergent Language",
    "volume": "long",
    "abstract": "In this paper, we introduce a benchmark for evaluating the overall quality of emergent languages using data-driven methods. Specifically, we interpret the notion of the \"quality\" of an emergent language as its similarity to human language within a deep learning framework. We measure this by using the emergent language as pretraining data for a downstream NLP tasks in human language—the better the downstream performance, the better the emergent language. We implement this benchmark as an easy-to-use Python package that only requires a text file of utterances from the emergent language to be evaluated. Finally, we empirically test the benchmark's validity using human, synthetic, and emergent language baselines",
    "checked": true,
    "id": "a535e1b2b9ee7abdde10787a09c19ed07a481d25",
    "semantic_title": "xferbench: a data-driven benchmark for emergent language",
    "citation_count": 0,
    "authors": [
      "Brendon Boldt",
      "David Mortensen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.83": {
    "title": "Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation",
    "volume": "long",
    "abstract": "Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies",
    "checked": true,
    "id": "d749810bb631947fbd9d21fa312a8bd9e8496ceb",
    "semantic_title": "evaluating large language models as generative user simulators for conversational recommendation",
    "citation_count": 3,
    "authors": [
      "Se-eun Yoon",
      "Zhankui He",
      "Jessica Echterhoff",
      "Julian McAuley"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.84": {
    "title": "A Symbolic Framework for Evaluating Mathematical Reasoning and Generalisation with Transformers",
    "volume": "long",
    "abstract": "This paper proposes a methodology for generating and perturbing detailed derivations of equations at scale, aided by a symbolic engine, to evaluate the generalisability of Transformers to out-of-distribution mathematical reasoning problems. Instantiating the framework in the context of sequence classification tasks, we compare the capabilities of GPT-4, GPT-3.5, and a canon of fine-tuned BERT models, exploring the relationship between specific operators and generalisation failure via the perturbation of reasoning aspects such as symmetry and variable surface forms. Surprisingly, our empirical evaluation reveals that the average in-distribution performance of fine-tuned models surpasses GPT-3.5, and rivals GPT-4. However, perturbations to input reasoning can reduce their performance by up to 80 F1 points. Overall, the results suggest that the in-distribution performance of smaller open-source models may potentially rival GPT by incorporating appropriately structured derivation dependencies during training, and highlight a shared weakness between BERT and GPT involving a relative inability to decode indirect references to mathematical entities. We release the full codebase, constructed datasets, and fine-tuned models to encourage future progress in the field",
    "checked": true,
    "id": "ad73c9595878d826da5450685d4bdbb7a9fb2df3",
    "semantic_title": "a symbolic framework for evaluating mathematical reasoning and generalisation with transformers",
    "citation_count": 6,
    "authors": [
      "Jordan Meadows",
      "Marco Valentino",
      "Damien Teney",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.85": {
    "title": "Identifying Linear Relational Concepts in Large Language Models",
    "volume": "long",
    "abstract": "Transformer language models (LMs) have been shown to represent concepts as directions in the latent space of hidden activations. However, for any human-interpretable concept, how can we find its direction in the latent space? We present a technique called linear relational concepts (LRC) for finding concept directions corresponding to human-interpretable concepts by first modeling the relation between subject and object as a linear relational embedding (LRE). We find that inverting the LRE and using earlier object layers results in a powerful technique for finding concept directions that outperforms standard black-box probing classifiers. We evaluate LRCs on their performance as concept classifiers as well as their ability to causally change model output",
    "checked": true,
    "id": "be431d20e27bafc584858bb76ba41b483cfd514b",
    "semantic_title": "identifying linear relational concepts in large language models",
    "citation_count": 1,
    "authors": [
      "David Chanin",
      "Anthony Hunter",
      "Oana-Maria Camburu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.86": {
    "title": "Benchmark Transparency: Measuring the Impact of Data on Evaluation",
    "volume": "long",
    "abstract": "In this paper we present an exploratory research on quantifying the impact that data distribution has on the performance and evaluation of NLP models. We propose an automated framework that measures the data point distribution across 6 different dimensions: ambiguity, difficulty, discriminability, length, noise, and perplexity.We use disproportional stratified sampling to measure how much the data distribution affects absolute (Acc/F1) and relative (Rank) model performance. We experiment on 2 different datasets (SQUAD and MNLI) and test a total of 135 different models (125 on SQUAD and 10 on MNLI). We demonstrate that without explicit control of the data distribution, standard evaluation frameworks are inconsistent and unreliable. We find that the impact of the data is statistically significant and is often larger than the impact of changing the metric. In a second set of experiments, we demonstrate that the impact of data on evaluation is not just observable, but also predictable. We propose to use benchmark transparency as a method for comparing datasets and quantifying the similarity between them. We find that the \"dataset similarity vector\" can be used to predict how well a model generalizes out of distribution",
    "checked": true,
    "id": "41be712a6d137c67d8809f261afacac482b1ee6f",
    "semantic_title": "benchmark transparency: measuring the impact of data on evaluation",
    "citation_count": 0,
    "authors": [
      "Venelin Kovatchev",
      "Matthew Lease"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.87": {
    "title": "JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models",
    "volume": "long",
    "abstract": "The permanence of online content combined with the enhanced authorship identification techniques calls for stronger computational methods to protect the identity and privacy of online authorship when needed, e.g., blind reviews for scientific papers, anonymous online reviews, or anonymous interactions in the mental health forums. In this paper, we propose an unsupervised inference-time approach to authorship obfuscation to address the unique challenges of authorship obfuscation: lack of supervision data for diverse authorship and domains, and the need for a sufficient level of revision beyond simple paraphrasing to obfuscate the authorship, all the while preserving the original content and fluency.We introduce JAMDEC, a user-controlled, inference-time algorithm for authorship obfuscation that can be in principle applied to any text and authorship. Our approach builds on small language models such as GPT2-XL in order to help avoid disclosing the original content to proprietary LLM's APIs, while also reducing the performance gap between small and large language models via algorithmic enhancement. The key idea behind our approach is to boost the creative power of smaller language models through constrained decoding, while also allowing for user-specified controls and flexibility. Experimental results demonstrate that our approach based on GPT2-XL outperforms previous state-of-the-art methods based on comparably small models, while performing competitively against GPT3.5 175B, a propriety model that is two orders of magnitudes larger",
    "checked": true,
    "id": "e1c8f6e56ad2a1e7e3ed150e2411dcca85d19b69",
    "semantic_title": "jamdec: unsupervised authorship obfuscation using constrained decoding over small language models",
    "citation_count": 0,
    "authors": [
      "Jillian Fisher",
      "Ximing Lu",
      "Jaehun Jung",
      "Liwei Jiang",
      "Zaid Harchaoui",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.88": {
    "title": "REST: Retrieval-Based Speculative Decoding",
    "volume": "long",
    "abstract": "We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm designed to speed up language model generation. The key insight driving the development of REST is the observation that the process of text generation often includes certain common phases and patterns. Unlike previous methods that rely on a draft language model for speculative decoding, REST harnesses the power of retrieval to generate draft tokens. This method draws from the reservoir of existing knowledge, retrieving and employing relevant tokens based on the current context. Its plug-and-play nature allows for seamless integration and acceleration of any language model, all without necessitating additional training. When benchmarked on 7B and 13B language models in a single-batch setting, REST achieves a significant speedup of 1.62 × to 2.36 × on code or text generation. The source code of REST is available at https://github.com/FasterDecoding/REST",
    "checked": true,
    "id": "532c2c7a247d9e97d20abec1b2f4612984fdab93",
    "semantic_title": "rest: retrieval-based speculative decoding",
    "citation_count": 23,
    "authors": [
      "Zhenyu He",
      "Zexuan Zhong",
      "Tianle Cai",
      "Jason Lee",
      "Di He"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.89": {
    "title": "Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic Representations",
    "volume": "long",
    "abstract": "We introduce sub-sentence encoder, a contrastively-learned contextual embedding model for fine-grained semantic representation of text. In contrast to the standard practice with sentence embeddings, where the meaning of an entire sequence of text is encoded into a fixed-length vector, the sub-sentence encoder learns to produce distinct contextual embeddings corresponding to different atomic propositions, i.e. atomic units of meaning expressed within a text sequence. The sub-sentence embeddings are contrastively learned to recognize (inferred) semantic equivalence between propositions across different text sequences. Our experiments show the effectiveness of sub-sentence encoders in applications, such as retrieving supporting facts for fine-grained text attribution or recognizing the conditional semantic similarity between texts. In practice, we demonstrate that sub-sentence encoders keep the same level of inference cost and space complexity compared to sentence encoders",
    "checked": true,
    "id": "d7503ed68591088a21e4d8c0c0d92b29885c8d66",
    "semantic_title": "sub-sentence encoder: contrastive learning of propositional semantic representations",
    "citation_count": 6,
    "authors": [
      "Sihao Chen",
      "Hongming Zhang",
      "Tong Chen",
      "Ben Zhou",
      "Wenhao Yu",
      "Dian Yu",
      "Baolin Peng",
      "Hongwei Wang",
      "Dan Roth",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.90": {
    "title": "MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference",
    "volume": "long",
    "abstract": "The task of scientific Natural Language Inference (NLI) involves predicting the semantic relation between two sentences extracted from research articles. This task was recently proposed along with a new dataset called SciNLI derived from papers published in the computational linguistics domain. In this paper, we aim to introduce diversity in the scientific NLI task and present MSciNLI, a dataset containing 132,320 sentence pairs extracted from five new scientific domains. The availability of multiple domains makes it possible to study domain shift for scientific NLI. We establish strong baselines on MSciNLI by fine-tuning Pre-trained Language Models (PLMs) and prompting Large Language Models (LLMs). The highest Macro F1 scores of PLM and LLM baselines are 77.21% and 51.77%, respectively, illustrating that MSciNLI is challenging for both types of models. Furthermore, we show that domain shift degrades the performance of scientific NLI models which demonstrates the diverse characteristics of different domains in our dataset. Finally, we use both scientific NLI datasets in an intermediate task transfer learning setting and show that they can improve the performance of downstream tasks in the scientific domain. We make our dataset and code available on Github",
    "checked": true,
    "id": "759716e988392bb7744f0213d6e09e24fe0a4590",
    "semantic_title": "mscinli: a diverse benchmark for scientific natural language inference",
    "citation_count": 0,
    "authors": [
      "Mobashir Sadat",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.91": {
    "title": "Causal Inference for Human-Language Model Collaboration",
    "volume": "long",
    "abstract": "In this paper, we examine the collaborative dynamics between humansand language models (LMs), where the interactions typically involveLMs proposing text segments and humans editing or responding to theseproposals. Productive engagement with LMs in such scenarios necessitates that humans discern effective text-based interaction strategies, such as editing and response styles, from historical human-LM interactions. This objective is inherently causal, driven by the counterfactual ‘what-if' question: how would the outcome of collaboration change if humans employed a different text editing/refinement strategy? A key challenge in answering this causal inference question is formulating an appropriate causal estimand: the conventional average treatment effect (ATE) estimand is inapplicable to text-based treatments due to their high dimensionality. To address this concern, we introduce a new causal estimand– *Incremental Stylistic Effect (ISE)*, which characterizes the average impact of infinitesimally shifting a text towards a specific style, such as increasing formality. We establish the conditions for the non-parametric identification of ISE. Building on this, we develop *CausalCollab*, an algorithm designed to estimate the ISE of various interaction strategies in dynamic human-LM collaborations. Our empirical investigations across three distinct human-LM collaboration scenarios reveal that *CausalCollab* effectively reduces confounding and significantly improves counterfactual estimation over a set of competitive baselines",
    "checked": true,
    "id": "7f1d9ca9fdde964ecea483d55ba83f91078b73a9",
    "semantic_title": "causal inference for human-language model collaboration",
    "citation_count": 0,
    "authors": [
      "Bohan Zhang",
      "Yixin Wang",
      "Paramveer Dhillon"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.92": {
    "title": "SELF-GUARD: Empower the LLM to Safeguard Itself",
    "volume": "long",
    "abstract": "With the increasing risk posed by jailbreak attacks, recent studies have investigated various methods to improve the safety of large language models (LLMs), mainly falling into two strategies: safety training and safeguards. Safety training involves fine-tuning the LLM with adversarial samples, which activate the LLM's capabilities against jailbreak. However, it is not always effective in countering new attacks and often leads to potential performance degradation. Safeguards, on the other hand, are methods using additional models to filter harmful content from the LLM's response. Nevertheless, they can only reduce a limited amount of harmful output and introduce extra computational costs. Given the distinct strengths and weaknesses of both, we combine them to balance out their flaws and propose a more effective method called Self-Guard.Specifically, we train the LLM to review its responses for any harmful content and append a [harmful] or [harmless] tag to the end of the response. In this way, Self-Guard possesses the advantages of safety training, leveraging the powerful capabilities of the LLMs themselves to detect harmfulness. Besides that, it gains flexibility like safeguards, making the safety check target the output side, which makes the system less vulnerable to attack updates. Experimental results indicate that our Self-Guard can effectively defend against jailbreak attacks and will not cause LLMs' performance degradation",
    "checked": true,
    "id": "c7ad19da81e24c387f0377fef6d19b0fce2cf470",
    "semantic_title": "self-guard: empower the llm to safeguard itself",
    "citation_count": 4,
    "authors": [
      "Zezhong Wang",
      "Fangkai Yang",
      "Lu Wang",
      "Pu Zhao",
      "Hongru Wang",
      "Liang Chen",
      "Qingwei Lin",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.93": {
    "title": "COSIGN: Contextual Facts Guided Generation for Knowledge Graph Completion",
    "volume": "long",
    "abstract": "Knowledge graph completion (KGC) aims to infer missing facts based on existing facts within a KG. Recently, research on generative models (GMs) has addressed the limitations of embedding methods in terms of generality and scalability. However, GM-based methods are sensitive to contextual facts on KG, so the contextual facts of poor quality can cause GMs to generate erroneous results. To improve the performance of GM-based methods for various KGC tasks, we propose a COntextual FactS GuIded GeneratioN (COSIGN) model. First, to enhance the inference ability of the generative model, we designed a contextual facts collector to achieve human-like retrieval behavior. Second, a contextual facts organizer is proposed to learn the organized capabilities of LLMs through knowledge distillation. Finally, the organized contextual facts as the input of the inference generator to generate missing facts. Experimental results demonstrate that COSIGN outperforms state-of-the-art baseline techniques in terms of performance",
    "checked": true,
    "id": "d66622beef468f7b934a5bf601cb8a3fcefe78f3",
    "semantic_title": "cosign: contextual facts guided generation for knowledge graph completion",
    "citation_count": 0,
    "authors": [
      "Jinpeng Li",
      "Hang Yu",
      "Xiangfeng Luo",
      "Qian Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.94": {
    "title": "Toward Informal Language Processing: Knowledge of Slang in Large Language Models",
    "volume": "long",
    "abstract": "Recent advancement in large language models (LLMs) has offered a strong potential for natural language systems to process informal language. A representative form of informal language is slang, used commonly in daily conversations and online social media. To date, slang has not been comprehensively evaluated in LLMs due partly to the absence of a carefully designed and publicly accessible benchmark. Using movie subtitles, we construct a dataset that supports evaluation on a diverse set of tasks pertaining to automatic processing of slang. For both evaluation and finetuning, we show the effectiveness of our dataset on two core applications: 1) slang detection, and 2) identification of regional and historical sources of slang from natural sentences. We also show how our dataset can be used to probe the output distributions of LLMs for interpretive insights. We find that while LLMs such as GPT-4 achieve good performance in a zero-shot setting, smaller BERT-like models finetuned on our dataset achieve comparable performance. Furthermore, we show that our dataset enables finetuning of LLMs such as GPT-3.5 that achieve substantially better performance than strong zero-shot baselines. Our work offers a comprehensive evaluation and a high-quality benchmark on English slang based on the OpenSubtitles corpus, serving both as a publicly accessible resource and a platform for applying tools for informal language processing",
    "checked": true,
    "id": "5465f9e89bbdf3090d3e4ca793723a56098347db",
    "semantic_title": "toward informal language processing: knowledge of slang in large language models",
    "citation_count": 0,
    "authors": [
      "Zhewei Sun",
      "Qian Hu",
      "Rahul Gupta",
      "Richard Zemel",
      "Yang Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.95": {
    "title": "Ghostbuster: Detecting Text Ghostwritten by Large Language Models",
    "volume": "long",
    "abstract": "We introduce Ghostbuster, a state-of-the-art system for detecting AI-generated text.Our method works by passing documents through a series of weaker language models, running a structured search over possible combinations of their features, and then training a classifier on the selected features to predict whether documents are AI-generated.Crucially, Ghostbuster does not require access to token probabilities from the target model, making it useful for detecting text generated by black-box or unknown models.In conjunction with our model, we release three new datasets of human- and AI-generated text as detection benchmarks in the domains of student essays, creative writing, and news articles. We compare Ghostbuster to several existing detectors, including DetectGPT and GPTZero, as well as a new RoBERTa baseline. Ghostbuster achieves 99.0 F1 when evaluated across domains, which is 5.9 F1 higher than the best preexisting model. It also outperforms all previous approaches in generalization across writing domains (+7.5 F1), prompting strategies (+2.1 F1), and language models (+4.4 F1). We also analyze our system's robustness to a variety of perturbations and paraphrasing attacks, and evaluate its performance on documents by non-native English speakers",
    "checked": true,
    "id": "fb467f368b9e196b32c90e3da7ae0986d59cd66f",
    "semantic_title": "ghostbuster: detecting text ghostwritten by large language models",
    "citation_count": 15,
    "authors": [
      "Vivek Verma",
      "Eve Fleisig",
      "Nicholas Tomlin",
      "Dan Klein"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.96": {
    "title": "End-to-End Beam Retrieval for Multi-Hop Question Answering",
    "volume": "long",
    "abstract": "Multi-hop question answering (QA) involves finding multiple relevant passages and step-by-step reasoning to answer complex questions, indicating a retrieve-and-read paradigm. However, previous retrievers were customized for two-hop questions, and most of them were trained separately across different hops, resulting in a lack of supervision over the entire multi-hop retrieval process and leading to poor performance in complicated scenarios beyond two hops. In this work, we introduce Beam Retrieval, an end-to-end beam retrieval framework for multi-hop QA. This approach models the multi-hop retrieval process in an end-to-end manner by jointly optimizing an encoder and two classification heads across all hops. Moreover, Beam Retrieval maintains multiple partial hypotheses of relevant passages at each step, expanding the search space and reducing the risk of missing relevant passages. To establish a complete QA system, we incorporate a supervised reader or a large language model (LLM). Experimental results demonstrate that Beam Retrieval achieves a nearly 50% improvement compared with baselines on challenging MuSiQue-Ans, and it also surpasses all previous retrievers on HotpotQA and achieves 99.9% precision on 2WikiMultiHopQA. Providing high-quality context, Beam Retrieval helps our supervised reader achieve new state-of-the-art performance and substantially improves the few-shot QA performance of LLMs",
    "checked": true,
    "id": "e5a0189334ab947ac34247015774fdaec032d2a5",
    "semantic_title": "end-to-end beam retrieval for multi-hop question answering",
    "citation_count": 7,
    "authors": [
      "Jiahao Zhang",
      "Haiyang Zhang",
      "Dongmei Zhang",
      "Liu Yong",
      "Shen Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.97": {
    "title": "Leveraging Generative Large Language Models with Visual Instruction and Demonstration Retrieval for Multimodal Sarcasm Detection",
    "volume": "long",
    "abstract": "Multimodal sarcasm detection aims to identify sarcasm in the given image-text pairs and has wide applications in the multimodal domains. Previous works primarily design complex network structures to fuse the image-text modality features for classification. However, such complicated structures may risk overfitting on in-domain data, reducing the performance in out-of-distribution (OOD) scenarios. Additionally, existing methods typically do not fully utilize cross-modal features, limiting their performance on in-domain datasets. Therefore, to build a more reliable multimodal sarcasm detection model, we propose a generative multimodal sarcasm model consisting of a designed instruction template and a demonstration retrieval module based on the large language model. Moreover, to assess the generalization of current methods, we introduce an OOD test set, RedEval. Experimental results demonstrate that our method is effective and achieves state-of-the-art (SOTA) performance on the in-domain MMSD2.0 and OOD RedEval datasets",
    "checked": true,
    "id": "ef224b1a0af6ef644bfb75c7193e967442b9a78c",
    "semantic_title": "leveraging generative large language models with visual instruction and demonstration retrieval for multimodal sarcasm detection",
    "citation_count": 1,
    "authors": [
      "Binghao Tang",
      "Boda Lin",
      "Haolong Yan",
      "Si Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.98": {
    "title": "Multi-Scale Prompt Memory-Augmented Model for Black-Box Scenarios",
    "volume": "long",
    "abstract": "Black-box few-shot text classification handles text classification in limited data without accessing the parameters and gradients of language models (LMs). Existing black-box optimization methods have demonstrated strong few-shot learning capabilities. However, they still require numerous LMs' calls to search optimal prompts, thus resulting in overfitting performance and increasing computational cost. To address this issue, we present MuSKPrompt (Multi-scale Knowledge Prompt for Memory Model), an efficient multi-scale knowledge prompt-based memory model in black-box few-shot text classification task. MuSKPrompt extracts instance-level and class-level knowledge at different scales and stores them in memory banks during training. Then, it references multi-scale memory banks to perform quick inference on new samples via a novel scoring module. MuSKPrompt achieves competitive performance in limited data through multi-scale instance-level and class-level knowledge. Moreover, it realizes gradient-free optimization with zero training parameters in the black-box scenario. Experiments on different benchmarks and parameter analysis demonstrate the effectiveness and efficiency of MuSKPrompt in black-box few-shot text classification tasks",
    "checked": true,
    "id": "5afe312885c74246a3ff6b7cdb0f814bf74e1fad",
    "semantic_title": "multi-scale prompt memory-augmented model for black-box scenarios",
    "citation_count": 0,
    "authors": [
      "Xiaojun Kuang",
      "C. L. Philip Chen",
      "Shuzhen Li",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.99": {
    "title": "Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction",
    "volume": "long",
    "abstract": "In the era of large language models (LLMs), in-context learning (ICL) stands out as an effective prompting strategy that explores LLMs' potency across various tasks. However, applying LLMs to grammatical error correction (GEC) is still a challenging task. In this paper, we propose a novel ungrammatical-syntax-based in-context example selection strategy for GEC. Specifically, we measure similarity of sentences based on their syntactic structures with diverse algorithms, and identify optimal ICL examples sharing the most similar ill-formed syntax to the test input. Additionally, we carry out a two-stage process to further improve the quality of selection results. On benchmark English GEC datasets, empirical results show that our proposed ungrammatical-syntax-based strategies outperform commonly-used word-matching or semantics-based methods with multiple LLMs. This indicates that for a syntax-oriented task like GEC, paying more attention to syntactic information can effectively boost LLMs' performance. Our code is available at https://github.com/JamyDon/SynICL4GEC",
    "checked": true,
    "id": "6b5bf715cd1027768e6632a45e53f5c00fa60cce",
    "semantic_title": "ungrammatical-syntax-based in-context example selection for grammatical error correction",
    "citation_count": 0,
    "authors": [
      "Chenming Tang",
      "Fanyi Qu",
      "Yunfang Wu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.100": {
    "title": "BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer",
    "volume": "long",
    "abstract": "Despite remarkable advancements in few-shot generalization in natural language processing, most models are developed and evaluated primarily in English. To establish a rigorous and equitable evaluation framework for few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions. Using BUFFET, we perform thorough evaluations of ten state-of-the-art multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. Strong multilingual pre-trained or instruction-tuned models such as BLOOM or ChatGPT often lag behind much smaller mT5-base models given the same number of few-shot samples, particularly in low-resource languages. Our analysis suggests avenues for future research in few-shot cross-lingual transfer",
    "checked": true,
    "id": "c1c98ef93fb6474837961ef300cf3d8e7d3a0cd0",
    "semantic_title": "buffet: benchmarking large language models for few-shot cross-lingual transfer",
    "citation_count": 30,
    "authors": [
      "Akari Asai",
      "Sneha Kudugunta",
      "Xinyan Yu",
      "Terra Blevins",
      "Hila Gonen",
      "Machel Reid",
      "Yulia Tsvetkov",
      "Sebastian Ruder",
      "Hannaneh Hajishirzi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.101": {
    "title": "TISE: A Tripartite In-context Selection Method for Event Argument Extraction",
    "volume": "long",
    "abstract": "In-context learning enhances the reasoning capabilities of LLMs by providing several examples. A direct yet effective approach to obtain in-context example is to select the top-k examples based on their semantic similarity to the test input. However, when applied to event argument extraction (EAE), this approach exhibits two shortcomings: 1) It may select almost identical examples, thus failing to provide additional event information, and 2) It overlooks event attributes, leading to the selected examples being unrelated to the test event type. In this paper, we introduce three necessary requirements when selecting an in-context example for EAE task: semantic similarity, example diversity and event correlation. And we further propose TISE, which scores examples from these three perspectives and integrates them using Determinantal Point Processes to directly select a set of examples as context. Experimental results on the ACE05 dataset demonstrate the effectiveness of TISE and the necessity of three requirements. Furthermore, we surprisingly observe that TISE can achieve superior performance with fewer examples and can even exceed some supervised methods",
    "checked": true,
    "id": "ff441dd0c222c24c2c4528c3e32244e98d300828",
    "semantic_title": "tise: a tripartite in-context selection method for event argument extraction",
    "citation_count": 0,
    "authors": [
      "Yanhe Fu",
      "Yanan Cao",
      "Qingyue Wang",
      "Yi Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.102": {
    "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
    "volume": "long",
    "abstract": "The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on \"counterfactual\" task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to an extent, they often also rely on narrow, non-transferable procedures for task-solving. These results motivate a more careful interpretation of language model performance that teases apart these aspects",
    "checked": true,
    "id": "f8e99be4f9a01761fab74bade2c3c18de9fc686b",
    "semantic_title": "reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks",
    "citation_count": 82,
    "authors": [
      "Zhaofeng Wu",
      "Linlu Qiu",
      "Alexis Ross",
      "Ekin Akyürek",
      "Boyuan Chen",
      "Bailin Wang",
      "Najoung Kim",
      "Jacob Andreas",
      "Yoon Kim"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.103": {
    "title": "TRUE-UIE: Two Universal Relations Unify Information Extraction Tasks",
    "volume": "long",
    "abstract": "Information extraction (IE) encounters challenges due to the variety of schemas and objectives that differ across tasks. Recent advancements hint at the potential for universal approaches to model such tasks, referred to as Universal Information Extraction (UIE). While handling diverse tasks in one model, their generalization is limited since they are actually learning task-specific knowledge.In this study, we introduce an innovative paradigm known as TRUE-UIE, wherein all IE tasks are aligned to learn the same goals: extracting mention spans and two universal relations named \\mathtt{NEXT} and \\mathtt{IS}. During the decoding process, the \\mathtt{NEXT} relation is utilized to group related elements, while the \\mathtt{IS} relation, in conjunction with structured language prompts, undertakes the role of type recognition. Additionally, we consider the sequential dependency of tokens during span extraction, an aspect often overlooked in prevalent models.Our empirical experiments indicate that TRUE-UIE achieves state-of-the-art performance on established benchmarks encompassing 16 datasets, spanning 7 diverse IE tasks. Further evaluations reveal that our approach effectively share knowledge between different IE tasks, showcasing significant transferability in zero-shot and few-shot scenarios",
    "checked": true,
    "id": "8d9489dde0aa56c6b2dcde532fa84fa4efdc18ae",
    "semantic_title": "true-uie: two universal relations unify information extraction tasks",
    "citation_count": 0,
    "authors": [
      "Yucheng Wang",
      "Bowen Yu",
      "Yilin Liu",
      "Shudong Lu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.104": {
    "title": "zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models",
    "volume": "long",
    "abstract": "Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, where hidden representations are learned to represent knowledge graph (KG) entities and relations based on the observed graph contexts. Although these methods show strong performance on traditional TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the unseen zero-shot relations that have no prior graph context. In this paper, we try to mitigate this problem as follows. We first input the text descriptions of KG relations into large language models (LLMs) for generating relation representations, and then introduce them into embedding-based TKGF methods. LLM-empowered representations can capture the semantic information in the relation descriptions. This makes the relations, whether seen or unseen, with similar semantic meanings stay close in the embedding space, enabling TKGF models to recognize zero-shot relations even without any observed graph context. Experimental results show that our approach helps TKGF models to achieve much better performance in forecasting the facts with previously unseen relations, while still maintaining their ability in link forecasting regarding seen relations",
    "checked": true,
    "id": "1a10ff8e42059451b1e0a40d1732175d0386a744",
    "semantic_title": "zrllm: zero-shot relational learning on temporal knowledge graphs with large language models",
    "citation_count": 2,
    "authors": [
      "Zifeng Ding",
      "Heling Cai",
      "Jingpei Wu",
      "Yunpu Ma",
      "Ruotong Liao",
      "Bo Xiong",
      "Volker Tresp"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.105": {
    "title": "Embodied Executable Policy Learning with Language-based Scene Summarization",
    "volume": "long",
    "abstract": "Large Language models (LLMs) have shown remarkable success in assisting robot learning tasks, i.e., complex household planning.However, the performance of pretrained LLMs heavily relies on domain-specific templated text data, which may be infeasible in real-world robot learning tasks with image-based observations. Moreover, existing LLMs with text inputs lack the capability to evolve with non-expert interactions with environments.In this work, we introduce a novel learning paradigm that generates robots' executable actions in the form of text, derived solely from visual observations. Our proposed paradigm stands apart from previous works, which utilized either language instructions or a combination of language and visual data as inputs. We demonstrate that our proposed method can employ two fine-tuning strategies, including imitation learning and reinforcement learning approaches, to adapt to the target test tasks effectively.We conduct extensive experiments involving various model selections, environments, and tasks across 7 house layouts in the VirtualHome environment. Our experimental results demonstrate that our method surpasses existing baselines, confirming the effectiveness of this novel learning paradigm",
    "checked": true,
    "id": "82da02137bae421a3f7a89c3bf2ab662037f4dfa",
    "semantic_title": "embodied executable policy learning with language-based scene summarization",
    "citation_count": 2,
    "authors": [
      "Jielin Qiu",
      "Mengdi Xu",
      "William Han",
      "Seungwhan Moon",
      "Ding Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.106": {
    "title": "Metacognitive Prompting Improves Understanding in Large Language Models",
    "volume": "long",
    "abstract": "In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. Recent advancements in prompting have enhanced reasoning in logic-intensive tasks for LLMs, yet the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. We conduct extensive experiments on four prevalent LLMs: Llama2, PaLM2, GPT-3.5, and GPT-4, across ten natural language understanding (NLU) datasets from GLUE, SuperGLUE, BLUE, and LexGLUE benchmarks. Additionally, we compare our method with chain-of-thought prompting and its advanced versions. The results show that GPT-4 consistently excels across all tasks, while other models have shown significant progress in some tasks when used in conjunction with MP. Furthermore, MP consistently outperforms existing prompting methods in both general and domain-specific NLU tasks. This study underscores the potential to amplify the understanding abilities of LLMs and highlights the benefits of mirroring human introspective reasoning in NLU tasks",
    "checked": true,
    "id": "896ca0a68e4d33d76a7366bcab85eb7d2605a8c4",
    "semantic_title": "metacognitive prompting improves understanding in large language models",
    "citation_count": 9,
    "authors": [
      "Yuqing Wang",
      "Yun Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.107": {
    "title": "MART: Improving LLM Safety with Multi-round Automatic Red-Teaming",
    "volume": "long",
    "abstract": "Red-teaming is a common practice for mitigating unsafe behaviors in Large Language Models (LLMs), which involves thoroughly assessing LLMs to identify potential flaws and addressing them with responsible and accurate responses.While effective, manual red-teaming is costly, and existing automatic red-teaming typically discovers safety risks without addressing them.In this paper, we propose a Multi-round Automatic Red-Teaming (MART) method, which incorporates both automatic adversarial prompt writing and safe response generation, significantly increasing red-teaming scalability and the safety of the target LLM.Specifically, an adversarial LLM and a target LLM interplay with each other in an iterative manner, where the adversarial LLM aims to generate challenging prompts that elicit unsafe responses from the target LLM, while the target LLM is fine-tuned with safety aligned data on these adversarial prompts. In each round, the adversarial LLM crafts better attacks on the updated target LLM, while the target LLM also improves itself through safety fine-tuning.On adversarial prompt benchmarks, the violation rate of an LLM with limited safety alignment reduces up to 84.7% after 4 rounds of MART, achieving comparable performance to LLMs with extensive adversarial prompt writing. Notably, model helpfulness on non-adversarial prompts remains stable throughout iterations, indicating the target LLM maintains strong performance on instruction following",
    "checked": true,
    "id": "709af143f78bc62413c50ea1a7ee75b0702c4f59",
    "semantic_title": "mart: improving llm safety with multi-round automatic red-teaming",
    "citation_count": 29,
    "authors": [
      "Suyu Ge",
      "Chunting Zhou",
      "Rui Hou",
      "Madian Khabsa",
      "Yi-Chia Wang",
      "Qifan Wang",
      "Jiawei Han",
      "Yuning Mao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.108": {
    "title": "DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset",
    "volume": "long",
    "abstract": "As sharing images in an instant message is a crucial factor, there has been active research on learning an image-text multi-modal dialogue models.However, training a well-generalized multi-modal dialogue model remains challenging due to the low quality and limited diversity of images per dialogue in existing multi-modal dialogue datasets.In this paper, we propose an automated pipeline to construct a multi-modal dialogue dataset, ensuring both dialogue quality and image diversity without requiring minimum human effort. In our pipeline, to guarantee the coherence between images and dialogue, we prompt GPT-4 to infer potential image-sharing moments - specifically, the utterance, speaker, rationale, and image description. Furthermore, we leverage CLIP similarity to maintain consistency between aligned multiple images to the utterance.Through this pipeline, we introduce DialogCC, a high-quality and diverse multi-modal dialogue dataset that surpasses existing datasets in terms of quality and diversity in human evaluation.Our comprehensive experiments highlight that when multi-modal dialogue models are trained using our dataset, their generalization performance on unseen dialogue datasets is significantly enhanced. We make our source code and dataset publicly available (https://dialogcc.github.io/)",
    "checked": true,
    "id": "a85ae093657f62bf13bf18b0652402026dd4186d",
    "semantic_title": "dialogcc: an automated pipeline for creating high-quality multi-modal dialogue dataset",
    "citation_count": 5,
    "authors": [
      "Young-Jun Lee",
      "Byungsoo Ko",
      "Han-Gyu Kim",
      "Jonghwan Hyeon",
      "Ho-Jin Choi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.109": {
    "title": "Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models",
    "volume": "long",
    "abstract": "The complementary potential of Large Language Models (LLM) assumes off-the-shelf LLMs have heterogeneous expertise in a wide range of domains and tasks so that an ensemble of LLMs can achieve consistently better performance. Existing ensemble methods for LLMs mainly focus on reward model ranking of outputs, leading to significant computation overhead. To combat this issue, we revisit the complementary potential of LLMs and further elaborate on it by mining latent expertise with off-the-shelf reward models. We propose ZOOTER, a reward-guided routing method distilling rewards on training queries to train a routing function, which can precisely distribute each query to the LLM with expertise about it. We also integrate a tag-based label enhancement to mitigate noise from uncertainty when using rewards as silver supervision. ZOOTER shows computation efficiency in inference as it only introduces minor computation overhead of a routing function compared with reward model ranking methods. We evaluate ZOOTER on a comprehensive benchmark collection with 26 subsets in different domains and tasks. ZOOTER outperforms the best single model on average and ranks first on 44% of tasks, even surpassing multiple reward model ranking methods",
    "checked": true,
    "id": "215de09ac6e5de81187c85065b5ace8bc01f2862",
    "semantic_title": "routing to the expert: efficient reward-guided ensemble of large language models",
    "citation_count": 13,
    "authors": [
      "Keming Lu",
      "Hongyi Yuan",
      "Runji Lin",
      "Junyang Lin",
      "Zheng Yuan",
      "Chang Zhou",
      "Jingren Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.110": {
    "title": "Automatic Generation of Model and Data Cards: A Step Towards Responsible AI",
    "volume": "long",
    "abstract": "In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-written model and data cards. We propose an automated generation approach using Large Language Models (LLMs). Our key contributions include the establishment of CardBench, a comprehensive dataset aggregated from over 4.8k model cards and 1.4k data cards, coupled with the development of the CardGen pipeline comprising a two-step retrieval process. Our approach exhibits enhanced completeness, objectivity, and faithfulness in generated model and data cards, a significant step in responsible AI documentation practices ensuring better accountability and traceability",
    "checked": true,
    "id": "b50a0752e812f75cec35225ffa7649356094e5b9",
    "semantic_title": "automatic generation of model and data cards: a step towards responsible ai",
    "citation_count": 0,
    "authors": [
      "Jiarui Liu",
      "Wenkai Li",
      "Zhijing Jin",
      "Mona Diab"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.111": {
    "title": "FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual Transfer with Scheduled Unfreezing",
    "volume": "long",
    "abstract": "Standard fine-tuning of language models typically performs well on in-distribution data, but suffers with generalization to distribution shifts. In this work, we aim to improve the generalization of adapter-based cross-lingual task transfer where such cross-language distribution shifts are imminent. We investigate scheduled unfreezing algorithms –originally proposed to mitigate catastrophic forgetting in transfer learning – for fine-tuning task adapters. Our experiments show that scheduled unfreezing methods close the gap to full fine-tuning and achieve stronger cross-lingual transfer performance, suggesting that these methods can go beyond just mitigating catastrophic forgetting. Next, aiming to understand these empirical findings, we investigate the learning dynamics of scheduled unfreezing using Fisher Information. Our experiments reveal that scheduled unfreezing induces different learning dynamics compared to standard fine-tuning, and provide evidence that the dynamics of Fisher Information during training correlate with cross-lingual generalization performance. We additionally propose a general scheduled unfreezing algorithm that achieves an average of 2 points improvement over four datasets compared to standard fine-tuning and provides empirical evidence for a theory-based justification of the heuristic unfreezing schedule for task adapter training",
    "checked": true,
    "id": "26f8a3542fa8a5b727fadab4607eba8b871e73dc",
    "semantic_title": "fun with fisher: improving generalization of adapter-based cross-lingual transfer with scheduled unfreezing",
    "citation_count": 5,
    "authors": [
      "Chen Liu",
      "Jonas Pfeiffer",
      "Ivan Vulić",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.112": {
    "title": "Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings",
    "volume": "long",
    "abstract": "Large language models (LLMs) are highly adept at question answering and reasoning tasks, but when reasoning in a situational context, human expectations vary depending on the relevant cultural common ground. As languages are associated with diverse cultures, LLMs should also be culturally-diverse reasoners. In this paper, we study the ability of a wide range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings in a conversational context. Our experiments reveal that: (1) mLLMs \"know\" limited proverbs and memorizing proverbs does not mean understanding them within a conversational context; (2) mLLMs struggle to reason with figurative proverbs and sayings, and when asked to select the wrong answer (instead of asking it to select the correct answer); and (3) there is a \"culture gap\" in mLLMs when reasoning about proverbs and sayings translated from other languages. We construct and release our evaluation dataset MAPS (MulticulturAl Proverbs and Sayings) for proverb understanding with conversational context for six different languages",
    "checked": true,
    "id": "25e4e7a69454099ca0e3ccbf079452878d3abce9",
    "semantic_title": "are multilingual llms culturally-diverse reasoners? an investigation into multicultural proverbs and sayings",
    "citation_count": 3,
    "authors": [
      "Chen Liu",
      "Fajri Koto",
      "Timothy Baldwin",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.113": {
    "title": "The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth",
    "volume": "long",
    "abstract": "Queer youth face increased mental health risks, such as depression, anxiety, and suicidal ideation. Hindered by negative stigma, they often avoid seeking help and rely on online resources, which may provide incompatible information. Although access to a supportive environment and reliable information is invaluable, many queer youth worldwide have no access to such support. However, this could soon change due to the rapid adoption of Large Language Models (LLMs) such as ChatGPT. This paper aims to comprehensively explore the potential of LLMs to revolutionize emotional support for queers. To this end, we conduct a qualitative and quantitative analysis of LLM's interactions with queer-related content. To evaluate response quality, we develop a novel ten-question scale that is inspired by psychological standards and expert input. We apply this scale to score several LLMs and human comments to posts where queer youth seek advice and share experiences. We find that LLM responses are supportive and inclusive, outscoring humans. However, they tend to be generic, not empathetic enough, and lack personalization, resulting in nonreliable and potentially harmful advice. We discuss these challenges, demonstrate that a dedicated prompt can improve the performance, and propose a blueprint of an LLM-supporter that actively (but sensitively) seeks user context to provide personalized, empathetic, and reliable responses. Our annotated dataset is available for further research.*https://github.com/nitaytech/LGBTeenDataset",
    "checked": true,
    "id": "0d637d5e257813e5e4dde1385f6e7cff0bfc8722",
    "semantic_title": "the colorful future of llms: evaluating and improving llms as emotional supporters for queer youth",
    "citation_count": 2,
    "authors": [
      "Shir Lissak",
      "Nitay Calderon",
      "Geva Shenkman",
      "Yaakov Ophir",
      "Eyal Fruchter",
      "Anat Brunstein Klomek",
      "Roi Reichart"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.114": {
    "title": "IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model",
    "volume": "long",
    "abstract": "Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model (IPED), an innovative approach for extracting relational triples. Our classifier-free solution adopts an implicit strategy using block coverage to complete the tables, avoiding the limitations of explicit tagging methods. Additionally, we introduce a generative model structure, the block-denoising diffusion model, to collaborate with our implicit perspective and effectively circumvent redundant information disruptions. Experimental results on two popular datasets demonstrate that IPED achieves state-of-the-art performance while gaining superior inference speed and low computational complexity. To support future research, we have made our source code publicly available online",
    "checked": true,
    "id": "92289dce8678092d5b967e578209c84482489b76",
    "semantic_title": "iped: an implicit perspective for relational triple extraction based on diffusion model",
    "citation_count": 0,
    "authors": [
      "Jianli Zhao",
      "Changhao Xu",
      "Bin. Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.115": {
    "title": "QualEval: Qualitative Evaluation for Model Improvement",
    "volume": "long",
    "abstract": "Quantitative evaluation metrics have been pivotal in gauging the advancements of AI systems like large language models (LLMs).However, due to the intricate nature of real-world tasks, a single scalar to quantify and compare performance trivializes the fine-grained nuances of model behavior. Additionally, metrics do not yield actionable diagnostics for model improvement, thus requiring extensive manual efforts of scientists, involving sifting through vast datasets and attempting hit-or-miss adjustments to training data or setups. In this work, we address the shortcomings of quantitative metrics by proposing QualEval, which uses automated qualitative evaluation as a vehicle for model improvement. QualEval uses a powerful LLM reasoner and our novel flexible linear programming solver to generate human-readable insights that when applied, accelerate model improvement. The insights are supported by a dashboard report with fine-grained visualizations and human-interpretable analyses. We corroborate the faithfulness of QualEval by demonstrating that leveraging its insights, for example, improves the absolute performance of the Llama 2 model by up to 15% points relative on a challenging dialogue task (DialogSum) when compared to baselines. QualEval successfully increases the pace and quality of model development by eliminating the need of arduous manual analysis, thus serving as a data-scientist-in-a-box",
    "checked": true,
    "id": "fff300f169616f031362e9f675ab899130b8d671",
    "semantic_title": "qualeval: qualitative evaluation for model improvement",
    "citation_count": 0,
    "authors": [
      "Vishvak Murahari",
      "Ameet Deshpande",
      "Peter Clark",
      "Tanmay Rajpurohit",
      "Ashish Sabharwal",
      "Karthik Narasimhan",
      "Ashwin Kalyan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.116": {
    "title": "Quantum-inspired Language Model with Lindblad Master Equation and Interference Measurement for Sentiment Analysis",
    "volume": "long",
    "abstract": "Quantum-inspired models have demonstrated superior performance in many downstream language tasks, such as question answering and sentiment analysis. However, recent models primarily focus on embedding and measurement operations, overlooking the significance of the quantum evolution process. In this work, we present a novel quantum-inspired neural network, LI-QiLM, which integrates the Lindblad Master Equation (LME) to model the evolution process and the interferometry to the measurement process, providing more physical meaning to strengthen the interpretability. We conduct comprehensive experiments on six sentiment analysis datasets. Compared to the traditional neural networks, transformer-based pre-trained models and quantum-inspired models, such as CICWE-QNN and ComplexQNN, the proposed method demonstrates superior performance in accuracy and F1-score on six commonly used datasets for sentiment analysis. Additional ablation tests verify the effectiveness of LME and interferometry",
    "checked": true,
    "id": "46d70e3942a331bc4db678a5200c4174025b8b60",
    "semantic_title": "quantum-inspired language model with lindblad master equation and interference measurement for sentiment analysis",
    "citation_count": 0,
    "authors": [
      "Kehuan Yan",
      "Peichao Lai",
      "Yilei Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.117": {
    "title": "VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization",
    "volume": "long",
    "abstract": "This paper presents VisLingInstruct, a novel approach to advancing Multi-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show impressive zero-shot abilities in multi-modal tasks, but their performance depends heavily on the quality of instructions. VisLingInstruct tackles this by autonomously evaluating and optimizing instructional texts through In-Context Learning, improving the synergy between visual perception and linguistic expression in MMLMs. Alongside this instructional advancement, we have also optimized the visual feature extraction modules in MMLMs, further augmenting their responsiveness to textual content. Our comprehensive experiments on MMLMs, based on FlanT5 and Vicuna, show that VisLingInstruct significantly improves zero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1% and 9% increase in accuracy over the prior state-of-the-art on the TextVQA and HatefulMemes datasets. Our main code is available at https://github.com/Zhudongsheng75/VisLingInstruct",
    "checked": true,
    "id": "9cf6e252b8a5566910e6fceda7d6a25c5b54be33",
    "semantic_title": "vislinginstruct: elevating zero-shot learning in multi-modal language models with autonomous instruction optimization",
    "citation_count": 2,
    "authors": [
      "Dongsheng Zhu",
      "Daniel Tang",
      "Weidong Han",
      "Jinghui Lu",
      "Yukun Zhao",
      "Guoliang Xing",
      "Junfeng Wang",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.118": {
    "title": "A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily",
    "volume": "long",
    "abstract": "Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to provide useful and safe responses. However, adversarial prompts known as ‘jailbreaks' can circumvent safeguards, leading LLMs to generate potentially harmful content. Exploring jailbreak prompts can help to better reveal the weaknesses of LLMs and further steer us to secure them. Unfortunately, existing jailbreak methods either suffer from intricate manual design or require optimization on other white-box models, which compromises either generalization or efficiency. In this paper, we generalize jailbreak prompt attacks into two aspects: (1) Prompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM, an automatic framework that leverages LLMs themselves to generate effective jailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantly improves the attack success rate while greatly reducing the time cost compared to existing baselines. Our study also reveals the inadequacy of current defense methods in safeguarding LLMs. Finally, we analyze the failure of LLMs defense from the perspective of prompt execution priority, and propose corresponding defense strategies. We hope that our research can catalyze both the academic community and LLMs developers towards the provision of safer and more regulated LLMs. The code is available at https://github.com/NJUNLP/ReNeLLM",
    "checked": true,
    "id": "c4ff1be5c254b60b96b7455eefcc4ec9583f82ed",
    "semantic_title": "a wolf in sheep's clothing: generalized nested jailbreak prompts can fool large language models easily",
    "citation_count": 24,
    "authors": [
      "Peng Ding",
      "Jun Kuang",
      "Dan Ma",
      "Xuezhi Cao",
      "Yunsen Xian",
      "Jiajun Chen",
      "Shujian Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.119": {
    "title": "P3Sum: Preserving Author's Perspective in News Summarization with Diffusion Language Models",
    "volume": "long",
    "abstract": "In this work, we take a first step towards designing summarization systems that are faithful to the author's intent, not only the semantic content of the article. Focusing on a case study of preserving political perspectives in news summarization, we find that existing approaches alter the political opinions and stances of news articles in more than 50% of summaries, misrepresenting the intent and perspectives of the news authors. We thus propose P3Sum, a diffusion model-based summarization approach controlled by political perspective classifiers. In P3Sum, the political leaning of a generated summary is iteratively evaluated at each decoding step, and any drift from the article's original stance incurs a loss back-propagated to the embedding layers, steering the political stance of the summary at inference time. Extensive experiments on three news summarization datasets demonstrate that P3Sum outperforms state-of-the-art summarization systems and large language models by up to 13.7% in terms of the success rate of stance preservation, with competitive performance on standard metrics of summarization quality. Our findings present a first analysis of preservation of pragmatic features in summarization, highlight the lacunae in existing summarization models—that even state-of-the-art models often struggle to preserve author's intents—and develop new summarization systems that are more faithful to author's perspectives",
    "checked": false,
    "id": "46add102869a54d9360c21f3721778b29d24e210",
    "semantic_title": "p^3sum: preserving author's perspective in news summarization with diffusion language models",
    "citation_count": 0,
    "authors": [
      "Yuhan Liu",
      "Shangbin Feng",
      "Xiaochuang Han",
      "Vidhisha Balachandran",
      "Chan Young Park",
      "Sachin Kumar",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.120": {
    "title": "Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes",
    "volume": "long",
    "abstract": "Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to translate an expert's latent thought process into a decision-making model for remediation. This involves an expert identifying (A) the student's error, (B) a remediation strategy, and (C) their intention before generating a response. We construct a dataset of 700 real tutoring conversations, annotated by experts with their decisions. We evaluate state-of-the-art LLMs on our dataset and find that the expert's decision-making model is critical for LLMs to close the gap: responses from GPT4 with expert decisions (e.g., \"simplify the problem\") are +76% more preferred than without. Additionally, context-sensitive decisions are critical to closing pedagogical gaps: random decisions decrease GPT4's response quality by -97% than expert decisions. Our work shows the potential of embedding expert thought processes in LLM generations to enhance their capability to bridge novice-expert knowledge gaps. Our dataset and code can be found at: https://github.com/rosewang2008/bridge",
    "checked": true,
    "id": "ff4b455af2ef2c3f7372c47209a617ddafd4e203",
    "semantic_title": "bridging the novice-expert gap via models of decision-making: a case study on remediating math mistakes",
    "citation_count": 6,
    "authors": [
      "Rose Wang",
      "Qingyang Zhang",
      "Carly Robinson",
      "Susanna Loeb",
      "Dorottya Demszky"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.121": {
    "title": "RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization",
    "volume": "long",
    "abstract": "For long document summarization, discourse structure is important to discern the key content of the text and the differences in importance level between sentences. Unfortunately, the integration of rhetorical structure theory (RST) into parameter-efficient fine-tuning strategies for long document summarization remains unexplored. Therefore, this paper introduces RST-LoRA and proposes four RST-aware variants to explicitly incorporate RST into the LoRA model. Our empirical evaluation demonstrates that incorporating the type and uncertainty of rhetorical relations can complementarily enhance the performance of LoRA in summarization tasks. Furthermore, the best-performing variant we introduced outperforms the vanilla LoRA and full-parameter fine-tuning models, as confirmed by multiple automatic and human evaluations, and even surpasses previous state-of-the-art methods",
    "checked": true,
    "id": "debf13581cf35a61598f765101e6136f5e5a574b",
    "semantic_title": "rst-lora: a discourse-aware low-rank adaptation for long document abstractive summarization",
    "citation_count": 1,
    "authors": [
      "Dongqi Pu",
      "Vera Demberg"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.122": {
    "title": "Strings from the Library of Babel: Random Sampling as a Strong Baseline for Prompt Optimisation",
    "volume": "long",
    "abstract": "Recent prompt optimisation approaches use the generative nature of language models to produce prompts – even rivaling the performance of human-curated prompts. In this paper, we demonstrate that randomly sampling tokens from the model vocabulary as \"separators\" can be as effective as language models for prompt-style text classification. Our experiments show that random separators are competitive baselines, having less than a 1% difference compared to previous self-optimisation methods and showing a 12% average relative improvement over strong human baselines across nine text classification tasks and eight language models. We further analyse this phenomenon in detail using three different random generation strategies, establishing that the language space is rich with potentially good separators, with a greater than 40% average chance that a randomly drawn separator performs better than human-curated separators. These observations challenge the common assumption that an effective prompt should be human readable or task relevant and establish a strong baseline for prompt optimisation research",
    "checked": true,
    "id": "612ea099df02770f6e02e16b049a7bb86b8eddc1",
    "semantic_title": "strings from the library of babel: random sampling as a strong baseline for prompt optimisation",
    "citation_count": 0,
    "authors": [
      "Yao Lu",
      "Jiayi Wang",
      "Raphael Tang",
      "Sebastian Riedel",
      "Pontus Stenetorp"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.123": {
    "title": "ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models",
    "volume": "long",
    "abstract": "Current logical reasoning evaluations of Large Language Models (LLMs) primarily focus on single-turn and static environments, such as arithmetic problems. The crucial problem of multi-turn, strategic reasoning is under-explored. In this work, we analyze the multi-turn strategic reasoning of LLMs through text-driven complete- and incomplete-information gaming, e.g., board games (Tic-Tac-Toe, Connect-4) and poker games (Texas Hold'em Poker). Specifically, we consider two distinct scenarios: 1) Online Racing, featuring multiple LLMs/agents to facilitate direct competition and comparison; 2) Offline Probing, constructing targeted questions with verified ground truth to evaluate LLMs' strategic behaviors. Experimental results demonstrate that existing state-of-the-art LLMs and reasoning schemes are largely ineffective for strategic reasoning tasks. To mitigate these limitations, we propose a simple yet effective Recursively Thinking-Ahead (ReTA) agent, incorporating a recursive prompting mechanism that automatically analyzes the opponents' future moves/actions and assigns reward signals for these situations, to strengthen the strategic reasoning of LLMs. We hope our work could spur further research and exploration in the multi-turn strategic reasoning of LLMs. The code is available at https://github.com/jinhaoduan/ReTA",
    "checked": true,
    "id": "6f3731706e6828838fcab7c39645a7fcb464160d",
    "semantic_title": "reta: recursively thinking ahead to improve the strategic reasoning of large language models",
    "citation_count": 0,
    "authors": [
      "Jinhao Duan",
      "Shiqi Wang",
      "James Diffenderfer",
      "Lichao Sun",
      "Tianlong Chen",
      "Bhavya Kailkhura",
      "Kaidi Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.124": {
    "title": "Fact Checking Beyond Training Set",
    "volume": "long",
    "abstract": "Evaluating the veracity of everyday claims is time consuming and in some cases requires domain expertise. We empirically demonstrate that the commonly used fact checking pipeline, known as the retriever-reader, suffers from performance deterioration when it is trained on the labeled data from one domain and used in another domain. Afterwards, we delve into each component of the pipeline and propose novel algorithms to address this problem. We propose an adversarial algorithm to make the retriever component robust against distribution shift. Our core idea is to initially train a bi-encoder on the labeled source data, and then, to adversarially train two separate document and claim encoders using unlabeled target data. We then focus on the reader component and propose to train it such that it is insensitive towards the order of claims and evidence documents. Our empirical evaluations support the hypothesis that such a reader shows a higher robustness against distribution shift. To our knowledge, there is no publicly available multi-topic fact checking dataset. Thus, we propose a simple automatic method to re-purpose two well-known fact checking datasets. We then construct eight fact checking scenarios from these datasets, and compare our model to a set of strong baseline models, including recent domain adaptation models that use GPT4 for generating synthetic data",
    "checked": true,
    "id": "4bc473543341cd37f969f6db424e4695d8785323",
    "semantic_title": "fact checking beyond training set",
    "citation_count": 0,
    "authors": [
      "Payam Karisani",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.125": {
    "title": "Program-Aided Reasoners (Better) Know What They Know",
    "volume": "long",
    "abstract": "Prior work shows that program-aided reasoning, in which large language models (LLMs) are combined with programs written in programming languages such as Python, can significantly improve accuracy on various reasoning tasks. However, while accuracy is essential, it is also important for such reasoners to \"know what they know\", which can be quantified through the calibration of the model. In this paper, we compare the calibration of Program Aided Language Models (PAL) and text-based Chain-of-thought (COT) prompting techniques over 5 datasets and 2 model types - LLaMA models and OpenAI models. Our results indicate that PAL leads to improved calibration in 75% of the instances. Our analysis uncovers that prompting styles that produce lesser diversity in generations also have more calibrated results, and thus we also experiment with inducing lower generation diversity using temperature scaling and find that for certain temperatures, PAL is not only more accurate but is also more calibrated than COT. Overall, we demonstrate that, in the majority of cases, program-aided reasoners better know what they know than text-based counterparts",
    "checked": true,
    "id": "76f6142d2b62972de89cb8651ea036d0dd6be68b",
    "semantic_title": "program-aided reasoners (better) know what they know",
    "citation_count": 1,
    "authors": [
      "Anubha Kabra",
      "Sanketh Rangreji",
      "Yash Mathur",
      "Aman Madaan",
      "Emmy Liu",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.126": {
    "title": "The Perspectivist Paradigm Shift: Assumptions and Challenges of Capturing Human Labels",
    "volume": "long",
    "abstract": "Longstanding data labeling practices in machine learning involve collecting and aggregating labels from multiple annotators. But what should we do when annotators disagree? Though annotator disagreement has long been seen as a problem to minimize, new perspectivist approaches challenge this assumption by treating disagreement as a valuable source of information. In this position paper, we examine practices and assumptions surrounding the causes of disagreement–some challenged by perspectivist approaches, and some that remain to be addressed–as well as practical and normative challenges for work operating under these assumptions. We conclude with recommendations for the data labeling pipeline and avenues for future research engaging with subjectivity and disagreement",
    "checked": true,
    "id": "d341da8368e950c0efc44d74ba3c33c9c5f1314e",
    "semantic_title": "the perspectivist paradigm shift: assumptions and challenges of capturing human labels",
    "citation_count": 0,
    "authors": [
      "Eve Fleisig",
      "Su Lin Blodgett",
      "Dan Klein",
      "Zeerak Talat"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.127": {
    "title": "Principles from Clinical Research for NLP Model Generalization",
    "volume": "long",
    "abstract": "The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to \"out-of-distribution\" effects. Here, we explore the foundations of generalizability and study the factors that affect it, articulating lessons from clinical studies. In clinical research, generalizability is an act of reasoning that depends on (a) *internal validity* of experiments to ensure controlled measurement of cause and effect, and (b) *external validity* or transportability of the results to the wider population. We demonstrate how learning spurious correlations, such as the distance between entities in relation extraction tasks, can affect a model's internal validity and in turn adversely impact generalization. We, therefore, present the need to ensure internal validity when building machine learning models in NLP. Our recommendations also apply to generative large language models, as they are known to be sensitive to even minor semantic preserving alterations. We also propose adapting the idea of *matching* in randomized controlled trials and observational studies to NLP evaluation to measure causation",
    "checked": true,
    "id": "ade0ab81403cd1dbe2a49d76c0393dbd615fd979",
    "semantic_title": "principles from clinical research for nlp model generalization",
    "citation_count": 1,
    "authors": [
      "Aparna Elangovan",
      "Jiayuan He",
      "Yuan Li",
      "Karin Verspoor"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.128": {
    "title": "First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models",
    "volume": "long",
    "abstract": "Many NLP researchers are experiencing an existential crisis triggered by the astonishing success of ChatGPT and other systems based on large language models (LLMs). After such a disruptive change to our understanding of the field, what is left to do? Taking a historical lens, we look for guidance from the first era of LLMs, which began in 2005 with large n-gram models for machine translation (MT). We identify durable lessons from the first era, and more importantly, we identify evergreen problems where NLP researchers can continue to make meaningful contributions in areas where LLMs are ascendant. We argue that disparities in scale are transient and researchers can work to reduce them; that data, rather than hardware, is still a bottleneck for many applications; that meaningful realistic evaluation is still an open problem; and that there is still room for speculative approaches",
    "checked": true,
    "id": "6476f1a688d18a93e73160d09da1d238885e73e3",
    "semantic_title": "first tragedy, then parse: history repeats itself in the new era of large language models",
    "citation_count": 0,
    "authors": [
      "Naomi Saphra",
      "Eve Fleisig",
      "Kyunghyun Cho",
      "Adam Lopez"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.129": {
    "title": "Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphael Tang",
      "Crystina Zhang",
      "Xueguang Ma",
      "Jimmy Lin",
      "Ferhan Ture"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.130": {
    "title": "From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuansheng Wu",
      "Wenlin Yao",
      "Jianshu Chen",
      "Xiaoman Pan",
      "Xiaoyang Wang",
      "Ninghao Liu",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.131": {
    "title": "POLYIE: A Dataset of Information Extraction from Polymer Material Scientific Literature",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jerry Cheung",
      "Yuchen Zhuang",
      "Yinghao Li",
      "Pranav Shetty",
      "Wantian Zhao",
      "Sanjeev Grampurohit",
      "Rampi Ramprasad",
      "Chao Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.132": {
    "title": "LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Zhang",
      "Yangyang Kang",
      "Fubang Zhao",
      "Xiaozhong Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.133": {
    "title": "SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob Parnell",
      "Inigo Jauregi Unanue",
      "Massimo Piccardi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.134": {
    "title": "KTRL+F: Knowledge-Augmented In-Document Search",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanseok Oh",
      "Haebin Shin",
      "Miyoung Ko",
      "Hyunji Lee",
      "Minjoon Seo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.135": {
    "title": "How Well Do Large Language Models Truly Ground?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunji Lee",
      "Se June Joo",
      "Chaeeun Kim",
      "Joel Jang",
      "Doyoung Kim",
      "Kyoung-Woon On",
      "Minjoon Seo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.136": {
    "title": "ALBA: Adaptive Language-Based Assessments for Mental Health",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasudha Varadarajan",
      "Sverker Sikström",
      "Oscar Kjell",
      "H. Schwartz"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.137": {
    "title": "FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhou",
      "Mohsen Mesgar",
      "Heike Adel",
      "Annemarie Friedrich"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.138": {
    "title": "MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengyue Jia",
      "Yiding Liu",
      "Xiangyu Zhao",
      "Xiaopeng Li",
      "Changying Hao",
      "Shuaiqiang Wang",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.139": {
    "title": "Efficient Benchmarking (of Language Models)",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yotam Perlitz",
      "Elron Bandel",
      "Ariel Gera",
      "Ofir Arviv",
      "Liat Ein-Dor",
      "Eyal Shnarch",
      "Noam Slonim",
      "Michal Shmueli-Scheuer",
      "Leshem Choshen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.140": {
    "title": "ReFACT: Updating Text-to-Image Models by Editing the Text Encoder",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dana Arad",
      "Hadas Orgad",
      "Yonatan Belinkov"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.141": {
    "title": "A Likelihood Ratio Test of Genetic Relationship among Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "V.S.D.S.Mahesh Akavarapu",
      "Arnab Bhattacharya"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.142": {
    "title": "PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuekai Zhu",
      "Biqing Qi",
      "Kaiyan Zhang",
      "Xinwei Long",
      "Zhouhan Lin",
      "Bowen Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.143": {
    "title": "MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanchit Ahuja",
      "Divyanshu Aggarwal",
      "Varun Gumma",
      "Ishaan Watts",
      "Ashutosh Sathe",
      "Millicent Ochieng",
      "Rishav Hada",
      "Prachi Jain",
      "Mohamed Ahmed",
      "Kalika Bali",
      "Sunayana Sitaram"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.144": {
    "title": "Unlocking Emergent Modularity in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Qiu",
      "Zeyu Huang",
      "Jie Fu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.145": {
    "title": "A School Student Essay Corpus for Analyzing Interactions of Argumentative Structure and Quality",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maja Stahl",
      "Nadine Michel",
      "Sebastian Kilsbach",
      "Julian Schmidtke",
      "Sara Rezat",
      "Henning Wachsmuth"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.146": {
    "title": "Adjusting Interpretable Dimensions in Embedding Space with Human Judgments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katrin Erk",
      "Marianna Apidianaki"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.147": {
    "title": "PatentEval: Understanding Errors in Patent Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "You Zuo",
      "Kim Gerdes",
      "Éric Clergerie",
      "Benoît Sagot"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.148": {
    "title": "Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Koneru",
      "Miriam Exel",
      "Matthias Huck",
      "Jan Niehues"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.149": {
    "title": "Metaphor Detection with Context Enhancement and Curriculum Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaidi Jia",
      "Rongsheng Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.150": {
    "title": "What Causes the Failure of Explicit to Implicit Discourse Relation Recognition?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Liu",
      "Stephen Wan",
      "Michael Strube"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.151": {
    "title": "UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddhant Arora",
      "Hayato Futami",
      "Jee-weon Jung",
      "Yifan Peng",
      "Roshan Sharma",
      "Yosuke Kashiwagi",
      "Emiru Tsunoo",
      "Karen Livescu",
      "Shinji Watanabe"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.152": {
    "title": "How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingbo Mo",
      "Boshi Wang",
      "Muhao Chen",
      "Huan Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.153": {
    "title": "Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Zhou",
      "Yada Zhu",
      "Diego Antognini",
      "Yoon Kim",
      "Yang Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.154": {
    "title": "TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengcheng Jiang",
      "Cao Xiao",
      "Zifeng Wang",
      "Parminder Bhatia",
      "Jimeng Sun",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.155": {
    "title": "GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengcheng Jiang",
      "Jiacheng Lin",
      "Zifeng Wang",
      "Jimeng Sun",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.156": {
    "title": "Curated Datasets and Neural Models for Machine Translation of Informal Registers between Mayan and Spanish Vernaculars",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrés Lou",
      "Juan Antonio Pérez-Ortiz",
      "Felipe Sánchez-Martínez",
      "Víctor Sánchez-Cartagena"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.157": {
    "title": "The Effect of Data Partitioning Strategy on Model Generalizability: A Case Study of Morphological Segmentation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zoey Liu",
      "Bonnie Dorr"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.158": {
    "title": "Measuring Entrainment in Spontaneous Code-switched Speech",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debasmita Bhattacharya",
      "Siying Ding",
      "Alayna Nguyen",
      "Julia Hirschberg"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.159": {
    "title": "A Survey of Meaning Representations – From Theory to Practical Utility",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zacchary Sadeddine",
      "Juri Opitz",
      "Fabian Suchanek"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.160": {
    "title": "Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhe Zhao",
      "Zefan Cai",
      "Shuzheng Si",
      "Liang Chen",
      "Yufeng He",
      "Kaikai An",
      "Baobao Chang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.161": {
    "title": "Evaluating In-Context Learning of Libraries for Code Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arkil Patel",
      "Siva Reddy",
      "Dzmitry Bahdanau",
      "Pradeep Dasigi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.162": {
    "title": "Visually-Aware Context Modeling for News Image Captioning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingyu Qu",
      "Tinne Tuytelaars",
      "Marie-Francine Moens"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.163": {
    "title": "Regularized Conventions: Equilibrium Computation as a Model of Pragmatic Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Athul Jacob",
      "Gabriele Farina",
      "Jacob Andreas"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.164": {
    "title": "TopicGPT: A Prompt-based Topic Modeling Framework",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chau Pham",
      "Alexander Hoyle",
      "Simeng Sun",
      "Philip Resnik",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.165": {
    "title": "ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiazhao Li",
      "Yijin Yang",
      "Zhuofeng Wu",
      "V.G.Vinod Vydiswaran",
      "Chaowei Xiao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.166": {
    "title": "Social Meme-ing: Measuring Linguistic Variation in Memes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naitian Zhou",
      "David Jurgens",
      "David Bamman"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.167": {
    "title": "ExpertQA: Expert-Curated Questions and Attributed Answers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaitanya Malaviya",
      "Subin Lee",
      "Sihao Chen",
      "Elizabeth Sieber",
      "Mark Yatskar",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.168": {
    "title": "What if you said that differently?: How Explanation Formats Affect Human Feedback Efficacy and User Perception",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaitanya Malaviya",
      "Subin Lee",
      "Dan Roth",
      "Mark Yatskar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.169": {
    "title": "When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyan Shi",
      "Emily Dinan",
      "Kurt Shuster",
      "Jason Weston",
      "Jing Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.170": {
    "title": "Kreyòl-MT: Building MT for Latin American, Caribbean and Colonial African Creole Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathaniel Robinson",
      "Raj Dabre",
      "Ammon Shurtz",
      "Rasul Dent",
      "Onenamiyi Onesi",
      "Claire Monroc",
      "Loïc Grobol",
      "Hasan Muhammad",
      "Ashi Garg",
      "Naome Etori",
      "Vijay Murari Tiyyala",
      "Olanrewaju Samuel",
      "Matthew Stutzman",
      "Bismarck Odoom",
      "Sanjeev Khudanpur",
      "Stephen Richardson",
      "Kenton Murray"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.171": {
    "title": "Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiashu Xu",
      "Mingyu Ma",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.172": {
    "title": "Modeling Empathetic Alignment in Conversation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiamin Yang",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.173": {
    "title": "Native Language Identification in Texts: A Survey",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dhiman Goswami",
      "Sharanya Thilagan",
      "Kai North",
      "Shervin Malmasi",
      "Marcos Zampieri"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.174": {
    "title": "LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Yang",
      "Jiajun Zhou",
      "Ngai Wong",
      "Zheng Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.175": {
    "title": "Which One? Leveraging Context Between Objects and Multiple Views for Language Grounding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chancharik Mitra",
      "Abrar Anwar",
      "Rodolfo Corona",
      "Dan Klein",
      "Trevor Darrell",
      "Jesse Thomason"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.176": {
    "title": "Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting-Yun Chang",
      "Jesse Thomason",
      "Robin Jia"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.177": {
    "title": "PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianrong Zhang",
      "Zhaohan Xi",
      "Ting Wang",
      "Prasenjit Mitra",
      "Jinghui Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.178": {
    "title": "Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixue Zhao",
      "Nikolaos Aletras"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.179": {
    "title": "A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shayne Longpre",
      "Gregory Yauney",
      "Emily Reif",
      "Katherine Lee",
      "Adam Roberts",
      "Barret Zoph",
      "Denny Zhou",
      "Jason Wei",
      "Kevin Robinson",
      "David Mimno",
      "Daphne Ippolito"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.180": {
    "title": "Instructional Fingerprinting of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiashu Xu",
      "Fei Wang",
      "Mingyu Ma",
      "Pang Wei Koh",
      "Chaowei Xiao",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.181": {
    "title": "Reinforced Multiple Instance Selection for Speaker Attribute Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alireza Salkhordeh Ziabari",
      "Ali Omrani",
      "Parsa Hejabi",
      "Preni Golazizian",
      "Brendan Kennedy",
      "Payam Piray",
      "Morteza Dehghani"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.182": {
    "title": "DynaMo: Accelerating Language Model Inference with Dynamic Multi-Token Sampling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shikhar Tuli",
      "Chi-Heng Lin",
      "Yen-Chang Hsu",
      "Niraj Jha",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.183": {
    "title": "Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochen Liu",
      "Song Wang",
      "Chen Chen",
      "Jundong Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.184": {
    "title": "Uncertainty Quantification for In-Context Learning of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Ling",
      "Xujiang Zhao",
      "Xuchao Zhang",
      "Wei Cheng",
      "Yanchi Liu",
      "Yiyou Sun",
      "Mika Oishi",
      "Takao Osaki",
      "Katsushi Matsuda",
      "Jie Ji",
      "Guangji Bai",
      "Liang Zhao",
      "Haifeng Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.185": {
    "title": "HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhilin Wang",
      "Yi Dong",
      "Jiaqi Zeng",
      "Virginia Adams",
      "Makesh Narsimhan Sreedhar",
      "Daniel Egert",
      "Olivier Delalleau",
      "Jane Scowcroft",
      "Neel Kant",
      "Aidan Swope",
      "Oleksii Kuchaiev"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.186": {
    "title": "A Preference-driven Paradigm for Enhanced Translation with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dawei Zhu",
      "Sony Trenous",
      "Xiaoyu Shen",
      "Dietrich Klakow",
      "Bill Byrne",
      "Eva Hasler"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.187": {
    "title": "Fair Abstractive Summarization of Diverse Perspectives",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusen Zhang",
      "Nan Zhang",
      "Yixin Liu",
      "Alexander Fabbri",
      "Junru Liu",
      "Ryo Kamoi",
      "Xiaoxin Lu",
      "Caiming Xiong",
      "Jieyu Zhao",
      "Dragomir Radev",
      "Kathleen McKeown",
      "Rui Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.188": {
    "title": "What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anthony Tiong",
      "Junqi Zhao",
      "Boyang Li",
      "Junnan Li",
      "Steven Hoi",
      "Caiming Xiong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.189": {
    "title": "Show Your Work with Confidence: Confidence Bands for Tuning Curves",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicholas Lourie",
      "Kyunghyun Cho",
      "He He"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.190": {
    "title": "GRASP: A Disagreement Analysis Framework to Assess Group Associations in Perspectives",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vinodkumar Prabhakaran",
      "Christopher Homan",
      "Lora Aroyo",
      "Aida Mostafazadeh Davani",
      "Alicia Parrish",
      "Alex Taylor",
      "Mark Diaz",
      "Ding Wang",
      "Gregory Serapio-García"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.191": {
    "title": "Event Causality Is Key to Computational Story Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yidan Sun",
      "Qin Chao",
      "Boyang Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.192": {
    "title": "Subspace Representations for Soft Set Operations and Sentence Similarities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yoichi Ishibashi",
      "Sho Yokoi",
      "Katsuhito Sudoh",
      "Satoshi Nakamura"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.193": {
    "title": "My Heart Skipped a Beat! Recognizing Expressions of Embodied Emotion in Natural Language",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Zhuang",
      "Tianyu Jiang",
      "Ellen Riloff"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.194": {
    "title": "Low-Cost Generation and Evaluation of Dictionary Example Sentences",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bill Cai",
      "Ng Clarence",
      "Daniel Liang",
      "Shelvia Hotama"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.195": {
    "title": "Making Language Models Better Tool Learners with Execution Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuofei Qiao",
      "Honghao Gui",
      "Chengfei Lv",
      "Qianghuai Jia",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.196": {
    "title": "Complex Claim Verification with Evidence Retrieved in the Wild",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jifan Chen",
      "Grace Kim",
      "Aniruddh Sriram",
      "Greg Durrett",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.197": {
    "title": "Multimodal Multi-loss Fusion Network for Sentiment Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehui Wu",
      "Ziwei Gong",
      "Jaywon Koo",
      "Julia Hirschberg"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.198": {
    "title": "Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanchen Liu",
      "Srishti Gautam",
      "Jiaqi Ma",
      "Himabindu Lakkaraju"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.199": {
    "title": "Analyzing the Use of Metaphors in News Editorials for Political Framing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meghdut Sengupta",
      "Roxanne El Baff",
      "Milad Alshomary",
      "Henning Wachsmuth"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.200": {
    "title": "SharpSeq: Empowering Continual Event Detection through Sharpness-Aware Sequential-task Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh-Thien Le",
      "Viet Dao",
      "Linh Nguyen",
      "Thi-Nhung Nguyen",
      "Linh Ngo",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.201": {
    "title": "Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary Information on Knowledge Retrieval from Pretrained Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephan Linzbach",
      "Dimitar Dimitrov",
      "Laura Kallmeyer",
      "Kilian Evang",
      "Hajira Jabeen",
      "Stefan Dietze"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.202": {
    "title": "Know When To Stop: A Study of Semantic Drift in Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ava Spataru"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.203": {
    "title": "Curriculum Masking in Vision-Language Pretraining to Maximize Cross Modal Interaction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kraig Tou",
      "Zijun Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.204": {
    "title": "Elote, Choclo and Mazorca: on the Varieties of Spanish",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cristina España-Bonet",
      "Alberto Barrón-Cedeño"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.205": {
    "title": "Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chonghua Wang",
      "Haodong Duan",
      "Songyang Zhang",
      "Dahua Lin",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.206": {
    "title": "A Zero-Shot Monolingual Dual Stage Information Retrieval System for Spanish Biomedical Systematic Literature Reviews",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Regina Ofori-Boateng",
      "Magaly Aceves-Martins",
      "Nirmalie Wiratunga",
      "Carlos Moreno-Garcia"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.207": {
    "title": "LayoutPointer: A Spatial-Context Adaptive Pointer Network for Visual Information Extraction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huang Siyuan",
      "Yongping Xiong",
      "Wu Guibin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.208": {
    "title": "Long-form evaluation of model editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Domenic Rosati",
      "Robie Gonzales",
      "Jinkun Chen",
      "Xuemin Yu",
      "Yahya Kayani",
      "Frank Rudzicz",
      "Hassan Sajjad"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.209": {
    "title": "Analyzing the Role of Semantic Representations in the Era of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhijing Jin",
      "Yuen Chen",
      "Fernando Gonzalez Adauto",
      "Jiarui Liu",
      "Jiayi Zhang",
      "Julian Michael",
      "Bernhard Schölkopf",
      "Mona Diab"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.210": {
    "title": "TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Li",
      "Sangdon Park",
      "Insup Lee",
      "Osbert Bastani"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.211": {
    "title": "MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinpei Zhao",
      "Jingyuan Sun",
      "Shaonan Wang",
      "Jing Ye",
      "Xhz Xhz",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.212": {
    "title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Monica Munnangi",
      "Sergey Feldman",
      "Byron Wallace",
      "Silvio Amir",
      "Tom Hope",
      "Aakanksha Naik"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.213": {
    "title": "This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bryan Li",
      "Samar Haider",
      "Chris Callison-Burch"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.214": {
    "title": "Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingwei Tan",
      "Yuxiang Zhou",
      "Gabriele Pergola",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.215": {
    "title": "LanguageFlow: Advancing Diffusion Language Generation with Probabilistic Flows",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shujian Zhang",
      "Lemeng Wu",
      "Chengyue Gong",
      "Xingchao Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.216": {
    "title": "Towards Improved Multi-Source Attribution for Long-Form Answer Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nilay Patel",
      "Shivashankar Subramanian",
      "Siddhant Garg",
      "Pratyay Banerjee",
      "Amita Misra"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.217": {
    "title": "Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems using Differentially Private Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aldo Carranza",
      "Rezsa Farahani",
      "Natalia Ponomareva",
      "Alexey Kurakin",
      "Matthew Jagielski",
      "Milad Nasr"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.218": {
    "title": "Okay, Let's Do This! Modeling Event Coreference with Generated Rationales and Knowledge Distillation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhijnan Nath",
      "Shadi Manafi Avari",
      "Avyakta Chelle",
      "Nikhil Krishnaswamy"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.219": {
    "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Garima Agrawal",
      "Tharindu Kumarage",
      "Zeyad Alghamdi",
      "Huan Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.220": {
    "title": "Pedagogically Aligned Objectives Create Reliable Automatic Cloze Tests",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brian Ondov",
      "Kush Attal",
      "Dina Demner-Fushman"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.221": {
    "title": "Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kazuma Hashimoto",
      "Karthik Raman",
      "Michael Bendersky"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.222": {
    "title": "LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi Han",
      "Qifan Wang",
      "Hao Peng",
      "Wenhan Xiong",
      "Yu Chen",
      "Heng Ji",
      "Sinong Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.223": {
    "title": "CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Albert Sun",
      "Varun Nair",
      "Elliot Schumacher",
      "Anitha Kannan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.224": {
    "title": "Advancing Beyond Identification: Multi-bit Watermark for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "KiYoon Yoo",
      "Wonhyuk Ahn",
      "Nojun Kwak"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.225": {
    "title": "HTCCN: Temporal Causal Convolutional Networks with Hawkes Process for Extrapolation Reasoning in Temporal Knowledge Graphs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingxuan Chen",
      "Jun Long",
      "Liu Yang",
      "Zidong Wang",
      "Yongheng Wang",
      "Xiongnan Jin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.226": {
    "title": "SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abe Hou",
      "Jingyu Zhang",
      "Tianxing He",
      "Yichen Wang",
      "Yung-Sung Chuang",
      "Hongwei Wang",
      "Lingfeng Shen",
      "Benjamin Van Durme",
      "Daniel Khashabi",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.227": {
    "title": "Media Bias Detection Across Families of Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iffat Maab",
      "Edison Marrese-Taylor",
      "Sebastian Padó",
      "Yutaka Matsuo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.228": {
    "title": "Better Zero-Shot Reasoning with Role-Play Prompting",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aobo Kong",
      "Shiwan Zhao",
      "Hao Chen",
      "Qicheng Li",
      "Yong Qin",
      "Ruiqi Sun",
      "Xin Zhou",
      "Enzhi Wang",
      "Xiaohang Dong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.229": {
    "title": "Event-Content-Oriented Dialogue Generation in Short Video",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fenghua Cheng",
      "Xue Li",
      "Zi Huang",
      "Jinxiang Wang",
      "Sen Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.230": {
    "title": "DoG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Instruction Wrapping",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongrui Chen",
      "Haiyun Jiang",
      "Xinting Huang",
      "Shuming Shi",
      "Guilin Qi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.231": {
    "title": "Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Santosh T.y.s.s",
      "Vatsal Venkatkrishna",
      "Saptarshi Ghosh",
      "Matthias Grabmair"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.232": {
    "title": "EDC: Effective and Efficient Dialog Comprehension For Dialog State Tracking",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qifan Lu",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.233": {
    "title": "Automatic Restoration of Diacritics for Speech Data Sets",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sara Shatnawi",
      "Sawsan Alqahtani",
      "Hanan Aldarmaki"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.234": {
    "title": "XNLIeu: a dataset for cross-lingual NLI in Basque",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maite Heredia",
      "Julen Etxaniz",
      "Muitze Zulaika",
      "Xabier Saralegi",
      "Jeremy Barnes",
      "Aitor Soroa"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.235": {
    "title": "MDR: Model-Specific Demonstration Retrieval at Inference Time for In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huazheng Wang",
      "Jinming Wu",
      "Haifeng Sun",
      "Zixuan Xia",
      "Daixuan Cheng",
      "Jingyu Wang",
      "Qi Qi",
      "Jianxin Liao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.236": {
    "title": "Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nayeon Lee",
      "Chani Jung",
      "Junho Myung",
      "Jiho Jin",
      "Jose Camacho-Collados",
      "Juho Kim",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.237": {
    "title": "Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Zhao",
      "Emilio Monti",
      "Jens Lehmann",
      "Haytham Assem"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.238": {
    "title": "Generalizable Sarcasm Detection is Just Around the Corner, of Course!",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyewon Jang",
      "Diego Frassinelli"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.239": {
    "title": "Encoding of lexical tone in self-supervised models of spoken language",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaofei Shen",
      "Michaela Watkins",
      "Afra Alishahi",
      "Arianna Bisazza",
      "Grzegorz Chrupała"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.240": {
    "title": "A Systematic Comparison of Contextualized Word Embeddings for Lexical Semantic Change",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Periti",
      "Nina Tahmasebi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.241": {
    "title": "iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiancai Xu",
      "Jia-Dong Zhang",
      "Lei Xiong",
      "Zhishang Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.242": {
    "title": "Rectifying Demonstration Shortcut in In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonwon Jang",
      "Sanghwan Jang",
      "Wonbin Kweon",
      "Minjin Jeon",
      "Hwanjo Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.243": {
    "title": "Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephen Mayhew",
      "Terra Blevins",
      "Shuheng Liu",
      "Marek Suppa",
      "Hila Gonen",
      "Joseph Marvin Imperial",
      "Börje Karlsson",
      "Peiqin Lin",
      "Nikola Ljubešić",
      "Lester James Miranda",
      "Barbara Plank",
      "Arij Riabi",
      "Yuval Pinter"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.244": {
    "title": "ODD: A Benchmark Dataset for the Natural Language Processing Based Opioid Related Aberrant Behavior Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sunjae Kwon",
      "Xun Wang",
      "Weisong Liu",
      "Emily Druhl",
      "Minhee Sung",
      "Joel Reisman",
      "Wenjun Li",
      "Robert Kerns",
      "William Becker",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.245": {
    "title": "A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingmeng Zhao",
      "Ali Niazi",
      "Anthony Rios"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.246": {
    "title": "The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paiheng Xu",
      "Jing Liu",
      "Nathan Jones",
      "Julie Cohen",
      "Wei Ai"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.247": {
    "title": "Differentially Private Next-Token Prediction of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Flemings",
      "Meisam Razaviyayn",
      "Murali Annavaram"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.248": {
    "title": "Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Janis Goldzycher",
      "Paul Röttger",
      "Gerold Schneider"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.249": {
    "title": "Memory Augmented Language Models through Mixture of Word Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cicero Nogueira dos Santos",
      "James Lee-Thorp",
      "Isaac Noble",
      "Chung-Ching Chang",
      "David Uthus"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.250": {
    "title": "Impossible Distillation for Paraphrasing and Summarization: How to Make High-quality Lemonade out of Small, Low-quality Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaehun Jung",
      "Peter West",
      "Liwei Jiang",
      "Faeze Brahman",
      "Ximing Lu",
      "Jillian Fisher",
      "Taylor Sorensen",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.251": {
    "title": "TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liyan Tang",
      "Igor Shalyminov",
      "Amy Wong",
      "Jon Burnsky",
      "Jake Vincent",
      "Yu’an Yang",
      "Siffi Singh",
      "Song Feng",
      "Hwanjun Song",
      "Hang Su",
      "Lijia Sun",
      "Yi Zhang",
      "Saab Mansour",
      "Kathleen McKeown"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.252": {
    "title": "MOKA: Moral Knowledge Augmentation for Moral Event Extraction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinliang Frederick Zhang",
      "Winston Wu",
      "Nicholas Beauchamp",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.253": {
    "title": "Fixing Rogue Memorization in Many-to-One Multilingual Translators of Extremely-Low-Resource Languages by Rephrasing Training Samples",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paulo Cavalin",
      "Pedro Henrique Domingues",
      "Claudio Pinhanez",
      "Julio Nogima"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.254": {
    "title": "Backdoor Attacks on Multilingual Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Wang",
      "Qiongkai Xu",
      "Xuanli He",
      "Benjamin Rubinstein",
      "Trevor Cohn"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.255": {
    "title": "Personalized Jargon Identification for Enhanced Interdisciplinary Communication",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Guo",
      "Joseph Chee Chang",
      "Maria Antoniak",
      "Erin Bransom",
      "Trevor Cohen",
      "Lucy Wang",
      "Tal August"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.256": {
    "title": "Flames: Benchmarking Value Alignment of LLMs in Chinese",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kexin Huang",
      "Xiangyang Liu",
      "Qianyu Guo",
      "Tianxiang Sun",
      "Jiawei Sun",
      "Yaru Wang",
      "Zeyang Zhou",
      "Yixu Wang",
      "Yan Teng",
      "Xipeng Qiu",
      "Yingchun Wang",
      "Dahua Lin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.257": {
    "title": "Mitigating Bias for Question Answering Models by Tracking Bias Influence",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Ma",
      "Jiun-Yu Kao",
      "Arpit Gupta",
      "Yu-Hsiang Lin",
      "Wenbo Zhao",
      "Tagyoung Chung",
      "Wei Wang",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.258": {
    "title": "Extending CLIP's Image-Text Alignment to Referring Image Segmentation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seoyeon Kim",
      "Minguk Kang",
      "Dongwon Kim",
      "Jaesik Park",
      "Suha Kwak"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.259": {
    "title": "Generating Attractive and Authentic Copywriting from Customer Reviews",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Xiang Lin",
      "Wei-Yun Ma"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.260": {
    "title": "Effective Long-Context Scaling of Foundation Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhan Xiong",
      "Jingyu Liu",
      "Igor Molybog",
      "Hejia Zhang",
      "Prajjwal Bhargava",
      "Rui Hou",
      "Louis Martin",
      "Rashi Rungta",
      "Karthik Abinav Sankararaman",
      "Barlas Oguz",
      "Madian Khabsa",
      "Han Fang",
      "Yashar Mehdad",
      "Sharan Narang",
      "Kshitiz Malik",
      "Angela Fan",
      "Shruti Bhosale",
      "Sergey Edunov",
      "Mike Lewis",
      "Sinong Wang",
      "Hao Ma"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.261": {
    "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhujin Gao",
      "Junliang Guo",
      "Xu Tan",
      "Yongxin Zhu",
      "Fang Zhang",
      "Jiang Bian",
      "Linli Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.262": {
    "title": "Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Xia",
      "Tong Yu",
      "Zhankui He",
      "Handong Zhao",
      "Julian McAuley",
      "Shuai Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.263": {
    "title": "Fake Alignment: Are LLMs Really Aligned Well?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixu Wang",
      "Yan Teng",
      "Kexin Huang",
      "Chengqi Lyu",
      "Songyang Zhang",
      "Wenwei Zhang",
      "Xingjun Ma",
      "Yu-Gang Jiang",
      "Yu Qiao",
      "Yingchun Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.264": {
    "title": "Visually Guided Generative Text-Layout Pre-training for Document Intelligence",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiming Mao",
      "Haoli Bai",
      "Lu Hou",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.265": {
    "title": "HILL: Hierarchy-aware Information Lossless Contrastive Learning for Hierarchical Text Classification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Zhu",
      "Junran Wu",
      "Ruomei Liu",
      "Yue Hou",
      "Ze Yuan",
      "Shangzhe Li",
      "Yicheng Pan",
      "Ke Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.266": {
    "title": "Investigating the Emergent Audio Classification Ability of ASR Foundation Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rao Ma",
      "Adian Liusie",
      "Mark Gales",
      "Kate Knill"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.267": {
    "title": "In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aaron Mueller",
      "Albert Webson",
      "Jackson Petty",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.268": {
    "title": "Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi Wang",
      "Ruofan Hu",
      "Rongjie Huang",
      "Zhiqing Hong",
      "Ruiqi Li",
      "Wenrui Liu",
      "Fuming You",
      "Tao Jin",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.269": {
    "title": "Lost in Transcription: Identifying and Quantifying the Accuracy Biases of Automatic Speech Recognition Systems Against Disfluent Speech",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dena Mujtaba",
      "Nihar Mahapatra",
      "Megan Arney",
      "J Yaruss",
      "Hope Gerlach-Houck",
      "Caryn Herring",
      "Jia Bin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.270": {
    "title": "MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and Classification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chadi Helwe",
      "Tom Calamai",
      "Pierre-Henri Paris",
      "Chloé Clavel",
      "Fabian Suchanek"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.271": {
    "title": "Diffusion Glancing Transformer for Parallel Sequence-to-Sequence Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lihua Qian",
      "Mingxuan Wang",
      "Yang Liu",
      "Hao Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.272": {
    "title": "No Context Needed: Contextual Quandary In Idiomatic Reasoning With Pre-Trained Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kellen Cheng",
      "Suma Bhat"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.273": {
    "title": "Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xindi Wang",
      "Robert Mercer",
      "Frank Rudzicz"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.274": {
    "title": "Anisotropy is Not Inherent to Transformers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anemily Machina",
      "Robert Mercer"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.275": {
    "title": "Finding Replicable Human Evaluations via Stable Ranking Probability",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parker Riley",
      "Daniel Deutsch",
      "George Foster",
      "Viresh Ratnakar",
      "Ali Dabirmoghaddam",
      "Markus Freitag"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.276": {
    "title": "Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanpu Cao",
      "Bochuan Cao",
      "Jinghui Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.277": {
    "title": "Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Ashish Somayajula",
      "Youwei Liang",
      "Li Zhang",
      "Abhishek Singh",
      "Pengtao Xie"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.278": {
    "title": "Detecting Bipolar Disorder from Misdiagnosed Major Depressive Disorder with Mood-Aware Multi-Task Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daeun Lee",
      "Hyolim Jeon",
      "Sejung Son",
      "Chaewon Park",
      "Ji hyun An",
      "Seungbae Kim",
      "Jinyoung Han"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.279": {
    "title": "Leveraging Code to Improve In-Context Learning for Semantic Parsing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Bogin",
      "Shivanshu Gupta",
      "Peter Clark",
      "Ashish Sabharwal"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.280": {
    "title": "Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Micheal Abaho",
      "Danushka Bollegala",
      "Gary Leeming",
      "Dan Joyce",
      "Iain Buchan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.281": {
    "title": "Language Models Implement Simple Word2Vec-style Vector Arithmetic",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jack Merullo",
      "Carsten Eickhoff",
      "Ellie Pavlick"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.282": {
    "title": "AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyi Zhang",
      "Rushi Qiang",
      "Sai Ashish Somayajula",
      "Pengtao Xie"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.283": {
    "title": "SportQA: A Benchmark for Sports Understanding in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haotian Xia",
      "Zhengbang Yang",
      "Yuqing Wang",
      "Rhys Tracy",
      "Yun Zhao",
      "Dongdong Huang",
      "Zezhi Chen",
      "Yan Zhu",
      "Yuan-fang Wang",
      "Weining Shen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.284": {
    "title": "Revisiting subword tokenization: A case study on affixal negation in large language models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thinh Truong",
      "Yulia Otmakhova",
      "Karin Verspoor",
      "Trevor Cohn",
      "Timothy Baldwin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.285": {
    "title": "Generating Mental Health Transcripts with SAPE (Spanish Adaptive Prompt Engineering)",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Lozoya",
      "Alejandro Berazaluce",
      "Juan Perches",
      "Eloy Lúa",
      "Mike Conway",
      "Simon D’Alfonso"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.286": {
    "title": "Where are you from? Geolocating Speech and Applications to Language Identification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Foley",
      "Matthew Wiesner",
      "Bismarck Odoom",
      "Leibny Paola Garcia Perera",
      "Kenton Murray",
      "Philipp Koehn"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.287": {
    "title": "Teaching Language Models to Self-Improve through Interactive Demonstrations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Yu",
      "Baolin Peng",
      "Michel Galley",
      "Jianfeng Gao",
      "Zhou Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.288": {
    "title": "MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hossein Aboutalebi",
      "Hwanjun Song",
      "Yusheng Xie",
      "Arshit Gupta",
      "Lijia Sun",
      "Hang Su",
      "Igor Shalyminov",
      "Nikolaos Pappas",
      "Siffi Singh",
      "Saab Mansour"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.289": {
    "title": "Zero-shot Generative Linguistic Steganography",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Lin",
      "Yiyang Luo",
      "Zijian Zhang",
      "Luo Ping"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.290": {
    "title": "Does GPT-4 pass the Turing test?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cameron Jones",
      "Ben Bergen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.291": {
    "title": "Polarity Calibration for Opinion Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanyuan Lei",
      "Kaiqiang Song",
      "Sangwoo Cho",
      "Xiaoyang Wang",
      "Ruihong Huang",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.292": {
    "title": "Sentence-level Media Bias Analysis with Event Relation Graph",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanyuan Lei",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.293": {
    "title": "EMONA: Event-level Moral Opinions in News Articles",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanyuan Lei",
      "Md Messal Monem Miah",
      "Ayesha Qamar",
      "Sai Ramana Reddy",
      "Jonathan Tong",
      "Haotian Xu",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.294": {
    "title": "DLM: A Decoupled Learning Model for Long-tailed Polyphone Disambiguation in Mandarin",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beibei Gao",
      "Yangsen Zhang",
      "Ga Xiang",
      "Yushan Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.295": {
    "title": "You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bangzhao Shu",
      "Lechen Zhang",
      "Minje Choi",
      "Lavinia Dunagan",
      "Lajanugen Logeswaran",
      "Moontae Lee",
      "Dallas Card",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.296": {
    "title": "CASA: Causality-driven Argument Sufficiency Assessment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Liu",
      "Yansong Feng",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.297": {
    "title": "MacGyver: Are Large Language Models Creative Problem Solvers?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Tian",
      "Abhilasha Ravichander",
      "Lianhui Qin",
      "Ronan Le Bras",
      "Raja Marjieh",
      "Nanyun Peng",
      "Yejin Choi",
      "Thomas Griffiths",
      "Faeze Brahman"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.298": {
    "title": "To Translate or Not to Translate: A Systematic Investigation of Translation-Based Cross-Lingual Transfer to Low-Resource Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benedikt Ebing",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.299": {
    "title": "Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Wang",
      "Hongru Wang",
      "Fei Mi",
      "Boyang Xue",
      "Yi Chen",
      "Kam-Fai Wong",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.300": {
    "title": "GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Urchade Zaratiana",
      "Nadi Tomeh",
      "Pierre Holat",
      "Thierry Charnois"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.301": {
    "title": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Röttger",
      "Hannah Kirk",
      "Bertie Vidgen",
      "Giuseppe Attanasio",
      "Federico Bianchi",
      "Dirk Hovy"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.302": {
    "title": "Carpe diem: On the Evaluation of World Knowledge in Lifelong Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujin Kim",
      "Jaehong Yoon",
      "Seonghyeon Ye",
      "Sangmin Bae",
      "Namgyu Ho",
      "Sung Ju Hwang",
      "Se-Young Yun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.303": {
    "title": "Fine-grained Gender Control in Machine Translation with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minwoo Lee",
      "Hyukhun Koh",
      "Minsung Kim",
      "Kyomin Jung"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.304": {
    "title": "DialogVCS: Robust Natural Language Understanding in Dialogue System Upgrade",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zefan Cai",
      "Xin Zheng",
      "Tianyu Liu",
      "Haoran Meng",
      "Jiaqi Han",
      "Gang Yuan",
      "Binghuai Lin",
      "Baobao Chang",
      "Yunbo Cao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.305": {
    "title": "LLatrieval: LLM-Verified Retrieval for Verifiable Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaonan Li",
      "Changtai Zhu",
      "Linyang Li",
      "Zhangyue Yin",
      "Tianxiang Sun",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.306": {
    "title": "Mapping Long-term Causalities in Psychiatric Symptomatology and Life Events from Social Media",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Chen",
      "Meilin Wang",
      "Minghao Lv",
      "Zhiling Zhang",
      "Juqianqian Juqianqian",
      "Dejiyangla Dejiyangla",
      "Yujia Peng",
      "Kenny Zhu",
      "Mengyue Wu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.307": {
    "title": "Multimodal Chart Retrieval: A Comparison of Text, Table and Image Based Approaches",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Averi Nowak",
      "Francesco Piccinno",
      "Yasemin Altun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.308": {
    "title": "Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seiji Maekawa",
      "Hayate Iso",
      "Sairam Gurajada",
      "Nikita Bhutani"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.309": {
    "title": "AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yassir Fathullah",
      "Chunyang Wu",
      "Egor Lakomkin",
      "Ke Li",
      "Junteng Jia",
      "Yuan Shangguan",
      "Jay Mahadeokar",
      "Ozlem Kalinli",
      "Christian Fuegen",
      "Mike Seltzer"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.310": {
    "title": "Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashim Gupta",
      "Rishanth Rajendhran",
      "Nathan Stringham",
      "Vivek Srikumar",
      "Ana Marasovic"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.311": {
    "title": "Sequential Compositional Generalization in Multimodal Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Semih Yagcioglu",
      "Osman Batur İnce",
      "Aykut Erdem",
      "Erkut Erdem",
      "Desmond Elliott",
      "Deniz Yuret"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.312": {
    "title": "Generating Uncontextualized and Contextualized Questions for Document-Level Event Argument Extraction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Nayem Uddin",
      "Enfa George",
      "Eduardo Blanco",
      "Steven Corman"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.313": {
    "title": "Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Yimeng Lu",
      "Lanyu Shang",
      "Yang Zhang",
      "Dong Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.314": {
    "title": "Open-Vocabulary Federated Learning with Multimodal Prototyping",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huimin Zeng",
      "Zhenrui Yue",
      "Dong Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.315": {
    "title": "Exploring Key Point Analysis with Pairwise Generation and Graph Partitioning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Li",
      "Yong Jiang",
      "Shen Huang",
      "Pengjun Xie",
      "Gong Cheng",
      "Fei Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.316": {
    "title": "Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Shen",
      "Lajanugen Logeswaran",
      "Moontae Lee",
      "Honglak Lee",
      "Soujanya Poria",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.317": {
    "title": "Code Models are Zero-shot Precondition Reasoners",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lajanugen Logeswaran",
      "Sungryull Sohn",
      "Yiwei Lyu",
      "Anthony Liu",
      "Dong-Ki Kim",
      "Dongsub Shim",
      "Moontae Lee",
      "Honglak Lee"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.318": {
    "title": "Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suyoung Kim",
      "Jiyeon Hwang",
      "Ho-Young Jung"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.319": {
    "title": "Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Wang",
      "Xuyang Wu",
      "Hsin-Tai Wu",
      "Zhiqiang Tao",
      "Yi Fang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.320": {
    "title": "TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Nahid",
      "Davood Rafiei"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.321": {
    "title": "Contextual Label Projection for Cross-Lingual Structured Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanmay Parekh",
      "I-Hung Hsu",
      "Kuan-Hao Huang",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.322": {
    "title": "Event Detection from Social Media for Epidemic Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanmay Parekh",
      "Anh Mac",
      "Jiarui Yu",
      "Yuxuan Dong",
      "Syed Shahriar",
      "Bonnie Liu",
      "Eric Yang",
      "Kuan-Hao Huang",
      "Wei Wang",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.323": {
    "title": "RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Song Jiang",
      "Zahra Shakeri",
      "Aaron Chan",
      "Maziar Sanjabi",
      "Hamed Firooz",
      "Yinglong Xia",
      "Bugra Akyildiz",
      "Yizhou Sun",
      "Jinchao Li",
      "Qifan Wang",
      "Asli Celikyilmaz"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.324": {
    "title": "BPE-knockout: Pruning Pre-existing BPE Tokenisers with Backwards-compatible Morphological Semi-supervision",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Bauwens",
      "Pieter Delobelle"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.325": {
    "title": "How are Prompts Different in Terms of Sensitivity?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sheng Lu",
      "Hendrik Schuff",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.326": {
    "title": "LSTDial: Enhancing Dialogue Generation via Long- and Short-Term Measurement Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanghui Ye",
      "Huan Zhao",
      "Zixing Zhang",
      "Xupeng Zha",
      "Zhihua Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.327": {
    "title": "The ART of LLM Refinement: Ask, Refine, and Trust",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kumar Shridhar",
      "Koustuv Sinha",
      "Andrew Cohen",
      "Tianlu Wang",
      "Ping Yu",
      "Ramakanth Pasunuru",
      "Mrinmaya Sachan",
      "Jason Weston",
      "Asli Celikyilmaz"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.328": {
    "title": "Modularized Multilingual NMT with Fine-grained Interlingua",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungjun Lim",
      "Yoonjung Choi",
      "Sangha Kim"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.329": {
    "title": "ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oren Sultan",
      "Yonatan Bitton",
      "Ron Yosef",
      "Dafna Shahaf"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.330": {
    "title": "AWESOME: GPU Memory-constrained Long Document Summarization using Memory Mechanism and Global Salient Content",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuyang Cao",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.331": {
    "title": "NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but Teaching the Distinction Helps",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kristina Gligoric",
      "Myra Cheng",
      "Lucia Zheng",
      "Esin Durmus",
      "Dan Jurafsky"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.332": {
    "title": "Debiasing with Sufficient Projection: A General Theoretical Framework for Vector Representations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enze Shi",
      "Lei Ding",
      "Linglong Kong",
      "Bei Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.333": {
    "title": "Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianfeng He",
      "Hang Su",
      "Jason Cai",
      "Igor Shalyminov",
      "Hwanjun Song",
      "Saab Mansour"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.334": {
    "title": "AfriMTE and AfriCOMET: Enhancing COMET to Embrace Under-resourced African Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Wang",
      "David Adelani",
      "Sweta Agrawal",
      "Marek Masiak",
      "Ricardo Rei",
      "Eleftheria Briakou",
      "Marine Carpuat",
      "Xuanli He",
      "Sofia Bourhim",
      "Andiswa Bukula",
      "Muhidin Mohamed",
      "Temitayo Olatoye",
      "Tosin Adewumi",
      "Hamam Mokayed",
      "Christine Mwase",
      "Wangui Kimotho",
      "Foutse Yuehgoh",
      "Anuoluwapo Aremu",
      "Jessica Ojo",
      "Shamsuddeen Muhammad",
      "Salomey Osei",
      "Abdul-Hakeem Omotayo",
      "Chiamaka Chukwuneke",
      "Perez Ogayo",
      "Oumaima Hourrane",
      "Salma El Anigri",
      "Lolwethu Ndolela",
      "Thabiso Mangwana",
      "Shafie Mohamed",
      "Hassan Ayinde",
      "Oluwabusayo Awoyomi",
      "Lama Alkhaled",
      "Sana Al-azzawi",
      "Naome Etori",
      "Millicent Ochieng",
      "Clemencia Siro",
      "Njoroge Kiragu",
      "Eric Muchiri",
      "Wangari Kimotho",
      "Toadoum Sari Sakayo",
      "Lyse Naomi Wamba",
      "Daud Abolade",
      "Simbiat Ajao",
      "Iyanuoluwa Shode",
      "Ricky Macharm",
      "Ruqayya Iro",
      "Saheed Abdullahi",
      "Stephen Moore",
      "Bernard Opoku",
      "Zainab Akinjobi",
      "Abeeb Afolabi",
      "Nnaemeka Obiefuna",
      "Onyekachi Ogbu",
      "Sam Ochieng’",
      "Verrah Otiende",
      "Chinedu Mbonu",
      "Yao Lu",
      "Pontus Stenetorp"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.335": {
    "title": "TableLlama: Towards Open Large Generalist Models for Tables",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshu Zhang",
      "Xiang Yue",
      "Yifei Li",
      "Huan Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.336": {
    "title": "PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "HyunJin Kim",
      "Young Jin Kim",
      "JinYeong Bak"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.337": {
    "title": "Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yan",
      "Vikas Yadav",
      "Shiyang Li",
      "Lichang Chen",
      "Zheng Tang",
      "Hai Wang",
      "Vijay Srinivasan",
      "Xiang Ren",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.338": {
    "title": "Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuaijie She",
      "Shujian Huang",
      "Xingyun Wang",
      "Yanke Zhou",
      "Jiajun Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.339": {
    "title": "Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changjiang Gao",
      "Hongda Hu",
      "Peng Hu",
      "Jiajun Chen",
      "Jixing Li",
      "Shujian Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.340": {
    "title": "A Study on the Calibration of In-context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanlin Zhang",
      "YiFan Zhang",
      "Yaodong Yu",
      "Dhruv Madeka",
      "Dean Foster",
      "Eric Xing",
      "Himabindu Lakkaraju",
      "Sham Kakade"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.341": {
    "title": "DialogBench: Evaluating LLMs as Human-like Dialogue Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiao Ou",
      "Junda Lu",
      "Che Liu",
      "Yihong Tang",
      "Fuzheng Zhang",
      "Di Zhang",
      "Kun Gai"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.342": {
    "title": "GINopic: Topic Modeling with Graph Isomorphism Network",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suman Adhya",
      "Debarshi Sanyal"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.343": {
    "title": "CMB: A Comprehensive Medical Benchmark in Chinese",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xidong Wang",
      "Guiming Chen",
      "Song Dingjie",
      "Zhang Zhiyi",
      "Zhihong Chen",
      "Qingying Xiao",
      "Junying Chen",
      "Feng Jiang",
      "Jianquan Li",
      "Xiang Wan",
      "Benyou Wang",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.344": {
    "title": "Massive End-to-end Speech Recognition Models with Time Reduction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiran Wang",
      "Rohit Prabhavalkar",
      "Haozhe Shan",
      "Zhong Meng",
      "Dongseong Hwang",
      "Qiujia Li",
      "Khe Chai Sim",
      "Bo Li",
      "James Qin",
      "Xingyu Cai",
      "Adam Stooke",
      "Chengjian Zheng",
      "Yanzhang He",
      "Tara Sainath",
      "Pedro Moreno Mengibar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.345": {
    "title": "SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arash Ardakani",
      "Altan Haan",
      "Shangyin Tan",
      "Doru Thom Popovici",
      "Alvin Cheung",
      "Costin Iancu",
      "Koushik Sen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.346": {
    "title": "Effective Large Language Model Adaptation for Improved Grounding and Citation Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Ye",
      "Ruoxi Sun",
      "Sercan Arik",
      "Tomas Pfister"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.347": {
    "title": "Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijia Shao",
      "Yucheng Jiang",
      "Theodore Kanell",
      "Peter Xu",
      "Omar Khattab",
      "Monica Lam"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.348": {
    "title": "Grounding Gaps in Language Model Generations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omar Shaikh",
      "Kristina Gligoric",
      "Ashna Khetan",
      "Matthias Gerstgrasser",
      "Diyi Yang",
      "Dan Jurafsky"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.349": {
    "title": "When Does Monolingual Data Help Multilingual Translation: The Role of Domain and Model Scale",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christos Baziotis",
      "Biao Zhang",
      "Alexandra Birch",
      "Barry Haddow"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.350": {
    "title": "ContraSim – Analyzing Neural Representations Based on Contrastive Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adir Rahamim",
      "Yonatan Belinkov"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.351": {
    "title": "Universal Prompt Optimizer for Safe Text-to-Image Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongyu Wu",
      "Hongcheng Gao",
      "Yueze Wang",
      "Xiang Zhang",
      "Suhang Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.352": {
    "title": "Language Model Based Unsupervised Dependency Parsing with Conditional Mutual Information and Grammatical Constraints",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Chen",
      "Xiangheng He",
      "Yusuke Miyao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.353": {
    "title": "The Bias Amplification Paradox in Text-to-Image Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Preethi Seshadri",
      "Sameer Singh",
      "Yanai Elazar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.354": {
    "title": "Grammar-based Data Augmentation for Low-Resource Languages: The Case of Guarani-Spanish Neural Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Agustín Lucas",
      "Alexis Baladón",
      "Victoria Pardiñas",
      "Marvin Agüero-Torales",
      "Santiago Góngora",
      "Luis Chiruzzo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.355": {
    "title": "Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anjishnu Mukherjee",
      "Aylin Caliskan",
      "Ziwei Zhu",
      "Antonios Anastasopoulos"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.356": {
    "title": "Toward Interactive Regional Understanding in Vision-Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jungbeom Lee",
      "Sanghyuk Chun",
      "Sangdoo Yun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.357": {
    "title": "ScriptMix: Mixing Scripts for Low-resource Language Parsing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeseong Lee",
      "Dohyeon Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.358": {
    "title": "MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahuan Li",
      "Shanbo Cheng",
      "Shujian Huang",
      "Jiajun Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.359": {
    "title": "ToXCL: A Unified Framework for Toxic Speech Detection and Explanation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nhat Hoang",
      "Do Long",
      "Duc Anh Do",
      "Duc Anh Vu",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.360": {
    "title": "LinkPrompt: Natural and Universal Adversarial Attacks on Prompt-based Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Xu",
      "Wenjie Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.361": {
    "title": "CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanchong Zhang",
      "Ruisheng Cao",
      "Hongshen Xu",
      "Lu Chen",
      "Kai Yu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.362": {
    "title": "ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jierui Li",
      "Vipul Raheja",
      "Dhruv Kumar"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.363": {
    "title": "Entity Disambiguation via Fusion Entity Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junxiong Wang",
      "Ali Mousavi",
      "Omar Attia",
      "Ronak Pradeep",
      "Saloni Potdar",
      "Alexander Rush",
      "Umar Farooq Minhas",
      "Yunyao Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.364": {
    "title": "PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myeonghwa Lee",
      "Seonho An",
      "Min-Soo Kim"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.365": {
    "title": "GPTScore: Evaluate as You Desire",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinlan Fu",
      "See-Kiong Ng",
      "Zhengbao Jiang",
      "Pengfei Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.366": {
    "title": "A Survey of Confidence Estimation and Calibration in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Geng",
      "Fengyu Cai",
      "Yuxia Wang",
      "Heinz Koeppl",
      "Preslav Nakov",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.367": {
    "title": "Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Tang",
      "Hongyuan Lu",
      "Yuchen Jiang",
      "Haoyang Huang",
      "Dongdong Zhang",
      "Xin Zhao",
      "Tom Kocmi",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.368": {
    "title": "Separation and Fusion: A Novel Multiple Token Linking Model for Event Argument Extraction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Xu",
      "Dandan Song",
      "Siu Hui",
      "Zhijing Wu",
      "Meihuizi Jia",
      "Hao Wang",
      "Yanru Zhou",
      "Changzhi Zhou",
      "Ziyi Yang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.369": {
    "title": "The Integration of Semantic and Structural Knowledge in Knowledge Graph Entity Typing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muzhi Li",
      "Minda Hu",
      "Irwin King",
      "Ho-fung Leung"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.370": {
    "title": "ComCLIP: Training-Free Compositional Image and Text Matching",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kenan Jiang",
      "Xuehai He",
      "Ruize Xu",
      "Xin Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.371": {
    "title": "ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sotaro Takeshita",
      "Tommaso Green",
      "Ines Reinig",
      "Kai Eckert",
      "Simone Ponzetto"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.372": {
    "title": "XAL: EXplainable Active Learning Makes Classifiers Better Low-resource Learners",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Luo",
      "Zhen Yang",
      "Fandong Meng",
      "Yingjie Li",
      "Fang Guo",
      "Qinglin Qi",
      "Jie Zhou",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.373": {
    "title": "LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchi Wang",
      "Shuhuai Ren",
      "Rundong Gao",
      "Linli Yao",
      "Qingyan Guo",
      "Kaikai An",
      "Jianhong Bai",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.374": {
    "title": "Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amey Hengle",
      "Aswini Padhi",
      "Sahajpreet Singh",
      "Anil Bandhakavi",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.375": {
    "title": "Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhichen Dong",
      "Zhanhui Zhou",
      "Chao Yang",
      "Jing Shao",
      "Yu Qiao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.376": {
    "title": "Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weize Liu",
      "Guocong Li",
      "Kai Zhang",
      "Bang Du",
      "Qiyuan Chen",
      "Xuming Hu",
      "Hongxia Xu",
      "Jintai Chen",
      "Jian Wu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.377": {
    "title": "Divergent Token Metrics: Measuring degradation to prune away LLM components – and optimize quantization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Björn Deiseroth",
      "Max Meuer",
      "Nikolas Gritsch",
      "Constantin Eichenberg",
      "Patrick Schramowski",
      "Matthias Aßenmacher",
      "Kristian Kersting"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.378": {
    "title": "Beyond Performance: Quantifying and Mitigating Label Bias in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuval Reif",
      "Roy Schwartz"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.379": {
    "title": "Instructing Large Language Models to Identify and Ignore Irrelevant Conditions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Wu",
      "Chao Shen",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.380": {
    "title": "Lower Bounds on the Expressivity of Recurrent Neural Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anej Svete",
      "Franz Nowak",
      "Anisha Sahabdeen",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.381": {
    "title": "Transformers Can Represent n-gram Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anej Svete",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.382": {
    "title": "The Role of n-gram Smoothing in the Age of Neural Networks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Malagutti",
      "Andrius Buinovskij",
      "Anej Svete",
      "Clara Meister",
      "Afra Amini",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.383": {
    "title": "Reliability Estimation of News Media Sources: Birds of a Feather Flock Together",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sergio Burdisso",
      "Dairazalia Sanchez-cortes",
      "Esaú Villatoro-tello",
      "Petr Motlicek"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.384": {
    "title": "On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takeshi Kojima",
      "Itsuki Okimura",
      "Yusuke Iwasawa",
      "Hitomi Yanaka",
      "Yutaka Matsuo"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.385": {
    "title": "NLP Progress in Indigenous Latin American Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atnafu Tonja",
      "Fazlourrahman Balouchzahi",
      "Sabur Butt",
      "Olga Kolesnikova",
      "Hector Ceballos",
      "Alexander Gelbukh",
      "Thamar Solorio"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.386": {
    "title": "On the Effectiveness of Adversarial Robustness for Abuse Mitigation with Counterspeech",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Ling Chung",
      "Jonathan Bright"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.387": {
    "title": "Leveraging the Structure of Pre-trained Embeddings to Minimize Annotation Effort",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cesar Gonzalez-Gutierrez",
      "Ariadna Quattoni"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.388": {
    "title": "UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijun Yang",
      "Jie He",
      "Pinzhen Chen",
      "Victor Gutierrez Basulto",
      "Jeff Pan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.389": {
    "title": "Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soyeong Jeong",
      "Jinheon Baek",
      "Sukmin Cho",
      "Sung Ju Hwang",
      "Jong Park"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.390": {
    "title": "Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukun Zhao",
      "Lingyong Yan",
      "Weiwei Sun",
      "Guoliang Xing",
      "Chong Meng",
      "Shuaiqiang Wang",
      "Zhicong Cheng",
      "Zhaochun Ren",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.391": {
    "title": "Are Large Language Model Temporally Grounded?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Qiu",
      "Zheng Zhao",
      "Yftah Ziser",
      "Anna Korhonen",
      "Edoardo Ponti",
      "Shay Cohen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.392": {
    "title": "Document Image Machine Translation with Dynamic Multi-pre-trained Models Assembling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yupu Liang",
      "Yaping Zhang",
      "Cong Ma",
      "Zhiyang Zhang",
      "Yang Zhao",
      "Lu Xiang",
      "Chengqing Zong",
      "Yu Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.393": {
    "title": "Elastic Weight Removal for Faithful and Abstractive Dialogue Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nico Daheim",
      "Nouha Dziri",
      "Mrinmaya Sachan",
      "Iryna Gurevych",
      "Edoardo Ponti"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.394": {
    "title": "R-Tuning: Instructing Large Language Models to Say ‘I Don't Know",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanning Zhang",
      "Shizhe Diao",
      "Yong Lin",
      "Yi Fung",
      "Qing Lian",
      "Xingyao Wang",
      "Yangyi Chen",
      "Heng Ji",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.395": {
    "title": "Bridging the Gap between Different Vocabularies for LLM Ensemble",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangyifan Xu",
      "Jinliang Lu",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.396": {
    "title": "KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xindi Luo",
      "Zequn Sun",
      "Jing Zhao",
      "Zhe Zhao",
      "Wei Hu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.397": {
    "title": "Extremely Weakly-supervised Text Classification with Wordsets Mining and Sync-Denoising",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lysa Xiao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.398": {
    "title": "F-MALLOC: Feed-forward Memory Allocation for Continual Learning in Neural Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhong Wu",
      "Yuchen Liu",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.399": {
    "title": "Towards Reducing Diagnostic Errors with Interpretable Risk Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Denis McInerney",
      "William Dickinson",
      "Lucy Flynn",
      "Andrea Young",
      "Geoffrey Young",
      "Jan-Willem van de Meent",
      "Byron Wallace"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.400": {
    "title": "Generalizable Multilingual Hate Speech Detection on Low Resource Indian Languages using Fair Selection in Federated Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshay Singh",
      "Rahul Thakur"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.401": {
    "title": "Key ingredients for effective zero-shot cross-lingual knowledge transfer in generative tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nadezhda Chirkova",
      "Vassilina Nikoulina"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.402": {
    "title": "The Impact of Depth on Compositional Generalization in Transformer Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jackson Petty",
      "Sjoerd Steenkiste",
      "Ishita Dasgupta",
      "Fei Sha",
      "Dan Garrette",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.403": {
    "title": "Pregnant Questions: The Importance of Pragmatic Awareness in Maternal Health Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neha Srikanth",
      "Rupak Sarkar",
      "Heran Mane",
      "Elizabeth Aparicio",
      "Quynh Nguyen",
      "Rachel Rudinger",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.404": {
    "title": "Towards Explainability in Legal Outcome Prediction Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Josef Valvoda",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.405": {
    "title": "The steerability of large language models toward data-driven personas",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Li",
      "Charith Peris",
      "Ninareh Mehrabi",
      "Palash Goyal",
      "Kai-Wei Chang",
      "Aram Galstyan",
      "Richard Zemel",
      "Rahul Gupta"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.406": {
    "title": "CCSum: A Large-Scale and High-Quality Dataset for Abstractive News Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Jiang",
      "Markus Dreyer"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.407": {
    "title": "Capturing Perspectives of Crowdsourced Annotators in Subjective Learning Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Negar Mokhberian",
      "Myrl Marmarelis",
      "Frederic Hopp",
      "Valerio Basile",
      "Fred Morstatter",
      "Kristina Lerman"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.408": {
    "title": "Improving Factual Accuracy of Neural Table-to-Text Output by Addressing Input Problems in ToTTo",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barkavi Sundararajan",
      "Yaji Sripada",
      "Ehud Reiter"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.409": {
    "title": "CERET: Cost-Effective Extrinsic Refinement for Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jason Cai",
      "Hang Su",
      "Monica Sunkara",
      "Igor Shalyminov",
      "Saab Mansour"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.410": {
    "title": "Parameter-Efficient Instruction Tuning of Large Language Models For Extreme Financial Numeral Labelling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhendu Khatuya",
      "Rajdeep Mukherjee",
      "Akash Ghosh",
      "Manjunath Hegde",
      "Koustuv Dasgupta",
      "Niloy Ganguly",
      "Saptarshi Ghosh",
      "Pawan Goyal"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.411": {
    "title": "Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maryam Davoodi",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.412": {
    "title": "DeMuX: Data-efficient Multilingual Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simran Khanuja",
      "Srinivas Gowriraj",
      "Lucio Dery",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.413": {
    "title": "DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by Diversifying Synthetic Query Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramraj Chandradevan",
      "Kaustubh Dhole",
      "Eugene Agichtein"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.414": {
    "title": "How did we get here? Summarizing conversation dynamics",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilun Hua",
      "Nicholas Chernogor",
      "Yuzhe Gu",
      "Seoyeon Jeong",
      "Miranda Luo",
      "Cristian Danescu-Niculescu-Mizil"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.415": {
    "title": "Can Language Model Moderators Improve the Health of Online Discourse?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyundong Cho",
      "Shuai Liu",
      "Taiwei Shi",
      "Darpan Jain",
      "Basem Rizk",
      "Yuyang Huang",
      "Zixun Lu",
      "Nuan Wen",
      "Jonathan Gratch",
      "Emilio Ferrara",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.416": {
    "title": "LeanReasoner: Boosting Complex Logical Reasoning with Lean",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongwei Jiang",
      "Marcio Fonseca",
      "Shay Cohen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.417": {
    "title": "UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jason Wu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.418": {
    "title": "Measuring Cross-lingual Transfer in Bytes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leandro De Souza",
      "Thales Almeida",
      "Roberto Lotufo",
      "Rodrigo Frassetto Nogueira"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.419": {
    "title": "MisgenderMender: A Community-Informed Approach to Interventions for Misgendering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tamanna Hossain",
      "Sunipa Dev",
      "Sameer Singh"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.420": {
    "title": "Interplay of Machine Translation, Diacritics, and Diacritization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Rui Chen",
      "Ife Adebara",
      "Muhammad Abdul-Mageed"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.421": {
    "title": "From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Li",
      "Yong Zhang",
      "Zhitao Li",
      "Jiuhai Chen",
      "Lichang Chen",
      "Ning Cheng",
      "Jianzong Wang",
      "Tianyi Zhou",
      "Jing Xiao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.422": {
    "title": "Safer-Instruct: Aligning Language Models with Automated Preference Data",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taiwei Shi",
      "Kai Chen",
      "Jieyu Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.423": {
    "title": "PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Peper",
      "Wenzhao Qiu",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.424": {
    "title": "Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bangzheng Li",
      "Ben Zhou",
      "Fei Wang",
      "Xingyu Fu",
      "Dan Roth",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.425": {
    "title": "IndiSentiment140: Sentiment Analysis Dataset for Indian Languages with Emphasis on Low-Resource Languages using Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saurabh Kumar",
      "Ranbir Sanasam",
      "Sukumar Nandi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.426": {
    "title": "Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nandan Thakur",
      "Jianmo Ni",
      "Gustavo Hernandez Abrego",
      "John Wieting",
      "Jimmy Lin",
      "Daniel Cer"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.427": {
    "title": "SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunjong Ok",
      "Taeho Kil",
      "Sukmin Seo",
      "Jaeho Lee"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.428": {
    "title": "A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Tian",
      "Nan Xu",
      "Wenji Mao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.429": {
    "title": "Learning to Compress Prompt in Natural Language Formats",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Neng Chuang",
      "Tianwei Xing",
      "Chia-Yuan Chang",
      "Zirui Liu",
      "Xun Chen",
      "Xia Hu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.430": {
    "title": "Automatic, Meta and Human Evaluation for Multimodal Summarization with Multimodal Output",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haojie Zhuang",
      "Wei Emma Zhang",
      "Leon Xie",
      "Weitong Chen",
      "Jian Yang",
      "Quan Sheng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.431": {
    "title": "Naive Bayes-based Context Extension for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianlin Su",
      "Murtadha Ahmed",
      "Bo Wen",
      "Luo Ao",
      "Mingren Zhu",
      "Yunfeng Liu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.432": {
    "title": "Leitner-Guided Memory Replay for Cross-lingual Continual Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meryem M’hamdi",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.433": {
    "title": "Multilingual Nonce Dependency Treebanks: Understanding how Language Models Represent and Process Syntactic Structure",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Arps",
      "Laura Kallmeyer",
      "Younes Samih",
      "Hassan Sajjad"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.434": {
    "title": "Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinggui Liang",
      "Lizi Liao",
      "Hao Fei",
      "Bobo Li",
      "Jing Jiang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.435": {
    "title": "Explaining Text Similarity in Transformer Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandros Vasileiou",
      "Oliver Eberle"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.436": {
    "title": "Large Language Models can Contrastively Refine their Generation for Better Sentence Representation Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiming Wang",
      "Zhaodonghui Li",
      "Liying Cheng",
      "De Wen Soh",
      "Lidong Bing"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.437": {
    "title": "HIL: Hybrid Isotropy Learning for Zero-shot Performance in Dense retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeyoung Kim",
      "Dohyeon Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.438": {
    "title": "SuperGLEBer: German Language Understanding Evaluation Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Pfister",
      "Andreas Hotho"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.439": {
    "title": "You are an expert annotator\": Automatic Best–Worst-Scaling Annotations for Emotion Intensity Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christopher Bagdon",
      "Prathamesh Karmalkar",
      "Harsha Gurulingappa",
      "Roman Klinger"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.440": {
    "title": "What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Zeng",
      "Hanbo Zhang",
      "Jiani Zheng",
      "Jiangnan Xia",
      "Guoqiang Wei",
      "Yang Wei",
      "Yuchen Zhang",
      "Tao Kong",
      "Ruihua Song"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.441": {
    "title": "Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ruan",
      "WangWenqing WangWenqing",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.442": {
    "title": "MOSAICo: a Multilingual Open-text Semantically Annotated Interlinked Corpus",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simone Conia",
      "Edoardo Barba",
      "Abelardo Carlos Martinez Lorenzo",
      "Pere-Lluís Huguet Cabot",
      "Riccardo Orlando",
      "Luigi Procopio",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.443": {
    "title": "SemRoDe: Macro Adversarial Training to Learn Representations that are Robust to Word-Level Attacks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brian Formento",
      "Wenjie Feng",
      "Chuan-Sheng Foo",
      "Anh Tuan Luu",
      "See-Kiong Ng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.444": {
    "title": "BUST: Benchmark for the evaluation of detectors of LLM-Generated Text",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Cornelius",
      "Oscar Lithgow-Serrano",
      "Sandra Mitrovic",
      "Ljiljana Dolamic",
      "Fabio Rinaldi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.445": {
    "title": "Improving In-context Learning of Multilingual Generative Language Models with Cross-lingual Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Li",
      "Shaonan Wang",
      "Jiajun Zhang",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.446": {
    "title": "MaCSC: Towards Multimodal-augmented Pre-trained Language Models via Conceptual Prototypes and Self-balancing Calibration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianwei Zhuang",
      "Zhichang Wang",
      "Xuxin Cheng",
      "Yuxin Xie",
      "Liming Liang",
      "Yuexian Zou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.447": {
    "title": "Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.448": {
    "title": "Discovering Lobby-Parliamentarian Alignments through NLP",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aswin Suresh",
      "Lazar Radojević",
      "Francesco Salvi",
      "Antoine Magron",
      "Victor Kristof",
      "Matthias Grossglauser"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.449": {
    "title": "IterCQR: Iterative Conversational Query Reformulation with Retrieval Guidance",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunah Jang",
      "Kang-il Lee",
      "Hyunkyung Bae",
      "Hwanhee Lee",
      "Kyomin Jung"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.450": {
    "title": "AceGPT, Localizing Large Language Models in Arabic",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huang Huang",
      "Fei Yu",
      "Jianqing Zhu",
      "Xuening Sun",
      "Hao Cheng",
      "Song Dingjie",
      "Zhihong Chen",
      "Mosen Alharthi",
      "Bang An",
      "Juncai He",
      "Ziche Liu",
      "Junying Chen",
      "Jianquan Li",
      "Benyou Wang",
      "Lian Zhang",
      "Ruoyu Sun",
      "Xiang Wan",
      "Haizhou Li",
      "Jinchao Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.451": {
    "title": "Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei He",
      "Xing Wang",
      "Wenxiang Jiao",
      "Zhuosheng Zhang",
      "Rui Wang",
      "Shuming Shi",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.452": {
    "title": "Depression Detection in Clinical Interviews with LLM-Empowered Structural Element Graph",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuang Chen",
      "Jiawen Deng",
      "Jinfeng Zhou",
      "Jincenzi Wu",
      "Tieyun Qian",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.453": {
    "title": "SQATIN: Supervised Instruction Tuning Meets Question Answering for Improved Dialogue NLU",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Evgeniia Razumovskaia",
      "Goran Glavaš",
      "Anna Korhonen",
      "Ivan Vulić"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.454": {
    "title": "Enhancing Argument Summarization: Prioritizing Exhaustiveness in Key Point Generation and Introducing an Automatic Coverage Evaluation Metric",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Khosravani",
      "Chenyang Huang",
      "Amine Trabelsi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.455": {
    "title": "ARM: Alignment with Residual Energy-Based Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Pang",
      "Caiming Xiong",
      "Yingbo Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.456": {
    "title": "HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Milan Gritta",
      "Gerasimos Lampouras",
      "Ignacio Iacobacci"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.457": {
    "title": "FAMuS: Frames Across Multiple Sources",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Vashishtha",
      "Alexander Martin",
      "William Gantt",
      "Benjamin Van Durme",
      "Aaron White"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.458": {
    "title": "Rationale-based Opinion Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyuan Li",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.459": {
    "title": "Mustango: Toward Controllable Text-to-Music Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Melechovsky",
      "Zixun Guo",
      "Deepanway Ghosal",
      "Navonil Majumder",
      "Dorien Herremans",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.460": {
    "title": "Adaptive Cross-lingual Text Classification through In-Context One-Shot Demonstrations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emilio Cueva",
      "Adrian Lopez Monroy",
      "Fernando Sánchez-Vega",
      "Thamar Solorio"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.461": {
    "title": "CNER: Concept and Named Entity Recognition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuliano Martinelli",
      "Francesco Molfese",
      "Simone Tedeschi",
      "Alberte Fernández-Castro",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.462": {
    "title": "Branch-Solve-Merge Improves Large Language Model Evaluation and Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Swarnadeep Saha",
      "Omer Levy",
      "Asli Celikyilmaz",
      "Mohit Bansal",
      "Jason Weston",
      "Xian Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.463": {
    "title": "REPLUG: Retrieval-Augmented Black-Box Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijia Shi",
      "Sewon Min",
      "Michihiro Yasunaga",
      "Minjoon Seo",
      "Richard James",
      "Mike Lewis",
      "Luke Zettlemoyer",
      "Wen-tau Yih"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.464": {
    "title": "David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaochuang Han",
      "Sachin Kumar",
      "Yulia Tsvetkov",
      "Marjan Ghazvininejad"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.465": {
    "title": "Efficient End-to-End Visual Document Understanding with Rationale Distillation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wang Zhu",
      "Alekh Agarwal",
      "Mandar Joshi",
      "Robin Jia",
      "Jesse Thomason",
      "Kristina Toutanova"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.466": {
    "title": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiwalayo Eisape",
      "Michael Tessler",
      "Ishita Dasgupta",
      "Fei Sha",
      "Sjoerd Steenkiste",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.467": {
    "title": "AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pietro Lesci",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.468": {
    "title": "ICLE++: Modeling Fine-Grained Traits for Holistic Essay Scoring",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengjie Li",
      "Vincent Ng"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.469": {
    "title": "UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenting Zhao",
      "Justin Chiu",
      "Jena Hwang",
      "Faeze Brahman",
      "Jack Hessel",
      "Sanjiban Choudhury",
      "Yejin Choi",
      "Xiang Li",
      "Alane Suhr"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.470": {
    "title": "To Tell The Truth: Language of Deception and Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanchaita Hazra",
      "Bodhisattwa Prasad Majumder"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.471": {
    "title": "Multilingual Models for ASR in Chibchan Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rolando Coto-Solano",
      "Tai Wan Kim",
      "Alexander Jones",
      "Sharid Loáiciga"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.472": {
    "title": "LegalDiscourse: Interpreting When Laws Apply and To Whom",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Spangher",
      "Zihan Xue",
      "Te-Lin Wu",
      "Mark Hansen",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.473": {
    "title": "X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented Instruction Tuning with Auxiliary Evaluation Aspects",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minqian Liu",
      "Ying Shen",
      "Zhiyang Xu",
      "Yixin Cao",
      "Eunah Cho",
      "Vaibhav Kumar",
      "Reza Ghanadan",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.474": {
    "title": "Is Reference Necessary in the Evaluation of NLG Systems? When and Where?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuqian Sheng",
      "Yi Xu",
      "Luoyi Fu",
      "Jiaxin Ding",
      "Lei Zhou",
      "Xinbing Wang",
      "Chenghu Zhou"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.475": {
    "title": "Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Su",
      "Tiep Le",
      "Steven Bethard",
      "Phillip Howard"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.476": {
    "title": "Evaluating the Deductive Competence of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "S Seals",
      "Valerie Shalin"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.477": {
    "title": "Large Human Language Models: A Need and the Challenges",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Soni",
      "H. Schwartz",
      "João Sedoc",
      "Niranjan Balasubramanian"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.478": {
    "title": "On Learning to Summarize with Large Language Models as References",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Liu",
      "Kejian Shi",
      "Katherine He",
      "Longtian Ye",
      "Alexander Fabbri",
      "Pengfei Liu",
      "Dragomir Radev",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.479": {
    "title": "Hallucination Diversity-Aware Active Learning for Text Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Xia",
      "Xu Liu",
      "Tong Yu",
      "Sungchul Kim",
      "Ryan Rossi",
      "Anup Rao",
      "Tung Mai",
      "Shuai Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.480": {
    "title": "Keep it Private: Unsupervised Privatization of Online Text",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Calvin Bao",
      "Marine Carpuat"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.481": {
    "title": "Tied-LoRA: Enhancing parameter efficiency of LoRA with Weight Tying",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adithya Renduchintala",
      "Tugrul Konuk",
      "Oleksii Kuchaiev"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.482": {
    "title": "Investigating Data Contamination in Modern Benchmarks for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunyuan Deng",
      "Yilun Zhao",
      "Xiangru Tang",
      "Mark Gerstein",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.483": {
    "title": "Pre-trained Language Models for Entity Blocking: A Reproducibility Study",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runhui Wang",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.484": {
    "title": "RE2: Region-Aware Relation Extraction from Visually Rich Documents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pritika Ramu",
      "Sijia Wang",
      "Lalla Mouatadid",
      "Joy Rimchala",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.485": {
    "title": "Mix-Initiative Response Generation with Dynamic Prefix Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Nie",
      "Heyan Huang",
      "Xian-Ling Mao",
      "Lizi Liao"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.486": {
    "title": "Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Value",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Yao",
      "Xiaoyuan Yi",
      "Yifan Gong",
      "Xiting Wang",
      "Xing Xie"
    ]
  },
  "https://aclanthology.org/2024.naacl-long.487": {
    "title": "IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nihar Sahoo",
      "Pranamya Kulkarni",
      "Arif Ahmad",
      "Tanu Goyal",
      "Narjis Asad",
      "Aparna Garimella",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.1": {
    "title": "Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anshuman Chhabra",
      "Hadi Askari",
      "Prasant Mohapatra"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.2": {
    "title": "Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangru Tang",
      "Yiming Zong",
      "Jason Phang",
      "Yilun Zhao",
      "Wangchunshu Zhou",
      "Arman Cohan",
      "Mark Gerstein"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.3": {
    "title": "Improving Toponym Resolution by Predicting Attributes to Constrain Geographical Ontology Entries",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyu Zhang",
      "Egoitz Laparra",
      "Steven Bethard"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.4": {
    "title": "Advancing Regular Language Reasoning in Linear Recurrent Neural Networks",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting-Han Fan",
      "Ta-Chung Chi",
      "Alexander Rudnicky"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.5": {
    "title": "Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Xie",
      "Orevaoghene Ahia",
      "Yulia Tsvetkov",
      "Antonios Anastasopoulos"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.6": {
    "title": "Clear Up Confusion: Advancing Cross-Domain Few-Shot Relation Extraction through Relation-Aware Prompt Learning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ge Bai",
      "Chenji Lu",
      "Daichi Guo",
      "Shilong Li",
      "Ying Liu",
      "Zhang Zhang",
      "Guanting Dong",
      "Ruifang Liu",
      "Sun Yong"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.7": {
    "title": "Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach for Zero-Shot Relation Extraction",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shilong Li",
      "Ge Bai",
      "Zhang Zhang",
      "Ying Liu",
      "Chenji Lu",
      "Daichi Guo",
      "Ruifang Liu",
      "Sun Yong"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.8": {
    "title": "Personalized Review Recommendation based on Implicit dimension mining",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bei Xu",
      "Yifan Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.9": {
    "title": "Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinhong Liu",
      "Yixuan Su",
      "Ehsan Shareghi",
      "Nigel Collier"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.10": {
    "title": "Returning to the Start: Generating Narratives with Related Endpoints",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anneliese Brei",
      "Chao Zhao",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.11": {
    "title": "Unified Examination of Entity Linking in Absence of Candidate Sets",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Ong",
      "Hassan Shavarani",
      "Anoop Sarkar"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.12": {
    "title": "MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daryna Dementieva",
      "Nikolay Babakov",
      "Alexander Panchenko"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.13": {
    "title": "SKICSE: Sentence Knowable Information Prompted by LLMs Improves Contrastive Sentence Embeddings",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangwei Ou",
      "Jinan Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.14": {
    "title": "A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaylen Jones",
      "Lingbo Mo",
      "Eric Fosler-Lussier",
      "Huan Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.15": {
    "title": "How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harmon Bhasin",
      "Timothy Ossowski",
      "Yiqiao Zhong",
      "Junjie Hu"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.16": {
    "title": "CELI: Simple yet Effective Approach to Enhance Out-of-Domain Generalization of Cross-Encoders",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Crystina Zhang",
      "Minghan Li",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.17": {
    "title": "ContrastiveMix: Overcoming Code-Mixing Dilemma in Cross-Lingual Transfer for Information Retrieval",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junggeun Do",
      "Jaeseong Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.18": {
    "title": "SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vikas Raunak",
      "Tom Kocmi",
      "Matt Post"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.19": {
    "title": "Separately Parameterizing Singleton Detection Improves End-to-end Neural Coreference Resolution",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiyuan Zou",
      "Yiran Li",
      "Ian Porada",
      "Jackie Cheung"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.20": {
    "title": "Unveiling Divergent Inductive Biases of LLMs on Temporal Data",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sindhu Kishore",
      "Hangfeng He"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.21": {
    "title": "On Retrieval Augmentation and the Limitations of Language Model Training",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting-Rui Chiang",
      "Xinyan Yu",
      "Joshua Robinson",
      "Ollie Liu",
      "Isabelle Lee",
      "Dani Yogatama"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.22": {
    "title": "GenDecider: Integrating \"None of the Candidates\" Judgments in Zero-Shot Entity Linking Re-ranking",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kang Zhou",
      "Yuepei Li",
      "Qing Wang",
      "Qiao Qiao",
      "Qi Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.23": {
    "title": "Advancing the Robustness of Large Language Models through Self-Denoised Smoothing",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiabao Ji",
      "Bairu Hou",
      "Zhen Zhang",
      "Guanhua Zhang",
      "Wenqi Fan",
      "Qing Li",
      "Yang Zhang",
      "Gaowen Liu",
      "Sijia Liu",
      "Shiyu Chang"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.24": {
    "title": "Can LLM's Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishnu Sashank Dorbala",
      "Sanjoy Chowdhury",
      "Dinesh Manocha"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.25": {
    "title": "On the Role of Summary Content Units in Text Summarization Evaluation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcel Nawrath",
      "Agnieszka Nowak",
      "Tristan Ratz",
      "Danilo Walenta",
      "Juri Opitz",
      "Leonardo Ribeiro",
      "João Sedoc",
      "Daniel Deutsch",
      "Simon Mille",
      "Yixin Liu",
      "Sebastian Gehrmann",
      "Lining Zhang",
      "Saad Mahamood",
      "Miruna Clinciu",
      "Khyathi Chandu",
      "Yufang Hou"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.26": {
    "title": "More room for language: Investigating the effect of retrieval on language models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Samuel",
      "Lucas Charpentier",
      "Sondre Wold"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.27": {
    "title": "Discourse-Aware In-Context Learning for Temporal Expression Normalization",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akash Gautam",
      "Lukas Lange",
      "Jannik Strötgen"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.28": {
    "title": "Contextualizing Argument Quality Assessment with Relevant Knowledge",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Darshan Deshpande",
      "Zhivar Sourati",
      "Filip Ilievski",
      "Fred Morstatter"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.29": {
    "title": "Selective Perception: Learning Concise State Descriptions for Language Model Actors",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kolby Nottingham",
      "Yasaman Razeghi",
      "Kyungmin Kim",
      "Jb Lanier",
      "Pierre Baldi",
      "Roy Fox",
      "Sameer Singh"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.30": {
    "title": "ALOHa: A New Measure for Hallucination in Captioning Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suzanne Petryk",
      "David Chan",
      "Anish Kachinthaya",
      "Haodi Zou",
      "John Canny",
      "Joseph Gonzalez",
      "Trevor Darrell"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.31": {
    "title": "Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honglei Zhuang",
      "Zhen Qin",
      "Kai Hui",
      "Junru Wu",
      "Le Yan",
      "Xuanhui Wang",
      "Michael Bendersky"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.32": {
    "title": "LLM-Driven Knowledge Injection Advances Zero-Shot and Cross-Target Stance Detection",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhao Zhang",
      "Yiming Li",
      "Jin Zhang",
      "Hui Xu"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.33": {
    "title": "Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shadi Iskander",
      "Kira Radinsky",
      "Yonatan Belinkov"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.34": {
    "title": "Direct Preference Optimization for Neural Machine Translation with Minimum Bayes Risk Decoding",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyu Yang",
      "Jinghong Chen",
      "Weizhe Lin",
      "Bill Byrne"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.35": {
    "title": "EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raja Sekhar Reddy Mekala",
      "Yasaman Razeghi",
      "Sameer Singh"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.36": {
    "title": "LEAF: Language Learners' English Essays and Feedback Corpus",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shabnam Behzad",
      "Omid Kashefi",
      "Swapna Somasundaran"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.37": {
    "title": "Zero-Shot vs. Translation-Based Cross-Lingual Transfer: The Case of Lexical Gaps",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abteen Ebrahimi",
      "Katharina Wense"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.38": {
    "title": "On the True Distribution Approximation of Minimum Bayes-Risk Decoding",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atsumoto Ohashi",
      "Ukyo Honda",
      "Tetsuro Morimura",
      "Yuu Jinnai"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.39": {
    "title": "Rehearsal-Free Modular and Compositional Continual Learning for Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyang Wang",
      "Heike Adel",
      "Lukas Lange",
      "Jannik Strötgen",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.40": {
    "title": "Llama meets EU: Investigating the European political spectrum through the lens of LLMs",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilias Chalkidis",
      "Stephanie Brandl"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.41": {
    "title": "M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Hsu",
      "Xiaoyu Liu",
      "Huayang Li",
      "Yoshinari Fujinuma",
      "Maria Nadejde",
      "Xing Niu",
      "Ron Litman",
      "Yair Kittenplon",
      "Raghavendra Pappagari"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.42": {
    "title": "Control-DAG: Constrained Decoding for Non-Autoregressive Directed Acyclic T5 using Weighted Finite State Automata",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinghong Chen",
      "Weizhe Lin",
      "Jingbiao Mei",
      "Bill Byrne"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.43": {
    "title": "Do Vision-Language Models Understand Compound Nouns?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sonal Kumar",
      "Sreyan Ghosh",
      "S Sakshi",
      "Utkarsh Tyagi",
      "Dinesh Manocha"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.44": {
    "title": "Is Prompt Transfer Always Effective? An Empirical Study of Prompt Transfer for Question Answering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minji Jung",
      "Soyeon Park",
      "Jeewoo Sul",
      "Yong Suk Choi"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.45": {
    "title": "Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georgios Pantazopoulos",
      "Alessandro Suglia",
      "Oliver Lemon",
      "Arash Eshghi"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.46": {
    "title": "Do Multilingual Language Models Think Better in English?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julen Etxaniz",
      "Gorka Azkune",
      "Aitor Soroa",
      "Oier Lacalle",
      "Mikel Artetxe"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.47": {
    "title": "A Continued Pretrained LLM Approach for Automatic Medical Note Generation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Yuan",
      "Eti Rastogi",
      "Gautam Naik",
      "Sree Prasanna Rajagopal",
      "Sagar Goyal",
      "Fen Zhao",
      "Bharath Chintagunta",
      "Jeffrey Ward"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.48": {
    "title": "Lost in Translation? Translation Errors and Challenges for Fair Assessment of Text-to-Image Models on Multilingual Concepts",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Saxon",
      "Yiran Luo",
      "Sharon Levy",
      "Chitta Baral",
      "Yezhou Yang",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.49": {
    "title": "Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingyu Xie",
      "Qi Li",
      "Yan Zhang",
      "Zuozhu Liu",
      "Hongwei Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.50": {
    "title": "Lifelong Event Detection with Embedding Space Separation and Compaction",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengwei Qin",
      "Ruirui Chen",
      "Ruochen Zhao",
      "Wenhan Xia",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.51": {
    "title": "Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Smriti Singh",
      "Cornelia Caragea",
      "Junyi Jessy Li"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.52": {
    "title": "CPopQA: Ranking Cultural Concept Popularity by LLMs",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Jiang",
      "Mansi Joshi"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.53": {
    "title": "The Impact of Language on Arithmetic Proficiency: A Multilingual Investigation with Cross-Agent Checking Computation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chung-Chi Chen",
      "Hiroya Takamura",
      "Ichiro Kobayashi",
      "Yusuke Miyao"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.54": {
    "title": "Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp Borchert",
      "Jochen De Weerdt",
      "Marie-Francine Moens"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.55": {
    "title": "A diverse Multilingual News Headlines Dataset from around the World",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Leeb",
      "Bernhard Schölkopf"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.56": {
    "title": "The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Evgeniia Tokarchuk",
      "Vlad Niculae"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.57": {
    "title": "Efficient Sample-Specific Encoder Perturbations",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yassir Fathullah",
      "Mark Gales"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.58": {
    "title": "Diverse Perspectives, Divergent Models: Cross-Cultural Evaluation of Depression Detection on Twitter",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nuredin Ali Abdelkadir",
      "Charles Zhang",
      "Ned Mayo",
      "Stevie Chancellor"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.59": {
    "title": "Removing RLHF Protections in GPT-4 via Fine-Tuning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiusi Zhan",
      "Richard Fang",
      "Rohan Bindu",
      "Akul Gupta",
      "Tatsunori Hashimoto",
      "Daniel Kang"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.60": {
    "title": "LifeTox: Unveiling Implicit Toxicity in Life Advice",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minbeom Kim",
      "Jahyun Koo",
      "Hwanhee Lee",
      "Joonsuk Park",
      "Hwaran Lee",
      "Kyomin Jung"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.61": {
    "title": "Arithmetic Reasoning with LLM: Prolog Generation & Permutation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaocheng Yang",
      "Bingsen Chen",
      "Yik-Cheung Tam"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.62": {
    "title": "Verifying Claims About Metaphors with Large-Scale Automatic Metaphor Identification",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kotaro Aono",
      "Ryohei Sasano",
      "Koichi Takeda"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.63": {
    "title": "InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Scaria",
      "Himanshu Gupta",
      "Siddharth Goyal",
      "Saurabh Sawant",
      "Swaroop Mishra",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.64": {
    "title": "MEMORY-VQ: Compression for Tractable Internet-Scale Memory",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yury Zemlyanskiy",
      "Michiel de Jong",
      "Luke Vilnis",
      "Santiago Ontanon",
      "William Cohen",
      "Sumit Sanghai",
      "Joshua Ainslie"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.65": {
    "title": "Unveiling the Magic: Investigating Attention Distillation in Retrieval-Augmented Generation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizhong Li",
      "Haopeng Zhang",
      "Jiawei Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.66": {
    "title": "Improving Factuality in Clinical Abstractive Multi-Document Summarization by Guided Continued Pre-training",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Elhady",
      "Khaled Elsayed",
      "Eneko Agirre",
      "Mikel Artetxe"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.67": {
    "title": "MuLan: A Study of Fact Mutability in Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Constanza Fierro",
      "Nicolas Garneau",
      "Emanuele Bugliarello",
      "Yova Kementchedjhieva",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.68": {
    "title": "Language-Independent Representations Improve Zero-Shot Summarization",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vladimir Solovyev",
      "Danni Liu",
      "Jan Niehues"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.69": {
    "title": "Trusting Your Evidence: Hallucinate Less with Context-aware Decoding",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijia Shi",
      "Xiaochuang Han",
      "Mike Lewis",
      "Yulia Tsvetkov",
      "Luke Zettlemoyer",
      "Wen-tau Yih"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.70": {
    "title": "GuyLingo: The Republic of Guyana Creole Corpora",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christopher Clarke",
      "Roland Daynauth",
      "Jason Mars",
      "Charlene Wilkinson",
      "Hubert Devonish"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.71": {
    "title": "DoubleLingo: Causal Estimation with Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marko Veljanovski",
      "Zach Wood-Doughty"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.72": {
    "title": "Improved Text Emotion Prediction Using Combined Valence and Arousal Ordinal Classification",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michail Mitsios",
      "Georgios Vamvoukakis",
      "Georgia Maniati",
      "Nikolaos Ellinas",
      "Georgios Dimitriou",
      "Konstantinos Markopoulos",
      "Panos Kakoulidis",
      "Alexandra Vioni",
      "Myrsini Christidou",
      "Junkwang Oh",
      "Gunu Jho",
      "Inchul Hwang",
      "Georgios Vardaxoglou",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis",
      "Spyros Raptis"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.73": {
    "title": "On Narrative Question Answering Skills",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emil Kalbaliyev",
      "Kairit Sirts"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.74": {
    "title": "Order-Based Pre-training Strategies for Procedural Text Understanding",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhilash Nandy",
      "Yash Kulkarni",
      "Pawan Goyal",
      "Niloy Ganguly"
    ]
  },
  "https://aclanthology.org/2024.naacl-short.75": {
    "title": "Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yotam Intrator",
      "Matan Halfon",
      "Roman Goldenberg",
      "Reut Tsarfaty",
      "Matan Eyal",
      "Ehud Rivlin",
      "Yossi Matias",
      "Natalia Aizenberg"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.1": {
    "title": "TOPICAL: TOPIC Pages AutomagicaLly",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "John Giorgi",
      "Amanpreet Singh",
      "Doug Downey",
      "Sergey Feldman",
      "Lucy Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.2": {
    "title": "Low-code LLM: Graphical User Interface over Large Language Models",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhe Cai",
      "Shaoguang Mao",
      "Wenshan Wu",
      "Zehua Wang",
      "Yaobo Liang",
      "Tao Ge",
      "Chenfei Wu",
      "WangYou WangYou",
      "Ting Song",
      "Yan Xia",
      "Nan Duan",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.3": {
    "title": "EdTec-QBuilder: A Semantic Retrieval Tool for Assembling Vocational Training Exams in German Language",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alonso Palomino",
      "Andreas Fischer",
      "Jakub Kuzilek",
      "Jarek Nitsch",
      "Niels Pinkwart",
      "Benjamin Paassen"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.4": {
    "title": "DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songbo Hu",
      "Xiaobin Wang",
      "Moy Yuan",
      "Anna Korhonen",
      "Ivan Vulić"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.5": {
    "title": "RTSUM: Relation Triple-based Interpretable Summarization with Multi-level Salience Visualization",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seonglae Cho",
      "Myungha Jang",
      "Jinyoung Yeo",
      "Dongha Lee"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.6": {
    "title": "Edu-ConvoKit: An Open-Source Library for Education Conversation Data",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rose Wang",
      "Dorottya Demszky"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.7": {
    "title": "jp-evalb: Robust Alignment-based PARSEVAL Measures",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jungyeul Park",
      "Junrui Wang",
      "Eunkyul Jo",
      "Angela Park"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.8": {
    "title": "OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Haller",
      "Ansar Aynetdinov",
      "Alan Akbik"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.9": {
    "title": "ATLAS: A System for PDF-centric Human Interaction Data Collection",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexa Siu",
      "Zichao Wang",
      "Joshua Hoeflich",
      "Naman Kapasi",
      "Ani Nenkova",
      "Tong Sun"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.10": {
    "title": "BeLeaf: Belief Prediction as Tree Generation",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "John Murzaku",
      "Owen Rambow"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.11": {
    "title": "QueryExplorer: An Interactive Query Generation Assistant for Search and Exploration",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaustubh Dhole",
      "Shivam Bajaj",
      "Ramraj Chandradevan",
      "Eugene Agichtein"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.12": {
    "title": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shizhe Diao",
      "Rui Pan",
      "Hanze Dong",
      "KaShun Shum",
      "Jipeng Zhang",
      "Wei Xiong",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.13": {
    "title": "DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document Question-Answering",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Nguyen",
      "Zilong Wang",
      "Jingbo Shang",
      "Dheeraj Mekala"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.14": {
    "title": "RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Tan",
      "Yun Zhu",
      "Lijuan Liu",
      "Hongyi Wang",
      "Yonghao Zhuang",
      "Jindong Chen",
      "Eric Xing",
      "Zhiting Hu"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.15": {
    "title": "Concept Over Time Analysis: Unveiling Temporal Patterns for Qualitative Data Analysis",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim Fischer",
      "Florian Schneider",
      "Robert Geislinger",
      "Florian Helfer",
      "Gertraud Koch",
      "Chris Biemann"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.16": {
    "title": "pyvene: A Library for Understanding and Improving PyTorch Models via Interventions",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengxuan Wu",
      "Atticus Geiger",
      "Aryaman Arora",
      "Jing Huang",
      "Zheng Wang",
      "Noah Goodman",
      "Christopher Manning",
      "Christopher Potts"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.17": {
    "title": "Newspaper Signaling for Crisis Prediction",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prajvi Saxena",
      "Sabine Janzen",
      "Wolfgang Maass"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.18": {
    "title": "FastFit: Fast and Effective Few-Shot Text Classification with a Multitude of Classes",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asaf Yehudai",
      "Elron Bandel"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.19": {
    "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Gioacchini",
      "Giuseppe Siracusano",
      "Davide Sanvito",
      "Kiril Gashteovski",
      "David Friede",
      "Roberto Bifulco",
      "Carolin Lawrence"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.20": {
    "title": "ZhuJiu-Knowledge: A Fairer Platform for Evaluating Multiple Knowledge Types in Large Language Models",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfan Du",
      "Sirui Liang",
      "Baoli Zhang",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2024.naacl-demo.21": {
    "title": "Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI",
    "volume": "demo",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elron Bandel",
      "Yotam Perlitz",
      "Elad Venezian",
      "Roni Friedman",
      "Ofir Arviv",
      "Matan Orbach",
      "Shachar Don-Yehiya",
      "Dafna Sheinwald",
      "Ariel Gera",
      "Leshem Choshen",
      "Michal Shmueli-Scheuer",
      "Yoav Katz"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.1": {
    "title": "Systematic Analysis for Pretrained Language Model Priming for Parameter-Efficient Fine-tuning",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shih-Cheng Huang",
      "Shih-Heng Wang",
      "Min-Han Shih",
      "Saurav Sahay",
      "Hung-yi Lee"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.2": {
    "title": "Rephrasing Invokes Better Generations for Large Language Models",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Yang",
      "Hongyuan Lu",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.3": {
    "title": "Exploring Compositional Generalization of Large Language Models",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Yang",
      "Hongyuan Lu",
      "Wai Lam",
      "Deng Cai"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.4": {
    "title": "Explainable CED: A Dataset for Explainable Critical Error Detection in Machine Translation",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dahyun Jung",
      "Sugyeong Eo",
      "Chanjun Park",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.5": {
    "title": "SMARTR: A Framework for Early Detection using Survival Analysis of Longitudinal Texts",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jean-Thomas Baillargeon",
      "Luc Lamontagne"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.6": {
    "title": "Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Richard Zhu"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.7": {
    "title": "Start Simple: Progressive Difficulty Multitask Learning",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunfei Luo",
      "Yuyang Liu",
      "Rukai Cai",
      "Tauhidur Rahman"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.8": {
    "title": "LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joe Stacey",
      "Jianpeng Cheng",
      "John Torr",
      "Tristan Guigue",
      "Joris Driesen",
      "Alexandru Coca",
      "Mark Gaynor",
      "Anders Johannsen"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.9": {
    "title": "Fine-tuning Pre-trained Named Entity Recognition Models For Indian Languages",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sankalp Bahad",
      "Pruthwik Mishra",
      "Parameswari Krishnamurthy",
      "Dipti Sharma"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.10": {
    "title": "Knowledge-centered conversational agents with a drive to learn",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Selene Baez Santamaria"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.11": {
    "title": "Exploring Inherent Biases in LLMs within Korean Social Context: A Comparative Analysis of ChatGPT and GPT-4",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungyoon Lee",
      "Dong Kim",
      "Dahyun Jung",
      "Chanjun Park",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.12": {
    "title": "To Clarify or not to Clarify: A Comparative Analysis of Clarification Classification with Fine-Tuning, Prompt Tuning, and Prompt Engineering",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alina Leippert",
      "Tatiana Anikina",
      "Bernd Kiefer",
      "Josef Genabith"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.13": {
    "title": "Detecting Response Generation Not Requiring Factual Judgment",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryohei Kamei",
      "Daiki Shiono",
      "Reina Akama",
      "Jun Suzuki"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.14": {
    "title": "Unknown Script: Impact of Script on Cross-Lingual Transfer",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wondimagegnhue Tufa",
      "Ilia Markov",
      "Piek Vossen"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.15": {
    "title": "Improving Repository-level Code Search with Text Conversion",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mizuki Kondo",
      "Daisuke Kawahara",
      "Toshiyuki Kurabayashi"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.16": {
    "title": "Improving Multi-lingual Alignment Through Soft Contrastive Learning",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minsu Park",
      "Seyeon Choi",
      "Chanyeol Choi",
      "Jun-Seong Kim",
      "Jy-yong Sohn"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.17": {
    "title": "Few-Shot Event Argument Extraction Based on a Meta-Learning Approach",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aboubacar Tuo",
      "Romaric Besançon",
      "Olivier Ferret",
      "Julien Tourille"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.18": {
    "title": "Investigating Web Corpus Filtering Methods for Language Model Development in Japanese",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rintaro Enomoto",
      "Arseny Tolmachev",
      "Takuro Niitsuma",
      "Shuhei Kurita",
      "Daisuke Kawahara"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.19": {
    "title": "Referring Expressions in Human-Robot Common Ground: A Thesis Proposal",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaap Kruijt"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.20": {
    "title": "Source Code is a Graph, Not a Sequence: A Cross-Lingual Perspective on Code Clone Detection",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Rahaman",
      "Julia Ive"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.21": {
    "title": "Distilling Text Style Transfer With Self-Explanation From LLMs",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chiyu Zhang",
      "Honglong Cai",
      "Yuezhang Li",
      "Yuexin Wu",
      "Le Hou",
      "Muhammad Abdul-Mageed"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.22": {
    "title": "Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wang",
      "Tetsuro Morimura",
      "Ukyo Honda",
      "Daisuke Kawahara"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.23": {
    "title": "Evaluation Dataset for Japanese Medical Text Simplification",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Koki Horiguchi",
      "Tomoyuki Kajiwara",
      "Yuki Arase",
      "Takashi Ninomiya"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.24": {
    "title": "Multi-Source Text Classification for Multilingual Sentence Encoder with Machine Translation",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reon Kajikawa",
      "Keiichiro Yamada",
      "Tomoyuki Kajiwara",
      "Takashi Ninomiya"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.25": {
    "title": "A Reproducibility Study on Quantifying Language Similarity: The Impact of Missing Values in the URIEL Knowledge Base",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hasti Toossi",
      "Guo Huai",
      "Jinyu Liu",
      "Eric Khiu",
      "A. Doğruöz",
      "En-Shiun Lee"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.26": {
    "title": "Coding Open-Ended Responses using Pseudo Response Generation by Large Language Models",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuki Zenimoto",
      "Ryo Hasegawa",
      "Takehito Utsuro",
      "Masaharu Yoshioka",
      "Noriko Kando"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.27": {
    "title": "Cross-Task Generalization Abilities of Large Language Models",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinyuan Ye"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.28": {
    "title": "Commentary Generation from Data Records of Multiplayer Strategy Esports Game",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Wang",
      "Naoki Yoshinaga"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.29": {
    "title": "Facilitating Opinion Diversity through Hybrid NLP Approaches",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michiel Van Der Meer"
    ]
  },
  "https://aclanthology.org/2024.naacl-srw.30": {
    "title": "HybridBERT - Making BERT Pretraining More Efficient Through Hybrid Mixture of Attention Mechanisms",
    "volume": "student",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gokul Srinivasagan",
      "Simon Ostermann"
    ]
  },
  "https://aclanthology.org/2024.naacl-tutorials.1": {
    "title": "Catch Me If You GPT: Tutorial on Deepfake Texts",
    "volume": "tutorial",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adaku Uchendu",
      "Saranya Venkatraman",
      "Thai Le",
      "Dongwon Lee"
    ]
  },
  "https://aclanthology.org/2024.naacl-tutorials.2": {
    "title": "Combating Security and Privacy Issues in the Era of Large Language Models",
    "volume": "tutorial",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhao Chen",
      "Chaowei Xiao",
      "Huan Sun",
      "Lei Li",
      "Leon Derczynski",
      "Anima Anandkumar",
      "Fei Wang"
    ]
  },
  "https://aclanthology.org/2024.naacl-tutorials.3": {
    "title": "Explanation in the Era of Large Language Models",
    "volume": "tutorial",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zining Zhu",
      "Hanjie Chen",
      "Xi Ye",
      "Qing Lyu",
      "Chenhao Tan",
      "Ana Marasovic",
      "Sarah Wiegreffe"
    ]
  },
  "https://aclanthology.org/2024.naacl-tutorials.4": {
    "title": "From Text to Context: Contextualizing Language with Humans, Groups, and Communities for Socially Aware NLP",
    "volume": "tutorial",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adithya V Ganesan",
      "Siddharth Mangalik",
      "Vasudha Varadarajan",
      "Nikita Soni",
      "Swanie Juhng",
      "João Sedoc",
      "H. Andrew Schwartz",
      "Salvatore Giorgi",
      "Ryan L Boyd"
    ]
  },
  "https://aclanthology.org/2024.naacl-tutorials.5": {
    "title": "Human-AI Interaction in the Age of LLMs",
    "volume": "tutorial",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diyi Yang",
      "Sherry Tongshuang Wu",
      "Marti A. Hearst"
    ]
  },
  "https://aclanthology.org/2024.naacl-tutorials.6": {
    "title": "Spatial and Temporal Language Understanding: Representation, Reasoning, and Grounding",
    "volume": "tutorial",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parisa Kordjamshidi",
      "Qiang Ning",
      "James Pustejovsky",
      "Marie-Francine Moens"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.1": {
    "title": "Structured Pruning for Large Language Models Using Coupled Components Elimination and Minor Fine-tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honghe Zhang",
      "XiaolongShi XiaolongShi",
      "Jingwei Sun",
      "Guangzhong Sun"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.2": {
    "title": "Weight-Inherited Distillation for Task-Agnostic BERT Compression",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taiqiang Wu",
      "Cheng Hou",
      "Shanshan Lao",
      "Jiayi Li",
      "Ngai Wong",
      "Zhe Zhao",
      "Yujiu Yang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.3": {
    "title": "Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for Pretraining on the Cybersecurity Domain",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eugene Jang",
      "Jian Cui",
      "Dayeon Yim",
      "Youngjin Jin",
      "Jin-Woo Chung",
      "Seungwon Shin",
      "Yongjae Lee"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.4": {
    "title": "Extremely efficient online query encoding for dense retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nachshon Cohen",
      "Yaron Fairstein",
      "Guy Kushilevitz"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.5": {
    "title": "DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain Question Answering over Knowledge Base and Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenting Zhao",
      "Ye Liu",
      "Tong Niu",
      "Yao Wan",
      "Philip Yu",
      "Shafiq Joty",
      "Yingbo Zhou",
      "Semih Yavuz"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.6": {
    "title": "SpeedE: Euclidean Geometric Knowledge Graph Embedding Strikes Back",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aleksandar Pavlović",
      "Emanuel Sallinger"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.7": {
    "title": "Language Guided Exploration for RL Agents in Text Environments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hitesh Golchha",
      "Sahil Yerawar",
      "Dhruvesh Patel",
      "Soham Dan",
      "Keerthiram Murugesan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.8": {
    "title": "GPT-who: An Information Density-based Machine-Generated Text Detector",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saranya Venkatraman",
      "Adaku Uchendu",
      "Dongwon Lee"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.9": {
    "title": "DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder Transformer Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Tang",
      "Pengkai Zhu",
      "Tian Li",
      "Srikar Appalaraju",
      "Vijay Mahadevan",
      "R. Manmatha"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.10": {
    "title": "Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ta-Chung Chi",
      "Ting-Han Fan",
      "Alexander Rudnicky"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.11": {
    "title": "Automatic Pair Construction for Contrastive Post-training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Canwen Xu",
      "Corby Rosset",
      "Ethan Chau",
      "Luciano Corro",
      "Shweti Mahajan",
      "Julian McAuley",
      "Jennifer Neville",
      "Ahmed Awadallah",
      "Nikhil Rao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.12": {
    "title": "Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miaoran Li",
      "Baolin Peng",
      "Michel Galley",
      "Jianfeng Gao",
      "Zhu Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.13": {
    "title": "Low-resource neural machine translation with morphological modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antoine Nzeyimana"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.14": {
    "title": "Self-Cleaning: Improving a Named Entity Recognizer Trained on Noisy Data with a Few Clean Instances",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhendong Chu",
      "Ruiyi Zhang",
      "Tong Yu",
      "Rajiv Jain",
      "Vlad Morariu",
      "Jiuxiang Gu",
      "Ani Nenkova"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.15": {
    "title": "VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for Vietnamese Natural Language Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phong Do",
      "Son Tran",
      "Phu Hoang",
      "Kiet Nguyen",
      "Ngan Nguyen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.16": {
    "title": "LETI: Learning to Generate from Textual Interactions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyao Wang",
      "Hao Peng",
      "Reyhaneh Jabbarvand",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.17": {
    "title": "Bilateral Masking with prompt for Knowledge Graph Completion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghui Kong",
      "Cunhang Fan",
      "Yujie Chen",
      "Shuai Zhang",
      "Zhao Lv",
      "Jianhua Tao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.18": {
    "title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenpeng Su",
      "Zijia Lin",
      "Baixue Baixue",
      "Hui Chen",
      "Songlin Hu",
      "Wei Zhou",
      "Guiguang Ding",
      "Xing W"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.19": {
    "title": "GOLD: Geometry Problem Solver with Natural Language Description",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Zhang",
      "Yashar Moshfeghi"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.20": {
    "title": "RoDia: A New Dataset for Romanian Dialect Identification from Speech",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rotaru Codruț",
      "Nicolae Ristea",
      "Radu Ionescu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.21": {
    "title": "Examining Modularity in Multilingual LMs via Language-Specialized Subnetworks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rochelle Choenni",
      "Ekaterina Shutova",
      "Dan Garrette"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.22": {
    "title": "Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinger Zhang",
      "Hui Cai",
      "Xierui Song",
      "Yicheng Chen",
      "Rui Sun",
      "Jing Zheng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.23": {
    "title": "Incorporating Exponential Smoothing into MLP: a Simple but Effective Sequence Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "JiqunChu JiqunChu",
      "Zuoquan Lin"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.24": {
    "title": "OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Kuang",
      "Hai Lin",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.25": {
    "title": "Comparing Two Model Designs for Clinical Note Generation; Is an LLM a Useful Evaluator of Consistency?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Brake",
      "Thomas Schaaf"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.26": {
    "title": "VOLTA: Improving Generative Diversity by Variational Mutual Information Maximizing Autoencoder",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yueen Ma",
      "DaFeng Chi",
      "Jingjing Li",
      "Kai Song",
      "Yuzheng Zhuang",
      "Irwin King"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.27": {
    "title": "EcoSpeak: Cost-Efficient Bias Mitigation for Partially Cross-Lingual Speaker Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divya Sharma"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.28": {
    "title": "Leveraging Contextual Information for Effective Entity Salience Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rajarshi Bhowmik",
      "Marco Ponza",
      "Atharva Tendle",
      "Anant Gupta",
      "Rebecca Jiang",
      "Xingyu Lu",
      "Qian Zhao",
      "Daniel Preotiuc-Pietro"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.29": {
    "title": "LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihui Zhang",
      "Chujie Gao",
      "Dongping Chen",
      "Yue Huang",
      "Yixin Huang",
      "Zhenyang Sun",
      "Shilin Zhang",
      "Weiye Li",
      "Zhengyan Fu",
      "Yao Wan",
      "Lichao Sun"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.30": {
    "title": "A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivo Verhoeven",
      "Pushkar Mishra",
      "Rahel Beloch",
      "Helen Yannakoudakis",
      "Ekaterina Shutova"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.31": {
    "title": "Citation: A Key to Building Responsible and Accountable Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Huang",
      "Kevin Chang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.32": {
    "title": "Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational AutoEncoders",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingji Zhang",
      "Marco Valentino",
      "Danilo Carvalho",
      "Ian Pratt-Hartmann",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.33": {
    "title": "Narrowing the Gap between Zero- and Few-shot Machine Translation by Matching Styles",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiting Tan",
      "Haoran Xu",
      "Lingfeng Shen",
      "Shuyue Stella Li",
      "Kenton Murray",
      "Philipp Koehn",
      "Benjamin Van Durme",
      "Yunmo Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.34": {
    "title": "Which Modality should I use - Text, Motif, or Image? : Understanding Graphs with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debarati Das",
      "Ishaan Gupta",
      "Jaideep Srivastava",
      "Dongyeop Kang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.35": {
    "title": "On-the-Fly Fusion of Large Language Models and Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hieu Hoang",
      "Huda Khayrallah",
      "Marcin Junczys-Dowmunt"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.36": {
    "title": "READ: Improving Relation Extraction from an ADversarial Perspective",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dawei Li",
      "William Hogan",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.37": {
    "title": "REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sana Ebrahimi",
      "Nima Shahbazi",
      "Abolfazl Asudeh"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.38": {
    "title": "Addressing Both Statistical and Causal Gender Fairness in NLP Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hannah Chen",
      "Yangfeng Ji",
      "David Evans"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.39": {
    "title": "LLM-Rec: Personalized Recommendation via Prompting Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanjia Lyu",
      "Song Jiang",
      "Hanqing Zeng",
      "Yinglong Xia",
      "Qifan Wang",
      "Si Zhang",
      "Ren Chen",
      "Chris Leung",
      "Jiajie Tang",
      "Jiebo Luo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.40": {
    "title": "A Robust Semantics-based Watermark for Large Language Model against Paraphrasing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ren",
      "Han Xu",
      "Yiding Liu",
      "Yingqian Cui",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Jiliang Tang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.41": {
    "title": "Solving Data-centric Tasks using Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shraddha Barke",
      "Christian Poelitz",
      "Carina Negreanu",
      "Benjamin Zorn",
      "José Cambronero",
      "Andrew Gordon",
      "Vu Le",
      "Elnaz Nouri",
      "Nadia Polikarpova",
      "Advait Sarkar",
      "Brian Slininger",
      "Neil Toronto",
      "Jack Williams"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.42": {
    "title": "A Novel Paradigm Boosting Translation Capabilities of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Guo",
      "Hao Yang",
      "Zongyao Li",
      "Daimeng Wei",
      "Hengchao Shang",
      "Xiaoyu Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.43": {
    "title": "Measuring Social Norms of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye Yuan",
      "Kexin Tang",
      "Jianhao Shen",
      "Ming Zhang",
      "Chenguang Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.44": {
    "title": "Source-Free Unsupervised Domain Adaptation for Question Answering via Prompt-Assisted Self-learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxwell Yin",
      "Boyu Wang",
      "Charles Ling"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.45": {
    "title": "Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenlong Zhao",
      "Xiwen Zhou",
      "Xiaopeng Xie",
      "Yong Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.46": {
    "title": "LEEETs-Dial: Linguistic Entrainment in End-to-End Task-oriented Dialogue systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nalin Kumar",
      "Ondrej Dusek"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.47": {
    "title": "Efficient Dependency Tree Sampling Without Replacement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bogdan Dobre"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.48": {
    "title": "Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Zhang",
      "Revanth Gangi Reddy",
      "Kevin Small",
      "Tong Zhang",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.49": {
    "title": "GEE! Grammar Error Explanation with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixiao Song",
      "Kalpesh Krishna",
      "Rajesh Bhatt",
      "Kevin Gimpel",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.50": {
    "title": "AdaRefiner: Refining Decisions of Language Models with Adaptive Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanpeng Zhang",
      "Zongqing Lu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.51": {
    "title": "DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented Dialogue Representations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihao Zeng",
      "Dayuan Fu",
      "Keqing He",
      "Yejie Wang",
      "Yukai Xu",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.52": {
    "title": "Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavel Denisov",
      "Thang Vu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.53": {
    "title": "CLEAN–EVAL: Clean Evaluation on Contaminated Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhong Zhu",
      "Hongkun Hao",
      "Zhiwei He",
      "Yun-Ze Song",
      "Jiao Yueyang",
      "Yumeng Zhang",
      "Hanxu Hu",
      "Yiran Wei",
      "Rui Wang",
      "Hongyuan Lu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.54": {
    "title": "R-BASS : Relevance-aided Block-wise Adaptation for Speech Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roshan Sharma",
      "Ruchira Sharma",
      "Hira Dhamyal",
      "Rita Singh",
      "Bhiksha Raj"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.55": {
    "title": "OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Yu",
      "Anningzhe Gao",
      "Benyou Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.56": {
    "title": "The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Wang",
      "Ee-Peng Lim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.57": {
    "title": "Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dhruv Agarwal",
      "Rajarshi Das",
      "Sopan Khosla",
      "Rashmi Gangadharaiah"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.58": {
    "title": "GraSAME: Injecting Token-Level Structural Information to Pretrained Language Models via Graph-guided Self-Attention Mechanism",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuzhou Yuan",
      "Michael Färber"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.59": {
    "title": "Can Public Large Language Models Help Private Cross-device Federated Learning?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boxin Wang",
      "Yibo Zhang",
      "Yuan Cao",
      "Bo Li",
      "Hugh McMahan",
      "Sewoong Oh",
      "Zheng Xu",
      "Manzil Zaheer"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.60": {
    "title": "LangNav: Language as a Perceptual Representation for Navigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Pan",
      "Rameswar Panda",
      "SouYoung Jin",
      "Rogerio Feris",
      "Aude Oliva",
      "Phillip Isola",
      "Yoon Kim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.61": {
    "title": "Planning and Editing What You Retrieve for Enhanced Tool Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tenghao Huang",
      "Dongwon Jung",
      "Vaibhav Kumar",
      "Mohammad Kachuee",
      "Xiang Li",
      "Puyang Xu",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.62": {
    "title": "Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Victor Carbune",
      "Hassan Mansoor",
      "Fangyu Liu",
      "Rahul Aralikatte",
      "Gilles Baechler",
      "Jindong Chen",
      "Abhanshu Sharma"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.63": {
    "title": "SLiM: Speculative Decoding with Hypothesis Reduction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi-Heng Lin",
      "Shikhar Tuli",
      "James Smith",
      "Yen-Chang Hsu",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.64": {
    "title": "REMATCH: Robust and Efficient Matching of Local Knowledge Graphs to Improve Structural and Semantic Similarity",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zoher Kachwala",
      "Jisun An",
      "Haewoon Kwak",
      "Filippo Menczer"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.65": {
    "title": "Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Hutchinson"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.66": {
    "title": "Testing the Effect of Code Documentation on Large Language Model Code Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Macke",
      "Michael Doyle"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.67": {
    "title": "Aligning Large Language Models with Recommendation Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwei Cao",
      "Nikhil Mehta",
      "Xinyang Yi",
      "Raghunandan Hulikal Keshavan",
      "Lukasz Heldt",
      "Lichan Hong",
      "Ed Chi",
      "Maheswaran Sathiamoorthy"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.68": {
    "title": "OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihong Liu",
      "Peiqin Lin",
      "Mingyang Wang",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.69": {
    "title": "SELF-EXPERTISE: Knowledge-based Instruction Dataset Augmentation for a Legal Expert Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minju Kim",
      "Haein Jung",
      "Myoung-Wan Koo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.70": {
    "title": "Re-evaluating the Need for Visual Signals in Unsupervised Grammar Induction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyi Li",
      "Rodolfo Corona",
      "Karttikeya Mangalam",
      "Catherine Chen",
      "Daniel Flaherty",
      "Serge Belongie",
      "Kilian Weinberger",
      "Jitendra Malik",
      "Trevor Darrell",
      "Dan Klein"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.71": {
    "title": "EDEntail: An Entailment-based Few-shot Text Classification with Extensional Definition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiao Zhu",
      "Junlang Qian",
      "Zijian Feng",
      "Hanzhang Zhou",
      "Kezhi Mao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.72": {
    "title": "What Makes Math Word Problems Challenging for LLMs?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kv Aditya Srivatsa",
      "Ekaterina Kochmar"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.73": {
    "title": "SMILE: Multimodal Dataset for Understanding Laughter in Video with Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lee Hyun",
      "Kim Sung-Bin",
      "Seungju Han",
      "Youngjae Yu",
      "Tae-Hyun Oh"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.74": {
    "title": "T3M: Text Guided 3D Human Motion Synthesis from Speech",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenshuo Peng",
      "Kaipeng Zhang",
      "Sai Qian Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.75": {
    "title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal Knowledge Graph Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Wenjie Xu",
      "Zihao Jiang",
      "Jiahui Zhu",
      "Min Peng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.76": {
    "title": "Explanation Extraction from Hierarchical Classification Frameworks for Long Legal Documents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nishchal Prasad",
      "Taoufiq Dkaki",
      "Mohand Boughanem"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.77": {
    "title": "Low-Rank Adaptation for Multilingual Summarization: An Empirical Study",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxi Whitehouse",
      "Fantine Huot",
      "Jasmijn Bastings",
      "Mostafa Dehghani",
      "Chu-Cheng Lin",
      "Mirella Lapata"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.78": {
    "title": "A Tree-of-Thoughts to Broaden Multi-step Reasoning across Languages",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leonardo Ranaldi",
      "Giulia Pucci",
      "Federico Ranaldi",
      "Elena Sofia Ruzzetti",
      "Fabio Massimo Zanzotto"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.79": {
    "title": "Emergent Abilities in Reduced-Scale Generative Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sherin Muckatira",
      "Vijeta Deshpande",
      "Vladislav Lialin",
      "Anna Rumshisky"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.80": {
    "title": "Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clemencia Siro",
      "Mohammad Aliannejadi",
      "Maarten Rijke"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.81": {
    "title": "Matching Varying-Length Texts via Topic-Informed and Decoupled Sentence Embeddings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xixi Zhou",
      "Chunbin Gu",
      "Xin Jie",
      "Jiajun Bu",
      "Haishuai Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.82": {
    "title": "Instruction Tuning with Human Curriculum",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bruce W Lee",
      "Hyunsoo Cho",
      "Kang Min Yoo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.83": {
    "title": "Natural Language-based State Representation in Deep Reinforcement Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Masudur Rahman",
      "Yexiang Xue"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.84": {
    "title": "Learning Cross-Architecture Instruction Embeddings for Binary Code Analysis in Low-Resource Architectures",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junzhe Wang",
      "Qiang Zeng",
      "Lannan Luo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.85": {
    "title": "ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large Language Models via Transferable Adversarial Attacks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaodong Yu",
      "Hao Cheng",
      "Xiaodong Liu",
      "Dan Roth",
      "Jianfeng Gao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.86": {
    "title": "An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tien-Hong Lo",
      "Fu-An Chao",
      "Tzu-i Wu",
      "Yao-Ting Sung",
      "Berlin Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.87": {
    "title": "GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shen Zheng",
      "Yuyu Zhang",
      "Yijie Zhu",
      "Chenguang Xi",
      "Pengyang Gao",
      "Zhou Xun",
      "Kevin Chang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.88": {
    "title": "Subword Attention and Post-Processing for Rare and Unknown Contextualized Embeddings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raj Patel",
      "Carlotta Domeniconi"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.89": {
    "title": "UGIF-DataSet: A New Dataset for Cross-lingual, Cross-modal Sequential actions on the UI",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sagar Gubbi Venkatesh",
      "Partha Talukdar",
      "Srini Narayanan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.90": {
    "title": "SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in Fine-tuned Source Code Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hossein Hajipour",
      "Ning Yu",
      "Cristian-Alexandru Staicu",
      "Mario Fritz"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.91": {
    "title": "Pruning as a Domain-specific LLM Extractor",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Zhang",
      "Yanchi Liu",
      "Xujiang Zhao",
      "Wei Cheng",
      "Runxue Bao",
      "Rui Zhang",
      "Prasenjit Mitra",
      "Haifeng Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.92": {
    "title": "LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenda Xu",
      "Daniel Deutsch",
      "Mara Finkelstein",
      "Juraj Juraska",
      "Biao Zhang",
      "Zhongtao Liu",
      "William Yang Wang",
      "Lei Li",
      "Markus Freitag"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.93": {
    "title": "Noisy Multi-Label Text Classification via Instance-Label Pair Correction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengyu Xu",
      "Mingyang Song",
      "Linkaida Liu",
      "Bing Liu",
      "Hongjian Sun",
      "Liping Jing",
      "Jian Yu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.94": {
    "title": "Composite Backdoor Attacks Against Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Huang",
      "Zhengyu Zhao",
      "Michael Backes",
      "Yun Shen",
      "Yang Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.95": {
    "title": "Adapting Fake News Detection to the Era of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyan Su",
      "Claire Cardie",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.96": {
    "title": "MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youbo Lei",
      "Feifei He",
      "Chen Chen",
      "Yingbin Mo",
      "Sijia Li",
      "Defeng Xie",
      "Haonan Lu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.97": {
    "title": "Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Qin",
      "Rolf Jagerman",
      "Kai Hui",
      "Honglei Zhuang",
      "Junru Wu",
      "Le Yan",
      "Jiaming Shen",
      "Tianqi Liu",
      "Jialu Liu",
      "Donald Metzler",
      "Xuanhui Wang",
      "Michael Bendersky"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.98": {
    "title": "FedLFC: Towards Efficient Federated Multilingual Modeling with LoRA-based Language Family Clustering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihan Guo",
      "Yifei Zhang",
      "Zhuo Zhang",
      "Zenglin Xu",
      "Irwin King"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.99": {
    "title": "Gaussian Process Optimization for Adaptable Multi-Objective Text Generation using Linearly-Weighted Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Mahdi Abdollah Pour",
      "Ali Pesaranghader",
      "Eldan Cohen",
      "Scott Sanner"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.100": {
    "title": "Groundedness in Retrieval-augmented Long-form Generation: An Empirical Study",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Stolfo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.101": {
    "title": "TagDebias: Entity and Concept Tagging for Social Bias Mitigation in Pretrained Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehrnaz Moslemi",
      "Amal Zouaq"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.102": {
    "title": "Improving Absent Keyphrase Generation with Diversity Heads",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Edwin Thomas",
      "Sowmya Vajjala"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.103": {
    "title": "mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianze Hua",
      "Tian Yun",
      "Ellie Pavlick"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.104": {
    "title": "Discovering and Mitigating Indirect Bias in Attention-Based Model Explanations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Farsheed Haque",
      "Depeng Xu",
      "Shuhan Yuan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.105": {
    "title": "i-Code V2: An Autoregressive Generation Framework over Vision, Language, and Speech Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Yang",
      "Mahmoud Khademi",
      "Yichong Xu",
      "Reid Pryzant",
      "Yuwei Fang",
      "Chenguang Zhu",
      "Dongdong Chen",
      "Yao Qian",
      "Xuemei Gao",
      "Yi-Ling Chen",
      "Robert Gmyr",
      "Naoyuki Kanda",
      "Noel Codella",
      "Bin Xiao",
      "Yu Shi",
      "Lu Yuan",
      "Takuya Yoshioka",
      "Michael Zeng",
      "Xuedong Huang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.106": {
    "title": "Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Qiu",
      "Varun Embar",
      "Shay Cohen",
      "Benjamin Han"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.107": {
    "title": "It's All Relative! – A Synthetic Query Generation Approach for Improving Zero-Shot Relevance Prediction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aditi Chaudhary",
      "Karthik Raman",
      "Michael Bendersky"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.108": {
    "title": "RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saeed Khaki",
      "JinJin Li",
      "Lan Ma",
      "Liu Yang",
      "Prathap Ramachandra"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.109": {
    "title": "Hypernetwork-Assisted Parameter-Efficient Fine-Tuning with Meta-Knowledge Distillation for Domain Knowledge Disentanglement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changqun Li",
      "Linlin Wang",
      "Xin Lin",
      "Shizhou Huang",
      "Liang He"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.110": {
    "title": "MICo: Preventative Detoxification of Large Language Models through Inhibition Control",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Siegelmann",
      "Ninareh Mehrabi",
      "Palash Goyal",
      "Prasoon Goyal",
      "Lisa Bauer",
      "Jwala Dhamala",
      "Aram Galstyan",
      "Rahul Gupta",
      "Reza Ghanadan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.111": {
    "title": "Reinforcement Learning with Token-level Feedback for Controllable Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wendi Li",
      "Wei Wei",
      "Kaihe Xu",
      "Wenfeng Xie",
      "Dangyang Chen",
      "Yu Cheng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.112": {
    "title": "CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pei Chen",
      "Shuai Zhang",
      "Boran Han"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.113": {
    "title": "Tokenization Matters: Navigating Data-Scarce Tokenization for Gender Inclusive Language Technologies",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anaelia Ovalle",
      "Ninareh Mehrabi",
      "Palash Goyal",
      "Jwala Dhamala",
      "Kai-Wei Chang",
      "Richard Zemel",
      "Aram Galstyan",
      "Yuval Pinter",
      "Rahul Gupta"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.114": {
    "title": "AdaPT: A Set of Guidelines for Hyperbolic Multimodal Multilingual NLP",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramit Sawhney",
      "Shrey Pandit",
      "Vishwa Shah",
      "Megh Thakkar",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.115": {
    "title": "More Samples or More Prompts? Exploring Effective Few-Shot In-Context Learning for LLMs with In-Context Sampling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingsheng Yao",
      "Guiming Chen",
      "Ruishi Zou",
      "Yuxuan Lu",
      "Jiachen Li",
      "Shao Zhang",
      "Yisi Sang",
      "Sijia Liu",
      "James Hendler",
      "Dakuo Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.116": {
    "title": "ZSEE: A Dataset based on Zeolite Synthesis Event Extraction for Automated Synthesis Platform",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Song He",
      "Xin Peng",
      "Yihan Cai",
      "Xin Li",
      "Zhiqing Yuan",
      "WenLi Du",
      "Weimin Yang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.117": {
    "title": "Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyubyung Chae",
      "Jaepill Choi",
      "Yohan Jo",
      "Taesup Kim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.118": {
    "title": "Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "San Kim",
      "Gary Lee"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.119": {
    "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fobo Shi",
      "Peijun Qing",
      "Dong Yang",
      "Nan Wang",
      "Youbo Lei",
      "Haonan Lu",
      "Xiaodong Lin",
      "Duantengchuan Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.120": {
    "title": "DAGCN: Distance-based and Aspect-oriented Graph Convolutional Network for Aspect-based Sentiment Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Wang",
      "Bo Zhang",
      "Ru Yang",
      "Chang Guo",
      "Maozhen Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.121": {
    "title": "Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoyi Peng",
      "Yi Yang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.122": {
    "title": "Self-Regulated Sample Diversity in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyue Liu",
      "Jonathan Frawley",
      "Sarah Wyer",
      "Hubert P. H. Shum",
      "Sara Uckelman",
      "Sue Black",
      "Chris Willcocks"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.123": {
    "title": "Methods, Applications, and Directions of Learning-to-Rank in NLP Research",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin Lee",
      "Gabriel Bernier-Colborne",
      "Tegan Maharaj",
      "Sowmya Vajjala"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.124": {
    "title": "When Quantization Affects Confidence of Large Language Models?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Irina Proskurina",
      "Luc Brun",
      "Guillaume Metzler",
      "Julien Velcin"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.125": {
    "title": "MedCycle: Unpaired Medical Report Generation via Cycle-Consistency",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elad Hirsch",
      "Gefen Dawidowicz",
      "Ayellet Tal"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.126": {
    "title": "Beta-LR: Interpretable Logical Reasoning based on Beta Distribution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhuo Ma",
      "Ke Qin",
      "Shuang Liang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.127": {
    "title": "Applications of BERT Models Towards Automation of Clinical Coding in Icelandic",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haraldur Hauksson",
      "Hafsteinn Einarsson"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.128": {
    "title": "Tell me who you are and I tell you how you argue\": Predicting Stances and Arguments for Stakeholder Groups",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp Heinisch",
      "Lorik Dumani",
      "Philipp Cimiano",
      "Ralf Schenkel"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.129": {
    "title": "Psychometric Predictive Power of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Timothy Baldwin"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.130": {
    "title": "Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pouya Pezeshkpour",
      "Estevam Hruschka"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.131": {
    "title": "PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thang Pham",
      "Peijie Chen",
      "Tin Nguyen",
      "Seunghyun Yoon",
      "Trung Bui",
      "Anh Nguyen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.132": {
    "title": "Ethos: Rectifying Language Models in Orthogonal Parameter Space",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Gao",
      "Yue Niu",
      "Tingting Tang",
      "Salman Avestimehr",
      "Murali Annavaram"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.133": {
    "title": "Crafting In-context Examples according to LMs' Parametric Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yoonsang Lee",
      "Pranav Atreya",
      "Xi Ye",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.134": {
    "title": "ICXML: An In-Context Learning Framework for Zero-Shot Extreme Multi-Label Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxin Zhu",
      "Hamed Zamani"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.135": {
    "title": "CLGSI: A Multimodal Sentiment Analysis Framework based on Contrastive Learning Guided by Sentiment Intensity",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Yang",
      "Xunde Dong",
      "Yupeng Qiang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.136": {
    "title": "Interpreting Answers to Yes-No Questions in Dialogues from Multiple Domains",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijie Wang",
      "Farzana Rashid",
      "Eduardo Blanco"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.137": {
    "title": "Enhancing Perception: Refining Explanations of News Claims with LLM Conversations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Li Hsu",
      "Jui-Ning Chen",
      "Yang Fan Chiang",
      "Shang-Chien Liu",
      "Aiping Xiong",
      "Lun-Wei Ku"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.138": {
    "title": "How Interpretable are Reasoning Explanations from Prompting Large Language Models?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeo Wei Jie",
      "Ranjan Satapathy",
      "Rick Goh",
      "Erik Cambria"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.139": {
    "title": "Plug-in Language Model: Controlling Text Generation with a Simple Regression Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nai-Chi Yang",
      "Wei-Yun Ma",
      "Pu-Jen Cheng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.140": {
    "title": "Signer Diversity-driven Data Augmentation for Signer-Independent Sign Language Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honghaofu Honghaofu",
      "Liang Zhang",
      "Biao Fu",
      "Rui Zhao",
      "Jinsong Su",
      "Xiaodong Shi",
      "Yidong Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.141": {
    "title": "A Systematic Analysis of Subwords and Cross-Lingual Transfer in Multilingual Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francois Meyer",
      "Jan Buys"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.142": {
    "title": "Multi-Granularity Guided Fusion-in-Decoder",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunseong Choi",
      "Hyeri Lee",
      "Jongwuk Lee"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.143": {
    "title": "Group Fairness in Multilingual Speech Recognition Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Zee",
      "Marc Zee",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.144": {
    "title": "Rethinking Machine Ethics – Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyan Zhou",
      "Minda Hu",
      "Junan Li",
      "Xiaoying Zhang",
      "Xixin Wu",
      "Irwin King",
      "Helen Meng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.145": {
    "title": "Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Wang",
      "Fei Mi",
      "Yi Chen",
      "Boyang Xue",
      "Hongru Wang",
      "Qi Zhu",
      "Kam-Fai Wong",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.146": {
    "title": "BERTweet's TACO Fiesta: Contrasting Flavors On The Path Of Inference And Information-Driven Argument Mining On Twitter",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marc Feger",
      "Stefan Dietze"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.147": {
    "title": "Testing the limits of logical reasoning in neural and hybrid models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manuel Guzman",
      "Jakub Szymanik",
      "Maciej Malicki"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.148": {
    "title": "METAL: Towards Multilingual Meta-Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishav Hada",
      "Varun Gumma",
      "Mohamed Ahmed",
      "Kalika Bali",
      "Sunayana Sitaram"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.149": {
    "title": "AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanjun Zhong",
      "Ruixiang Cui",
      "Yiduo Guo",
      "Yaobo Liang",
      "Shuai Lu",
      "Yanlin Wang",
      "Amin Saied",
      "Weizhu Chen",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.150": {
    "title": "Product Description and QA Assisted Self-Supervised Opinion Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tejpalsingh Siledar",
      "Rupasai Rangaraju",
      "Sankara Muddu",
      "Suman Banerjee",
      "Amey Patil",
      "Sudhanshu Singh",
      "Muthusamy Chelliah",
      "Nikesh Garera",
      "Swaprava Nath",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.151": {
    "title": "COMEM: In-Context Retrieval-Augmented Mass-Editing Memory in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanbao Qiao",
      "Xuebing Liu",
      "Seung-Hoon Na"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.152": {
    "title": "Content-Specific Humorous Image Captioning Using Incongruity Resolution Chain-of-Thought",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kohtaro Tanaka",
      "Kohei Uehara",
      "Lin Gu",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.153": {
    "title": "Denoising Attention for Query-aware User Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elias Bassani",
      "Pranav Kasela",
      "Gabriella Pasi"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.154": {
    "title": "A Lightweight Mixture-of-Experts Neural Machine Translation Model with Stage-wise Training Strategy",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Zhang",
      "Mei Tu",
      "Song Liu",
      "Jinyao Yan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.155": {
    "title": "BEAR: A Unified Framework for Evaluating Relational Knowledge in Causal and Masked Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacek Wiland",
      "Max Ploner",
      "Alan Akbik"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.156": {
    "title": "Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Floris Hengst",
      "Ralf Wolter",
      "Patrick Altmeyer",
      "Arda Kaygan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.157": {
    "title": "Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models in Court Decisions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Nyffenegger",
      "Matthias Stürmer",
      "Joel Niklaus"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.158": {
    "title": "X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "DongJae Shin",
      "HyeonSeok Lim",
      "Inho Won",
      "ChangSu Choi",
      "Minjun Kim",
      "SeungWoo Song",
      "HanGyeol Yoo",
      "SangMin Kim",
      "KyungTae Lim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.159": {
    "title": "Why So Gullible? Enhancing the Robustness of Retrieval-Augmented Models against Counterfactual Noise",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giwon Hong",
      "Jeonghwan Kim",
      "Junmo Kang",
      "Sung-Hyon Myaeng",
      "Joyce Whang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.160": {
    "title": "Heterogeneity over Homogeneity: Investigating Multilingual Speech Pre-Trained Models for Detecting Audio Deepfake",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Orchid Chetia Phukan",
      "Gautam Kashyap",
      "Arun Balaji Buduru",
      "Rajesh Sharma"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.161": {
    "title": "Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenghao Yang",
      "Tuhin Chakrabarty",
      "Karli Hochstatter",
      "Melissa Slavin",
      "Nabila El-Bassel",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.162": {
    "title": "Self-Adaptive Sampling for Accurate Video Question Answering on Image Text Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Han",
      "Hui Chen",
      "Min-Yen Kan",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.163": {
    "title": "Towards an On-device Agent for Text Rewriting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Zhu",
      "Yinxiao Liu",
      "Felix Stahlberg",
      "Shankar Kumar",
      "Yu-Hui Chen",
      "Liangchen Luo",
      "Lei Shu",
      "Renjie Liu",
      "Jindong Chen",
      "Lei Meng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.164": {
    "title": "Tailoring Vaccine Messaging with Common-Ground Opinions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rickard Stureborg",
      "Sanxing Chen",
      "Roy Xie",
      "Aayushi Patel",
      "Christopher Li",
      "Chloe Zhu",
      "Tingnan Hu",
      "Jun Yang",
      "Bhuwan Dhingra"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.165": {
    "title": "Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robert Vacareanu",
      "Fahmida Alam",
      "Md Asiful Islam",
      "Haris Riaz",
      "Mihai Surdeanu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.166": {
    "title": "Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhui Guo",
      "Shaoyuan Xu",
      "Jinmiao Fu",
      "Jia Liu",
      "Chaosheng Dong",
      "Bryan Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.167": {
    "title": "In-Context Example Ordering Guided by Label Distributions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhichao Xu",
      "Daniel Cohen",
      "Bei Wang",
      "Vivek Srikumar"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.168": {
    "title": "Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial Narratives",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Liu",
      "Yi Yang",
      "Kar Yan Tam"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.169": {
    "title": "Laying Anchors: Semantically Priming Numerals in Language Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mandar Sharma",
      "Rutuja Taware",
      "Pravesh Koirala",
      "Nikhil Muralidhar",
      "Naren Ramakrishnan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.170": {
    "title": "UEGP: Unified Expert-Guided Pre-training for Knowledge Rekindle",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Mou",
      "Kexiang Wang",
      "Jianhe Lin",
      "Dehong Ma",
      "Jun Fan",
      "Daiting Shi",
      "Zhicong Cheng",
      "Gu Simiu",
      "Dawei Yin",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.171": {
    "title": "LatticeGen: Hiding Generated Text in a Lattice for Privacy-Aware Large Language Model Generation on Cloud",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengke Zhang",
      "Tianxing He",
      "Tianle Wang",
      "Lu Mi",
      "Niloofar Mireshghallah",
      "Binyi Chen",
      "Hao Wang",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.172": {
    "title": "HateModerate: Testing Hate Speech Detectors against Content Moderation Policies",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangrui Zheng",
      "Xueqing Liu",
      "Mirazul Haque",
      "Xing Qian",
      "Guanqun Yang",
      "Wei Yang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.173": {
    "title": "Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Gao",
      "Jie Ou",
      "Lei Wang",
      "Yuting Xiao",
      "Xiangzhiyuan Xiangzhiyuan",
      "Ruiting Dai",
      "Jun Cheng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.174": {
    "title": "Contrastive Preference Learning for Neural Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianfei He",
      "Shichao Sun",
      "Sen Peng",
      "Jie Xu",
      "Xiaohua Jia",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.175": {
    "title": "SocREval: Large Language Models with the Socratic Method for Reference-free Reasoning Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hangfeng He",
      "Hongming Zhang",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.176": {
    "title": "Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Zhu",
      "Hongyi Liu",
      "Qingxiu Dong",
      "Jingjing Xu",
      "Shujian Huang",
      "Lingpeng Kong",
      "Jiajun Chen",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.177": {
    "title": "Unleashing the Power of LLMs in Court View Generation by Stimulating Internal Knowledge and Incorporating External Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Liu",
      "Yiquan Wu",
      "Ang Li",
      "Yating Zhang",
      "Changlong Sun",
      "Weiming Lu",
      "Fei Wu",
      "Kun Kuang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.178": {
    "title": "Prompting Vision-Language Models For Aspect-Controlled Generation of Referring Expressions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danfeng Guo",
      "Sanchit Agarwal",
      "Arpit Gupta",
      "Jiun-Yu Kao",
      "Emre Barut",
      "Tagyoung Chung",
      "Jing Huang",
      "Mohit Bansal"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.179": {
    "title": "Task-Agnostic Detector for Insertion-Based Backdoor Attacks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weimin Lyu",
      "Xiao Lin",
      "Songzhu Zheng",
      "Lu Pang",
      "Haibin Ling",
      "Susmit Jha",
      "Chao Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.180": {
    "title": "Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianfeng He",
      "Linlin Yu",
      "Shuo Lei",
      "Chang-Tien Lu",
      "Feng Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.181": {
    "title": "Exploring Language Model's Code Generation Ability with Auxiliary Functions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seonghyeon Lee",
      "Sanghwan Jang",
      "Seongbo Jang",
      "Dongha Lee",
      "Hwanjo Yu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.182": {
    "title": "Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sang Truong",
      "Duc Nguyen",
      "Toan Nguyen",
      "Dong Le",
      "Nhi Truong",
      "Tho Quan",
      "Sanmi Koyejo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.183": {
    "title": "GoT: Effective Graph-of-Thought Reasoning in Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Yao",
      "Zuchao Li",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.184": {
    "title": "Enhancing the General Agent Capabilities of Low-Paramter LLMs through Tuning and Multi-Branch Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinhao Zhou",
      "Zihan Zhang",
      "Xiang Xiang",
      "Ke Wang",
      "Yuchuan Wu",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.185": {
    "title": "MuMath: Multi-perspective Data Augmentation for Mathematical Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihao You",
      "Shuo Yin",
      "Xudong Zhao",
      "Zhilong Ji",
      "Guoqiang Zhong",
      "Jinfeng Bai"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.186": {
    "title": "Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Ye",
      "Lingfei Wu",
      "Tengfei Ma",
      "Xuhong Zhang",
      "Yangkai Du",
      "Peiyu Liu",
      "Shouling Ji",
      "Wenhai Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.187": {
    "title": "UNO-DST: Leveraging Unlabelled Data in Zero-Shot Dialogue State Tracking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuang Li",
      "Yan Zhang",
      "Min-Yen Kan",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.188": {
    "title": "Evaluating Step-by-Step Reasoning through Symbolic Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YiFan Zhang",
      "Hanlin Zhang",
      "Li Li",
      "Eric Xing"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.189": {
    "title": "Multi-Review Fusion-in-Context",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aviv Slobodkin",
      "Ori Shapira",
      "Ran Levy",
      "Ido Dagan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.190": {
    "title": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxime Bouthors",
      "Josep Crego",
      "François Yvon"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.191": {
    "title": "Extending Input Contexts of Language Models through Training on Segmented Sequences",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Petros Karypis",
      "Julian McAuley",
      "George Karypis"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.192": {
    "title": "Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanda Li",
      "Dixuan Wang",
      "Jiaqing Liang",
      "Guochao Jiang",
      "Qianyu He",
      "Yanghua Xiao",
      "Deqing Yang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.193": {
    "title": "Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanyong Feng",
      "Jaewook Lee",
      "Hunter McNichols",
      "Alexander Scarlatos",
      "Digory Smith",
      "Simon Woodhead",
      "Nancy Ornelas",
      "Andrew Lan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.194": {
    "title": "Aspect-based Sentiment Analysis with Context Denoising",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanhe Tian",
      "Chang Liu",
      "Yan Song",
      "Fei Xia",
      "Yongdong Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.195": {
    "title": "IruMozhi: Automatically classifying diglossia in Tamil",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kabilan Prasanna",
      "Aryaman Arora"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.196": {
    "title": "RENOVI: A Benchmark Towards Remediating Norm Violations in Socio-Cultural Conversations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haolan Zhan",
      "Zhuang Li",
      "Xiaoxi Kang",
      "Tao Feng",
      "Yuncheng Hua",
      "Lizhen Qu",
      "Yi Ying",
      "Mei Rianto Chandra",
      "Kelly Rosalin",
      "Jureynolds Jureynolds",
      "Suraj Sharma",
      "Shilin Qu",
      "Linhao Luo",
      "Ingrid Zukerman",
      "Lay-Ki Soon",
      "Zhaleh Semnani Azad",
      "Reza Haf"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.197": {
    "title": "Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Jin Kang",
      "Fabrice Harel-Canada",
      "Muhammad Ali Gulzar",
      "Nanyun Peng",
      "Miryung Kim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.198": {
    "title": "COMMIT: Code-Mixing English-Centric Large Language Model for Multilingual Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeseong Lee",
      "YeonJoon Jung",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.199": {
    "title": "DiLM: Distilling Dataset into Language Model for Text-level Dataset Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aru Maekawa",
      "Satoshi Kosugi",
      "Kotaro Funakoshi",
      "Manabu Okumura"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.200": {
    "title": "MindAgent: Emergent Gaming Interaction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ran Gong",
      "Qiuyuan Huang",
      "Xiaojian Ma",
      "Yusuke Noda",
      "Zane Durante",
      "Zilong Zheng",
      "Demetri Terzopoulos",
      "Li Fei-Fei",
      "Jianfeng Gao",
      "Hoi Vo"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.201": {
    "title": "BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haodong Duan",
      "Jueqi Wei",
      "Chonghua Wang",
      "Hongwei Liu",
      "Yixiao Fang",
      "Songyang Zhang",
      "Dahua Lin",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.202": {
    "title": "Learning Mutually Informed Representations for Characters and Subwords",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilin Wang",
      "Xinyi Hu",
      "Matthew Gormley"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.203": {
    "title": "A Novel Two-step Fine-tuning Framework for Transfer Learning in Low-Resource Neural Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Gao",
      "Feng Hou",
      "Ruili Wang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.204": {
    "title": "Enhancing Cross-lingual Sentence Embedding for Low-resource Languages with Word Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongtao Miao",
      "Qiyu Wu",
      "Kaiyan Zhao",
      "Zilong Wu",
      "Yoshimasa Tsuruoka"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.205": {
    "title": "C3LPGCN:Integrating Contrastive Learning and Cooperative Learning with Prompt into Graph Convolutional Network for Aspect-based Sentiment Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye He",
      "Shihao Zou",
      "YuzheChen YuzheChen",
      "Xianying Huang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.206": {
    "title": "Visual Enhanced Entity-Level Interaction Network for Multimodal Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haolong Yan",
      "Binghao Tang",
      "Boda Lin",
      "Gang Zhao",
      "Si Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.207": {
    "title": "Knowledgeable In-Context Tuning: Exploring and Exploiting Factual Knowledge for In-Context Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Chuanqi Tan",
      "Jun Huang",
      "Ming Gao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.208": {
    "title": "Time Machine GPT",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Drinkall",
      "Eghbal Rahimikia",
      "Janet Pierrehumbert",
      "Stefan Zohren"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.209": {
    "title": "An End-to-End Submodular Framework for Data-Efficient In-Context Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lilly Kumari",
      "Shengjie Wang",
      "Arnav Das",
      "Tianyi Zhou",
      "Jeff Bilmes"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.210": {
    "title": "Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hele-Andra Kuulmets",
      "Taido Purason",
      "Agnes Luhtaru",
      "Mark Fishel"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.211": {
    "title": "Simulating Opinion Dynamics with Networks of LLM-based Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun-Shiuan Chuang",
      "Agam Goyal",
      "Nikunj Harlalka",
      "Siddharth Suresh",
      "Robert Hawkins",
      "Sijia Yang",
      "Dhavan Shah",
      "Junjie Hu",
      "Timothy Rogers"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.212": {
    "title": "Probing the Category of Verbal Aspect in Transformer Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anisia Katinskaia",
      "Roman Yangarber"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.213": {
    "title": "A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanja Samardzic",
      "Ximena Gutierrez",
      "Christian Bentz",
      "Steven Moran",
      "Olga Pelloni"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.214": {
    "title": "Beyond Read-Only: Crafting a Comprehensive Chinese Text-to-SQL Dataset for Database Manipulation and Query",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Chen",
      "Jinguo You",
      "Likun Likun",
      "Xiang Li"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.215": {
    "title": "Normalizing without Modernizing: Keeping Historical Wordforms of Middle French while Reducing Spelling Variants",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphael Rubino",
      "Johanna Gerlach",
      "Jonathan Mutal",
      "Pierrette Bouillon"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.216": {
    "title": "Anti-LM Decoding for Zero-shot In-context Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suzanna Sia",
      "Alexandra DeLucia",
      "Kevin Duh"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.217": {
    "title": "Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Zhao",
      "Leilei Gan",
      "Anh Tuan Luu",
      "Jie Fu",
      "Lingjuan Lyu",
      "Meihuizi Jia",
      "Jinming Wen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.218": {
    "title": "Select and Summarize: Scene Saliency for Movie Script Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohit Saxena",
      "Frank Keller"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.219": {
    "title": "Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seunguk Yu",
      "Juhwan Choi",
      "YoungBin Kim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.220": {
    "title": "Z-GMOT: Zero-shot Generic Multiple Object Tracking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kim Tran",
      "Anh Duy Le Dinh",
      "Tien-Phat Nguyen",
      "Thinh Phan",
      "Pha Nguyen",
      "Khoa Luu",
      "Donald Adjeroh",
      "Gianfranco Doretto",
      "Ngan Le"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.221": {
    "title": "NLP for Counterspeech against Hate: A Survey and How-To Guide",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Helena Bonaldi",
      "Yi-Ling Chung",
      "Gavin Abercrombie",
      "Marco Guerini"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.222": {
    "title": "PRODIGy: a PROfile-based DIalogue Generation dataset",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniela Occhipinti",
      "Serra Tekiroglu",
      "Marco Guerini"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.223": {
    "title": "WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piotr Molenda",
      "Adian Liusie",
      "Mark Gales"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.224": {
    "title": "Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Xu",
      "Fei Wang",
      "Ben Zhou",
      "Bangzheng Li",
      "Chaowei Xiao",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.225": {
    "title": "PAELLA: Parameter-Efficient Lightweight Language-Agnostic Captioning Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rita Ramos",
      "Emanuele Bugliarello",
      "Bruno Martins",
      "Desmond Elliott"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.226": {
    "title": "OSCaR: Object State Captioning and State Change Representation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nguyen Nguyen",
      "Jing Bi",
      "Ali Vosoughi",
      "Yapeng Tian",
      "Pooyan Fazli",
      "Chenliang Xu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.227": {
    "title": "SumCSE: Summary as a transformation for Contrastive Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raghuveer Thirukovalluru",
      "Xiaolan Wang",
      "Jun Chen",
      "Shuyang Li",
      "Jie Lei",
      "Rong Jin",
      "Bhuwan Dhingra"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.228": {
    "title": "The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanzhu Guo",
      "Guokan Shang",
      "Michalis Vazirgiannis",
      "Chloé Clavel"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.229": {
    "title": "PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Jiang",
      "Xiajie Zhang",
      "Xubo Cao",
      "Cynthia Breazeal",
      "Deb Roy",
      "Jad Kabbara"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.230": {
    "title": "FIRE: A Dataset for Financial Relation Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hassan Hamad",
      "Abhinav Kumar Thakur",
      "Nijil Kolleri",
      "Sujith Pulikodan",
      "Keith Chugg"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.231": {
    "title": "MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Deng",
      "Yinghao Ma",
      "Yudong Liu",
      "Rongchen Guo",
      "Ge Zhang",
      "Wenhu Chen",
      "Wenhao Huang",
      "Emmanouil Benetos"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.232": {
    "title": "Investigating Acceleration of LLaMA Inference by Enabling Intermediate Layer Decoding via Instruction Tuning with ‘LITE",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neeraj Varshney",
      "Agneet Chatterjee",
      "Mihir Parmar",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.233": {
    "title": "Instruction-following Evaluation through Verbalizer Manipulation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyang Li",
      "Jun Yan",
      "Hai Wang",
      "Zheng Tang",
      "Xiang Ren",
      "Vijay Srinivasan",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.234": {
    "title": "WebWISE: Unlocking Web Interface Control for LLMs via Sequential Exploration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heyi Tao",
      "Sethuraman T V",
      "Michal Shlapentokh-Rothman",
      "Tanmay Gupta",
      "Heng Ji",
      "Derek Hoiem"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.235": {
    "title": "CodecLM: Aligning Language Models with Tailored Synthetic Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zifeng Wang",
      "Chun-Liang Li",
      "Vincent Perot",
      "Long Le",
      "Jin Miao",
      "Zizhao Zhang",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.236": {
    "title": "Prompting Few-shot Multi-hop Question Generation via Comprehending Type-aware Semantics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zefeng Lin",
      "Weidong Chen",
      "Yan Song",
      "Yongdong Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.237": {
    "title": "When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhong Li",
      "Chenghao Yang",
      "Allyson Ettinger"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.238": {
    "title": "CoDa: Constrained Generation based Data Augmentation for Low-Resource NLP",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chandra Kiran Evuru",
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Ramaneswaran S",
      "Utkarsh Tyagi",
      "Dinesh Manocha"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.239": {
    "title": "Synonym relations affect object detection learned on vision-language data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giacomo Nebbia",
      "Adriana Kovashka"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.240": {
    "title": "CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Li",
      "FanBu FanBu",
      "Ambuj Mehrish",
      "Yingting Li",
      "Jiale Han",
      "Bo Cheng",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.241": {
    "title": "RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Javad Rafiei Asl",
      "Prajwal Panzade",
      "Eduardo Blanco",
      "Daniel Takabi",
      "Zhipeng Cai"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.242": {
    "title": "Characterizing Human and Zero-Shot GPT-3.5 Object-Similarity Judgments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "D McKnight",
      "Alona Fyshe"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.243": {
    "title": "Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei He",
      "Shichun Liu",
      "Jun Zhao",
      "Yiwen Ding",
      "Yi Lu",
      "Zhiheng Xi",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.244": {
    "title": "Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge Conflicts in Event Temporal Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqing Fang",
      "Zhaowei Wang",
      "Wenxuan Zhou",
      "Hongming Zhang",
      "Yangqiu Song",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.245": {
    "title": "MCECR: A Novel Dataset for Multilingual Cross-Document Event Coreference Resolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Pouran Ben Veyseh",
      "Viet Lai",
      "Chien Nguyen",
      "Franck Dernoncourt",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.246": {
    "title": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Zhang",
      "Yue Deng",
      "Bing Liu",
      "Sinno Pan",
      "Lidong Bing"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.247": {
    "title": "Tokenizer Choice For LLM Training: Negligible or Crucial?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehdi Ali",
      "Michael Fromm",
      "Klaudia Thellmann",
      "Richard Rutmann",
      "Max Lübbering",
      "Johannes Leveling",
      "Katrin Klug",
      "Jan Ebert",
      "Niclas Doll",
      "Jasper Buschhoff",
      "Charvi Jain",
      "Alexander Weber",
      "Lena Jurkschat",
      "Hammam Abdelwahab",
      "Chelsea John",
      "Pedro Ortiz Suarez",
      "Malte Ostendorff",
      "Samuel Weinbach",
      "Rafet Sifa",
      "Stefan Kesselheim",
      "Nicolas Flores-Herr"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.248": {
    "title": "Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkai Zhou",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.249": {
    "title": "The Impact of Differential Privacy on Group Disparity Mitigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Victor Hansen",
      "Atula Neerkaje",
      "Ramit Sawhney",
      "Lucie Flek",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.250": {
    "title": "Isometric Neural Machine Translation using Phoneme Count Ratio Reward-based Reinforcement Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivam Mhaskar",
      "Nirmesh Shah",
      "Mohammadi Zaki",
      "Ashishkumar Gudmalwar",
      "Pankaj Wasnik",
      "Rajiv Shah"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.251": {
    "title": "Read between the lines - Functionality Extraction From READMEs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prince Kumar",
      "Srikanth Tamilselvam",
      "Dinesh Garg"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.252": {
    "title": "AbsPyramid: Benchmarking the Abstraction Ability of Language Models with a Unified Entailment Graph",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaowei Wang",
      "Haochen Shi",
      "Weiqi Wang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Sehyun Choi",
      "Xin Liu",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.253": {
    "title": "Few-TK: A Dataset for Few-shot Scientific Typed Keyphrase Recognition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avishek Lahiri",
      "Pratyay Sarkar",
      "Medha Sen",
      "Debarshi Sanyal",
      "Imon Mukherjee"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.254": {
    "title": "Language Models can be Deductive Solvers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiazhan Feng",
      "Ruochen Xu",
      "Junheng Hao",
      "Hiteshi Sharma",
      "Yelong Shen",
      "Dongyan Zhao",
      "Weizhu Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.255": {
    "title": "Interpreting User Requests in the Context of Natural Language Standing Instructions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Moghe",
      "Patrick Xia",
      "Jacob Andreas",
      "Jason Eisner",
      "Benjamin Van Durme",
      "Harsh Jhamtani"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.256": {
    "title": "Secure Your Model: An Effective Key Prompt Protection Mechanism for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruixiang Tang",
      "Yu-Neng Chuang",
      "Xuanting Cai",
      "Mengnan Du",
      "Xia Hu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.257": {
    "title": "Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiashuo Sun",
      "Yi Luo",
      "Yeyun Gong",
      "Chen Lin",
      "Yelong Shen",
      "Jian Guo",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.258": {
    "title": "Do Prompt Positions Really Matter?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyu Mao",
      "Stuart Middleton",
      "Mahesan Niranjan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.259": {
    "title": "Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhua Zhang",
      "Jiaxin Ge",
      "Hongyin Luo",
      "Yung-Sung Chuang",
      "Mingye Gao",
      "Yuan Gong",
      "Yoon Kim",
      "Xixin Wu",
      "Helen Meng",
      "James Glass"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.260": {
    "title": "A Study on Scaling Up Multilingual News Framing Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Syeda Sabrina Akter",
      "Antonios Anastasopoulos"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.261": {
    "title": "ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh-Nam Tran",
      "Phu-Vinh Nguyen",
      "Long Nguyen",
      "Dien Dinh"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.262": {
    "title": "Exploring the Trade-off Between Model Performance and Explanation Plausibility of Text Classifiers Using Human Rationales",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas Resck",
      "Marcos M. Raimundo",
      "Jorge Poco"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.263": {
    "title": "Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Su",
      "Xin Peng",
      "Sarubi Thillainathan",
      "David Guzmán",
      "Surangika Ranathunga",
      "En-Shiun Lee"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.264": {
    "title": "ADaPT: As-Needed Decomposition and Planning with Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Archiki Prasad",
      "Alexander Koller",
      "Mareike Hartmann",
      "Peter Clark",
      "Ashish Sabharwal",
      "Mohit Bansal",
      "Tushar Khot"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.265": {
    "title": "Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayeon Ki",
      "Marine Carpuat"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.266": {
    "title": "Non-contrastive sentence representations via self-supervision",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duccio Pappadopulo",
      "Marco Farina"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.267": {
    "title": "Semantically-Prompted Language Models Improve Visual Descriptions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Ogezi",
      "Bradley Hauer",
      "Grzegorz Kondrak"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.268": {
    "title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruotong Liao",
      "Xu Jia",
      "Yangzhe Li",
      "Yunpu Ma",
      "Volker Tresp"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.269": {
    "title": "A Transformer with Stack Attention",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaoda Li",
      "Jennifer White",
      "Mrinmaya Sachan",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.270": {
    "title": "InstructEval: Systematic Evaluation of Instruction Selection Methods",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anirudh Ajith",
      "Chris Pan",
      "Mengzhou Xia",
      "Ameet Deshpande",
      "Karthik Narasimhan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.271": {
    "title": "RecMind: Large Language Model Powered Agent For Recommendation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yancheng Wang",
      "Ziyan Jiang",
      "Zheng Chen",
      "Fan Yang",
      "Yingxue Zhou",
      "Eunah Cho",
      "Xing Fan",
      "Yanbin Lu",
      "Xiaojiang Huang",
      "Yingzhen Yang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.272": {
    "title": "GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohsen Gholami",
      "Mohammad Akbari",
      "Tianxi Hu",
      "Vaden Masrani",
      "Z. Wang",
      "Yong Zhang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.273": {
    "title": "How Lexical is Bilingual Lexicon Induction?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harsh Kohli",
      "Helian Feng",
      "Nicholas Dronen",
      "Calvin McCarter",
      "Sina Moeini",
      "Ali Kebarighotbi"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.274": {
    "title": "Fumbling in Babel: An Investigation into ChatGPT's Language Identification Ability",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Rui Chen",
      "Ife Adebara",
      "Khai Doan",
      "Qisheng Liao",
      "Muhammad Abdul-Mageed"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.275": {
    "title": "Targeted Augmentation for Low-Resource Event Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijia Wang",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.276": {
    "title": "Asking More Informative Questions for Grounded Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sedrick Keh",
      "Justin Chiu",
      "Daniel Fried"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.277": {
    "title": "Efficient Citer: Tuning Large Language Models for Enhanced Answer Quality and Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marzieh Tahaei",
      "Aref Jafari",
      "Ahmad Rashid",
      "David Alfonso-Hermelo",
      "Khalil Bibi",
      "Yimeng Wu",
      "Ali Ghodsi",
      "Boxing Chen",
      "Mehdi Rezagholizadeh"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.278": {
    "title": "Addressing Healthcare-related Racial and LGBTQ+ Biases in Pretrained Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sean Xie",
      "Saeed Hassanpour",
      "Soroush Vosoughi"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.279": {
    "title": "ATG: Benchmarking Automated Theorem Generation for Generative Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohan Lin",
      "Qingxing Cao",
      "Yinya Huang",
      "Zhicheng Yang",
      "Zhengying Liu",
      "Zhenguo Li",
      "Xiaodan Liang"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.280": {
    "title": "Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Liu",
      "Alexander Fabbri",
      "Jiawen Chen",
      "Yilun Zhao",
      "Simeng Han",
      "Shafiq Joty",
      "Pengfei Liu",
      "Dragomir Radev",
      "Chien-Sheng Wu",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.281": {
    "title": "NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phillip Howard",
      "Junlin Wang",
      "Vasudev Lal",
      "Gadi Singer",
      "Yejin Choi",
      "Swabha Swayamdipta"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.282": {
    "title": "Emotion-Anchored Contrastive Learning Framework for Emotion Recognition in Conversation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangxu Yu",
      "Junjie Guo",
      "Zhen Wu",
      "Xinyu Dai"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.283": {
    "title": "SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shicheng Liu",
      "Jialiang Xu",
      "Wesley Tjangnaka",
      "Sina Semnani",
      "Chen Yu",
      "Monica Lam"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.284": {
    "title": "On Evaluating the Integration of Reasoning and Action in LLM Agents with Database Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linyong Nan",
      "Ellen Zhang",
      "Weijin Zou",
      "Yilun Zhao",
      "Wenfei Zhou",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.285": {
    "title": "CARE: Extracting Experimental Findings From Clinical Literature",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aakanksha Naik",
      "Bailey Kuehl",
      "Erin Bransom",
      "Doug Downey",
      "Tom Hope"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.286": {
    "title": "Personalized Federated Learning for Text Classification with Gradient-Free Prompt Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Wang",
      "Tong Yu",
      "Ruiyi Zhang",
      "Sungchul Kim",
      "Ryan Rossi",
      "Handong Zhao",
      "Junda Wu",
      "Subrata Mitra",
      "Lina Yao",
      "Ricardo Henao"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.287": {
    "title": "SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shasha Guo",
      "Lizi Liao",
      "Jing Zhang",
      "Yanling Wang",
      "Cuiping Li",
      "Hong Chen"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.288": {
    "title": "Biomedical Entity Representation with Graph-Augmented Multi-Objective Transformer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrey Sakhovskiy",
      "Natalia Semenova",
      "Artur Kadurin",
      "Elena Tutubalina"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.289": {
    "title": "Cross-Lingual Summarization with Pseudo-Label Regularization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thang Le"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.290": {
    "title": "On the Way to Gentle AI Counselor: Politeness Cause Elicitation and Intensity Tagging in Code-mixed Hinglish Conversations for Social Good",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priyanshu Priya",
      "Gopendra Singh",
      "Mauajama Firdaus",
      "Jyotsna Agrawal",
      "Asif Ekbal"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.291": {
    "title": "Leveraging Summarization for Unsupervised Dialogue Topic Segmentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aleksei Artemiev",
      "Daniil Parinov",
      "Alexey Grishanov",
      "Ivan Borisov",
      "Alexey Vasilev",
      "Daniil Muravetskii",
      "Aleksey Rezvykh",
      "Aleksei Goncharov",
      "Andrey Savchenko"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.292": {
    "title": "LLaMA-Rider: Spurring Large Language Models to Explore the Open World",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Feng",
      "Yuxuan Wang",
      "Jiazheng Liu",
      "Sipeng Zheng",
      "Zongqing Lu"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.293": {
    "title": "Contrastive Learning as a Polarizer: Mitigating Gender Bias by Fair and Biased sentences",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyungmin Park",
      "Sihyun Oh",
      "Daehyun Kim",
      "Juae Kim"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.294": {
    "title": "PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Derui Zhu",
      "Dingfan Chen",
      "Qing Li",
      "Zongxiong Chen",
      "Lei Ma",
      "Jens Grossklags",
      "Mario Fritz"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.295": {
    "title": "Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juraj Vladika",
      "Florian Matthes"
    ]
  },
  "https://aclanthology.org/2024.findings-naacl.296": {
    "title": "DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Langedijk",
      "Hosein Mohebbi",
      "Gabriele Sarti",
      "Willem Zuidema",
      "Jaap Jumelet"
    ]
  }
}