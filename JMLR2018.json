{
  "https://jmlr.org/papers/v18/15-619.html": {
    "title": "On Binary Embedding using Circulant Matrices",
    "abstract": "Binary embeddings provide efficient and powerful ways to perform operations on large scale data. However binary embedding typically requires long codes in order to preserve the discriminative power of the input space. Thus binary coding methods traditionally suffer from high computation and storage costs in such a scenario. To address this problem, we propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The circulant structure allows us to use Fast Fourier Transform algorithms to speed up the computation. For obtaining $k$-bit binary codes from $d$-dimensional data, our method improves the time complexity from $\\mathcal{O}(dk)$ to $\\mathcal{O}(d\\log{d})$, and the space complexity from $\\mathcal{O}(dk)$ to $\\mathcal{O}(d)$. We study two settings, which differ in the way we choose the parameters of the circulant matrix. In the first, the parameters are chosen randomly and in the second, the parameters are learned using the data. For randomized CBE, we give a theoretical analysis comparing it with binary embedding using an unstructured random projection matrix. The challenge here is to show that the dependencies in the entries of the circulant matrix do not lead to a loss in performance. In the second setting, we design a novel time-frequency alternating optimization to learn data-dependent circulant projections, which alternatively minimizes the objective in original and Fourier domains. In both the settings, we show by extensive experiments that the CBE approach gives much better performance than the state-of-the-art approaches if we fix a running time, and provides much faster computation with negligible performance degradation if we fix the number of bits in the embedding",
    "volume": "main",
    "checked": true,
    "id": "1edb498c7cef4b43783809b0a3e86ac857c69573",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v18/16-579.html": {
    "title": "Variational Fourier Features for Gaussian Processes",
    "abstract": "This work brings together two powerful concepts in Gaussian processes: the variational approach to sparse approximation and the spectral representation of Gaussian processes. This gives rise to an approximation that inherits the benefits of the variational approach but with the representational power and computational scalability of spectral representations. The work hinges on a key result that there exist spectral features related to a finite domain of the Gaussian process which exhibit almost-independent covariances. We derive these expressions for MatÃ©rn kernels in one dimension, and generalize to more dimensions using kernels with specific structures. Under the assumption of additive Gaussian noise, our method requires only a single pass through the data set, making for very fast and accurate computation. We fit a model to 4 million training points in just a few minutes on a standard laptop. With non- conjugate likelihoods, our MCMC scheme reduces the cost of computation from $\\mathcal{O}(NM^2)$ (for a sparse Gaussian process) to $\\mathcal{O}(NM)$ per iteration, where $N$ is the number of data and $M$ is the number of features",
    "volume": "main",
    "checked": true,
    "id": "a9fae3cbd13c2d0a80a1f0a625167884d2738344",
    "citation_count": 162
  },
  "https://jmlr.org/papers/v18/17-434.html": {
    "title": "HyperTools: a Python Toolbox for Gaining Geometric Insights into High-Dimensional Data",
    "abstract": "Dimensionality reduction algorithms have played a foundational role in facilitating the deep understanding of complex high- dimensional data. One particularly useful application of dimensionality reduction techniques is in data visualization. Low-dimensional visualizations can help practitioners understand where machine learning algorithms might leverage the geometric properties of a dataset to improve performance. Another challenge is to generalize insights across datasets [e.g. data from multiple modalities describing the same system (Haxby et al., 2011), artwork or photographs of similar content in different styles (Zhu et al., 2017), etc.]. Several recently developed techniques(e.g. Haxby et al., 2011; Chen et al., 2015) use the procrustean transformation (Schonemann, 1966) to align the geometries of two or more spaces so that data with different axes may be plotted in a common space. We propose that each of these techniques (dimensionality reduction, alignment, and visualization) applied in sequence should be cast as a single conceptual hyperplot operation for gaining geometric insights into high-dimensional data. Our Python toolbox enables this operation in a single (highly flexible) function call",
    "volume": "MLOSS",
    "checked": true,
    "id": "71602749a2f9c449b032f06498edcc8c8dd5a944",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v18/17-468.html": {
    "title": "Automatic Differentiation in Machine Learning: a Survey",
    "abstract": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply Ã¢ÂÂautodiffÃ¢ÂÂ, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names Ã¢ÂÂdynamic computational graphsÃ¢ÂÂ and Ã¢ÂÂdifferentiable programmingÃ¢ÂÂ. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms Ã¢ÂÂautodiffÃ¢ÂÂ, Ã¢ÂÂautomatic differentiationÃ¢ÂÂ, and Ã¢ÂÂsymbolic differentiationÃ¢ÂÂ as these are encountered more and more in machine learning settings",
    "volume": "main",
    "checked": true,
    "id": "da118b8aa99699edd7609fbbd081d5b93bc2e87b",
    "citation_count": 1809
  }
}