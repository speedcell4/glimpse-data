{
  "https://aclanthology.org/2023.iwslt-1.1": {
    "title": "FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN",
    "abstract": "This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia",
    "volume": "IWSLT",
    "checked": true,
    "id": "f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b",
    "citation_count": 13
  },
  "https://aclanthology.org/2023.iwslt-1.2": {
    "title": "Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology",
    "abstract": "We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics",
    "volume": "IWSLT",
    "checked": true,
    "id": "c5849f406e8263806a84e1a407ec0e0fe131bd5c",
    "citation_count": 4
  },
  "https://aclanthology.org/2023.iwslt-1.3": {
    "title": "The MineTrans Systems for IWSLT 2023 Offline Speech Translation and Speech-to-Speech Translation Tasks",
    "abstract": "This paper presents the extscMineTrans English-to-Chinese speech translation systems developed for two challenge tracks of IWSLT 2023, i.e., Offline Speech Translation (S2T) and Speech-to-Speech Translation (S2ST). For the S2T track, extscMineTrans employs a practical cascaded system to explore the limits of translation performance in both constrained and unconstrained settings, where the whole system consists of automatic speech recognition (ASR), punctuation recognition (PC), and machine translation (MT) modules. We also investigate the effectiveness of multiple ASR architectures and explore two MT strategies: supervised in-domain fine-tuning and prompt-guided translation using a large language model. For the S2ST track, we explore a speech-to-unit (S2U) framework to build an end-to-end S2ST system. This system encodes the target speech as discrete units via our trained HuBERT. Then it leverages the standard sequence-to-sequence model to directly learn the mapping between source speech and discrete units without any auxiliary recognition tasks (i.e., ASR and MT tasks). Various efforts are made to improve the extscMineTrans’s performance, such as acoustic model pre-training on large-scale data, data filtering, data augmentation, speech segmentation, knowledge distillation, consistency training, model ensembles, etc",
    "volume": "IWSLT",
    "checked": true,
    "id": "3c0d4eff49b3a474bacdbc4fbd67034c4e8146d9",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.4": {
    "title": "Improving End-to-End Speech Translation by Imitation-Based Knowledge Distillation with Synthetic Transcripts",
    "abstract": "End-to-end automatic speech translation (AST) relies on data that combines audio inputs with text translation outputs. Previous work used existing large parallel corpora of transcriptions and translations in a knowledge distillation (KD) setup to distill a neural machine translation (NMT) into an AST student model. While KD allows using larger pretrained models, the reliance of previous KD approaches on manual audio transcripts in the data pipeline restricts the applicability of this framework to AST. We present an imitation learning approach where a teacher NMT system corrects the errors of an AST student without relying on manual transcripts. We show that the NMT teacher can recover from errors in automatic transcriptions and is able to correct erroneous translations of the AST student, leading to improvements of about 4 BLEU points over the standard AST end-to-end baseline on the English-German CoVoST-2 and MuST-C datasets, respectively. Code and data are publicly available: https://github.com/HubReb/imitkd_ast/releases/tag/v1.1",
    "volume": "IWSLT",
    "checked": true,
    "id": "f542abda96065e3e1dea020166086ef73460c4a5",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.5": {
    "title": "The USTC's Dialect Speech Translation System for IWSLT 2023",
    "abstract": "This paper presents the USTC system for the IWSLT 2023 Dialectal and Low-resource shared task, which involves translation from Tunisian Arabic to English. We aim to investigate the mutual transfer between Tunisian Arabic and Modern Standard Arabic (MSA) to enhance the performance of speech translation (ST) by following standard pre-training and fine-tuning pipelines. We synthesize a substantial amount of pseudo Tunisian-English paired data using a multi-step pre-training approach. Integrating a Tunisian-MSA translation module into the end-to-end ST model enables the transfer from Tunisian to MSA and facilitates linguistic normalization of the dialect. To increase the robustness of the ST system, we optimize the model’s ability to adapt to ASR errors and propose a model ensemble method. Results indicate that applying the dialect transfer method can increase the BLEU score of dialectal ST. It is shown that the optimal system ensembles both cascaded and end-to-end ST models, achieving BLEU improvements of 2.4 and 2.8 in test1 and test2 sets, respectively, compared to the best published system",
    "volume": "IWSLT",
    "checked": true,
    "id": "b293f87da5528af49965c20343200fd60490ff8c",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.6": {
    "title": "KIT's Multilingual Speech Translation System for IWSLT 2023",
    "abstract": "Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks",
    "volume": "IWSLT",
    "checked": true,
    "id": "0732c385dc9a8e9b9673422bed986e5b57aa22ea",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.iwslt-1.7": {
    "title": "The BIGAI Offline Speech Translation Systems for IWSLT 2023 Evaluation",
    "abstract": "This paper describes the BIGAI’s submission to IWSLT 2023 Offline Speech Translation task on three language tracks from English to Chinese, German and Japanese. The end-to-end systems are built upon a Wav2Vec2 model for speech recognition and mBART50 models for machine translation. An adapter module is applied to bridge the speech module and the translation module. The CTC loss between speech features and source token sequence is incorporated during training. Experiments show that the systems can generate reasonable translations on three languages. The proposed models achieve BLEU scores of 22.3 for en→de, 10.7 for en→ja and 33.0 for en→zh on tst2023 TED datasets. However, the performance is decreased by a significant margin on complex scenarios like persentations and interview",
    "volume": "IWSLT",
    "checked": true,
    "id": "ab9873c27df5619f6e0d99600cc91f717041b023",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.8": {
    "title": "Enhancing Video Translation Context with Object Labels",
    "abstract": "We present a simple yet efficient method to enhance the quality of machine translation models trained on multimodal corpora by augmenting the training text with labels of detected objects in the corresponding video segments. We then test the effects of label augmentation in both baseline and two automatic speech recognition (ASR) conditions. In contrast with multimodal techniques that merge visual and textual features, our modular method is easy to implement and the results are more interpretable. Comparisons are made with Transformer translation architectures trained with baseline and augmented labels, showing improvements of up to +1.0 BLEU on the How2 dataset",
    "volume": "IWSLT",
    "checked": true,
    "id": "cde6d6fc9dbc295b8b4d229c4a663e2269e4ffe5",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.9": {
    "title": "Length-Aware NMT and Adaptive Duration for Automatic Dubbing",
    "abstract": "This paper presents the submission of Huawei Translation Services Center for the IWSLT 2023 dubbing task in the unconstrained setting. The proposed solution consists of a Transformer-based machine translation model and a phoneme duration predictor. The Transformer is deep and multiple target-to-source length-ratio class labels are used to control target lengths. The variation predictor in FastSpeech2 is utilized to predict phoneme durations. To optimize the isochrony in dubbing, re-ranking and scaling are performed. The source audio duration is used as a reference to re-rank the translations of different length-ratio labels, and the one with minimum time deviation is preferred. Additionally, the phoneme duration outputs are scaled within a defined threshold to narrow the duration gap with the source audio",
    "volume": "IWSLT",
    "checked": true,
    "id": "b7651f354a8df8af3763deb2c4cc1d4aff6dc4b3",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.10": {
    "title": "NAVER LABS Europe's Multilingual Speech Translation Systems for the IWSLT 2023 Low-Resource Track",
    "abstract": "This paper presents NAVER LABS Europe’s systems for Tamasheq-French and Quechua-Spanish speech translation in the IWSLT 2023 Low-Resource track. Our work attempts to maximize translation quality in low-resource settings using multilingual parameter-efficient solutions that leverage strong pre-trained models. Our primary submission for Tamasheq outperforms the previous state of the art by 7.5 BLEU points on the IWSLT 2022 test set, and achieves 23.6 BLEU on this year’s test set, outperforming the second best participant by 7.7 points. For Quechua, we also rank first and achieve 17.7 BLEU, despite having only two hours of translation data. Finally, we show that our proposed multilingual architecture is also competitive for high-resource languages, outperforming the best unconstrained submission to the IWSLT 2021 Multilingual track, despite using much less training data and compute",
    "volume": "IWSLT",
    "checked": true,
    "id": "d27f510be5024a5af056ccdd20a5957d00d81037",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.11": {
    "title": "Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023",
    "abstract": "This paper describes the FBK’s participation in the Simultaneous Translation and Automatic Subtitling tracks of the IWSLT 2023 Evaluation Campaign. Our submission focused on the use of direct architectures to perform both tasks: for the simultaneous one, we leveraged the knowledge already acquired by offline-trained models and directly applied a policy to obtain the real-time inference; for the subtitling one, we adapted the direct ST model to produce well-formed subtitles and exploited the same architecture to produce timestamps needed for the subtitle synchronization with audiovisual content. Our English-German SimulST system shows a reduced computational-aware latency compared to the one achieved by the top-ranked systems in the 2021 and 2022 rounds of the task, with gains of up to 3.5 BLEU. Our automatic subtitling system outperforms the only-existing solution based on a direct system by 3.7 and 1.7 SubER in English-German and English-Spanish respectively",
    "volume": "IWSLT",
    "checked": true,
    "id": "9dcbab7c35c0fd23f50bad8e2c566dfdb4784536",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.12": {
    "title": "MT Metrics Correlate with Human Ratings of Simultaneous Speech Translation",
    "abstract": "There have been several meta-evaluation studies on the correlation between human ratings and offline machine translation (MT) evaluation metrics such as BLEU, chrF2, BertScore and COMET. These metrics have been used to evaluate simultaneous speech translation (SST) but their correlations with human ratings of SST, which has been recently collected as Continuous Ratings (CR), are unclear. In this paper, we leverage the evaluations of candidate systems submitted to the English-German SST task at IWSLT 2022 and conduct an extensive correlation analysis of CR and the aforementioned metrics. Our study reveals that the offline metrics are well correlated with CR and can be reliably used for evaluating machine translation in simultaneous mode, with some limitations on the test set size. We conclude that given the current quality levels of SST, these metrics can be used as proxies for CR, alleviating the need for large scale human evaluation. Additionally, we observe that correlations of the metrics with translation as a reference is significantly higher than with simultaneous interpreting, and thus we recommend the former for reliable evaluation",
    "volume": "IWSLT",
    "checked": true,
    "id": "26f10cea3d27f90315d8ace9834aff049d7cb463",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.13": {
    "title": "Improving Neural Machine Translation Formality Control with Domain Adaptation and Reranking-based Transductive Learning",
    "abstract": "This paper presents Huawei Translation Service Center (HW-TSC)’s submission on the IWSLT 2023 formality control task, which provides two training scenarios: supervised and zero-shot, each containing two language pairs, and sets constrained and unconstrained conditions. We train the formality control models for these four language pairs under these two conditions respectively, and submit the corresponding translation results. Our efforts are divided into two fronts: enhancing general translation quality and improving formality control capability. According to the different requirements of the formality control task, we use a multi-stage pre-training method to train a bilingual or multilingual neural machine translation (NMT) model as the basic model, which can improve the general translation quality of the base model to a relatively high level. Then, under the premise of affecting the general translation quality of the basic model as little as possible, we adopt domain adaptation and reranking-based transductive learning methods to improve the formality control capability of the model",
    "volume": "IWSLT",
    "checked": true,
    "id": "8a6e36bb5e02667ba4767778d6e3f50b2bd86acf",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.14": {
    "title": "HW-TSC at IWSLT2023: Break the Quality Ceiling of Offline Track via Pre-Training and Domain Adaptation",
    "abstract": "This paper presents HW-TSC’s submissions to the IWSLT 2023 Offline Speech Translation task, including speech translation of talks from English to German, Chinese, and Japanese, respectively. We participate in all three conditions (constrained training, constrained with large language models training, and unconstrained training) with models of cascaded architectures. We use data enhancement, pre-training models and other means to improve the ASR quality, and R-Drop, deep model, domain data selection, etc. to improve the translation quality. Compared with last year’s best results, we achieve 2.1 BLEU improvement on the MuST-C English-German test set",
    "volume": "IWSLT",
    "checked": true,
    "id": "f69fc5e9f23507207bb72d59425d185dbd9c09ca",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.15": {
    "title": "Submission of USTC's System for the IWSLT 2023 - Offline Speech Translation Track",
    "abstract": "This paper describes the submissions of the research group USTC-NELSLIP to the 2023 IWSLT Offline Speech Translation competition, which involves translating spoken English into written Chinese. We utilize both cascaded models and end-to-end models for this task. To improve the performance of the cascaded models, we introduce Whisper to reduce errors in the intermediate source language text, achieving a significant improvement in ASR recognition performance. For end-to-end models, we propose Stacked Acoustic-and-Textual En- coding extension (SATE-ex), which feeds the output of the acoustic decoder into the textual decoder for information fusion and to prevent error propagation. Additionally, we improve the performance of the end-to-end system in translating speech by combining the SATE-ex model with the encoder-decoder model through ensembling",
    "volume": "IWSLT",
    "checked": true,
    "id": "1f1804280a936670a66afb8e496ed38394f8acbd",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.16": {
    "title": "I2R's End-to-End Speech Translation System for IWSLT 2023 Offline Shared Task",
    "abstract": "This paper describes I2R’s submission to the offline speech translation track for IWSLT 2023. We focus on an end-to-end approach for translation from English audio to German text, one of the three available language directions in this year’s edition. The I2R system leverages on pretrained models that have been exposed to large-scale audio and text data for our base model. We introduce several stages of additional pretraining followed by fine-tuning to adapt the system for the downstream speech translation task. The strategy is supplemented by other techniques such as data augmentation, domain tagging, knowledge distillation, and model ensemble, among others. We evaluate the system on several publicly available test sets for comparison",
    "volume": "IWSLT",
    "checked": true,
    "id": "c009d943326fc3fc78a9446b9f969ff555c3b93f",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.17": {
    "title": "The NiuTrans End-to-End Speech Translation System for IWSLT23 English-to-Chinese Offline Task",
    "abstract": "This paper describes the NiuTrans end-to-end speech translation system submitted for the IWSLT 2023 English-to-Chinese offline task. Our speech translation models are composed of pre-trained ASR and MT models under the SATE framework. Several pre-trained models with diverse architectures and input representations (e.g., log Mel-filterbank and waveform) were utilized. We proposed an IDA method to iteratively improve the performance of the MT models and generate the pseudo ST data through MT systems. We then trained ST models with different structures and data settings to enhance ensemble performance. Experimental results demonstrate that our NiuTrans system achieved a BLEU score of 29.22 on the MuST-C En-Zh tst-COMMON set, outperforming the previous year’s submission by 0.12 BLEU despite using less MT training data",
    "volume": "IWSLT",
    "checked": true,
    "id": "131d9adfa9fb9a2ecff3a33d97d04a5eae9cac1d",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.18": {
    "title": "ON-TRAC Consortium Systems for the IWSLT 2023 Dialectal and Low-resource Speech Translation Tasks",
    "abstract": "This paper describes the ON-TRAC consortium speech translation systems developed for IWSLT 2023 evaluation campaign. Overall, we participated in three speech translation tracks featured in the low-resource and dialect speech translation shared tasks, namely; i) spoken Tamasheq to written French, ii) spoken Pashto to written French, and iii) spoken Tunisian to written English. All our primary submissions are based on the end-to-end speech-to-text neural architecture using a pretrained SAMU-XLSR model as a speech encoder and a mbart model as a decoder. The SAMU-XLSR model is built from the XLS-R 128 in order to generate language agnostic sentence-level embeddings. This building is driven by the LaBSE model trained on multilingual text dataset. This architecture allows us to improve the input speech representations and achieve significant improvements compared to conventional end-to-end speech translation systems",
    "volume": "IWSLT",
    "checked": true,
    "id": "ddff657f31b21c82084436ddb50615a6ae9ea054",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.19": {
    "title": "BUT Systems for IWSLT 2023 Marathi - Hindi Low Resource Speech Translation Task",
    "abstract": "This paper describes the systems submitted for Marathi to Hindi low-resource speech translation task. Our primary submission is based on an end-to-end direct speech translation system, whereas the contrastive one is a cascaded system. The backbone of both the systems is a Hindi-Marathi bilingual ASR system trained on 2790 hours of imperfect transcribed speech. The end-to-end speech translation system was directly initialized from the ASR, and then fine-tuned for direct speech translation with an auxiliary CTC loss for translation. The MT model for the cascaded system is initialized from a cross-lingual language model, which was then fine-tuned using 1.6 M parallel sentences. All our systems were trained from scratch on publicly available datasets. In the end, we use a language model to re-score the n-best hypotheses. Our primary submission achieved 30.5 and 39.6 BLEU whereas the contrastive system obtained 21.7 and 28.6 BLEU on official dev and test sets respectively. The paper also presents the analysis on several experiments that were conducted and outlines the strategies for improving speech translation in low-resource scenarios",
    "volume": "IWSLT",
    "checked": true,
    "id": "fa9b32f0ec3cc1db3619d38d44be9b216586fcc3",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.20": {
    "title": "CMU's IWSLT 2023 Simultaneous Speech Translation System",
    "abstract": "This paper describes CMU’s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion. We first build offline speech-to-text (ST) models using the joint CTC/attention framework. These models also use WavLM front-end features and mBART decoder initialization. We adapt our offline ST models for simultaneous speech-to-text translation (SST) by 1) incrementally encoding chunks of input speech, re-computing encoder states for each new chunk and 2) incrementally decoding output text, pruning beam search hypotheses to 1-best after processing each chunk. We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models",
    "volume": "IWSLT",
    "checked": true,
    "id": "3c01b59cd923192913bb96849a892c5732c40d3d",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.21": {
    "title": "Improving Low Resource Speech Translation with Data Augmentation and Ensemble Strategies",
    "abstract": "This paper describes the speech translation system submitted as part of the IWSLT 2023 shared task on low resource speech translation. The low resource task aids in building models for language pairs where the training corpus is limited. In this paper, we focus on two language pairs, namely, Tamasheq-French (Tmh→Fra) and Marathi-Hindi (Mr→Hi) and implement a speech translation system that is unconstrained. We evaluate three strategies in our system: (a) Data augmentation where we perform different operations on audio as well as text samples, (b) an ensemble model that integrates a set of models trained using a combination of augmentation strategies, and (c) post-processing techniques where we explore the use of large language models (LLMs) to improve the quality of sentences that are generated. Experiments show how data augmentation can relatively improve the BLEU score by 5.2% over the baseline system for Tmh→Fra while an ensemble model further improves performance by 17% for Tmh→Fra and 23% for Mr→Hi task",
    "volume": "IWSLT",
    "checked": true,
    "id": "a314bc35020be9239e98079ecbb691a747e940c4",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.22": {
    "title": "Speech Translation with Style: AppTek's Submissions to the IWSLT Subtitling and Formality Tracks in 2023",
    "abstract": "AppTek participated in the subtitling and formality tracks of the IWSLT 2023 evaluation. This paper describes the details of our subtitling pipeline - speech segmentation, speech recognition, punctuation prediction and inverse text normalization, text machine translation and direct speech-to-text translation, intelligent line segmentation - and how we make use of the provided subtitling-specific data in training and fine-tuning. The evaluation results show that our final submissions are competitive, in particular outperforming the submissions by other participants by 5% absolute as measured by the SubER subtitle quality metric. For the formality track, we participate with our En-Ru and En-Pt production models, which support formality control via prefix tokens. Except for informal Portuguese, we achieve near perfect formality level accuracy while at the same time offering high general translation quality",
    "volume": "IWSLT",
    "checked": true,
    "id": "bedd880592abfdbc5909c6608403c5d52fb4a170",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.23": {
    "title": "QUESPA Submission for the IWSLT 2023 Dialect and Low-resource Speech Translation Tasks",
    "abstract": "This article describes the QUESPA team speech translation (ST) submissions for the Quechua to Spanish (QUE–SPA) track featured in the Evaluation Campaign of IWSLT 2023: low-resource and dialect speech translation. Two main submission types were supported in the campaign: constrained and unconstrained. We submitted six total systems of which our best (primary) constrained system consisted of an ST model based on the Fairseq S2T framework where the audio representations were created using log mel-scale filter banks as features and the translations were performed using a transformer. The best (primary) unconstrained system used a pipeline approach which combined automatic speech recognition (ASR) with machine translation (MT). The ASR transcriptions for the best unconstrained system were computed using a pre-trained XLS-R-based model along with a fine-tuned language model. Transcriptions were translated using a MT system based on a fine-tuned, pre-trained language model (PLM). The four other submissions are presented in this article (2 constrained and 2 unconstrained) for comparison because they consist of various architectures. Our results show that direct ST (ASR and MT combined together) can be more effective than a PLM in a low-resource (constrained) setting for Quechua to Spanish. On the other hand, we show that fine-tuning of any type on both the ASR and MT system is worthwhile, resulting in nearly 16 BLEU for the unconstrained task",
    "volume": "IWSLT",
    "checked": true,
    "id": "603341b7eca692f75ae4dafacec0881f7d2df787",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.24": {
    "title": "GMU Systems for the IWSLT 2023 Dialect and Low-resource Speech Translation Tasks",
    "abstract": "This paper describes the GMU Systems for the IWSLT 2023 Dialect and Low-resource Speech Translation Tasks. We submitted systems for five low-resource tasks and the dialectal task. In this work, we explored self-supervised pre-trained speech models and finetuned them on speech translation downstream tasks. We use the Wav2vec 2.0, XLSR-53, and Hubert as self-supervised models. Unlike Hubert, Wav2vec 2.0 and XLSR-53 achieve the best results when we remove the top three layers. Our results show that Wav2vec 2.0 and Hubert perform similarly with their relative best configuration. In addition, we found that Wav2vec 2.0 pre-trained on audio data of the same language as the source language of a speech translation model achieves better results. For the low-resource setting, the best results are achieved using either the Wav2vec 2.0 or Hubert models, while XLSR-53 achieves the best results for the dialectal transfer task. We find that XLSR-53 does not perform well for low-resource tasks. Using Wav2vec 2.0, we report close to 2 BLEU point improvements on the test set for the Tamasheq-French compared to the baseline system at the IWSLT 2022",
    "volume": "IWSLT",
    "checked": true,
    "id": "0ca3ea625fdbb3f039b2ab24566fa47a4c2ea304",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.25": {
    "title": "The HW-TSC's Speech-to-Speech Translation System for IWSLT 2023",
    "abstract": "This paper describes our work on the IWSLT2023 Speech-to-Speech task. Our proposed cascaded system consists of an ensemble of Conformer and S2T-Transformer-based ASR models, a Transformer-based MT model, and a Diffusion-based TTS model. Our primary focus in this competition was to investigate the modeling ability of the Diffusion model for TTS tasks in high-resource scenarios and the role of TTS in the overall S2S task. To this end, we proposed DTS, an end-to-end diffusion-based TTS model that takes raw text as input and generates waveform by iteratively denoising on pure Gaussian noise. Compared to previous TTS models, the speech generated by DTS is more natural and performs better in code-switching scenarios. As the training process is end-to-end, it is relatively straightforward. Our experiments demonstrate that DTS outperforms other TTS models on the GigaS2S benchmark, and also brings positive gains for the entire S2S system",
    "volume": "IWSLT",
    "checked": true,
    "id": "94831dce4cae2a5b39953fa5c76178fbd8ecbcd0",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.26": {
    "title": "JHU IWSLT 2023 Dialect Speech Translation System Description",
    "abstract": "This paper presents JHU’s submissions to the IWSLT 2023 dialectal and low-resource track of Tunisian Arabic to English speech translation. The Tunisian dialect lacks formal orthography and abundant training data, making it challenging to develop effective speech translation (ST) systems. To address these challenges, we explore the integration of large pre-trained machine translation (MT) models, such as mBART and NLLB-200 in both end-to-end (E2E) and cascaded speech translation (ST) systems. We also improve the performance of automatic speech recognition (ASR) through the use of pseudo-labeling data augmentation and channel matching on telephone data. Finally, we combine our E2E and cascaded ST systems with Minimum Bayes-Risk decoding. Our combined system achieves a BLEU score of 21.6 and 19.1 on test2 and test3, respectively",
    "volume": "IWSLT",
    "checked": true,
    "id": "b9edd0382d6721c797a1839bcd93092b373c611e",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.27": {
    "title": "Learning Nearest Neighbour Informed Latent Word Embeddings to Improve Zero-Shot Machine Translation",
    "abstract": "Multilingual neural translation models exploit cross-lingual transfer to perform zero-shot translation between unseen language pairs. Past efforts to improve cross-lingual transfer have focused on aligning contextual sentence-level representations. This paper introduces three novel contributions to allow exploiting nearest neighbours at the token level during training, including: (i) an efficient, gradient-friendly way to share representations between neighboring tokens; (ii) an attentional semantic layer which extracts latent features from shared embeddings; and (iii) an agreement loss to harmonize predictions across different sentence representations. Experiments on two multilingual datasets demonstrate consistent gains in zero shot translation over strong baselines",
    "volume": "IWSLT",
    "checked": true,
    "id": "dba3ac0bb46c59e18d3e28065535761d4ffc5420",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.28": {
    "title": "JHU IWSLT 2023 Multilingual Speech Translation System Description",
    "abstract": "We describe the Johns Hopkins ACL 60-60 Speech Translation systems submitted to the IWSLT 2023 Multilingual track, where we were tasked to translate ACL presentations from English into 10 languages. We developed cascaded speech translation systems for both the constrained and unconstrained subtracks. Our systems make use of pre-trained models as well as domain-specific corpora for this highly technical evaluation-only task. We find that the specific technical domain which ACL presentations fall into presents a unique challenge for both ASR and MT, and we present an error analysis and an ACL-specific corpus we produced to enable further work in this area",
    "volume": "IWSLT",
    "checked": true,
    "id": "ef7de4c64d33336b5c1806725e08cd1f2ba6f902",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.29": {
    "title": "The NPU-MSXF Speech-to-Speech Translation System for IWSLT 2023 Speech-to-Speech Translation Task",
    "abstract": "This paper describes the NPU-MSXF system for the IWSLT 2023 speech-to-speech translation (S2ST) task which aims to translate from English speech of multi-source to Chinese speech. The system is built in a cascaded manner consisting of automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS). We make tremendous efforts to handle the challenging multi-source input. Specifically, to improve the robustness to multi-source speech input, we adopt various data augmentation strategies and a ROVER-based score fusion on multiple ASR model outputs. To better handle the noisy ASR transcripts, we introduce a three-stage fine-tuning strategy to improve translation accuracy. Finally, we build a TTS model with high naturalness and sound quality, which leverages a two-stage framework, using network bottleneck features as a robust intermediate representation for speaker timbre and linguistic content disentanglement. Based on the two-stage framework, pre-trained speaker embedding is leveraged as a condition to transfer the speaker timbre in the source English speech to the translated Chinese speech. Experimental results show that our system has high translation accuracy, speech naturalness, sound quality, and speaker similarity. Moreover, it shows good robustness to multi-source data",
    "volume": "IWSLT",
    "checked": true,
    "id": "ad86f04206b64a11d8fd4d570be553e3879c3275",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.30": {
    "title": "Low-Resource Formality Controlled NMT Using Pre-trained LM",
    "abstract": "This paper describes the UCSC’s submission to the shared task on formality control for spoken language translation at IWSLT 2023. For this task, we explored the use of ‘additive style intervention’ using a pre-trained multilingual translation model, namely mBART. Compared to prior approaches where a single style-vector was added to all tokens in the encoder output, we explored an alternative approach in which we learn a unique style-vector for each input token. We believe this approach, which we call ‘style embedding intervention,’ is better suited for formality control as it can potentially learn which specific input tokens to modify during decoding. While the proposed approach obtained similar performance to ‘additive style intervention’ for the supervised English-to-Vietnamese task, it performed significantly better for English-to-Korean, in which it achieved an average matched accuracy of 90.6 compared to 85.2 for the baseline. When we constrained the model further to only perform style intervention on the <bos> (beginning of sentence) token, the average matched accuracy improved further to 92.0, indicating that the model could learn to control the formality of the translation output based solely on the embedding of the <bos> token",
    "volume": "IWSLT",
    "checked": true,
    "id": "19aee395feeb9e8b8bdd66fc095a1021d5b5fbac",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.31": {
    "title": "NAIST Simultaneous Speech-to-speech Translation System for IWSLT 2023",
    "abstract": "This paper describes NAIST’s submission to the IWSLT 2023 Simultaneous Speech Translation task: English-to-German, Japanese, Chinese speech-to-text translation and English-to-Japanese speech-to-speech translation. Our speech-to-text system uses an end-to-end multilingual speech translation model based on large-scale pre-trained speech and text models. We add Inter-connections into the model to incorporate the outputs from intermediate layers of the pre-trained speech model and augment prefix-to-prefix text data using Bilingual Prefix Alignment to enhance the simultaneity of the offline speech translation model. Our speech-to-speech system employs an incremental text-to-speech module that consists of a Japanese pronunciation estimation model, an acoustic model, and a neural vocoder",
    "volume": "IWSLT",
    "checked": true,
    "id": "3ebf4385084c97e18f00f011d425d0608ffdb397",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.32": {
    "title": "Language Model Based Target Token Importance Rescaling for Simultaneous Neural Machine Translation",
    "abstract": "The decoder in simultaneous neural machine translation receives limited information from the source while having to balance the opposing requirements of latency versus translation quality. In this paper, we use an auxiliary target-side language model to augment the training of the decoder model. Under this notion of target adaptive training, generating rare or difficult tokens is rewarded which improves the translation quality while reducing latency. The predictions made by a language model in the decoder are combined with the traditional cross entropy loss which frees up the focus on the source side context. Our experimental results over multiple language pairs show that compared to previous state of the art methods in simultaneous translation, we can use an augmented target side context to improve BLEU scores significantly. We show improvements over the state of the art in the low latency range with lower average lagging values (faster output)",
    "volume": "IWSLT",
    "checked": true,
    "id": "56ccfd38c04bbcd6c7373bfedc20258e2bed3c10",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.33": {
    "title": "The Kyoto Speech-to-Speech Translation System for IWSLT 2023",
    "abstract": "This paper describes the Kyoto speech-to-speech translation system for IWSLT 2023. Our system is a combination of speech-to-text translation and text-to-speech synthesis. For the speech-to-text translation model, we used the dual-decoderTransformer model. For text-to-speech synthesis model, we took a cascade approach of an acoustic model and a vocoder",
    "volume": "IWSLT",
    "checked": true,
    "id": "513b6d15e2d4fd9d77b2dd5b1d6a609bd5499110",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.34": {
    "title": "Tagged End-to-End Simultaneous Speech Translation Training Using Simultaneous Interpretation Data",
    "abstract": "Simultaneous speech translation (SimulST) translates partial speech inputs incrementally. Although the monotonic correspondence between input and output is preferable for smaller latency, it is not the case for distant language pairs such as English and Japanese. A prospective approach to this problem is to mimic simultaneous interpretation (SI) using SI data to train a SimulST model. However, the size of such SI data is limited, so the SI data should be used together with ordinary bilingual data whose translations are given in offline. In this paper, we propose an effective way to train a SimulST model using mixed data of SI and offline. The proposed method trains a single model using the mixed data with style tags that tell the model to generate SI- or offline-style outputs. Experiment results show improvements of BLEURT in different latency ranges, and our analyses revealed the proposed model generates SI-style outputs more than the baseline",
    "volume": "IWSLT",
    "checked": true,
    "id": "405349567ede6061749d9a6974829ac1fc09f8a9",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.35": {
    "title": "The HW-TSC's Simultaneous Speech-to-Text Translation System for IWSLT 2023 Evaluation",
    "abstract": "In this paper, we present our submission to the IWSLT 2023 Simultaneous Speech-to-Text Translation competition. Our participation involves three language directions: English-German, English-Chinese, and English-Japanese. Our proposed solution is a cascaded incremental decoding system that comprises an ASR model and an MT model. The ASR model is based on the U2++ architecture and can handle both streaming and offline speech scenarios with ease. Meanwhile, the MT model adopts the Deep-Transformer architecture. To improve performance, we explore methods to generate a confident partial target text output that guides the next MT incremental decoding process. In our experiments, we demonstrate that our simultaneous strategies achieve low latency while maintaining a loss of no more than 2 BLEU points when compared to offline systems",
    "volume": "IWSLT",
    "checked": true,
    "id": "c99cec996507c795c83d32ee9a283b105b4145e3",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.36": {
    "title": "The HW-TSC's Simultaneous Speech-to-Speech Translation System for IWSLT 2023 Evaluation",
    "abstract": "In this paper, we present our submission to the IWSLT 2023 Simultaneous Speech-to-Speech Translation competition. Our participation involves three language directions: English-German, English-Chinese, and English-Japanese. Our solution is a cascaded incremental decoding system, consisting of an ASR model, an MT model, and a TTS model. By adopting the strategies used in the Speech-to-Text track, we have managed to generate a more confident target text for each audio segment input, which can guide the next MT incremental decoding process. Additionally, we have integrated the TTS model to seamlessly reproduce audio files from the translation hypothesis. To enhance the effectiveness of our experiment, we have utilized a range of methods to reduce error conditions in the TTS input text and improve the smoothness of the TTS output audio",
    "volume": "IWSLT",
    "checked": true,
    "id": "b7cab49c5b14b25cd0d049cc956a4429528f8366",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.37": {
    "title": "Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023",
    "abstract": "In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF)",
    "volume": "IWSLT",
    "checked": true,
    "id": "f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.iwslt-1.38": {
    "title": "Speech Translation with Foundation Models and Optimal Transport: UPC at IWSLT23",
    "abstract": "This paper describes the submission of the UPC Machine Translation group to the IWSLT 2023 Offline Speech Translation task. Our Speech Translation systems utilize foundation models for speech (wav2vec 2.0) and text (mBART50). We incorporate a Siamese pretraining step of the speech and text encoders with CTC and Optimal Transport, to adapt the speech representations to the space of the text model, thus maximizing transfer learning from MT. After this pretraining, we fine-tune our system end-to-end on ST, with Cross Entropy and Knowledge Distillation. Apart from the available ST corpora, we create synthetic data with SegAugment to better adapt our models to the custom segmentations of the IWSLT test sets. Our best single model obtains 31.2 BLEU points on MuST-C tst-COMMON, 29.8 points on IWLST.tst2020 and 33.4 points on the newly released IWSLT.ACLdev2023",
    "volume": "IWSLT",
    "checked": true,
    "id": "074e40b84d52de0147ce470e45be9ac5322025a9",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.39": {
    "title": "The Xiaomi AI Lab's Speech Translation Systems for IWSLT 2023 Offline Task, Simultaneous Task and Speech-to-Speech Task",
    "abstract": "This system description paper introduces the systems submitted by Xiaomi AI Lab to the three tracks of the IWSLT 2023 Evaluation Campaign, namely the offline speech translation (Offline-ST) track, the offline speech-to-speech translation (Offline-S2ST) track, and the simultaneous speech translation (Simul-ST) track. All our submissions for these three tracks only involve the English-Chinese language direction. Our English-Chinese speech translation systems are constructed using large-scale pre-trained models as the foundation. Specifically, we fine-tune these models’ corresponding components for various downstream speech translation tasks. Moreover, we implement several popular techniques, such as data filtering, data augmentation, speech segmentation, and model ensemble, to improve the system’s overall performance. Extensive experiments show that our systems achieve a significant improvement over the strong baseline systems in terms of the automatic evaluation metric",
    "volume": "IWSLT",
    "checked": true,
    "id": "5ceefc8e50375ac2195659def2ef4fc31366f918",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.40": {
    "title": "Improving Formality-Sensitive Machine Translation Using Data-Centric Approaches and Prompt Engineering",
    "abstract": "In this paper, we present the KU x Upstage team’s submission for the Special Task on Formality Control on Spoken Language Translation, which involves translating English into four languages with diverse grammatical formality markers. Our methodology comprises two primary components: 1) a language-specific data-driven approach, and 2) the generation of synthetic data through the employment of large-scale language models and empirically-grounded prompt engineering. By adapting methodologies and models to accommodate the unique linguistic properties of each language, we observe a notable enhancement in performance relative to the baseline, substantiating the heightened efficacy of data-driven approaches. Moreover, our devised prompt engineering strategy yields superior synthetic translation instances",
    "volume": "IWSLT",
    "checked": true,
    "id": "aa3cdaac0dc02e90b9ca0073dd27f41944b8f1a9",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.41": {
    "title": "UM-DFKI Maltese Speech Translation",
    "abstract": "For the 2023 IWSLT Maltese Speech Translation Task, UM-DFKI jointly presents a cascade solution which achieves 0.6 BLEU. While this is the first time that a Maltese speech translation task has been released by IWSLT, this paper explores previous solutions for other speech translation tasks, focusing primarily on low-resource scenarios. Moreover, we present our method of fine-tuning XLS-R models for Maltese ASR using a collection of multi-lingual speech corpora as well as the fine-tuning of the mBART model for Maltese to English machine translation",
    "volume": "IWSLT",
    "checked": true,
    "id": "85beff07a265f04318f3196fccffdc52e072cc09",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.42": {
    "title": "NVIDIA NeMo Offline Speech Translation Systems for IWSLT 2023",
    "abstract": "This paper provides an overview of NVIDIA NeMo’s speech translation systems for the IWSLT 2023 Offline Speech Translation Task. This year, we focused on end-to-end system which capitalizes on pre-trained models and synthetic data to mitigate the problem of direct speech translation data scarcity. When trained on IWSLT 2022 constrained data, our best En->De end-to-end model achieves the average score of 31 BLEU on 7 test sets from IWSLT 2010-2020 which improves over our last year cascade (28.4) and end-to-end (25.7) submissions. When trained on IWSLT 2023 constrained data, the average score drops to 29.5 BLEU",
    "volume": "IWSLT",
    "checked": true,
    "id": "b2f73323c88de359f1ef5a767b1c19f44dd241a2",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.43": {
    "title": "SRI-B's Systems for IWSLT 2023 Dialectal and Low-resource Track: Marathi-Hindi Speech Translation",
    "abstract": "This paper describes the speech translation systems SRI-B developed for the IWSLT 2023 Evaluation Campaign Dialectal and Low-resource track: Marathi-Hindi Speech Translation. We propose systems for both the constrained (systems are trained only on the datasets provided by the organizers) and the unconstrained conditions (systems can be trained with any resource). For both the conditions, we build end-to-end speech translation networks comprising of a conformer encoder and a transformer decoder. Under both the conditions, we leverage Marathi Automatic Speech Recognition (ASR) data to pre-train the encoder and subsequently train the entire model on the speech translation data. Our results demonstrate that pre-training the encoder with ASR data is a key step in significantly improving the speech translation performance. We also show that conformer encoders are inherently superior to its transformer counterparts for speech translation tasks. Our primary submissions achieved a BLEU% score of 31.2 on the constrained condition and 32.4 on the unconstrained condition. We secured the top position in the constrained condition and second position in the unconstrained condition",
    "volume": "IWSLT",
    "checked": true,
    "id": "5c3c7cf456a04a3117c026686ccb26f11c76b60f",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.44": {
    "title": "BIT's System for Multilingual Track",
    "abstract": "This paper describes the system we submitted to the IWSLT 2023 multilingual speech translation track, with input being English speech and output being text in 10 target languages. Our system consists of CNN and Transformer, convolutional neural networks downsample speech features and extract local information, while transformer extract global features and output the final results. In our system, we use speech recognition tasks to pre-train encoder parameters, and then use speech translation corpus to train the multilingual speech translation model. We have also adopted other methods to optimize the model, such as data augmentation, model ensemble, etc. Our system can obtain satisfactory results on test sets of 10 languages in the MUST-C corpus",
    "volume": "IWSLT",
    "checked": true,
    "id": "10ada5277b321712579c6cb0d4eac22496225d97",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.45": {
    "title": "Matesub: The Translated Subtitling Tool at the IWSLT2023 Subtitling Task",
    "abstract": "This paper briefly describes Matesub, the subtitling tool Translated used to participate in the Subtitling shared task at IWSLT 2023. Matesub is a professional web-based tool that combines state-of-the-art AI with a WYSIWYG editor. The automatic generation of subtitles in Matesub is based on a cascade architecture, composed of ASR, text segmenter and MT neural models, which allows covering any pair from about 70 languages and their variants",
    "volume": "IWSLT",
    "checked": true,
    "id": "b7b38599f6fdfdb363735aadcabbe7ccfa1cdf9d",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.iwslt-1.46": {
    "title": "Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling",
    "abstract": "Generative Spoken Language Modeling research focuses on optimizing speech Language Models (LMs) using raw audio recordings without accessing any textual supervision. Such speech LMs usually operate over discrete units obtained from quantizing internal representations of self-supervised models. Although such units show impressive modeling results, their robustness capabilities have not been extensively investigated. This work focuses on improving the robustness of discrete input representations for generative spoken language modeling. First, we formally define how to measure the robustness of such representations to various signal variations that do not alter the spoken information (e.g., time-stretch). Next, we empirically demonstrate how current state-of-the-art representation models lack robustness to such variations. To overcome this, we propose an effective and efficient method to learn robust discrete speech representation for generative spoken language modeling. The proposed approach is based on applying a set of signal transformations to the speech signal and optimizing the model using an iterative pseudo-labeling scheme. Our method significantly improves over the evaluated baselines when considering encoding and modeling metrics. We additionally evaluate our method on the speech-to-speech translation task, considering Spanish-English and French-English translations, and show the proposed approach outperforms the evaluated baselines",
    "volume": "IWSLT",
    "checked": true,
    "id": "9ff4885331c90468f633a637bb5ab75c9474efb4",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.iwslt-1.47": {
    "title": "DePA: Improving Non-autoregressive Translation with Dependency-Aware Decoder",
    "abstract": "Non-autoregressive machine translation (NAT) models have lower translation quality than autoregressive translation (AT) models because NAT decoders do not depend on previous target tokens in the decoder input. We propose a novel and general Dependency-Aware Decoder (DePA) to enhance target dependency modeling in the decoder of fully NAT models from two perspectives: decoder self-attention and decoder input. First, we propose an autoregressive forward-backward pre-training phase before NAT training, which enables the NAT decoder to gradually learn bidirectional target dependencies for the final NAT training. Second, we transform the decoder input from the source language representation space to the target language representation space through a novel attentive transformation process, which enables the decoder to better capture target dependencies. DePA can be applied to any fully NAT models. Extensive experiments show that DePA consistently improves highly competitive and state-of-the-art fully NAT models on widely used WMT and IWSLT benchmarks by up to 1.88 BLEU gain, while maintaining the inference latency comparable to other fully NAT models",
    "volume": "IWSLT",
    "checked": true,
    "id": "d98bfe7181fa81602e0c414202639fa2ebb81d80",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.iwslt-1.48": {
    "title": "On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss",
    "abstract": "Although unsupervised neural machine translation (UNMT) has achieved success in many language pairs, the copying problem, i.e., directly copying some parts of the input sentence as the translation, is common among distant language pairs, especially when low-resource languages are involved. We find this issue is closely related to an unexpected copying behavior during online back-translation (BT). In this work, we propose a simple but effective training schedule that incorporates a language discriminator loss. The loss imposes constraints on the intermediate translation so that the translation is in the desired language. By conducting extensive experiments on different language pairs, including similar and distant, high and low-resource languages, we find that our method alleviates the copying problem, thus improving the translation performance on low-resource languages",
    "volume": "IWSLT",
    "checked": true,
    "id": "5e1152cbf447cab9e868b05db4324600e73b60e2",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.semeval-1.1": {
    "title": "KnowComp at SemEval-2023 Task 7: Fine-tuning Pre-trained Language Models for Clinical Trial Entailment Identification",
    "abstract": "In this paper, we present our system for the textual entailment identification task as a subtask of the SemEval-2023 Task 7: Multi-evidence Natural Language Inference for Clinical Trial Data.The entailment identification task aims to determine whether a medical statement affirms a valid entailment given a clinical trial premise or forms a contradiction with it.Since the task is inherently a text classification task, we propose a system that performs binary classification given a statement and its associated clinical trial.Our proposed system leverages a human-defined prompt to aggregate the information contained in the statement, section name, and clinical trials.Pre-trained language models are then finetuned on the prompted input sentences to learn to discriminate the inference relation between the statement and clinical trial.To validate our system, we conduct extensive experiments with a wide variety of pre-trained language models.Our best system is built on DeBERTa-v3-large, which achieves an F1 score of 0.764 and secures the fifth rank in the official leaderboard.Further analysis indicates that leveraging our designed prompt is effective, and our model suffers from a low recall.Our code and pre-trained models are available at [https://github.com/HKUST-KnowComp/NLI4CT](https://github.com/HKUST-KnowComp/NLI4CT)",
    "volume": "SemEval",
    "checked": true,
    "id": "352bbd9950778530c5a6f7127a42ec361583a940",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.2": {
    "title": "lasigeBioTM at SemEval-2023 Task 7: Improving Natural Language Inference Baseline Systems with Domain Ontologies",
    "abstract": "Clinical Trials Reports (CTRs) contain highly valuable health information from which Natural Language Inference (NLI) techniques determine if a given hypothesis can be inferred from a given premise. CTRs are abundant with domain terminology with particular terms that are difficult to understand without prior knowledge. Thus, we proposed to use domain ontologies as a source of external knowledge that could help with the inference process in theSemEval-2023 Task 7: Multi-evidence Natural Language Inference for Clinical Trial Data (NLI4CT). This document describes our participation in subtask 1: Textual Entailment, where Ontologies, NLP techniques, such as tokenization and named-entity recognition, and rule-based approaches are all combined in our approach. We were able to show that inputting annotations from domain ontologies improved the baseline systems",
    "volume": "SemEval",
    "checked": true,
    "id": "567c84041fcfb909404986405bcf947c27daa2a4",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.3": {
    "title": "UoR-NCL at SemEval-2023 Task 1: Learning Word-Sense and Image Embeddings for Word Sense Disambiguation",
    "abstract": "In SemEval-2023 Task 1, a task of applying Word Sense Disambiguation in an image retrieval system was introduced. To resolve this task, this work proposes three approaches: (1) an unsupervised approach considering similarities between word senses and image captions, (2) a supervised approach using a Siamese neural network, and (3) a self-supervised approach using a Bayesian personalized ranking framework. According to the results, both supervised and self-supervised approaches outperformed the unsupervised approach. They can effectively identify correct images of ambiguous words in the dataset provided in this task",
    "volume": "SemEval",
    "checked": true,
    "id": "c0afcd0f1a56be518588a575df804efc233e00e0",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.4": {
    "title": "Lexicools at SemEval-2023 Task 10: Sexism Lexicon Construction via XAI",
    "abstract": "This paper presents our work on the SemEval-2023 Task 10 Explainable Detection of Online Sexism (EDOS) using lexicon-based models. Our approach consists of three main steps: lexicon construction based on Pointwise Mutual Information (PMI) and Shapley value, lexicon augmentation using an unannotated corpus and Large Language Models (LLMs), and, lastly, lexical incorporation for Bag-of-Word (BoW) logistic regression and fine-tuning LLMs. Our results demonstrate that our Shapley approach effectively produces a high-quality lexicon. We also show that by simply counting the presence of certain words in our lexicons and comparing the count can outperform a BoW logistic regression in task B/C and fine-tuning BERT in task C. In the end, our classifier achieved F1-scores of 53.34\\% and 27.31\\% on the official blind test sets for tasks B and C, respectively. We, additionally, provide in-depth analysis highlighting model limitation and bias. We also present our attempts to understand the model’s behaviour based on our constructed lexicons. Our code and the resulting lexicons are open-sourced in our GitHub repository https://github.com/SirBadr/SemEval2022-Task10",
    "volume": "SemEval",
    "checked": true,
    "id": "6645be27de1022db1a986d995724164d77dc9f95",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.semeval-1.5": {
    "title": "Augmenters at SemEval-2023 Task 1: Enhancing CLIP in Handling Compositionality and Ambiguity for Zero-Shot Visual WSD through Prompt Augmentation and Text-To-Image Diffusion",
    "abstract": "This paper describes our zero-shot approachesfor the Visual Word Sense Disambiguation(VWSD) Task in English. Our preliminarystudy shows that the simple approach of match-ing candidate images with the phrase usingCLIP suffers from the many-to-many natureof image-text pairs. We find that the CLIP textencoder may have limited abilities in captur-ing the compositionality in natural language.Conversely, the descriptive focus of the phrasevaries from instance to instance. We addressthese issues in our two systems, Augment-CLIPand Stable Diffusion Sampling (SD Sampling).Augment-CLIP augments the text prompt bygenerating sentences that contain the contextphrase with the help of large language mod-els (LLMs). We further explore CLIP modelsin other languages, as the an ambiguous wordmay be translated into an unambiguous one inthe other language. SD Sampling uses text-to-image Stable Diffusion to generate multipleimages from the given phrase, increasing thelikelihood that a subset of images match theone that paired with the text",
    "volume": "SemEval",
    "checked": true,
    "id": "5549b17694c194861a284c28a959615094f0e1bd",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.6": {
    "title": "HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource TweetData for Sentiment Analysis",
    "abstract": "We present the findings of SemEval-2023 Task 12, a shared task on sentiment analysis for low-resource African languages using Twitter dataset. The task featured three subtasks; subtask A is monolingual sentiment classification with 12 tracks which are all monolingual languages, subtask B is multilingual sentiment classification using the tracks in subtask A and subtask C is a zero-shot sentiment classification. We present the results and findings of subtask A, subtask B and subtask C. We also release the code on github. Our goal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large, AfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert), Multilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African languages. The datasets for these subtasks consists of a gold standard multi-class labeled Twitter datasets from these languages. Our results demonstrate that Afro-xlmr-large model performed better compared to the other models in most of the languages datasets. Similarly, Nigerian languages: Hausa, Igbo, and Yoruba achieved better performance compared to other languages and this can be attributed to the higher volume of data present in the languages",
    "volume": "SemEval",
    "checked": true,
    "id": "0a45d0cb2357de960765da3f6f0355a6a1bd4a88",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.7": {
    "title": "BERTastic at SemEval-2023 Task 3: Fine-Tuning Pretrained Multilingual Transformers Does Order Matter?",
    "abstract": "The naive approach for fine-tuning pretrained deep learning models on downstream tasks involves feeding them mini-batches of randomly sampled data. In this paper, we propose a more elaborate method for fine-tuning Pretrained Multilingual Transformers (PMTs) on multilingual data. Inspired by the success of curriculum learning approaches, we investigate the significance of fine-tuning PMTs on multilingual data in a sequential fashion language by language. Unlike the curriculum learning paradigm where the model is presented with increasingly complex examples, we do not adopt a notion of “easy” and “hard” samples. Instead, our experiments draw insight from psychological findings on how the human brain processes new information and the persistence of newly learned concepts. We perform our experiments on a challenging news-framing dataset that contains texts in six languages. Our proposed method outperforms the naïve approach by achieving improvements of 2.57\\% in terms of F1 score. Even when we supplement the naïve approach with recency fine-tuning, we still achieve an improvement of 1.34\\% with a 3.63\\%$ convergence speed-up. Moreover, we are the first to observe an interesting pattern in which deep learning models exhibit a human-like primacy-recency effect",
    "volume": "SemEval",
    "checked": true,
    "id": "208b091d2458d1ddef1e18d39f839fff7f992748",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.8": {
    "title": "Brooke-English at SemEval-2023 Task 5: Clickbait Spoiling",
    "abstract": "The task of clickbait spoiling is: generating a short text that satisfies the curiosity induced by a clickbait post. Clickbait links to a web page and advertises its contents by arousing curiosity instead of providing an informative summary. Previous studies on clickbait spoiling has shown the approach that classifing the type of spoilers is needed, then generating the appropriate spoilers is more effective on the Webis Clickbait Spoiling Corpus 2022 dataset. Our contribution focused on study of the three classes (phrase, passage and multi) and finding appropriate models to generate spoilers foreach class. Results were analysed in each type of spoilers, revealed some reasons of having diversed results in different spoiler types. “passage” type spoiler was identified as the most difficult and the most valuable type of spoiler",
    "volume": "SemEval",
    "checked": true,
    "id": "9096e710b928c9fe3e741a7a72299e859f0dc1f8",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.9": {
    "title": "Sea_and_Wine at SemEval-2023 Task 9: A Regression Model with Data Augmentation for Multilingual Intimacy Analysis",
    "abstract": "In Task 9, we are required to analyze the textual intimacy of tweets in 10 languages.We fine-tune XLM-RoBERTa (XLM-R) pre-trained model to adapt to this multilingual regression task. After tentative experiments, severe class imbalance is observed in the official released dataset, which may compromise the convergence and weaken the model effect. To tackle such challenge, we take measures in two aspects. On the one hand, we implement data augmentation through machine translation to enlarge the scale of classes with fewer samples. On the other hand, we introduce focal mean square error (MSE) loss to emphasize the contributions of hard samples to total loss, thus further mitigating the impact of class imbalance on model effect.Extensive experiments demonstrate remarkable effectiveness of our strategies, and our model achieves high performance on the Pearson’s correlation coefficient (CC) almost above 0.85 on validation dataset",
    "volume": "SemEval",
    "checked": true,
    "id": "40d928593ed8d087e57e601b0904a5853f474edf",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.10": {
    "title": "MarsEclipse at SemEval-2023 Task 3: Multi-lingual and Multi-label Framing Detection with Contrastive Learning",
    "abstract": "This paper describes our system for SemEval-2023 Task 3 Subtask 2 on Framing Detection. We used a multi-label contrastive loss for fine-tuning large pre-trained language models in a multi-lingual setting, achieving very competitive results: our system was ranked first on the official test set and on the official shared task leaderboard for five of the six languages for which we had training data and for which we could perform fine-tuning. Here, we describe our experimental setup, as well as various ablation studies. The code of our system is available at https://github.com/QishengL/SemEval2023",
    "volume": "SemEval",
    "checked": true,
    "id": "d803acc220c0b178fb5188cfe8f696d984f3b5a2",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.semeval-1.11": {
    "title": "Mr-Fosdick at SemEval-2023 Task 5: Comparing Dataset Expansion Techniques for Non-Transformer and Transformer Models: Improving Model Performance through Data Augmentation",
    "abstract": "In supervised learning, a significant amount of data is essential. To achieve this, we generated and evaluated datasets based on a provided dataset using transformer and non-transformer models. By utilizing these generated datasets during the training of new models, we attain a higher balanced accuracy during validation compared to using only the original dataset",
    "volume": "SemEval",
    "checked": true,
    "id": "3ae90543962fac3c37556812f59e3728384ff193",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.12": {
    "title": "SafeWebUH at SemEval-2023 Task 11: Learning Annotator Disagreement in Derogatory Text: Comparison of Direct Training vs Aggregation",
    "abstract": "Subjectivity and difference of opinion are key social phenomena, and it is crucial to take these into account in the annotation and detection process of derogatory textual content. In this paper, we use four datasets provided by SemEval-2023 Task 11 and fine-tune a BERT model to capture the disagreement in the annotation. We find individual annotator modeling and aggregation lowers the Cross-Entropy score by an average of 0.21, compared to the direct training on the soft labels. Our findings further demonstrate that annotator metadata contributes to the average 0.029 reduction in the Cross-Entropy score",
    "volume": "SemEval",
    "checked": true,
    "id": "e7ec9bc4efc5e916bbbc74c24bb73be9aa2515de",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.13": {
    "title": "ECNU_MIV at SemEval-2023 Task 1: CTIM - Contrastive Text-Image Model for Multilingual Visual Word Sense Disambiguation",
    "abstract": "Our team focuses on the multimodal domain of images and texts, we propose a model that can learn the matching relationship between text-image pairs by contrastive learning. More specifically, We train the model from the labeled data provided by the official organizer, after pre-training, texts are used to reference learned visual concepts enabling visual word sense disambiguation tasks. In addition, the top results our teams get have been released showing the effectiveness of our solution",
    "volume": "SemEval",
    "checked": true,
    "id": "66a57b6d57074885b7fd8e422e5a2e666a94fd81",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.14": {
    "title": "MELODI at SemEval-2023 Task 3: In-domain Pre-training for Low-resource Classification of News Articles",
    "abstract": "This paper describes our approach to Subtask 1 “News Genre Categorization” of SemEval-2023 Task 3 “Detecting the Category, the Framing, and the Persuasion Techniques in Online News in a Multi-lingual Setup”, which aims to determine whether a given news article is an opinion piece, an objective report, or satirical. We fine-tuned the domain-specific language model POLITICS, which was pre-trained on a large-scale dataset of more than 3.6M English political news articles following ideology-driven pre-training objectives. In order to use it in the multilingual setup of the task, we added as a pre-processing step the translation of all documents into English. Our system ranked among the top systems overall in most language, and ranked 1st on the English dataset",
    "volume": "SemEval",
    "checked": true,
    "id": "8639c93225673d8b8ab2effc95bdf40a6eea17a0",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.15": {
    "title": "Samsung Research China - Beijing at SemEval-2023 Task 2: An AL-R Model for Multilingual Complex Named Entity Recognition",
    "abstract": "This paper describes our system for SemEval-2023 Task 2 Multilingual Complex Named EntityRecognition (MultiCoNER II). Our teamSamsung Research China - Beijing proposesan AL-R (Adjustable Loss RoBERTa) model toboost the performance of recognizing short andcomplex entities with the challenges of longtaildata distribution, out of knowledge base andnoise scenarios. We first employ an adjustabledice loss optimization objective to overcomethe issue of long-tail data distribution, which isalso proved to be noise-robusted, especially incombatting the issue of fine-grained label confusing.Besides, we develop our own knowledgeenhancement tool to provide related contextsfor the short context setting and addressthe issue of out of knowledge base. Experimentshave verified the validation of our approaches",
    "volume": "SemEval",
    "checked": true,
    "id": "fc19f267a5a22ac5623908fb084db9fcb6bf5219",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.16": {
    "title": "NLP-LISAC at SemEval-2023 Task 9: Multilingual Tweet Intimacy Analysis via a Transformer-based Approach and Data Augmentation",
    "abstract": "This paper presents our system and findings for SemEval 2023 Task 9 Tweet Intimacy Analysis. The main objective of this task was to predict the intimacy of tweets in 10 languages. Our submitted model (ranked 28/45) consists of a transformer-based approach with data augmentation via machine translation",
    "volume": "SemEval",
    "checked": true,
    "id": "c313080d21dea0ab02fc92dcc4b7c44cbb4fcd36",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.semeval-1.17": {
    "title": "Bf3R at SemEval-2023 Task 7: a text similarity model for textual entailment and evidence retrieval in clinical trials and animal studies",
    "abstract": "We describe our participation on the Multi-evidence Natural Language Inference for Clinical Trial Data (NLI4CT) of SemEval’23. The organizers provided a collection of clinical trials as training data and a set of statements, which can be related to either a single trial or to a comparison of two trials. The task consisted of two sub-tasks: (i) textual entailment (Task 1) for predicting whether the statement is supported (Entailment) or not (Contradiction) by the corresponding trial(s); and (ii) evidence retrieval (Task 2) for selecting the evidences (sentences in the trials) that support the decision made for Task 1. We built a model based on a sentence-based BERT similarity model which was pre-trained on ClinicalBERT embeddings. Our best results on the official test sets were f-scores of 0.64 and 0.67 for Tasks 1 and 2, respectively",
    "volume": "SemEval",
    "checked": true,
    "id": "13731bd8d73e1a692b129c6879311c863c4d7f44",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.18": {
    "title": "University of Hildesheim at SemEval-2023 Task 1: Combining Pre-trained Multimodal and Generative Models for Image Disambiguation",
    "abstract": "Multimodal ambiguity is a challenge for understanding text and images. Large pre-trained models have reached a high level of quality already. This paper presents an implementation for solving a image disambiguation task relying solely on the knowledge captured in multimodal and language models. Within the task 1 of SemEval 2023 (Visual Word Sense Disambiguation), this approach managed to achieve an MRR of 0.738 using CLIP-Large and the OPT model for generating text. Applying a generative model to create more text given a phrase with an ambiguous word leads to an improvement of our results. The performance gain from a bigger language model is larger than the performance gain from using the lager CLIP model",
    "volume": "SemEval",
    "checked": true,
    "id": "a73e01f60741c84ca76929fb56ca424436a94037",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.19": {
    "title": "LRL_NC at SemEval-2023 Task 4: The Touche23-George-boole Approach for Multi-Label Classification of Human-Values behind Arguments",
    "abstract": "The task ValueEval aims at assigning a sub- set of possible human value categories under- lying a given argument. Values behind argu- ments are often determinants to evaluate the relevance and importance of decisions in eth- ical sense, thereby making them essential for argument mining. The work presented here proposes two systems for the same. Both sys- tems use RoBERTa to encode sentences in each document. System1 makes use of features ob- tained from training models for two auxiliary tasks, whereas System2 combines RoBERTa with topic modeling to get sentence represen- tation. These features are used by a classifi- cation head to generate predictions. System1 secured the rank 22 in the official task rank- ing, achieving the macro F1-score 0.46 on the main dataset. System2 was not a part of official evaluation. Subsequent experiments achieved highest (among the proposed systems) macro F1-scores of 0.48 (System2), 0.31 (ablation on System1) and 0.33 (ablation on System1) on the main dataset, the Nahj al-Balagha dataset, and the New York Times dataset",
    "volume": "SemEval",
    "checked": true,
    "id": "a53fde4cd0962c98eea53f7585762d1a48fd586c",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.20": {
    "title": "LRL_NC at SemEval-2023 Task 6: Sequential Sentence Classification for Legal Documents Using Topic Modeling Features",
    "abstract": "Natural Language Processing techniques can be leveraged to process legal proceedings for various downstream applications, such as sum- marization of a given judgement, prediction of the judgement for a given legal case, prece- dent search, among others. These applications will benefit from legal judgement documents already segmented into topically coherent units. The current task, namely, Rhetorical Role Pre- diction, aims at categorising each sentence in the sequence of sentences in a judgement document into different labels. The system proposed in this work combines topic mod- eling and RoBERTa to encode sentences in each document. A BiLSTM layer has been utilised to get contextualised sentence repre- sentations. The Rhetorical Role predictions for each sentence in each document are gen- erated by a final CRF layer of the proposed neuro-computing system. This system secured the rank 12 in the official task ranking, achiev- ing the micro-F1 score 0.7980. The code for the proposed systems has been made available at https://github.com/KushagriT/SemEval23_ LegalEval_TeamLRL_NC",
    "volume": "SemEval",
    "checked": true,
    "id": "2d3fe8d3877c78175120cc9f9737978edd5c06ce",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.21": {
    "title": "OPI at SemEval-2023 Task 9: A Simple But Effective Approach to Multilingual Tweet Intimacy Analysis",
    "abstract": "This paper describes our submission to the SemEval 2023 multilingual tweet intimacy analysis shared task. The goal of the task was to assess the level of intimacy of Twitter posts in ten languages. The proposed approach consists of several steps. First, we perform in-domain pre-training to create a language model adapted to Twitter data. In the next step, we train an ensemble of regression models to expand the training set with pseudo-labeled examples. The extended dataset is used to train the final solution. Our method was ranked first in five out of ten language subtasks, obtaining the highest average score across all languages",
    "volume": "SemEval",
    "checked": true,
    "id": "e3f457c2e7cce646264569ecf4b7b00c172040df",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.22": {
    "title": "OPI at SemEval-2023 Task 1: Image-Text Embeddings and Multimodal Information Retrieval for Visual Word Sense Disambiguation",
    "abstract": "The goal of visual word sense disambiguation is to find the image that best matches the provided description of the word’s meaning. It is a challenging problem, requiring approaches that combine language and image understanding. In this paper, we present our submission to SemEval 2023 visual word sense disambiguation shared task. The proposed system integrates multimodal embeddings, learning to rank methods, and knowledge-based approaches. We build a classifier based on the CLIP model, whose results are enriched with additional information retrieved from Wikipedia and lexical databases. Our solution was ranked third in the multilingual task and won in the Persian track, one of the three language subtasks",
    "volume": "SemEval",
    "checked": true,
    "id": "b658731eb0c3f276a746ba081c373510b742926c",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.23": {
    "title": "RGAT at SemEval-2023 Task 2: Named Entity Recognition Using Graph Attention Network",
    "abstract": "In this paper, we (team RGAT) describe our approach for the SemEval 2023 Task 2: Multilingual Complex Named Entity Recognition (MultiCoNER II). The goal of this task is to locate and classify named entities in unstructured short complex texts in 12 different languages and one multilingual setup. We use the dependency tree of the input query as additional feature in a Graph Attention Network along with the token and part-of-speech features. We also experiment with additional layers like BiLSTM and Transformer in addition to the CRF layer. However, we have not included any external Knowledge base like Wikipedia to enrich our inputs. We evaluated our proposed approach on the English NER dataset that resulted in a clean-subset F1 of 61.29\\% and overall F1 of 56.91\\%. However, other approaches that used external knowledge base performed significantly better",
    "volume": "SemEval",
    "checked": true,
    "id": "4d78dca0b9cdd7bfc62d6811f663e560a0535f87",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.24": {
    "title": "eevvgg at SemEval-2023 Task 11: Offensive Language Classification with Rater-based Information",
    "abstract": "A standard majority-based approach to text classification is challenged with an individualised approach in the Semeval-2023 Task 11. Here, disagreements are treated as a useful source of information that could be utilised in the training pipeline. The team proposal makes use of partially disaggregated data and additional information about annotators provided by the organisers to train a BERT-based model for offensive text classification. The approach extends previous studies examining the impact of using raters’ demographic features on classification performance (Hovy, 2015) or training machine learning models on disaggregated data (Davani et al., 2022). The proposed approach was ranked 11 across all 4 datasets, scoring best for cases with a large pool of annotators (6th place in the MD-Agreement dataset) utilising features based on raters’ annotation behaviour",
    "volume": "SemEval",
    "checked": true,
    "id": "5048e2f1d6ce367cc179f5ded73e9423895d66b7",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.25": {
    "title": "HULAT at SemEval-2023 Task 9: Data Augmentation for Pre-trained Transformers Applied to Multilingual Tweet Intimacy Analysis",
    "abstract": "This paper describes our participation in SemEval-2023 Task 9, Intimacy Analysis of Multilingual Tweets. We fine-tune some of the most popular transformer models with the training dataset and synthetic data generated by different data augmentation techniques. During the development phase, our best results were obtained by using XLM-T. Data augmentation techniques provide a very slight improvement in the results. Our system ranked in the 27th position out of the 45 participating systems. Despite its modest results, our system shows promising results in languages such as Portuguese, English, and Dutch. All our code is available in the repository https://github.com/isegura/hulat_intimacy",
    "volume": "SemEval",
    "checked": true,
    "id": "eca7df2b71032ae5f18f848c8ef5b9a6257a5084",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.26": {
    "title": "HULAT at SemEval-2023 Task 10: Data Augmentation for Pre-trained Transformers Applied to the Detection of Sexism in Social Media",
    "abstract": "This paper describes our participation in SemEval-2023 Task 10, whose goal is the detection of sexism in social media. We explore some of the most popular transformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study different data augmentation techniques to increase the training dataset. During the development phase, our best results were obtained by using RoBERTa and data augmentation for tasks B and C. However, the use of synthetic data does not improve the results for task C. We participated in the three subtasks. Our approach still has much room for improvement, especially in the two fine-grained classifications. All our code is available in the repository https://github.com/isegura/hulat_edos",
    "volume": "SemEval",
    "checked": true,
    "id": "5f0a14c16a1f58dc8437f0824924323aae7a1575",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.semeval-1.27": {
    "title": "Lauri Ingman at SemEval-2023 Task 4: A Chain Classifier for Identifying Human Values behind Arguments",
    "abstract": "Identifying expressions of human values in textual data is a crucial albeit complicated challenge, not least because ethics are highly variable, often implicit, and transcend circumstance. Opinions, arguments, and the like are generally founded upon more than one guiding principle, which are not necessarily independent. As such, little is known about how to classify and predict moral undertones in natural language sequences. Here, we describe and present a solution to ValueEval, our shared contribution to SemEval 2023 Task 4. Our research design focuses on investigating chain classifier architectures with pretrained contextualized embeddings to detect 20 different human values in written arguments. We show that our best model substantially surpasses the classification performance of the baseline method established in prior work. We discuss limitations to our approach and outline promising directions for future work",
    "volume": "SemEval",
    "checked": true,
    "id": "2ae0e359922095dcfda60fbeb3f7cb0f2a924401",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.28": {
    "title": "NLP-LISAC at SemEval-2023 Task 12: Sentiment Analysis for Tweets expressed in African languages via Transformer-based Models",
    "abstract": "This paper presents our systems and findings for SemEval-2023 Task 12: AfriSenti-SemEval: Sentiment Analysis for Low-resource African Languages. The main objective of this task was to determine the polarity of a tweet (positive, negative, or neutral). Our submitted models (highest rank is 1 and lowest rank is 21 depending on the target Track) consist of various Transformer-based approaches",
    "volume": "SemEval",
    "checked": true,
    "id": "70c58f4250c261c5e0e2fe33e4d270d7756a3f1f",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.semeval-1.29": {
    "title": "StFX-NLP at SemEval-2023 Task 4: Unsupervised and Supervised Approaches to Detecting Human Values in Arguments",
    "abstract": "In this paper, we discuss our models applied to Task 4: Human Value Detection of SemEval 2023, which incorporated two different embedding techniques to interpret the data. Preliminary experiments were conducted to observe important word types. Subsequently, we explored an XGBoost model, an unsupervised learning model, and two Ensemble learning models were then explored. The best performing model, an ensemble model employing a soft voting technique, secured the 34th spot out of 39 teams, on a class imbalanced dataset. We explored the inclusion of different parts of the provided knowledge resource and found that considering only specific parts assisted our models",
    "volume": "SemEval",
    "checked": true,
    "id": "f1a07536ce7ec223bd1f64a595e33cbc028df3fc",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.30": {
    "title": "FII SMART at SemEval 2023 Task7: Multi-evidence Natural Language Inference for Clinical Trial Data",
    "abstract": "The “Multi-evidence Natural Language Inference forClinical Trial Data” task at SemEval 2023competition focuses on extracting essentialinformation on clinical trial data, by posing twosubtasks on textual entailment and evidence retrieval.In the context of SemEval, we present a comparisonbetween a method based on the BioBERT model anda CNN model. The task is based on a collection ofbreast cancer Clinical Trial Reports (CTRs),statements, explanations, and labels annotated bydomain expert annotators. We achieved F1 scores of0.69 for determining the inference relation(entailment vs contradiction) between CTR -statement pairs. The implementation of our system ismade available via Github - https://github.com/volosincu/FII_Smart__Semeval2023",
    "volume": "SemEval",
    "checked": true,
    "id": "3f8e45926e46b67083cd30b8b7fcada661d67391",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.31": {
    "title": "Epicurus at SemEval-2023 Task 4: Improving Prediction of Human Values behind Arguments by Leveraging Their Definitions",
    "abstract": "We describe our experiments for SemEval-2023 Task 4 on the identification of human values behind arguments (ValueEval). Because human values are subjective concepts which require precise definitions, we hypothesize that incorporating the definitions of human values (in the form of annotation instructions and validated survey items) during model training can yield better prediction performance. We explore this idea and show that our proposed models perform better than the challenge organizers’ baselines, with improvements in macro F1 scores of up to 18%",
    "volume": "SemEval",
    "checked": true,
    "id": "e14e283231d7ce026661b4459872dc77d38a6a55",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.32": {
    "title": "MaChAmp at SemEval-2023 tasks 2, 3, 4, 5, 7, 8, 9, 10, 11, and 12: On the Effectiveness of Intermediate Training on an Uncurated Collection of Datasets",
    "abstract": "To improve the ability of language models to handle Natural Language Processing(NLP) tasks and intermediate step of pre-training has recently beenintroduced. In this setup, one takes a pre-trained language model, trains it ona (set of) NLP dataset(s), and then finetunes it for a target task. It isknown that the selection of relevant transfer tasks is important, but recentlysome work has shown substantial performance gains by doing intermediatetraining on a very large set of datasets. Most previous work uses generativelanguage models or only focuses on one or a couple of tasks and uses acarefully curated setup. We compare intermediate training with one or manytasks in a setup where the choice of datasets is more arbitrary; we use allSemEval 2023 text-based tasks. We reach performance improvements for most taskswhen using intermediate training. Gains are higher when doing intermediatetraining on single tasks than all tasks if the right transfer taskis identified. Dataset smoothing and heterogeneous batching did not lead torobust gains in our setup",
    "volume": "SemEval",
    "checked": true,
    "id": "428035de9f3cdce1e9c52767f580a6d07c406a19",
    "citation_count": 6
  },
  "https://aclanthology.org/2023.semeval-1.33": {
    "title": "UBC-DLNLP at SemEval-2023 Task 12: Impact of Transfer Learning on African Sentiment Analysis",
    "abstract": "We describe our contribution to the SemEVAl 2023 AfriSenti-SemEval shared task, where we tackle the task of sentiment analysis in 14 different African languages. We develop both monolingual and multilingual models under a full supervised setting (subtasks A and B). We also develop models for the zero-shot setting (subtask C). Our approach involves experimenting with transfer learning using six language models, including further pretraining of some of these models as well as a final finetuning stage. Our best performing models achieve an F1-score of 70.36 on development data and an F1-score of 66.13 on test data. Unsurprisingly, our results demonstrate the effectiveness of transfer learning and finetuning techniques for sentiment analysis across multiple languages. Our approach can be applied to other sentiment analysis tasks in different languages and domains",
    "volume": "SemEval",
    "checked": true,
    "id": "cfcdcb006a9427fbac9bb979e4e40266d30f904a",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.34": {
    "title": "PAI at SemEval-2023 Task 4: A General Multi-label Classification System with Class-balanced Loss Function and Ensemble Module",
    "abstract": "The Human Value Detection shared task\\cite{kiesel:2023} aims to classify whether or not the argument draws on a set of 20 value categories, given a textual argument. This is a difficult task as the discrimination of human values behind arguments is often implicit. Moreover, the number of label categories can be up to 20 and the distribution of data is highly imbalanced. To address these issues, we employ a multi-label classification model and utilize a class-balanced loss function. Our system wins 5 first places, 2 second places, and 6 third places out of 20 categories of the Human Value Detection shared task, and our overall average score of 0.54 also places third. The code is publicly available at \\url{https://www.github.com/diqiuzhuanzhuan/semeval2023}",
    "volume": "SemEval",
    "checked": true,
    "id": "af2ac5ca00baa22f595eed4190f31e29bd8bcf23",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.semeval-1.35": {
    "title": "TüReuth Legal at SemEval-2023 Task 6: Modelling Local and Global Structure of Judgements for Rhetorical Role Prediction",
    "abstract": "This paper describes our system for SemEval-2023 Task 6: LegalEval: Understanding Legal Texts. We only participate in Sub-Task (A), Predicting Rhetorical Roles. Our final submission achieves 73.35 test set F1 score, ranking 17th of 27 participants. The proposed method combines global and local models of label distributions and transitions between labels. Through our analyses, we show that especially modelling the temporal distribution of labels contributes positively to performance",
    "volume": "SemEval",
    "checked": true,
    "id": "62f50d8c329dffbe9b1955d1b555fbc1893aaf1f",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.36": {
    "title": "nclu_team at SemEval-2023 Task 6: Attention-based Approaches for Large Court Judgement Prediction with Explanation",
    "abstract": "Legal documents tend to be large in size. In this paper, we provide an experiment with attention-based approaches complemented by certain document processing techniques for judgment prediction. For the prediction of explanation, we consider this as an extractive text summarization problem based on an output of (1) CNN with attention mechanism and (2) self-attention of language models. Our extensive experiments show that treating document endings at first results in a 2.1% improvement in judgment prediction across all the models. Additional content peeling from non-informative sentences allows an improvement of explanation prediction performance by 4% in the case of attention-based CNN models. The best submissions achieved 8’th and 3’rd ranks on judgment prediction (C1) and prediction with explanation (C2) tasks respectively among 11 participating teams. The results of our experiments are published",
    "volume": "SemEval",
    "checked": true,
    "id": "b34e25257f671989d4c946e4554b944e004a11eb",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.37": {
    "title": "TeamUnibo at SemEval-2023 Task 6: A transformer based approach to Rhetorical Roles prediction and NER in Legal Texts",
    "abstract": "This study aims to tackle some challenges posed by legal texts in the field of NLP. The LegalEval challenge proposes three tasks, based on Indial Legal documents: Rhetorical Roles Prediction, Legal Named Entity Recognition, and Court Judgement Prediction with Explanation. Our work focuses on the first two tasks. For the first task we present a context-aware approach to enhance sentence information. With the help of this approach, the classification model utilizing InLegalBert as a transformer achieved 81.12% Micro-F1. For the second task we present a NER approach to extract and classify entities like names of petitioner, respondent, court or statute of a given document. The model utilizing XLNet as transformer and a dependency parser on top achieved 87.43% Macro-F1",
    "volume": "SemEval",
    "checked": true,
    "id": "e0ff0e687b4b9b69a3a0c4b06a630f3f9a86f053",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.38": {
    "title": "UMUTeam at SemEval-2023 Task 12: Ensemble Learning of LLMs applied to Sentiment Analysis for Low-resource African Languages",
    "abstract": "These working notes summarize the participation of the UMUTeam in the SemEval 2023 shared task: AfriSenti, focused on Sentiment Analysis in several African languages. Two subtasks are proposed, one in which each language is considered separately and another one in which all languages are merged. Our proposal to solve both subtasks is grounded on the combination of features extracted from several multilingual Large Language Models and a subset of language-independent linguistic features. Our best results are achieved with the African languages less represented in the training set: Xitsonga, a Mozambique dialect, with a weighted f1-score of 54.89\\%; Algerian Arabic, with a weighted f1-score of 68.52\\%; Swahili, with a weighted f1-score of 60.52\\%; and Twi, with a weighted f1-score of 71.14%",
    "volume": "SemEval",
    "checked": true,
    "id": "301da90258806ad8fac24541d50e11d0ca97ecf0",
    "citation_count": 2
  },
  "https://aclanthology.org/2023.semeval-1.39": {
    "title": "UMUTeam and SINAI at SemEval-2023 Task 9: Multilingual Tweet Intimacy Analysis using Multilingual Large Language Models and Data Augmentation",
    "abstract": "This work presents the participation of the UMUTeam and the SINAI research groups in the SemEval-2023 Task 9: Multilingual Tweet Intimacy Analysis. The goal of this task is to predict the intimacy of a set of tweets in 10 languages: English, Spanish, Italian, Portuguese, French, Chinese, Hindi, Arabic, Dutch and Korean, of which, the last 4 are not in the training data. Our approach to address this task is based on data augmentation and the use of three multilingual Large Language Models (multilingual BERT, XLM and mDeBERTA) by ensemble learning. Our team ranked 30th out of 45 participants. Our best results were achieved with two unseen languages: Korean (16th) and Hindi (19th)",
    "volume": "SemEval",
    "checked": true,
    "id": "04097ed8a31952c6a6542b3a12e6681eec4515d5",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.semeval-1.40": {
    "title": "Team QUST at SemEval-2023 Task 3: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting Online News Genre, Framing and Persuasion Techniques",
    "abstract": "This paper describes the participation of team QUST in the SemEval2023 task3. The monolingual models are first evaluated with the under-sampling of the majority classes in the early stage of the task. Then, the pre-trained multilingual model is fine-tuned with a combination of the class weights and the sample weights. Two different fine-tuning strategies, the task-agnostic and the task-dependent, are further investigated. All experiments are conducted under the 10-fold cross-validation, the multilingual approaches are superior to the monolingual ones. The submitted system achieves the second best in Italian and Spanish (zero-shot) in subtask-1",
    "volume": "SemEval",
    "checked": true,
    "id": "835258930b435fabc7a396adf422a1209b2bbb24",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.41": {
    "title": "niceNLP at SemEval-2023 Task 10: Dual Model Alternate Pseudo-labeling Improves Your Predictions",
    "abstract": "Sexism is a growing online problem. It harms women who are targeted and makes online spaces inaccessible and unwelcoming. In this paper, we present our approach for Task A of SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS), which aims to perform binary sexism detection on textual content. To solve this task, we fine-tune the pre-trained model based on several popular natural language processing methods to improve the generalization ability in the face of different data. According to the experimental results, the effective combination of multiple methods enables our approach to achieve excellent performance gains",
    "volume": "SemEval",
    "checked": true,
    "id": "2255a6584e586387b5962c71faf695a3ae71e21d",
    "citation_count": 0
  },
  "https://aclanthology.org/2023.semeval-1.42": {
    "title": "NCUEE-NLP at SemEval-2023 Task 8: Identifying Medical Causal Claims and Extracting PIO Frames Using the Transformer Models",
    "abstract": "This study describes the model design of the NCUEE-NLP system for the SemEval-2023 Task 8. We use the pre-trained transformer models and fine-tune the task datasets to identify medical causal claims and extract population, intervention, and outcome elements in a Reddit post when a claim is given. Our best system submission for the causal claim identification subtask achieved a F1-score of 70.15%. Our best submission for the PIO frame extraction subtask achieved F1-scores of 37.78% for Population class, 43.58% for Intervention class, and 30.67% for Outcome class, resulting in a macro-averaging F1-score of 37.34%. Our system evaluation results ranked second position among all participating teams",
    "volume": "SemEval",
    "checked": true,
    "id": "5fc0bd49856a7a32ce468724d6a87ac3425c2814",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.43": {
    "title": "Zhegu at SemEval-2023 Task 9: Exponential Penalty Mean Squared Loss for Multilingual Tweet Intimacy Analysis",
    "abstract": "We present the system description of our team Zhegu in SemEval-2023 Task 9 Multilingual Tweet Intimacy Analysis. We propose \\textbf{EPM} (\\textbf{E}xponential \\textbf{P}enalty \\textbf{M}ean Squared Loss) for the purpose of enhancing the ability of learning difficult samples during the training process. Meanwhile, we also apply several methods (frozen Tuning \\&amp; contrastive learning based on Language) on the XLM-R multilingual language model for fine-tuning and model ensemble. The results in our experiments provide strong faithful evidence of the effectiveness of our methods. Eventually, we achieved a Pearson score of 0.567 on the test set",
    "volume": "SemEval",
    "checked": true,
    "id": "a0904fdef84b9397eb0e3e9075dc89aa20c0eff0",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.44": {
    "title": "ABCD Team at SemEval-2023 Task 12: An Ensemble Transformer-based System for African Sentiment Analysis",
    "abstract": "This paper describes the system of the ABCD team for three main tasks in the SemEval-2023 Task 12: AfriSenti-SemEval for Low-resource African Languages using Twitter Dataset. We focus on exploring the performance of ensemble architectures based on the soft voting technique and different pre-trained transformer-based language models. The experimental results show that our system has achieved competitive performance in some Tracks in Task A: Monolingual Sentiment Analysis, where we rank the Top 3, Top 2, and Top 4 for the Hause, Igbo and Moroccan languages. Besides, our model achieved competitive results and ranked $14ˆ{th}$ place in Task B (multilingual) setting and $14ˆ{th}$ and $8ˆ{th}$ place in Track 17 and Track 18 of Task C (zero-shot) setting",
    "volume": "SemEval",
    "checked": true,
    "id": "771902fe84430655fe426e1799ac0d444587925e",
    "citation_count": 1
  },
  "https://aclanthology.org/2023.semeval-1.45": {
    "title": "RIGA at SemEval-2023 Task 2: NER Enhanced with GPT-3",
    "abstract": "The following is a description of the RIGA team’s submissions for the English track of the SemEval-2023 Task 2: Multilingual Complex Named Entity Recognition (MultiCoNER) II. Our approach achieves 17% boost in results by utilizing pre-existing Large-scale Language Models (LLMs), such as GPT-3, to gather additional contexts. We then fine-tune a pre-trained neural network utilizing these contexts. The final step of our approach involves meticulous model and compute resource scaling, which results in improved performance. Our results placed us 12th out of 34 teams in terms of overall ranking and 7th in terms of the noisy subset ranking. The code for our method is available on GitHub (https://github.com/emukans/multiconer2-riga)",
    "volume": "SemEval",
    "checked": true,
    "id": "889a736ac167b5e465d0f0c83400244619efb566",
    "citation_count": 1
  }
}