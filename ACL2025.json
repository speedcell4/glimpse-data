{
  "https://aclanthology.org/2025.acl-long.1": {
    "title": "EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association",
    "volume": "long",
    "abstract": "Goal-oriented script planning, or the ability to devise coherent sequences of actions toward specific goals, is commonly employed by humans to plan for typical activities. In e-commerce, customers increasingly seek LLM-based assistants to generate scripts and recommend products at each step, thereby facilitating convenient and efficient shopping experiences. However, this capability remains underexplored due to several challenges, including the inability of LLMs to simultaneously conduct script planning and product retrieval, difficulties in matching products caused by semantic discrepancies between planned actions and search queries, and a lack of methods and benchmark data for evaluation. In this paper, we step forward by formally defining the task of E-commerce Script Planning (EcomScript) as three sequential subtasks. We propose a novel framework that enables the scalable generation of product-enriched scripts by associating products with each step based on the semantic similarity between the actions and their purchase intentions. By applying our framework to real-world e-commerce data, we construct the very first large-scale EcomScript dataset, EcomScriptBench, which includes 605,229 scripts sourced from 2.4 million products. Human annotations are then conducted to provide gold labels for a sampled subset, forming an evaluation benchmark. Extensive experiments reveal that current (L)LMs face significant challenges with EcomScript tasks, even after fine-tuning, while injecting product purchase intentions improves their performance",
    "checked": true,
    "id": "2ec9dce660b4e1b0125e148cfe64d989844a5910",
    "semantic_title": "ecomscriptbench: a multi-task benchmark for e-commerce script planning via step-wise intention-driven product association",
    "citation_count": 3,
    "authors": [
      "Weiqi Wang",
      "Limeng Cui",
      "Xin Liu",
      "Sreyashi Nag",
      "Wenju Xu",
      "Chen Luo",
      "Sheikh Muhammad Sarwar",
      "Yang Li",
      "Hansu Gu",
      "Hui Liu",
      "Changlong Yu",
      "Jiaxin Bai",
      "Yifan Gao",
      "Haiyang Zhang",
      "Qi He",
      "Shuiwang Ji",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.acl-long.2": {
    "title": "GraphNarrator: Generating Textual Explanations for Graph Neural Networks",
    "volume": "long",
    "abstract": "Graph representation learning has garnered significant attention due to its broad applications in various domains, such as recommendation systems and social network analysis. Despite advancements in graph learning methods, challenges still remain in explainability when graphs are associated with semantic features. In this paper, we present GraphNarrator, the first method designed to generate natural language explanations for Graph Neural Networks. GraphNarrator employs a generative language model that maps input-output pairs to explanations reflecting the model's decision-making process. To address the lack of ground truth explanations to train the model, we propose first generating pseudo-labels that capture the model's decisions from saliency-based explanations, then using Expert Iteration to iteratively train the pseudo-label generator based on training objectives on explanation quality. The high-quality pseudo-labels are finally utilized to train an end-to-end explanation generator model. Extensive experiments are conducted to demonstrate the effectiveness of GraphNarrator in producing faithful, concise, and human-preferred natural language explanations",
    "checked": true,
    "id": "2faaf795183358c80712492b9822d624e9b672c7",
    "semantic_title": "graphnarrator: generating textual explanations for graph neural networks",
    "citation_count": 1,
    "authors": [
      "Bo Pan",
      "Zhen Xiong",
      "Guanchen Wu",
      "Zheng Zhang",
      "Yifei Zhang",
      "Yuntong Hu",
      "Liang Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.3": {
    "title": "M-RewardBench: Evaluating Reward Models in Multilingual Settings",
    "volume": "long",
    "abstract": "Reward models (RMs) have driven the state-of-the-art performance of LLMs today by enabling the integration of human feedback into the language modeling process. However, RMs are primarily trained and evaluated in English, and their capabilities in multilingual settings remain largely understudied. In this work, we conduct a systematic evaluation of several reward models in multilingual settings. We first construct the first-of-its-kind multilingual RM evaluation benchmark, M-RewardBench, consisting of 2.87k preference instances for 23 typologically diverse languages, that tests the chat, safety, reasoning, and translation capabilities of RMs. We then rigorously evaluate a wide range of reward models on M-RewardBench, offering fresh insights into their performance across diverse languages. We identify a significant gap in RMs' performances between English and non-English languages and show that RM preferences can change substantially from one language to another. We also present several findings on how different multilingual aspects impact RM performance. Specifically, we show that the performance of RMs is improved with improved translation quality. Similarly, we demonstrate that the models exhibit better performance for high-resource languages. We release M-RewardBench dataset and the codebase in this study to facilitate a better understanding of RM evaluation in multilingual settings",
    "checked": true,
    "id": "7b4c8f700f9c79cfa63c0bd7b133c58dae0c0894",
    "semantic_title": "m-rewardbench: evaluating reward models in multilingual settings",
    "citation_count": 24,
    "authors": [
      "Srishti Gureja",
      "Lester James Validad Miranda",
      "Shayekh Bin Islam",
      "Rishabh Maheshwary",
      "Drishti Sharma",
      "Gusti Triandi Winata",
      "Nathan Lambert",
      "Sebastian Ruder",
      "Sara Hooker",
      "Marzieh Fadaee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.4": {
    "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming",
    "volume": "long",
    "abstract": "While recent research increasingly emphasizes the value of human-LLM collaboration in competitive programming and proposes numerous empirical methods, a comprehensive understanding remains elusive due to the fragmented nature of existing studies and their use of diverse, application-specific human feedback. Thus, our work serves a three-fold purpose: First, we present the first taxonomy of human feedback consolidating the entire programming process, which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a novel programming dataset specifically designed for human-LLM collaboration, meticulously annotated to enable large-scale simulated human feedback and facilitate cost-effective real human interaction studies. Third, we introduce ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM competitive programming. With ELABORATION, we pinpoint strengthes and weaknesses of existing methods, thereby setting the foundation for furture improvement. Our dataset and code will be openly released",
    "checked": true,
    "id": "c10c8bcab9a77cc34283e80c8e724ef3cc454bb1",
    "semantic_title": "elaboration: a comprehensive benchmark on human-llm competitive programming",
    "citation_count": 0,
    "authors": [
      "Xinwei Yang",
      "Zhaofeng Liu",
      "Chen Huang",
      "Jiashuai Zhang",
      "Tong Zhang",
      "Yifan Zhang",
      "Wenqiang Lei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.5": {
    "title": "The Impossibility of Fair LLMs",
    "volume": "long",
    "abstract": "The rise of general-purpose artificial intelligence (AI) systems, particularly large language models (LLMs), has raised pressing moral questions about how to reduce bias and ensure fairness at scale. Researchers have documented a sort of \"bias\" in the significant correlations between demographics (e.g., race, gender) in LLM prompts and responses, but it remains unclear how LLM fairness could be evaluated with more rigorous definitions, such as group fairness or fair representations. We analyze a variety of technical fairness frameworks and find inherent challenges in each that make the development of a fair LLM intractable. We show that each framework either does not logically extend to the general-purpose AI context or is infeasible in practice, primarily due to the large amounts of unstructured training data and the many potential combinations of human populations, use cases, and sensitive attributes. These inherent challenges would persist for general-purpose AI, including LLMs, even if empirical challenges, such as limited participatory input and limited measurement methods, were overcome. Nonetheless, fairness will remain an important type of model evaluation, and there are still promising research directions, particularly the development of standards for the responsibility of LLM developers, context-specific evaluations, and methods of iterative, participatory, and AI-assisted evaluation that could scale fairness across the diverse contexts of modern human-AI interaction",
    "checked": true,
    "id": "6e22d4b3070a9efa61b842cc530e6622b656b18a",
    "semantic_title": "the impossibility of fair llms",
    "citation_count": 14,
    "authors": [
      "Jacy Reese Anthis",
      "Kristian Lum",
      "Michael Ekstrand",
      "Avi Feller",
      "Chenhao Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.6": {
    "title": "Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process",
    "volume": "long",
    "abstract": "Supervised Fine-Tuning (SFT) and Preference Optimization (PO) are key processes for aligning Language Models (LMs) with human preferences post pre-training. While SFT excels in efficiency and PO in effectiveness, they are often combined sequentially without integrating their optimization objectives. This approach ignores the opportunities to bridge their paradigm gap and take the strengths from both. In this paper, we interpret SFT and PO with two sub-processes — *Preference Estimation* and *Transition Optimization* — defined at token level within the Markov Decision Process (MDP). This modeling shows that SFT is only a special case of PO with inferior estimation and optimization. PO estimates the model's preference by its entire generation, while SFT only scores model's subsequent predicted tokens based on prior tokens from ground truth answer. These priors deviates from model's distribution, hindering the preference estimation and transition optimization. Building on this view, we introduce **Intuitive Fine-Tuning (IFT)** to integrate SFT and PO into a single process. Through a temporal residual connection, IFT brings better estimation and optimization by capturing LMs' intuitive sense of its entire answers. But it solely relies on a single policy and the same volume of non-preference-labeled data as SFT. Our experiments show that IFT performs comparably or even superiorly to SFT and some typical PO methods across several tasks, particularly those requires generation, reasoning, and fact-following abilities. An explainable Frozen Lake game further validates the effectiveness of IFT for getting competitive policy",
    "checked": true,
    "id": "2052a297586451686bbf959c47254cc3db13abab",
    "semantic_title": "intuitive fine-tuning: towards simplifying alignment into a single process",
    "citation_count": 5,
    "authors": [
      "Ermo Hua",
      "Biqing Qi",
      "Kaiyan Zhang",
      "Kai Tian",
      "Xingtai Lv",
      "Ning Ding",
      "Bowen Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.7": {
    "title": "Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation",
    "volume": "long",
    "abstract": "Standard bias benchmarks used for large language models (LLMs) measure the association between social attributes in model inputs and single-word model outputs. We test whether these benchmarks are robust to lengthening the model outputs via a more realistic user prompt, in the commonly studied domain of gender-occupation bias, as a step towards measuring Realistic Use and Tangible Effects (i.e., RUTEd evaluations). From the current literature, we adapt three standard metrics of next-word prediction (neutrality, skew, and stereotype), and we develop analogous RUTEd evaluations in three contexts of real-world LLM use: children's bedtime stories, user personas, and English language learning exercises. We find that standard bias metrics have no significant correlation with long-form output metrics. For example, selecting the least biased model based on the standard \"trick tests\" coincides with selecting the least biased model based on longer output no more than random chance. There may not yet be evidence to justify standard benchmarks as reliable proxies of real-world biases, and we encourage further development of context-specific RUTEd evaluations",
    "checked": false,
    "id": "566892d844b6c474aed5c27672a788f2ed1bd741",
    "semantic_title": "bias in language models: beyond trick tests and toward ruted evaluation",
    "citation_count": 17,
    "authors": [
      "Kristian Lum",
      "Jacy Reese Anthis",
      "Kevin Robinson",
      "Chirag Nagpal",
      "Alexander Nicholas D’Amour"
    ]
  },
  "https://aclanthology.org/2025.acl-long.8": {
    "title": "Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown exciting performance in listwise passage ranking. Due to the limited input length, existing methods often adopt the sliding window strategy. Such a strategy, though effective, is inefficient as it involves repetitive and serialized processing, which usually re-evaluates relevant passages multiple times. As a result, it incurs redundant API costs, which are proportional to the number of inference tokens. The development of long-context LLMs enables the full ranking of all passages within a single inference, avoiding redundant API costs. In this paper, we conduct a comprehensive study of long-context LLMs for ranking tasks in terms of efficiency and effectiveness. Surprisingly, our experiments reveal that full ranking with long-context LLMs can deliver superior performance in the supervised fine-tuning setting with a huge efficiency improvement. Furthermore, we identify two limitations of fine-tuning the full ranking model based on existing methods: (1) sliding window strategy fails to produce a full ranking list as a training label, and (2) the language modeling loss cannot emphasize top-ranked passage IDs in the label. To alleviate these issues, we propose a new complete listwise label construction approach and a novel importance-aware learning objective for full ranking. Experiments show the superior performance of our method over baselines",
    "checked": true,
    "id": "3f70254a70369b67e7777a751a6e0ded75d27432",
    "semantic_title": "sliding windows are not the end: exploring full ranking with long-context large language models",
    "citation_count": 2,
    "authors": [
      "Wenhan Liu",
      "Xinyu Ma",
      "Yutao Zhu",
      "Ziliang Zhao",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.9": {
    "title": "The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It",
    "volume": "long",
    "abstract": "This study investigates the integration of diverse patient data sources into multimodal language models for automated chest X-ray (CXR) report generation. Traditionally, CXR report generation relies solely on data from a patient's CXR exam, overlooking valuable information from patient electronic health records. Utilising the MIMIC-CXR and MIMIC-IV-ED datasets, we investigate the use of patient data from emergency department (ED) records — such as vital signs measured and medicines reconciled during an ED stay — for CXR report generation, with the aim of enhancing diagnostic accuracy. We also investigate conditioning CXR report generation on the clinical history section of radiology reports, which has been overlooked in the literature. We introduce a novel approach to transform these heterogeneous data sources into patient data embeddings that prompt a multimodal language model (CXRMate-ED). Our comprehensive evaluation indicates that using a broader set of patient data significantly enhances diagnostic accuracy. The model, training code, and dataset are publicly available",
    "checked": true,
    "id": "2fd9836f3848f8514875cdc0d4d7455737e32b22",
    "semantic_title": "the impact of auxiliary patient data on automated chest x-ray report generation and how to incorporate it",
    "citation_count": 1,
    "authors": [
      "Aaron Nicolson",
      "Shengyao Zhuang",
      "Jason Dowling",
      "Bevan Koopman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.10": {
    "title": "CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction",
    "volume": "long",
    "abstract": "The paper focuses on the interpretability of Grammatical Error Correction (GEC) evaluation metrics, which received little attention in previous studies. To bridge the gap, we introduce **CLEME2.0**, a reference-based metric describing four fundamental aspects of GEC systems: hit-correction, wrong-correction, under-correction, and over-correction. They collectively contribute to exposing critical qualities and locating drawbacks of GEC systems. Evaluating systems by combining these aspects also leads to superior human consistency over other reference-based and reference-less metrics. Extensive experiments on two human judgment datasets and six reference datasets demonstrate the effectiveness and robustness of our method, achieving a new state-of-the-art result. Our codes are released at https://github.com/THUKElab/CLEME",
    "checked": true,
    "id": "686fe73dc0f33ad9fe57be4cd35bc6b37dcd8082",
    "semantic_title": "cleme2.0: towards interpretable evaluation by disentangling edits for grammatical error correction",
    "citation_count": 0,
    "authors": [
      "Jingheng Ye",
      "Zishan Xu",
      "Yinghui Li",
      "Linlin Song",
      "Qingyu Zhou",
      "Hai-Tao Zheng",
      "Ying Shen",
      "Wenhao Jiang",
      "Hong-Gee Kim",
      "Ruitong Liu",
      "Xin Su",
      "Zifei Shan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.11": {
    "title": "StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in Structure-Rich Text",
    "volume": "long",
    "abstract": "The effective utilization of structured data, integral to corporate data strategies, has been challenged by the rise of large language models (LLMs) capable of processing unstructured information. This shift prompts the question: can LLMs interpret structured data directly in its unstructured form? We propose an automatic evaluation data generation method for assessing LLMs' reasoning capabilities on structure-rich text to explore this. Our approach supports 8 structured languages and 29 tasks, generating data with adjustable complexity through controllable nesting and structural width. We introduce StrucText-Eval, a benchmark containing 5,800 pre-generated and annotated samples designed to evaluate how well LLMs understand and reason through structured text. StrucText-Eval is divided into two suites: a regular Test suite (3,712 samples) and a Test-Hard suite (2,088 samples), the latter emphasizing the gap between human and model performance on more complex tasks. Experimental results show that while open-source LLMs achieve a maximum accuracy of 74.9% on the standard dataset, their performance drops significantly to 45.8% on the harder dataset. In contrast, human participants reach an accuracy of 92.6% on StrucText-Eval-Hard, highlighting LLMs' current limitations in handling intricate structural information",
    "checked": true,
    "id": "9c980b713cf92e612c7af42c067245710aaf994e",
    "semantic_title": "structext-eval: evaluating large language model's reasoning ability in structure-rich text",
    "citation_count": 3,
    "authors": [
      "Zhouhong Gu",
      "Haoning Ye",
      "Xingzhou Chen",
      "Zeyang Zhou",
      "Hongwei Feng",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.12": {
    "title": "Literature Meets Data: A Synergistic Approach to Hypothesis Generation",
    "volume": "long",
    "abstract": "AI holds promise for transforming scientific processes, including hypothesis generation. Prior work on hypothesis generation can be broadly categorized into theory-driven and data-driven approaches. While both have proven effective in generating novel and plausible hypotheses, it remains an open question whether they can complement each other. To address this, we develop the first method that combines literature-based insights with data to perform LLM-powered hypothesis generation. We apply our method on five different datasets and demonstrate that integrating literature and data outperforms other baselines (8.97% over few-shot, 15.75% over literature-based alone, and 3.37% over data-driven alone). Additionally, we conduct the first human evaluation to assess the utility of LLM-generated hypotheses in assisting human decision-making on two challenging tasks: deception detection and AI generated content detection. Our results show that human accuracy improves significantly by 7.44% and 14.19% on these tasks, respectively. These findings suggest that integrating literature-based and data-driven approaches provides a comprehensive and nuanced framework for hypothesis generation and could open new avenues for scientific inquiry",
    "checked": true,
    "id": "186a11b9010e79c1e8ce9768d9343b5cae449d0b",
    "semantic_title": "literature meets data: a synergistic approach to hypothesis generation",
    "citation_count": 9,
    "authors": [
      "Haokun Liu",
      "Yangqiaoyu Zhou",
      "Mingxuan Li",
      "Chenfei Yuan",
      "Chenhao Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.13": {
    "title": "GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization",
    "volume": "long",
    "abstract": "Recent advances in large language models have highlighted the critical need for precise control over model outputs through predefined constraints. While existing methods attempt to achieve this through either direct instruction-response synthesis or preferential response optimization, they often struggle with constraint understanding and adaptation. This limitation becomes particularly evident when handling fine-grained constraints, leading to either hallucination or brittle performance. We introduce Generative Adversarial Policy Optimization (GAPO), a novel framework that combines GAN-based training dynamics with an encoder-only reward model to progressively learn and adapt to increasingly complex constraints. GAPO leverages adversarial training to automatically generate training samples of varying difficulty while utilizing the encoder-only architecture to better capture prompt-response relationships. Extensive experiments demonstrate GAPO's superior performance across multiple benchmarks, particularly in scenarios requiring fine-grained constraint handling, where it significantly outperforms existing methods like PPO, DPO, and KTO. Our results suggest that GAPO's unique approach to preferential prompt learning offers a more robust and effective solution for controlling LLM outputs",
    "checked": true,
    "id": "c84cad456ad539fa2765cf39f41090d15f582a8c",
    "semantic_title": "gapo: learning preferential prompt through generative adversarial policy optimization",
    "citation_count": 1,
    "authors": [
      "Zhouhong Gu",
      "Xingzhou Chen",
      "Xiaoran Shi",
      "Tao Wang",
      "Suhang Zheng",
      "Tianyu Li",
      "Hongwei Feng",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.14": {
    "title": "Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models",
    "volume": "long",
    "abstract": "Data synthesis has become a crucial research area in large language models (LLMs), especially for generating high-quality instruction fine-tuning data to enhance downstream performance. In code generation, a key application of LLMs, manual annotation of code instruction data is costly. Recent methods, such as Code Evol-Instruct and OSS-Instruct, leverage LLMs to synthesize large-scale code instruction data, significantly improving LLM coding capabilities. However, these approaches face limitations due to unidirectional synthesis and randomness-driven generation, which restrict data quality and diversity. To overcome these challenges, we introduce Tree-of-Evolution (ToE), a novel framework that models code instruction synthesis process with a tree structure, exploring multiple evolutionary paths to alleviate the constraints of unidirectional generation. Additionally, we propose optimization-driven evolution, which refines each generation step based on the quality of the previous iteration. Experimental results across five widely-used coding benchmarks—HumanEval, MBPP, EvalPlus, LiveCodeBench, and BigCodeBench—demonstrate that base models fine-tuned on just 75k data synthesized by our method achieve comparable or superior performance to the state-of-the-art open-weight Code LLM, Qwen2.5-Coder-Instruct, which was fine-tuned on millions of samples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Luo",
      "Kaixin Li",
      "Hongzhan Lin",
      "Yuchen Tian",
      "Mohan Kankanhalli",
      "Jing Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.15": {
    "title": "Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models",
    "volume": "long",
    "abstract": "Despite the recent strides in large language models, studies have underscored the existence of social biases within these systems. In this paper, we delve into the validation and comparison of the ethical biases of LLMs concerning globally discussed and potentially sensitive topics, hypothesizing that these biases may arise from language-specific distinctions. Introducing the Multilingual Sensitive Questions & Answers Dataset (**MSQAD**), we collected news articles from Human Rights Watch covering 17 topics, and generated socially sensitive questions along with corresponding responses in multiple languages. We scrutinized the biases of these responses across languages and topics, employing two statistical hypothesis tests. The results showed that the null hypotheses were rejected in most cases, indicating biases arising from cross-language differences. It demonstrates that ethical biases in responses are widespread across various languages, and notably, these biases were prevalent even among different LLMs. By making the proposed MSQAD openly available, we aim to facilitate future research endeavors focused on examining cross-language biases in LLMs and their variant models",
    "checked": true,
    "id": "635ad6313a913b3004e1436a0f1427223ebcbb75",
    "semantic_title": "delving into multilingual ethical bias: the msqad with statistical hypothesis tests for large language models",
    "citation_count": 0,
    "authors": [
      "Seunguk Yu",
      "Juhwan Choi",
      "YoungBin Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.16": {
    "title": "ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision",
    "volume": "long",
    "abstract": "Multi-hop question answering (MHQA) involves reasoning across multiple documents to answer complex questions. Dense retrievers typically outperform sparse methods like BM25 by leveraging semantic embeddings in many tasks; however, they require labeled query-document pairs for fine-tuning, which poses a significant challenge in MHQA due to the complexity of the reasoning steps. To overcome this limitation, we introduce Retriever Supervision with Consistency and Relevance (ReSCORE), a novel method for training dense retrievers for MHQA without the need for labeled documents. ReSCORE leverages large language models to measure document-question relevance with answer consistency and utilizes this information to train a retriever within an iterative question-answering framework. Evaluated on three MHQA benchmarks, our extensive experiments demonstrate the effectiveness of ReSCORE, with significant improvements in retrieval performance that consequently lead to state-of-the-art Exact Match and F1 scores for MHQA",
    "checked": true,
    "id": "5b429de1c48dcf74d3ae6d29ae62f3eb9a4fb090",
    "semantic_title": "rescore: label-free iterative retriever training for multi-hop question answering with relevance-consistency supervision",
    "citation_count": 0,
    "authors": [
      "Dosung Lee",
      "Wonjun Oh",
      "Boyoung Kim",
      "Minyoung Kim",
      "Joonsuk Park",
      "Paul Hongsuck Seo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.17": {
    "title": "FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis",
    "checked": true,
    "id": "caee3a9d2cd6188efa77d9f55e37ecf3afa6175b",
    "semantic_title": "fact-audit: an adaptive multi-agent framework for dynamic fact-checking evaluation of large language models",
    "citation_count": 1,
    "authors": [
      "Hongzhan Lin",
      "Yang Deng",
      "Yuxuan Gu",
      "Wenxuan Zhang",
      "Jing Ma",
      "See-Kiong Ng",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.acl-long.18": {
    "title": "Statistical Deficiency for Task Inclusion Estimation",
    "volume": "long",
    "abstract": "Tasks are central in machine learning, as they are the most natural objects to assess the capabilities of current models. The trend is to build general models able to address any task. Even though transfer learning and multitask learning try to leverage the underlying task space, no well-founded tools are available to study its structure. This study proposes a theoretically grounded setup to define the notion of task and to compute the inclusion between two tasks from a statistical deficiency point of view. We propose a tractable proxy as information sufficiency to estimate the degree of inclusion between tasks, show its soundness on synthetic data, and use it to reconstruct empirically the classic NLP pipeline",
    "checked": true,
    "id": "7bb9f9adb9e70b56fb7c6c3b744f087ade28ed3b",
    "semantic_title": "statistical deficiency for task inclusion estimation",
    "citation_count": 0,
    "authors": [
      "Loïc Fosse",
      "Frederic Bechet",
      "Benoit Favre",
      "Géraldine Damnati",
      "Gwénolé Lecorvé",
      "Maxime Darrin",
      "Philippe Formont",
      "Pablo Piantanida"
    ]
  },
  "https://aclanthology.org/2025.acl-long.19": {
    "title": "Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients",
    "volume": "long",
    "abstract": "Federated fine-tuning for Large Language Models (LLMs) has recently gained attention due to the heavy communication overhead of transmitting large model updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its application in federated learning is complicated by discordance in aggregation. Existing methods addressing this discordance often suffer from performance degradation at low ranks in heterogeneous data settings. In response, we introduce LoRA-A^2 (Low Rank Adaptation with Alternating freeze and Adaptive rank selection), which demonstrates robustness in challenging settings with low ranks and high data heterogeneity. Our experimental findings reveal that LoRA-A^2 maintains performance even under extreme heterogeneity and low rank conditions, achieving up to a 99.8% reduction in uploaded parameters compared to full fine-tuning without compromising performance. This adaptive mechanism boosts robustness and communication efficiency in federated fine-tuning, enabling the practical deployment of LLMs in resource-constrained environments",
    "checked": true,
    "id": "5a946e6470e9aa7dfe34e1343a29186c3c9b05c9",
    "semantic_title": "towards robust and efficient federated low-rank adaptation with heterogeneous clients",
    "citation_count": 7,
    "authors": [
      "Jabin Koo",
      "Minwoo Jang",
      "Jungseul Ok"
    ]
  },
  "https://aclanthology.org/2025.acl-long.20": {
    "title": "LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs",
    "volume": "long",
    "abstract": "Detecting tricky bugs in plausible programs, those that pass existing test suites yet still contain bugs, remains a significant challenge in software testing. To address this problem, we propose TrickCatcher, an LLM-powered approach to generating test cases for uncovering bugs in plausible programs. TrickCatcher operates in three stages: First, it uses an LLM to generate program variants based on the program under test (PUT) and its specification. Second, it employs an LLM to construct an input generator from the specification for producing test inputs. Finally, these inputs are executed on both the PUT and its program variants to detect inconsistencies in their outputs. We evaluate TrickCatcher on two datasets, TrickyBugs and EvalPlus, which include 366 human-written and 151 AI-generated plausible programs with tricky bugs. TrickCatcher achieves recall, precision, and F1 scores that are 1.80×, 2.65×, and 1.66× those of the state-of-the-art baselines, respectively. Code and data used are available at https://github.com/RinCloud/TrickCatcher/",
    "checked": true,
    "id": "ad2f0e7d80360dbdeb7d084bcfd4754c281d807f",
    "semantic_title": "llm-powered test case generation for detecting bugs in plausible programs",
    "citation_count": 1,
    "authors": [
      "Kaibo Liu",
      "Zhenpeng Chen",
      "Yiyang Liu",
      "Jie M. Zhang",
      "Mark Harman",
      "Yudong Han",
      "Yun Ma",
      "Yihong Dong",
      "Ge Li",
      "Gang Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.21": {
    "title": "Capture the Key in Reasoning to Enhance CoT Distillation Generalization",
    "volume": "long",
    "abstract": "As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts (CoTs) reasoning abilities, practical resource constraints drive efforts to distill these capabilities into more compact Smaller Language Models (SLMs). We find that CoTs consist mainly of simple reasoning forms, with a small proportion (4.7%) of key reasoning steps that truly impact conclusions. However, previous distillation methods typically involve supervised fine-tuning student SLMs only on correct CoTs data produced by teacher LLMs, resulting in students struggling to learn the key, instead imitating the teacher's reasoning forms and making errors or omissions in reasoning. To address these issues, drawing an analogy to human learning, where analyzing mistakes according to correct solutions often reveals the crucial steps leading to successes or failures, we propose mistakE-Driven key reasonIng step distillaTion (EDIT), a novel method that further aids SLMs learning key reasoning steps rather than mere simple fine-tuning. Firstly, to expose the crucial steps in CoTs, we carefully design specific prompts to generate dual CoTs data with similar reasoning paths but divergent conclusions. Then, we apply the minimum edit distance algorithm on the dual CoTs data to locate these key steps and optimize the likelihood on these tokens. Extensive experiments and analysis validate the effectiveness of EDIT across both in-domain(IND) and out-of-domain(OOD) benchmark reasoning datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengwei Dai",
      "Kun Li",
      "Wei Zhou",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.22": {
    "title": "How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond",
    "volume": "long",
    "abstract": "With the advancement of large language models (LLMs), intelligent models have evolved from mere tools to autonomous agents with their own goals and strategies for cooperating with humans. This evolution has birthed a novel paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable progress in numerous NLP tasks in recent years. In this paper, we take the first step to present a thorough review of human-model cooperation, exploring its principles, formalizations, and open challenges. In particular, we introduce a new taxonomy that provides a unified perspective to summarize existing approaches. Also, we discuss potential frontier areas and their corresponding challenges. We regard our work as an entry point, paving the way for more breakthrough research in this regard",
    "checked": true,
    "id": "a00fb72b46aa9b273fee8a2a6471ba52bfc70904",
    "semantic_title": "how to enable effective cooperation between humans and nlp models: a survey of principles, formalizations, and beyond",
    "citation_count": 1,
    "authors": [
      "Chen Huang",
      "Yang Deng",
      "Wenqiang Lei",
      "Jiancheng Lv",
      "Tat-Seng Chua",
      "Jimmy Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.23": {
    "title": "Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge",
    "volume": "long",
    "abstract": "Text-based hyperbole and metaphor detection are of great significance for natural language processing (NLP) tasks. However, due to their semantic obscurity and expressive diversity, it is rather challenging to identify them. Existing methods mostly focus on superficial text features, ignoring the associations of hyperbole and metaphor as well as the effect of implicit emotion on perceiving these rhetorical devices. To implement these hypotheses, we propose an emotion-guided hyperbole and metaphor detection framework based on bidirectional dynamic interaction (EmoBi). Firstly, the emotion analysis module deeply mines the emotion connotations behind hyperbole and metaphor. Next, the emotion-based domain mapping module identifies the target and source domains to gain a deeper understanding of the implicit meanings of hyperbole and metaphor. Finally, the bidirectional dynamic interaction module enables the mutual promotion between hyperbole and metaphor. Meanwhile, a verification mechanism is designed to ensure detection accuracy and reliability. Experiments show that EmoBi outperforms all baseline methods on four datasets. Specifically, compared to the current SoTA, the F1 score increased by 28.1% for hyperbole detection on the TroFi dataset and 23.1% for metaphor detection on the HYPO-L dataset. These results, underpinned by in-depth analyses, underscore the effectiveness and potential of our approach for advancing hyperbole and metaphor detection",
    "checked": true,
    "id": "c6ea4031eb837c2b11336d10e105552d11d04648",
    "semantic_title": "enhancing hyperbole and metaphor detection with their bidirectional dynamic interaction and emotion knowledge",
    "citation_count": 0,
    "authors": [
      "Li Zheng",
      "Sihang Wang",
      "Hao Fei",
      "Zuquan Peng",
      "Fei Li",
      "Jianming Fu",
      "Chong Teng",
      "Donghong Ji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.24": {
    "title": "UniICL: An Efficient ICL Framework Unifying Compression, Selection, and Generation",
    "volume": "long",
    "abstract": "In-context learning (ICL) enhances the reasoning abilities of Large Language Models (LLMs) by prepending a few demonstrations. It motivates researchers to introduce more examples to provide additional contextual information for the generation. However, existing methods show a significant limitation due to the problem of excessive growth in context length which causes a large hardware burden. Additionally, shallow-relevant examples selected by out-off-shelf tools hinder LLMs from capturing useful contextual information for generation. In this paper, to approach these limitations, we propose UniICL, a novel Unified ICL framework that unifies demonstration compression, demonstration selection, and final response generation. Furthermore, to avoid repeated compression of the same demonstration and boost inference efficiency, we design a tailored compression strategy that allows UniICL caching compression results into Demonstration Bank(DB). Extensive out-of-domain evaluations prove the advantages of UniICL in both effectiveness and efficiency",
    "checked": false,
    "id": "c26627d02768ba1f78424f8b4fb81c0e4ffc11f4",
    "semantic_title": "uniicl: an efficient unified framework unifying compression, selection, and generation",
    "citation_count": 3,
    "authors": [
      "Jun Gao",
      "Qi Lv",
      "Zili Wang",
      "Tianxiang Wu",
      "Ziqiang Cao",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.25": {
    "title": "BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian",
    "volume": "long",
    "abstract": "In the epoch of multilingual large language models (LLMs), it is still challenging to evaluate the models' understanding of lower-resourced languages, which motivates further development of expert-crafted natural language understanding benchmarks. We introduce BelarusianGLUE — a natural language understanding benchmark for Belarusian, an East Slavic language, with ≈15K instances in five tasks: sentiment analysis, linguistic acceptability, word in context, Winograd schema challenge, textual entailment. A systematic evaluation of BERT models and LLMs against this novel benchmark reveals that both types of models approach human-level performance on easier tasks, such as sentiment analysis, but there is a significant gap in performance between machine and human on a harder task — Winograd schema challenge. We find the optimal choice of model type to be task-specific: e.g. BERT models underperform on textual entailment task but are competitive for linguistic acceptability. We release the datasets (https://hf.co/datasets/maaxap/BelarusianGLUE) and evaluation code (https://github.com/maaxap/BelarusianGLUE)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maksim Aparovich",
      "Volha Harytskaya",
      "Vladislav Poritski",
      "Oksana Volchek",
      "Pavel Smrz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.26": {
    "title": "A Survey on Foundation Language Models for Single-cell Biology",
    "volume": "long",
    "abstract": "The recent advancements in language models have significantly catalyzed progress in computational biology. A growing body of research strives to construct unified foundation models for single-cell biology, with language models serving as the cornerstone. In this paper, we systematically review the developments in foundation language models designed specifically for single-cell biology. Our survey offers a thorough analysis of various incarnations of single-cell foundation language models, viewed through the lens of both pre-trained language models (PLMs) and large language models (LLMs). This includes an exploration of data tokenization strategies, pre-training/tuning paradigms, and downstream single-cell data analysis tasks. Additionally, we discuss the current challenges faced by these pioneering works and speculate on future research directions. Overall, this survey provides a comprehensive overview of the existing single-cell foundation language models, paving the way for future research endeavors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Zhang",
      "Hao Chen",
      "Zhihong Zhu",
      "Ziheng Zhang",
      "Zhenxi Lin",
      "Ziyue Qiao",
      "Yefeng Zheng",
      "Xian Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.27": {
    "title": "RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios",
    "volume": "long",
    "abstract": "This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning. Covering three practical domains – airline baggage fees, NBA transactions, and tax regulations – RuleArena assesses LLMs' proficiency in handling intricate natural language instructions that demand long-context understanding, logical reasoning, and accurate mathematical computation. Two key attributes distinguish RuleArena from traditional rule-based reasoning benchmarks: (1) it extends beyond standard first-order logic representations, and (2) it is grounded in authentic, practical scenarios, providing insights into the suitability and reliability of LLMs for real-world applications. Our findings reveal several notable limitations in LLMs: (1) they struggle to identify and apply the appropriate rules, frequently becoming confused by similar but distinct regulations, (2) they cannot consistently perform accurate mathematical computations, even when they correctly identify the relevant rules, and (3) in general, they perform poorly in the benchmark. We also observe a significant performance boost when LLMs are provided with external tools for oracle math and logic operations. These results highlight significant challenges and promising research directions in advancing LLMs' rule-guided reasoning capabilities in real-life applications. Our codes and data are publicly available on https://github.com/skyriver-2000/rulearena",
    "checked": true,
    "id": "1a45658fbec0503cec2d6f1015aa39118249e904",
    "semantic_title": "rulearena: a benchmark for rule-guided reasoning with llms in real-world scenarios",
    "citation_count": 4,
    "authors": [
      "Ruiwen Zhou",
      "Wenyue Hua",
      "Liangming Pan",
      "Sitao Cheng",
      "Xiaobao Wu",
      "En Yu",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.28": {
    "title": "Extending LLM Context Window with Adaptive Grouped Positional Encoding: A Training-Free Method",
    "volume": "long",
    "abstract": "Processing long input remains a significant challenge for large language models (LLMs) due to the scarcity of large-scale long-context training data and the high computational cost of training models for extended context windows. In this paper, we propose **Ada**ptive **Gro**uped **P**ositional **E**ncoding (AdaGroPE), a training-free, plug-and-play method to enhance long-context understanding in existing LLMs. AdaGroPE progressively increases the reuse count of relative positions as the distance grows and dynamically adapts the positional encoding mapping to sequence length, thereby fully exploiting the range of pre-trained position embeddings. Its design is consistent with the principles of rotary position embedding (RoPE) and aligns with human perception of relative distance, enabling robust performance in real-world settings with variable-length inputs. Extensive experiments across various benchmarks demonstrate that our AdaGroPE consistently achieves state-of-the-art performance, surpassing baseline methods and even outperforming LLMs inherently designed for long-context processing on certain tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhao Xu",
      "Jiaxin Li",
      "Hui Chen",
      "Zijia Lin",
      "Jungong Han",
      "Guiguang Ding"
    ]
  },
  "https://aclanthology.org/2025.acl-long.29": {
    "title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models",
    "volume": "long",
    "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer from computational inefficiency and redundancy. First, they overlook the diversity of task difficulties, leading to unnecessarily extensive searches even for easy tasks. Second, they neglect the semantics of reasoning paths, resulting in redundant exploration of semantically identical paths. To address these limitations, we propose Semantic Exploration with Adaptive Gating (SEAG), a computationally efficient method. SEAG employs an adaptive gating mechanism that dynamically decides whether to conduct a tree search, based on the confidence level of answers from a preceding simple reasoning method. Furthermore, its tree-based exploration consolidates semantically identical reasoning steps, reducing redundant explorations while maintaining or even improving accuracy. Our extensive experiments demonstrate that SEAG significantly improves accuracy by 4.3% on average while requiring only 31% of computational costs compared to existing tree search-based methods on complex reasoning benchmarks including GSM8K and ARC with diverse language models such as Llama2, Llama3, and Mistral. Our code is available at https://github.com/ml-postech/SEAG-semantic-exploration-with-adaptive-gating",
    "checked": true,
    "id": "b4358b6ca45b74121cd7d3a9e1ea2ba99cbe3667",
    "semantic_title": "semantic exploration with adaptive gating for efficient problem solving with language models",
    "citation_count": 1,
    "authors": [
      "Sungjae Lee",
      "Hyejin Park",
      "Jaechang Kim",
      "Jungseul Ok"
    ]
  },
  "https://aclanthology.org/2025.acl-long.30": {
    "title": "HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval",
    "volume": "long",
    "abstract": "We present HotelMatch-LLM, a multimodal dense retrieval model for the travel domain that enables natural language property search, addressing the limitations of traditional travel search engines which require users to start with a destination and editing search parameters. HotelMatch-LLM features three key innovations: (1) Domain-specific multi-task optimization with three novel retrieval, visual, and language modeling objectives; (2) Asymmetrical dense retrieval architecture combining a small language model (SLM) for efficient online query processing and a large language model (LLM) for embedding hotel data; and (3) Extensive image processing to handle all property image galleries. Experiments on four diverse test sets show HotelMatch-LLM significantly outperforms state-of-the-art models, including VISTA and MARVEL. Specifically, on the test set—main query type—we achieve 0.681 for HotelMatch-LLM compared to 0.603 for the most effective baseline, MARVEL. Our analysis highlights the impact of our multi-task optimization, the generalizability of HotelMatch-LLM across LLM architectures, and its scalability for processing large image galleries",
    "checked": true,
    "id": "1e0108406ca7b4fa8b467aa5ecbde2a74c1ac0a2",
    "semantic_title": "hotelmatch-llm: joint multi-task training of small and large language models for efficient multimodal hotel retrieval",
    "citation_count": 0,
    "authors": [
      "Arian Askari",
      "Emmanouil Stergiadis",
      "Ilya Gusev",
      "Moran Beladev"
    ]
  },
  "https://aclanthology.org/2025.acl-long.31": {
    "title": "Can Multimodal Large Language Models Understand Spatial Relations?",
    "volume": "long",
    "abstract": "Spatial relation reasoning is a crucial task for multimodal large language models (MLLMs) to understand the objective world. However, current benchmarks have issues like relying on bounding boxes, ignoring perspective substitutions, or allowing questions to be answered using only the model's prior knowledge without image understanding. To address these issues, we introduce SpatialMQA, a human-annotated spatial relation reasoning benchmark based on COCO2017, which enables MLLMs to focus more on understanding images in the objective world. To ensure data quality, we design a well-tailored annotation procedure, resulting in SpatialMQA consisting of 5,392 samples. Based on this benchmark, a series of closed- and open-source MLLMs are implemented and the results indicate that the current state-of-the-art MLLM achieves only 48.14% accuracy, far below the human-level accuracy of 98.40%. Extensive experimental analyses are also conducted, suggesting the future research directions. The benchmark and codes are available at https://huggingface.co/datasets/liuziyan/SpatialMQA",
    "checked": true,
    "id": "78dfdc412030122e5bc456b5ca7d23f9bb7dd3a2",
    "semantic_title": "can multimodal large language models understand spatial relations?",
    "citation_count": 0,
    "authors": [
      "Jingping Liu",
      "Ziyan Liu",
      "Zhedong Cen",
      "Yan Zhou",
      "Yinan Zou",
      "Weiyan Zhang",
      "Haiyun Jiang",
      "Tong Ruan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.32": {
    "title": "S3 - Semantic Signal Separation",
    "volume": "long",
    "abstract": "Topic models are useful tools for discovering latent semantic structures in large textual corpora. Recent efforts have been oriented at incorporating contextual representations in topic modeling and have been shown to outperform classical topic models. These approaches are typically slow, volatile, and require heavy preprocessing for optimal results. We present Semantic Signal Separation (S3), a theory-driven topic modeling approach in neural embedding spaces. S3 conceptualizes topics as independent axes of semantic space and uncovers these by decomposing contextualized document embeddings using Independent Component Analysis. Our approach provides diverse and highly coherent topics, requires no preprocessing, and is demonstrated to be the fastest contextual topic model, being, on average, 4.5x faster than the runner-up BERTopic. We offer an implementation of S3, and all contextual baselines, in the Turftopic Python package",
    "checked": true,
    "id": "078b73136bda4b59e566bf338ed21c76bffa0439",
    "semantic_title": "s3 - semantic signal separation",
    "citation_count": 1,
    "authors": [
      "Márton Kardos",
      "Jan Kostkan",
      "Kenneth Enevoldsen",
      "Arnault-Quentin Vermillet",
      "Kristoffer Nielbo",
      "Roberta Rocca"
    ]
  },
  "https://aclanthology.org/2025.acl-long.33": {
    "title": "TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs",
    "volume": "long",
    "abstract": "Specializing large language models (LLMs) for local deployment in domain-specific use cases is necessary for strong performance while meeting latency and privacy constraints. However, conventional task-specific adaptation approaches do not show simultaneous memory saving and inference speedup at deployment time. Practical compression techniques like quantization and pruning require dedicated hardware or kernel support to achieve measured inference speedup. We develop TrimLLM based on the layer-wise specialization phenomenon we empirically observed and verified on contemporary LLMs. TrimLLM reduces the depth of LLMs via progressive layer dropping. We show it retains LLMs' capacity in specific domains and achieves inference speedup irrespective of hardware and deep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for inference; models adapted on medical, legal, and financial datasets all demonstrate 2.1 - 5.7× inference speedup on consumer GPUs and up to 3.1× speedup on A100 when compared to state-of-the-art model compression algorithms, with no loss in accuracy at 50∼ 60% model compression ratio",
    "checked": true,
    "id": "73c001565de2c7bc9a3b49202e6902493065ce21",
    "semantic_title": "trimllm: progressive layer dropping for domain-specific llms",
    "citation_count": 0,
    "authors": [
      "Lanxiang Hu",
      "Tajana Rosing",
      "Hao Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.34": {
    "title": "JuStRank: Benchmarking LLM Judges for System Ranking",
    "volume": "long",
    "abstract": "Given the rapid progress of generative AI, there is a pressing need to systematically compare and choose between the numerous models and configurations available. The scale and versatility of such evaluations make the use of LLM-based judges a compelling solution for this challenge. Crucially, this approach requires first to validate the quality of the LLM judge itself. Previous work has focused on instance-based assessment of LLM judges, where a judge is evaluated over a set of responses, or response pairs, while being agnostic to their source systems. We argue that this setting overlooks critical factors affecting system-level ranking, such as a judge's positive or negative bias towards certain systems. To address this gap, we conduct the first large-scale study of LLM judges as system rankers. System scores are generated by aggregating judgment scores over multiple system outputs, and the judge's quality is assessed by comparing the resulting system ranking to a human-based ranking. Beyond overall judge assessment, our analysis provides a fine-grained characterization of judge behavior, including their decisiveness and bias",
    "checked": true,
    "id": "c85e7a719c68b88ebae654b13196d248576e5910",
    "semantic_title": "justrank: benchmarking llm judges for system ranking",
    "citation_count": 5,
    "authors": [
      "Ariel Gera",
      "Odellia Boni",
      "Yotam Perlitz",
      "Roy Bar-Haim",
      "Lilach Eden",
      "Asaf Yehudai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.35": {
    "title": "Generating Diverse Training Samples for Relation Extraction with Large Language Models",
    "volume": "long",
    "abstract": "Using Large Language Models (LLMs) to generate training data can potentially be a preferable way to improve zero or few-shot NLP tasks. However, many problems remain to be investigated for this direction. For the task of Relation Extraction (RE), we find that samples generated by directly prompting LLMs may easily have high structural similarities with each other. They tend to use a limited variety of phrasing while expressing the relation between a pair of entities. Therefore, in this paper, we study how to effectively improve the diversity of the training samples generated with LLMs for RE, while also maintaining their correctness. We first try to make the LLMs produce dissimilar samples by directly giving instructions in In-Context Learning (ICL) prompts. Then, we propose an approach to fine-tune LLMs for diversity training sample generation through Direct Preference Optimization (DPO). Our experiments on commonly used RE datasets show that both attempts can improve the quality of the generated training data. We also find that comparing with directly performing RE with an LLM, training a non-LLM RE model with its generated samples may lead to better performance",
    "checked": true,
    "id": "e49f9440be361fe5a2873f6606f2b6902bf5e7f7",
    "semantic_title": "generating diverse training samples for relation extraction with large language models",
    "citation_count": 0,
    "authors": [
      "Zexuan Li",
      "Hongliang Dai",
      "Piji Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.36": {
    "title": "MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts",
    "volume": "long",
    "abstract": "Recent LLMs are able to generate high-quality multilingual texts, indistinguishable for humans from authentic human-written ones. Research in machine-generated text detection is however mostly focused on the English language and longer texts, such as news articles, scientific papers or student essays. Social-media texts are usually much shorter and often feature informal language, grammatical errors, or distinct linguistic items (e.g., emoticons, hashtags). There is a gap in studying the ability of existing methods in detection of such texts, reflected also in the lack of existing multilingual benchmark datasets. To fill this gap we propose the first multilingual (22 languages) and multi-platform (5 social media platforms) dataset for benchmarking machine-generated text detection in the social-media domain, called MultiSocial. It contains 472,097 texts, of which about 58k are human-written and approximately the same amount is generated by each of 7 multilingual LLMs. We use this benchmark to compare existing detection methods in zero-shot as well as fine-tuned form. Our results indicate that the fine-tuned detectors have no problem to be trained on social-media texts and that the platform selection for training matters",
    "checked": true,
    "id": "657efb4b79c2c1761d6ca99b961f7bedd66cd955",
    "semantic_title": "multisocial: multilingual benchmark of machine-generated text detection of social-media texts",
    "citation_count": 3,
    "authors": [
      "Dominik Macko",
      "Jakub Kopál",
      "Robert Moro",
      "Ivan Srba"
    ]
  },
  "https://aclanthology.org/2025.acl-long.37": {
    "title": "Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection",
    "volume": "long",
    "abstract": "Automatic prompt engineering aims to enhance the generation quality of large language models (LLMs). Recent works utilize feedbacks generated from erroneous cases to guide the prompt optimization. During inference, they may further retrieve several semantically-related exemplars and concatenate them to the optimized prompts to improve the performance. However, those works only utilize the feedback at the current step, ignoring historical and unseleccted feedbacks which are potentially beneficial. Moreover, the selection of exemplars only considers the general semantic relationship and may not be optimal in terms of task performance and matching with the optimized prompt. In this work, we propose an Exemplar-Guided Reflection with Memory mechanism (ERM) to realize more efficient and accurate prompt optimization. Specifically, we design an exemplar-guided reflection mechanism where the feedback generation is additionally guided by the generated exemplars. We further build two kinds of memory to fully utilize the historical feedback information and support more effective exemplar retrieval. Empirical evaluations show our method surpasses previous state-of-the-arts with less optimization steps, i.e., improving F1 score by 10.1 on LIAR dataset, and reducing half of the optimization steps on ProTeGi",
    "checked": true,
    "id": "0f555b9c72b7270d7c277246e0ad8a836cda7075",
    "semantic_title": "efficient and accurate prompt optimization: the benefit of memory in exemplar-guided reflection",
    "citation_count": 5,
    "authors": [
      "Cilin Yan",
      "Jingyun Wang",
      "Lin Zhang",
      "Ruihui Zhao",
      "Xiaopu Wu",
      "Kai Xiong",
      "Qingsong Liu",
      "Guoliang Kang",
      "Yangyang Kang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.38": {
    "title": "Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation",
    "volume": "long",
    "abstract": "The capabilities of recent large language models (LLMs) to generate high-quality content indistinguishable by humans from human-written texts raises many concerns regarding their misuse. Previous research has shown that LLMs can be effectively misused for generating disinformation news articles following predefined narratives. Their capabilities to generate personalized (in various aspects) content have also been evaluated and mostly found usable. However, a combination of personalization and disinformation abilities of LLMs has not been comprehensively studied yet. Such a dangerous combination should trigger integrated safety filters of the LLMs, if there are some. This study fills this gap by evaluating vulnerabilities of recent open and closed LLMs, and their willingness to generate personalized disinformation news articles in English. We further explore whether the LLMs can reliably meta-evaluate the personalization quality and whether the personalization affects the generated-texts detectability. Our results demonstrate the need for stronger safety-filters and disclaimers, as those are not properly functioning in most of the evaluated LLMs. Additionally, our study revealed that the personalization actually reduces the safety-filter activations; thus effectively functioning as a jailbreak. Such behavior must be urgently addressed by LLM developers and service providers",
    "checked": true,
    "id": "1071d2be74aaf5eae5d083925ce46f85cdb246dd",
    "semantic_title": "evaluation of llm vulnerabilities to being misused for personalized disinformation generation",
    "citation_count": 5,
    "authors": [
      "Aneta Zugecova",
      "Dominik Macko",
      "Ivan Srba",
      "Robert Moro",
      "Jakub Kopál",
      "Katarína Marcinčinová",
      "Matúš Mesarčík"
    ]
  },
  "https://aclanthology.org/2025.acl-long.39": {
    "title": "EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents",
    "volume": "long",
    "abstract": "Language model agents excel in long-session planning and reasoning, but existing benchmarks primarily focus on goal-oriented tasks with explicit objectives, neglecting creative adaptation in unfamiliar environments. To address this, we introduce EscapeBench—a benchmark suite of room escape game environments designed to challenge agents with creative reasoning, unconventional tool use, and iterative problem-solving to uncover implicit goals. Our results show that current LM models, despite employing working memory and Chain-of-Thought reasoning, achieve only 15% average progress without hints, highlighting their limitations in creativity. To bridge this gap, we propose EscapeAgent, a framework designed to enhance creative reasoning through Foresight (innovative tool use) and Reflection (identifying unsolved tasks). Experiments show that EscapeAgent can execute action chains over 1,000 steps while maintaining logical coherence. It navigates and completes games with up to 40% fewer steps and hints, performs robustly across difficulty levels, and achieves higher action success rates with more efficient and innovative puzzle-solving strategies",
    "checked": true,
    "id": "38723a5e21bc645355bd1ef667851aae291db961",
    "semantic_title": "escapebench: towards advancing creative intelligence of language model agents",
    "citation_count": 0,
    "authors": [
      "Cheng Qian",
      "Peixuan Han",
      "Qinyu Luo",
      "Bingxiang He",
      "Xiusi Chen",
      "Yuji Zhang",
      "Hongyi Du",
      "Jiarui Yao",
      "Xiaocheng Yang",
      "Denghui Zhang",
      "Yunzhu Li",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.40": {
    "title": "BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving",
    "volume": "long",
    "abstract": "LLMs exhibit advanced reasoning capabilities, offering the potential to transform natural language questions into mathematical models. However, existing open-source datasets in operations research domain lack detailed annotations of the modeling process, such as variable definitions, focusing solely on objective values, which hinders reinforcement learning applications. To address this, we release the StructuredOR dataset, annotated with comprehensive labels that capture the complete mathematical modeling process. We further propose BPP-Search, an algorithm that integrates reinforcement learning into a tree-of-thought structure using Beam search, a Process reward model, and a pairwise Preference algorithm. This approach enables efficient exploration of tree structures, avoiding exhaustive search while improving accuracy. Extensive experiments on StructuredOR, NL4OPT, and MAMO-ComplexLP datasets show that BPP-Search significantly outperforms state-of-the-art methods. In tree-based reasoning, BPP-Search excels in accuracy and efficiency, enabling faster retrieval of correct solutions. The StructuredOR dataset is available on Huggingface https://huggingface.co/datasets/LLM4OR/StructuredOR and GitHub https://github.com/LLM4OR/StructuredOR",
    "checked": true,
    "id": "d73af7a1507d2a41fbd2100ea8b4b4b5046233f4",
    "semantic_title": "bpp-search: enhancing tree of thought reasoning for mathematical modeling problem solving",
    "citation_count": 3,
    "authors": [
      "Teng Wang",
      "Wing Yin Yu",
      "Zhenqi He",
      "Zehua Liu",
      "HaileiGong HaileiGong",
      "Han Wu",
      "Xiongwei Han",
      "Wei Shi",
      "Ruifeng She",
      "Fangzhou Zhu",
      "Tao Zhong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.41": {
    "title": "LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation",
    "volume": "long",
    "abstract": "Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed sentiment analysis in a target language by transferring knowledge from a source language with available annotated data. Most existing methods depend heavily on often unreliable translation tools to bridge the language gap. In this paper, we propose a new approach that leverages a large language model (LLM) to generate high-quality pseudo-labelled data in the target language without the need for translation tools. First, the framework trains an ABSA model to obtain predictions for unlabelled target language data. Next, LLM is prompted to generate natural sentences that better represent these noisy predictions than the original text. The ABSA model is then further fine-tuned on the resulting pseudo-labelled dataset. We demonstrate the effectiveness of this method across six languages and five backbone models, surpassing previous state-of-the-art translation-based approaches. The proposed framework also supports generative models, and we show that fine-tuned LLMs outperform smaller multilingual models",
    "checked": false,
    "id": "9ceedde540060d0fe7a23fc6e2701a00c0d768fa",
    "semantic_title": "sentiment analysis with neural models for hungarian",
    "citation_count": 12,
    "authors": [
      "Jakub Šmíd",
      "Pavel Priban",
      "Pavel Kral"
    ]
  },
  "https://aclanthology.org/2025.acl-long.42": {
    "title": "Fusing Highly Specialized Language Models for Comprehensive Expertise",
    "volume": "long",
    "abstract": "Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we aim to \"play the dealt cards well\" and propose to fuse models that are already highly-specialized directly. The proposed fusing framework, , consists of different distinct specialists that are already sufficiently trained on different domains (we mainly focus on language, coding, and mathematics in this paper). A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a high-quality supervised instruction tuning dataset, , which includes text, code, and mathematical content. This dataset comprises approximately 300,000 instructions and covers a wide range of topics in each domain. Experiments show that our model could simultaneously achieve mastery of the three crucial domains",
    "checked": false,
    "id": "4ebee7a7e144ff14d1f6643447a81fa02bc7b658",
    "semantic_title": "blendergym: benchmarking foundational model systems for graphics editing",
    "citation_count": 1,
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Ganqu Cui",
      "Xingtai Lv",
      "Weilin Zhao",
      "Kaiyan Zhang",
      "Ruobing Xie",
      "Bowen Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.43": {
    "title": "HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases",
    "volume": "long",
    "abstract": "Given a semi-structured knowledge base (SKB), where text documents are interconnected by relations, how can we effectively retrieve relevant information to answer user questions?Retrieval-Augmented Generation (RAG) retrieves documents to assist large language models (LLMs) in question answering; while Graph RAG (GRAG) uses structured knowledge bases as its knowledge source.However, many questions require both textual and relational information from SKB — referred to as \"hybrid\" questions — which complicates the retrieval process and underscores the need for a hybrid retrieval method that leverages both information.In this paper, through our empirical analysis, we identify key insights that show why existing methods may struggle with hybrid question answering (HQA) over SKB. Based on these insights, we propose HybGRAG for HQA, consisting of a retriever bank and a critic module, with the following advantages:1. Agentic, it automatically refines the output by incorporating feedback from the critic module, 2. Adaptive, it solves hybrid questions requiring both textual and relational information with the retriever bank,3. Interpretable, it justifies decision making with intuitive refinement path, and4. Effective, it surpasses all baselines on HQA benchmarks.In experiments on the STaRK benchmark, HybGRAG achieves significant performance gains, with an average relative improvement in Hit@1 of 51%",
    "checked": true,
    "id": "fd0bea427aa72b3ea2e2f485a90cf1c9da6b9305",
    "semantic_title": "hybgrag: hybrid retrieval-augmented generation on textual and relational knowledge bases",
    "citation_count": 4,
    "authors": [
      "Meng-Chieh Lee",
      "Qi Zhu",
      "Costas Mavromatis",
      "Zhen Han",
      "Soji Adeshina",
      "Vassilis N. Ioannidis",
      "Huzefa Rangwala",
      "Christos Faloutsos"
    ]
  },
  "https://aclanthology.org/2025.acl-long.44": {
    "title": "Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms",
    "volume": "long",
    "abstract": "Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement, which can result in inadvertent exposure to harmful content. Current moderation efforts, reliant on classifiers trained with extensive human-annotated data, struggle with scalability and adapting to new forms of harm. To address these challenges, we propose a novel re-ranking approach using Large Language Models (LLMs) in zero-shot and few-shot settings. Our method dynamically assesses and re-ranks content sequences, effectively mitigating harmful content exposure without requiring extensive labeled data. Alongside traditional ranking metrics, we also introduce two new metrics to evaluate the effectiveness of re-ranking in reducing exposure to harmful content. Through experiments on three datasets, three models and across three configurations, we demonstrate that our LLM-based approach significantly outperforms existing proprietary moderation approaches, offering a scalable and adaptable solution for harm mitigation",
    "checked": true,
    "id": "4ed9126a38345639f202ea3b937baa34eefb6428",
    "semantic_title": "re-ranking using large language models for mitigating exposure to harmful content on social media platforms",
    "citation_count": 0,
    "authors": [
      "Rajvardhan Oak",
      "Muhammad Haroon",
      "Claire Wonjeong Jo",
      "Magdalena Wojcieszak",
      "Anshuman Chhabra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.45": {
    "title": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review",
    "volume": "long",
    "abstract": "Clinical coding is crucial for healthcare billing and data analysis. Manual clinical coding is labour-intensive and error-prone, which has motivated research towards full automation of the process. However, our analysis, based on US English electronic health records and automated coding research using these records, shows that widely used evaluation methods are not aligned with real clinical contexts. For example, evaluations that focus on the top 50 most common codes are an oversimplification, as there are thousands of codes used in practice. This position paper aims to align AI coding research more closely with practical challenges of clinical coding. Based on our analysis, we offer eight specific recommendations, suggesting ways to improve current evaluation methods. Additionally, we propose new AI-based methods beyond automated coding, suggesting alternative approaches to assist clinical coders in their workflows",
    "checked": true,
    "id": "6bf684f3ec31589c28f80a83438114447443fb07",
    "semantic_title": "aligning ai research with the needs of clinical coding workflows: eight recommendations based on us data analysis and critical review",
    "citation_count": 0,
    "authors": [
      "Yidong Gan",
      "Maciej Rybinski",
      "Ben Hachey",
      "Jonathan K. Kummerfeld"
    ]
  },
  "https://aclanthology.org/2025.acl-long.46": {
    "title": "MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection",
    "volume": "long",
    "abstract": "The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyan Liu",
      "Chunxiao Fan",
      "Haoran Lou",
      "Yuexin Wu",
      "Kaiwei Deng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.47": {
    "title": "EvoWiki: Evaluating LLMs on Evolving Knowledge",
    "volume": "long",
    "abstract": "Knowledge utilization is a critical aspect of LLMs, and understanding how they adapt to evolving knowledge is essential for their effective deployment. However, existing benchmarks are predominantly static, failing to capture the evolving nature of LLMs and knowledge, leading to inaccuracies and vulnerabilities such as contamination. In this paper, we introduce EvoWiki, an evolving dataset designed to reflect knowledge evolution by categorizing information into stable, evolved, and uncharted states. EvoWiki is fully auto-updatable, enabling precise evaluation of continuously changing knowledge and newly released LLMs. Through experiments with Retrieval-Augmented Generation (RAG) and Continual Learning (CL), we evaluate how effectively LLMs adapt to evolving knowledge. Our results indicate that current models often struggle with evolved knowledge, frequently providing outdated or incorrect responses. Moreover, the dataset highlights a synergistic effect between RAG and CL, demonstrating their potential to better adapt to evolving knowledge. EvoWiki provides a robust benchmark for advancing future research on the knowledge evolution capabilities of large language models",
    "checked": true,
    "id": "c046a548f94ff1e6560eae8b9e1e99c1223d0e89",
    "semantic_title": "evowiki: evaluating llms on evolving knowledge",
    "citation_count": 2,
    "authors": [
      "Wei Tang",
      "Yixin Cao",
      "Yang Deng",
      "Jiahao Ying",
      "Bo Wang",
      "Yizhe Yang",
      "Yuyue Zhao",
      "Qi Zhang",
      "Xuanjing Huang",
      "Yu-Gang Jiang",
      "Yong Liao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.48": {
    "title": "Rethinking Repetition Problems of LLMs in Code Generation",
    "volume": "long",
    "abstract": "With the advent of neural language models, the performance of code generation has been significantly boosted. However, the problem of repetitions during the generation process continues to linger. Previous work has primarily focused on content repetition, which is merely a fraction of the broader repetition problem in code generation. A more prevalent and challenging problem is structural repetition. In structural repetition, the repeated code appears in various patterns but possesses a fixed structure, which can be inherently reflected in grammar. In this paper, we formally define structural repetition and propose an efficient decoding approach called RPG, which stands for Repetition Penalization based on Grammar, to alleviate the repetition problems in code generation for LLMs. Specifically, RPG first leverages grammar rules to identify repetition problems during code generation, and then strategically decays the likelihood of critical tokens that contribute to repetitions, thereby mitigating them in code generation. To facilitate this study, we construct a new dataset CodeRepetEval to comprehensively evaluate approaches for mitigating the repetition problems in code generation. Extensive experimental results demonstrate that RPG substantially outperforms the best-performing baselines on CodeRepetEval dataset as well as HumanEval and MBPP benchmarks, effectively reducing repetitions and enhancing the quality of generated code",
    "checked": true,
    "id": "6782ccdab29f6c117827139c7c98bcc53ab2244e",
    "semantic_title": "rethinking repetition problems of llms in code generation",
    "citation_count": 1,
    "authors": [
      "Yihong Dong",
      "Yuchen Liu",
      "Xue Jiang",
      "Bin Gu",
      "Zhi Jin",
      "Ge Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.49": {
    "title": "PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension",
    "volume": "long",
    "abstract": "Multimodal punchlines, which involve humor or sarcasm conveyed in image-caption pairs, are a popular way of communication on online multimedia platforms. With the rapid development of multimodal large language models (MLLMs), it is essential to assess their ability to effectively comprehend these punchlines. However, existing benchmarks on punchline comprehension suffer from three major limitations: 1) language shortcuts that allow models to solely rely on text, 2) lack of question diversity, and 3) narrow focus on a specific domain of multimodal content (e.g., cartoon). To address these limitations, we introduce a multimodal **Punch**line comprehension **Bench**mark, named **PunchBench**, which is tailored for accurate and comprehensive evaluation of punchline comprehension. To enhance the evaluation accuracy, we generate synonymous and antonymous captions by modifying original captions, which mitigates the impact of shortcuts in the captions. To provide a comprehensive evaluation, PunchBench incorporates diverse question formats and image-captions from various domains. On this basis, we conduct extensive evaluations and reveal a significant gap between state-of-the-art MLLMs and humans in punchline comprehension. To improve punchline comprehension, we propose Simple-to-Complex Chain-of-Question (SC-CoQ) strategy, enabling the models to incrementally address complicated questions by first mastering simple ones. SC-CoQ effectively enhances the performance of various MLLMs on PunchBench, surpassing in-context learning and chain-of-thought",
    "checked": true,
    "id": "fd72ab9fc32effaa17213a1296671a9ac62040d4",
    "semantic_title": "punchbench: benchmarking mllms in multimodal punchline comprehension",
    "citation_count": 1,
    "authors": [
      "Kun Ouyang",
      "Yuanxin Liu",
      "Shicheng Li",
      "Yi Liu",
      "Hao Zhou",
      "Fandong Meng",
      "Jie Zhou",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.50": {
    "title": "ProcessBench: Identifying Process Errors in Mathematical Reasoning",
    "volume": "long",
    "abstract": "As language models regularly make mistakes when solving math problems, automated identification of errors in the reasoning process becomes increasingly significant for their scalable oversight. In this paper, we introduce ProcessBench for measuring the ability to identify erroneous steps in mathematical reasoning. It consists of 3,400 test cases, primarily focused on competition- and Olympiad-level math problems. Each test case contains a step-by-step solution with error location annotated by human experts. Models are required to identify the earliest step that contains an error, or conclude that all steps are correct. We conduct extensive evaluation on ProcessBench, involving two types of models: process reward models (PRMs) and critic models, where for the latter we prompt general language models to critique each solution step by step. We draw two main observations: (1) Existing PRMs typically fail to generalize to more challenging math problems beyond GSM8K and MATH. They underperform both critic models (i.e., prompted general language models) and our own trained PRM that is straightforwardly fine-tuned on the PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has demonstrated the critique capability competitive with the proprietary model GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We hope ProcessBench can foster future research in reasoning process assessment, paving the way toward scalable oversight of language models",
    "checked": true,
    "id": "dccd3899dd16beec8adcc97b65f6e24e7927d19b",
    "semantic_title": "processbench: identifying process errors in mathematical reasoning",
    "citation_count": 77,
    "authors": [
      "Chujie Zheng",
      "Zhenru Zhang",
      "Beichen Zhang",
      "Runji Lin",
      "Keming Lu",
      "Bowen Yu",
      "Dayiheng Liu",
      "Jingren Zhou",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.51": {
    "title": "Model Extrapolation Expedites Alignment",
    "volume": "long",
    "abstract": "Given the high computational cost of preference alignment training of large language models (LLMs), exploring efficient methods to reduce the training overhead remains an important and compelling research problem. Motivated by the observation that alignment training typically involves only small parameter changes without injecting new knowledge into models, we propose a straightforward method called ExPO (model extrapolation) to expedite LLMs' alignment with human preferences. Given a partially-trained model and its initial SFT checkpoint, ExPO improves the implicit optimization objective of alignment training by simply amplifying the parameter change based on a first-order approximation, without any additional training overhead. Through controlled experiments, we demonstrate that ExPO boosts a DPO model trained with only 20% steps to outperform the fully-trained one. Moreover, we show that ExPO notably improves existing open-source LLMs (ranging from 1.8B to 70B parameters) on the leading AlpacaEval 2.0 and MT-Bench benchmarks, which highlights ExPO's broader utility in efficiently enhancing LLM alignment",
    "checked": true,
    "id": "3ec648362481eaa44e439fa0955533da390cacfd",
    "semantic_title": "model extrapolation expedites alignment",
    "citation_count": 33,
    "authors": [
      "Chujie Zheng",
      "Ziqi Wang",
      "Heng Ji",
      "Minlie Huang",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.52": {
    "title": "ATLANTIS: Weak-to-Strong Learning via Importance Sampling",
    "volume": "long",
    "abstract": "Supervised fine-tuning (SFT) enables large language models to align with training data for better performance in many aspects. Nevertheless, the gap between the distribution of current datasets from human annotations or model generations and the real-world data distribution heavily limits the capacities and potentials of models. As a result, we propose a new SFT technique, ATLANTIS, to bridge the gap. We adopt importance sampling to estimate the optimal data distribution in the real world from existing training datasets because the former is hard to sample from. Furthermore, we introduce an extra small model and reference model to estimate the sampling ratio through the probability gap between them. We evaluate our method with benchmarks in knowledge & understanding and preference aspects. The experiment results prove that ATLANTIS can bring consistent and significant improvements to models' performance. What's more, our method can be flexibly transferred among models with different structures. Our analyses demonstrate that our method is well-compatible with other SFT techniques to further enhance models' capacities and has great potential to be combined with existing training frameworks",
    "checked": false,
    "id": "653d5c71a9fe9fe65d074be7deab18404cf50810",
    "semantic_title": "multidimensional sleep profiles via machine learning and risk of dementia and cardiovascular disease",
    "citation_count": 0,
    "authors": [
      "Yi Liu",
      "Guoyin Wang",
      "Shicheng Li",
      "Feifan Song",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.53": {
    "title": "MPVStance: Mitigating Hallucinations in Stance Detection with Multi-Perspective Verification",
    "volume": "long",
    "abstract": "Stance detection is a pivotal task in Natural Language Processing (NLP), identifying textual attitudes toward various targets. Despite advances in using Large Language Models (LLMs), challenges persist due to hallucination-models generating plausible yet inaccurate content. Addressing these challenges, we introduce MPVStance, a framework that incorporates Multi-Perspective Verification (MPV) with Retrieval-Augmented Generation (RAG) across a structured five-step verification process. Our method enhances stance detection by rigorously validating each response from factual accuracy, logical consistency, contextual relevance, and other perspectives. Extensive testing on the SemEval-2016 and VAST datasets, including scenarios that challenge existing methods and comprehensive ablation studies, demonstrates that MPVStance significantly outperforms current models. It effectively mitigates hallucination issues and sets new benchmarks for reliability and accuracy in stance detection, particularly in zero-shot, few-shot, and challenging scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "ZhaoDan Zhang",
      "Zhao Zhang",
      "Jin Zhang",
      "Hui Xu",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.54": {
    "title": "Personality-Guided Code Generation Using Large Language Models",
    "volume": "long",
    "abstract": "Code generation, the automatic creation of source code from natural language descriptions, has garnered significant attention due to its potential to streamline software development. Inspired by research that links task-personality alignment with improved development outcomes, we conduct an empirical study on personality-guided code generation using large language models (LLMs). Specifically, we investigate how emulating personality traits appropriate to the coding tasks affects LLM performance. We extensively evaluate this approach using seven widely adopted LLMs across four representative datasets. Our results show that personality guidance significantly enhances code generation accuracy, with improved pass rates in 23 out of 28 LLM-dataset combinations. Notably, in 11 cases, the improvement exceeds 5%, and in 5 instances, it surpasses 10%, with the highest gain reaching 12.9%. Additionally, personality guidance can be easily integrated with other prompting strategies to further boost performance",
    "checked": true,
    "id": "d5ebc71f7afd544d84b801b3f582b74f5dba4384",
    "semantic_title": "personality-guided code generation using large language models",
    "citation_count": 0,
    "authors": [
      "Yaoqi Guo",
      "Zhenpeng Chen",
      "Jie M. Zhang",
      "Yang Liu",
      "Yun Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.55": {
    "title": "PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling",
    "volume": "long",
    "abstract": "Currently, large language models (LLMs) have made significant progress in the field of psychological counseling. However, existing mental health LLMs overlook a critical issue where they do not consider the fact that different psychological counselors exhibit different personal styles, including linguistic style and therapy techniques, etc. As a result, these LLMs fail to satisfy the individual needs of clients who seek different counseling styles. To help bridge this gap, we propose PsyDT, a novel framework using LLMs to construct the Digital Twin of Psychological counselor with personalized counseling style. Compared to the time-consuming and costly approach of collecting a large number of real-world counseling cases to create a specific counselor's digital twin, our framework offers a faster and more cost-effective solution. To construct PsyDT, we utilize dynamic one-shot learning by using GPT-4 to capture counselor's unique counseling style, mainly focusing on linguistic style and therapy techniques. Subsequently, using existing single-turn long-text dialogues with client's questions, GPT-4 is guided to synthesize multi-turn dialogues of specific counselor. Finally, we fine-tune the LLMs on the synthetic dataset, PsyDTCorpus, to achieve the digital twin of psychological counselor with personalized counseling style. Experimental results indicate that our proposed PsyDT framework can synthesize multi-turn dialogues that closely resemble real-world counseling cases and demonstrate better performance compared to other baselines, thereby show that our framework can effectively construct the digital twin of psychological counselor with a specific counseling style",
    "checked": true,
    "id": "02db7f914c78e721fc0c8c66bc424bc5813b0aae",
    "semantic_title": "psydt: using llms to construct the digital twin of psychological counselor with personalized counseling style for psychological counseling",
    "citation_count": 5,
    "authors": [
      "Haojie Xie",
      "Yirong Chen",
      "Xiaofen Xing",
      "Jingkai Lin",
      "Xiangmin Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.56": {
    "title": "BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework",
    "volume": "long",
    "abstract": "Recently, generative pre-trained models have made significant strides, particularly highlighted by the release of ChatGPT and GPT-4, which exhibit superior cross-domain capabilities. However, these models still face challenges on constrained writing tasks like poem generation under open-domain titles via direct generation.In response to this challenge, we introduce Block Inverse Prompting (BIPro) constrained generation framework. BIPro leverages two block inverse prompting methods, revise and rewrite. This inference scaling approach mimics the process of human text writing using block generative models. It significantly improves the zero-shot generation quality on the constrained generation task of open-domain traditional-form Chinese poem generation. Based on a less powerful block generative model GLM-10B-Chinese, poems composed via BIPro without priming or additional training outperform both much larger direct generative systems like GPT-4 or GLM-4 and domain-specific systems such as Yusheng, Shisanbai, or Baidu Poetry Helper in human evaluation by proficient poets. BIPro considerably narrows the gap between AI-generated works and short-listed human literary arts in another human evaluation, unveiling the promising potential of inference scaling in improving the quality of constrained generation. It is open-sourced and available as an agent in chatglm app",
    "checked": true,
    "id": "397035435a388f2cee62b169cfd88f80055e74fe",
    "semantic_title": "bipro: zero-shot chinese poem generation via block inverse prompting constrained generation framework",
    "citation_count": 0,
    "authors": [
      "Xu Zou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.57": {
    "title": "LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating",
    "volume": "long",
    "abstract": "Large vision language models (LVLMs) have improved the document understanding capabilities remarkably, enabling the handling of complex document elements, longer contexts, and a wider range of tasks. However, existing document understanding benchmarks have been limited to handling only a small number of pages and fail to provide a comprehensive analysis of layout elements locating. In this paper, we first define three primary task categories: Long Document Understanding, numerical Reasoning, and cross-element Locating, and then propose a comprehensive benchmark—LongDocURL—integrating above three primary tasks and comprising 20 sub-tasks categorized based on different primary tasks and answer evidences. Furthermore, we develop a semi-automated construction pipeline and collect 2,325 high-quality question-answering pairs, covering more than 33,000 pages of documents, significantly outperforming existing benchmarks. Subsequently, we conduct comprehensive evaluation experiments on both open-source and closed- source models across 26 different configurations, revealing critical performance gaps in this field. The code and data: https://github.com/dengc2023/LongDocURL",
    "checked": true,
    "id": "d48979be70c432a907b5afaece05361430a0ee9b",
    "semantic_title": "longdocurl: a comprehensive multimodal long document benchmark integrating understanding, reasoning, and locating",
    "citation_count": 6,
    "authors": [
      "Chao Deng",
      "Jiale Yuan",
      "Pi Bu",
      "Peijie Wang",
      "Zhong-Zhi Li",
      "Jian Xu",
      "Xiao-Hui Li",
      "Yuan Gao",
      "Jun Song",
      "Bo Zheng",
      "Cheng-Lin Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.58": {
    "title": "ObfusLM: Privacy-preserving Language Model Service against Embedding Inversion Attacks",
    "volume": "long",
    "abstract": "As the rapid expansion of Machine Learning as a Service (MLaaS) for language models, concerns over the privacy of client inputs during inference or fine-tuning have correspondingly escalated. Recently, solutions have been proposed to safeguard client privacy by obfuscation techniques. However, the solutions incur notable decline in model utility and mainly focus on classification tasks, rendering them impractical for real-world applications. Moreover, recent studies reveal that these obfuscation, if not well designed, is susceptible to embedding inversion attacks (EIAs). In this paper, we devise ObfusLM, a privacy-preserving MLaaS framework for both classification and generation tasks. ObfusLM leverages a model obfuscation module to achieve privacy protection for both classification and generation tasks. Based on (k, 𝜖)-anonymity, ObfusLM includes novel obfuscation algorithms to reach provable security against EIAs. Extensive experiments show that ObfusLM outperforms existing works in utility by 10% with a nearly 80% resistance rate against EIAs",
    "checked": false,
    "id": "a89978394b3b03ef512d1445d18ef09f741277f4",
    "semantic_title": "remoterag: a privacy-preserving llm cloud rag service",
    "citation_count": 1,
    "authors": [
      "Yu Lin",
      "Ruining Yang",
      "Yunlong Mao",
      "Qizhi Zhang",
      "Jue Hong",
      "Quanwei Cai",
      "Ye Wu",
      "Huiqi Liu",
      "Zhiyu Chen",
      "Bing Duan",
      "Sheng Zhong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.59": {
    "title": "Interlocking-free Selective Rationalization Through Genetic-based Learning",
    "volume": "long",
    "abstract": "A popular end-to-end architecture for selective rationalization is the select-then-predict pipeline, comprising a generator to extract highlights fed to a predictor. Such a cooperative system suffers from suboptimal equilibrium minima due to the dominance of one of the two modules, a phenomenon known as interlocking. While several contributions aimed at addressing interlocking, they only mitigate its effect, often by introducing feature-based heuristics, sampling, and ad-hoc regularizations. We present GenSPP, the first interlocking-free architecture for selective rationalization that does not require any learning overhead, as the above-mentioned. GenSPP avoids interlocking by performing disjoint training of the generator and predictor via genetic global search. Experiments on a synthetic and a real-world benchmark show that our model outperforms several state-of-the-art competitors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Federico Ruggeri",
      "Gaetano Signorelli"
    ]
  },
  "https://aclanthology.org/2025.acl-long.60": {
    "title": "Re-identification of De-identified Documents with Autoregressive Infilling",
    "volume": "long",
    "abstract": "Documents revealing sensitive information about individuals must typically be de-identified. This de-identification is often done by masking all mentions of personally identifiable information (PII), thereby making it more difficult to uncover the identity of the person(s) in question. To investigate the robustness of de-identification methods, we present a novel, RAG-inspired approach that attempts the reverse process of re-identification based on a database of documents representing background knowledge. Given a text in which personal identifiers have been masked, the re-identification proceeds in two steps. A retriever first selects from the background knowledge passages deemed relevant for the re-identification. Those passages are then provided to an infilling model which seeks to infer the original content of each text span. This process is repeated until all masked spans are replaced. We evaluate the re-identification on three datasets (Wikipedia biographies, court rulings and clinical notes). Results show that (1) as many as 80% of de-identified text spans can be successfully recovered and (2) the re-identification accuracy increases along with the level of background knowledge",
    "checked": true,
    "id": "196711eb1cfa7cd88a04b8a2e0d8b717aa28458a",
    "semantic_title": "re-identification of de-identified documents with autoregressive infilling",
    "citation_count": 0,
    "authors": [
      "Lucas Georges Gabriel Charpentier",
      "Pierre Lison"
    ]
  },
  "https://aclanthology.org/2025.acl-long.61": {
    "title": "Modeling Uncertainty in Composed Image Retrieval via Probabilistic Embeddings",
    "volume": "long",
    "abstract": "Composed Image Retrieval (CIR) enables users to search for images using multimodal queries that combine text and reference images. While metric learning methods have shown promise, they rely on deterministic point embeddings that fail to capture the inherent uncertainty in the input data, in which user intentions may be imprecisely specified or open to multiple interpretations. We address this challenge by reformulating CIR through our proposed Composed Probabilistic Embedding (CoPE) framework, which represents both queries and targets as Gaussian distributions in latent space rather than fixed points. Through careful design of probabilistic distance metrics and hierarchical learning objectives, CoPE explicitly captures uncertainty at both instance and feature levels, enabling more flexible, nuanced, and robust matching that can handle polysemy and ambiguity in search intentions. Extensive experiments across multiple benchmarks demonstrate that CoPE effectively quantifies both quality and semantic uncertainties within Composed Image Retrieval, achieving state-of-the-art performance on recall rate. Code: https://github.com/tanghme0w/ACL25-CoPE",
    "checked": false,
    "id": "250441a048b28a9aea1f455fa566f830b4ce6aab",
    "semantic_title": "llm-enhanced composed image retrieval: an intent uncertainty-aware linguistic-visual dual channel matching model",
    "citation_count": 4,
    "authors": [
      "Haomiao Tang",
      "Jinpeng Wang",
      "Yuang Peng",
      "GuangHao Meng",
      "Ruisheng Luo",
      "Bin Chen",
      "Long Chen",
      "Yaowei Wang",
      "Shu-Tao Xia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.62": {
    "title": "Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models",
    "volume": "long",
    "abstract": "Large language models (LLM) have prioritized expanding the context window from which models can incorporate more information. However, training models to handle long contexts presents significant challenges. These include the scarcity of high-quality natural long-context data, the potential for performance degradation on short-context tasks, and the reduced training efficiency associated with attention mechanisms. In this paper, we introduce Untie the Knots (UtK), a novel data augmentation strategy employed during the continue pre-training phase, designed to efficiently enable LLMs to gain long-context capabilities without the need to modify the existing data mixture. In particular, we chunk the documents, shuffle the chunks, and create a complex and knotted structure of long texts; LLMs are then trained to untie these knots and identify relevant segments within seemingly chaotic token sequences. This approach greatly improves the model's performance by accurately attending to relevant information in long context and the training efficiency is also largely increased. We conduct extensive experiments on models with 7B and 72B parameters, trained on 20 billion tokens, demonstrating that UtK achieves 75% and 84.5% accurracy on RULER at 128K context length, significantly outperforming other long context strategies. The trained models will open-source for further research",
    "checked": true,
    "id": "ce0a381d4b6a104993ffbe825910900606caa3f0",
    "semantic_title": "untie the knots: an efficient data augmentation strategy for long-context pre-training in language models",
    "citation_count": 5,
    "authors": [
      "Junfeng Tian",
      "Da Zheng",
      "Yang Chen",
      "Rui Wang",
      "Colin Zhang",
      "Debing Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.63": {
    "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have become increasingly capable of handling diverse tasks with the aid of well-crafted prompts and integration of external tools, but as task complexity rises, the workflow involving LLMs can be complicated and thus challenging to implement and maintain. To address this challenge, we propose APPL, A Prompt Programming Language that acts as a bridge between computer programs and LLMs, allowing seamless embedding of prompts into Python functions, and vice versa. APPL provides an intuitive and Python-native syntax, an efficient parallelized runtime with asynchronous semantics, and a tracing module supporting effective failure diagnosis and replaying without extra costs. We demonstrate that APPL programs are intuitive, concise, and efficient through representative scenarios including Chain-of-Thought with self-consistency (CoT-SC) and ReAct tool-use agent. We further use LLMs to judge the language design between APPL and previous work, where the results indicate that codes written in APPL are more readable and intuitive. Our code, tutorial and documentation are available at https://github.com/appl-team/appl",
    "checked": true,
    "id": "32adfdfa1032c725b4eca9c0fc2557cb5ab51b49",
    "semantic_title": "appl: a prompt programming language for harmonious integration of programs and large language model prompts",
    "citation_count": 1,
    "authors": [
      "Honghua Dong",
      "Qidong Su",
      "Yubo Gao",
      "Zhaoyu Li",
      "Yangjun Ruan",
      "Gennady Pekhimenko",
      "Chris J. Maddison",
      "Xujie Si"
    ]
  },
  "https://aclanthology.org/2025.acl-long.64": {
    "title": "Evaluating Lexical Proficiency in Neural Language Models",
    "volume": "long",
    "abstract": "We present a novel evaluation framework designed to assess the lexical proficiency and linguistic creativity of Transformer-based Language Models (LMs). We validate the framework by analyzing the performance of a set of LMs of different sizes, in both mono- and multilingual configuration, across tasks involving the generation, definition, and contextual usage of lexicalized words, neologisms, and nonce words. To support these evaluations, we developed a novel dataset of lexical entries for the Italian language, including curated definitions and usage examples sourced from various online platforms. The results highlight the robustness and effectiveness of our framework in evaluating multiple dimensions of LMs' linguistic understanding and offer an insight, through the assessment of their linguistic creativity, on the lexical generalization abilities of LMs",
    "checked": false,
    "id": "9cf3a53492bbdaeb7d58afffa3be78749d178b11",
    "semantic_title": "evaluating lexical aspect with large language models",
    "citation_count": 1,
    "authors": [
      "Cristiano Ciaccio",
      "Alessio Miaschi",
      "Felice Dell’Orletta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.65": {
    "title": "Autoregressive Speech Synthesis without Vector Quantization",
    "volume": "long",
    "abstract": "We present MELLE, a novel continuous-valued token based language modeling approach for text-to-speech synthesis (TTS). MELLE autoregressively generates continuous mel-spectrogram frames directly from text condition, bypassing the need for vector quantization, which is typically designed for audio compression and sacrifices fidelity compared to continuous representations. Specifically, (i) instead of cross-entropy loss, we apply regression loss with a proposed spectrogram flux loss function to model the probability distribution of the continuous-valued tokens; (ii) we have incorporated variational inference into MELLE to facilitate sampling mechanisms, thereby enhancing the output diversity and model robustness. Experiments demonstrate that, compared to the two-stage codec language model VALL-E and its variants, the single-stage MELLE mitigates robustness issues by avoiding the inherent flaws of sampling vector-quantized codes, achieves superior performance across multiple metrics, and, most importantly, offers a more streamlined paradigm. The demos of our work are provided at https://aka.ms/melle",
    "checked": true,
    "id": "df05872bd7a1b88f89e3b8a3014318bee337a809",
    "semantic_title": "autoregressive speech synthesis without vector quantization",
    "citation_count": 43,
    "authors": [
      "Lingwei Meng",
      "Long Zhou",
      "Shujie Liu",
      "Sanyuan Chen",
      "Bing Han",
      "Shujie Hu",
      "Yanqing Liu",
      "Jinyu Li",
      "Sheng Zhao",
      "Xixin Wu",
      "Helen M. Meng",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.66": {
    "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
    "volume": "long",
    "abstract": "Massive high-quality data, both pre-training raw texts and post-training annotations, have been carefully prepared to incubate advanced large language models (LLMs). In contrast, for information extraction (IE), pre-training data, such as BIO-tagged sequences, are hard to scale up. We show that IE models can act as free riders on LLM resources by reframing next-token prediction into extraction for tokens already present in the context. Specifically, our proposed next tokens extraction (NTE) paradigm learns a versatile IE model, Cuckoo, with 102.6M extractive data converted from LLM's pre-training and post-training data. Under the few-shot setting, Cuckoo adapts effectively to traditional and complex instruction-following IE with better performance than existing pre-trained IE models. As a free rider, Cuckoo can naturally evolve with the ongoing advancements in LLM data preparation, benefiting from improvements in LLM training pipelines without additional manual effort",
    "checked": true,
    "id": "7fd174ee3708e052c620a68688194368eff3a68f",
    "semantic_title": "cuckoo: an ie free rider hatched by massive nutrition in llm's nest",
    "citation_count": 0,
    "authors": [
      "Letian Peng",
      "Zilong Wang",
      "Feng Yao",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.67": {
    "title": "FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Large Language Models",
    "volume": "long",
    "abstract": "Low-Rank Adaptation (LoRA) is a popular technique for efficient fine-tuning of foundation models. However, applying LoRA in federated learning environments, where data is distributed across multiple clients, presents unique challenges. Existing methods rely on traditional federated averaging of LoRA adapters, resulting in inexact updates. To address this, we propose Federated Exact LoRA, or FedEx-LoRA, which adds a residual error term to the pre-trained frozen weight matrix. Our approach achieves exact updates with minimal computational and communication overhead, preserving LoRA's efficiency. We evaluate the method on various models across arithmetic reasoning, commonsense reasoning, natural language understanding and natural language generation tasks, showing consistent performance gains over state-of-the-art methods across multiple settings. Through extensive analysis, we quantify that the deviations in updates from the ideal solution are significant, highlighting the need for exact aggregation. Our method's simplicity, efficiency, and broad applicability position it as a promising solution for accurate and effective federated fine-tuning of foundation models",
    "checked": false,
    "id": "88dac29fc9d032b5a3cc4ed1d3f7ad5c83461dcc",
    "semantic_title": "fedex-lora: exact aggregation for federated and efficient fine-tuning of foundation models",
    "citation_count": 6,
    "authors": [
      "Raghav Singhal",
      "Kaustubh Ponkshe",
      "Praneeth Vepakomma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.68": {
    "title": "Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality",
    "volume": "long",
    "abstract": "Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models' predictions and assess the preference of MLMs towards disadvantaged and advantaged groups. We find that all models encode concerning social biases. We compare bias estimations with those produced by other evaluation methods using benchmark datasets and assess their alignment with human annotated biases. We extend previous work by evaluating social biases introduced after retraining an MLM under the masked language modeling objective and find proposed measures produce more accurate and sensitive estimations of biases based on relative preference for biased sentences between models, while other methods tend to underestimate biases after retraining on sentences biased towards disadvantaged groups",
    "checked": true,
    "id": "dc522377c3323622b02739e9dbe7a1fac70cb7d2",
    "semantic_title": "measuring social biases in masked language models by proxy of prediction quality",
    "citation_count": 1,
    "authors": [
      "Rahul Zalkikar",
      "Kanchan Chandra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.69": {
    "title": "Capturing Author Self Beliefs in Social Media Language",
    "volume": "long",
    "abstract": "Measuring the prevalence and dimensions of self beliefs is essential for understanding human self-perception and various psychological outcomes. In this paper, we develop a novel task for classifying language that contains explicit or implicit mentions of the author's self beliefs. We contribute a set of 2,000 human-annotated self beliefs, 100,000 LLM-labeled examples, and 10,000 surveyed self belief paragraphs. We then evaluate several encoder-based classifiers and training routines for this task. Our trained model, SelfAwareNet, achieved an AUC of 0.944, outperforming 0.839 from OpenAI's state-of-the-art GPT-4o model. Using this model we derive data-driven categories of self beliefs and demonstrate their ability to predict valence, depression, anxiety, and stress. We release the resulting self belief classification model and annotated datasets for use in future research",
    "checked": false,
    "id": "7c690e5a697c108c2f655842e7548d76b23c89da",
    "semantic_title": "a critical genre analysis of social media news reporting: the case of instagram",
    "citation_count": 0,
    "authors": [
      "Siddharth Mangalik",
      "Adithya V Ganesan",
      "Abigail B. Wheeler",
      "Nicholas Kerry",
      "Jeremy D. W. Clifton",
      "H. Schwartz",
      "Ryan L. Boyd"
    ]
  },
  "https://aclanthology.org/2025.acl-long.70": {
    "title": "Neural Topic Modeling with Large Language Models in the Loop",
    "volume": "long",
    "abstract": "Topic modeling is a fundamental task in natural language processing, allowing the discovery of latent thematic structures in text corpora. While Large Language Models (LLMs) have demonstrated promising capabilities in topic discovery, their direct application to topic modeling suffers from issues such as incomplete topic coverage, misalignment of topics, and inefficiency. To address these limitations, we propose LLM-ITL, a novel LLM-in-the-loop framework that integrates LLMs with Neural Topic Models (NTMs). In LLM-ITL, global topics and document representations are learned through the NTM. Meanwhile, an LLM refines these topics using an Optimal Transport (OT)-based alignment objective, where the refinement is dynamically adjusted based on the LLM's confidence in suggesting topical words for each set of input words. With the flexibility of being integrated into many existing NTMs, the proposed approach enhances the interpretability of topics while preserving the efficiency of NTMs in learning topics and document representations. Extensive experiments demonstrate that LLM-ITL helps NTMs significantly improve their topic interpretability while maintaining the quality of document representation. Our code and datasets are available athttps://github.com/Xiaohao-Yang/LLM-ITL",
    "checked": true,
    "id": "37653b5417c192d79626e93201ec723fd8e0b9a2",
    "semantic_title": "neural topic modeling with large language models in the loop",
    "citation_count": 1,
    "authors": [
      "Xiaohao Yang",
      "He Zhao",
      "Weijie Xu",
      "Yuanyuan Qi",
      "Jueqing Lu",
      "Dinh Phung",
      "Lan Du"
    ]
  },
  "https://aclanthology.org/2025.acl-long.71": {
    "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
    "volume": "long",
    "abstract": "Despite their impressive ability to generate high-quality and fluent text, generative large language models (LLMs) also produce hallucinations: statements that are misaligned with established world knowledge or provided input context. However, measuring hallucination can be challenging, as having humans verify model generations on-the-fly is both expensive and time-consuming. In this work, we release HALoGEN, a comprehensive hallucination benchmark consisting of: (1) 10,923 prompts for generative models spanning nine domains including programming, scientific attribution, and summarization, and (2) automatic high-precision verifiers for each use case that decompose LLM generations into atomic units, and verify each unit against a high-quality knowledge source. We use this framework to evaluate ~150,000 generations from 14 language models, finding that even the best-performing models are riddled with hallucinations (sometimes up to 86% of generated atomic facts depending on the domain). We further define a novel error classification for LLM hallucinations based on whether they likely stem from incorrect recollection of training data (Type A errors), or incorrect knowledge in training data (Type B errors), or are fabrication (Type C errors). We hope our framework provides a foundation to enable the principled study of why generative models hallucinate, and advances the development of trustworthy large language models",
    "checked": true,
    "id": "7486325fbf143d1dab5a99094da23a0a7dc7e41b",
    "semantic_title": "halogen: fantastic llm hallucinations and where to find them",
    "citation_count": 6,
    "authors": [
      "Abhilasha Ravichander",
      "Shrusti Ghela",
      "David Wadden",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.72": {
    "title": "Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) can assist multimodal fake news detection by predicting pseudo labels. However, LLM-generated pseudo labels alone demonstrate poor performance compared to traditional detection methods, making their effective integration non-trivial. In this paper, we propose Global Label Propagation Network with LLM-based Pseudo Labeling (GLPN-LLM) for multimodal fake news detection, which integrates LLM capabilities via label propagation techniques. The global label propagation can utilize LLM-generated pseudo labels, enhancing prediction accuracy by propagating label information among all samples. For label propagation, a mask-based mechanism is designed to prevent label leakage during training by ensuring that training nodes do not propagate their own labels back to themselves. Experimental results on benchmark datasets show that by synergizing LLMs with label propagation, our model achieves superior performance over state-of-the-art baselines",
    "checked": true,
    "id": "a42f812cdac48373550cc00344612f709e142fca",
    "semantic_title": "synergizing llms with global label propagation for multimodal fake news detection",
    "citation_count": 0,
    "authors": [
      "Shuguo Hu",
      "Jun Hu",
      "Huaiwen Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.73": {
    "title": "Yes, My LoRD.\" Guiding Language Model Extraction with Locality Reinforced Distillation",
    "volume": "long",
    "abstract": "Model extraction attacks (MEAs) on large language models (LLMs) have received increasing attention in recent research. However, existing attack methods typically adapt the extraction strategies originally developed for deep neural networks (DNNs). They neglect the underlying inconsistency between the training tasks of MEA and LLM alignment, leading to suboptimal attack performance. To tackle this issue, we propose Locality Reinforced Distillation (LoRD), a novel model extraction algorithm specifically designed for LLMs. In particular, LoRD employs a newly defined policy-gradient-style training task that utilizes the responses of victim model as the signal to guide the crafting of preference for the local model. Theoretical analyses demonstrate that I) The convergence procedure of LoRD in model extraction is consistent with the alignment procedure of LLMs, and II) LoRD can reduce query complexity while mitigating watermark protection through our exploration-based stealing. Extensive experiments validate the superiority of our method in extracting various state-of-the-art commercial LLMs. Our code is available at: https://github.com/liangzid/LoRD-MEA",
    "checked": false,
    "id": "dca9242b227eebb3f052139dcb6a45c4dcbfde83",
    "semantic_title": "yes, my lord.\"guiding language model extraction with locality reinforced distillation",
    "citation_count": 0,
    "authors": [
      "Zi Liang",
      "Qingqing Ye",
      "Yanyun Wang",
      "Sen Zhang",
      "Yaxin Xiao",
      "RongHua Li",
      "Jianliang Xu",
      "Haibo Hu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.74": {
    "title": "Jailbreak Large Vision-Language Models Through Multi-Modal Linkage",
    "volume": "long",
    "abstract": "With the rapid advancement of Large Vision-Language Models (VLMs), concerns about their ‌potential misuse and abuse have grown rapidly. Prior research has exposed VLMs' vulnerability to jailbreak attacks, where carefully crafted inputs can lead the model to produce content that violates ethical and legal standards. However, current jailbreak methods often fail against cutting-edge models such as GPT-4o. We attribute this to the over-exposure of harmful content and the absence of stealthy malicious guidance. In this work, we introduce a novel jailbreak framework: Multi-Modal Linkage (MML) Attack. Drawing inspiration from cryptography, MML employs an encryption-decryption process across text and image modalities to mitigate the over-exposure of malicious information. To covertly align the model's output with harmful objectives, MML leverages a technique we term evil alignment, framing the attack within the narrative context of a video game development scenario. Extensive experiments validate the effectiveness of MML. Specifically, MML jailbreaks GPT-4o with attack success rates of 99.40% on SafeBench, 98.81% on MM-SafeBench, and 99.07% on HADES-Dataset. Our code is available at https://github.com/wangyu-ovo/MML",
    "checked": true,
    "id": "ed1edc7bdfa7f9badb042a285d5e486ba0d48972",
    "semantic_title": "jailbreak large vision-language models through multi-modal linkage",
    "citation_count": 9,
    "authors": [
      "Yu Wang",
      "Xiaofei Zhou",
      "Yichen Wang",
      "Geyuan Zhang",
      "Tianxing He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.75": {
    "title": "Wait, that's not an option: LLMs Robustness with Incorrect Multiple-Choice Options",
    "volume": "long",
    "abstract": "This work introduces a novel framework for evaluating LLMs' capacity to balance instruction-following with critical reasoning when presented with multiple-choice questions containing no valid answers. Through systematic evaluation across arithmetic, domain-specific knowledge, and high-stakes medical decision tasks, we demonstrate that post-training aligned models often default to selecting invalid options, while base models exhibit improved refusal capabilities that scale with model size. Our analysis reveals that alignment techniques, though intended to enhance helpfulness, can inadvertently impair models' reflective judgment–the ability to override default behaviors when faced with invalid options. We additionally conduct a parallel human study showing similar instruction-following biases, with implications for how these biases may propagate through human feedback datasets used in alignment. We provide extensive ablation studies examining the impact of model size, training techniques, and prompt engineering. Our findings highlight fundamental tensions between alignment optimization and preservation of critical reasoning capabilities, with important implications for developing more robust AI systems for real-world deployment",
    "checked": true,
    "id": "d10c90ffe0e42acc63e6034d3dcf18bb31d1107f",
    "semantic_title": "wait, that's not an option: llms robustness with incorrect multiple-choice options",
    "citation_count": 1,
    "authors": [
      "Gracjan Góral",
      "Emilia Wiśnios",
      "Piotr Sankowski",
      "Paweł Budzianowski"
    ]
  },
  "https://aclanthology.org/2025.acl-long.76": {
    "title": "The Hidden Attention of Mamba Models",
    "volume": "long",
    "abstract": "The Mamba layer offers an efficient selective state-space model (SSM) that is highly effective in modeling multiple domains, includingNLP, long-range sequence processing, and computer vision. Selective SSMs are viewed as dual models, in which one trains in parallel on the entire sequence via an IO-aware parallel scan, and deploys in an autoregressive manner. We add a third view and show that such models can be viewed as attention-driven models. This new perspective enables us to empirically and theoretically compare the underlying mechanisms to that of the attention in transformers and allows us to peer inside the inner workings of the Mamba model with explainability methods. Our code is publicly available",
    "checked": true,
    "id": "26e6cd121c5fdb147df83cb848e4813c926737c8",
    "semantic_title": "the hidden attention of mamba models",
    "citation_count": 64,
    "authors": [
      "Ameen Ali Ali",
      "Itamar Zimerman",
      "Lior Wolf"
    ]
  },
  "https://aclanthology.org/2025.acl-long.77": {
    "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding",
    "volume": "long",
    "abstract": "Large language models (LLMs) based on Transformer Decoders have become the preferred choice for conversational generative AI. Despite the overall superiority of the Decoder architecture, the gradually increasing Key-Value (KV) cache during inference has emerged as a primary efficiency bottleneck, both in aspects of memory consumption and data transfer bandwidth limitations. To address these challenges, we propose a paradigm called KV-Latent. By down-sampling the Key-Value vector dimensions into a latent space, we can significantly reduce the KV Cache footprint and improve inference speed, only with a small amount of extra training, less than 1% of pre-training takes. Besides, we enhanced the stability of Rotary Positional Embedding applied on lower-dimensional vectors by modifying its frequency sampling mechanism, avoiding noise introduced by higher frequencies while retaining position attenuation. Our experiments, including both models with Grouped Query Attention and those without, have yielded satisfactory results. Finally, we conducted comparative experiments to study the impact of separately reducing Key and Value components on model's performance. Our approach allows for the construction of more efficient language model systems, and opens the new possibility on KV Cache saving and efficient LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shi Luohe",
      "Zuchao Li",
      "Lefei Zhang",
      "Baoyuan Qi",
      "Liu Guoming",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.78": {
    "title": "LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models for code often entail significant computational complexity, which grows significantly with the length of the input code sequence. We propose LeanCode for code simplification to reduce training and prediction time, leveraging code contexts in utilizing attention scores to represent the tokens' importance. We advocate for the selective removal of tokens based on the average context-aware attention scores rather than average scores across all inputs. LeanCode uses the attention scores of ‘CLS' tokens within the encoder for classification tasks, such as code search. It also employs the encoder-decoder attention scores to determine token significance for sequence-to-sequence tasks like code summarization. Our evaluation shows LeanCode‘s superiority over the SOTAs DietCode and SlimCode, with improvements of 60% and 16% for code search, and 29% and 27% for code summarization, respectively",
    "checked": true,
    "id": "35c2fb6a499fde19f074d7aa4d5aad0e516edf46",
    "semantic_title": "leancode: understanding models better for code simplification of pre-trained large language models",
    "citation_count": 0,
    "authors": [
      "Yan Wang",
      "Ling Ding",
      "Tien N Nguyen",
      "Shaohua Wang",
      "Yanan Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.79": {
    "title": "MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset",
    "volume": "long",
    "abstract": "To enable Large Language Models (LLMs) to function as conscious agents with generalizable reasoning capabilities, it is crucial that they possess the ability to ***comprehend situational changes (transitions) in distribution*** triggered by environmental factors or actions from other agents. Despite its fundamental significance, this ability remains underexplored due to the complexity of modeling infinite possible changes in an event and their associated distributions, coupled with the lack of benchmark data with situational transitions. Addressing these gaps, we propose a novel formulation of ***reasoning with distributional changes as a three-step discriminative process***, termed as ***MetAphysical ReaSoning***. We then introduce the first-ever benchmark, **MARS**, comprising three tasks corresponding to each step. These tasks systematically assess LLMs' capabilities in reasoning the plausibility of (i) changes in actions, (ii) states caused by changed actions, and (iii) situational transitions driven by changes in action. Extensive evaluations with 20 (L)LMs of varying sizes and methods indicate that all three tasks in this process pose significant challenges, even after fine-tuning. Further analyses reveal potential causes for the underperformance of LLMs and demonstrate that pre-training on large-scale conceptualization taxonomies can potentially enhance LMs' metaphysical reasoning capabilities. Our data and models are publicly accessible at https://github.com/HKUST-KnowComp/MARS",
    "checked": true,
    "id": "6d4d3927b80a5ff60df4b79a5c129316128a03f5",
    "semantic_title": "mars: benchmarking the metaphysical reasoning abilities of language models with a multi-task evaluation dataset",
    "citation_count": 10,
    "authors": [
      "Weiqi Wang",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.acl-long.80": {
    "title": "Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions",
    "volume": "long",
    "abstract": "The rise of large language models (LLMs) offers new opportunities for automatic error detection in education, particularly for math word problems (MWPs). While prior studies demonstrate the promise of LLMs as error detectors, they overlook the presence of multiple valid solutions for a single MWP. Our preliminary analysis reveals a significant performance gap between conventional and alternative solutions in MWPs, a phenomenon we term conformity bias in this work. To mitigate this bias, we introduce the Ask-Before-Detect (AskBD) framework, which generates adaptive reference solutions using LLMs to enhance error detection. Experiments on 200 examples of GSM8K show that AskBD effectively mitigates bias and improves performance, especially when combined with reasoning-enhancing techniques like chain-of-thought prompting",
    "checked": true,
    "id": "ec0625a411312be94a7cf51133e7a49722d6cd19",
    "semantic_title": "ask-before-detection: identifying and mitigating conformity bias in llm-powered error detector for math word problem solutions",
    "citation_count": 0,
    "authors": [
      "Hang Li",
      "Tianlong Xu",
      "Kaiqi Yang",
      "Yucheng Chu",
      "Yanling Chen",
      "Yichi Song",
      "Qingsong Wen",
      "Hui Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.81": {
    "title": "Real-time Factuality Assessment from Adversarial Feedback",
    "volume": "long",
    "abstract": "We show that existing evaluations for assessing the factuality of news from conventional sources, such as claims on fact-checking websites, result in high accuracies over time for LLM-based detectors—even after their knowledge cutoffs. This suggests that recent popular false information from such sources can be easily identified due to its likely presence in pre-training/retrieval corpora or the emergence of salient, yet shallow, patterns in these datasets. Instead, we argue that a proper factuality evaluation dataset should test a model's ability to reason about current events by retrieving and reading related evidence. To this end, we develop a novel pipeline that leverages natural language feedback from a RAG-based detector to iteratively modify real-time news into deceptive variants that challenge LLMs. Our iterative rewrite decreases the binary classification ROC-AUC by an absolute 17.5 percent for a strong RAG-based GPT-4o detector. Our experiments reveal the important role of RAG in both evaluating and generating challenging news examples, as retrieval-free LLM detectors are vulnerable to unseen events and adversarial attacks, while feedback from RAG-based evaluation helps discover more deceitful patterns",
    "checked": false,
    "id": "81508c379713a157a4c5537852656a2aea3c54d2",
    "semantic_title": "real-time fake news from adversarial feedback",
    "citation_count": 0,
    "authors": [
      "Sanxing Chen",
      "Yukun Huang",
      "Bhuwan Dhingra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.82": {
    "title": "Improve Vision Language Model Chain-of-thought Reasoning",
    "volume": "long",
    "abstract": "Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial for improving interpretability and trustworthiness. However, current training recipes often relying on datasets dominated by short annotations with minimal rationales. In this work, we show that training VLM on short answers leads to poor generalization on reasoning tasks that require more detailed explanations. To address this limitation, we propose a two-stage post-training strategy that extends the usage of short answer data for enhanced CoT reasoning. First, we augment short answers with CoT reasoning generated by GPT-4o, enhancing the VLM's CoT capabilities through fine-tuning. Second, we leverage short answers as outcome rewards for reinforcement learning. Specifically, short answers are used as correctness indicators to construct positive (correct) and negative (incorrect) pairs from model-generated reasoning chains. These pairs are then used to calibrate the model's reasoning via Direct Preference Optimization. Our experiments show significant improvements in CoT reasoning on benchmark datasets, along with enhanced generalization to direct answer prediction. This work provides a critical data resource for VLM CoT training and demonstrates the effectiveness of outcome rewards for multimodal models post-training",
    "checked": true,
    "id": "d27b8bb0aa2775c270d6f4edc2f32437aae20afc",
    "semantic_title": "improve vision language model chain-of-thought reasoning",
    "citation_count": 47,
    "authors": [
      "Ruohong Zhang",
      "Bowen Zhang",
      "Yanghao Li",
      "Haotian Zhang",
      "Zhiqing Sun",
      "Zhe Gan",
      "Yinfei Yang",
      "Ruoming Pang",
      "Yiming Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.83": {
    "title": "On the Mutual Influence of Gender and Occupation in LLM Representations",
    "volume": "long",
    "abstract": "We examine LLM representations of gender for first names in various occupational contexts to study how occupations and the gender perception of first names in LLMs influence each other mutually. We find that LLMs' first-name gender representations correlate with real-world gender statistics associated with the name, and are influenced by the co-occurrence of stereotypically feminine or masculine occupations. Additionally, we study the influence of first-name gender representations on LLMs in a downstream occupation prediction task and their potential as an internal metric to identify extrinsic model biases. While feminine first-name embeddings often raise the probabilities for female-dominated jobs (and vice versa for male-dominated jobs), reliably using these internal gender representations for bias detection remains challenging",
    "checked": true,
    "id": "7c8f623f131e9784380f8072261ede4072bb4aa3",
    "semantic_title": "on the mutual influence of gender and occupation in llm representations",
    "citation_count": 1,
    "authors": [
      "Haozhe An",
      "Connor Baumler",
      "Abhilasha Sancheti",
      "Rachel Rudinger"
    ]
  },
  "https://aclanthology.org/2025.acl-long.84": {
    "title": "Disentangling Memory and Reasoning Ability in Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have demonstrated strong performance in handling complex tasks that require both extensive knowledge and reasoning abilities. However, the existing LLM inference pipeline operates as an opaque process without explicit separation between knowledge retrieval and reasoning steps, making the model's decision-making process unclear and disorganized. Recent research has shown that this ambiguity will lead to issues such as knowledge forgetting, which significantly impact the reliability of LLMs. In this paper, we propose a novel language model inference paradigm that decomposes the complex inference process into two distinct and clear actions: (1) memory recall: which retrieves relevant knowledge in LLM, and (2) reasoning: which performs reasoning steps based on the recalled knowledge. To facilitate this decomposition, we introduce two special tokens memory and reason, guiding the model to distinguish between steps that require knowledge retrieval and those that involve reasoning. Our experiment results show that this decomposition not only improves LLMs' performance among utility benchmarks but also enhances interpretability during the inference process, enabling users to identify sources of error and refine model responses effectively. The code is available at: https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning",
    "checked": true,
    "id": "fb49f485dc3652f5d5ece8f259cb46a83891d7dd",
    "semantic_title": "disentangling memory and reasoning ability in large language models",
    "citation_count": 10,
    "authors": [
      "Mingyu Jin",
      "Weidi Luo",
      "Sitao Cheng",
      "Xinyi Wang",
      "Wenyue Hua",
      "Ruixiang Tang",
      "William Yang Wang",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.85": {
    "title": "Open-World Attribute Mining for E-Commerce Products with Multimodal Self-Correction Instruction Tuning",
    "volume": "long",
    "abstract": "In e-commerce, effective product Attribute Mining (AM) is essential for improving product features and aiding consumer decisions. However, current AM methods often focus on extracting attributes from unimodal text, underutilizing multimodal data. In this paper, we propose a novel framework called Multimodal Self-Correction Instruction Tuning (MSIT) to mine new potential attributes from both images and text with Multimodal Large Language Models. The tuning process involves two datasets: Attribute Generation Tuning Data (AGTD) and Chain-of-Thought Tuning Data (CTTD). AGTD is constructed utilizing in-context learning with a small set of seed attributes, aiding the MLLM in accurately extracting attribute-value pairs from multimodal information. To introduce explicit reasoning and improve the extraction in accuracy, we construct CTTD, which incorporates a structured 5-step reasoning process for self-correction. Finally, we employ a 3-stage inference process to filter out redundant attributes and sequentially validate each generated attribute. Comprehensive experimental results on two datasets show that MSIT outperforms state-of-the-art methods. We will release our code and data in the near future",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Li",
      "Yanming Li",
      "Xiaoli Shen",
      "Chuanyi Zhang",
      "Guilin Qi",
      "Sheng Bi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.86": {
    "title": "Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attributions Explainability",
    "volume": "long",
    "abstract": "Deep neural network predictions are notoriously difficult to interpret. Feature attribution methods aim to explain these predictions by identifying the contribution of each input feature. Faithfulness, often evaluated using the area over the perturbation curve (AOPC), reflects feature attributions' accuracy in describing the internal mechanisms of deep neural networks. However, many studies rely on AOPC to compare faithfulness across different models, which we show can lead to false conclusions about models' faithfulness. Specifically, we find that AOPC is sensitive to variations in the model, resulting in unreliable cross-model comparisons. Moreover, AOPC scores are difficult to interpret in isolation without knowing the model-specific lower and upper limits. To address these issues, we propose a normalization approach, Normalized AOPC (NAOPC), enabling consistent cross-model evaluations and more meaningful interpretation of individual scores. Our experiments demonstrate that this normalization can radically change AOPC results, questioning the conclusions of earlier studies and offering a more robust framework for assessing feature attribution faithfulness. Our code is available at https://github.com/JoakimEdin/naopc",
    "checked": false,
    "id": "3967e050023ea8893ad95afd0dc4f46412971987",
    "semantic_title": "normalized aopc: fixing misleading faithfulness metrics for feature attribution explainability",
    "citation_count": 4,
    "authors": [
      "Joakim Edin",
      "Andreas Geert Motzfeldt",
      "Casper L. Christensen",
      "Tuukka Ruotsalo",
      "Lars Maaløe",
      "Maria Maistro"
    ]
  },
  "https://aclanthology.org/2025.acl-long.87": {
    "title": "Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling",
    "volume": "long",
    "abstract": "Expressive zero-shot voice conversion (VC) is a critical and challenging task that aims to transform the source timbre into an arbitrary unseen speaker while preserving the original content and expressive qualities. Despite recent progress in zero-shot VC, there remains considerable potential for improvements in speaker similarity and speech naturalness. Moreover, existing zero-shot VC systems struggle to fully reproduce paralinguistic information in highly expressive speech, such as breathing, crying, and emotional nuances, limiting their practical applicability. To address these issues, we propose Takin-VC, a novel expressive zero-shot VC framework via adaptive hybrid content encoding and memory-augmented context-aware timbre modeling. Specifically, we introduce an innovative hybrid content encoder that incorporates an adaptive fusion module, capable of effectively integrating quantized features of the pre-trained WavLM and HybridFormer in an implicit manner, so as to extract precise linguistic features while enriching paralinguistic elements. For timbre modeling, we propose advanced memory-augmented and context-aware modules to generate high-quality target timbre features and fused representations that seamlessly align source content with target timbre. To enhance real-time performance, we advocate a conditional flow matching model to reconstruct the Mel-spectrogram of the source speech. Experimental results show that our Takin-VC consistently surpasses state-of-the-art VC systems, achieving notable improvements in terms of speech naturalness, speech expressiveness, and speaker similarity, while offering enhanced inference speed",
    "checked": true,
    "id": "a134f7f85d0b8165053ae1b8d597364f13e7dc21",
    "semantic_title": "takin-vc: expressive zero-shot voice conversion via adaptive hybrid content encoding and enhanced timbre modeling",
    "citation_count": 2,
    "authors": [
      "Yang Yuguang",
      "Yu Pan",
      "Jixun Yao",
      "Xiang Zhang",
      "Jianhao Ye",
      "Hongbin Zhou",
      "Lei Xie",
      "Lei Ma",
      "Jianjun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.88": {
    "title": "LangSAMP: Language-Script Aware Multilingual Pretraining",
    "volume": "long",
    "abstract": "Recent multilingual pretrained language models (mPLMs) often avoid using language embeddings – learnable vectors assigned to individual languages. However, this places a significant burden on token representations to encode all language-specific information, which may hinder language neutrality. To address this limitation, we propose Language-Script Aware Multilingual Pretraining (LangSAMP), a method that incorporates both language and script embeddings to enhance representation learning. Specifically, we integrate these embeddings into the output of the Transformer blocks before passing the final representations to the language modeling head for prediction. We apply LangSAMP to the continual pretraining of XLM-R on a highly multilingual corpus covering more than 500 languages. The resulting model consistently outperforms the baseline in zero-shot crosslingual transfer across diverse downstream tasks. Extensive analysis reveals that language and script embeddings capture language- and script-specific nuances, which benefits more language-neutral representations, proven by improved pairwise cosine similarity. In our case study, we also show that language and script embeddings can be used to select better source languages for crosslingual transfer. We make our code and models publicly available at https://github.com/cisnlp/LangSAMP",
    "checked": true,
    "id": "35c38a09e9a9ef34d234112b9bb3eb8ff0085bab",
    "semantic_title": "langsamp: language-script aware multilingual pretraining",
    "citation_count": 0,
    "authors": [
      "Yihong Liu",
      "Haotian Ye",
      "Chunlan Ma",
      "Mingyang Wang",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.acl-long.89": {
    "title": "RelationalCoder: Rethinking Complex Tables via Programmatic Relational Transformation",
    "volume": "long",
    "abstract": "Semi-structured tables, with their varied layouts and formatting artifacts, remain a major obstacle for automated data processing and analytics. To address these challenges, we propose RelationalCoder, which uniformly converts semi-structured tables into relational data, enabling smooth integration with the rich ecosystem of data processing and analytics tools. By leveraging SQL code, RelationalCoder prevents schema errors and markedly improves normalization quality across multiple relational tables.To address the challenge of large tables, we propose a new technique called Loop Reference Decoding (LRD): it identifies expandable groups—repeating regions of similar structure and semantics—and replicates each group using a concise loop over its repetitive region by referencing cell addresses, rather than regenerating each individual cell. This design substantially reduces output length from 𝒪(N × M)—proportional to the table's height (N) and width (M)—to approximately 𝒪(K), where K is the total number of unique cell types within detected expandable groups. As a result, LRD is highly scalable: the larger the input table, the greater the compression ratio. It scales seamlessly to extremely large tables, achieving output reductions of up to 100,000×.We further create the first human-labeled corpus for table transformation, created with a cost-efficient, actively supervised pipeline. Extensive experiments on HiTab and MultiHiertt show that RelationalCoder not only enables programmatic symbolic reasoning but also boosts QA accuracy—raising Llama-2 and Mistral models by more than 20%, and GPT-4o by over 4%. Project page: https://github.com/haoyudong/RelationalCoder",
    "checked": true,
    "id": "7ca3b61c0fc1b30fce6b89a7898cfc9f3da15dfd",
    "semantic_title": "relationalcoder: rethinking complex tables via programmatic relational transformation",
    "citation_count": 0,
    "authors": [
      "Haoyu Dong",
      "Yue Hu",
      "Huailiang Peng",
      "Yanan Cao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.90": {
    "title": "Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study",
    "volume": "long",
    "abstract": "In recent research, large language models (LLMs) have been increasingly used to investigate public opinions. This study investigates the algorithmic fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and nuanced opinions of human participants. Using open-ended survey data from the German Longitudinal Election Studies (GLES), we prompt different LLMs to generate synthetic public opinions reflective of German subpopulations by incorporating demographic features into the persona prompts. Our results show that Llama performs better than other LLMs at representing subpopulations, particularly when there is lower opinion diversity within those groups. Our findings further reveal that the LLM performs better for supporters of left-leaning parties like The Greens and The Left compared to other parties, and matches the least with the right-party AfD. Additionally, the inclusion or exclusion of specific variables in the prompts can significantly impact the models' predictions. These findings underscore the importance of aligning LLMs to more effectively model diverse public opinions while minimizing political biases and enhancing robustness in representativeness",
    "checked": true,
    "id": "17d898ea659dccedd58e0d124cf47f00a77e450a",
    "semantic_title": "algorithmic fidelity of large language models in generating synthetic german public opinions: a case study",
    "citation_count": 1,
    "authors": [
      "Bolei Ma",
      "Berk Yoztyurk",
      "Anna-Carolina Haensch",
      "Xinpeng Wang",
      "Markus Herklotz",
      "Frauke Kreuter",
      "Barbara Plank",
      "Matthias Aßenmacher"
    ]
  },
  "https://aclanthology.org/2025.acl-long.91": {
    "title": "TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos",
    "volume": "long",
    "abstract": "Videos are unique in their integration of temporal elements, including camera, scene, action, and attribute, along with their dynamic relationships over time. However, existing benchmarks for video understanding often treat these properties separately or narrowly focus on specific aspects, overlooking the holistic nature of video content. To address this, we introduce TUNA, a temporal-oriented benchmark for fine-grained understanding on dense dynamic videos, with two complementary tasks: captioning and QA. Our TUNA features diverse video scenarios and dynamics, assisted by interpretable and robust evaluation criteria. We evaluate several leading models on our benchmark, providing fine-grained performance assessments across various dimensions. This evaluation reveals key challenges in video temporal understanding, such as limited action description, inadequate multi-subject understanding, and insensitivity to camera motion, offering valuable insights for improving video understanding models",
    "checked": true,
    "id": "3452df196f838dc17667bd416d2eb6fc3f246e08",
    "semantic_title": "tuna: comprehensive fine-grained temporal understanding evaluation on dense dynamic videos",
    "citation_count": 1,
    "authors": [
      "Fanheng Kong",
      "Jingyuan Zhang",
      "Hongzhi Zhang",
      "Shi Feng",
      "Daling Wang",
      "Linhao Yu",
      "Xingguang Ji",
      "Yu Tian",
      "V. W.",
      "Fuzheng Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.92": {
    "title": "Self-Instructed Derived Prompt Generation Meets In-Context Learning: Unlocking New Potential of Black-Box LLMs",
    "volume": "long",
    "abstract": "Improving prompt quality is crucial for enhancing the performance of large language models (LLMs), particularly for Black-Box models like GPT4. Existing prompt refinement methods, while effective, often suffer from semantic inconsistencies between refined and original prompts, and fail to maintain users' real intent. To address these challenges, we propose a self-instructed in-context learning framework that generates reliable derived prompts, keeping semantic consistency with the original prompts. Specifically, our framework incorporates a reinforcement learning mechanism, enabling direct interaction with the response model during prompt generation to better align with human preferences. We then formulate the querying as an in-context learning task, combining responses from LLMs with derived prompts to create a contextual demonstration for the original prompt. This approach effectively enhances alignment, reduces semantic discrepancies, and activates the LLM's in-context learning ability for generating more beneficial response. Extensive experiments demonstrate that the proposed method not only generates better derived prompts but also significantly enhances LLMs' ability to deliver more effective responses, particularly for Black-Box models like GPT4",
    "checked": true,
    "id": "9733fef11486689b7716963e0d9ff98b3af75935",
    "semantic_title": "self-instructed derived prompt generation meets in-context learning: unlocking new potential of black-box llms",
    "citation_count": 2,
    "authors": [
      "Zhuo Li",
      "Yuhao Du",
      "Jinpeng Hu",
      "Xiang Wan",
      "Anningzhe Gao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.93": {
    "title": "Binary Classifier Optimization for Large Language Model Alignment",
    "volume": "long",
    "abstract": "In real-world services such as ChatGPT, aligning models based on user feedback is crucial for improving model performance. However, due to the simplicity and convenience of providing feedback, users typically offer only basic binary signals, such as ‘thumbs-up' or ‘thumbs-down'. Most existing alignment research, on the other hand, relies on preference-based approaches that require both positive and negative responses as a pair. We propose Binary Classifier Optimization (BCO), a technique that effectively aligns LLMs using only binary feedback. BCO trains a binary classifier, where the logit serves as an implicit reward, effectively minimizing the Direct Preference Optimization (DPO) loss. We demonstrate that the binary cross-entropy loss employed in classifier training acts as an upper bound for the DPO loss. Additionally, a novel reward shift technique further minimizes the gap between the losses. We validate our methodology in two settings: first, on a paired preference dataset, where our method performs on par with DPO; and second, on a Likert-5 scale annotation dataset which stems from real users' queries. Our model consistently demonstrates effective and robust alignment across four base LLMs and three different datasets, showcasing the strength of our approach to learning from binary signals",
    "checked": true,
    "id": "97dc1b2b7910c7a946fead4fe6b53240b398301a",
    "semantic_title": "binary classifier optimization for large language model alignment",
    "citation_count": 25,
    "authors": [
      "Seungjae Jung",
      "Gunsoo Han",
      "Daniel Wontae Nam",
      "Kyoung-Woon On"
    ]
  },
  "https://aclanthology.org/2025.acl-long.94": {
    "title": "UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs' Memorization",
    "volume": "long",
    "abstract": "This paper introduces UnSeenTimeQA, a novel data contamination-free time-sensitive question-answering (TSQA) benchmark. It differs from existing TSQA benchmarks by avoiding web-searchable queries grounded in the real world. We present a series of time-sensitive event scenarios based on synthetically generated facts. It requires large language models (LLMs) to engage in genuine temporal reasoning without depending on the factual knowledge acquired during the pre-training phase. Our data generation framework enables on-demand generation of new samples, mitigating the risk of data leakage. We designed three types of time-sensitive questions to test LLMs' temporal reasoning abilities over sequential and parallel event occurrences. Our evaluation of five LLMs on synthetic fact-based TSQA reveals mixed results: while they perform well on simpler subsets, their overall performance remains inferior as compared to real world fact-based TSQA. Error analysis indicates that LLMs face difficulties in reasoning over long-range event dependencies and parallel events",
    "checked": true,
    "id": "d73b8de6a5d4a4a80fc14059a4538e46c1453ee6",
    "semantic_title": "unseentimeqa: time-sensitive question-answering beyond llms' memorization",
    "citation_count": 4,
    "authors": [
      "Md Nayem Uddin",
      "Amir Saeidi",
      "Divij Handa",
      "Agastya Seth",
      "Tran Cao Son",
      "Eduardo Blanco",
      "Steven Corman",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2025.acl-long.95": {
    "title": "From Information to Insight: Leveraging LLMs for Open Aspect-Based Educational Summarization",
    "volume": "long",
    "abstract": "This paper addresses the challenge of aspect-based summarization in education by introducing Reflective ASPect-based summarization (ReflectASP), a novel dataset that summarizes student reflections on STEM lectures. Despite the promising performance of large language models in general summarization, their application to nuanced aspect-based summaries remains under-explored. ReflectASP eases the exploration of open-aspect-based summarization (OABS), overcoming the limitations of current datasets and comes with ample human annotations. We benchmarked different types of zero-shot summarization methods and proposed two refinement methods to improve summaries, supported by both automatic and human manual evaluations. Additionally, we analyzed suggestions and revisions made during the refinement process, offering a fine-grained study of the editing strategies employed by these methods. We make our models, dataset, and all human evaluation results available at https://github.com/cs329yangzhong/ReflectASP",
    "checked": false,
    "id": "6fee80fb0dd8a566c09357fcb015e60ce92a6673",
    "semantic_title": "leveraging the power of llms: a fine-tuning approach for high-quality aspect-based summarization",
    "citation_count": 0,
    "authors": [
      "Yang Zhong",
      "Diane Litman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.96": {
    "title": "AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset",
    "volume": "long",
    "abstract": "Recent advancements in large language model (LLM) performance on medical multiplechoice question (MCQ) benchmarks have stimulated interest from healthcare providers and patients globally. Particularly in low-andmiddle-income countries (LMICs) facing acute physician shortages and lack of specialists, LLMs offer a potentially scalable pathway to enhance healthcare access and reduce costs. However, their effectiveness in the Global South, especially across the African continent, remains to be established. In this work, we introduce AfriMed-QA , the first largescale Pan-African English multi-specialty medical Question-Answering (QA) dataset, 15,000 questions (open and closed-ended) sourced from over 60 medical schools across 16 countries, covering 32 medical specialties. We further evaluate 30 LLMs across multiple axes including correctness and demographic bias. Our findings show significant performance variation across specialties and geographies, MCQ performance clearly lags USMLE (MedQA). We find that biomedical LLMs underperform general models and smaller edge-friendly LLMs struggle to achieve a passing score. Interestingly, human evaluations show a consistent consumer preference for LLM answers and explanations when compared with clinician answers",
    "checked": true,
    "id": "24353a793b7bc5ff36728b422c073d2b96e84174",
    "semantic_title": "afrimed-qa: a pan-african, multi-specialty, medical question-answering benchmark dataset",
    "citation_count": 3,
    "authors": [
      "Charles Nimo",
      "Tobi Olatunji",
      "Abraham Toluwase Owodunni",
      "Tassallah Abdullahi",
      "Emmanuel Ayodele",
      "Mardhiyah Sanni",
      "Ezinwanne C. Aka",
      "Folafunmi Omofoye",
      "Foutse Yuehgoh",
      "Timothy Faniran",
      "Bonaventure F. P. Dossou",
      "Moshood O. Yekini",
      "Jonas Kemp",
      "Katherine A Heller",
      "Jude Chidubem Omeke",
      "Chidi Asuzu Md",
      "Naome A Etori",
      "Aïmérou Ndiaye",
      "Ifeoma Okoh",
      "Evans Doe Ocansey",
      "Wendy Kinara",
      "Michael L. Best",
      "Irfan Essa",
      "Stephen Edward Moore",
      "Chris Fourie",
      "Mercy Nyamewaa Asiedu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.97": {
    "title": "Root Defense Strategies: Ensuring Safety of LLM at the Decoding Level",
    "volume": "long",
    "abstract": "Large language models (LLMs) have demonstrated immense utility across various industries. However, as LLMs advance, the risk of harmful outputs increases due to incorrect or malicious prompts. While current methods effectively address jailbreak risks, they share common limitations: 1) Judging harmful outputs from the prefill-level lacks utilization of the model's decoding outputs, leading to relatively lower effectiveness and robustness. 2) Rejecting potentially harmful outputs based on a single evaluation can significantly impair the model's helpfulness. To address the above issues, we examine LLMs' capability to recognize harmful outputs, revealing and quantifying their proficiency in assessing the danger of previous tokens. Motivated by pilot experiment results, we design a robust defense mechanism at the decoding level. Our novel decoder-oriented, step-by-step defense architecture corrects the outputs of harmful queries directly rather than rejecting them outright. We introduce speculative decoding to enhance usability and facilitate deployment to boost safe decoding speed. Extensive experiments demonstrate that our approach improves model security without compromising reasoning speed. Notably, our method leverages the model's ability to discern hazardous information, maintaining its helpfulness compared to existing methods",
    "checked": false,
    "id": "96f9ed594ab9848591d71d5d7bb7d2b15f95aca4",
    "semantic_title": "root defence strategies: ensuring safety of llm at the decoding level",
    "citation_count": 4,
    "authors": [
      "Xinyi Zeng",
      "Yuying Shang",
      "Jiawei Chen",
      "Jingyuan Zhang",
      "Yu Tian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.98": {
    "title": "In-the-wild Audio Spatialization with Flexible Text-guided Localization",
    "volume": "long",
    "abstract": "Binaural audio enriches immersive experiences by enabling the perception of the spatial locations of sounding objects in AR, VR, and embodied AI applications. While existing audio spatialization methods can generally map any available monaural audio to binaural audio signals, they often lack the flexible and interactive control needed in complex multi-object user-interactive environments. To address this, we propose a Text-guided Audio Spatialization (TAS) framework that utilizes diverse text prompts and evaluates our model from unified generation and comprehension perspectives. Due to the limited availability of high-quality, large-scale stereo data, we construct the SpatialTAS dataset, which encompasses 376,000 simulated binaural audio samples to facilitate the training of our model. Our model learns binaural differences guided by 3D spatial location and relative position prompts, enhanced with flipped-channel audio. Experimental results show that our model can generate high quality binaural audios for various audio types on both simulated and real-recorded datasets. Besides, we establish an assessment model based on Llama-3.1-8B, which evaluates the semantic accuracy of spatial locations through a spatial reasoning task. Results demonstrate that by utilizing text prompts for flexible and interactive control, we can generate binaural audio with both high quality and semantic consistency in spatial locations",
    "checked": true,
    "id": "84041be6407c69714601cfbd8c539bbd92a0121d",
    "semantic_title": "in-the-wild audio spatialization with flexible text-guided localization",
    "citation_count": 0,
    "authors": [
      "Tianrui Pan",
      "Jie Liu",
      "Zewen Huang",
      "Jie Tang",
      "Gangshan Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.99": {
    "title": "L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models",
    "volume": "long",
    "abstract": "Due to the high memory and computational costs associated with large language models (LLMs), model compression techniques such as quantization, which reduces inference costs, and parameter-efficient fine-tuning (PEFT) methods like Low-Rank Adaptation (LoRA), which reduce training costs, have gained significant popularity. This trend has spurred active research into quantization-aware PEFT techniques, aimed at maintaining model accuracy while minimizing memory overhead during both inference and training. Previous quantization-aware PEFT methods typically apply post-training quantiation (PTQ) to pre-trained LLMs, followed by PEFT to recover accuracy loss. Meanwhile, this approach has limitations in recovering the accuracy loss. In this paper, we propose L4Q, a method that integrates Quantization-Aware Training (QAT) with LoRA. By employing a memory-optimized layer design, L4Q significantly reduces QAT's memory overhead, making its training cost comparable to LoRA, while preserving the advantage of QAT in producing fully quantized LLMs with high accuracy. Our experiments demonstrate that this combined approach to quantization and fine-tuning achieves superior accuracy compared to decoupled fine-tuning schemes, particularly in 4-bit and 3-bit quantization, positioning L4Q as an efficient QAT solution. Using the LLaMA and Mistral models with instructional datasets, we showcase L4Q's capabilities in language tasks and few-shot learning",
    "checked": true,
    "id": "f06191042e5b20b7d18672fbe9fc85f7b1bc4dfd",
    "semantic_title": "l4q: parameter efficient quantization-aware fine-tuning on large language models",
    "citation_count": 5,
    "authors": [
      "Hyesung Jeon",
      "Yulhwa Kim",
      "Jae-Joon Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.100": {
    "title": "Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion",
    "volume": "long",
    "abstract": "This paper addresses the critical need for democratizing large language models (LLM) in the Arab world, a region that has seen slower progress in developing models comparable to state-of-the-art offerings like GPT-4 or GPT-3.5, due to a predominant focus on mainstream languages (e.g., English and Chinese). One practical objective for Arabic LLMs is to utilize Arabic-specific vocabulary in the tokenizer to accelerate decoding. However, using a different vocabulary often leads to degradation of the model's learned knowledge, since many words become out-of-vocabulary (OOV) at the beginning of training. Inspired by the vocabulary learning during Second Language (Arabic) Acquisition for humans, the released AraLLaMA employs progressive vocabulary expansion, which is implemented by a modified BPE algorithm that progressively extends the Arabic subwords in its dynamic vocabulary during training, thereby balancing the OOV ratio at every stage. The ablation study demonstrated the effectiveness of Progressive Vocabulary Expansion.Moreover, AraLLaMA achieves decent performance comparable to the best Arabic LLMs across a variety of Arabic benchmarks. Our model weights are available at: https://github.com/FreedomIntelligence/AraLLaMa",
    "checked": true,
    "id": "48e3cb12bbce399a81232a22418b16439fc17dee",
    "semantic_title": "second language (arabic) acquisition of llms via progressive vocabulary expansion",
    "citation_count": 3,
    "authors": [
      "Jianqing Zhu",
      "Huang Huang",
      "Zhihang Lin",
      "Juhao Liang",
      "Zhengyang Tang",
      "Khalid Almubarak",
      "Mosen Alharthi",
      "Bang An",
      "Juncai He",
      "Xiangbo Wu",
      "Fei Yu",
      "Junying Chen",
      "Ma Zhuoheng",
      "Yuhao Du",
      "He Zhang",
      "Saied Alshahrani",
      "Emad A. Alghamdi",
      "Lian Zhang",
      "Ruoyu Sun",
      "Haizhou Li",
      "Benyou Wang",
      "Jinchao Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.101": {
    "title": "What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs",
    "volume": "long",
    "abstract": "We investigate long-context vulnerabilities in Large Language Models (LLMs) through Many-Shot Jailbreaking (MSJ). Our experiments utilize context length of up to 128K tokens. Through comprehensive analysis with various many-shot attack settings with different instruction styles, shot density, topic, and format, we reveal that context length is the primary factor determining attack effectiveness. Critically, we find that successful attacks do not require carefully crafted harmful content. Even repetitive shots or random dummy text can circumvent model safety measures, suggesting fundamental limitations in long-context processing capabilities of LLMs. The safety behavior of well-aligned models becomes increasingly inconsistent with longer contexts. These findings highlight significant safety gaps in context expansion capabilities of LLMs, emphasizing the need for new safety mechanisms",
    "checked": true,
    "id": "a2fa61583ef45801d5c18204e4bb4de875e3a9a0",
    "semantic_title": "what really matters in many-shot attacks? an empirical study of long-context vulnerabilities in llms",
    "citation_count": 0,
    "authors": [
      "Sangyeop Kim",
      "Yohan Lee",
      "Yongwoo Song",
      "Kimin Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.102": {
    "title": "ECERC: Evidence-Cause Attention Network for Multi-Modal Emotion Recognition in Conversation",
    "volume": "long",
    "abstract": "Multi-modal Emotion Recognition in Conversation (MMERC) aims to identify speakers' emotional states using multi-modal conversational data, significant for various domains. MMERC requires addressing emotional causes: contextual factors that influence emotions, alongside emotional evidence directly expressed in the target utterance. Existing methods primarily model general conversational dependencies, such as sequential utterance relationships or inter-speaker dynamics, but fall short in capturing diverse and detailed emotional causes, including emotional contagion, influences from others, and self-referenced or externally introduced events. To address these limitations, we propose the Evidence-Cause Attention Network for Multi-Modal Emotion Recognition in Conversation (ECERC). ECERC integrates emotional evidence with contextual causes through five stages: Evidence Gating extracts and refines emotional evidence across modalities; Cause Encoding captures causes from conversational context; Evidence-Cause Interaction uses attention to integrate evidence with diverse causes, generating rich candidate features for emotion inference; Feature Gating adaptively weights contributions of candidate features; and Emotion Classification classifies emotions. We evaluate ECERC on two widely used benchmark datasets, IEMOCAP and MELD. Experimental results show that ECERC achieves competitive performance in weighted F1-score and accuracy, demonstrating its effectiveness in MMERC",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Zhang",
      "Zhenhua Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.103": {
    "title": "CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System",
    "volume": "long",
    "abstract": "With open-source projects growing in size and complexity, manual compilation becomes tedious and error-prone, highlighting the need for automation to improve efficiency and accuracy. However, the complexity of compilation instruction search and error resolution makes automatic compilation challenging. Inspired by the success of LLM-based agents in various fields, we propose CompileAgent, the first LLM-based agent framework dedicated to repo-level compilation. CompileAgent integrates five tools and a flow-based agent strategy, enabling interaction with software artifacts for compilation instruction search and error resolution. To measure the effectiveness of our method, we design a public repo-level benchmark CompileAgentBench, and we also design two baselines for comparison by combining two compilation-friendly schemes. The performance on this benchmark shows that our method significantly improves the compilation success rate, ranging from 10% to 71%. Meanwhile, we evaluate the performance of CompileAgent under different agent strategies and verify the effectiveness of the flow-based strategy. Additionally, we emphasize the scalability of CompileAgent, further expanding its application prospects. The complete code and data are available at https://github.com/Ch3nYe/AutoCompiler",
    "checked": true,
    "id": "278796f521d941dca4eb26075c42ee7d4e7c2709",
    "semantic_title": "compileagent: automated real-world repo-level compilation with tool-integrated llm-based agent system",
    "citation_count": 1,
    "authors": [
      "Li Hu",
      "Guoqiang Chen",
      "Xiuwei Shang",
      "Shaoyin Cheng",
      "Benlong Wu",
      "LiGangyang LiGangyang",
      "Xu Zhu",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.104": {
    "title": "Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals' Subjective Text Perceptions",
    "volume": "long",
    "abstract": "People naturally vary in their annotations for subjective questions and some of this variation is thought to be due to the person's sociodemographic characteristics. LLMs have also been used to label data, but recent work has shown that models perform poorly when prompted with sociodemographic attributes, suggesting limited inherent sociodemographic knowledge. Here, we ask whether LLMs can be trained to be accurate sociodemographic models of annotator variation. Using a curated dataset of five tasks with standardized sociodemographics, we show that models do improve in sociodemographic prompting when trained but that this performance gain is largely due to models learning annotator-specific behaviour rather than sociodemographic behaviours. Across all tasks, our results suggest that models learn little meaningful connection between sociodemographics and annotation, raising doubts about the current use of LLMs for simulating sociodemographic variation and behaviour",
    "checked": true,
    "id": "9a39d737abc4b67a24fed22c246353335616de63",
    "semantic_title": "beyond demographics: fine-tuning large language models to predict individuals' subjective text perceptions",
    "citation_count": 3,
    "authors": [
      "Matthias Orlikowski",
      "Jiaxin Pei",
      "Paul Röttger",
      "Philipp Cimiano",
      "David Jurgens",
      "Dirk Hovy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.105": {
    "title": "Exploring Forgetting in Large Language Model Pre-Training",
    "volume": "long",
    "abstract": "Catastrophic forgetting remains a formidable obstacle to building an omniscient model in large language models (LLMs). Despite the pioneering research on task-level forgetting in LLM fine-tuning, there is scant focus on forgetting during pre-training. We systematically explored the existence and measurement of forgetting in pre-training, questioning traditional metrics such as perplexity (PPL) and introducing new metrics to better detect entity memory retention. Based on our revised assessment of forgetting metrics, we explored low-cost, straightforward methods to mitigate forgetting during the pre-training phase. In addition, we carefully analyzed the learning curves, offering insights into the dynamics of forgetting. Extensive evaluations and analyses on forgetting of pre-training could facilitate future research on LLMs",
    "checked": true,
    "id": "ff4154bfea34d70d0ed46e353c939bcf53f90a9f",
    "semantic_title": "exploring forgetting in large language model pre-training",
    "citation_count": 1,
    "authors": [
      "Chonghua Liao",
      "Ruobing Xie",
      "Xingwu Sun",
      "Haowen Sun",
      "Zhanhui Kang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.106": {
    "title": "Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks",
    "volume": "long",
    "abstract": "Large language models (LLMs) inherit biases from their training data and alignment processes, influencing their responses in subtle ways. While many studies have examined these biases, little work has explored their robustness during interactions. In this paper, we introduce a novel approach where two instances of an LLM engage in self-debate, arguing opposing viewpoints to persuade a neutral version of the model. Through this, we evaluate how firmly biases hold and whether models are susceptible to reinforcing misinformation or shifting to harmful viewpoints. Our experiments span multiple LLMs of varying sizes, origins, and languages, providing deeper insights into bias persistence and flexibility across linguistic and cultural contexts",
    "checked": false,
    "id": "ba1376ef3884eb233842c8fb7ebe82c1b384722e",
    "semantic_title": "bias in the mirror : are llms opinions robust to their own adversarial attacks ?",
    "citation_count": 0,
    "authors": [
      "Virgile Rennard",
      "Christos Xypolopoulos",
      "Michalis Vazirgiannis"
    ]
  },
  "https://aclanthology.org/2025.acl-long.107": {
    "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents",
    "volume": "long",
    "abstract": "Autonomous agents have become increasingly important for interacting with the real world. Android agents, in particular, have been a frequently-mentioned interaction method. However, existing studies for training and evaluating Android agents lack systematic research on both open-source and closed-source models. In this work, we propose AndroidLab as a systematic Android agent framework. It includes an operation environment with different modalities, action space, and a reproducible benchmark. It supports both large language models (LLMs) and multimodal models (LMMs) in the same action space. AndroidLab benchmark includes predefined Android virtual devices and 138 tasks across nine apps built on these devices. By using the AndroidLab environment, we develop an Android Instruction dataset and train six open-source LLMs and LMMs, lifting the average success rates from 4.59% to 21.50% for LLMs and from 1.93% to 13.28% for LMMs. AndroidLab is open-sourced and publicly available at https://github.com/THUDM/Android-Lab",
    "checked": true,
    "id": "d7be1db214359621d17c191cc494de8f077211f3",
    "semantic_title": "androidlab: training and systematic benchmarking of android autonomous agents",
    "citation_count": 0,
    "authors": [
      "Yifan Xu",
      "Xiao Liu",
      "Xueqiao Sun",
      "Siyi Cheng",
      "Hao Yu",
      "Hanyu Lai",
      "Shudan Zhang",
      "Dan Zhang",
      "Jie Tang",
      "Yuxiao Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.108": {
    "title": "Modular Sentence Encoders: Separating Language Specialization from Cross-Lingual Alignment",
    "volume": "long",
    "abstract": "Multilingual sentence encoders (MSEs) are commonly obtained by training multilingual language models to map sentences from different languages into a shared semantic space. As such, they are subject to curse of multilinguality, a loss of monolingual representational accuracy due to parameter sharing. Another limitation of MSEs is the trade-off between different task performance: cross-lingual alignment training distorts the optimal monolingual structure of semantic spaces of individual languages, harming the utility of sentence embeddings in monolingual tasks; cross-lingual tasks, such as cross-lingual semantic similarity and zero-shot transfer for sentence classification, may also require conflicting cross-lingual alignment strategies. In this work, we address both issues by means of modular training of sentence encoders. We first train language-specific monolingual modules to mitigate negative interference between languages (i.e., the curse). We then align all non-English sentence embeddings to the English by training cross-lingual alignment adapters, preventing interference with monolingual specialization from the first step. We train the cross-lingual adapters with two different types of data to resolve the conflicting requirements of different cross-lingual tasks. Monolingual and cross-lingual results on semantic text similarity and relatedness, bitext mining and sentence classification show that our modular solution achieves better and more balanced performance across all the tasks compared to full-parameter training of monolithic multilingual sentence encoders, especially benefiting low-resource languages",
    "checked": true,
    "id": "14a2b146508713998361ca27dc278e4d82fe390d",
    "semantic_title": "modular sentence encoders: separating language specialization from cross-lingual alignment",
    "citation_count": 1,
    "authors": [
      "Yongxin Huang",
      "Kexin Wang",
      "Goran Glavaš",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.109": {
    "title": "Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs",
    "volume": "long",
    "abstract": "Multimodal Sentiment Analysis (MSA) is a rapidly developing field that integrates multimodal information to recognize sentiments, and existing models have made significant progress in this area. The central challenge in MSA is multimodal fusion, which is predominantly addressed by Multimodal Transformers (MulTs). Although act as the paradigm, MulTs suffer from efficiency concerns. In this work, from the perspective of efficiency optimization, we propose and prove that MulTs are hierarchical modal-wise heterogeneous graphs (HMHGs), and we introduce the graph-structured representation pattern of MulTs. Based on this pattern, we propose an Interlaced Mask (IM) mechanism to design the Graph-Structured and Interlaced-Masked Multimodal Transformer (GsiT). It is formally equivalent to MulTs which achieves an efficient weight-sharing mechanism without information disorder through IM, enabling All-Modal-In-One fusion with only 1/3 of the parameters of pure MulTs. A kernel called Decomposition is implemented to ensure avoiding additional computational overhead. Moreover, it achieves significantly higher performance than traditional MulTs. To further validate the effectiveness of GsiT itself and the HMHG concept, we integrate them into multiple state-of-the-art models and demonstrate notable performance improvements and parameter reduction on widely used MSA datasets. Experimental results also demonstrate its effectiveness on other multimodal tasks. The code is available in https://github.com/drewjin/GsiT.git",
    "checked": true,
    "id": "51114a9bb274365c79be77f392b45e3c8e7a8514",
    "semantic_title": "multimodal transformers are hierarchical modal-wise heterogeneous graphs",
    "citation_count": 0,
    "authors": [
      "Yijie Jin",
      "Junjie Peng",
      "Xuanchao Lin",
      "Haochen Yuan",
      "Lan Wang",
      "Cangzhi Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.110": {
    "title": "Have We Designed Generalizable Structural Knowledge Promptings? Systematic Evaluation and Rethinking",
    "volume": "long",
    "abstract": "Large language models (LLMs) have demonstrated exceptional performance in text generation within current NLP research. However, the lack of factual accuracy is still a dark cloud hanging over the LLM skyscraper. Structural knowledge prompting (SKP) is a prominent paradigm to integrate external knowledge into LLMs by incorporating structural representations, achieving state-of-the-art results in many knowledge-intensive tasks. However, existing methods often focus on specific problems, lacking a comprehensive exploration of the generalization and capability boundaries of SKP. This paper aims to evaluate and rethink the generalization capability of the SKP paradigm from four perspectives including Granularity, Transferability, Scalability, and Universality. To provide a thorough evaluation, we introduce a novel multi-granular, multi-level benchmark called SUBARU, consisting of 9 different tasks with varying levels of granularity and difficulty. Through extensive experiments, we draw key conclusions regarding the generalization of SKP, offering insights to guide the future development and extension of the SKP paradigm",
    "checked": true,
    "id": "b6a436a8723233072744eae4119993e0d477fc7e",
    "semantic_title": "have we designed generalizable structural knowledge promptings? systematic evaluation and rethinking",
    "citation_count": 1,
    "authors": [
      "Yichi Zhang",
      "Zhuo Chen",
      "Lingbing Guo",
      "Yajing Xu",
      "Shaokai Chen",
      "Mengshu Sun",
      "Binbin Hu",
      "Zhiqiang Zhang",
      "Lei Liang",
      "Wen Zhang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.111": {
    "title": "LLäMmlein: Transparent, Compact and Competitive German-Only Language Models from Scratch",
    "volume": "long",
    "abstract": "We transparently create two German-only decoder models, LLäMmlein 120M and 1B, from scratch and publish them, along with the training data, for the (German) NLP research community to use. The model training involved several key steps, including data preprocessing/filtering, the creation of a German tokenizer, the training itself, as well as the evaluation of the final models on various benchmarks, also against existing models. Throughout the training process, multiple checkpoints were saved in equal intervals and analyzed using the German SuperGLEBer benchmark to gain insights into the models' learning process.Compared to state-of-the-art models on the SuperGLEBer benchmark, both LLäMmlein models performed competitively, consistently matching or surpassing models with similar parameter sizes. The results show that the models' quality scales with size as expected, but performance improvements on some tasks plateaued early during training, offering valuable insights into resource allocation for future models",
    "checked": false,
    "id": "4cdc8dc39657e5bc96ce15af7442f61b1a9f0103",
    "semantic_title": "ll\\\"ammlein: transparent, compact and competitive german-only language models from scratch",
    "citation_count": 0,
    "authors": [
      "Jan Pfister",
      "Julia Wunderle",
      "Andreas Hotho"
    ]
  },
  "https://aclanthology.org/2025.acl-long.112": {
    "title": "Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues",
    "volume": "long",
    "abstract": "Nonverbal communication is integral to human interaction, with gestures, facial expressions, and body language conveying critical aspects of intent and emotion. However, existing large language models (LLMs) fail to effectively incorporate these nonverbal elements, limiting their capacity to create fully immersive conversational experiences. We introduce MARS, a multimodal language model designed to understand and generate nonverbal cues alongside text, bridging this gap in conversational AI.Our key innovation is VENUS, a large-scale dataset comprising annotated videos with time-aligned text, facial expressions, and body language.Leveraging VENUS, we train MARS with a next-token prediction objective, combining text with vector-quantized nonverbal representations to achieve multimodal understanding and generation within a unified framework.Based on various analyses of the VENUS datasets, we validate its substantial scale and high effectiveness. Our quantitative and qualitative results demonstrate that MARS successfully generates text and nonverbal languages, corresponding to conversational input.Our dataset and code are available at https://github.com/winston1214/nonverbal-conversation",
    "checked": true,
    "id": "73e9cc0270fba2c5c3cf777ed114f5fe85231df4",
    "semantic_title": "speaking beyond language: a large-scale multimodal dataset for learning nonverbal cues from video-grounded dialogues",
    "citation_count": 0,
    "authors": [
      "Youngmin Kim",
      "Jiwan Chung",
      "Jisoo Kim",
      "Sunghyun Lee",
      "Sangkyu Lee",
      "Junhyeok Kim",
      "Cheoljong Yang",
      "Youngjae Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.113": {
    "title": "How Much Do Encoder Models Know About Word Senses?",
    "volume": "long",
    "abstract": "Word Sense Disambiguation (WSD) is a key task in Natural Language Processing (NLP), involving selecting the correct meaning of a word based on its context. With Pretrained Language Models (PLMs) like BERT and DeBERTa now well established, significant progress has been made in understanding contextual semantics. Nevertheless, how well these models inherently disambiguate word senses remains uncertain. In this work, we evaluate several encoder-only PLMs across two popular inventories (i.e. WordNet and the Oxford Dictionary of English) by analyzing their ability to separate word senses without any task-specific fine-tuning. We compute centroids of word senses and measure similarity to assess performance across different layers. Our results show that DeBERTa-v3 delivers the best performance on the task, with the middle layers (specifically the 7th and 8th layers) achieving the highest accuracy, outperforming the output layer by approximately 15 percentage points. Our experiments also explore the inherent structure of WordNet and ODE sense inventories, highlighting their influence on the overall model behavior and performance. Finally, based on our findings, we develop a small, efficient model for the WSD task that attains robust performance while significantly reducing the carbon footprint",
    "checked": false,
    "id": "21ecd62a1f21816e9c805d37b6dd879b3d2aba29",
    "semantic_title": "what do self-supervised speech models know about words?",
    "citation_count": 36,
    "authors": [
      "Simone Teglia",
      "Simone Tedeschi",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2025.acl-long.114": {
    "title": "When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are known to be vulnerable to backdoor attacks, where triggers embedded in poisoned samples can maliciously alter LLMs' behaviors. In this paper, we move beyond attacking LLMs and instead examine backdoor attacks through the novel lens of natural language explanations. Specifically, we leverage LLMs' generative capabilities to produce human-readable explanations for their decisions, enabling direct comparisons between explanations for clean and poisoned samples. Our results show that backdoored models produce coherent explanations for clean inputs but diverse and logically flawed explanations for poisoned data, a pattern consistent across classification and generation tasks for different backdoor attacks. Further analysis reveals key insights into the explanation generation process. At the token level, explanation tokens associated with poisoned samples only appear in the final few transformer layers. At the sentence level, attention dynamics indicate that poisoned inputs shift attention away from the original input context during explanation generation. These findings enhance our understanding of backdoor mechanisms in LLMs and present a promising framework for detecting vulnerabilities through explainability",
    "checked": true,
    "id": "a9cb46bda6502fd70070815c42e80d5ea41cb407",
    "semantic_title": "when backdoors speak: understanding llm backdoor attacks through model-generated explanations",
    "citation_count": 2,
    "authors": [
      "Huaizhi Ge",
      "Yiming Li",
      "Qifan Wang",
      "Yongfeng Zhang",
      "Ruixiang Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.115": {
    "title": "HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter",
    "volume": "long",
    "abstract": "To address the global challenge of online hate speech, prior research has developed detection models to flag such content on social media. However, due to systematic biases in evaluation datasets, the real-world effectiveness of these models remains unclear, particularly across geographies. We introduce HateDay, the first global hate speech dataset representative of social media settings, constructed from a random sample of all tweets posted on September 21, 2022 and covering eight languages and four English-speaking countries. Using HateDay, we uncover substantial variation in the prevalence and composition of hate speech across languages and regions. We show that evaluations on academic datasets greatly overestimate real-world detection performance, which we find is very low, especially for non-European languages. Our analysis identifies key drivers of this gap, including models' difficulty to distinguish hate from offensive speech and a mismatch between the target groups emphasized in academic datasets and those most frequently targeted in real-world settings. We argue that poor model performance makes public models ill-suited for automatic hate speech moderation and find that high moderation rates are only achievable with substantial human oversight. Our results underscore the need to evaluate detection systems on data that reflects the complexity and diversity of real-world social media",
    "checked": true,
    "id": "fe4b1453f5d70752323a17e596a0e8c30e4bbbe0",
    "semantic_title": "hateday: insights from a global hate speech dataset representative of a day on twitter",
    "citation_count": 2,
    "authors": [
      "Manuel Tonneau",
      "Diyi Liu",
      "Niyati Malhotra",
      "Scott A. Hale",
      "Samuel Fraiberger",
      "Victor Orozco-Olvera",
      "Paul Röttger"
    ]
  },
  "https://aclanthology.org/2025.acl-long.116": {
    "title": "LegalAgentBench: Evaluating LLM Agents in Legal Domain",
    "volume": "long",
    "abstract": "With the increasing intelligence and autonomy of LLM Agents, their potential applications in the legal domain are becoming increasingly apparent. However, existing general-domain benchmarks are unable to fully capture the complexity and subtle nuances inherent in real-world judicial cognition and decision-making. Therefore, we propose LegalAgentBench, a comprehensive benchmark specifically designed to evaluate LLM Agents in the Chinese legal domain. LegalAgentBench includes 17 corpora from real-world legal scenarios and provides 37 tools for interacting with external knowledge. To cover tasks of varying difficulty and types, we designed a scalable task construction process that enables a more precise evaluation of performance in both tool utilization and reasoning. Moreover, Beyond assessing performance through the success rate of final outcomes, LegalAgentBench incorporates keyword analysis during intermediate processes to calculate progress rates, facilitating a more fine-grained evaluation. We evaluated eight popular LLMs, highlighting the strengths, limitations, and potential areas for improvement of existing models and methods. LegalAgentBench sets a new benchmark for the practical application of LLMs in the legal domain, with its code and data available at https://github.com/CSHaitao/LegalAgentBench",
    "checked": true,
    "id": "0eb229fd2e62bd62ddb894c4f8150eb9cb51d749",
    "semantic_title": "legalagentbench: evaluating llm agents in legal domain",
    "citation_count": 17,
    "authors": [
      "Haitao Li",
      "Junjie Chen",
      "Jingli Yang",
      "Qingyao Ai",
      "Wei Jia",
      "Youfeng Liu",
      "Kai Lin",
      "Yueyue Wu",
      "Guozhi Yuan",
      "Yiran Hu",
      "Wuyue Wang",
      "Yiqun Liu",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.117": {
    "title": "Inference Compute-Optimal Video Vision Language Models",
    "volume": "long",
    "abstract": "This work investigates the optimal allocation of inference compute across three key scaling factors in video vision language models: language model size, frame count, and the number of visual tokens per frame. While prior works typically focuses on optimizing model efficiency or improving performance without considering resource constraints, we instead identify optimal model configuration under fixed inference compute budgets. We conduct large-scale training sweeps and careful parametric modeling of task performance to identify the inference compute-optimal frontier. Our experiments reveal how task performance depends on scaling factors and finetuning data size, as well as how changes in data size shift the compute-optimal frontier. These findings translate to practical tips for selecting these scaling factors",
    "checked": true,
    "id": "8cb9b5989e386f5a6b8dbcb1b8dfdea6e0d53ea5",
    "semantic_title": "inference compute-optimal video vision language models",
    "citation_count": 0,
    "authors": [
      "Peiqi Wang",
      "ShengYun Peng",
      "Xuewen Zhang",
      "Hanchao Yu",
      "Yibo Yang",
      "Lifu Huang",
      "Fujun Liu",
      "Qifan Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.118": {
    "title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models",
    "volume": "long",
    "abstract": "Aligned representations across languages is a desired property in multilingual large language models (mLLMs), as alignment can improve performance in cross-lingual tasks. Typically alignment requires fine-tuning a model, which is computationally expensive, and sizable language data, which often may not be available. A data-efficient alternative to fine-tuning is model interventions — a method for manipulating model activations to steer generation into the desired direction. We analyze the effect of a popular intervention (finding experts) on the alignment of cross-lingual representations in mLLMs. We identify the neurons to manipulate for a given language and introspect the embedding space of mLLMs pre- and post-manipulation. We show that modifying the mLLM's activations changes its embedding space such that cross-lingual alignment is enhanced. Further, we show that the changes to the embedding space translate into improved downstream performance on retrieval tasks, with up to 2x improvements in top-1 accuracy on cross-lingual retrieval",
    "checked": true,
    "id": "f9e07c13673622ce3f49ed85c0059374a779500a",
    "semantic_title": "steering into new embedding spaces: analyzing cross-lingual alignment induced by model interventions in multilingual language models",
    "citation_count": 1,
    "authors": [
      "Anirudh Sundar",
      "Sinead Williamson",
      "Katherine Metcalf",
      "Barry-John Theobald",
      "Skyler Seto",
      "Masha Fedzechkina"
    ]
  },
  "https://aclanthology.org/2025.acl-long.119": {
    "title": "Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits",
    "volume": "long",
    "abstract": "Search engines play a crucial role as digital gatekeepers, shaping the visibility of Web and social media content through algorithmic curation. This study investigates how search engines like Google selectively promotes or suppresses certain hashtags and subreddits, impacting the information users encounter. By comparing search engine results with nonsampled data from Reddit and Twitter/X, we reveal systematic biases in content visibility. Google's algorithms tend to suppress subreddits and hashtags related to sexually explicit material, conspiracy theories, advertisements, and cryptocurrencies, while promoting content associated with higher engagement. These findings suggest that Google's gatekeeping practices influence public discourse by curating the social media narratives available to users",
    "checked": true,
    "id": "9c11398055f2d38aaad6f1e58e69f85316d73fc3",
    "semantic_title": "digital gatekeepers: google's role in curating hashtags and subreddits",
    "citation_count": 0,
    "authors": [
      "Amrit Poudel",
      "Yifan Ding",
      "Tim Weninger",
      "Jürgen Pfeffer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.120": {
    "title": "Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse",
    "volume": "long",
    "abstract": "The surge in online content has created an urgent demand for robust detection systems, especially in non-English contexts where current tools demonstrate significant limitations. We introduce forePLay, a novel Polish-language dataset for erotic content detection, comprising over 24,000 annotated sentences. The dataset features a multidimensional taxonomy that captures ambiguity, violence, and socially unacceptable behaviors. Our comprehensive evaluation demonstrates that specialized Polish language models achieve superior performance compared to multilingual alternatives, with transformer-based architectures showing particular strength in handling imbalanced categories. The dataset and accompanying analysis establish essential frameworks for developing linguistically-aware content moderation systems, while highlighting critical considerations for extending such capabilities to morphologically complex languages",
    "checked": true,
    "id": "519ec8498daa5689e3e55416faf8c21954e81daa",
    "semantic_title": "behind closed words: creating and investigating the foreplay annotated dataset for polish erotic discourse",
    "citation_count": 0,
    "authors": [
      "Anna Kołos",
      "Katarzyna Lorenc",
      "Emilia Wiśnios",
      "Agnieszka Karlińska"
    ]
  },
  "https://aclanthology.org/2025.acl-long.121": {
    "title": "Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales",
    "volume": "long",
    "abstract": "Human-like personality traits have recently been discovered in large language models, raising the hypothesis that their (known and as yet undiscovered) biases conform with human latent psychological constructs. While large conversational models may be tricked into answering psychometric questionnaires, the latent psychological constructs of thousands of simpler transformers, trained for other tasks, cannot be assessed because appropriate psychometric methods are currently lacking. Here, we show how standard psychological questionnaires can be reformulated into natural language inference prompts, and we provide a code library to support the psychometric assessment of arbitrary models. We demonstrate, using a sample of 88 publicly available models, the existence of human-like mental health-related constructs—including anxiety, depression, and the sense of coherence—which conform with standard theories in human psychology and show similar correlations and mitigation strategies. The ability to interpret and rectify the performance of language models by using psychological tools can boost the development of more explainable, controllable, and trustworthy models",
    "checked": true,
    "id": "c3a09575df3b8e954627c718c86ee7059bf06b03",
    "semantic_title": "assessment and manipulation of latent constructs in pre-trained language models using psychometric scales",
    "citation_count": 0,
    "authors": [
      "Maor Reuben",
      "Ortal Slobodin",
      "Idan-Chaim Cohen",
      "Aviad Elyashar",
      "Orna Braun-Lewensohn",
      "Odeya Cohen",
      "Rami Puzis"
    ]
  },
  "https://aclanthology.org/2025.acl-long.122": {
    "title": "Did Translation Models Get More Robust Without Anyone Even Noticing?",
    "volume": "long",
    "abstract": "Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to \"noisy\" inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation. Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data. This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness. Next, we show that similar trends hold for social media translation experiments – LLMs are more robust to social media text. We include an analysis of the circumstances in which source correction techniques can be used to mitigate the effects of noise. Altogether, we show that robustness to many types of noise has increased",
    "checked": true,
    "id": "5ab54edcc6ee2b322716fc7cc7a4e14ab318c210",
    "semantic_title": "did translation models get more robust without anyone even noticing?",
    "citation_count": 3,
    "authors": [
      "Ben Peters",
      "Andre Martins"
    ]
  },
  "https://aclanthology.org/2025.acl-long.123": {
    "title": "Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset",
    "volume": "long",
    "abstract": "Recent English Common Crawl datasets like FineWeb-Edu and DCLM achieved significant benchmark gains via aggressive model-based filtering, but at the cost of removing 90% of data. This limits their suitability for long token horizon training, such as 15T tokens for Llama 3.1. In this paper, we show how to achieve better trade-offs between accuracy and data quantity by a combination of classifier ensembling, synthetic data rephrasing, and reduced reliance on heuristic filters. When training 8B parameter models for 1T tokens, using a high-quality subset of our data improves MMLU by 5.6 over DCLM, demonstrating the efficacy of our methods for boosting accuracies over a relatively short token horizon. Furthermore, our full 6.3T token dataset matches DCLM on MMLU, but contains four times more unique real tokens than DCLM. This unlocks state-of-the-art training over a long token horizon: an 8B parameter model trained for 15T tokens, of which 7.2T came from our dataset, is better than the Llama 3.1 8B model: +5 on MMLU, +3.1 on ARC-Challenge, and +0.5 on average across ten diverse tasks. The dataset is available at https://data.commoncrawl.org/contrib/Nemotron/Nemotron-CC/index.html",
    "checked": true,
    "id": "9b032d641fed0cb33af71f06a40fdf8ac27c5dfe",
    "semantic_title": "nemotron-cc: transforming common crawl into a refined long-horizon pretraining dataset",
    "citation_count": 18,
    "authors": [
      "Dan Su",
      "Kezhi Kong",
      "Ying Lin",
      "Joseph Jennings",
      "Brandon Norick",
      "Markus Kliegl",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ]
  },
  "https://aclanthology.org/2025.acl-long.124": {
    "title": "Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings",
    "volume": "long",
    "abstract": "Contextual large language model embeddings are increasingly utilized for topic modeling and clustering. However, current methods often scale poorly, rely on opaque similarity metrics, and struggle in multilingual settings. In this work, we present a novel, scalable, interpretable, hierarchical, and multilingual approach to clustering news articles and social media data. To do this, we first train multilingual Matryoshka embeddings that can determine story similarity at varying levels of granularity based on which subset of the dimensions of the embeddings is examined. This embedding model achieves state-of-the-art performance on the SemEval 2022 Task 8 test dataset (Pearson 𝜌 = 0.816). Once trained, we develop an efficient hierarchical clustering algorithm that leverages the hierarchical nature of Matryoshka embeddings to identify unique news stories, narratives, and themes. We conclude by illustrating how our approach can identify and cluster stories, narratives, and overarching themes within real-world news datasets",
    "checked": true,
    "id": "38ec60492333e94e7bec5141550557bde346dd9e",
    "semantic_title": "hierarchical level-wise news article clustering via multilingual matryoshka embeddings",
    "citation_count": 0,
    "authors": [
      "Hans William Alexander Hanley",
      "Zakir Durumeric"
    ]
  },
  "https://aclanthology.org/2025.acl-long.125": {
    "title": "Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models",
    "volume": "long",
    "abstract": "The generation of toxic content by large language models (LLMs) remains a critical challenge for the safe deployment of language technology. We propose a novel framework for implicit knowledge editing and controlled text generation by fine-tuning LLMs with a prototype-based contrastive perplexity objective. Central to our method is the construction of hard negatives—toxic outputs that are generated through adversarial paraphrasing to be semantically similar and model probability to their non-toxic counterparts. By training on these challenging and realistic pairs, our approach ensures robust and stable contrastive optimization. Experimental results in the domain of detoxification demonstrate that our method significantly reduces toxic generation while maintaining strong performance on downstream tasks such as commonsense reasoning and reading comprehension. Our findings highlight the effectiveness of exploiting hard negatives for attribute-aware fine-tuning",
    "checked": true,
    "id": "5ab5ed1ee85d2adabf46ec6f86c9820120fe774c",
    "semantic_title": "contrastive perplexity for controlled generation: an application in detoxifying large language models",
    "citation_count": 1,
    "authors": [
      "Tassilo Klein",
      "Moin Nabi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.126": {
    "title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent",
    "volume": "long",
    "abstract": "Recent advancements have underscored the potential of large language model (LLM)-based agents in financial decision-making. Despite this progress, the field currently encounters two main challenges: (1) the lack of a comprehensive LLM agent framework adaptable to a variety of financial tasks, and (2) the absence of standardized benchmarks and consistent datasets for assessing agent performance. To tackle these issues, we introduce InvestorBench, the first benchmark specifically designed for evaluating LLM-based agents in diverse financial decision-making contexts. InvestorBench enhances the versatility of LLM-enabled agents by providing a comprehensive suite of tasks applicable to different financial products, including single equities like stocks and cryptocurrencies, and exchange-traded funds (ETFs). Additionally, we assess the reasoning and decision-making capabilities of our agent framework using thirteen different LLMs as backbone models, across various market environments and tasks. Furthermore, we have curated a diverse collection of open-source, datasets and developed a comprehensive suite of environments for financial decision-making. This establishes a highly accessible platform for evaluating financial agents' performance across various scenarios",
    "checked": true,
    "id": "74e898dbf4a82980d600828f6ffcb6cd1c4d1522",
    "semantic_title": "investorbench: a benchmark for financial decision-making tasks with llm-based agent",
    "citation_count": 9,
    "authors": [
      "Haohang Li",
      "Yupeng Cao",
      "Yangyang Yu",
      "Shashidhar Reddy Javaji",
      "Zhiyang Deng",
      "Yueru He",
      "Yuechen Jiang",
      "Zining Zhu",
      "K.p. Subbalakshmi",
      "Jimin Huang",
      "Lingfei Qian",
      "Xueqing Peng",
      "Jordan W. Suchow",
      "Qianqian Xie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.127": {
    "title": "Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference",
    "volume": "long",
    "abstract": "Encoder-only transformer models such as BERT offer a great performance-size tradeoff for retrieval and classification tasks with respect to larger decoder-only models. Despite being the workhorse of numerous production pipelines, there have been limited Pareto improvements to BERT since its release. In this paper, we introduce ModernBERT, bringing modern model optimizations to encoder-only models and representing a major Pareto improvement over older encoders. Trained on 2 trillion tokens with a native 8192 sequence length, ModernBERT models exhibit state-of-the-art results on a large pool of evaluations encompassing diverse classification tasks and both single and multi-vector retrieval on different domains (including code). In addition to strong downstream performance, ModernBERT is also the most speed and memory efficient encoder and is designed for inference on common GPUs",
    "checked": true,
    "id": "8dc5a5f57b5a4564536badf3ca98e5680f313314",
    "semantic_title": "smarter, better, faster, longer: a modern bidirectional encoder for fast, memory efficient, and long context finetuning and inference",
    "citation_count": 130,
    "authors": [
      "Benjamin Warner",
      "Antoine Chaffin",
      "Benjamin Clavié",
      "Orion Weller",
      "Oskar Hallström",
      "Said Taghadouini",
      "Alexis Gallagher",
      "Raja Biswas",
      "Faisal Ladhak",
      "Tom Aarsen",
      "Griffin Thomas Adams",
      "Jeremy Howard",
      "Iacopo Poli"
    ]
  },
  "https://aclanthology.org/2025.acl-long.128": {
    "title": "Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models",
    "volume": "long",
    "abstract": "We present a comprehensive evaluation of gender fairness in large language models (LLMs), focusing on their ability to handle both binary and non-binary genders. While previous studies primarily focus on binary gender distinctions, we introduce the Gender Inclusivity Fairness Index (GIFI), a novel and comprehensive metric that quantifies the diverse gender inclusivity of LLMs. GIFI consists of a wide range of evaluations at different levels, from simply probing the model with respect to provided gender pronouns to testing various aspects of model generation and cognitive behaviors under different gender assumptions, revealing biases associated with varying gender identifiers.We conduct extensive evaluations with GIFI on 20 prominent open-source and proprietary LLMs of varying sizes and capabilities, discovering significant variations in LLMs' gender inclusivity. Our study highlights the importance of improving LLMs' inclusivity, providing a critical benchmark for future advancements in gender fairness in generative models",
    "checked": true,
    "id": "97e90a86875e770550b8a0dac792d47ea62f1e67",
    "semantic_title": "gender inclusivity fairness index (gifi): a multilevel framework for evaluating gender diversity in large language models",
    "citation_count": 0,
    "authors": [
      "Zhengyang Shan",
      "Emily Diana",
      "Jiawei Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.129": {
    "title": "D.Va: Validate Your Demonstration First Before You Use It",
    "volume": "long",
    "abstract": "In-context learning (ICL) has demonstrated significant potential in enhancing the capabilities of large language models (LLMs) during inference. It's well-established that ICL heavily relies on selecting effective demonstrations to achieve outputs that better align with the expected results. As for demonstration selection, previous approaches have typically relied on intuitive metrics to evaluate the effectiveness of demonstrations, which often results in limited robustness and poor cross-model generalization capabilities. To tackle these challenges, we propose a novel method, **D**emonstration **Va**lidation (**D.Va**), which integrates a demonstration validation perspective into this field. By introducing the demonstration validation mechanism, our method effectively identifies demonstrations that are both effective and highly generalizable. **D.Va** surpasses all existing retrieval-based in-context learning techniques across both natural language understanding (NLU) and natural language generation (NLG) tasks. Additionally, we demonstrate the robustness and generalizability of our approach across various language models and retrieval models",
    "checked": true,
    "id": "4eefbb3040ebf4d40e016dcf7ab1cab1bc6b7033",
    "semantic_title": "d.va: validate your demonstration first before you use it",
    "citation_count": 0,
    "authors": [
      "Qi Zhang",
      "Zhiqing Xiao",
      "Ruixuan Xiao",
      "Lirong Gao",
      "Junbo Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.130": {
    "title": "Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?",
    "volume": "long",
    "abstract": "Any-to-any generative models aim to enable seamless interpretation and generation across multiple modalities within a unified framework, yet their ability to preserve relationships across modalities remains uncertain. Do unified models truly achieve cross-modal coherence, or is this coherence merely perceived? To explore this, we introduce ACON, a dataset of 1,000 images (500 newly contributed) paired with captions, editing instructions, and Q&A pairs to evaluate cross-modal transfers rigorously. Using three consistency criteria—cyclic consistency, forward equivariance, and conjugated equivariance—our experiments reveal that any-to-any models do not consistently demonstrate greater cross-modal consistency than specialized models in pointwise evaluations such as cyclic consistency. However, equivariance evaluations uncover weak but observable consistency through structured analyses of the intermediate latent space enabled by multiple editing operations. We release our code and data at https://github.com/JiwanChung/ACON",
    "checked": true,
    "id": "9b02feb9c73da752c81d54267e7a2b3d06add4f2",
    "semantic_title": "are any-to-any models more consistent across modality transfers than specialists?",
    "citation_count": 0,
    "authors": [
      "Jiwan Chung",
      "Janghan Yoon",
      "Junhyeong Park",
      "Sangeyl Lee",
      "Joowon Yang",
      "Sooyeon Park",
      "Youngjae Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.131": {
    "title": "MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are becoming essential tools for various natural language processing tasks but often suffer from generating outdated or incorrect information. Retrieval-Augmented Generation (RAG) addresses this issue by incorporating external, real-time information retrieval to ground LLM responses. However, the existing RAG systems frequently struggle with the quality of retrieval documents, as irrelevant or noisy documents degrade performance, increase computational overhead, and undermine response reliability. To tackle this problem, we propose Multi-Agent Filtering Retrieval-Augmented Generation (MAIN-RAG), a training-free RAG framework that leverages multiple LLM agents to collaboratively filter and score retrieved documents. Specifically, MAIN-RAG introduces an adaptive filtering mechanism that dynamically adjusts the relevance filtering threshold based on score distributions, effectively minimizing noise while maintaining high recall of relevant documents. The proposed approach leverages inter-agent consensus to ensure robust document selection without requiring additional training data or fine-tuning. Experimental results across four QA benchmarks demonstrate that MAIN-RAG consistently outperforms traditional RAG approaches, achieving a 2–11% improvement in answer accuracy while reducing the number of irrelevant retrieved documents. Quantitative analysis further reveals that our approach achieves superior response consistency and answer accuracy over baseline methods, offering a competitive and practical alternative to training-based solutions",
    "checked": true,
    "id": "f6c0cd7d2c2706e022a785c40890a155f12db212",
    "semantic_title": "main-rag: multi-agent filtering retrieval-augmented generation",
    "citation_count": 2,
    "authors": [
      "Chia-Yuan Chang",
      "Zhimeng Jiang",
      "Vineeth Rakesh",
      "Menghai Pan",
      "Chin-Chia Michael Yeh",
      "Guanchu Wang",
      "Mingzhi Hu",
      "Zhichao Xu",
      "Yan Zheng",
      "Mahashweta Das",
      "Na Zou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.132": {
    "title": "Unraveling the Mechanics of Learning-Based Demonstration Selection for In-Context Learning",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities from few-shot demonstration exemplars. Recent learning-based demonstration selection methods have proven beneficial to ICL by choosing more useful exemplars. While these methods generally assume they learn better similarity measurements between exemplars and test cases from the proxy task, what kinds of similarities are captured by them and are vital to performing ICL still need to be explored. To dive into this question, we analyze the working mechanism of learning-based demonstration selection methods and empirically identify two essential factors of their similarity measurements: 1) Integrating task-agnostic similarities of different levels between the input of exemplars and test cases; 2) Incorporating task-specific similarity between the output of exemplars and test cases. We validate these two findings through extensive quantitative analysis across ten datasets and various LLMs. Based on these insights, we introduce two simplified exemplar selection methods, MLSM and TTF, catering to task-agnostic and task-specific demands to eliminate costly data collection. The effectiveness of both methods evince our findings again and pave the way for future studies",
    "checked": true,
    "id": "b85c45c2186ed2eb066cc625f1d8d418b7b0204f",
    "semantic_title": "unraveling the mechanics of learning-based demonstration selection for in-context learning",
    "citation_count": 6,
    "authors": [
      "Hui Liu",
      "Wenya Wang",
      "Hao Sun",
      "Chris Xing Tian",
      "Chenqi Kong",
      "Xin Dong",
      "Haoliang Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.133": {
    "title": "Direct Prompt Optimization with Continuous Representations",
    "volume": "long",
    "abstract": "Prompt optimization for language models faces challenges due to the large discrete search space, the reliance on continuous gradient updates, and the need to round continuous representations into discrete prompts, which causes inflexibility and instability. Existing methods attempt to address these by constraining the search space and adopting greedy, incremental improvements, but they often fail to fully leverage historical gradient information. In this paper, we model the prompt optimization problem by the probability distribution of the prompt and present a novel approach that integrates greedy strategies into optimization with continuous representations. This approach can exploit historical gradient information to address the instability caused by rounding in existing methods. Our study indicates that using continuous representations can improve prompt optimization performance on both text classification and attack tasks, as well as models, including GPT-2, OPT, Vicuna, and LLaMA-2, and also be adaptable to models of different sizes",
    "checked": false,
    "id": "4843a71eea96646cec2fcb3437f2d292c2f9520d",
    "semantic_title": "llm pretraining with continuous concepts",
    "citation_count": 4,
    "authors": [
      "Yangkun Wang",
      "Zihan Wang",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.134": {
    "title": "uMedSum: A Unified Framework for Clinical Abstractive Summarization",
    "volume": "long",
    "abstract": "Clinical abstractive summarization struggles to balance faithfulness and informativeness, sacrificing key information or introducing confabulations. Techniques like in-context learning and fine-tuning have improved overall summary quality orthogonally, without considering the above issue. Conversely, methods aimed at improving faithfulness and informativeness, such as model reasoning and self improvement, have not been systematically evaluated in the clinical domain. We address this gap by first performing a comprehensive benchmark and study of six advanced abstractive summarization methods across three datasets using five reference-based and reference-free metrics, with the latter specifically assessing faithfulness and informativeness. Based on its findings we then develop uMedSum, a modular hybrid framework introducing novel approaches for sequential confabulation removal and key information addition. Our work outperforms previous GPT-4-based state-of-the-art (SOTA) methods in both quantitative metrics and expert evaluations, achieving an 11.8% average improvement in dedicated faithfulness metrics over the previous SOTA. Doctors prefer uMedSum's summaries 6 times more than previous SOTA in difficult cases containing confabulations or missing information. These results highlight uMedSum's effectiveness and generalizability across various datasets and metrics, marking a significant advancement in clinical summarization. uMedSum toolkit is made available on GitHub",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aishik Nagar",
      "Yutong Liu",
      "Andy T. Liu",
      "Viktor Schlegel",
      "Vijay Prakash Dwivedi",
      "Arun-Kumar Kaliya-Perumal",
      "Guna Pratheep Kalanchiam",
      "Yili Tang",
      "Robby T. Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.135": {
    "title": "GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement",
    "volume": "long",
    "abstract": "The evolution of speech technology has been spurred by the rapid increase in dataset sizes. Traditional speech models generally depend on a large amount of labeled training data, which is scarce for low-resource languages. This paper presents GigaSpeech 2, a large-scale, multi-domain, multilingual speech recognition corpus. It is designed for low-resource languages and does not rely on paired speech and text data. GigaSpeech 2 comprises about 30,000 hours of automatically transcribed speech, including Thai, Indonesian, and Vietnamese, gathered from unlabeled YouTube videos. We also introduce an automated pipeline for data crawling, transcription, and label refinement. Specifically, this pipeline involves Whisper for initial transcription, MMS for forced alignment, and multi-dimensional filtering for data quality assurance. A modified Noisy Student Training is developed to further refine flawed pseudo labels iteratively, thereby enhancing model performance. Experimental results on our manually transcribed evaluation set and two public test sets from Common Voice and FLEURS confirm our corpus's high quality and broad applicability. Notably, ASR models trained on GigaSpeech 2 can reduce the word error rate for Thai, Indonesian, and Vietnamese on our challenging and realistic YouTube test set by 25% to 40% compared to Whisper large-v3, with merely 10% model parameters. Furthermore, our ASR models trained on GigaSpeech 2 yield superior performance compared to commercial services. We hope that our newly introduced corpus and pipeline will open a new avenue for low-resource speech recognition and significantly facilitate research in this area",
    "checked": true,
    "id": "5328b32c265241256ae1a113cb4e2d65d5ab045d",
    "semantic_title": "gigaspeech 2: an evolving, large-scale and multi-domain asr corpus for low-resource languages with automated crawling, transcription and refinement",
    "citation_count": 12,
    "authors": [
      "Yifan Yang",
      "Zheshu Song",
      "Jianheng Zhuo",
      "Mingyu Cui",
      "Jinpeng Li",
      "Bo Yang",
      "Yexing Du",
      "Ziyang Ma",
      "Xunying Liu",
      "Ziyuan Wang",
      "Ke Li",
      "Shuai Fan",
      "Kai Yu",
      "Wei-Qiang Zhang",
      "Guoguo Chen",
      "Xie Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.136": {
    "title": "Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents",
    "volume": "long",
    "abstract": "User sentiment on social media reveals underlying social trends, crises, and needs. Researchers have analyzed users' past messages to track the evolution of sentiments and reconstruct sentiment dynamics. However, predicting the imminent sentiment response of users to ongoing events remains understudied. In this paper, we address the problem of sentiment forecasting on social media to predict users' future sentiment based on event developments. We extract sentiment-related features to enhance modeling and propose a multi-perspective role-playing framework to simulate human response processes. Our preliminary results show significant improvements in sentiment forecasting at both microscopic and macroscopic levels",
    "checked": true,
    "id": "c92b9a7ca87840dd6093e610b92f3eae9050ad3d",
    "semantic_title": "context-aware sentiment forecasting via llm-based multi-perspective role-playing agents",
    "citation_count": 0,
    "authors": [
      "Fanhang Man",
      "Huandong Wang",
      "Jianjie Fang",
      "Zhaoyi Deng",
      "Baining Zhao",
      "Xinlei Chen",
      "Yong Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.137": {
    "title": "TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data",
    "volume": "long",
    "abstract": "Semantic parsing, which converts natural language queries into logic forms, plays a crucial role in reasoning within structured environments. However, existing methods encounter two significant challenges: reliance on extensive manually annotated datasets and limited generalization capability to unseen examples. To tackle these issues, we propose Targeted Synthetic Data Generation (Targa), a practical framework that dynamically generates high-relevance synthetic data without manual annotation. Starting from the pertinent entity and relation of a given question, we probe for the potential relevant queries through layer-wise expansion and cross-layer combination. Then, we generate corresponding natural language questions for these constructed queries to jointly serve as the synthetic demonstration for in-context learning. Experiments on multiple knowledge-based question answering (KBQA) datasets demonstrate that Targa, using only a 7B-parameter model, substantially outperforms existing non-fine-tuned methods that utilize close-sourced model, achieving notable improvements in F1 scores on GrailQA(+7.7) and KBQA-Agent(+12.2). Furthermore, Targa also exhibits superior sample efficiency, robustness, and generalization capabilities under non-I.I.D. settings",
    "checked": true,
    "id": "95b17f92fddb0adf4b14bd3c23cae7c491500f45",
    "semantic_title": "targa: targeted synthetic data generation for practical reasoning over structured data",
    "citation_count": 1,
    "authors": [
      "Xiang Huang",
      "Jiayu Shen",
      "Shanshan Huang",
      "Sitao Cheng",
      "Xiaxia Wang",
      "Yuzhong Qu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.138": {
    "title": "AndroidGen: Building an Android Language Agent under Data Scarcity",
    "volume": "long",
    "abstract": "Large language models have opened up a world of possibilities for various NLP tasks, sparking optimism for the future. Despite their potential, LLMs have yet to be widely used as agents on real mobile devices. The main challenge is the need for high-quality data sources. Time constraints and labor intensity often hinder human annotation. On the other hand, existing LLMs exhibit inadequate completion rates and need a robust data filtration strategy. Given these challenges, we develop a framework called AndroidGen to enhance the capabilities of LLM-based agents under data scarcity. In addition, we leverage AndroidGen to collect trajectories given human tasks and train open-source LLMs on these trajectories to develop an open-source mobile agent without manually labeled trajectories. We extensively evaluate AndroidGen with AndroidWorld, AitW, and various popular applications, demonstrating its improvements and revealing potential areas for future improvement. Code, model, and data are available at https://github.com/THUDM/AndroidGen",
    "checked": true,
    "id": "1bf2a864b5b46c7c93ff273d49f0f5020f73ae20",
    "semantic_title": "androidgen: building an android language agent under data scarcity",
    "citation_count": 0,
    "authors": [
      "Hanyu Lai",
      "Junjie Gao",
      "Xiao Liu",
      "Yifan Xu",
      "Shudan Zhang",
      "Yuxiao Dong",
      "Jie Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.139": {
    "title": "Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation",
    "volume": "long",
    "abstract": "Recently, Large Language Models (LLMs) have demonstrated significant potential for data annotation, markedly reducing the labor costs associated with downstream applications. However, existing methods mostly adopt an aggressive strategy by prompting LLM to determine a single gold label for each unlabeled sample. Due to the inherent uncertainty within LLMs, they often produce incorrect labels for difficult samples, severely compromising the data quality for downstream applications. Motivated by ambiguity aversion in human behaviors, we propose a novel candidate annotation paradigm wherein large language models are encouraged to output all possible labels when incurring uncertainty. To ensure unique labels are provided for downstream tasks, we develop a teacher-student framework CanDist that distills candidate annotations with a Small Language Model (SLM). We further provide a rigorous justification demonstrating that distilling candidate annotations from the teacher LLM offers superior theoretical guarantees compared to directly using single annotations. Extensive experiments across six text classification tasks validate the effectiveness of our proposed method. The source code is available at https://github.com/MingxuanXia/CanDist",
    "checked": true,
    "id": "4966b27ac26b48425f97746d7a8bfb9a4988ef97",
    "semantic_title": "prompt candidates, then distill: a teacher-student framework for llm-driven data annotation",
    "citation_count": 1,
    "authors": [
      "Mingxuan Xia",
      "Haobo Wang",
      "Yixuan Li",
      "Zewei Yu",
      "Jindong Wang",
      "Junbo Zhao",
      "Runze Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.140": {
    "title": "A Survey of Post-Training Scaling in Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) have achieved remarkable proficiency in understanding and generating human natural languages, mainly owing to the \"scaling law\" that optimizes relationships among language modeling loss, model parameters, and pre-trained tokens. However, with the exhaustion of high-quality internet corpora and increasing computational demands, the sustainability of pre-training scaling needs to be addressed. This paper presents a comprehensive survey of post-training scaling, an emergent paradigm aiming to relieve the limitations of traditional pre-training by focusing on the alignment phase, which traditionally accounts for a minor fraction of the total training computation. Our survey categorizes post-training scaling into three key methodologies: Supervised Fine-tuning (SFT), Reinforcement Learning from Feedback (RLxF), and Test-time Compute (TTC). We provide an in-depth analysis of the motivation behind post-training scaling, the scalable variants of these methodologies, and a comparative discussion against traditional approaches. By examining the latest advancements, identifying promising application scenarios, and highlighting unresolved issues, we seek a coherent understanding and map future research trajectories in the landscape of post-training scaling for LLMs",
    "checked": false,
    "id": "2d269a8b8cd99889efadd041993a35e71bf2c1c2",
    "semantic_title": "sailing ai by the stars: a survey of learning from rewards in post-training and test-time scaling of large language models",
    "citation_count": 2,
    "authors": [
      "Hanyu Lai",
      "Xiao Liu",
      "Junjie Gao",
      "Jiale Cheng",
      "Zehan Qi",
      "Yifan Xu",
      "Shuntian Yao",
      "Dan Zhang",
      "Jinhua Du",
      "Zhenyu Hou",
      "Xin Lv",
      "Minlie Huang",
      "Yuxiao Dong",
      "Jie Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.141": {
    "title": "Position-aware Automatic Circuit Discovery",
    "volume": "long",
    "abstract": "A widely used strategy to discover and understand language model mechanisms is circuit analysis. A circuit is a minimal subgraph of a model's computation graph that executes a specific task. We identify a gap in existing circuit discovery methods: they assume circuits are position-invariant, treating model components as equally relevant across input positions. This limits their ability to capture cross-positional interactions or mechanisms that vary across positions. To address this gap, we propose two improvements to incorporate positionality into circuits, even on tasks containing variable-length examples. First, we extend edge attribution patching, a gradient-based method for circuit discovery, to differentiate between token positions. Second, we introduce the concept of a dataset schema, which defines token spans with similar semantics across examples, enabling position-aware circuit discovery in datasets with variable length examples. We additionally develop an automated pipeline for schema generation and application using large language models. Our approach enables fully automated discovery of position-sensitive circuits, yielding better trade-offs between circuit size and faithfulness compared to prior work",
    "checked": true,
    "id": "b7ec8f0ba450d654cc7ecd8e9cca5022b72dd38d",
    "semantic_title": "position-aware automatic circuit discovery",
    "citation_count": 1,
    "authors": [
      "Tal Haklay",
      "Hadas Orgad",
      "David Bau",
      "Aaron Mueller",
      "Yonatan Belinkov"
    ]
  },
  "https://aclanthology.org/2025.acl-long.142": {
    "title": "HyperFM: Fact-Centric Multimodal Fusion for Link Prediction over Hyper-Relational Knowledge Graphs",
    "volume": "long",
    "abstract": "With the ubiquity of hyper-relational facts in modern Knowledge Graphs (KGs), existing link prediction techniques mostly focus on learning the sophisticated relationships among multiple entities and relations contained in a fact, while ignoring the multimodal information, which often provides additional clues to boost link prediction performance. Nevertheless, traditional multimodel fusion approaches, which are mainly designed for triple facts under either entity-centric or relation-guided fusion schemes, fail to integrate the multimodal information with the rich context of the hyper-relational fact consisting of multiple entities and relations. Against this background, we propose **HyperFM**, a **Hyper**-relational **F**act-centric **M**ultimodal Fusion technique. It effectively captures the intricate interactions between different data modalities while accommodating the hyper-relational structure of the KG in a fact-centric manner via a customized Hypergraph Transformer. We evaluate HyperFM against a sizeable collection of baselines in link prediction tasks on two real-world KG datasets. Results show that HyperFM consistently achieves the best performance, yielding an average improvement of 6.0-6.8% over the best-performing baselines on the two datasets. Moreover, a series of ablation studies systematically validate our fact-centric fusion scheme",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhuan Lu",
      "Weijian Yu",
      "Xin Jing",
      "Dingqi Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.143": {
    "title": "Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model",
    "volume": "long",
    "abstract": "Most Large Vision-Language Models (LVLMs) to date are trained predominantly on English data, which makes them struggle to understand non-English input and fail to generate output in the desired target language. Existing efforts mitigate these issues by adding multilingual training data, but do so in a largely ad-hoc manner, lacking insight into how different training mixes tip the scale for different groups of languages. In this work, we present a comprehensive investigation into the training strategies for massively multilingual LVLMs. First, we conduct a series of multi-stage experiments spanning 13 downstream vision-language tasks and 43 languages, systematically examining: (1) the number of training languages that can be included without degrading English performance and (2) optimal language distributions of pre-training as well as (3) instruction-tuning data. Further, we (4) investigate how to improve multilingual text-in-image understanding, and introduce a new benchmark for the task. Surprisingly, our analysis reveals that one can (i) include as many as 100 training languages simultaneously (ii) with as little as 25-50% of non-English data, to greatly improve multilingual performance while retaining strong English performance. We further find that (iii) including non-English OCR data in pre-training and instruction-tuning is paramount for improving multilingual text-in-image understanding. Finally, we put all our findings together and train , a 100-language LVLM, offering state-of-the-art performance in an evaluation covering 14 tasks and 56 languages",
    "checked": true,
    "id": "bf12635587f572cdf3b02335a59ff8274017667c",
    "semantic_title": "centurio: on drivers of multilingual ability of large vision-language model",
    "citation_count": 1,
    "authors": [
      "Gregor Geigle",
      "Florian Schneider",
      "Carolin Holtermann",
      "Chris Biemann",
      "Radu Timofte",
      "Anne Lauscher",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2025.acl-long.144": {
    "title": "Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation",
    "volume": "long",
    "abstract": "Scientific language models drive research innovation but require extensive fine-tuning on large datasets. This work enhances such models by improving their inference and evaluation capabilities with minimal or no additional training. Focusing on molecule caption generation, we explore post-training synergies between alignment fine-tuning and model merging in a cross-modal setup. We reveal intriguing insights into the behaviour and suitability of such methods while significantly surpassing state-of-the-art models. Moreover, we propose a novel atomic-level evaluation method leveraging off-the-shelf Natural Language Inference (NLI) models for use in the unseen chemical domain. Our experiments demonstrate that our evaluation operates at the right level of granularity, effectively handling multiple content units and subsentence reasoning, while widely adopted NLI methods consistently misalign with assessment criteria",
    "checked": true,
    "id": "d5c4bdc54f974550dce55fc5d40a2e828aafcdf3",
    "semantic_title": "less for more: enhanced feedback-aligned mixed llms for molecule caption generation and fine-grained nli evaluation",
    "citation_count": 0,
    "authors": [
      "Dimitris Gkoumas",
      "Maria Liakata"
    ]
  },
  "https://aclanthology.org/2025.acl-long.145": {
    "title": "Ensemble Watermarks for Large Language Models",
    "volume": "long",
    "abstract": "As large language models (LLMs) reach human-like fluency, reliably distinguishing AI-generated text from human authorship becomes increasingly difficult. While watermarks already exist for LLMs, they often lack flexibility and struggle with attacks such as paraphrasing. To address these issues, we propose a multi-feature method for generating watermarks that combines multiple distinct watermark features into an ensemble watermark. Concretely, we combine acrostica and sensorimotor norms with the established red-green watermark to achieve a 98% detection rate. After a paraphrasing attack, the performance remains high with 95% detection rate. In comparison, the red-green feature alone as a baseline achieves a detection rate of 49% after paraphrasing. The evaluation of all feature combinations reveals that the ensemble of all three consistently has the highest detection rate across several LLMs and watermark strength settings. Due to the flexibility of combining features in the ensemble, various requirements and trade-offs can be addressed. Additionally, the same detection function can be used without adaptations for all ensemble configurations. This method is particularly of interest to facilitate accountability and prevent societal harm",
    "checked": true,
    "id": "ebc0902f3f9200994fe4e002d07aedb1d1eae0e2",
    "semantic_title": "ensemble watermarks for large language models",
    "citation_count": 0,
    "authors": [
      "Georg Niess",
      "Roman Kern"
    ]
  },
  "https://aclanthology.org/2025.acl-long.146": {
    "title": "\\mathsf{Con Instruction}: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities",
    "volume": "long",
    "abstract": "Existing attacks against multimodal language models often communicate instruction through text, either as an explicit malicious instruction or a crafted generic prompt, and accompanied by a toxic image. In contrast, here we exploit the capabilities of MLLMs in following non-textual instruction, i.e., an adversarial image or audio, namely Con Instruction. It is a novel gray-box attack method that generates adversarial images or audio to convey specific harmful instructions to MLLMs. We also find that combining our adversarial examples with certain non-empty text inputs amplifies attack success, while appending these after malicious text has limited effects. To evaluate whether an attack is successful, we introduce a new attack response categorization (ARC) that considers the response quality and relevancy concerning the malicious instruction. The results show that Con Instruction effectively bypasses the safety mechanisms in various visual and audio-language models, including LLaVA-v1.5, InternVL, Qwen-VL, and Qwen-Audio, across two standard benchmarks: AdvBench and SafeBench. Specifically, our method achieves the highest attack success rates, reaching 81.3% and 86.6% on LLaVA-v1.5 (13B). We show that larger models are more susceptible toCon Instruction, contrasting observations in their underlying LLMs. On the defense side, we explore various methods against our attacks and find substantial gaps among existing techniques. The code will be made available upon publication",
    "checked": false,
    "id": "3de19f0fbc5add0f74bde83dfb5798294d589c33",
    "semantic_title": "con instruction: universal jailbreaking of multimodal large language models via non-textual modalities",
    "citation_count": 0,
    "authors": [
      "Jiahui Geng",
      "Thy Thy Tran",
      "Preslav Nakov",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.147": {
    "title": "TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge",
    "volume": "long",
    "abstract": "The LLM-as-a-judge paradigm uses large language models (LLMs) for automated text evaluation, assigning a score to the input based on scoring rubrics. Existing methods for fine-tuning LLM-as-a-judge use cross-entropy (CE) loss, which neglects the numeric nature of score prediction. Recent work addresses numerical prediction limitations of LLM fine-tuning through regression-aware fine-tuning but does not consider chain-of-thought (CoT) reasoning for score prediction. In this paper, we introduce TRACT (Two-stage Regression-Aware fine-tuning with CoT), which combines CoT reasoning with regression-aware training. TRACT uses a two-stage process: first, it fine-tunes the seed LLM to generate CoTs, which serve as the training data for the second stage; next, it uses these self-generated CoTs to retrain the seed LLM. The fine-tuning objective of TRACT applies CE loss for CoT reasoning and regression-aware loss for the score. Experiments across four LLM-as-a-judge datasets and two LLMs show that TRACT significantly outperforms existing methods. Extensive ablation studies validate the effectiveness of each component in TRACT",
    "checked": true,
    "id": "9934c78aab745e1c8b51d966dd7af8b789d543bc",
    "semantic_title": "tract: regression-aware fine-tuning meets chain-of-thought reasoning for llm-as-a-judge",
    "citation_count": 2,
    "authors": [
      "Cheng-Han Chiang",
      "Hung-yi Lee",
      "Michal Lukasik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.148": {
    "title": "DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "Dynamic Retrieval-augmented Generation (RAG) has shown great success in mitigating hallucinations in large language models (LLMs) during generation. However, existing dynamic RAG methods face significant limitations in two key aspects: 1) Lack of an effective mechanism to control retrieval triggers, and 2) Lack of effective scrutiny of retrieval content. To address these limitations, we propose an innovative dynamic RAG method, DioR (Adaptive Cognitive Detection and Contextual Retrieval Optimization), which consists of two main components: adaptive cognitive detection and contextual retrieval optimization, specifically designed to determine when retrieval is needed and what to retrieve for LLMs is useful. Experimental results demonstrate that DioR achieves superior performance on all tasks, demonstrating the effectiveness of our work",
    "checked": true,
    "id": "a057a3dd30b925df673ff896a1406033cd00c1d2",
    "semantic_title": "dior: adaptive cognitive detection and contextual retrieval optimization for dynamic retrieval-augmented generation",
    "citation_count": 0,
    "authors": [
      "Hanghui Guo",
      "Jia Zhu",
      "Shimin Di",
      "Weijie Shi",
      "Zhangze Chen",
      "Jiajie Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.149": {
    "title": "Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation",
    "volume": "long",
    "abstract": "Maximum a posteriori decoding, a commonly used method for neural machine translation (NMT), aims to maximize the estimated posterior probability. However, high estimated probability does not always lead to high translation quality. Minimum Bayes Risk (MBR) decoding offers an alternative by seeking hypotheses with the highest expected utility.Inspired by Quality Estimation (QE) reranking which uses the QE model as a ranker, we propose source-based MBR (sMBR) decoding, a novel approach that utilizes quasi-sources (generated via paraphrasing or back-translation) as \"support hypotheses\" and a reference-free quality estimation metric as the utility function, marking the first work to solely use sources in MBR decoding. Experiments show that sMBR outperforms QE reranking and the standard MBR decoding. Our findings suggest that sMBR is a promising approach for NMT decoding",
    "checked": true,
    "id": "98b264884e12e30b17285046f40224a427f75499",
    "semantic_title": "unveiling the power of source: source-based minimum bayes risk decoding for neural machine translation",
    "citation_count": 0,
    "authors": [
      "Boxuan Lyu",
      "Hidetaka Kamigaito",
      "Kotaro Funakoshi",
      "Manabu Okumura"
    ]
  },
  "https://aclanthology.org/2025.acl-long.150": {
    "title": "ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use",
    "volume": "long",
    "abstract": "Effective evaluation of multi-hop tool use is critical for analyzing the understanding, reasoning, and function-calling capabilities of large language models (LLMs). However, progress has been hindered by a lack of reliable evaluation datasets. To address this, we present ToolHop, a dataset comprising 995 user queries and 3,912 associated tools, specifically designed for rigorous evaluation of multi-hop tool use. ToolHop ensures diverse queries, meaningful interdependencies, locally executable tools, detailed feedback, and verifiable answers through a novel query-driven data construction approach that includes tool creation, document refinement, and code generation. We evaluate 14 LLMs across five model families (i.e., LLaMA3.1, Qwen2.5, Gemini1.5, Claude3.5, and GPT), uncovering significant challenges in handling multi-hop tool-use scenarios. The leading model, GPT-4o, achieves an accuracy of 49.04%, underscoring substantial room for improvement. Further analysis reveals variations in tool-use strategies for various families, offering actionable insights to guide the development of more effective approaches. Code and data can be found in https://huggingface.co/datasets/bytedance-research/ToolHop",
    "checked": true,
    "id": "6f3c98b477cb251d2288c84e424a99dcb5bd649d",
    "semantic_title": "toolhop: a query-driven benchmark for evaluating large language models in multi-hop tool use",
    "citation_count": 0,
    "authors": [
      "Junjie Ye",
      "Zhengyin Du",
      "Xuesong Yao",
      "Weijian Lin",
      "Yufei Xu",
      "Zehui Chen",
      "Zaiyuan Wang",
      "Sining Zhu",
      "Zhiheng Xi",
      "Siyu Yuan",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang",
      "Jiecao Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.151": {
    "title": "Mixture of insighTful Experts (MoTE): The Synergy of Reasoning Chains and Expert Mixtures in Self-Alignment",
    "volume": "long",
    "abstract": "As the capabilities of large language models (LLMs) continue to expand, aligning these models with human values remains a significant challenge. Recent studies show that reasoning abilities contribute significantly to model safety, while integrating Mixture-of-Experts (MoE) architectures can further enhance alignment.In this work, we address a fundamental question:How to effectively incorporate reasoning abilitiesand MoE architectures into self-alignment processin LLMs?We propose Mixture of insighTful Experts (MoTE), a novel framework that synergistically combines reasoning chains and expert mixtures to improve self-alignments.From a data perspective, MoTE employs a structured reasoning chain comprising four key stages: Question Analysis, Answer Guidance, Safe Answer, and Safety Checking. This approach enhances safety through multi-step reasoning and proves effective even for smaller and less powerful LLMs (e.g., 7B models). From an architectural perspective, MoTE adopts a multi-LoRA framework with step-level routing, where each expert is dedicated to a specific reasoning step. This design eliminates the need for balance losses, ensures stable training, and supports adaptive inference lengths. Experimental results demonstrate that MoTE significantly improves model safety, jailbreak resistance, and over-refusal capabilities, achieving performance comparable to OpenAI's state-of-the-art o1 model",
    "checked": false,
    "id": "df9c4ddabe92d2676ff1662070064960f28f8a3e",
    "semantic_title": "mixture of insightful experts (mote): the synergy of thought chains and expert mixtures in self-alignment",
    "citation_count": 10,
    "authors": [
      "Zhili Liu",
      "Yunhao Gou",
      "Kai Chen",
      "Lanqing Hong",
      "Jiahui Gao",
      "Fei Mi",
      "Yu Zhang",
      "Zhenguo Li",
      "Xin Jiang",
      "Qun Liu",
      "James Kwok"
    ]
  },
  "https://aclanthology.org/2025.acl-long.152": {
    "title": "MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation Alignment",
    "volume": "long",
    "abstract": "Personalized product search aims to retrieve and rank items that match users' preferences and search intent. Despite their effectiveness, existing approaches typically assume that users' query fully captures their real motivation. However, our analysis of a real-world e-commerce platform reveals that users often engage in relevant consultations before searching, indicating they refine intents through consultations based on motivation and need. The implied motivation in consultations is a key enhancing factor for personalized search. This unexplored area comes with new challenges including aligning contextual motivations with concise queries, bridging the category-text gap, and filtering noise within sequence history. To address these, we propose a Motivation-Aware Personalized Search (MAPS) method. It embeds queries and consultations into a unified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE) to prioritize critical semantics, and introduces dual alignment: (1) contrastive learning aligns consultations, reviews, and product features; (2) bidirectional attention integrates motivation-aware embeddings with user preferences. Extensive experiments on real and synthetic data show MAPS outperforms existing methods in both retrieval and ranking tasks. Code and supplementary materials are available at: https://github.com/E-qin/MAPS",
    "checked": true,
    "id": "9df58fbdd9a0644a9408fd9977252a40a76ee514",
    "semantic_title": "maps: motivation-aware personalized search via llm-driven consultation alignment",
    "citation_count": 1,
    "authors": [
      "Weicong Qin",
      "Yi Xu",
      "Weijie Yu",
      "Chenglei Shen",
      "Ming He",
      "Jianping Fan",
      "Xiao Zhang",
      "Jun Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.153": {
    "title": "Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework",
    "volume": "long",
    "abstract": "In the context of large language models (LLMs), current advanced reasoning methods have made impressive strides in various reasoning tasks. However, when it comes to logical reasoning tasks, significant challenges remain in both efficacy and efficiency. This is rooted in the fact that these systems fail to fully leverage the inherent structure of logical tasks throughout the reasoning processes, including decomposition, search, and resolution. To address this, this paper proposes a logic-complete reasoning framework, Aristotle. The framework consists of three key components: Logical Decomposer, Logical Search Router, and Logical Resolver, in which symbolic expressions and logical rules are comprehensively integrated into the entire reasoning process, significantly alleviating the bottlenecks of logical reasoning, i.e., reducing sub-task complexity, minimizing search errors, and resolving logical contradictions. Experimental results demonstrate that Aristotle consistently outperforms state-of-the-art reasoning frameworks in both accuracy and efficiency, particularly excelling in complex logical reasoning scenarios",
    "checked": true,
    "id": "a26cc821b349dec6a271d665125468314b97320e",
    "semantic_title": "aristotle: mastering logical reasoning with a logic-complete decompose-search-resolve framework",
    "citation_count": 1,
    "authors": [
      "Jundong Xu",
      "Hao Fei",
      "Meng Luo",
      "Qian Liu",
      "Liangming Pan",
      "William Yang Wang",
      "Preslav Nakov",
      "Mong-Li Lee",
      "Wynne Hsu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.154": {
    "title": "LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs",
    "volume": "long",
    "abstract": "Long-context modeling has drawn more and more attention in the area of Large Language Models (LLMs). Continual training with long-context data becomes the de-facto method to equip LLMs with the ability to process long inputs. However, it still remains an open challenge to measure the quality of long-context training data. To address this issue, we propose a Long-context data selection framework with Attention-based Dependency Measurement (LADM), which can efficiently identify high-quality long-context data from a large-scale, multi-domain pre-training corpus. LADM leverages the retrieval capabilities of the attention mechanism to capture contextual dependencies, ensuring a comprehensive quality measurement of long-context data. Experimental results show that our LADM framework significantly boosts the performance of LLMs on multiple long-context tasks with only 1B tokens for continual training",
    "checked": true,
    "id": "f9575c9f6a3405dda5af2dfa0fe257ad36ea2a18",
    "semantic_title": "ladm: long-context training data selection with attention-based dependency measurement for llms",
    "citation_count": 1,
    "authors": [
      "Jianghao Chen",
      "Junhong Wu",
      "Yangyifan Xu",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.155": {
    "title": "Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training",
    "volume": "long",
    "abstract": "Machine-generated Text (MGT) detection is crucial for regulating and attributing online texts. While the existing MGT detectors achieve strong performance, they remain vulnerable to simple perturbations and adversarial attacks. To build an effective defense against malicious perturbations, we view MGT detection from a threat modeling perspective, that is, analyzing the model's vulnerability from an adversary's point of view and exploring effective mitigations. To this end, we introduce an adversarial framework for training a robust MGT detector, named GREedy Adversary PromoTed DefendER (GREATER). The GREATER consists of two key components: an adversary GREATER-A and a detector GREATER-D. The GREATER-D learns to defend against the adversarial attack from GREATER-A and generalizes the defense to other attacks. GREATER-A identifies and perturbs the critical tokens in embedding space, along with greedy search and pruning to generate stealthy and disruptive adversarial examples. Besides, we update the GREATER-A and GREATER-D synchronously, encouraging the GREATER-D to generalize its defense to different attacks and varying attack intensities. Our experimental results across 10 text perturbation strategies and 6 adversarial attacks show that our GREATER-D reduces the Attack Success Rate (ASR) by 0.67% compared with SOTA defense methods while our GREATER-A is demonstrated to be more effective and efficient than SOTA attack approaches. Codes and dataset are available in https://github.com/Liyuuuu111/GREATER",
    "checked": true,
    "id": "5f24db2a4154f9dd634af37cfda656ff274c216a",
    "semantic_title": "iron sharpens iron: defending against attacks in machine-generated text detection with adversarial training",
    "citation_count": 1,
    "authors": [
      "Yuanfan Li",
      "Zhaohan Zhang",
      "Chengzhengxu Li",
      "Chao Shen",
      "Xiaoming Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.156": {
    "title": "Cultural Learning-Based Culture Adaptation of Language Models",
    "volume": "long",
    "abstract": "Adapting large language models (LLMs) to diverse cultural values is a challenging task, as existing LLMs often reflect the values of specific groups by default, and potentially cause harm to others. In this paper, we present CLCA, a novel framework for enhancing LLM alignment with cultural values based on cultural learning. The framework leverages simulated social interactions to generate conversations in which LLMs engage in role-playing within culturally adapted social scenarios, capturing implicit cultural norms for model fine-tuning. CLCA improves cultural value alignment across various model architectures measured using World Value Survey data, demonstrating the effectiveness of our proposed approach. Our results provide early evidence that understanding intent and social interactions can enhance cultural value adaptation in LLMs, highlighting the promise of training approaches based on cultural learning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Cecilia Liu",
      "Anna Korhonen",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.157": {
    "title": "A-TASC: Asian TED-Based Automatic Subtitling Corpus",
    "volume": "long",
    "abstract": "Subtitles play a crucial role in improving the accessibility of the vast amount of audiovisual content available on the Internet, allowing audiences worldwide to comprehend and engage with this content in various languages. Automatic subtitling (AS) systems are essential for alleviating the substantial workload of human transcribers and translators. However, existing AS corpora and the primary metric SubER focus on European languages. This paper introduces A-TASC, an Asian TED-based automatic subtitling corpus derived from English TED Talks, comprising nearly 800 hours of audio segments, aligned English transcripts, and subtitles in Chinese, Japanese, Korean, and Vietnamese. We then present SacreSubER, a modification of SubER, to enable the reliable evaluation of subtitle quality for languages without explicit word boundaries. Experimental results, using both end-to-end systems and pipeline approaches built on strong ASR and LLM components, validate the quality of the proposed corpus and reveal differences in AS performance between European and Asian languages. The code to build our corpus is released",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Zhou",
      "Naoki Yoshinaga"
    ]
  },
  "https://aclanthology.org/2025.acl-long.158": {
    "title": "Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training",
    "volume": "long",
    "abstract": "This study addresses a critical gap in safety tuning practices for Large Language Models (LLMs) by identifying and tackling a refusal position bias within safety tuning data, which compromises the models' ability to appropriately refuse generating unsafe content. We introduce a novel approach, Decoupled Refusal Training (DeRTa), designed to empower LLMs to refuse compliance to harmful prompts at any response position, significantly enhancing their safety capabilities. DeRTa incorporates two novel components: (1) Maximum Likelihood Estimation (MLE) with Harmful Response Prefix, which trains models to recognize and avoid unsafe content by appending a segment of harmful response to the beginning of a safe response, and (2) Reinforced Transition Optimization (RTO), which equips models with the ability to transition from potential harm to safety refusal consistently throughout the harmful response sequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model families across six attack scenarios, demonstrates that our method not only improves model safety without compromising performance but also surpasses baseline methods in defending against attacks",
    "checked": true,
    "id": "242c76a916f83a6e7ec368c76c0c546d69cefc00",
    "semantic_title": "refuse whenever you feel unsafe: improving safety in llms via decoupled refusal training",
    "citation_count": 32,
    "authors": [
      "Youliang Yuan",
      "Wenxiang Jiao",
      "Wenxuan Wang",
      "Jen-tse Huang",
      "Jiahao Xu",
      "Tian Liang",
      "Pinjia He",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.159": {
    "title": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs",
    "volume": "long",
    "abstract": "Extracting sentence embeddings from large language models (LLMs) is a promising direction, as LLMs have demonstrated stronger semantic understanding capabilities. Previous studies typically focus on prompt engineering to elicit sentence embeddings from LLMs by prompting the model to encode sentence information into the embedding of the last token.However, LLMs are mostly decoder-only models with causal attention and the earlier tokens in the sentence cannot attend to the latter tokens, resulting in biased encoding of sentence information and cascading effects on the final decoded token.To this end, we propose a novel Token Prepending (TP) technique that prepends each layer's decoded sentence embedding to the beginning of the sentence in the next layer's input, allowing earlier tokens to attend to the complete sentence information under the causal attention mechanism.The proposed TP technique is a plug-and-play and training-free technique, which means it can be seamlessly integrated with various prompt-based sentence embedding methods and autoregressive LLMs.Extensive experiments on various Semantic Textual Similarity (STS) tasks and downstream classification tasks demonstrate that our proposed TP technique can significantly improve the performance of existing prompt-based sentence embedding methods across different LLMs, while incurring negligible additional inference cost",
    "checked": true,
    "id": "d7a77fd6da5afd5afcb7abb5deae210237bd98a6",
    "semantic_title": "token prepending: a training-free approach for eliciting better sentence embeddings from llms",
    "citation_count": 2,
    "authors": [
      "Yuchen Fu",
      "Zifeng Cheng",
      "Zhiwei Jiang",
      "Zhonghui Wang",
      "Yafeng Yin",
      "Zhengliang Li",
      "Qing Gu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.160": {
    "title": "No Questions are Stupid, but some are Poorly Posed: Understanding Poorly-Posed Information-Seeking Questions",
    "volume": "long",
    "abstract": "Questions help unlock information to satisfy users' information needs. However, when the question is poorly posed, answerers (whether human or computer) may struggle to answer the question in a way that satisfies the asker, despite possibly knowing everything necessary to address the asker's latent information need. Using Reddit question-answer interactions from r/NoStupidQuestions, we develop a computational framework grounded in linguistic theory to study poorly-posedness of questions by generating spaces of potential interpretations of questions and computing distributions over these spaces based on interpretations chosen by both human answerers in the Reddit question thread, as well as by a suite of large language models. Both humans and models struggle to converge on dominant interpretations when faced with poorly-posed questions, but employ different strategies: humans focus on specific interpretations through question negotiation, while models attempt comprehensive coverage by addressing many interpretations simultaneously",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neha Srikanth",
      "Rachel Rudinger",
      "Jordan Lee Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.161": {
    "title": "Understanding Common Ground Misalignment in Goal-Oriented Dialog: A Case-Study with Ubuntu Chat Logs",
    "volume": "long",
    "abstract": "While it is commonly accepted that maintaining common ground plays a role in conversational success, little prior research exists connecting conversational grounding to success in task-oriented conversations. We study failures of grounding in the Ubuntu IRC dataset, where participants use text-only communication to resolve technical issues. We find that disruptions in conversational flow often stem from a misalignment in common ground, driven by a divergence in beliefs and assumptions held by participants. These disruptions, which we call conversational friction, significantly correlate with task success. While LLMs can identify overt cases of conversational friction, they struggle with subtler and more context-dependent instances that require pragmatic or domain-specific reasoning",
    "checked": true,
    "id": "c6d2100051970dcd23b497fcce34cdbb39944f20",
    "semantic_title": "understanding common ground misalignment in goal-oriented dialog: a case-study with ubuntu chat logs",
    "citation_count": 0,
    "authors": [
      "Rupak Sarkar",
      "Neha Srikanth",
      "Taylor Pellegrin",
      "Rachel Rudinger",
      "Claire Bonial",
      "Philip Resnik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.162": {
    "title": "Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models",
    "volume": "long",
    "abstract": "Evaluating Video Language Models (VLMs) is a challenging task. Due to its transparency, Multiple-Choice Question Answering (MCQA) is widely used to measure the performance of these models through accuracy. However, existing MCQA benchmarks fail to capture the full reasoning capabilities of VLMs due to selection bias, when models disproportionately favor certain answer options based on positional patterns observed during training. In this work, we conduct a comprehensive empirical analysis of several VLM architectures across major datasets designed to assess complex video-focused reasoning. We identify where the bias is most pronounced and demonstrate to what extent model responses reflect genuine understanding of video content and related questions, as opposed to reliance on arbitrary patterns or superficial cues, such as answer position. By decomposing the MCQA task and adapting fairness bias metrics to VLMs, we introduce a post-processing calibration technique BOLD to balance this bias. Our results show that reducing selection bias improves not only debiasing metrics but also overall model performance, including Accuracy and F1 Mean score. Our method, by suppressing \"blind guessing\", offers a more cost- and time-effective approach to mitigating selection bias compared to existing techniques. This study represents the first focused investigation of selection bias in video-to-text LLM-powered models",
    "checked": true,
    "id": "a5dd702d2819d0bb5e28980d99cf1c285e91dff0",
    "semantic_title": "addressing blind guessing: calibration of selection bias in multiple-choice question answering by video language models",
    "citation_count": 2,
    "authors": [
      "Olga Loginova",
      "Oleksandr Bezrukov",
      "Ravi Shekhar",
      "Alexey Kravets"
    ]
  },
  "https://aclanthology.org/2025.acl-long.163": {
    "title": "Towards Reward Fairness in RLHF: From a Resource Allocation Perspective",
    "volume": "long",
    "abstract": "Rewards serve as proxies for human preferences and play a crucial role in Reinforcement Learning from Human Feedback (RLHF). However, if these rewards are inherently imperfect, exhibiting various biases, they can adversely affect the alignment of large language models (LLMs). In this paper, we collectively define the various biases present in rewards as the problem of reward unfairness. We propose a bias-agnostic method to address the issue of reward fairness from a resource allocation perspective, without specifically designing for each type of bias, yet effectively mitigating them. Specifically, we model preference learning as a resource allocation problem, treating rewards as resources to be allocated while considering the trade-off between utility and fairness in their distribution. We propose two methods, Fairness Regularization and Fairness Coefficient, to achieve fairness in rewards. We apply our methods in both verification and reinforcement learning scenarios to obtain a fairness reward model and a policy model, respectively. Experiments conducted in these scenarios demonstrate that our approach aligns LLMs with human preferences in a more fair manner. Our data and code are available athttps://github.com/shoyua/Towards-Reward-Fairness",
    "checked": true,
    "id": "fab2cb0b275dc555024af61b22e14219971393c5",
    "semantic_title": "towards reward fairness in rlhf: from a resource allocation perspective",
    "citation_count": 0,
    "authors": [
      "Sheng Ouyang",
      "Yulan Hu",
      "Ge Chen",
      "Qingyang Li",
      "Fuzheng Zhang",
      "Yong Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.164": {
    "title": "Taming LLMs with Gradient Grouping",
    "volume": "long",
    "abstract": "Training large language models (LLMs) poses challenges due to their massive scale and heterogeneous architectures. While adaptive optimizers like AdamW help address gradient variations, they still struggle with efficient and effective parameter-wise learning rate estimation, resulting in training instability, slow convergence, and poor compatibility with parameter-efficient fine-tuning (PEFT) techniques. This work introduces Scaling with Gradient Grouping (SGG), an optimizer wrapper that improves adaptive learning rate estimation by dynamic grouping and group-specific scaling. SGG first groups gradient statistics in each layer into clusters and then applies cluster-specific scaling to calibrate learning rates for each parameter, thus imposing collective group-wise constraints while maintaining precise per-parameter adaptation. Experiments on diverse (M)LLM benchmarks show that SGG integrates seamlessly with existing optimizers, and offers consistent gains and faster convergence over baselines, with various model sizes. Its stability across varying batch sizes and learning rates establishes SGG as a robust choice for LLM optimization",
    "checked": false,
    "id": "5f94ae83094accb22334994eb0ab1dc4ba1d346b",
    "semantic_title": "taming llms by scaling learning rates with gradient grouping",
    "citation_count": 0,
    "authors": [
      "Siyuan Li",
      "Juanxi Tian",
      "Zedong Wang",
      "Xin Jin",
      "Zicheng Liu",
      "Wentao Zhang",
      "Dan Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.165": {
    "title": "LazyReview: A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews",
    "volume": "long",
    "abstract": "Peer review is a cornerstone of quality control in scientific publishing. With the increasing workload, the unintended use of ‘quick' heuristics, referred to as lazy thinking, has emerged as a recurring issue compromising review quality. Automated methods to detect such heuristics can help improve the peer-reviewing process. However, there is limited NLP research on this issue, and no real-world dataset exists to support the development of detection tools. This work introduces LazyReview, a dataset of peer-review sentences annotated with fine-grained lazy thinking categories. Our analysis reveals that Large Language Models (LLMs) struggle to detect these instances in a zero-shot setting. However, instruction-based fine-tuning on our dataset significantly boosts performance by 10-20 performance points, highlighting the importance of high-quality training data. Furthermore, a controlled experiment demonstrates that reviews revised with lazy thinking feedback are more comprehensive and actionable than those written without such feedback. We will release our dataset and the enhanced guidelines that can be used to train junior reviewers in the community",
    "checked": false,
    "id": "76a74d00ea891fe0e90cb6f76cfd528a70f18623",
    "semantic_title": "lazyreview a dataset for uncovering lazy thinking in nlp peer reviews",
    "citation_count": 0,
    "authors": [
      "Sukannya Purkayastha",
      "Zhuang Li",
      "Anne Lauscher",
      "Lizhen Qu",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.166": {
    "title": "Revisiting Common Assumptions about Arabic Dialects in NLP",
    "volume": "long",
    "abstract": "Arabic has diverse dialects, where one dialect can be substantially different from the others. In the NLP literature, some assumptions about these dialects are widely adopted (e.g., \"Arabic dialects can be grouped into distinguishable regional dialects\") and are manifested in different computational tasks such as Arabic Dialect Identification (ADI). However, these assumptions are not quantitatively verified. We identify four of these assumptions and examine them by extending and analyzing a multi-label dataset, where the validity of each sentence in 11 different country-level dialects is manually assessed by speakers of these dialects. Our analysis indicates that the four assumptions oversimplify reality, and some of them are not always accurate. This in turn might be hindering further progress in different Arabic NLP tasks",
    "checked": true,
    "id": "d5d8df5860b4e5a4e9bf8ef10c211f8887ec76dc",
    "semantic_title": "revisiting common assumptions about arabic dialects in nlp",
    "citation_count": 0,
    "authors": [
      "Amr Keleg",
      "Sharon Goldwater",
      "Walid Magdy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.167": {
    "title": "Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification",
    "volume": "long",
    "abstract": "Language models hold incredible promise for enabling scientific discovery by synthesizing massive research corpora. Many complex scientific research questions have multiple plausible answers, each supported by evidence of varying strength. However, existing language models lack the capability to quantitatively and faithfully compare answer plausibility in terms of supporting evidence. To address this, we introduce Retrieve to Explain (R2E), a retrieval-based model that scores and ranks all possible answers to a research question based on evidence retrieved from a document corpus. The architecture represents each answer only in terms of its supporting evidence, with the answer itself masked. This allows us to extend feature attribution methods such as Shapley values, to transparently attribute answer scores to supporting evidence at inference time. The architecture also allows incorporation of new evidence without retraining, including non-textual data modalities templated into natural language. We developed R2E for the challenging scientific discovery task of drug target identification, a human-in-the-loop process where failures are extremely costly and explainability paramount. When predicting whether drug targets will subsequently be confirmed as efficacious in clinical trials, R2E not only matches non-explainable literature-based models but also surpasses a genetics-based target identification approach used throughout the pharmaceutical industry",
    "checked": true,
    "id": "0736fb0ed61a3cceb5349b44b19af7940e7dd494",
    "semantic_title": "retrieve to explain: evidence-driven predictions for explainable drug target identification",
    "citation_count": 0,
    "authors": [
      "Ravi Patel",
      "Angus Brayne",
      "Rogier Hintzen",
      "Daniel Jaroslawicz",
      "Georgiana Neculae",
      "Dane S. Corneil"
    ]
  },
  "https://aclanthology.org/2025.acl-long.168": {
    "title": "Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas",
    "volume": "long",
    "abstract": "LLMs are aligned to follow input instructions by learning which of two responses users prefer for a prompt. However, such preference data do not convey *why* users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To surface these parameters of personalization, we apply *abductive reasoning* to preference data, inferring needs and interests of users, i.e., personas, that may prefer either response. We test this idea in two steps: **Persona Inference (PI)**—abductively inferring personas of users who prefer chosen or rejected outputs—and **Persona Tailoring (PT)**—training models to tailor outputs to personas from PI. We show: 1) LLMs infer personas accurately explaining why different users may prefer *both* chosen or rejected outputs; 2) Training on preference data augmented with PI personas via PT boosts personalization and generalizes to supporting user-written personas; and 3) Rejected response personas form harder personalization evaluations, showing PT better aids users with uncommon preferences versus typical alignment methods. We argue for an abductive view of preferences for personalization, asking not only which response is better but when, why, and for whom",
    "checked": true,
    "id": "af0bd618ed97579b044f7540e8c128832a52d5ee",
    "semantic_title": "whose boat does it float? improving personalization in preference tuning via inferred user personas",
    "citation_count": 7,
    "authors": [
      "Nishant Balepur",
      "Vishakh Padmakumar",
      "Fumeng Yang",
      "Shi Feng",
      "Rachel Rudinger",
      "Jordan Lee Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.169": {
    "title": "Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above",
    "volume": "long",
    "abstract": "Multiple choice question answering (MCQA) is popular for LLM evaluation due to its simplicity and human-like testing, but we argue for its reform. We first reveal flaws in MCQA's format, as it struggles to: 1) test generation/subjectivity; 2) match LLM use cases; and 3) fully test knowledge. We instead advocate for generative formats based on human testing—where LLMs construct and explain answers—better capturing user needs and knowledge while remaining easy to score. We then show even when MCQA is a useful format, its datasets suffer from: leakage; unanswerability; shortcuts; and saturation. In each issue, we give fixes from education, like rubrics to guide MCQ writing; scoring methods to bridle guessing; and Item Response Theory to build harder MCQs. Lastly, we discuss LLM errors in MCQA—robustness, biases, and unfaithful explanations—showing how our prior solutions better measure or address these issues. While we do not need to desert MCQA, we encourage more efforts in refining the task based on educational testing, advancing evaluations",
    "checked": true,
    "id": "d24f355d004362e7cfc2717acc6488effa4b64b5",
    "semantic_title": "which of these best describes multiple choice evaluation with llms? a) forced b) flawed c) fixable d) all of the above",
    "citation_count": 7,
    "authors": [
      "Nishant Balepur",
      "Rachel Rudinger",
      "Jordan Lee Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.170": {
    "title": "Detection of Human and Machine-Authored Fake News in Urdu",
    "volume": "long",
    "abstract": "The rise of social media has amplified the spread of fake news, now further complicated by large language models (LLMs) like ChatGPT, which ease the generation of highly convincing, error-free misinformation, making it increasingly challenging for the public to discern truth from falsehood. Traditional fake news detection methods relying on linguistic cues have also become less effective. Moreover, current detectors primarily focus on binary classification and English texts, often overlooking the distinction between machine-generated true vs. fake news and the detection in low-resource languages. To this end, we updated the detection schema to include machine-generated news focusing on Urdu. We further propose a conjoint detection strategy to improve the accuracy and robustness. Experiments show its effectiveness across four datasets in various settings",
    "checked": true,
    "id": "f946d55b2d59e3288da28111cc2f623fcf2f50b7",
    "semantic_title": "detection of human and machine-authored fake news in urdu",
    "citation_count": 1,
    "authors": [
      "Muhammad Zain Ali",
      "Yuxia Wang",
      "Bernhard Pfahringer",
      "Tony C Smith"
    ]
  },
  "https://aclanthology.org/2025.acl-long.171": {
    "title": "An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals",
    "volume": "long",
    "abstract": "Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue systems to optimize dialogue policy, but it struggles to balance exploration and exploitation due to the high dimensionality of state and action spaces. This challenge often results in local optima or poor convergence. Evolutionary Algorithms (EAs) have been proven to effectively explore the solution space of neural networks by maintaining population diversity. Inspired by this, we innovatively combine the global search capabilities of EA with the local optimization of DRL to achieve a balance between exploration and exploitation. Nevertheless, the inherent flexibility of natural language in dialogue tasks complicates this direct integration, leading to prolonged evolutionary times. Thus, we further propose an elite individual injection mechanism to enhance EA's search efficiency by adaptively introducing best-performing individuals into the population. Experiments across four datasets show that our approach significantly improves the balance between exploration and exploitation, boosting performance. Moreover, the effectiveness of the EII mechanism in reducing exploration time has been demonstrated, achieving an efficient integration of EA and DRL on task-oriented dialogue policy tasks",
    "checked": true,
    "id": "7f83c8a644f873b99bb925643019846455036fc6",
    "semantic_title": "an efficient task-oriented dialogue policy: evolutionary reinforcement learning injected by elite individuals",
    "citation_count": 0,
    "authors": [
      "Yangyang Zhao",
      "Ben Niu",
      "Libo Qin",
      "Shihan Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.172": {
    "title": "SR-LLM: Rethinking the Structured Representation in Large Language Model",
    "volume": "long",
    "abstract": "Structured representations, exemplified by Abstract Meaning Representation (AMR), have long been pivotal in computational linguistics. However, their role remains ambiguous in the Large Language Models (LLMs) era. Initial attempts to integrate structured representation into LLMs via a zero-shot setting yielded inferior performance. We hypothesize that such a decline stems from the structure information being passed into LLMs in a code format unfamiliar to LLMs' training corpora. Consequently, we propose SR-LLM, an innovative framework with two settings to explore a superior way of integrating structured representation with LLMs from training-free and training-dependent perspectives. The former integrates structural information through natural language descriptions in LLM prompts, whereas its counterpart augments the model's inference capability through fine-tuning on linguistically described structured representations. Performance improvements were observed in widely downstream datasets, with particularly notable gains of 3.17% and 12.38% in PAWS. To the best of our knowledge, this work represents the pioneering demonstration that leveraging structural representations can substantially enhance LLMs' inference capability. We hope that our work sheds light and encourages future research to enhance the reasoning and interoperability of LLMs by structure data",
    "checked": true,
    "id": "4fe4fc4d1af2711d713c6dda8ec1c1f2c04f3e6e",
    "semantic_title": "sr-llm: rethinking the structured representation in large language model",
    "citation_count": 1,
    "authors": [
      "Jiahuan Zhang",
      "Tianheng Wang",
      "Ziyi Huang",
      "Yulong Wu",
      "Hanqing Wu",
      "DongbaiChen DongbaiChen",
      "Linfeng Song",
      "Yue Zhang",
      "Guozheng Rao",
      "Kaicheng Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.173": {
    "title": "Taming Language Models for Text-attributed Graph Learning with Decoupled Aggregation",
    "volume": "long",
    "abstract": "Text-attributed graphs (TAGs) are prevalent in various real-world applications, including academic networks, e-commerce platforms, and social networks. Effective learning on TAGs requires leveraging both textual node features and structural graph information. While language models (LMs) excel at processing text and graph neural networks (GNNs) effectively capture relational structures, their direct integration is computationally prohibitive due to the high cost of text and graph representation learning. Existing approaches address this challenge by adopting a two-step pipeline where LMs generate fixed node embeddings, which are then used for GNN training. However, this method neglects the interaction between textual and structural information, leading to suboptimal learning outcomes. To overcome these limitations, we propose SKETCH (Semantic Knowledge and Structure Enrichment), a novel framework that decouples node aggregation from graph convolution and integrates it into the text representation learning process. SKETCH enhances TAG learning by incorporating two key aggregation mechanisms: (1) Semantic aggregation, which retrieves semantically relevant node texts for contextual enrichment, and (2) Structural aggregation, which propagates textual features beyond immediate neighbors to capture broader graph relationships. Extensive experiments demonstrate that SKETCH outperforms state-of-the-art TAG learning methods while requiring fewer computational resources. By enabling a more efficient and effective fusion of textual and structural information, SKETCH provides new insights into TAG problems and offers a practical solution for real applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuang Zhou",
      "Zhu Wang",
      "Shengyuan Chen",
      "Jiahe Du",
      "Qiyuan Zheng",
      "Zhaozhuo Xu",
      "Xiao Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.174": {
    "title": "Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering",
    "volume": "long",
    "abstract": "Extracting sentence embeddings from large language models (LLMs) is a practical direction, as it requires neither additional data nor fine-tuning. Previous studies usually focus on prompt engineering to guide LLMs to encode the core semantic information of the sentence into the embedding of the last token. However, the last token in these methods still encodes an excess of non-essential information, such as stop words, limiting its encoding capacity. To this end, we propose a Contrastive Prompting (CP) technique that introduces an extra auxiliary prompt to elicit better sentence embedding. By contrasting with the auxiliary prompt, CP can steer existing prompts to encode the core semantics of the sentence, rather than non-essential information. CP is a plug-and-play inference-time intervention method that can be combined with various prompt-based methods. Extensive experiments on Semantic Textual Similarity (STS) tasks and downstream classification tasks demonstrate that our method can improve the performance of existing prompt-based methods across different LLMs",
    "checked": true,
    "id": "0ea780e126c70b5e70d074049db412d1f791208f",
    "semantic_title": "contrastive prompting enhances sentence embeddings in llms through inference-time steering",
    "citation_count": 1,
    "authors": [
      "Zifeng Cheng",
      "Zhonghui Wang",
      "Yuchen Fu",
      "Zhiwei Jiang",
      "Yafeng Yin",
      "Cong Wang",
      "Qing Gu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.175": {
    "title": "Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence",
    "volume": "long",
    "abstract": "Large vision-language models (LVLMs) have made substantial progress in integrating large language models (LLMs) with visual inputs, enabling advanced multimodal reasoning. Despite their success, a persistent challenge is hallucination—where generated text fails to accurately reflect visual content—undermining both accuracy and reliability. Existing methods focus on alignment training or decoding refinements but primarily address symptoms at the generation stage without probing the underlying causes. In this work, we investigate the internal mechanisms driving hallucination in LVLMs, with an emphasis on the multi-head attention module. Specifically, we introduce Vision-aware Head Divergence (VHD), a metric that quantifies the sensitivity of attention head outputs to visual context. Based on this, our findings reveal the presence of vision-aware attention heads that are more attuned to visual information; however, the model's overreliance on its prior language patterns is closely related to hallucinations. Building on these insights, we propose Vision-aware Head Reinforcement (VHR), a training-free approach to mitigate hallucination by enhancing the role of vision-aware attention heads. Extensive experiments demonstrate that our method achieves superior performance compared to state-of-the-art approaches in mitigating hallucinations, while maintaining high efficiency with negligible additional time overhead. The code is available at https://github.com/jinghan1he/VHR",
    "checked": true,
    "id": "41d8d18f8ca9942ab62fab8092cd13757640d720",
    "semantic_title": "cracking the code of hallucination in lvlms with vision-aware head divergence",
    "citation_count": 5,
    "authors": [
      "Jinghan He",
      "Kuan Zhu",
      "Haiyun Guo",
      "Junfeng Fang",
      "Zhenglin Hua",
      "Yuheng Jia",
      "Ming Tang",
      "Tat-Seng Chua",
      "Jinqiao Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.176": {
    "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation",
    "volume": "long",
    "abstract": "Real-world RAG applications often encounter long-context input scenarios, where redundant information and noise results in higher inference costs and reduced performance. To address these challenges, we propose LongRefiner, an efficient plug-and-play refiner that leverages the inherent structural characteristics of long documents. LongRefiner employs dual-level query analysis, hierarchical document structuring, and adaptive refinement through multi-task learning on a single foundation model. Experiments on seven QA datasets demonstrate that LongRefiner achieves competitive performance in various scenarios while using 10x fewer computational costs and latency compared to the best baseline. Further analysis validates that LongRefiner is scalable, efficient, and effective, providing practical insights for real-world long-text RAG applications. Our code is available at https://github.com/ignorejjj/LongRefiner",
    "checked": true,
    "id": "a71c99d3836007721e8e6194f9c52f17ca77187d",
    "semantic_title": "hierarchical document refinement for long-context retrieval-augmented generation",
    "citation_count": 1,
    "authors": [
      "Jiajie Jin",
      "Xiaoxi Li",
      "Guanting Dong",
      "Yuyao Zhang",
      "Yutao Zhu",
      "Yongkang Wu",
      "Zhonghua Li",
      "Ye Qi",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.177": {
    "title": "Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations",
    "volume": "long",
    "abstract": "As the impact of large language models increases, understanding the moral values they encode becomes ever more important. Assessing moral values encoded in these models via direct prompting is challenging due to potential leakage of human norms into model training data, and their sensitivity to prompt formulation. Instead, we propose to use word associations, which have been shown to reflect moral reasoning in humans, as low-level underlying representations to obtain a more robust picture of LLMs' moral reasoning. We study moral differences in associations from western English-speaking communities and LLMs trained predominantly on English data. First, we create a large dataset of LLM-generated word associations, resembling an existing data set of human word associations. Next, we propose a novel method to propagate moral values based on seed words derived from Moral Foundation Theory through the human and LLM-generated association graphs. Finally, we compare the resulting moral representations, highlighting detailed but systematic differences between moral values emerging from English speakers and LLM associations",
    "checked": true,
    "id": "6e040100c878c66bf119db7cda995fe5b3f4b9c5",
    "semantic_title": "comparing moral values in western english-speaking societies and llms with word associations",
    "citation_count": 0,
    "authors": [
      "Chaoyi Xiang",
      "Chunhua Liu",
      "Simon De Deyne",
      "Lea Frermann"
    ]
  },
  "https://aclanthology.org/2025.acl-long.178": {
    "title": "TEACH: A Contrastive Knowledge Adaptive Distillation Framework for Classical Chinese Understanding",
    "volume": "long",
    "abstract": "Traditional methods for processing classical Chinese typically segment language understanding into discrete tasks, which overlook crucial background information and reduce user engagement. Large language models (LLMs) provide integrated solutions, yet they entail high computational costs and risks of generating inaccurate historical information. To tackle these challenges, we propose a novel framework, TEACH (conTrastive knowlEdge Adaptive distillation with enhanCed Historical interpretability), which focuses on classical Chinese understanding by integrating word sense disambiguation with sentence translation. This integration leverages a confidence-annotated knowledge base and a step-by-step Chain-of-Thought prompting mechanism to minimize hallucinations and improve semantic analysis. Moreover, TEACH employs contrastive distillation learning to efficiently transfer capabilities from larger models to smaller ones (e.g., Qwen2-1.5B), addressing overly liberal translations. Additionally, we introduce an innovative generation evaluation metric using iterative word alignment, enhancing LLM performance assessments by distinguishing additional information and addressing excessive translation issues. Experiments conducted on real-world datasets validate TEACH's efficacy in classical Chinese educational scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuting Wei",
      "Qi Meng",
      "Yuanxing Xu",
      "Bin Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.179": {
    "title": "RAG-Critic: Leveraging Automated Critic-Guided Agentic Workflow for Retrieval Augmented Generation",
    "volume": "long",
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a pivotal technology in natural language processing, owing to its efficacy in generating factual content. However, its informative inputs and complex paradigms often lead to a greater variety of errors. Consequently, achieving automated on-policy assessment and error-oriented correction remain unresolved issues. In this paper, we propose RAG-Critic, a novel framework that leverages a critic-guided agentic workflow to improve RAG capabilities autonomously. Specifically, we initially design a data-driven error mining pipeline to establish a hierarchical RAG error system. Based on this system, we progressively align an error-critic model using a coarse-to-fine training objective, which automatically provides fine-grained error feedback. Finally, we design a critic-guided agentic RAG workflow that customizes executor-based solution flows based on the error-critic model's feedback, facilitating an error-driven self-correction process. Experimental results across seven RAG-related datasets confirm the effectiveness of RAG-Critic, while qualitative analysis offers practical insights for achieving reliable RAG systems. Our dataset and code are available at https://github.com/RUC-NLPIR/RAG-Critic",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanting Dong",
      "Jiajie Jin",
      "Xiaoxi Li",
      "Yutao Zhu",
      "Zhicheng Dou",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.180": {
    "title": "Progressive Multimodal Reasoning via Active Retrieval",
    "volume": "long",
    "abstract": "Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). AR-MCTS follows the MCTS algorithm and heuristically integrates an active retrieval mechanism during the expansion stage to automatically acquire high-quality step-wise reasoning annotations. Moreover, we further introduce curriculum training objectives to progressively align with a process reward model, ultimately achieving process-level multimodal reasoning verification. Experimental results across three complex multimodal reasoning benchmarks confirm the effectiveness of AR-MCTS. Further analysis demonstrates that it can optimize sampling diversity and accuracy, yielding reliable multimodal reasoning",
    "checked": true,
    "id": "f05cf0438b5dc19bc4d32ca6cd85d1525c936de6",
    "semantic_title": "progressive multimodal reasoning via active retrieval",
    "citation_count": 11,
    "authors": [
      "Guanting Dong",
      "Chenghao Zhang",
      "Mengjie Deng",
      "Yutao Zhu",
      "Zhicheng Dou",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.181": {
    "title": "Pre-training Distillation for Large Language Models: A Design Space Exploration",
    "volume": "long",
    "abstract": "Knowledge distillation (KD) aims to transfer knowledge from a large teacher model to a smaller student model. Previous work applying KD in the field of large language models (LLMs) typically focused on the post-training phase, where the student LLM learns directly from instructions and corresponding responses generated by the teacher model. In this paper, we extend KD to the pre-training phase of LLMs, named pre-training distillation (PD). We first conduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a 1.9B parameter student LLM, validating the effectiveness of PD. Considering the key impact factors of distillation, we systematically explore the design space of pre-training distillation across four aspects: logits processing, loss selection, scaling law, and offline or online logits. We conduct extensive experiments to explore the design space of pre-training distillation and find better configurations and interesting conclusions, such as larger student LLMs generally benefiting more from pre-training distillation, while a larger teacher LLM does not necessarily guarantee better results. We hope our exploration of the design space will inform future practices in pre-training distillation",
    "checked": true,
    "id": "1db93f8ce312fac041f9271a9b8068b9cb4b9fb2",
    "semantic_title": "pre-training distillation for large language models: a design space exploration",
    "citation_count": 4,
    "authors": [
      "Hao Peng",
      "Xin Lv",
      "Yushi Bai",
      "Zijun Yao",
      "Jiajie Zhang",
      "Lei Hou",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.182": {
    "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions",
    "volume": "long",
    "abstract": "In visual question answering (VQA) context, users often pose ambiguous questions to visual language models (VLMs) due to varying expression habits. Existing research addresses such ambiguities primarily by rephrasing questions. These approaches neglect the inherently interactive nature of user interactions with VLMs, where ambiguities can be clarified through user feedback. However, research on interactive clarification faces two major challenges: (1) Benchmarks are absent to assess VLMs' capacity for resolving ambiguities through interaction; (2) VLMs are trained to prefer answering rather than asking, preventing them from seeking clarification. To overcome these challenges, we introduce ClearVQA benchmark, which targets three common categories of ambiguity in VQA context, and encompasses various VQA scenarios. Furthermore, we propose an automated pipeline to generate ambiguity-clarification question pairs, enabling VLMs to ask reasonable clarification questions and generate more accurate and specific answers based on user feedback, as demonstrated by experimental results",
    "checked": false,
    "id": "67241544ae69cf2972376439e35494f6e8c26dba",
    "semantic_title": "learning by asking for embodied visual navigation and task completion",
    "citation_count": 2,
    "authors": [
      "Pu Jian",
      "Donglei Yu",
      "Wen Yang",
      "Shuo Ren",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.183": {
    "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks",
    "volume": "long",
    "abstract": "This paper introduces LongBench v2, a benchmark designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 consists of 503 challenging multiple-choice questions, with contexts ranging from 8k to 2M words, across six major task categories: single-document QA, multi-document QA, long in-context learning, long-dialogue history understanding, code repository understanding, and long structured data understanding. To ensure the breadth and the practicality, we collect data from nearly 100 highly educated individuals with diverse professional backgrounds. We employ both automated and manual review processes to maintain high quality and difficulty, resulting in human experts achieving only 53.7% accuracy under a 15-minute time constraint. Our evaluation reveals that the best-performing model, when directly answers the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model, which includes longer reasoning, achieves 57.7%, surpassing the human baseline by 4%. These results highlight the importance of enhanced reasoning ability and scaling inference-time compute to tackle the long-context challenges in LongBench v2",
    "checked": true,
    "id": "06796ca506bb28419a734f777f069ea2f42c1eb9",
    "semantic_title": "longbench v2: towards deeper understanding and reasoning on realistic long-context multitasks",
    "citation_count": 45,
    "authors": [
      "Yushi Bai",
      "Shangqing Tu",
      "Jiajie Zhang",
      "Hao Peng",
      "Xiaozhi Wang",
      "Xin Lv",
      "Shulin Cao",
      "Jiazheng Xu",
      "Lei Hou",
      "Yuxiao Dong",
      "Jie Tang",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.184": {
    "title": "Battling against Tough Resister: Strategy Planning with Adversarial Game for Non-collaborative Dialogues",
    "volume": "long",
    "abstract": "Non-collaborative dialogue involves two participants with conflicting interests engaging in a multi-round dialogue to achieve their own goals. Strategy planning is the key to guiding both participants towards a consensus. Most LLMs-based methods use stimulus prompts or external strategy planners for strategy planning. However, stimulus prompts fail to teach LLMs to plan dialogue strategies explicitly. Moreover, training external strategy planners doesn't fully account for adversarial interactions, thereby limiting their effectiveness against tough resisters. In this paper, to mitigate the above issues, we propose GAIA, a Game-based Adversarial self-play InterActive training paradigm, which constructs an adversarial two-player (a persuader and a resister) zero-sum game and guides the game to approximate Nash Equilibrium (NE) via reinforcement learning (RL) for the non-collaborative dialogues. First, we design a Chain-of-Mind prompt to reason the resister's dialogue act step-by-step to plan the persuasive strategies. Secondly, to adversarially improve the persuader, we construct diverse resistant planners and theoretically improve the persuader's optimal lower bound. Finally, we iteratively optimise their policies via adversarial self-play interactive RL and design an 𝜖-NE verification algorithm to approximate the game's NE. Experiments on three datasets show that our model obtains state-of-the-art performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiyang Wang",
      "Zhiliang Tian",
      "Yuchen Pan",
      "Xin Song",
      "Xin Niu",
      "Minlie Huang",
      "Bin Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.185": {
    "title": "Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts",
    "volume": "long",
    "abstract": "Understanding the inner workings of Large Language Models (LLMs) is a critical research frontier. Prior research has shown that a single LLM's concept representations can be captured as steering vectors (SVs), enabling the control of LLM behavior (e.g., towards generating harmful content). Our work takes a novel approach by exploring the intricate relationships between concept representations across different LLMs, drawing an intriguing parallel to Plato's Allegory of the Cave. In particular, we introduce a linear transformation method to bridge these representations and present three key findings: 1) Concept representations across different LLMs can be effectively aligned using simple linear transformations, enabling efficient cross-model transfer and behavioral control via SVs. 2) This linear transformation generalizes across concepts, facilitating alignment and control of SVs representing different concepts across LLMs. 3) A weak-to-strong transferability exists between LLM concept representations, whereby SVs extracted from smaller LLMs can effectively control the behavior of larger LLMs. Our code is provided in the supplementary file and will be openly released",
    "checked": true,
    "id": "70c4c6a5dc844d7919983776d3cbd00f41af3347",
    "semantic_title": "cross-model transferability among large language models on the platonic representations of concepts",
    "citation_count": 1,
    "authors": [
      "Youcheng Huang",
      "Chen Huang",
      "Duanyu Feng",
      "Wenqiang Lei",
      "Jiancheng Lv"
    ]
  },
  "https://aclanthology.org/2025.acl-long.186": {
    "title": "FoldMoE: Efficient Long Sequence MoE Training via Attention-MoE Pipelining",
    "volume": "long",
    "abstract": "Training LLMs with Mixture-of-Experts (MoE) architecture on long sequences poses significant challenges due to the all-to-all communication bottleneck of expert parallelism. While existing approaches attempt to hide the communication costs in computation through token-level pipelining within MoE layers, their effectiveness is limited by the insufficient computation. We present FoldMoE, a high-performance MoE training system that enables token-level overlapping across entire Transformer blocks through novel attention-MoE pipelining. We propose an efficient pipeline schedule, and a novel token buffering design to decouple attention and MoE layer partitioning, along with a time-uniform micro-batching strategy for enhanced efficiency. Evaluations on GPT-MoE models with sequences up to 32K tokens show that FoldMoE achieves up to 1.49x and 2.72x speedup over state-of-the-art token-level overlapping and non-overlapping baselines respectively",
    "checked": false,
    "id": "304965a51b428af89df398ec0cc84314b00ac94c",
    "semantic_title": "janusdna: a powerful bi-directional hybrid dna foundation model",
    "citation_count": 0,
    "authors": [
      "Guichao Zhu",
      "Lintian Lei",
      "Yuhao Qing",
      "Yichao Fu",
      "Fanxin Li",
      "Dong Huang",
      "Zekai Sun",
      "Heming Cui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.187": {
    "title": "LongReward: Improving Long-context Large Language Models with AI Feedback",
    "volume": "long",
    "abstract": "Though significant advancements have been achieved in developing long-context large language models (LLMs), the compromised quality of LLM-synthesized data for supervised fine-tuning (SFT) often affects the long-context performance of SFT models and leads to inherent limitations. In principle, reinforcement learning (RL) with appropriate reward signals can further enhance models' capacities. However, how to obtain reliable rewards in long-context scenarios remains unexplored. To this end, we propose LongReward, a novel method that utilizes an off-the-shelf LLM to provide rewards for long-context model responses from four human-valued dimensions: helpfulness, logicality, faithfulness, and completeness, each with a carefully designed assessment pipeline. By combining LongReward and offline RL algorithm DPO, we are able to effectively improve long-context SFT models. Our experiments indicate that LongReward not only significantly improves models' long-context performance but also enhances their ability to follow short instructions. We also find that long-context DPO with LongReward and conventional short-context DPO can be used together without hurting either one's performance",
    "checked": true,
    "id": "5401d8fa36a78642971c694506594afdcb100c73",
    "semantic_title": "longreward: improving long-context large language models with ai feedback",
    "citation_count": 10,
    "authors": [
      "Jiajie Zhang",
      "Zhongni Hou",
      "Xin Lv",
      "Shulin Cao",
      "Zhenyu Hou",
      "Yilin Niu",
      "Lei Hou",
      "Yuxiao Dong",
      "Ling Feng",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.188": {
    "title": "Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles",
    "volume": "long",
    "abstract": "Calibration, the alignment between model confidence and prediction accuracy, is critical for the reliable deployment of large language models (LLMs). Existing works neglect to measure the generalization of their methods to other prompt styles and different sizes of LLMs. To address this, we define a controlled experimental setting covering 12 LLMs and four prompt styles. We additionally investigate if incorporating the response agreement of multiple LLMs and an appropriate loss function can improve calibration performance. Concretely, we build Calib-n, a novel framework that trains an auxiliary model for confidence estimation that aggregates responses from multiple LLMs to capture inter-model agreement. To optimize calibration, we integrate focal and AUC surrogate losses alongside binary cross-entropy. Experiments across four datasets demonstrate that both response agreement and focal loss improve calibration from baselines. We find that few-shot prompts are the most effective for auxiliary model-based methods, and auxiliary models demonstrate robust calibration performance across accuracy variations, outperforming LLMs' internal probabilities and verbalized confidences. These insights deepen the understanding of influence factors in LLM calibration, supporting their reliable deployment in diverse applications",
    "checked": true,
    "id": "3ae1d0fd1639383d30088ba7ea35ec189a4068d9",
    "semantic_title": "influences on llm calibration: a study of response agreement, loss functions, and prompt styles",
    "citation_count": 0,
    "authors": [
      "Yuxi Xia",
      "Pedro Henrique Luz De Araujo",
      "Klim Zaporojets",
      "Benjamin Roth"
    ]
  },
  "https://aclanthology.org/2025.acl-long.189": {
    "title": "UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench",
    "volume": "long",
    "abstract": "The advent of Large Language Models (LLMs) has spurred the development of coding agents for real-world code generation.As a widely used benchmark for evaluating the code generation capabilities of these agents, SWE-Bench uses real-world problems based on GitHub issues and their corresponding pull requests.However, the manually written test cases included in these pull requests are often insufficient, allowing generated patches to pass the tests without resolving the underlying issue.To address this challenge, we introduce UTGenerator, an LLM-driven test case generator that automatically analyzes codebases and dependencies to generate test cases for real-world Python projects.Building on UTGenerator, we propose UTBoost, a comprehensive framework for test case augmentation.In our evaluation, we identified 36 task instances with insufficient test cases and uncovered 345 erroneous patches incorrectly labeled as passed in the original SWE Bench.These corrections, impacting 40.9% of SWE-Bench Lite and 24.4% of SWE-Bench Verified leaderboard entries, yield 18 and 11 ranking changes, respectively",
    "checked": true,
    "id": "7e0d3c77e73a9aeb8e3ccc88e3fabc1d14fc16cc",
    "semantic_title": "utboost: rigorous evaluation of coding agents on swe-bench",
    "citation_count": 0,
    "authors": [
      "Boxi Yu",
      "Yuxuan Zhu",
      "Pinjia He",
      "Daniel Kang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.190": {
    "title": "Towards Better Evaluation for Generated Patent Claims",
    "volume": "long",
    "abstract": "Patent claims define the scope of protection and establish the legal boundaries of an invention. Drafting these claims is a complex and time-consuming process that usually requires the expertise of skilled patent attorneys, which can form a large access barrier for many small enterprises. To solve these challenges, researchers have investigated large language models (LLMs) for automating patent claim generation. However, existing studies highlight inconsistencies between automated evaluation metrics and human expert assessments. To bridge this gap, we introduce Patent-CE, the first comprehensive benchmark for evaluating patent claims. Patent-CE includes comparative claim evaluations annotated by patent experts, focusing on five key criteria: feature completeness, conceptual clarity, terminology consistency, logical linkage, and overall quality. Additionally, we propose PatClaimEval, a novel multi-dimensional evaluation method specifically designed for patent claims. Our experiments demonstrate that PatClaimEval achieves the highest correlation with human expert evaluations across all assessment criteria among all tested metrics. This research provides the groundwork for more accurate evaluations of automated patent claim generation systems",
    "checked": true,
    "id": "4d3a0b037e9e8f9c7774f20d2341c5a47414d470",
    "semantic_title": "towards better evaluation for generated patent claims",
    "citation_count": 2,
    "authors": [
      "Lekang Jiang",
      "Pascal A. Scherz",
      "Stefan Goetz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.191": {
    "title": "Fine-Tuning on Diverse Reasoning Chains Drives Within-Inference CoT Refinement in LLMs",
    "volume": "long",
    "abstract": "Requiring a large language model (LLM) to generate intermediary reasoning steps, known as Chain of Thought (CoT), has been shown to be an effective way of boosting performance. Previous approaches have focused on generating multiple independent CoTs, combining them through ensembling or other post-hoc strategies to enhance reasoning. In this work, we introduce a novel approach where LLMs are fine-tuned to generate a sequence of Diverse Chains of Thought (DCoT) within a single inference step, which is fundamentally different from prior work that primarily operate on parallel CoT generations. DCoT allows LLMs to gain the ability to perform within-inference refinement of reasoning chains without requiring external feedback. Through a rigorous set of experiments spanning a wide range of tasks that require various reasoning types, we show that fine-tuning on DCoT improves performance over the CoT baseline across model families and scales (1.3B to 70B). These improvements are particularly impactful for tasks with a large result state space, such as those involving numeric answers. Our work is also significant because both quantitative analyses and manual evaluations reveal the observed gains stem from the models' ability to refine an initial reasoning chain by generating a second, improved chain within the same inference step, demonstrating previously elusive self-improvement. Our code and data are publicly available",
    "checked": true,
    "id": "9667ade52a71dcfa0efb26bd06abf09708df7e1a",
    "semantic_title": "fine-tuning on diverse reasoning chains drives within-inference cot refinement in llms",
    "citation_count": 9,
    "authors": [
      "Haritz Puerto",
      "Tilek Chubakov",
      "Xiaodan Zhu",
      "Harish Tayyar Madabushi",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.192": {
    "title": "Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis",
    "volume": "long",
    "abstract": "The development of large language models (LLMs) depends on **trustworthy evaluation**. However, most current evaluations rely on public benchmarks, which are prone to data contamination issues that significantly compromise fairness. Previous researches have focused on constructing dynamic benchmarks to address contamination. However, continuously building new benchmarks is costly and cyclical.In this work, we aim to tackle contamination by analyzing the mechanisms of contaminated models themselves. Through our experiments, we discover that the overestimation of contaminated models is likely due to parameters acquiring shortcut solutions in training. We further propose a novel method for identifying shortcut neurons through **comparative and causal analysis**.Building on this, we introduce an evaluation method called **shortcut neuron patching** to suppress shortcut neurons. Experiments validate the effectiveness of our approach in mitigating contamination. Additionally, our evaluation results exhibit a strong linear correlation with MixEval, a recently released trustworthy benchmark, achieving a Spearman coefficient (𝜌) exceeding 0.95. This high correlation indicates that our method closely reveals true capabilities of the models and is trustworthy. We conduct further experiments to demonstrate the generalizability of our method across various benchmarks and hyperparameter settings. **Code**: https://github.com/GaryStack/Trustworthy-Evaluation",
    "checked": true,
    "id": "fa705f87a2ba9330d7648b6aa5e0996dbd584227",
    "semantic_title": "establishing trustworthy llm evaluation via shortcut neuron analysis",
    "citation_count": 0,
    "authors": [
      "Kejian Zhu",
      "Shangqing Tu",
      "Zhuoran Jin",
      "Lei Hou",
      "Juanzi Li",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.193": {
    "title": "Do Large Language Models have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs",
    "volume": "long",
    "abstract": "Current Large Language Models (LLMs) are predominantly designed with English as the primary language, and even the few that are multilingual tend to exhibit strong English-centric biases. Much like speakers who might produce awkward expressions when learning a second language, LLMs often generate unnatural outputs in non-English languages, reflecting English-centric patterns in both vocabulary and grammar. Despite the importance of this issue, the naturalness of multilingual LLM outputs has received limited attention. In this paper, we address this gap by introducing novel automatic corpus-level metrics to assess the lexical and syntactic naturalness of LLM outputs in a multilingual context. Using our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark in French and Chinese, revealing a tendency towards English-influenced patterns. To mitigate this issue, we also propose a simple and effective alignment method to improve the naturalness of an LLM in a target language and domain, achieving consistent improvements in naturalness without compromising the performance on general-purpose benchmarks. Our work highlights the importance of developing multilingual metrics, resources and methods for the new wave of multilingual LLMs",
    "checked": true,
    "id": "af24eef44a541efdd1451c5a1fcd2ff411edf794",
    "semantic_title": "do large language models have an english accent? evaluating and improving the naturalness of multilingual llms",
    "citation_count": 3,
    "authors": [
      "Yanzhu Guo",
      "Simone Conia",
      "Zelin Zhou",
      "Min Li",
      "Saloni Potdar",
      "Henry Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.194": {
    "title": "Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning",
    "volume": "long",
    "abstract": "Tokenization methods like Byte-Pair Encoding (BPE) enhance computational efficiency in large language models (LLMs) but often obscure internal character structures within tokens. This limitation hinders LLMs' ability to predict precise character positions, which is crucial in tasks like Chinese Spelling Correction (CSC) where identifying the positions of misspelled characters accelerates correction processes. We propose Token Internal Position Awareness (TIPA), a method that significantly improves models' ability to capture character positions within tokens by training them on reverse character prediction tasks using the tokenizer's vocabulary. Experiments demonstrate that TIPA enhances position prediction accuracy in LLMs, enabling more precise identification of target characters in original text. Furthermore, when applied to downstream tasks that do not require exact position prediction, TIPA still boosts performance in tasks needing character-level information, validating its versatility and effectiveness",
    "checked": true,
    "id": "117b5eccd7163e7bb4d2f1bf05df0c08f6d79f8a",
    "semantic_title": "enhancing character-level understanding in llms through token internal structure learning",
    "citation_count": 2,
    "authors": [
      "Zhu Xu",
      "Zhiqiang Zhao",
      "Zihan Zhang",
      "Yuchi Liu",
      "Quanwei Shen",
      "Fei Liu",
      "Yu Kuang",
      "Jian He",
      "Conglin Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.195": {
    "title": "Conformity in Large Language Models",
    "volume": "long",
    "abstract": "The conformity effect describes the tendency of individuals to align their responses with the majority. Studying this bias in large language models (LLMs) is crucial, as LLMs are increasingly used in various information-seeking and decision-making tasks as conversation partners to improve productivity. Thus, conformity to incorrect responses can compromise their effectiveness. In this paper, we adapt psychological experiments to examine the extent of conformity in state-of-the-art LLMs. Our findings reveal that all models tested exhibit varying levels of conformity toward the majority, regardless of their initial choice or correctness, across different knowledge domains. Notably, we are the first to show that LLMs are more likely to conform when they are more uncertain in their own prediction. We further explore factors that influence conformity, such as training paradigms and input characteristics, finding that instruction-tuned models are less susceptible to conformity, while increasing the naturalness of majority tones amplifies conformity. Finally, we propose two interventions—Devil's Advocate and Question Distillation—to mitigate conformity, providing insights into building more robust language models",
    "checked": true,
    "id": "eb8c373ac4b1495517cef7cd6d01c09c446a8f59",
    "semantic_title": "conformity in large language models",
    "citation_count": 0,
    "authors": [
      "Xiaochen Zhu",
      "Caiqi Zhang",
      "Tom Stafford",
      "Nigel Collier",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2025.acl-long.196": {
    "title": "Interpret and Improve In-Context Learning via the Lens of Input-Label Mappings",
    "volume": "long",
    "abstract": "Large language models (LLMs) excel at downstream NLP tasks through in-context learning (ICL) with a few demonstrations of input–label pairs. However, the internal mechanisms behind ICL remain under-explored, particularly the mappings between inputs and labels. In this work, we reverse-engineer ICL by examining input-label mappings: what they are within LLMs, where they function, and how LLMs utilize them. (1) what: We discover input-label mappings stored within a few specific layers in the form of principal components (PCs), which capture human-interpretable and task-related words. (2) where: We propose a PC patching approach to identify the modules where input-label mappings function. Specifically, PC patching automatically crafts counterfactual representations using identified semantic PCs, rather than manually designing counterfactual text, to suppress the behavior related to LLM capability for ICL-related modules. Utilizing PC patching, we identify LLMs apply input-label mappings in a small fraction of attention heads. (3) how: We observe and verify that the identified key heads utilize input-label mappings from demonstrations to generate target labels for new queries. Based on these discoveries, we further show that precisely fine-tuning key ICL-related modules leads to significant improvements across diverse tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenghao Sun",
      "Zhen Huang",
      "Yonggang Zhang",
      "Le Lu",
      "Houqiang Li",
      "Xinmei Tian",
      "Xu Shen",
      "Jieping Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.197": {
    "title": "Positional Overload: Positional Debiasing and Context Window Extension for Large Language Models using Set Encoding",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) typically track the order of tokens using positional encoding, which causes the following problems: positional bias, where the model is influenced by an ordering within the prompt, and a fixed context window, as models struggle to generalize to positions beyond those encountered during training. To address these limitations, we developed a novel method called set encoding. This method allows multiple pieces of text to be encoded in the same position, thereby eliminating positional bias entirely. Another promising use case for set encoding is to increase the size of the input an LLM can handle. Our experiments demonstrate that set encoding allows an LLM to solve tasks with far more tokens than without set encoding. To our knowledge, set encoding is the first technique to effectively extend an LLM's context window without requiring any additional training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Kinder",
      "Lukas Edman",
      "Alexander Fraser",
      "Tobias Käfer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.198": {
    "title": "FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling",
    "volume": "long",
    "abstract": "Speculative sampling has emerged as an important technique for accelerating the auto-regressive generation process of large language models (LLMs) by utilizing a draft-then-verify mechanism to produce multiple tokens per forward pass. While state-of-the-art speculative sampling methods use only a single layer and a language modeling (LM) head as the draft model to achieve impressive layer compression, their efficiency gains are substantially reduced for large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens. To address this, we present FR-Spec, a frequency-ranked speculative sampling framework that optimizes draft candidate selection through vocabulary space compression. By constraining the draft search to a frequency-prioritized token subset, our method reduces LM Head computation overhead by 75% while ensuring the equivalence of the final output distribution. Experiments across multiple datasets demonstrate an average of 1.12× speedup over the state-of-the-art speculative sampling method EAGLE-2. Code is availableat https://github.com/thunlp/FR-Spec",
    "checked": true,
    "id": "7b34dfcb6ec93beadc8958e53615bb78dc818c8d",
    "semantic_title": "fr-spec: accelerating large-vocabulary language models via frequency-ranked speculative sampling",
    "citation_count": 2,
    "authors": [
      "Weilin Zhao",
      "Tengyu Pan",
      "Xu Han",
      "Yudi Zhang",
      "Sun Ao",
      "Yuxiang Huang",
      "Kaihuo Zhang",
      "Weilun Zhao",
      "Yuxuan Li",
      "Jie Zhou",
      "Hao Zhou",
      "Jianyong Wang",
      "Maosong Sun",
      "Zhiyuan Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.199": {
    "title": "VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism",
    "volume": "long",
    "abstract": "Large Vision-Language Models (LVLMs) have shown exceptional performance in multimodal tasks, but their effectiveness in complex visual reasoning is still constrained, especially when employing Chain-of-Thought prompting techniques. In this paper, we propose VReST, a novel training-free approach that enhances Reasoning in LVLMs through Monte Carlo Tree Search and Self-Reward mechanisms. VReST meticulously traverses the reasoning landscape by establishing a search tree, where each node encapsulates a reasoning step, and each path delineates a comprehensive reasoning sequence. Our innovative multimodal Self-Reward mechanism assesses the quality of reasoning steps by integrating the utility of sub-questions, answer correctness, and the relevance of vision-language clues, all without the need for additional models. VReST surpasses current prompting methods and secures state-of-the-art performance across three multimodal mathematical reasoning benchmarks. Furthermore, it substantiates the efficacy of test-time scaling laws in multimodal tasks, offering a promising direction for future research",
    "checked": true,
    "id": "f561ef070b7fa419093e66173fc050e596724aae",
    "semantic_title": "vrest: enhancing reasoning in large vision-language models through tree search and self-reward mechanism",
    "citation_count": 0,
    "authors": [
      "Congzhi Zhang",
      "Jiawei Peng",
      "Zhenglin Wang",
      "Yilong Lai",
      "Haowen Sun",
      "Heng Chang",
      "Fei Ma",
      "Weijiang Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.200": {
    "title": "Past Meets Present: Creating Historical Analogy with Large Language Models",
    "volume": "long",
    "abstract": "Historical analogies, which compare known past events with contemporary but unfamiliar events, are important abilities that help people make decisions and understand the world. However, research in applied history suggests that people have difficulty finding appropriate analogies. And previous studies in the AI community have also overlooked historical analogies. To fill this gap, in this paper, we focus on the historical analogy acquisition task, which aims to acquire analogous historical events for a given event. We explore retrieval and generation methods for acquiring historical analogies based on different large language models (LLMs). Furthermore, we propose a self-reflection method to mitigate hallucinations and stereotypes when LLMs generate historical analogies. Through human evaluations and our specially designed automatic multi-dimensional assessment, we find that LLMs generally have a good potential for historical analogies. And the performance of the models can be further improved by using our self-reflection method. Resources of this paper can be found at https://anonymous.4open.science/r/Historical-Analogy-of-LLMs-FC17",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nianqi Li",
      "Siyu Yuan",
      "Jiangjie Chen",
      "Jiaqing Liang",
      "Feng Wei",
      "Zujie Liang",
      "Deqing Yang",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.201": {
    "title": "Meta-Reflection: A Feedback-Free Reflection Learning Framework",
    "volume": "long",
    "abstract": "Despite the remarkable capabilities of large language models (LLMs) in natural language understanding and reasoning, they often display undesirable behaviors, such as generating hallucinations and unfaithful reasoning. A prevalent strategy to mitigate these issues is the use of reflection, which refines responses through an iterative process. However, while promising, reflection heavily relies on high-quality external feedback and requires iterative multi-agent inference processes, thus hindering its practical application. In this paper, we propose Meta-Reflection, a novel feedback-free reflection mechanism that necessitates only a single inference pass without external feedback. Motivated by the human ability to remember and retrieve reflections from past experiences when encountering similar problems, Meta-Reflection integrates reflective insights into a codebook, allowing the historical insights to be stored, retrieved, and used to guide LLMs in problem-solving. To thoroughly investigate and evaluate the practicality of Meta-Reflection in real-world scenarios, we introduce an industrial e-commerce benchmark named E-commerce Customer Intent Detection. Extensive experiments conducted on both public datasets and the ECID benchmark highlight the effectiveness and efficiency of our proposed approach. Project is available at https://github.com/DCDmllm/Meta-Reflection",
    "checked": true,
    "id": "d32eee5091697c00ac5fe63b7e7415e96b43e808",
    "semantic_title": "meta-reflection: a feedback-free reflection learning framework",
    "citation_count": 1,
    "authors": [
      "Yaoke Wang",
      "Yun Zhu",
      "XintongBao XintongBao",
      "Wenqiao Zhang",
      "Suyang Dai",
      "Kehan Chen",
      "Wenqiang Li",
      "Gang Huang",
      "Siliang Tang",
      "Yueting Zhuang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.202": {
    "title": "Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books",
    "volume": "long",
    "abstract": "While large language models (LLMs) have shown promise in translating extremely low-resource languages using resources like dictionaries, the effectiveness of grammar books remains debated. This paper investigates the role of grammar books in translating extremely low-resource languages by decomposing it into two key steps: grammar rule retrieval and application. To facilitate the study, we introduce ZhuangRules, a modularized dataset of grammar rules and their corresponding test sentences. Our analysis reveals that rule retrieval constitutes a primary bottleneck in grammar-based translation. Moreover, although LLMs can apply simple rules for translation when explicitly provided, they encounter difficulties in handling more complex rules. To address these challenges, we propose representing grammar rules as code functions, considering their similarities in structure and the benefit of code in facilitating LLM reasoning. Our experiments show that using code rules significantly boosts both rule retrieval and application, ultimately resulting in a 13.1% BLEU improvement in translation",
    "checked": true,
    "id": "b97082d1d14a56a7143413adbc6daa2a246f0552",
    "semantic_title": "read it in two steps: translating extremely low-resource languages with code-augmented grammar books",
    "citation_count": 0,
    "authors": [
      "Chen Zhang",
      "Jiuheng Lin",
      "Xiao Liu",
      "Zekai Zhang",
      "Yansong Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.203": {
    "title": "Confidence v.s. Critique: A Decomposition of Self-Correction Capability for LLMs",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) can correct their self-generated responses, but a decline in accuracy after self-correction is also witnessed. To have a deeper understanding of self-correction, we endeavor to decompose, evaluate, and analyze the self-correction behaviors of LLMs. By enumerating and analyzing answer correctness before and after self-correction, we decompose the self-correction capability into confidence (being confident to correct answers) and critique (turning wrong answers to correct) capabilities, and propose two metrics from a probabilistic perspective to measure these 2 capabilities, along with another metric for overall self-correction capability evaluation. Based on our decomposition and evaluation metrics, we conduct extensive experiments and draw some empirical conclusions. For example, we find different models can exhibit distinct behaviors: some models are confident while others are more critical. We also find the trade-off between the two capabilities (i.e. improving one can lead to a decline in the other) when manipulating model self-correction behavior by prompts or in-context learning. Further, we find a simple yet efficient strategy to improve self-correction capability by transforming Supervision Fine-Tuning (SFT) data format, and our strategy outperforms vanilla SFT in both capabilities and achieves much higher accuracy after self-correction",
    "checked": true,
    "id": "eb6f7cafc54d96be4a630a7193d60802cc4434b7",
    "semantic_title": "confidence v.s. critique: a decomposition of self-correction capability for llms",
    "citation_count": 6,
    "authors": [
      "Zhe Yang",
      "Yichang Zhang",
      "Yudong Wang",
      "Ziyao Xu",
      "Junyang Lin",
      "Zhifang Sui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.204": {
    "title": "Automating Legal Interpretation with LLMs: Retrieval, Generation, and Evaluation",
    "volume": "long",
    "abstract": "Interpreting the law is always essential for the law to adapt to the ever-changing society. It is a critical and challenging task even for legal practitioners, as it requires meticulous and professional annotations and summarizations by legal experts, which are admittedly time-consuming and expensive to collect at scale. To alleviate the burden on legal experts, we propose a method for automated legal interpretation. Specifically, by emulating doctrinal legal research, we introduce a novel framework, **ATRIE**, to address Legal Concept Interpretation, a typical task in legal interpretation. **ATRIE** utilizes large language models (LLMs) to **A**u**T**omatically **R**etrieve concept-related information, **I**nterpret legal concepts, and **E**valuate generated interpretations, eliminating dependence on legal experts. ATRIE comprises a legal concept interpreter and a legal concept interpretation evaluator. The interpreter uses LLMs to retrieve relevant information from previous cases and interpret legal concepts. The evaluator uses performance changes on Legal Concept Entailment, a downstream task we propose, as a proxy of interpretation quality. Automated and multifaceted human evaluations indicate that the quality of our interpretations is comparable to those written by legal experts, with superior comprehensiveness and readability. Although there remains a slight gap in accuracy, it can already assist legal practitioners in improving the efficiency of legal interpretation",
    "checked": true,
    "id": "5065ff825ecad9d7fc73e6c5de1ec5997479b386",
    "semantic_title": "automating legal interpretation with llms: retrieval, generation, and evaluation",
    "citation_count": 1,
    "authors": [
      "Kangcheng Luo",
      "Quzhe Huang",
      "Cong Jiang",
      "Yansong Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.205": {
    "title": "Visual Evidence Prompting Mitigates Hallucinations in Large Vision-Language Models",
    "volume": "long",
    "abstract": "Large Vision-Language Models (LVLMs) have shown impressive progress by integrating visual perception with linguistic understanding to produce contextually grounded outputs. Despite these advancements achieved, LVLMs still suffer from the hallucination problem, e.g., they tend to produce content that does not exist in the input images. Our investigation suggests that such hallucinations often stem from the deficiencies in fine-grained comprehension on the visual aspect, particularly when visual scenes exhibit appearance or semantic similarities (e.g., bicycle vs. motorcycles, baseball bat vs. baseball). In this work, we show such hallucination is naturally mitigated via a novel method called visual evidence prompting, utilizing small visual models to complement the LVLMs. While traditional visual models are not adept at interacting with humans, they excel at perceiving the fine-grained image contents. By symbolizing the professional outputs of domain-expert models as prompts, the LVLM generalists are able to refer to these evidences as visual knowledge to generate more precise answers. Detailed analysis shows that visual evidence enables models to adjust and rectify the attribution and attention on the images, reducing visual confusion by suppressing false activation while enhancing correct ones. Extensive experiments and in-depth analysis demonstrate the effectiveness of our method. We hope our straightforward but insightful work enhances the comprehension of hallucination in LVLMs and offers valuable perspectives on addressing such challenges",
    "checked": false,
    "id": "6cd4b57f7741144d010c738e75d9d6b681a137e1",
    "semantic_title": "black-box visual prompt engineering for mitigating object hallucination in large vision language models",
    "citation_count": 0,
    "authors": [
      "Wei Li",
      "Zhen Huang",
      "Houqiang Li",
      "Le Lu",
      "Yang Lu",
      "Xinmei Tian",
      "Xu Shen",
      "Jieping Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.206": {
    "title": "Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration",
    "volume": "long",
    "abstract": "Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent *System 1* and *System 2* methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates *System 1* and *System 2* for efficient real-time simultaneous human-AI collaboration. DPT-Agent's *System 1* uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's *System 2* integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent",
    "checked": true,
    "id": "65e3d5e1ba3f5e1d2e3730538dc8cee6e0ee2382",
    "semantic_title": "leveraging dual process theory in language agent framework for real-time simultaneous human-ai collaboration",
    "citation_count": 2,
    "authors": [
      "Shao Zhang",
      "Xihuai Wang",
      "Wenhao Zhang",
      "Chaoran Li",
      "Junru Song",
      "Tingyu Li",
      "Lin Qiu",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Wen Yao",
      "Weinan Zhang",
      "Xinbing Wang",
      "Ying Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.207": {
    "title": "TokAlign: Efficient Vocabulary Adaptation via Token Alignment",
    "volume": "long",
    "abstract": "Tokenization serves as a foundational step for Large Language Models (LLMs) to process text. In new domains or languages, the inefficiency of the tokenizer will slow down the training and generation of LLM. The mismatch in vocabulary also hinders deep knowledge transfer between LLMs like token-level distillation. To mitigate this gap, we propose an efficient method named **TokAlign** to replace the vocabulary of LLM from the token co-occurrences view, and further transfer the token-level knowledge between models. It first aligns the source vocabulary to the target one by learning a one-to-one mapping matrix for token IDs. Model parameters, including embeddings, are rearranged and progressively fine-tuned for the new vocabulary. Our method significantly improves multilingual text compression rates and vocabulary initialization for LLMs, decreasing the perplexity from 3.4e2 of strong baseline methods to 1.2e2 after initialization. Experimental results on models across multiple parameter scales demonstrate the effectiveness and generalization of TokAlign, which costs as few as 5k steps to restore the performance of the vanilla model. After unifying vocabularies between LLMs, token-level distillation can remarkably boost (+4.4% than sentence-level distillation) the base model, costing only 235M tokens",
    "checked": true,
    "id": "13af1f85c4c92df570bea192af7c515cbf68fa9e",
    "semantic_title": "tokalign: efficient vocabulary adaptation via token alignment",
    "citation_count": 0,
    "authors": [
      "Chong Li",
      "Jiajun Zhang",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.208": {
    "title": "AdaEdit: Advancing Continuous Knowledge Editing For Large Language Models",
    "volume": "long",
    "abstract": "Knowledge editing (KE) has emerged as a prominent alternative that enables efficient and precise information modification inside language models. However, a critical challenge arises in continuous language models editing — a significant performance decline both in knowledge update and retention when the number of edits increases. By dissecting the perturbation weight of language model in continuous KE, we uncover that disentangled and sparsified knowledge representation can significantly alleviate the performance decline. Building on these insights, we introduce AdaEdit, a novel knowledge editing method. Extensive empirical evaluations on multiple LLMs demonstrate that our proposed methods can enhance the performance of edited LLMs in large-size continuous editing regimes, outperforming existing ones without substantially compromising the general abilities of these models",
    "checked": false,
    "id": "918e3804fe3b8b2e2e642e7ce2d7bed758541fb1",
    "semantic_title": "cknowedit: a new chinese knowledge editing dataset for linguistics, facts, and logic error correction in llms",
    "citation_count": 0,
    "authors": [
      "Qi Li",
      "Xiaowen Chu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.209": {
    "title": "The Impact of Token Granularity on the Predictive Power of Language Model Surprisal",
    "volume": "long",
    "abstract": "Word-by-word language model surprisal is often used to model the incremental processing of human readers, which raises questions about how various choices in language modeling influence its predictive power. One factor that has been overlooked in cognitive modeling is the granularity of subword tokens, which explicitly encodes information about word length and frequency, and ultimately influences the quality of vector representations that are learned. This paper presents experiments that manipulate the token granularity and evaluate its impact on the ability of surprisal to account for processing difficulty of naturalistic text and garden-path constructions. Experiments with naturalistic reading times reveal a substantial influence of token granularity on surprisal, with tokens defined by a vocabulary size of 8,000 resulting in surprisal that is most predictive. In contrast, on garden-path constructions, language models trained on coarser-grained tokens generally assigned higher surprisal to critical regions, suggesting a greater sensitivity to garden-path effects than previously reported. Taken together, these results suggest a large role of token granularity on the quality of language model surprisal for cognitive modeling",
    "checked": true,
    "id": "afabc1d6851c563a3cc0b1d353366bbcc5916c8d",
    "semantic_title": "the impact of token granularity on the predictive power of language model surprisal",
    "citation_count": 0,
    "authors": [
      "Byung-Doh Oh",
      "William Schuler"
    ]
  },
  "https://aclanthology.org/2025.acl-long.210": {
    "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
    "volume": "long",
    "abstract": "Diffusion models have shown promise in text generation, but often struggle with generating long, coherent, and contextually accurate text. Token-level diffusion doesn't model word-order dependencies explicitly and operates on short, fixed output windows, while passage-level diffusion struggles with learning robust representations for long-form text. To address these challenges, we propose Segment-Level Diffusion (SLD), a framework that enhances diffusion-based text generation through text segmentation, robust representation training with adversarial and contrastive learning, and improved latent-space guidance. By segmenting long-form outputs into multiple latent representations and decoding them with an autoregressive decoder, SLD simplifies diffusion predictions and improves scalability. Experiments on four datasets demonstrate that, when compared to other diffusion and autoregressive baselines SLD achieves competitive or superior fluency, coherence, and contextual compatibility in automatic and human evaluations",
    "checked": true,
    "id": "4632af889b03c454ed02a95c947c417888fa8fbf",
    "semantic_title": "segment-level diffusion: a framework for controllable long-form generation with diffusion language models",
    "citation_count": 1,
    "authors": [
      "Xiaochen Zhu",
      "Georgi Karadzhov",
      "Chenxi Whitehouse",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2025.acl-long.211": {
    "title": "BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering",
    "volume": "long",
    "abstract": "Multi-hop question answering (QA) involves finding multiple relevant passages and performing step-by-step reasoning to answer complex questions. Previous works on multi-hop QA employ specific methods from different modeling perspectives based on large language models (LLMs), regardless of the question types. In this paper, we first conduct an in-depth analysis of public multi-hop QA benchmarks, dividing the questions into four types and evaluating five types of cutting-edge methods for multi-hop QA: Chain-of-Thought (CoT), Single-step, Iterative-step, Sub-step, and Adaptive-step. We find that different types of multi-hop questions have varying degrees of sensitivity to different types of methods. Thus, we propose a Bi-levEL muLti-agEnt reasoning (BELLE) framework to address multi-hop QA by specifically focusing on the correspondence between question types and methods, where each type of method is regarded as an \"operator\" by prompting LLMs differently. The first level of BELLE includes multiple agents that debate to obtain an executive plan of combined \"operators\" to address the multi-hop QA task comprehensively. During the debate, in addition to the basic roles of affirmative debater, negative debater, and judge, at the second level, we further leverage fast and slow debaters to monitor whether changes in viewpoints are reasonable. Extensive experiments demonstrate that BELLE significantly outperforms strong baselines in various datasets. Additionally, the model consumption of BELLE is higher cost-effectiveness than that of single models in more complex multi-hop QA scenarios",
    "checked": true,
    "id": "4e826915ce02cb2f523dc0b08e5badac6f48ed84",
    "semantic_title": "belle: a bi-level multi-agent reasoning framework for multi-hop question answering",
    "citation_count": 0,
    "authors": [
      "Taolin Zhang",
      "Dongyang Li",
      "Qizhou Chen",
      "Chengyu Wang",
      "Xiaofeng He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.212": {
    "title": "Dynamic and Generalizable Process Reward Modeling",
    "volume": "long",
    "abstract": "Process Reward Models (PRMs) are crucial for guiding Large Language Models (LLMs) in complex scenarios by providing dense reward signals. However, existing PRMs primarily rely on heuristic approaches, which struggle with cross-domain generalization. While LLM-as-judge has been proposed to provide generalized rewards, current research has focused mainly on feedback results, overlooking the meaningful guidance embedded within the text. Additionally, static and coarse-grained evaluation criteria struggle to adapt to complex process supervision. To tackle these challenges, we propose Dynamic and Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to capture and store fine-grained, multi-dimensional reward criteria. DG-PRM dynamically selects reward signals for step-wise reward scoring. To handle multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation to identify discriminative positive and negative pairs. Experimental results show that DG-PRM achieves stunning performance on prevailing benchmarks, significantly boosting model performance across tasks with dense rewards. Further analysis reveals that DG-PRM adapts well to out-of-distribution scenarios, demonstrating exceptional generalizability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangyue Yin",
      "Qiushi Sun",
      "Zhiyuan Zeng",
      "Qinyuan Cheng",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.213": {
    "title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness",
    "volume": "long",
    "abstract": "The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at https://github.com/Lbotirx/AdamMeme",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixin Chen",
      "Hongzhan Lin",
      "Kaixin Li",
      "Ziyang Luo",
      "Zhen Ye",
      "Guang Chen",
      "Zhiyong Huang",
      "Jing Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.214": {
    "title": "Towards Text-Image Interleaved Retrieval",
    "volume": "long",
    "abstract": "Current multimodal information retrieval studies mainly focus on single-image inputs, which limits real-world applications involving multiple images and text-image interleaved content. In this work, we introduce the text-image interleaved retrieval (TIIR) task, where the query and document are interleaved text-image sequences, and the model is required to understand the semantics from the interleaved context for effective retrieval. We construct a TIIR benchmark based on naturally interleaved wikiHow tutorials, where a specific pipeline is designed to generate interleaved queries. To explore the task, we adapt several off-the-shelf retrievers and build a dense baseline by interleaved multimodal large language model (MLLM). We then propose a novel Matryoshka Multimodal Embedder (MME), which compresses the number of visual tokens at different granularity, to address the challenge of excessive visual tokens in MLLM-based TIIR models. Experiments demonstrate that simple adaption of existing models does not consistently yield effective results. Our MME achieves significant improvements over the baseline by substantially fewer visual tokens. We provide extensive analysis and will release the dataset and code to facilitate future research",
    "checked": true,
    "id": "a836a285c4603ffcde55730082de74dc32ab1acb",
    "semantic_title": "towards text-image interleaved retrieval",
    "citation_count": 0,
    "authors": [
      "Xin Zhang",
      "Ziqi Dai",
      "Yongqi Li",
      "Yanzhao Zhang",
      "Dingkun Long",
      "Pengjun Xie",
      "Meishan Zhang",
      "Jun Yu",
      "Wenjie Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.215": {
    "title": "Large Margin Representation Learning for Robust Cross-lingual Named Entity Recognition",
    "volume": "long",
    "abstract": "Cross-lingual named entity recognition (NER) aims to build an NER model that generalizes to the low-resource target language with labeled data from the high-resource source language. Current state-of-the-art methods typically combine self-training mechanism with contrastive learning paradigm, in order to develop discriminative entity clusters for cross-lingual adaptation. Despite the promise, we identify that these methods neglect two key problems: distribution skewness and pseudo-label bias, leading to indistinguishable entity clusters with small margins. To this end, we propose a novel framework, MARAL, which optimizes an adaptively reweighted contrastive loss to handle the class skewness and theoretically guarantees the optimal feature arrangement with maximum margin. To further mitigate the adverse effects of unreliable pseudo-labels, MARAL integrates a progressive cross-lingual adaptation strategy, which first selects reliable samples as anchors and then refines the remaining unreliable ones. Extensive experiments demonstrate that MARAL significantly outperforms the current state-of-the-art methods on multiple benchmarks, e.g., +2.04% on the challenging MultiCoNER dataset",
    "checked": false,
    "id": "3e2a380dfd2934420f188a616acacbd31c782e71",
    "semantic_title": "cricavpr: cross-image correlation-aware representation learning for visual place recognition",
    "citation_count": 37,
    "authors": [
      "Guangcheng Zhu",
      "Ruixuan Xiao",
      "Haobo Wang",
      "Zhen Zhu",
      "Gengyu Lyu",
      "Junbo Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.216": {
    "title": "An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning",
    "volume": "long",
    "abstract": "Enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) is of great scientific and practical significance. Researchers typically employ process-supervised reward models (PRMs) to guide the reasoning process, effectively improving the models' reasoning abilities. However, existing methods for constructing process supervision training data, such as manual annotation and per-step Monte Carlo estimation, are often costly or suffer from poor quality. To address these challenges, this paper introduces a framework called EpicPRM (Efficient, Precise, Cheap), which annotates each intermediate reasoning step based on its quantified contribution and uses an adaptive binary search algorithm to enhance both annotation precision and efficiency. Using this approach, we efficiently construct a high-quality process supervision training dataset named Epic50k, consisting of 50k annotated intermediate steps. Compared to other publicly available datasets, the PRM trained on Epic50k demonstrates significantly superior performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Sun",
      "Qianlong Du",
      "Fuwei Cui",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.217": {
    "title": "QAEncoder: Towards Aligned Representation Learning in Question Answering Systems",
    "volume": "long",
    "abstract": "Modern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses. However, the inherent gap between user queries and relevant documents hinders precise matching. We introduce QAEncoder, a training-free approach to bridge this gap. Specifically, QAEncoder estimates the expectation of potential queries in the embedding space as a robust surrogate for the document embedding, and attaches document fingerprints to effectively distinguish these embeddings. Extensive experiments across diverse datasets, languages, and embedding models confirmed QAEncoder's alignment capability, which offers a simple-yet-effective solution with zero additional index storage, retrieval latency, training costs, or catastrophic forgetting and hallucination issues. The repository is publicly available at https://github.com/IAAR-Shanghai/QAEncoder",
    "checked": false,
    "id": "3af77204e621ad84c6114434eb086d672d24b45e",
    "semantic_title": "qaencoder: towards aligned representation learning in question answering system",
    "citation_count": 1,
    "authors": [
      "Zhengren Wang",
      "Qinhan Yu",
      "Shida Wei",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Xiaoxing Wang",
      "Simin Niu",
      "Hao Liang",
      "Wentao Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.218": {
    "title": "Game Development as Human-LLM Interaction",
    "volume": "long",
    "abstract": "Game development is a highly specialized task that relies on a complex game engine powered by complex programming languages, preventing many gaming enthusiasts from handling it. This paper introduces the Chat Game Engine (ChatGE) powered by LLM, which allows everyone to develop a custom game using natural language through Human-LLM interaction. To enable an LLM to function as a ChatGE, we instruct it to perform the following processes in each turn: (1) Pscript: configure the game script segment based on the user's input; (2) Pcode: generate the corresponding code snippet based on the game script segment; (3) Putter: interact with the user, including guidance and feedback. We propose a data synthesis pipeline based on LLM to generate game script-code pairs and interactions from a few manually crafted seed data. We propose a three-stage training strategy following curriculum learning principles to transfer the dialogue-based LLM to our ChatGE smoothly. We construct a ChatGE for poker games as a case study and comprehensively evaluate it from two perspectives: interaction quality and code correctness",
    "checked": true,
    "id": "1849b6b8acfa03bd5f04e71e1695e87fee6448d0",
    "semantic_title": "game development as human-llm interaction",
    "citation_count": 0,
    "authors": [
      "Jiale Hong",
      "Hongqiu Wu",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.219": {
    "title": "Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases",
    "volume": "long",
    "abstract": "This study evaluates Large Language Models' (LLMs) ability to simulate non-native-like English use observed in human second language (L2) learners interfered with by their native first language (L1). In dialogue-based interviews, we prompt LLMs to mimic L2 English learners with specific L1s (e.g., Japanese, Thai, Urdu) across seven languages, comparing their outputs to real L2 learner data. Our analysis examines L1-driven linguistic biases, such as reference word usage and avoidance behaviors, using information-theoretic and distributional density measures. Results show that modern LLMs (e.g., Qwen2.5, LLAMA3, DeepseekV3, GPT 4o) replicate L1-dependent patterns observed in human L2 data, with distinct influences from various languages (e.g., Japanese, Korean, and Mandarin significantly affect tense agreement, and Urdu influences noun-verb collocations). Our results reveal LLMs' potential for L2 dialogue generation and evaluation for future educational applications",
    "checked": true,
    "id": "e209fff7dbece97cc444d9d10678da2e252650a0",
    "semantic_title": "can llms simulate l2-english dialogue? an information-theoretic analysis of l1-dependent biases",
    "citation_count": 0,
    "authors": [
      "Rena Wei Gao",
      "Xuetong Wu",
      "Tatsuki Kuribayashi",
      "Mingrui Ye",
      "Siya Qi",
      "Carsten Roever",
      "Yuanxing Liu",
      "Zheng Yuan",
      "Jey Han Lau"
    ]
  },
  "https://aclanthology.org/2025.acl-long.220": {
    "title": "DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking",
    "volume": "long",
    "abstract": "Designing solutions for complex engineering challenges is crucial in human production activities. However, previous research in the retrieval-augmented generation (RAG) field has not sufficiently addressed tasks related to the design of complex engineering solutions. To fill this gap, we introduce a new benchmark, SolutionBench, to evaluate a system's ability to generate complete and feasible solutions for engineering problems with multiple complex constraints. To further advance the design of complex engineering solutions, we propose a novel system, SolutionRAG, that leverages the tree-based exploration and bi-point thinking mechanism to generate reliable solutions. Extensive experimental results demonstrate that SolutionRAG achieves state-of-the-art (SOTA) performance on the SolutionBench, highlighting its potential to enhance the automation and reliability of complex engineering solution design in real-world applications",
    "checked": true,
    "id": "9c5718032de470df3dec34a629816c178f54d05f",
    "semantic_title": "deepsolution: boosting complex engineering solution design via tree-based exploration and bi-point thinking",
    "citation_count": 4,
    "authors": [
      "Zhuoqun Li",
      "Haiyang Yu",
      "Xuanang Chen",
      "Hongyu Lin",
      "Yaojie Lu",
      "Fei Huang",
      "Xianpei Han",
      "Yongbin Li",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.221": {
    "title": "SurveyPilot: an Agentic Framework for Automated Human Opinion Collection from Social Media",
    "volume": "long",
    "abstract": "Opinion survey research is a crucial method used by social scientists for understanding societal beliefs and behaviors. Traditional methodologies often entail high costs and limited scalability, while current automated methods such as opinion synthesis exhibit severe biases and lack traceability. In this paper, we introduce SurveyPilot, a novel finite-state orchestrated agentic framework that automates the collection and analysis of human opinions from social media platforms. SurveyPilot addresses the limitations of pioneering approaches by (i) providing transparency and traceability in each state of opinion collection and (ii) incorporating several techniques for mitigating biases, notably with a novel genetic algorithm for improving result diversity. Our extensive experiments reveal that SurveyPilot achieves a close alignment with authentic survey results across multiple domains, observing average relative improvements of 68,98% and 51,37% when comparing to opinion synthesis and agent-based approaches. Implementation of SurveyPilot is available on https://github.com/thanhpv2102/SurveyPilot",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viet Thanh Pham",
      "Lizhen Qu",
      "Zhuang Li",
      "Suraj Sharma",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2025.acl-long.222": {
    "title": "Sharper and Faster mean Better: Towards More Efficient Vision-Language Model for Hour-scale Long Video Understanding",
    "volume": "long",
    "abstract": "Despite existing multimodal language models showing impressive performance on the video understanding task, extremely long videos still pose significant challenges to language model's context length, memory consumption, and computational complexity. To address these issues, we propose a vision-language model named Sophia for long video understanding, which can efficiently handle hour-scale long videos. First, we employ a Shot-adaptive Frame Pruning technique, which naturally segments long videos into multiple camera shots, to more sharply identify and focus on the frames relevant to the query. Additionally, we introduce a Hierarchical Attention mechanism to effectively model the long-term temporal dependencies between video frames, which achieves a time and space complexity of O(N) w.r.t. the input sequence length N while theoretically maintaining the global modeling efficiency. Experimentally, our Sophia exhibits competitive performance compared to existing video understanding baselines across various benchmarks for long video understanding with reduced time and memory consumption. The model code and weights are available at https://huggingface.co/Tao-tse/Sophia",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daoze Zhang",
      "Yuze Zhao",
      "Jintao Huang",
      "Yingda Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.223": {
    "title": "Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions",
    "volume": "long",
    "abstract": "As LLMs continuously evolve, there is an urgent need for a reliable evaluation method that delivers trustworthy results promptly. Currently, static benchmarks suffer from inflexibility and unreliability, leading users to prefer human voting platforms like Chatbot Arena. However, human evaluations require significant manual effort. Therefore, we propose Auto-Arena, an innovative framework that automates the entire evaluation process using LLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM candidates engage in a multi-round peer battle based on the questions, aiming at revealing their true performance differences. Finally, a committee of LLM judges collaboratively discusses and decides the winner, reducing bias and enhancing fairness. During the peer battles, we observe intriguing scenarios where the LLM candidates display competitive behaviors and learn from the opponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena shows a 92.14% correlation with human preferences, surpassing all previous expert-annotated benchmarks without any manual efforts. Auto-Arena offers a promising alternative to current human evaluation platforms for evaluating LLMs automatically",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruochen Zhao",
      "Wenxuan Zhang",
      "Yew Ken Chia",
      "Weiwen Xu",
      "Deli Zhao",
      "Lidong Bing"
    ]
  },
  "https://aclanthology.org/2025.acl-long.224": {
    "title": "How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian",
    "volume": "long",
    "abstract": "People can categorize the same entity at multiple taxonomic levels, such as basic (bear), superordinate (animal), and subordinate (grizzly bear). While prior research has focused on basic-level categories, this study is the first attempt to examine the organization of categories by analyzing exemplars produced at the subordinate level. We present a new Italian psycholinguistic dataset of human-generated exemplars for 187 concrete words. We then leverage these data to evaluate whether textual and vision LLMs produce meaningful exemplars that align with human category organization across three key tasks: exemplar generation, category induction, and typicality judgment. Our findings show a low alignment between humans and LLMs, consistent with previous studies. However, their performance varies notably across different semantic domains. Ultimately, this study highlights both the promises and the constraints of using AI-generated exemplars to support psychological and linguistic research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Pedrotti",
      "Giulia Rambelli",
      "Caterina Villani",
      "Marianna Bolognesi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.225": {
    "title": "PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) suffer severe performance degradation when facing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bit post-training quantization (PTQ) methods utilize a mix-precision scheme by leveraging an unstructured fine-grained mask to explicitly distinguish salient weights, while which introduces an extra 1-bit or more per weight. To explore the real limit of PTQ, we propose an extremely low-bit PTQ method called PTQ1.61, which enables weight quantization to 1.61-bit for the first time. Specifically, we first introduce a one-dimensional structured mask with negligibly additional 0.0002-bit per weight based on input activations from the perspective of reducing the upper bound of quantization error to allocate corresponding salient weight channels to 4-bit. For non-salient channels binarization, an efficient block-wise scaling factors optimization framework is then presented to take implicit row-wise correlations and angular biases into account. Different from prior works that concentrate on adjusting quantization methodologies, we further propose a novel paradigm called quantization preprocessing, where we argue that transforming the weight distribution of the pretrained model before quantization can alleviate the difficulty in per-channel extremely low-bit PTQ. Extensive experiments indicate our PTQ1.61 achieves state-of-the-art performance in extremely low-bit quantization. Codes are available at https://github.com/zjq0455/PTQ1.61",
    "checked": true,
    "id": "4edcccfbf1d43a2dd3037608ab495bb5439fe959",
    "semantic_title": "ptq1.61: push the real limit of extremely low-bit post-training quantization methods for large language models",
    "citation_count": 1,
    "authors": [
      "Jiaqi Zhao",
      "Miao Zhang",
      "Ming Wang",
      "Yuzhang Shang",
      "Kaihao Zhang",
      "Weili Guan",
      "Yaowei Wang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.226": {
    "title": "ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification",
    "volume": "long",
    "abstract": "In this work, we propose ProtoLens, a novel prototype-based model that provides fine-grained, sub-sentence level interpretability for text classification. ProtoLens uses a Prototype-aware Span Extraction module to identify relevant text spans associated with learned prototypes and a Prototype Alignment mechanism to ensure prototypes are semantically meaningful throughout training. By aligning the prototype embeddings with human-understandable examples, ProtoLens provides interpretable predictions while maintaining competitive accuracy. Extensive experiments demonstrate that ProtoLens outperforms both prototype-based and non-interpretable baselines on multiple text classification benchmarks. Code and data are available at https://github.com/weibowen555/ProtoLens",
    "checked": false,
    "id": "54ae35c6e1e2169477f562687441fe8c685c91b0",
    "semantic_title": "advancing interpretability in text classification through prototype learning",
    "citation_count": 1,
    "authors": [
      "Bowen Wei",
      "Ziwei Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.227": {
    "title": "Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization",
    "volume": "long",
    "abstract": "Video dubbing aims to translate original speech in visual media programs from the source language to the target language, relying on neural machine translation and text-to-speech technologies. Due to varying information densities across languages, target speech often mismatches the source speech duration, causing audio-video synchronization issues that significantly impact viewer experience. In this study, we approach duration alignment in LLM-based video dubbing machine translation as a preference optimization problem. We propose the Segment Supervised Preference Optimization (SSPO) method, which employs a segment-wise sampling strategy and fine-grained loss to mitigate duration mismatches between source and target lines. Experimental results demonstrate that SSPO achieves superior performance in duration alignment tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqun Cui",
      "Liangbin Huang",
      "Shijing Wang",
      "Zhe Tong",
      "Zhaolong Huang",
      "Xiao Zeng",
      "Xiaofeng Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.228": {
    "title": "Sparse Latents Steer Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "Understanding the mechanisms underlying Large Language Model (LLM) behavior in Retrieval-Augmented Generation (RAG) systems is critical for enhancing reliability. In this paper, we leverage Sparse Autoencoders (SAEs) within the LLaMA Scope to uncover sparse, interpretable latents that govern RAG behaviors. Through systematic analysis of SAE activations, we identify specific latents associated with two fundamental RAG decisions: (1) context versus memory prioritization, and (2) response generation versus query rejection. Intervention experiments demonstrate that these latents enable precise control over model behavior and maintain generalizability across various experimental settings. Mechanistic analysis reveals that manipulating these latents influences model behavior by reconfiguring attention patterns of retrieval heads. Our findings establish SAEs as a principled tool for understanding and controlling RAG behaviors, demonstrating capabilities in precise behavior steering without architectural modifications",
    "checked": false,
    "id": "b3a3a982e94164a12c7dbb1daab239f4c71084db",
    "semantic_title": "gear: graph-enhanced agent for retrieval-augmented generation",
    "citation_count": 1,
    "authors": [
      "Chunlei Xin",
      "Shuheng Zhou",
      "Huijia Zhu",
      "Weiqiang Wang",
      "Xuanang Chen",
      "Xinyan Guan",
      "Yaojie Lu",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.229": {
    "title": "Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders",
    "volume": "long",
    "abstract": "The mechanisms behind multilingual capabilities in Large Language Models (LLMs) have been examined using neuron-based or internal-activation-based methods. However, these methods often face challenges such as superposition and layer-wise activation variance, which limit their reliability. Sparse Autoencoders (SAEs) offer a more nuanced analysis by decomposing the activations of LLMs into a sparse linear combination of SAE features. We introduce a novel metric to assess the monolinguality of features obtained from SAEs, discovering that some features are strongly related to specific languages. Additionally, we show that ablating these SAE features only significantly reduces abilities in one language of LLMs, leaving others almost unaffected. Interestingly, we find some languages have multiple synergistic SAE features, and ablating them together yields greater improvement than ablating individually. Moreover, we leverage these SAE-derived language-specific features to enhance steering vectors, achieving control over the language generated by LLMs. The code is publicly available at https://github.com/Aatrox103/multilingual-llm-features",
    "checked": true,
    "id": "5af1703757a341a3be991e45ebcea6380787a3ea",
    "semantic_title": "unveiling language-specific features in large language models via sparse autoencoders",
    "citation_count": 1,
    "authors": [
      "Boyi Deng",
      "Yu Wan",
      "Baosong Yang",
      "Yidan Zhang",
      "Fuli Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.230": {
    "title": "SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model",
    "volume": "long",
    "abstract": "The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge. In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security. First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service. Next, we construct RAG security evaluation dataset (i.e., SafeRAG dataset) primarily manually for each task. We then utilize the SafeRAG dataset to simulate various attack scenarios that RAG may encounter. Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality. Code is available at: https://github.com/IAAR-Shanghai/SafeRAG",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xun Liang",
      "Simin Niu",
      "Zhiyu Li",
      "Sensen Zhang",
      "Hanyu Wang",
      "Feiyu Xiong",
      "Zhaoxin Fan",
      "Bo Tang",
      "Jihao Zhao",
      "Jiawei Yang",
      "Shichao Song",
      "Mengwei Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.231": {
    "title": "AnRe: Analogical Replay for Temporal Knowledge Graph Forecasting",
    "volume": "long",
    "abstract": "Temporal Knowledge Graphs (TKGs) are vital for event prediction, yet current methods face limitations. Graph neural networks mainly depend on structural information, often overlooking semantic understanding and requiring high computational costs. Meanwhile, Large Language Models (LLMs) support zero-shot reasoning but lack sufficient capabilities to grasp the laws of historical event development. To tackle these challenges, we introduce a training-free Analogical Replay (AnRe) reasoning framework. Our approach retrieves similar events for queries through semantic-driven clustering and builds comprehensive historical contexts using a dual history extraction module that integrates long-term and short-term history. It then uses LLMs to generate analogical reasoning examples as contextual inputs, enabling the model to deeply understand historical patterns of similar events and improve its ability to predict unknown ones. Our experiments on four benchmarks show that AnRe significantly exceeds traditional training and existing LLM-based methods. Further ablation studies also confirm the effectiveness of the dual history extraction and analogical replay mechanisms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guo Tang",
      "Zheng Chu",
      "Wenxiang Zheng",
      "Junjia Xiang",
      "Yizhuo Li",
      "Weihao Zhang",
      "Ming Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.232": {
    "title": "Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?",
    "volume": "long",
    "abstract": "The advent of test-time scaling in large language models (LLMs), exemplified by OpenAI's o1 series, has advanced reasoning capabilities by scaling computational resource allocation during inference. While successors like QwQ, Deepseek-R1 (R1) and LIMO replicate these advancements, whether these models truly possess test-time scaling capabilities remains underexplored. This study found that longer CoTs of these o1-like models do not consistently enhance accuracy; in fact, correct solutions are often shorter than incorrect ones for the same questions. Further investigation shows this phenomenon is closely related to models' self-revision capabilities - longer CoTs contain more self-revisions, which often lead to performance degradation. We then compare sequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that parallel scaling achieves better coverage and scalability. Based on these insights, we propose \"Shortest Majority Vote\", a method that combines parallel scaling strategies with CoT length characteristics, significantly improving models' test-time scalability compared to conventional majority voting approaches",
    "checked": true,
    "id": "acf24131433fabf6304b27f2466445199d91a418",
    "semantic_title": "revisiting the test-time scaling of o1-like models: do they truly possess test-time scaling capabilities?",
    "citation_count": 20,
    "authors": [
      "Zhiyuan Zeng",
      "Qinyuan Cheng",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.233": {
    "title": "Text is All You Need: LLM-enhanced Incremental Social Event Detection",
    "volume": "long",
    "abstract": "Social event detection (SED) is the task of identifying, categorizing, and tracking events from social data sources such as social media posts, news articles, and online discussions. Existing state-of-the-art (SOTA) SED models predominantly rely on graph neural networks (GNNs), which involve complex graph construction and time-consuming training processes, limiting their practicality in real-world scenarios. In this paper, we rethink the key challenge in SED: the informal and noisy nature of short texts on social media platforms, which impacts clustering accuracy. We propose a novel framework, LLM-enhanced Social Event Detection (LSED), which leverages the rich background knowledge of large language models (LLMs) to address this challenge. Specifically, LSED utilizes LLMs to formalize and disambiguate short texts by completing abbreviations and summarizing informal expressions. Furthermore, we introduce hyperbolic space embeddings, which are more suitable for natural language sentence representations, to enhance clustering performance. Extensive experiments on two challenging real-world datasets demonstrate that LSED outperforms existing SOTA models, achieving improvements in effectiveness, efficiency, and stability. Our work highlights the potential of LLMs in SED and provides a practical solution for real-world applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zitai Qiu",
      "Congbo Ma",
      "Jia Wu",
      "Jian Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.234": {
    "title": "Multimodal Pragmatic Jailbreak on Text-to-image Models",
    "volume": "long",
    "abstract": "Diffusion models have recently achieved remarkable advancements in terms of image quality and fidelity to textual prompts. Concurrently, the safety of such generative models has become an area of growing concern. This work introduces a novel type of jailbreak, which triggers T2I models to generate the image with visual text, where the image and the text, although considered to be safe in isolation, combine to form unsafe content. To systematically explore this phenomenon, we propose a dataset to evaluate the current diffusion-based text-to-image (T2I) models under such jailbreak. We benchmark nine representative T2I models, including two closed-source commercial models. Experimental results reveal a concerning tendency to produce unsafe content: all tested models suffer from such type of jailbreak, with rates of unsafe generation ranging from around 10% to 70% where DALL·E 3 demonstrates almost the highest unsafety. In real-world scenarios, various filters such as keyword blocklists, customized prompt filters, and NSFW image filters, are commonly employed to mitigate these risks. We evaluate the effectiveness of such filters against our jailbreak and found that, while these filters may be effective for single modality detection, they fail to work against our jailbreak. We also investigate the underlying reason for such jailbreaks, from the perspective of text rendering capability and training data. Our work provides a foundation for further development towards more secure and reliable T2I models",
    "checked": true,
    "id": "f92c8cf796e33f9fba51d71f904afeee54c883e4",
    "semantic_title": "multimodal pragmatic jailbreak on text-to-image models",
    "citation_count": 5,
    "authors": [
      "Tong Liu",
      "Zhixin Lai",
      "Jiawen Wang",
      "Gengyuan Zhang",
      "Shuo Chen",
      "Philip Torr",
      "Vera Demberg",
      "Volker Tresp",
      "Jindong Gu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.235": {
    "title": "Principled Understanding of Generalization for Generative Transformer Models in Arithmetic Reasoning Tasks",
    "volume": "long",
    "abstract": "Transformer-based models excel in various tasks but their generalization capabilities, especially in arithmetic reasoning, remain incompletely understood. Arithmetic tasks provide a controlled framework to explore these capabilities, yet performance anomalies persist, such as inconsistent effectiveness in multiplication and erratic generalization in modular addition (e.g., modulo 100 vs. 101). This paper develops a unified theoretical framework for understanding the generalization behaviors of transformers in arithmetic tasks, focusing on length generalization. Through detailed analysis of addition, multiplication, and modular operations, we reveal that translation invariance in addition aligns with relative positional encoding for robust generalization, while base mismatch in modular operations disrupts this alignment. Experiments across GPT-family models validate our framework, confirming its ability to predict generalization behaviors. Our work highlights the importance of task structure and training data distribution for achieving data-efficient and structure-aware training, providing a systematic approach to understanding of length generalization in transformers",
    "checked": true,
    "id": "834676db5aa6b3a09bacd92068854f132f9a7ba1",
    "semantic_title": "principled understanding of generalization for generative transformer models in arithmetic reasoning tasks",
    "citation_count": 0,
    "authors": [
      "Xingcheng Xu",
      "Zibo Zhao",
      "Haipeng Zhang",
      "Yanqing Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.236": {
    "title": "Discourse Relation-Enhanced Neural Coherence Modeling",
    "volume": "long",
    "abstract": "Discourse coherence theories posit relations between text spans as a key feature of coherent texts. However, existing work on coherence modeling has paid little attention to discourse relations. In this paper, we provide empirical evidence to demonstrate that relation features are correlated with text coherence. Then, we investigate a novel fusion model that uses position-aware attention and a visible matrix to combine text- and relation-based features for coherence assessment. Experimental results on two benchmarks show that our approaches can significantly improve baselines, demonstrating the importance of relation features for coherence modeling",
    "checked": false,
    "id": "6cae6fb9ae36f0a0bfe6ab9634bd0dd409711654",
    "semantic_title": "improving long document topic segmentation models with enhanced coherence modeling",
    "citation_count": 10,
    "authors": [
      "Wei Liu",
      "Michael Strube"
    ]
  },
  "https://aclanthology.org/2025.acl-long.237": {
    "title": "Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models",
    "volume": "long",
    "abstract": "Large Audio-Language Models (LALMs), such as GPT-4o, have recently unlocked audio dialogue capabilities, enabling direct spoken exchanges with humans. The potential of LALMs broadens their applicability across a wide range of practical scenarios supported by audio dialogues. However, given these advancements, a comprehensive benchmark to evaluate the performance of LALMs in the open-ended audio dialogue understanding remains absent currently. To address this gap, we propose an **A**udio **D**ialogue **U**nderstanding **Bench**mark **(ADU-Bench),** which consists of 4 benchmark datasets. They assess the open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9 multilingual languages, and 4 categories of ambiguity handling. Notably, *we firstly propose the evaluation of ambiguity handling* in audio dialogues that expresses different intentions beyond the same literal meaning of sentences, *e.g.,* ‘\"Really!?\"‘ with different intonations. In summary, ADU-Bench includes over 20,000 open-ended audio dialogues for the assessment of LALMs. Through extensive experiments conducted on 16 LALMs, our analysis reveals that existing LALMs struggle with mathematical symbols and formulas, understanding human behavior such as roleplay, comprehending multiple languages, and handling audio dialogue ambiguities from different phonetic elements, such as intonations, pause positions, and homophones. The benchmark is available at https://adu-bench.github.io/",
    "checked": true,
    "id": "78a09eeaef1e457218c018d270d4116b53381bc4",
    "semantic_title": "benchmarking open-ended audio dialogue understanding for large audio-language models",
    "citation_count": 9,
    "authors": [
      "Kuofeng Gao",
      "Shu-Tao Xia",
      "Ke Xu",
      "Philip Torr",
      "Jindong Gu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.238": {
    "title": "from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors",
    "volume": "long",
    "abstract": "Current studies have exposed the risk of Large Language Models (LLMs) generating harmful content by jailbreak attacks. However, they overlook that the direct generation of harmful content from scratch is more difficult than inducing LLM to calibrate benign content into harmful forms.In our study, we introduce a novel attack framework that exploits AdVersArial meTAphoR (AVATAR) to induce the LLM to calibrate malicious metaphors for jailbreaking.Specifically, to answer harmful queries, AVATAR adaptively identifies a set of benign but logically related metaphors as the initial seed.Then, driven by these metaphors, the target LLM is induced to reason and calibrate about the metaphorical content, thus jailbroken by either directly outputting harmful responses or calibrating residuals between metaphorical and professional harmful content.Experimental results demonstrate that AVATAR can effectively and transferably jailbreak LLMs and achieve a state-of-the-art attack success rate across multiple advanced LLMs",
    "checked": true,
    "id": "adf1e3bcbdda379f5378e12bb6b0d8c376fb0705",
    "semantic_title": "from benign import toxic: jailbreaking the language model via adversarial metaphors",
    "citation_count": 0,
    "authors": [
      "Yu Yan",
      "Sheng Sun",
      "Zenghao Duan",
      "Teli Liu",
      "Min Liu",
      "Zhiyi Yin",
      "LeiJingyu LeiJingyu",
      "Qi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.239": {
    "title": "ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Multilingual Contrastive Framework",
    "volume": "long",
    "abstract": "Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To further enhance the performance of non-dominant languages, we propose ShifCon, a Shift-based multilingual Contrastive framework that aligns the internal forward process of other languages toward that of the dominant one. Specifically, it shifts the representations of non-dominant languages into the dominant language subspace, allowing them to access relatively rich information encoded in the model parameters. The enriched representations are then shifted back into their original language subspace before generation. Moreover, we introduce a subspace distance metric to pinpoint the optimal layer area for shifting representations and employ multilingual contrastive learning to further enhance the alignment of representations within this area. Experiments demonstrate that our ShifCon framework significantly enhances the performance of non-dominant languages, particularly for low-resource ones. Further analysis offers extra insights to verify the effectiveness of ShifCon and propel future research",
    "checked": false,
    "id": "0c98c94659a41c795981dce510edbca9c0350b74",
    "semantic_title": "shifcon: enhancing non-dominant language capabilities with a shift-based contrastive framework",
    "citation_count": 6,
    "authors": [
      "Hengyuan Zhang",
      "Chenming Shang",
      "Sizhe Wang",
      "Dongdong Zhang",
      "Yiyao Yu",
      "Feng Yao",
      "Renliang Sun",
      "Yujiu Yang",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.240": {
    "title": "MorphMark: Flexible Adaptive Watermarking for Large Language Models",
    "volume": "long",
    "abstract": "Watermarking by altering token sampling probabilities based on red-green list is a promising method for tracing the origin of text generated by large language models (LLMs). However, existing watermark methods often struggle with a fundamental dilemma: improving watermark effectiveness (the detectability of the watermark) often comes at the cost of reduced text quality. This trade-off limits their practical application. To address this challenge, we first formalize the problem within a multi-objective trade-off analysis framework. Within this framework, we identify a key factor that influences the dilemma. Unlike existing methods, where watermark strength is typically treated as a fixed hyperparameter, our theoretical insights lead to the development of MorphMark—a method that adaptively adjusts the watermark strength in response to changes in the identified factor, thereby achieving an effective resolution of the dilemma. In addition, MorphMark also prioritizes flexibility since it is an model-agnostic and model-free watermark method, thereby offering a practical solution for real-world deployment, particularly in light of the rapid evolution of AI models. Extensive experiments demonstrate that MorphMark achieves a superior resolution of the effectiveness-quality dilemma, while also offering greater flexibility and time and space efficiency",
    "checked": true,
    "id": "7117c2eb7367cdf8dfcf63d03489ecee2afc6a31",
    "semantic_title": "morphmark: flexible adaptive watermarking for large language models",
    "citation_count": 0,
    "authors": [
      "Zongqi Wang",
      "Tianle Gu",
      "Baoyuan Wu",
      "Yujiu Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.241": {
    "title": "A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression",
    "volume": "long",
    "abstract": "In this work, we provide an empirical investigation of gist-based context compression methods to improve context processing in large language models. We focus on two key questions: (1) How well can these methods replace full attention models? and (2) What potential failure patterns arise due to compression? Through extensive experiments, we show that while gist-based compression can achieve only slight performance loss on tasks like retrieval-augmented generation and long-document QA, it faces challenges in tasks like synthetic recall. Furthermore, we identify three key failure patterns: lost by the boundary, lost if surprise, and lost along the way. To mitigate these issues, we propose two effective strategies: fine-grained autoencoding, which enhances the reconstruction of original token information, and segment-wise token importance estimation, which adjusts optimization based on token dependencies. Our work provides valuable insights into the understanding of gist token-based context compression and offers practical strategies for improving compression capabilities",
    "checked": true,
    "id": "2d43280f399efbe7610886ad309514bece36840d",
    "semantic_title": "a silver bullet or a compromise for full attention? a comprehensive study of gist token-based context compression",
    "citation_count": 4,
    "authors": [
      "Chenlong Deng",
      "Zhisong Zhang",
      "Kelong Mao",
      "Shuaiyi Li",
      "Xinting Huang",
      "Dong Yu",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.242": {
    "title": "On the Limit of Language Models as Planning Formalizers",
    "volume": "long",
    "abstract": "Large Language Models have been found to create plans that are neither executable nor verifiable in grounded environments. An emerging line of work demonstrates success in using the LLM as a formalizer to generate a formal representation of the planning domain in some language, such as Planning Domain Definition Language (PDDL). This formal representation can be deterministically solved to find a plan. We systematically evaluate this methodology while bridging some major gaps. While previous work only generates a partial PDDL representation, given templated, and therefore unrealistic environment descriptions, we generate the complete representation given descriptions of various naturalness levels. Among an array of observations critical to improve LLMs' formal planning abilities, we note that most large enough models can effectively formalize descriptions as PDDL, outperforming those directly generating plans, while being robust to lexical perturbation. As the descriptions become more natural-sounding, we observe a decrease in performance and provide detailed error analysis",
    "checked": true,
    "id": "9810d8ffdacf12695c21f95c850302b3946db23b",
    "semantic_title": "on the limit of language models as planning formalizers",
    "citation_count": 4,
    "authors": [
      "Cassie Huang",
      "Li Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.243": {
    "title": "Learning to Generate Structured Output with Schema Reinforcement Learning",
    "volume": "long",
    "abstract": "This study investigates the structured generation capabilities of large language models (LLMs), focusing on producing valid JSON outputs against a given schema. Despite the widespread use of JSON in integrating language models with programs, there is a lack of comprehensive analysis and benchmarking of these capabilities. We explore various aspects of JSON generation, such as structure understanding, escaping, and natural language description, to determine how to assess and enable LLMs to generate valid responses. Building upon this, we propose SchemaBench features around 40K different JSON schemas to obtain and assess models' abilities in generating valid JSON. We find that the latest LLMs are still struggling to generate a valid JSON string. Moreover, we demonstrate that incorporating reinforcement learning with a Fine-grained Schema Validator can further enhance models' understanding of JSON schema, leading to improved performance. Our models demonstrate significant improvement in both generating JSON outputs and downstream tasks",
    "checked": true,
    "id": "23c86f865148f40c20b652bbfb773a10d9a1b88b",
    "semantic_title": "learning to generate structured output with schema reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Yaxi Lu",
      "Haolun Li",
      "Xin Cong",
      "Zhong Zhang",
      "Yesai Wu",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Fangming Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.244": {
    "title": "Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning",
    "volume": "long",
    "abstract": "Recently, using large language models (LLMs) for data augmentation has led to considerable improvements in unsupervised sentence embedding models. However, existing methods encounter two primary challenges: limited data diversity and high data noise. Current approaches often neglect fine-grained knowledge, such as entities and quantities, leading to insufficient diversity. Besides, unsupervised data frequently lacks discriminative information, and the generated synthetic samples may introduce noise. In this paper, we propose a pipeline-based data augmentation method via LLMs and introduce the Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model to enhance unsupervised sentence embeddings. To tackle the issue of low data diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and quantities, enabling LLMs to generate more diverse samples. To address high data noise, the GCSE model uses a Gaussian-decayed function to limit the impact of false hard negative samples, enhancing the model's discriminative capability. Experimental results show that our approach achieves state-of-the-art performance in semantic textual similarity (STS) tasks, using fewer data samples and smaller LLMs, demonstrating its efficiency and robustness across various models",
    "checked": true,
    "id": "fc0ca75113e9d1627267f77e982ada9ab8da7e11",
    "semantic_title": "enhancing unsupervised sentence embeddings via knowledge-driven data augmentation and gaussian-decayed contrastive learning",
    "citation_count": 2,
    "authors": [
      "Peichao Lai",
      "Zhengfeng Zhang",
      "Wentao Zhang",
      "Fangcheng Fu",
      "Bin Cui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.245": {
    "title": "Improve Safety Training of Large Language Models with Safety-Critical Singular Vectors Localization",
    "volume": "long",
    "abstract": "The rapid advancement of large language models (LLMs) has brought about increased concerns regarding their safety, especially as adversaries develop jailbreak techniques to bypass LLMs' safety mechanism. Although recent work on safety training with modules such as low-rank adaptation (LoRA) to resist jailbreaks shows promise, these approaches can inadvertently degrade a model's general utility. In this paper, we propose a novel plug-and-play method that mitigates the impact of safety training on model utility by explicitly locating and leveraging safety-critical singular vectors, which only contribute to safety, within the model's parameter space. We quantify the safety-criticality of each singular vector as the difference of their importance for safety and utility measured by a corresponding low-rank projection. The top scored singular vectors are located as safety-critical and are used to initialize the LoRA modules within existing safety training methods in a plug-and-play manner, thereby constraining the training updates within safety-critical parameters. Additionally, we propose a dynamic rank number determination strategy to further reduce parameter overhead. Experiments on HarmBench with multiple jailbreak methods validate the effectiveness of our approach in safety training, while evaluations on several utility benchmarks demonstrate that our method successfully mitigates the adverse impact of safety training on model utility, enhancing the utility performance of the evaluated safety training baselines",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peijian Gu",
      "Quan Wang",
      "Zhendong Mao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.246": {
    "title": "WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models",
    "volume": "long",
    "abstract": "Despite recent progress achieved by code large language models (LLMs), their remarkable abilities are largely dependent on fine-tuning on the high-quality data, posing challenges for data collection and annotation. To address this, current methods often design various data flywheels to collect complex code instructions, enabling models to handle more intricate tasks. However, these approaches typically rely on off-the-shelf datasets and data augmentation from a limited set of proprietary LLMs (e.g., Claude, GPT4, and so on), which restricts the diversity of the constructed data and makes it prone to systemic biases. In this paper, we propose **WarriorCoder**, a novel paradigm learns from expert battles to address these limitations. Specifically, we create an arena where leading expert code LLMs challenge each other, with evaluations conducted by impartial judges. This competitive framework generates novel training data from scratch, leveraging the strengths of all participants. Experimental results show that **WarriorCoder** achieves state-of-the-art performance compared to previous models of the same size, even without relying on proprietary LLMs",
    "checked": true,
    "id": "f98e66439962390990eec532b8bf1315979068d8",
    "semantic_title": "warriorcoder: learning from expert battles to augment code large language models",
    "citation_count": 0,
    "authors": [
      "Huawen Feng",
      "Pu Zhao",
      "Qingfeng Sun",
      "Can Xu",
      "Fangkai Yang",
      "Lu Wang",
      "Qianli Ma",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.247": {
    "title": "A Triple-View Framework for Fine-Grained Emotion Classification with Clustering-Guided Contrastive Learning",
    "volume": "long",
    "abstract": "Fine-grained emotion classification (FEC) aims to analyze speakers' utterances and distinguish dozens of emotions with subtle differences, allowing for a more nuanced understanding of human emotional states. However, compared to traditional coarse-grained emotion classification, two difficulties arise as the granularity of emotions becomes finer, i.e., the presence of closely confusable emotions which are hard to distinguish, and the biased performance caused by long-tailed emotions. Although addressing both difficulties is vital to FEC, previous studies have predominantly focused on dealing with only one of them. In this paper, we propose TACO, a novel triple-view framework that treats FEC as an instance-label (i.e., utterance-emotion) joint embedding learning problem to tackle both difficulties concurrently by considering three complementary views. Specifically, we design a clustering-guided contrastive loss, which incorporates clustering techniques to guide the contrastive learning process and facilitate more discriminative instance embeddings. Additionally, we introduce the emotion label description as a helpful resource to refine label embeddings and mitigate the poor performance towards under-represented (i.e., long-tailed) emotions. Extensive experiments on two widely-used benchmark datasets demonstrate that our proposed TACO achieves substantial and consistent improvements compared to other competitive baseline methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junqing Gong",
      "Binhan Yang",
      "Wei Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.248": {
    "title": "Quantification of Large Language Model Distillation",
    "volume": "long",
    "abstract": "Model distillation is a fundamental technique in building large language models (LLMs), transferring knowledge from a teacher model to a student model. However, distillation can lead to model homogenization, reducing diversity among models and impairing their ability to robustly handle complex or novel tasks. These limitations underscore the need to systematically quantify the distillation process and its impact. In this work, we propose a framework to evaluate and quantify model distillation. Our method addresses two key aspects: (1) Identifying identity cognition contradictions to assess discrepancies in how models perceive and represent identity-related information, and (2) Analyzing multi-granularity response similarities across models to measure the extent of homogenization. Experimental results demonstrate two key insights: (1) Well-known closed-source and open-source LLMs usually exhibit high distillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show higher distillation degrees compared to aligned LLMs. By offering a systematic approach to improve the transparency of LLM data distillation, we call for LLMs with more independent development and more transparent technical reports to improve LLMs' robustness and safety. The code and data are available at https://github.com/Aegis1863/LLMs-Distillation-Quantification",
    "checked": true,
    "id": "8c8104c49722b6284c97c6f8b463ab502bb1ab5d",
    "semantic_title": "quantification of large language model distillation",
    "citation_count": 1,
    "authors": [
      "Sunbowen Lee",
      "Junting Zhou",
      "Chang Ao",
      "Kaige Li",
      "Xeron Du",
      "Sirui He",
      "Haihong Wu",
      "Tianci Liu",
      "Jiaheng Liu",
      "Hamid Alinejad-Rokny",
      "Min Yang",
      "Yitao Liang",
      "Zhoufutu Wen",
      "Shiwen Ni"
    ]
  },
  "https://aclanthology.org/2025.acl-long.249": {
    "title": "Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models",
    "volume": "long",
    "abstract": "This paper revisits the implementation of Load-Balancing-Loss (LBL) when training Mixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as NE ∑i=1NE fipi, where NE is the total number of experts, fi represents the frequency of expert i being selected, and pi denotes the average gating score of the expert i. Existing MoE training frameworks usually employ the parallel training strategy so that fi and the LBL are calculated within a micro-batch and averaged across parallel groups.However, a micro-batch for training billion-scale LLMs typically contains very few sequences, leading to the micro-batch LBL being almost at the sequence level, and the router is pushed to distribute the token evenly within each sequence.Under this strict constraint, even tokens from a domain-specific sequence (e.g., code) are uniformly routed to all experts, thereby inhibiting expert specialization.In this work, we propose calculating LBL using a global-batch to loose this constraint. Because a global-batch contains much more diverse sequences than a micro-batch, which will encourage load balance at the corpus level. Specifically, we introduce an extra communication step to synchronize fi across micro-batches and then use it to calculate the LBL.Through experiments on training MoEs-based LLMs (up to 42.8B parameters and 400B tokens), we surprisingly find that the global-batch LBL strategy yields excellent performance gains in both pre-training perplexity and downstream tasks.Our analysis reveals that the global-batch LBL greatly improves the domain specialization of experts. Global-batch LBL is also used in Qwen3-MoEs",
    "checked": true,
    "id": "cf7f15e93bc4151f39a01b95f58d03179ab10696",
    "semantic_title": "demons in the detail: on implementing load balancing loss for training specialized mixture-of-expert models",
    "citation_count": 7,
    "authors": [
      "Zihan Qiu",
      "Zeyu Huang",
      "Bo Zheng",
      "Kaiyue Wen",
      "Zekun Wang",
      "Rui Men",
      "Ivan Titov",
      "Dayiheng Liu",
      "Jingren Zhou",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.250": {
    "title": "Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial method for addressing hallucinations in large language models (LLMs). While recent research has extended RAG models to complex noisy scenarios, these explorations often confine themselves to limited noise types and presuppose that noise is inherently detrimental to LLMs, potentially deviating from real-world retrieval environments and restricting practical applicability. In this paper, we define seven distinct noise types from a linguistic perspective and establish a Noise RAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing multiple datasets and reasoning tasks. Through empirical evaluation of eight representative LLMs with diverse architectures and scales, we reveal that these noises can be further categorized into two practical groups: noise that is beneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs (aka harmful noise). While harmful noise generally impairs performance, beneficial noise may enhance several aspects of model capabilities and overall performance. Our analysis offers insights for developing robust RAG solutions and mitigating hallucinations across diverse retrieval scenarios. Code is available at https://github.com/jinyangwu/NoiserBench",
    "checked": true,
    "id": "dc9ab4fa53e68d280ee508ddd264b68bbe349850",
    "semantic_title": "pandora's box or aladdin's lamp: a comprehensive analysis revealing the role of rag noise in large language models",
    "citation_count": 6,
    "authors": [
      "Jinyang Wu",
      "Shuai Zhang",
      "Feihu Che",
      "Mingkuan Feng",
      "Pengpeng Shao",
      "Jianhua Tao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.251": {
    "title": "Stepwise Reasoning Disruption Attack of LLMs",
    "volume": "long",
    "abstract": "Large language models (LLMs) have made remarkable strides in complex reasoning tasks, but their safety and robustness in reasoning processes remain unexplored, particularly in third-party platforms that facilitate user interactions via APIs. Existing attacks on LLM reasoning are constrained by specific settings or lack of imperceptibility, limiting their feasibility and generalizability. To address these challenges, we propose the Stepwise rEasoning Error Disruption (SEED) attack, which subtly injects errors into prior reasoning steps to mislead the model into producing incorrect subsequent reasoning and final answers. Unlike previous methods, SEED is compatible with zero-shot and few-shot settings, maintains the natural reasoning flow, and ensures covert execution without modifying the instruction. Extensive experiments on four datasets across four different models demonstrate SEED's effectiveness, revealing the vulnerabilities of LLMs to disruptions in reasoning processes. These findings underscore the need for greater attention to the robustness of LLM reasoning to ensure safety in practical applications. Our code is available at: https://github.com/Applied-Machine-Learning-Lab/SEED-Attack",
    "checked": true,
    "id": "838463a782ee7c4cb0fa6403adb2308563ab29cd",
    "semantic_title": "stepwise reasoning disruption attack of llms",
    "citation_count": 0,
    "authors": [
      "Jingyu Peng",
      "Maolin Wang",
      "Xiangyu Zhao",
      "Kai Zhang",
      "Wanyu Wang",
      "Pengyue Jia",
      "Qidong Liu",
      "Ruocheng Guo",
      "Qi Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.252": {
    "title": "Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge",
    "volume": "long",
    "abstract": "LLM-as-a-Judge, which generates chain-of-thought (CoT) judgments, has become a widely adopted auto-evaluation method. However, its reliability is compromised by the CoT reasoning's inability to capture comprehensive and deeper details, often leading to incomplete outcomes. Existing methods mainly rely on majority voting or criteria expansion, which is insufficient to address the limitation in CoT. We propose Crowd-based Comparative Evaluation, which introduces additional crowd responses to compare with the candidate responses, thereby exposing deeper and more comprehensive details within the candidate responses. This process effectively guides LLM-as-a-Judge to provide a more detailed CoT judgment. Extensive experiments demonstrate that our approach enhances evaluation reliability, achieving an average accuracy gain of 6.7% across five benchmarks. Moreover, our method produces higher-quality CoTs that facilitate judge distillation and exhibit superior performance in rejection sampling for supervised fine-tuning (SFT), referred to as crowd rejection sampling, thereby enabling more efficient SFT. Our analysis confirms that CoTs generated by ours are more comprehensive and of higher quality, and evaluation accuracy improves as inference scales",
    "checked": true,
    "id": "b17ca4d3c08ec1ccedced30c9781cdbd52b645bc",
    "semantic_title": "crowd comparative reasoning: unlocking comprehensive evaluations for llm-as-a-judge",
    "citation_count": 2,
    "authors": [
      "Qiyuan Zhang",
      "Yufei Wang",
      "Yuxin Jiang",
      "Liangyou Li",
      "Chuhan Wu",
      "Yasheng Wang",
      "Xin Jiang",
      "Lifeng Shang",
      "Ruiming Tang",
      "Fuyuan Lyu",
      "Chen Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.253": {
    "title": "Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models",
    "volume": "long",
    "abstract": "Multilingual language models (MLMs) store factual knowledge across languages but often struggle to provide consistent responses to semantically equivalent prompts in different languages. While previous studies point out this cross-lingual inconsistency issue, the underlying causes remain unexplored. In this work, we use mechanistic interpretability methods to investigate cross-lingual inconsistencies in MLMs. We find that MLMs encode knowledge in a language-independent concept space through most layers, and only transition to language-specific spaces in the final layers. Failures during the language transition often result in incorrect predictions in the target language, even when the answers are correct in other languages. To mitigate this inconsistency issue, we propose a linear shortcut method that bypasses computations in the final layers, enhancing both prediction accuracy and cross-lingual consistency. Our findings shed light on the internal mechanisms of MLMs and provide a lightweight, effective strategy for producing more consistent factual outputs",
    "checked": true,
    "id": "53804a199653d0482f1423732218b6586436e281",
    "semantic_title": "lost in multilinguality: dissecting cross-lingual factual inconsistency in transformer language models",
    "citation_count": 5,
    "authors": [
      "Mingyang Wang",
      "Heike Adel",
      "Lukas Lange",
      "Yihong Liu",
      "Ercong Nie",
      "Jannik Strötgen",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.acl-long.254": {
    "title": "Optimizing Decomposition for Optimal Claim Verification",
    "volume": "long",
    "abstract": "Current research on the Decompose-Then-Verify paradigm for evaluating the factuality of long-form text typically treats decomposition and verification in isolation, overlooking their interactions and potential misalignment. We find that existing decomposition policies, typically hand-crafted demonstrations, do not align well with downstream verifiers in terms of atomicity—a novel metric quantifying information density—leading to suboptimal verification results. We formulate finding the optimal decomposition policy for optimal verification as a bilevel optimization problem. To approximate a solution for this strongly NP-hard problem, we propose dynamic decomposition, a reinforcement learning framework that leverages verifier feedback to learn a policy for dynamically decomposing claims to verifier-preferred atomicity. Experimental results show that dynamic decomposition outperforms existing decomposition policies, improving verification confidence by 0.07 and accuracy by 0.12 (on a 0-1 scale) on average across varying verifiers, datasets, and atomcities of input claims",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yining Lu",
      "Noah Ziems",
      "Hy Dang",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.255": {
    "title": "GradOT: Training-free Gradient-preserving Offsite-tuning for Large Language Models",
    "volume": "long",
    "abstract": "The rapid growth of large language models (LLMs) with traditional centralized fine-tuning emerges as a key technique for adapting these models to domain-specific challenges, yielding privacy risks for both model and data owners. One promising solution, called offsite-tuning (OT), is proposed to address these challenges, where a weaker emulator is compressed from the original model and further fine-tuned with adapter to enhance privacy. However, the existing OT-based methods require high computational costs and lack theoretical analysis. This paper introduces a novel OT approach based on gradient-preserving compression. By analyzing the OT problem through the lens of optimization, we propose a method that selectively applies compression techniques such as rank compression and channel pruning, preserving the gradients of fine-tuned adapters while ensuring privacy. Extensive experiments demonstrate that our approach surpasses existing OT methods, both in terms of privacy protection and model performance. Our method provides a theoretical foundation for OT and offers a practical, training-free solution for offsite-tuning of large-scale LLMs",
    "checked": false,
    "id": "187f4521e6080f93fc2a26bf91b4e7d64f94e18a",
    "semantic_title": "fedbpt: efficient federated black-box prompt tuning for large language models",
    "citation_count": 26,
    "authors": [
      "Kai Yao",
      "Zhaorui Tan",
      "Penglei Gao",
      "Lichun Li",
      "Kaixin Wu",
      "Yinggui Wang",
      "Yuan Zhao",
      "Yixin Ji",
      "Jianke Zhu",
      "Wei Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.256": {
    "title": "Knowledge Boundary of Large Language Models: A Survey",
    "volume": "long",
    "abstract": "Although large language models (LLMs) store vast amount of knowledge in their parameters, they still have limitations in the memorization and utilization of certain knowledge, leading to undesired behaviors such as generating untruthful and inaccurate responses. This highlights the critical need to understand the knowledge boundary of LLMs, a concept that remains inadequately defined in existing research. In this survey, we propose a comprehensive definition of the LLM knowledge boundary and introduce a formalized taxonomy categorizing knowledge into four distinct types. Using this foundation, we systematically review the field through three key lenses: the motivation for studying LLM knowledge boundaries, methods for identifying these boundaries, and strategies for mitigating the challenges they present. Finally, we discuss open challenges and potential research directions in this area. We aim for this survey to offer the community a comprehensive overview, facilitate access to key issues, and inspire further advancements in LLM knowledge research",
    "checked": true,
    "id": "26ed9ef3e1853c8b98b4f8282d2ec13d38da1f32",
    "semantic_title": "knowledge boundary of large language models: a survey",
    "citation_count": 9,
    "authors": [
      "Moxin Li",
      "Yong Zhao",
      "Wenxuan Zhang",
      "Shuaiyi Li",
      "Wenya Xie",
      "See-Kiong Ng",
      "Tat-Seng Chua",
      "Yang Deng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.257": {
    "title": "Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning",
    "volume": "long",
    "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated enhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting to advanced, product-oriented solutions like OpenAI o1. During our re-implementation of this model, we noticed that in multimodal tasks requiring visual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to maintain focus on the visual information, in other words, MLLMs suffer from a gradual decline in attention to visual information as reasoning progresses, causing text-over-relied outputs. To investigate this, we ablate image inputs during long-chain reasoning. Concretely, we truncate the reasoning process midway, then re-complete the reasoning process with the input image removed. We observe only a ~2 accuracy drop on MathVista's test-hard subset, revealing the model's textual outputs dominate the following reasoning process. Motivated by this, we propose Take-along Visual Conditioning (TVC), a strategy that shifts image input to critical reasoning stages and compresses redundant visual tokens via dynamic pruning. This methodology helps the model retain attention to the visual components throughout the reasoning. Our approach achieves state-of-the-art performance on average across five mathematical reasoning benchmarks (+3.4% vs previous sota), demonstrating the effectiveness of TVC in enhancing multimodal reasoning systems. The project page is available at https://sun-hailong.github.io/projects/TVC",
    "checked": true,
    "id": "2a2b8ae584838c3bd387d57857881821f2847acb",
    "semantic_title": "mitigating visual forgetting via take-along visual conditioning for multi-modal long cot reasoning",
    "citation_count": 6,
    "authors": [
      "Hai-Long Sun",
      "Zhun Sun",
      "Houwen Peng",
      "Han-Jia Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.258": {
    "title": "MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG), while serving as a viable complement to large language models (LLMs), often overlooks the crucial aspect of text chunking within its pipeline. This paper initially introduces a dual-metric evaluation method, comprising Boundary Clarity and Chunk Stickiness, to enable the direct quantification of chunking quality. Leveraging this assessment method, we highlight the inherent limitations of traditional and semantic chunking in handling complex contextual nuances, thereby substantiating the necessity of integrating LLMs into chunking process. To address the inherent trade-off between computational efficiency and chunking precision in LLM-based approaches, we devise the granularity-aware Mixture-of-Chunkers (MoC) framework, which consists of a three-stage processing mechanism. Notably, our objective is to guide the chunker towards generating a structured list of chunking regular expressions, which are subsequently employed to extract chunks from the original text. Extensive experiments demonstrate that both our proposed metrics and the MoC framework effectively settle challenges of the chunking task, revealing the chunking kernel while enhancing the performance of the RAG system",
    "checked": true,
    "id": "11f0642a81afb6aaea49e4f46673c361f4a948df",
    "semantic_title": "moc: mixtures of text chunking learners for retrieval-augmented generation system",
    "citation_count": 1,
    "authors": [
      "Jihao Zhao",
      "Zhiyuan Ji",
      "Zhaoxin Fan",
      "Hanyu Wang",
      "Simin Niu",
      "Bo Tang",
      "Feiyu Xiong",
      "Zhiyu Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.259": {
    "title": "Mitigating Selection Bias with Node Pruning and Auxiliary Options",
    "volume": "long",
    "abstract": "Large language models (LLMs) often exhibit systematic preferences for certain answer choices when responding to multiple-choice questions—a behavior known as selection bias. This bias reduces the accuracy and reliability of LLM outputs, limiting their usefulness in decision-critical applications. While prior work has focused on adjusting model inputs or outputs to mitigate this issue, our work takes a fundamentally different approach by identifying and removing the internal sources of bias. We introduce two methods: Bias Node Pruning (BNP), which prunes parameters that contribute to selection bias, and Auxiliary Option Injection (AOI), which introduces an additional answer choice to reduce bias in both white-box and black-box settings. To address the shortcomings of existing evaluation metrics, we propose Choice Kullback-Leibler Divergence (CKLD), a new metric that captures distributional imbalances in model predictions. Experiments on three LLMs across multiple datasets demonstrate that our methods consistently improve answer accuracy while reducing selection bias, providing a robust solution for both open- and closed-source models",
    "checked": true,
    "id": "c9ba0baad1092ca685ba46f23178801d445de390",
    "semantic_title": "mitigating selection bias with node pruning and auxiliary options",
    "citation_count": 2,
    "authors": [
      "Hyeong Kyu Choi",
      "Weijie Xu",
      "Chi Xue",
      "Stephanie Eckman",
      "Chandan K. Reddy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.260": {
    "title": "Dually Self-Improved Counterfactual Data Augmentation Using Large Language Model",
    "volume": "long",
    "abstract": "Counterfactual data augmentation, which generates minimally edited tokens to alter labels, has become a key approach to improving model robustness in natural language processing (NLP). It is usually implemented by first identifying the causal terms and then modifying these terms to create counterfactual candidates. The emergence of large language models (LLMs) has effectively facilitated the task of counterfactual data augmentation. However, existing LLM-based approaches still face some challenges in 1) accurately extracting the task-specific causal terms, and 2) the quality of LLM-generated counterfacts. To address the issues, we propose a dually self-improved counterfactual data augmentation method using LLM for the Natural Language Inference (NLI) task. On the one hand, we design a self-improved strategy employing the attention distribution of the task model to identify the task-specific causal terms, which is lightweight and task-specific. On the other hand, a second self-improved strategy based on direct preference optimization is utilized to refine LLM-generated counterfacts, achieving high-quality counterfacts. Finally, a balanced loss preventing over-emphasis on augmented data is proposed to retrain the task model on the fusion of existing data and generated counterfacts. Extensive experiments on NLI benchmarks demonstrate the effectiveness of our proposed method in generating high-quality counterfacts for improving task performance",
    "checked": false,
    "id": "f5a0a56abb35f5176d95452a60102fa86c980e72",
    "semantic_title": "improving long-tail vulnerability detection through data augmentation based on large language models",
    "citation_count": 0,
    "authors": [
      "Luhao Zhang",
      "Xinyu Zhang",
      "Linmei Hu",
      "Dandan Song",
      "Liqiang Nie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.261": {
    "title": "RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "While Retrieval-Augmented Generation (RAG) has exhibited promise in utilizing external knowledge, its generation process heavily depends on the quality and accuracy of the retrieved context. Large language models (LLMs) struggle to evaluate the correctness of non-parametric knowledge retrieved externally when it differs from internal memorization, leading to knowledge conflicts during response generation. To this end, we introduce the **R**etrieval **P**reference **O**ptimization (RPO), a lightweight and effective alignment method to adaptively leverage multi-source knowledge based on retrieval relevance. An implicit representation of retrieval relevance is derived and incorporated into the reward model to integrate retrieval evaluation and response generation into a single model, solving the problem that previous methods necessitate the additional procedure to assess the retrieval quality. Notably, RPO is a RAG-dedicated alignment approach that quantifies the awareness of retrieval relevance in training, first overcoming mathematical obstacles. Experiments on four datasets demonstrate that RPO outperforms RAG by 4-10% in accuracy without any extra component, exhibiting its robust generalization",
    "checked": true,
    "id": "a045c037f44956332fbd76e1817b90373724c9a8",
    "semantic_title": "rpo: retrieval preference optimization for robust retrieval-augmented generation",
    "citation_count": 0,
    "authors": [
      "Shi-Qi Yan",
      "Quan Liu",
      "Zhen-Hua Ling"
    ]
  },
  "https://aclanthology.org/2025.acl-long.262": {
    "title": "Learning to Reason from Feedback at Test-Time",
    "volume": "long",
    "abstract": "Solving complex tasks in a single attempt is challenging for large language models (LLMs). Iterative interaction with the environment and feedback is often required to achieve success, making effective feedback utilization a critical topic. Existing approaches either struggle with length generalization or rely on naive retries without leveraging prior information. In this paper, we introduce FTTT, a novel paradigm that formulates feedback utilization as an optimization problem at test time. Additionally, we propose a learnable test-time optimizer, OpTune, to effectively exploit feedback. Experiments on two LLMs across four reasoning datasets demonstrate that FTTT and OpTune achieve superior scalability and performance",
    "checked": true,
    "id": "ed7a6e478a2949e1b70c27fcaf9d1150e44bbc0a",
    "semantic_title": "learning to reason from feedback at test-time",
    "citation_count": 4,
    "authors": [
      "Yanyang Li",
      "Michael R. Lyu",
      "Liwei Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.263": {
    "title": "L-CiteEval: A Suite for Evaluating Fidelity of Long-context Models",
    "volume": "long",
    "abstract": "Long-context models(LCMs) have witnessed remarkable advancements in recent years, facilitating real-world tasks like long-document QA. The success of LCMs is founded on the hypothesis that the model demonstrates strong fidelity, enabling it to respond based on the provided long context rather than relying solely on the intrinsic knowledge acquired during pre-training. Yet, in this paper, we find that open-sourced LCMs are not as faithful as expected. We introduce L-CiteEval, an out-of-the-box suite that can assess both generation quality and fidelity in long-context understanding tasks. It covers 11 tasks with context lengths ranging from 8K to 48K and a corresponding automatic evaluation pipeline. Evaluation of 11 cutting-edge closed-source and open-source LCMs indicates that, while there are minor differences in their generation, open-source models significantly lag behind closed-source counterparts in terms of fidelity. Furthermore, we analyze the benefits of citation generation for LCMs from both the perspective of explicit model output and the internal attention mechanism",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zecheng Tang",
      "Keyan Zhou",
      "Juntao Li",
      "Baibei Ji",
      "Jianye Hou",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.264": {
    "title": "SECRET: Semi-supervised Clinical Trial Document Similarity Search",
    "volume": "long",
    "abstract": "Clinical trials are vital for evaluation of safety and efficacy of new treatments. However, clinical trials are resource-intensive, time-consuming and expensive to conduct, where errors in trial design, reduced efficacy, and safety events can result in significant delays, financial losses, and damage to reputation. These risks underline the importance of informed and strategic decisions in trial design to mitigate these risks and improve the chances of a successful trial. Identifying similar historical trials is critical as these trials can provide an important reference for potential pitfalls and challenges including serious adverse events, dosage inaccuracies, recruitment difficulties, patient adherence issues, etc. Addressing these challenges in trial design can lead to development of more effective study protocols with optimized patient safety and trial efficiency. In this paper, we present a novel method to identify similar historical trials by summarizing clinical trial protocols and searching for similar trials based on a query trial's protocol. Our approach significantly outperforms all baselines, achieving up to a 78% improvement in recall@1 and a 53% improvement in precision@1 over the best baseline. We also show that our method outperforms all other baselines in partial trial similarity search and zero-shot patient-trial matching, highlighting its superior utility in these tasks",
    "checked": true,
    "id": "5a81642f1ce9242434027e2206e5dbe04798e59b",
    "semantic_title": "secret: semi-supervised clinical trial document similarity search",
    "citation_count": 0,
    "authors": [
      "Trisha Das",
      "Afrah Shafquat",
      "Mandis Beigi",
      "Jacob Aptekar",
      "Jimeng Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.265": {
    "title": "Geometric Signatures of Compositionality Across a Language Model's Lifetime",
    "volume": "long",
    "abstract": "By virtue of linguistic compositionality, few syntactic rules and a finite lexicon can generate an unbounded number of sentences. That is, language, though seemingly high-dimensional, can be explained using relatively few degrees of freedom. An open question is whether contemporary language models (LMs) reflect the intrinsic simplicity of language that is enabled by compositionality. We take a geometric view of this problem by relating the degree of compositionality in a dataset to the intrinsic dimension (ID) of its representations under an LM, a measure of feature complexity. We find not only that the degree of dataset compositionality is reflected in representations' ID, but that the relationship between compositionality and geometric complexity arises due to learned linguistic features over training. Finally, our analyses reveal a striking contrast between nonlinear and linear dimensionality, showing they respectively encode semantic and superficial aspects of linguistic composition",
    "checked": true,
    "id": "5dbbbbce29d3b12cb5cff5cd8961140cea145dd9",
    "semantic_title": "geometric signatures of compositionality across a language model's lifetime",
    "citation_count": 4,
    "authors": [
      "Jin Hwa Lee",
      "Thomas Jiralerspong",
      "Lei Yu",
      "Yoshua Bengio",
      "Emily Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.266": {
    "title": "Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) such as ChatGPT demonstrate significant potential in the medical domain and are often evaluated using multiple-choice questions (MCQs) modeled on exams like the USMLE. However, such benchmarks may overestimate true clinical understanding by rewarding pattern recognition and test-taking heuristics. To investigate this, we created a fictional medical benchmark centered on an imaginary organ, the Glianorex, allowing us to separate memorized knowledge from reasoning ability. We generated textbooks and MCQs in English and French using leading LLMs, then evaluated proprietary, open-source, and domain-specific models in a zero-shot setting. Despite the fictional content, models achieved an average score of 64%, while physicians scored only 27%. Fine-tuned medical models outperformed base models in English but not in French. Ablation and interpretability analyses revealed that models frequently relied on shallow cues, test-taking strategies, and hallucinated reasoning to identify the correct choice. These results suggest that standard MCQ-based evaluations may not effectively measure clinical reasoning and highlight the need for more robust, clinically meaningful assessment methods for LLMs",
    "checked": true,
    "id": "1271a2b8feae30fe83151464aa229149fe1f4728",
    "semantic_title": "pattern recognition or medical knowledge? the problem with multiple-choice questions in medicine",
    "citation_count": 6,
    "authors": [
      "Maxime Griot",
      "Jean Vanderdonckt",
      "Demet Yuksel",
      "Coralie Hemptinne"
    ]
  },
  "https://aclanthology.org/2025.acl-long.267": {
    "title": "People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text",
    "volume": "long",
    "abstract": "In this paper, we study how well humans can detect text generated by commercial LLMs (GPT-4o, Claude, o1). We hire annotators to read 300 non-fiction English articles, label them as either human-written or AI-generated, and provide paragraph-length explanations for their decisions. Our experiments show that annotators who frequently use LLMs for writing tasks excel at detecting AI-generated text, even without any specialized training or feedback. In fact, the majority vote among five such \"expert\" annotators misclassifies only 1 of 300 articles, significantly outperforming most commercial and open-source detectors we evaluated even in the presence of evasion tactics like paraphrasing and humanization. Qualitative analysis of the experts' free-form explanations shows that while they rely heavily on specific lexical clues (‘AI vocabulary'), they also pick up on more complex phenomena within the text (e.g., formality, originality, clarity) that are challenging to assess for automatic detectors. We release our annotated dataset and code to spur future research into both human and automated detection of AI-generated text",
    "checked": true,
    "id": "b1bff38f79cd3aa4f24b8285da650735f970c57c",
    "semantic_title": "people who frequently use chatgpt for writing tasks are accurate and robust detectors of ai-generated text",
    "citation_count": 10,
    "authors": [
      "Jenna Russell",
      "Marzena Karpinska",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.268": {
    "title": "YuLan-Mini: Pushing the Limits of Open Data-efficient Language Model",
    "volume": "long",
    "abstract": "Due to the immense resource demands and the involved complex techniques, it is still challenging for successfully pre-training a large language models (LLMs) with state-of-the-art performance. In this paper, we explore the key bottlenecks and designs during pre-training, and make the following contributions: (1) a comprehensive investigation into the factors contributing to training instability; (2) a robust optimization approach designed to mitigate training instability effectively; (3) an elaborate data pipeline that integrates data synthesis, data curriculum, and data selection. By integrating the above techniques, we create a rather low-cost training recipe and use it to pre-train YuLan-Mini, a fully-open base model with 2.4B parameters on 1.08T tokens. Remarkably, YuLan-Mini achieves top-tier performance among models of similar parameter scale, with comparable performance to industry-leading models that require significantly more data. To facilitate reproduction, we release the full details of training recipe and data composition. Project details can be accessed at the following link: https://anonymous.4open.science/r/YuLan-Mini/README.md",
    "checked": true,
    "id": "a6c94b59bf5f34b35d573b7d70f8001bb8e30319",
    "semantic_title": "yulan-mini: pushing the limits of open data-efficient language model",
    "citation_count": 0,
    "authors": [
      "Hu Yiwen",
      "Huatong Song",
      "Jie Chen",
      "Jia Deng",
      "Jiapeng Wang",
      "Kun Zhou",
      "Yutao Zhu",
      "Jinhao Jiang",
      "Zican Dong",
      "Yang Lu",
      "Xu Miao",
      "Xin Zhao",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.269": {
    "title": "Your Model is Overconfident, and Other Lies We Tell Ourselves",
    "volume": "long",
    "abstract": "The difficulty intrinsic to a given example, rooted in its inherent ambiguity, is a key yet often overlooked factor in evaluating neural NLP models. We investigate the interplay and divergence among various metrics for assessing intrinsic difficulty, including annotator dissensus, training dynamics, and model confidence. Through a comprehensive analysis using 29 models on three datasets, we reveal that while correlations exist among these metrics, their relationships are neither linear nor monotonic. By disentangling these dimensions of uncertainty, we aim to refine our understanding of data complexity and its implications for evaluating and improving NLP models",
    "checked": true,
    "id": "6effceb18d5d6bbf99355feb96b82dce01b7d99a",
    "semantic_title": "your model is overconfident, and other lies we tell ourselves",
    "citation_count": 0,
    "authors": [
      "Timothee Mickus",
      "Aman Sinha",
      "Raúl Vázquez"
    ]
  },
  "https://aclanthology.org/2025.acl-long.270": {
    "title": "Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural language processing but exhibit significant performance gaps among different languages. Most existing approaches to address these disparities rely on pretraining or fine-tuning, which are resource-intensive. To overcome these limitations without incurring significant costs, we propose Inference-Time Cross-Lingual Intervention (INCLINE), a novel framework that enhances LLM performance on low-performing (source) languages by aligning their internal representations with those of high-performing (target) languages during inference. INCLINE initially learns alignment matrices using parallel sentences from source and target languages through a Least-Squares optimization, and then applies these matrices during inference to transform the low-performing language representations toward the high-performing language space. Extensive experiments on nine benchmarks with five LLMs demonstrate that INCLINE significantly improves performance across diverse tasks and languages, compared to recent strong baselines. Our analysis demonstrates that INCLINE is highly cost-effective and applicable to a wide range of applications. In addition, we release the code to foster research along this line",
    "checked": true,
    "id": "f1d195191e280980734e221bce83dae508fbf319",
    "semantic_title": "bridging the language gaps in large language models with inference-time cross-lingual intervention",
    "citation_count": 5,
    "authors": [
      "Weixuan Wang",
      "Minghao Wu",
      "Barry Haddow",
      "Alexandra Birch"
    ]
  },
  "https://aclanthology.org/2025.acl-long.271": {
    "title": "Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) are renowned for their extensive linguistic knowledge and strong generalization capabilities, but their high computational demands make them unsuitable for resource-constrained environments. In contrast, small language models (SLMs) are computationally efficient but often lack the broad generalization capacity of LLMs. To bridge this gap, we propose PiFi, a novel framework that combines the strengths of both LLMs and SLMs to achieve high performance while maintaining efficiency. PiFi integrates a single frozen layer from an LLM into a SLM and fine-tunes the combined model for specific tasks, boosting performance without a significant increase in computational cost. We show that PiFi delivers consistent performance improvements across a range of natural language processing tasks, including both natural language understanding and generation. Moreover, our findings demonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing generalization to unseen domains and facilitating the transfer of linguistic abilities",
    "checked": true,
    "id": "0171145d48115e090985e44a6fa497470db78c68",
    "semantic_title": "plug-in and fine-tuning: bridging the gap between small language models and large language models",
    "citation_count": 0,
    "authors": [
      "Kyeonghyun Kim",
      "Jinhee Jang",
      "Juhwan Choi",
      "Yoonji Lee",
      "Kyohoon Jin",
      "YoungBin Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.272": {
    "title": "What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma",
    "volume": "long",
    "abstract": "Mental-health stigma remains a pervasive social problem that hampers treatment-seeking and recovery. Existing resources for training neural models to finely classify such stigma are limited, relying primarily on social-media or synthetic data without theoretical underpinnings. To remedy this gap, we present an expert-annotated, theory-informed corpus of human-chatbot interviews, comprising 4,141 snippets from 684 participants with documented socio-cultural backgrounds. Our experiments benchmark state-of-the-art neural models and empirically unpack the challenges of stigma detection. This dataset can facilitate research on computationally detecting, neutralizing, and counteracting mental-health stigma. Our corpus is openly available at https://github.com/HanMeng2004/Mental-Health-Stigma-Interview-Corpus",
    "checked": true,
    "id": "598c3319804da5e832a41a511c40d2ad6eb1ea62",
    "semantic_title": "what is stigma attributed to? a theory-grounded, expert-annotated interview corpus for demystifying mental-health stigma",
    "citation_count": 0,
    "authors": [
      "Han Meng",
      "Yancan Chen",
      "Yunan Li",
      "Yitian Yang",
      "Jungup Lee",
      "Renwen Zhang",
      "Yi-Chieh Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.273": {
    "title": "ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors",
    "volume": "long",
    "abstract": "Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. To address the inconsistency issue in multilingual audio-text retrieval, we first identify two intuitive factors that contribute to inconsistency: misalignment between audio and multilingual text embeddings, and error propagation in model optimization. By systematically analyzing these factors, we derive theoretical weight error upper bounds for quantifying their effects and find that the main source of inconsistency is the data distribution error during training. This finding motivates our solution to reduce data distribution errors.We propose a consistent ML-ATR scheme using 1-to-k contrastive learning and audio-English co-anchor contrastive learning, aiming to mitigate the negative impact of data distribution error on recall and consistency in ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets show that our scheme achieves state-of-the-art performance on recall and consistency metrics for eight mainstream languages, including English. Our code will be available at https://github.com/ATRI-ACL/ATRI-ACL",
    "checked": true,
    "id": "277dacc92536d3874b42b220ac99b34b7d6b1186",
    "semantic_title": "atri: mitigating multilingual audio text retrieval inconsistencies by reducing data distribution errors",
    "citation_count": 5,
    "authors": [
      "Yuguo Yin",
      "Yuxin Xie",
      "Wenyuan Yang",
      "Dongchao Yang",
      "Jinghan Ru",
      "Xianwei Zhuang",
      "Liming Liang",
      "Yuexian Zou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.274": {
    "title": "Enhancing Transformers for Generalizable First-Order Logical Entailment",
    "volume": "long",
    "abstract": "Transformers, as the fundamental deep learning architecture, have demonstrated great capability in reasoning. This paper studies the generalizable first-order logical reasoning ability of transformers with their *parameterized* knowledge and how to improve it. Transformers' capability of first-order reasoning is further captured by whether they can conduct first-order logical entailment, which is quantitatively measured by their performance in answering knowledge graph queries. We establish the connections between (1) two types of distribution shifts studied in out-of-distribution generalization and (2) unseen knowledge and query settings discussed in the task of knowledge graph query answering, which makes it possible to characterize the fine-grained generalizability. Results on our comprehensive dataset showed that transformers **outperform** previous methods designed particularly for this task and provided detailed empirical evidence about the impact of the input query syntax, token embedding, and transformer architectures on the reasoning capability of transformers. Interestingly, our results revealed the mismatch of positional encoding and other design choices of transformer architectures in previous practices. Motivated by this, we propose **TEGA**, a logic-aware architecture that significantly improves the performance in generalizable first-order logical entailment",
    "checked": true,
    "id": "a8d29b5c2803855c16c8713f16498f76c54d442e",
    "semantic_title": "enhancing transformers for generalizable first-order logical entailment",
    "citation_count": 3,
    "authors": [
      "Tianshi Zheng",
      "Jiazheng Wang",
      "Zihao Wang",
      "Jiaxin Bai",
      "Hang Yin",
      "Zheye Deng",
      "Yangqiu Song",
      "Jianxin Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.275": {
    "title": "Self-Taught Agentic Long Context Understanding",
    "volume": "long",
    "abstract": "Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM's understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow. At the core of AgenticLU is Chain-of-Clarifications (CoC), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. By scaling inference as a tree search where each node represents a CoC step, we achieve 97.8% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight. To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the CoC workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables AgenticLU models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass. Extensive experiments across seven long-context tasks demonstrate that AgenticLU significantly outperforms state-of-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows",
    "checked": true,
    "id": "35deef280018088de6d228c1e8dbc8a169417e8f",
    "semantic_title": "self-taught agentic long context understanding",
    "citation_count": 0,
    "authors": [
      "Yufan Zhuang",
      "Xiaodong Yu",
      "Jialian Wu",
      "Ximeng Sun",
      "Ze Wang",
      "Jiang Liu",
      "Yusheng Su",
      "Jingbo Shang",
      "Zicheng Liu",
      "Emad Barsoum"
    ]
  },
  "https://aclanthology.org/2025.acl-long.276": {
    "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training",
    "volume": "long",
    "abstract": "As large language models (LLMs) become increasingly prevalent, concerns about their reliability, particularly due to hallucinations - factually inaccurate or irrelevant outputs - have grown. Our research investigates the relationship between the uncertainty in training dynamics and the emergence of hallucinations. Using models from the Pythia suite and several hallucination detection metrics, we analyze hallucination trends and identify significant variance during training. To address this, we propose Sensitivity Dropout (SenD), a novel training protocol designed to reduce hallucination variance during training by deterministically dropping embedding indices with significant variability. In addition, we develop an unsupervised hallucination detection metric, Efficient EigenScore (EES), which approximates the traditional EigenScore in 2x speed. This metric is integrated into our training protocol, allowing SenD to be both computationally scalable and effective at reducing hallucination variance. SenD improves test-time reliability of Pythia and Meta's Llama models by up to 17% and enhances factual accuracy in Wikipedia, Medical, Legal, and Coding domains without affecting downstream task performance",
    "checked": true,
    "id": "9ca26cc48ffbbc4c0f8391935fe6442b201c1921",
    "semantic_title": "hallucination detox: sensitivity dropout (send) for large language model training",
    "citation_count": 0,
    "authors": [
      "Shahrad Mohammadzadeh",
      "Juan David Guerra",
      "Marco Bonizzato",
      "Reihaneh Rabbany",
      "Golnoosh Farnadi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.277": {
    "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
    "volume": "long",
    "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, the development of such agents faces a critical bottleneck: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Further, these approaches exhibit significant gaps between the generated data and online environments, alongside limited data diversity. To address this issue, we introduce OS-Genesis, a novel GUI data synthesis pipeline that overcomes the challenges above. Unlike prior methods that rely on preset tasks, OS-Genesis reverse engineers the GUI trajectory construction process. Agents first perceive environments and perform step-level interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's cost-effectiveness and its superior data quality and diversity compared to existing synthesis methods",
    "checked": true,
    "id": "285f38de28b79df0bb64a859ab0d79048e860f30",
    "semantic_title": "os-genesis: automating gui agent trajectory construction via reverse task synthesis",
    "citation_count": 26,
    "authors": [
      "Qiushi Sun",
      "Kanzhi Cheng",
      "Zichen Ding",
      "Chuanyang Jin",
      "Yian Wang",
      "Fangzhi Xu",
      "Zhenyu Wu",
      "Chengyou Jia",
      "Liheng Chen",
      "Zhoumianze Liu",
      "Ben Kao",
      "Guohao Li",
      "Junxian He",
      "Yu Qiao",
      "Zhiyong Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.278": {
    "title": "CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter",
    "volume": "long",
    "abstract": "Speculative decoding is a powerful technique that accelerates Large Language Model (LLM) inference by leveraging a lightweight speculative draft model. However, existing designs suffers in performance due to misalignment between training and inference. Recent methods have tried to solve this issue by adopting a multi-step training strategy, but the complex inputs of different training steps make it harder for the draft model to converge. To address this, we propose CORAL, a novel framework that improves both accuracy and efficiency in speculative drafting. CORAL introduces Cross-Step Representation Alignment, a method that enhances consistency across multiple training steps, significantly improving speculative drafting performance. Additionally, we identify the LM head as a major bottleneck in the inference speed of the draft model. We introduce a weight-grouping mechanism that selectively activates a subset of LM head parameters during inference, substantially reducing the latency of the draft model. We evaluate CORAL on three LLM families and three benchmark datasets, achieving speedup ratios of 2.50x-4.07x, outperforming state-of-the-art methods such as EAGLE-2 and HASS. Our results demonstrate that CORAL effectively mitigates training-inference misalignment and delivers significant speedup for modern LLMs with large vocabularies",
    "checked": true,
    "id": "061b9d662f76b06e0319ee42aabc489b59e0bc97",
    "semantic_title": "coral: learning consistent representations across multi-step training with lighter speculative drafter",
    "citation_count": 0,
    "authors": [
      "Yepeng Weng",
      "Dianwen Mei",
      "Huishi Qiu",
      "Xujie Chen",
      "Li Liu",
      "Jiang Tian",
      "Zhongchao Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.279": {
    "title": "ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability",
    "volume": "long",
    "abstract": "Concept-based explanations work by mapping complex model computations to human-understandable concepts. Evaluating such explanations is very difficult, as it includes not only the quality of the induced space of possible concepts but also how effectively the chosen concepts are communicated to users. Existing evaluation metrics often focus solely on the former, neglecting the latter.We introduce an evaluation framework for measuring concept explanations via automated simulatability: a simulator's ability to predict the explained model's outputs based on the provided explanations. This approach accounts for both the concept space and its interpretation in an end-to-end evaluation. Human studies for simulatability are notoriously difficult to enact, particularly at the scale of a wide, comprehensive empirical evaluation (which is the subject of this work). We propose using large language models (LLMs) as simulators to approximate the evaluation and report various analyses to make such approximations reliable. Our method allows for scalable and consistent evaluation across various models and datasets. We report a comprehensive empirical evaluation using this framework and show that LLMs provide consistent rankings of explanation methods. Code available at Anonymous GitHub",
    "checked": true,
    "id": "32901424e88a11361fa223f59b7a97b7aa04212a",
    "semantic_title": "consim: measuring concept-based explanations' effectiveness with automated simulatability",
    "citation_count": 3,
    "authors": [
      "Antonin Poché",
      "Alon Jacovi",
      "Agustin Martin Picard",
      "Victor Boutin",
      "Fanny Jourdan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.280": {
    "title": "Decoding Reading Goals from Eye Movements",
    "volume": "long",
    "abstract": "Readers can have different goals with respect to the text that they are reading. Can these goals be decoded from their eye movements over the text? In this work, we examine for the first time whether it is possible to distinguish between two types of common reading goals: information seeking and ordinary reading for comprehension. Using large-scale eye tracking data, we address this task with a wide range of models that cover different architectural and data representation strategies, and further introduce a new model ensemble. We find that transformer-based models with scanpath representations coupled with language modeling solve it most successfully, and that accurate predictions can be made in real time, shortly after the participant started reading the text. We further introduce a new method for model performance analysis based on mixed effect modeling. Combining this method with rich textual annotations reveals key properties of textual items and participants that contribute to the difficulty of the task, and improves our understanding of the variability in eye movement patterns across the two reading regimes",
    "checked": true,
    "id": "b96b63dffa54ebd8cc1523af92c49cc8322c4813",
    "semantic_title": "decoding reading goals from eye movements",
    "citation_count": 1,
    "authors": [
      "Omer Shubi",
      "Cfir Avraham Hadar",
      "Yevgeni Berzak"
    ]
  },
  "https://aclanthology.org/2025.acl-long.281": {
    "title": "Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Space",
    "volume": "long",
    "abstract": "Imageability (potential of text to evoke a mental image) and concreteness (perceptibility of text) are two psycholinguistic properties that link visual and semantic spaces. It is little surprise that computational methods that estimate them do so using parallel visual and semantic spaces, such as collections of image-caption pairs or multi-modal models. In this paper, we work on the supposition that text itself in an image-caption dataset offers sufficient signals to accurately estimate these properties. We hypothesize, in particular, that the peakedness of the neighborhood of a word in the semantic embedding space reflects its degree of imageability and concreteness. We then propose an unsupervised, distribution-free measure, which we call Neighborhood Stability Measure (NSM), that quantifies the sharpness of peaks. Extensive experiments show that NSM correlates more strongly with ground-truth ratings than existing unsupervised methods, and is a strong predictor of these properties for classification. Our code and data are available on GitHub (https://github.com/Artificial-Memory-Lab/imageability)",
    "checked": false,
    "id": "8c25c4e6bcaa2025ca363a5bfbf293b17674a8db",
    "semantic_title": "uncovering visual-semantic psycholinguistic properties from the distributional structure of text embedding spac",
    "citation_count": 0,
    "authors": [
      "Si Wu",
      "Sebastian Bruch"
    ]
  },
  "https://aclanthology.org/2025.acl-long.282": {
    "title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent",
    "volume": "long",
    "abstract": "GUI automation faces critical challenges in dynamic environments. MLLMs suffer from two key issues: misinterpreting UI components and outdated knowledge. Traditional fine-tuning methods are costly for app-specific knowledge updates. We propose GUI-explorer, a training-free GUI agent that incorporates two fundamental mechanisms: (1) Autonomous Exploration of Function-aware Trajectory. To comprehensively cover all application functionalities, we design a Function-aware Task Goal Generator that automatically constructs exploration goals by analyzing GUI structural information (e.g., screenshots and activity hierarchies). This enables systematic exploration to collect diverse trajectories. (2) Unsupervised Mining of Transition-aware Knowledge. To establish precise screen-operation logic, we develop a Transition-aware Knowledge Extractor that extracts effective screen-operation logic through unsupervised analysis the state transition of structured interaction triples (observation, action, outcome). This eliminates the need for human involvement in knowledge extraction. With a task success rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows significant improvements over SOTA agents. It requires no parameter updates for new apps. GUI-explorer is open-sourced and publicly available at https://github.com/JiuTian-VL/GUI-explorer",
    "checked": true,
    "id": "6aa37368093709706812e91e124e33c776b88ecb",
    "semantic_title": "gui-explorer: autonomous exploration and mining of transition-aware knowledge for gui agent",
    "citation_count": 1,
    "authors": [
      "Bin Xie",
      "Rui Shao",
      "Gongwei Chen",
      "Kaiwen Zhou",
      "Yinchuan Li",
      "Jie Liu",
      "Min Zhang",
      "Liqiang Nie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.283": {
    "title": "P2 Law: Scaling Law for Post-Training After Model Pruning",
    "volume": "long",
    "abstract": "Pruning has become a widely adopted technique for reducing the hardware requirements of large language models (LLMs). To recover model performance after pruning, post-training is commonly employed to mitigate the resulting performance degradation. While post-training benefits from larger datasets, once the dataset size is already substantial, increasing the training data provides only limited performance gains. To balance post-training cost and model performance, it is necessary to explore the optimal amount of post-training data. Through extensive experiments on the Llama-3 and Qwen-2.5 series models, pruned using various common pruning methods, we uncover the scaling Law for Post-training after model Pruning, referred to as the P2 Law. This law identifies four key factors for predicting the pruned model's post-training loss: the model size before pruning, the number of post-training tokens, the pruning rate, and the model's loss before pruning. Moreover, P2 Law can generalize to larger dataset sizes, larger model sizes, and higher pruning rates, offering valuable insights for the post-training of pruned LLMs",
    "checked": false,
    "id": "10e6c00fea9818264e9d624af89edeaf298d0a78",
    "semantic_title": "p$^2$ law: scaling law for post-training after model pruning",
    "citation_count": 0,
    "authors": [
      "Xiaodong Chen",
      "Yuxuan Hu",
      "Xiaokang Zhang",
      "Yanling Wang",
      "Cuiping Li",
      "Hong Chen",
      "Jing Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.284": {
    "title": "Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats",
    "volume": "long",
    "abstract": "Dog whistles are coded expressions with dual meanings: one intended for the general public (outgroup) and another that conveys a specific message to an intended audience (ingroup). Often, these expressions are used to convey controversial political opinions while maintaining plausible deniability and slip by content moderation filters. Identification of dog whistles relies on curated lexicons, which have trouble keeping up to date. We introduce FETCH!, a task for finding novel dog whistles in massive social media corpora. We find that state-of-the-art systems fail to achieve meaningful results across three distinct social media case studies. We present EarShot, a strong baseline system that combines the strengths of vector databases and Large Language Models (LLMs) to efficiently and effectively identify new dog whistles",
    "checked": true,
    "id": "5f574685c68d9b55879e4d55d148abf0c0d4402d",
    "semantic_title": "making fetch! happen: finding emergent dog whistles through common habitats",
    "citation_count": 0,
    "authors": [
      "Kuleen Sasse",
      "Carlos Alejandro Aguirre",
      "Isabel Cachola",
      "Sharon Levy",
      "Mark Dredze"
    ]
  },
  "https://aclanthology.org/2025.acl-long.285": {
    "title": "Lost in the Context: Insufficient and Distracted Attention to Contexts in Preference Modeling",
    "volume": "long",
    "abstract": "In Reinforcement Learning from Human Feedback (RLHF), the reward model (RM) evaluates the response quality based on the given context and assigns a reward. It plays a crucial role in aligning RLHF with human preferences. Although the current RM training paradigm concatenates the context and response while amplifying the reward difference between good and bad response pairs, we demonstrate that the RM faces two significant issues: i) it often allocates only a small proportion of attention to the context, and ii) it frequently ignores segments of the context that are relevant for evaluating the response quality. These issues undermine the RM's effectiveness in modeling human preferences. To further address these challenges, we propose AttnRM, a novel optimization framework that enables the RM to concentrate on crucial segments of the context. Experimental results demonstrate that AttnRM significantly improves preference modeling by increasing attention to relevant information within the context. It also enhances the RM's generalizability and achieves better performance in aligning with human preferences",
    "checked": true,
    "id": "6d63ef075c5426bb190ab2088704a5c765732e2f",
    "semantic_title": "lost in the context: insufficient and distracted attention to contexts in preference modeling",
    "citation_count": 0,
    "authors": [
      "Shihan Dou",
      "Jiayi Chen",
      "Chenhao Huang",
      "Feng Chen",
      "Wei Chengzhi",
      "Huiyuan Zheng",
      "Shichun Liu",
      "Yan Liu",
      "Chenxiao Liu",
      "Chao Xin",
      "Lin Yan",
      "Zongzhang Zhang",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.286": {
    "title": "Entailment-Preserving First-order Logic Representations in Natural Language Entailment",
    "volume": "long",
    "abstract": "First-order logic (FOL) is often used to represent logical entailment, but determining natural language (NL) entailment using FOL remains a challenge. To address this, we propose the Entailment-Preserving FOL representations (EPF) task and introduce reference-free evaluation metrics for EPF (Entailment-Preserving Rate (EPR) family). In EPF, one should generate FOL representations from multi-premise NL entailment data (e.g., EntailmentBank) so that the automatic prover's result preserves the entailment labels. Furthermore, we propose a training method specialized for the task, iterative learning-to-rank, which trains an NL-to-FOL translator by using the natural language entailment labels as verifiable rewards. Our method achieves a 1.8–2.7% improvement in EPR and a 17.4–20.6% increase in EPR@16 compared to diverse baselines in three datasets. Further analyses reveal that iterative learning-to-rank effectively suppresses the arbitrariness of FOL representation by reducing the diversity of predicate signatures, and maintains strong performance across diverse inference types and out-of-domain data",
    "checked": true,
    "id": "3c1a314e6fc944c5abe7f99be7dcb6477a2c0619",
    "semantic_title": "entailment-preserving first-order logic representations in natural language entailment",
    "citation_count": 1,
    "authors": [
      "Jinu Lee",
      "Qi Liu",
      "Runzhi Ma",
      "Vincent Han",
      "Ziqi Wang",
      "Heng Ji",
      "Julia Hockenmaier"
    ]
  },
  "https://aclanthology.org/2025.acl-long.287": {
    "title": "Enhancing Multimodal Continual Instruction Tuning with BranchLoRA",
    "volume": "long",
    "abstract": "Multimodal Continual Instruction Tuning (MCIT) aims to finetune Multimodal Large Language Models (MLLMs) to continually align with human intent across sequential tasks. Existing approaches often rely on the Mixture-of-Experts (MoE) LoRA framework to preserve previous instruction alignments. However, these methods are prone to Catastrophic Forgetting (CF), as they aggregate all LoRA blocks via simple summation, which compromises performance over time. In this paper, we identify a critical parameter inefficiency in the MoELoRA framework within the MCIT context. Based on this insight, we propose BranchLoRA, an asymmetric framework to enhance both efficiency and performance. To mitigate CF, we introduce a flexible tuning-freezing mechanism within BranchLoRA, enabling branches to specialize in intra-task knowledge while fostering inter-task collaboration. Moreover, we incrementally incorporate task-specific routers to ensure an optimal branch distribution over time, rather than favoring the most recent task. To streamline inference, we introduce a task selector that automatically routes test inputs to the appropriate router without requiring task identity. Extensive experiments on the latest MCIT benchmark demonstrate that BranchLoRA significantly outperforms MoELoRA and maintains its superiority across various MLLM sizes",
    "checked": true,
    "id": "6c056139e892f608414f78c7f4aa86c142b2a899",
    "semantic_title": "enhancing multimodal continual instruction tuning with branchlora",
    "citation_count": 1,
    "authors": [
      "Duzhen Zhang",
      "Yong Ren",
      "Zhong-Zhi Li",
      "Yahan Yu",
      "Jiahua Dong",
      "Chenxing Li",
      "Zhilong Ji",
      "Jinfeng Bai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.288": {
    "title": "Enhancing Automated Interpretability with Output-Centric Feature Descriptions",
    "volume": "long",
    "abstract": "Automated interpretability pipelines generate natural language descriptions for the concepts represented by features in large language models (LLMs), such as \"plants\" or \"the first word in a sentence\". These descriptions are derived using inputs that activate the feature, which may be a dimension or a direction in the model's representation space. However, identifying activating inputs is costly, and the mechanistic role of a feature in model behavior is determined both by how inputs cause a feature to activate and by how feature activation affects outputs. Using steering evaluations, we reveal that current pipelines provide descriptions that fail to capture the causal effect of the feature on outputs. To fix this, we propose efficient, output-centric methods for automatically generating feature descriptions. These methods use the tokens weighted higher after feature stimulation or the highest weight tokens after applying the vocabulary \"unembedding\" head directly to the feature. Our output-centric descriptions better capture the causal effect of a feature on model outputs than input-centric descriptions, but combining the two leads to the best performance on both input and output evaluations. Lastly, we show that output-centric descriptions can be used to find inputs that activate features previously thought to be \"dead\"",
    "checked": true,
    "id": "c0f2a9febf819ba2313cfc8eb77d8acf279b51ae",
    "semantic_title": "enhancing automated interpretability with output-centric feature descriptions",
    "citation_count": 15,
    "authors": [
      "Yoav Gur-Arieh",
      "Roy Mayan",
      "Chen Agassy",
      "Atticus Geiger",
      "Mor Geva"
    ]
  },
  "https://aclanthology.org/2025.acl-long.289": {
    "title": "Towards Effective and Efficient Continual Pre-training of Large Language Models",
    "volume": "long",
    "abstract": "Continual pre-training (CPT) has been an important approach for adapting language models to specific domains or tasks. In this paper, we comprehensively study its key designs to balance the new abilities while retaining the original abilities, and present an effective CPT method that can greatly improve the Chinese language ability and scientific reasoning ability of LLMs. To achieve it, we design specific data mixture and curriculum strategies based on existing datasets and synthetic high-quality data. Concretely, we synthesize multidisciplinary scientific QA pairs based on related web pages to guarantee the data quality, and also devise the performance tracking and data mixture adjustment strategy to ensure the training stability. For the detailed designs, we conduct preliminary studies on a relatively small model, and summarize the findings to help optimize our CPT method. Extensive experiments on a number of evaluation benchmarks show that our approach can largely improve the performance of Llama-3 (8B), including both the general abilities (+8.81 on C-Eval and +6.31 on CMMLU) and the scientific reasoning abilities (+12.00 on MATH and +4.13 on SciEval). Our model, data, and codes are available at https://github.com/RUC-GSAI/Llama-3-SynE",
    "checked": true,
    "id": "df448a66ddc961aaec74244b3d2ef6cfb792d1c1",
    "semantic_title": "towards effective and efficient continual pre-training of large language models",
    "citation_count": 6,
    "authors": [
      "Jie Chen",
      "Zhipeng Chen",
      "Jiapeng Wang",
      "Kun Zhou",
      "Yutao Zhu",
      "Jinhao Jiang",
      "Yingqian Min",
      "Xin Zhao",
      "Zhicheng Dou",
      "Jiaxin Mao",
      "Yankai Lin",
      "Ruihua Song",
      "Jun Xu",
      "Xu Chen",
      "Rui Yan",
      "Zhewei Wei",
      "Di Hu",
      "Wenbing Huang",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.290": {
    "title": "Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization",
    "volume": "long",
    "abstract": "Universal goal hijacking is a kind of prompt injection attack that forces LLMs to return a target malicious response for arbitrary normal user prompts. The previous methods achieve high attack performance while being too cumbersome and time-consuming. Also, they have concentrated solely on optimization algorithms, overlooking the crucial role of the prompt. To this end, we propose a method called POUGH that incorporates an efficient optimization algorithm and two semantics-guided prompt organization strategies. Specifically, our method starts with a sampling strategy to select representative prompts from a candidate pool, followed by a ranking strategy that prioritizes them. Given the sequentially ranked prompts, our method employs an iterative optimization algorithm to generate a fixed suffix that can concatenate to arbitrary user prompts for universal goal hijacking. Experiments conducted on four popular LLMs and ten types of target responses verified the effectiveness",
    "checked": true,
    "id": "f1611e6d829ba799783393b00f529c1e3f01ed76",
    "semantic_title": "efficient universal goal hijacking with semantics-guided prompt organization",
    "citation_count": 9,
    "authors": [
      "Yihao Huang",
      "Chong Wang",
      "Xiaojun Jia",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Jian Zhang",
      "Yang Liu",
      "Geguang Pu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.291": {
    "title": "mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding",
    "volume": "long",
    "abstract": "Multimodel Large Language Models(MLLMs) have achieved promising OCR-free Document Understanding performance by increasing the supported resolution of document images. However, this comes at the cost of generating thousands of visual tokens for a single document image, leading to excessive GPU memory and slower inference times, particularly in multi-page document comprehension. In this work, to address these challenges, we propose a High-resolution DocCompressor module to compress each high-resolution document image into 324 tokens, guided by low-resolution global visual features. With this compression module, to strengthen multi-page document comprehension ability and balance both token efficiency and question-answering performance, we develop the DocOwl2 under a three-stage training framework: Single-image Pretraining, Multi-image Continue-pretraining, and Multi-task Finetuning. DocOwl2 sets a new state-of-the-art across multi-page document understanding benchmarks and reduces first token latency by more than 50%. Compared to single-image MLLMs trained on similar data, our DocOwl2 achieves comparable single-page understanding performance with less than 20% of the visual tokens. Our codes, models, and data will be publicly available",
    "checked": true,
    "id": "b2c6feb05abaf988cef89c524560e953c930fca2",
    "semantic_title": "mplug-docowl2: high-resolution compressing for ocr-free multi-page document understanding",
    "citation_count": 37,
    "authors": [
      "Anwen Hu",
      "Haiyang Xu",
      "Liang Zhang",
      "Jiabo Ye",
      "Ming Yan",
      "Ji Zhang",
      "Qin Jin",
      "Fei Huang",
      "Jingren Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.292": {
    "title": "What Makes a Good Natural Language Prompt?",
    "volume": "long",
    "abstract": "As large language models (LLMs) have progressed towards more human-like and human–AI communications prevalent, prompting has emerged as a decisive component. However, there is limited conceptual consensus on what exactly quantifies natural language prompts. We attempt to address this question by conducting a meta-analysis surveying 150+ prompting-related papers from leading NLP and AI conferences (2022–2024), and blogs. We propose a property- and human-centric framework for evaluating prompt quality, encompassing 21 properties categorized into six dimensions. We then examine how existing studies assess their impact on LLMs, revealing their imbalanced support across models and tasks, and substantial research gaps. Further, we analyze correlations among properties in high-quality natural language prompts, deriving prompting recommendations. Finally, we explore multi-property prompt enhancements in reasoning tasks, observing that single-property enhancements often have the greatest impact. Our findings establish a foundation for property-centric prompt evaluation and optimization, bridging the gaps between human–AI communication and opening new prompting research directions",
    "checked": true,
    "id": "e1e7b8eb65bf4eed85ce0fbf9949a84d432aadfa",
    "semantic_title": "what makes a good natural language prompt?",
    "citation_count": 0,
    "authors": [
      "Do Xuan Long",
      "Duy Dinh",
      "Ngoc-Hai Nguyen",
      "Kenji Kawaguchi",
      "Nancy F. Chen",
      "Shafiq Joty",
      "Min-Yen Kan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.293": {
    "title": "X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents",
    "volume": "long",
    "abstract": "The Turing test examines whether AIs exhibit human-like behaviour in natural language conversations. The traditional setting limits each participant to one message at a time and requires constant human participation. This fails to reflect a natural conversational style and hinders the evaluation of dialogue agents based on Large Language Models (LLMs) in complex and prolonged interactions. This paper proposes X-Turing, which enhances the original test with a burst dialogue pattern, allowing more dynamic exchanges using consecutive messages. It further reduces human workload by iteratively generating dialogues that simulate the long-term interaction between the agent and a human to compose the majority of the test process. With the pseudo-dialogue history, the agent then engages in a shorter dialogue with a real human, which is paired with a human-human conversation on the same topic to be judged using questionnaires. We introduce the X-Turn Pass-Rate metric to assess the human likeness of LLMs across varying durations. While LLMs like GPT-4 initially perform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10 turns of dialogues respectively, their performance drops as the dialogue progresses, which underscores the difficulty in maintaining consistency in the long term",
    "checked": true,
    "id": "8e1b3b990ad2a7b05b44330e3985aac04cc07cd8",
    "semantic_title": "x-turing: towards an enhanced and efficient turing test for long-term dialogue agents",
    "citation_count": 2,
    "authors": [
      "Weiqi Wu",
      "Hongqiu Wu",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.294": {
    "title": "Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral",
    "volume": "long",
    "abstract": "Moral reasoning is a complex cognitive process shaped by individual experiences and cultural contexts and presents unique challenges for computational analysis. While natural language processing (NLP) offers promising tools for studying this phenomenon, current research lacks cohesion, employing discordant datasets and tasks that examine isolated aspects of moral reasoning. We bridge this gap with UniMoral, a unified dataset integrating psychologically grounded and social-media-derived moral dilemmas annotated with labels for action choices, ethical principles, contributing factors, and consequences, alongside annotators' moral and cultural profiles. Recognizing the cultural relativity of moral reasoning, UniMoral spans six languages, Arabic, Chinese, English, Hindi, Russian, and Spanish, capturing diverse socio-cultural contexts. We demonstrate UniMoral's utility through a benchmark evaluations of three large language models (LLMs) across four tasks: action prediction, moral typology classification, factor attribution analysis, and consequence generation. Key findings reveal that while implicitly embedded moral contexts enhance the moral reasoning capability of LLMs, there remains a critical need for increasingly specialized approaches to further advance moral reasoning in these models",
    "checked": true,
    "id": "ce8484fa04b29d5e26b09a3015489d65858d33ed",
    "semantic_title": "are rules meant to be broken? understanding multilingual moral reasoning as a computational pipeline with unimoral",
    "citation_count": 1,
    "authors": [
      "Shivani Kumar",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2025.acl-long.295": {
    "title": "Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models",
    "volume": "long",
    "abstract": "Generative models such as Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) trained on massive datasets can lead them to memorize and inadvertently reveal sensitive information, raising ethical and privacy concerns. While some prior works have explored this issue in the context of LLMs, it presents a unique challenge for MLLMs due to the entangled nature of knowledge across modalities, making comprehensive unlearning more difficult. To address this challenge, we propose Modality Aware Neuron Unlearning (MANU), a novel unlearning framework for MLLMs designed to selectively clip neurons based on their relative importance to the targeted forget data, curated for different modalities. Specifically, MANU consists of two stages: important neuron selection and selective pruning. The first stage identifies and collects the most influential neurons across modalities relative to the targeted forget knowledge, while the second stage is dedicated to pruning those selected neurons. MANU effectively isolates and removes the neurons that contribute most to the forget data within each modality, while preserving the integrity of retained knowledge. Our experiments conducted across various MLLM architectures illustrate that MANU can achieve a more balanced and comprehensive unlearning in each modality without largely affecting the overall model utility",
    "checked": true,
    "id": "0d9050f64dc2ea021dfa4534fb2810a234fa4d92",
    "semantic_title": "modality-aware neuron pruning for unlearning in multimodal large language models",
    "citation_count": 3,
    "authors": [
      "Zheyuan Liu",
      "Guangyao Dou",
      "Xiangchi Yuan",
      "Chunhui Zhang",
      "Zhaoxuan Tan",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.296": {
    "title": "NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning",
    "volume": "long",
    "abstract": "Diet plays a critical role in human health, yet tailoring dietary reasoning to individual health conditions remains a major challenge. Nutrition Question Answering (QA) has emerged as a popular method for addressing this problem. However, current research faces two critical limitations. On one hand, the absence of datasets involving user-specific medical information severely limits personalization. This challenge is further compounded by the wide variability in individual health needs. On the other hand, while large language models (LLMs), a popular solution for this task, demonstrate strong reasoning abilities, they struggle with the domain-specific complexities of personalized healthy dietary reasoning, and existing benchmarks fail to capture these challenges. To address these gaps, we introduce the Nutritional Graph Question Answering (NGQA) benchmark, the first graph question answering dataset designed for personalized nutritional health reasoning. NGQA leverages data from the National Health and Nutrition Examination Survey (NHANES) and the Food and Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is healthy for a specific user, supported by explanations of the key contributing nutrients. The benchmark incorporates three question complexity settings and evaluates reasoning across three downstream tasks. Extensive experiments with LLM backbones and baseline models demonstrate that the NGQA benchmark effectively challenges existing models. In sum, NGQA addresses a critical real-world problem while advancing GraphQA research with a novel domain-specific benchmark. Our codebase and dataset are available here",
    "checked": true,
    "id": "67d0dba0de772ba0e0912e5f827b5da601e7ef2c",
    "semantic_title": "ngqa: a nutritional graph question answering benchmark for personalized health-aware nutritional reasoning",
    "citation_count": 5,
    "authors": [
      "Zheyuan Zhang",
      "Yiyang Li",
      "Nhi Ha Lan Le",
      "Zehong Wang",
      "Tianyi Ma",
      "Vincent Galassi",
      "Keerthiram Murugesan",
      "Nuno Moniz",
      "Werner Geyer",
      "Nitesh V Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.297": {
    "title": "ReLearn: Unlearning via Learning for Large Language Models",
    "volume": "long",
    "abstract": "Current unlearning methods for large language models usually rely on reverse optimization to reduce target token probabilities. However, this paradigm disrupts the subsequent tokens prediction, degrading model performance and linguistic coherence. Moreover, existing evaluation metrics overemphasize contextual forgetting while inadequately assessing response fluency and relevance. To address these challenges, we propose ReLearn, a data augmentation and fine-tuning pipeline for effective unlearning, along with a comprehensive evaluation framework. This framework introduces Knowledge Forgetting Ratio (KFR) and Knowledge Retention Ratio (KRR) to measure knowledge-level preservation, and Linguistic Score (LS) to evaluate generation quality. Our experiments show that ReLearn successfully achieves targeted forgetting while preserving high-quality outputs. Through mechanistic analysis, we further demonstrate how reverse optimization disrupts coherent text generation, while ReLearn preserves this essential capability",
    "checked": true,
    "id": "8ce06676dba0e1ff50cf32b073e24f2aecf29ffa",
    "semantic_title": "relearn: unlearning via learning for large language models",
    "citation_count": 3,
    "authors": [
      "Haoming Xu",
      "Ningyuan Zhao",
      "Liming Yang",
      "Sendong Zhao",
      "Shumin Deng",
      "Mengru Wang",
      "Bryan Hooi",
      "Nay Oo",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.298": {
    "title": "Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling",
    "volume": "long",
    "abstract": "Topic modeling plays a vital role in uncovering hidden semantic structures within text corpora, but existing models struggle in low-resource settings where limited target-domain data leads to unstable and incoherent topic inference. We address this challenge by formally introducing domain adaptation for low-resource topic modeling, where a high-resource source domain informs a low-resource target domain without overwhelming it with irrelevant content. We establish a finite-sample generalization bound showing that effective knowledge transfer depends on robust performance in both domains, minimizing latent-space discrepancy, and preventing overfitting to the data. Guided by these insights, we propose DALTA (Domain-Aligned Latent Topic Adaptation), a new framework that employs a shared encoder for domain-invariant features, specialized decoders for domain-specific nuances, and adversarial alignment to selectively transfer relevant information. Experiments on diverse low-resource datasets demonstrate that DALTA consistently outperforms state-of-the-art methods in terms of topic coherence, stability, and transferability",
    "checked": true,
    "id": "a2bfdc21fc65b07229065a4194f3fb9c01e7841a",
    "semantic_title": "understanding cross-domain adaptation in low-resource topic modeling",
    "citation_count": 0,
    "authors": [
      "Pritom Saha Akash",
      "Kevin Chen-Chuan Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.299": {
    "title": "UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models",
    "volume": "long",
    "abstract": "Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, which leverages Uncertainty estimations to represent knowledge boundaries, and then explicitly incorporates these representations as input features into prompts for LLMs to Align with factual knowledge. First, we prepare the dataset on knowledge question-answering (QA) samples by calculating two uncertainty estimations, including confidence score and semantic entropy, to represent the knowledge boundaries for LLMs. Subsequently, using the prepared dataset, we train a reward model that incorporates uncertainty estimations and then employ the Proximal Policy Optimization (PPO) algorithm for factuality alignment on LLMs. Experimental results indicate that, by integrating uncertainty representations in LLM alignment, the proposed UAlign can significantly enhance the LLMs' capacities to confidently answer known questions and refuse unknown questions on both in-domain and out-of-domain tasks, showing reliability improvements and good generalizability over various prompt- and training-based baselines",
    "checked": true,
    "id": "5d373c79f1802e5c57d1d3f7a22c666ce10b29c9",
    "semantic_title": "ualign: leveraging uncertainty estimations for factuality alignment on large language models",
    "citation_count": 2,
    "authors": [
      "Boyang Xue",
      "Fei Mi",
      "Qi Zhu",
      "Hongru Wang",
      "Rui Wang",
      "Sheng Wang",
      "Erxin Yu",
      "Xuming Hu",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.300": {
    "title": "CoT-Valve: Length-Compressible Chain-of-Thought Tuning",
    "volume": "long",
    "abstract": "Chain-of-Thought significantly enhances a model's reasoning capability, but it also comes with a considerable increase in inference costs due to long chains. With the observation that the reasoning path can be easily compressed under easy tasks but struggle on hard tasks, we explore the feasibility of elastically controlling the length of reasoning paths with only one model, thereby reducing the inference overhead of reasoning models dynamically based on task difficulty. We introduce a new tuning and inference strategy named CoT-Valve, designed to allow models to generate reasoning chains of varying lengths. To achieve this, we propose to identify a direction in the parameter space that, when manipulated, can effectively control the length of generated CoT. Moreover, we show that this property is valuable for compressing the reasoning chain. We construct datasets with chains from long to short for the same questions and explore two enhanced strategies for CoT-Valve: (1) a precise length-compressible CoT tuning method, and (2) a progressive chain length compression approach. Our experiments show that CoT-Valve successfully enables controllability and compressibility of the chain and shows better performance than the prompt-based control. We applied this method to QwQ-32B-Preview, reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with only one additional incorrect answer",
    "checked": true,
    "id": "2039018e618ccc34744addf94c2ab8ad141d7f24",
    "semantic_title": "cot-valve: length-compressible chain-of-thought tuning",
    "citation_count": 55,
    "authors": [
      "Xinyin Ma",
      "Guangnian Wan",
      "Runpeng Yu",
      "Gongfan Fang",
      "Xinchao Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.301": {
    "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "While Retrieval-Augmented Generation (RAG) has emerged as an effective approach for addressing the knowledge outdating problem in Large Language Models (LLMs), it still faces a critical challenge: the prevalence of outdated information in knowledge bases. Current research primarily focuses on incorporating up-to-date information, yet the impact of outdated information coexisting in retrieval sources remains inadequately addressed. To bridge this gap, we introduce HoH, the first benchmark specifically designed to evaluate the impact of outdated information on RAG. Our benchmark leverages token-level diff algorithms combined with LLM pipelines to efficiently create a large-scale QA dataset that accurately captures the evolution of temporal knowledge in real-world facts.Through comprehensive experiments, we reveal that outdated information significantly degrades RAG performance in two critical ways: (1) it substantially reduces response accuracy by distracting models from correct information, and (2) it can mislead models into generating potentially harmful outputs, even when current information is available. Current RAG approaches struggle with both retrieval and generation aspects when handling outdated information. These findings highlight the urgent need for innovative solutions to address the temporal challenges in RAG",
    "checked": true,
    "id": "1fd9ab68584b6277409bee54de6deb224e4e8b34",
    "semantic_title": "hoh: a dynamic benchmark for evaluating the impact of outdated information on retrieval-augmented generation",
    "citation_count": 0,
    "authors": [
      "Jie Ouyang",
      "Tingyue Pan",
      "Mingyue Cheng",
      "Ruiran Yan",
      "Yucong Luo",
      "Jiaying Lin",
      "Qi Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.302": {
    "title": "Uncertainty Propagation on LLM Agent",
    "volume": "long",
    "abstract": "Large language models (LLMs) integrated into multi-step agent systems enable complex decision-making processes across various applications. However, their outputs often lack reliability, making uncertainty estimation crucial. Existing uncertainty estimation methods primarily focus on final-step outputs, which fail to account for cumulative uncertainty over the multi-step decision-making process and the dynamic interactions between agents and their environments. To address these limitations, we propose SAUP (Situation Awareness Uncertainty Propagation), a novel framework that propagates uncertainty through each step of an LLM-based agent's reasoning process. SAUP incorporates situational awareness by assigning situational weights to each step's uncertainty during the propagation. Our method, compatible with various one-step uncertainty estimation techniques, provides a comprehensive and accurate uncertainty measure. Extensive experiments on benchmark datasets demonstrate that SAUP significantly outperforms existing state-of-the-art methods, achieving up to 20% improvement in AUROC",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiwei Zhao",
      "Dong Li",
      "Yanchi Liu",
      "Wei Cheng",
      "Yiyou Sun",
      "Mika Oishi",
      "Takao Osaki",
      "Katsushi Matsuda",
      "Huaxiu Yao",
      "Chen Zhao",
      "Haifeng Chen",
      "Xujiang Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.303": {
    "title": "Beyond Position: the emergence of wavelet-like properties in Transformers",
    "volume": "long",
    "abstract": "This paper studies how Transformer models with Rotary Position Embeddings (RoPE) develop emergent, wavelet-like properties that compensate for the positional encoding's theoretical limitations. Through an analysis spanning model scales, architectures, and training checkpoints, we show that attention heads evolve to implement multi-resolution processing analogous to wavelet transforms. We demonstrate that this scale-invariant behavior is unique to RoPE, emerges through distinct evolutionary phases during training, and statistically adheres to the fundamental uncertainty principle. Our findings suggest that the effectiveness of modern Transformers stems from their remarkable ability to spontaneously develop optimal, multi-resolution decompositions to address inherent architectural constraints",
    "checked": true,
    "id": "d284a14bcb86fcf5a445661da915b0ecb4f9a4c3",
    "semantic_title": "beyond position: the emergence of wavelet-like properties in transformers",
    "citation_count": 0,
    "authors": [
      "Valeria Ruscio",
      "Umberto Nanni",
      "Fabrizio Silvestri"
    ]
  },
  "https://aclanthology.org/2025.acl-long.304": {
    "title": "Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs",
    "volume": "long",
    "abstract": "Factual hallucinations are a major challenge for Large Language Models (LLMs). They undermine reliability and user trust by generating inaccurate or fabricated content. Recent studies suggest that when generating false statements, the internal states of LLMs encode information about truthfulness. However, these studies often rely on synthetic datasets that lack realism, which limits generalization when evaluating the factual accuracy of text generated by the model itself. In this paper, we challenge the findings of previous work by investigating truthfulness encoding capabilities, leading to the generation of a more realistic and challenging dataset. Specifically, we extend previous work by introducing: (1) a strategy for sampling plausible true-false factoid sentences from tabular data and (2) a procedure for generating realistic, LLM-dependent true-false datasets from Question Answering collections. Our analysis of two open-source LLMs reveals that while the findings from previous studies are partially validated, generalization to LLM-generated datasets remains challenging. This study lays the groundwork for future research on factuality in LLMs and offers practical guidelines for more effective evaluation",
    "checked": true,
    "id": "8a3e10ab926b0aa1c934f3b82d3904d716d58734",
    "semantic_title": "are the hidden states hiding something? testing the limits of factuality-encoding capabilities in llms",
    "citation_count": 0,
    "authors": [
      "Giovanni Servedio",
      "Alessandro De Bellis",
      "Dario Di Palma",
      "Vito Walter Anelli",
      "Tommaso Di Noia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.305": {
    "title": "Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning",
    "volume": "long",
    "abstract": "The rapid development of Large Language Models (LLMs) has led to their widespread adoption across various domains, leveraging vast pre-training knowledge and impressive generalization capabilities. However, these models often inherit biased knowledge, resulting in unfair decisions in sensitive applications. It is challenging to remove this biased knowledge without compromising reasoning abilities due to the entangled nature of the learned knowledge within LLMs. To solve this problem, existing approaches have attempted to mitigate the bias using techniques such as fine-tuning with unbiased datasets, model merging, and gradient ascent. While these methods have experimentally proven effective, they can still be sub-optimum in fully disentangling biases from reasoning. To address this gap, we propose Selective Disentanglement Unlearning (SDU), a novel unlearning framework that selectively removes biased knowledge while preserving reasoning capabilities. SDU operates in three stages: identifying biased parameters using a shadow LLM, fine-tuning with unbiased data, and performing selective parameter updates based on weight saliency. Experimental results across multiple LLMs show that SDU improves fairness accuracy by 14.7% and enhances reasoning performance by 62.6% compared to existing baselines",
    "checked": false,
    "id": "51c184bc40aa1960958a5950d3a9e2f5f1dc751a",
    "semantic_title": "llamp: large language model made powerful for high-fidelity materials knowledge retrieval and distillation",
    "citation_count": 12,
    "authors": [
      "Zheyuan Liu",
      "Suraj Maharjan",
      "Fanyou Wu",
      "Rahil Parikh",
      "Belhassen Bayar",
      "Srinivasan H. Sengamedu",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.306": {
    "title": "LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have rapidly become central to NLP, demonstrating their ability to adapt to various tasks through prompting techniques, including sentiment analysis. However, we still have a limited understanding of how these models capture sentiment-related information. This study probes the hidden layers of LLaMA models to pinpoint where sentiment features are most represented and to assess how this affects sentiment analysis.Using probe classifiers, we analyze sentiment encoding across layers and scales, identifying the layers and pooling methods that best capture sentiment signals. Our results show that sentiment information is most concentrated in mid-layers for binary polarity tasks, with detection accuracy increasing up to 14% over prompting techniques. Additionally, we find that in decoder-only models, the last token is not consistently the most informative for sentiment encoding. Finally, this approach enables sentiment tasks to be performed with memory requirements reduced by an average of 57%.These insights contribute to a broader understanding of sentiment in LLMs, suggesting layer-specific probing as an effective approach for sentiment tasks beyond prompting, with potential to enhance model utility and reduce memory requirements",
    "checked": true,
    "id": "90e10000931914fee2ea8aed057f0ba7760338e9",
    "semantic_title": "llamas have feelings too: unveiling sentiment and emotion representations in llama models through probing",
    "citation_count": 0,
    "authors": [
      "Dario Di Palma",
      "Alessandro De Bellis",
      "Giovanni Servedio",
      "Vito Walter Anelli",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.307": {
    "title": "CxGGEC: Construction-Guided Grammatical Error Correction",
    "volume": "long",
    "abstract": "The grammatical error correction (GEC) task aims to detect and correct grammatical errors in text to enhance its accuracy and readability. Current GEC methods primarily rely on grammatical labels for syntactic information, often overlooking the inherent usage patterns of language. In this work, we explore the potential of construction grammar (CxG) to improve GEC by leveraging constructions to capture underlying language patterns and guide corrections. We first establish a comprehensive construction inventory from corpora. Next, we introduce a construction prediction model that identifies potential constructions in ungrammatical sentences using a noise-tolerant language model. Finally, we train a CxGGEC model on construction-masked parallel data, which performs GEC by decoding construction tokens into their original forms and correcting erroneous tokens. Extensive experiments on English and Chinese GEC benchmarks demonstrate the effectiveness of our approach",
    "checked": false,
    "id": "209e85c1251f5ac9b01c75525b68d12e44259d41",
    "semantic_title": "a simple yet effective corpus construction framework for indonesian grammatical error correction",
    "citation_count": 1,
    "authors": [
      "Yayu Cao",
      "Tianxiang Wang",
      "Lvxiaowei Xu",
      "Zhenyao Wang",
      "Ming Cai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.308": {
    "title": "Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation",
    "volume": "long",
    "abstract": "The advent of large language models has significantly advanced automatic code generation, transforming the way programmers writing code. Inspired by natural language processing, mainstream code generation approaches represent code as a linear sequence of tokens. In this paper, we propose to represent code snippets as two-dimensional entities, where both code lines and tokens within lines are explicitly modeled. This representation allows us to capture the hierarchical and spatial structure of code, especially the dependencies between code lines. Our method CoDE introduces a dependency encoding approach that leverages dictionary learning to perform semantic matching between code lines. As such, it avoids the reliance on strict position indices, leading to better generalization to code with diverse context and lengths. We thoroughly evaluate CoDE based on four categories of tasks. The experimental results showcase its generalizability, context understanding and retrieval, as well as interpretability in code generation",
    "checked": true,
    "id": "b4d9836c6e8a26693d5519e6ea144b03856a82dd",
    "semantic_title": "beyond sequences: two-dimensional representation and dependency encoding for code generation",
    "citation_count": 0,
    "authors": [
      "Xiangyu Zhang",
      "Yu Zhou",
      "Guang Yang",
      "Wei Cheng",
      "Taolue Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.309": {
    "title": "HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs",
    "volume": "long",
    "abstract": "In recent years, large language models (LLMs) have made remarkable advancements, yet hallucination, where models produce inaccurate or non-factual statements, remains a significant challenge for real-world deployment. Although current classification-based methods, such as SAPLMA, are highly efficient in mitigating hallucinations, they struggle when non-factual information arises in the early or mid-sequence of outputs, reducing their reliability. To address these issues, we propose Hallucination Detection-Neural Differential Equations (HD-NDEs), a novel method that systematically assesses the truthfulness of statements by capturing the full dynamics of LLMs within their latent space. Our approaches apply neural differential equations (Neural DEs) to model the dynamic system in the latent space of LLMs. Then, the sequence in the latent space is mapped to the classification space for truth assessment. The extensive experiments across five datasets and six widely used LLMs demonstrate the effectiveness of HD-NDEs, especially, achieving over 14% improvement in AUC-ROC on the True-False dataset compared to state-of-the-art techniques",
    "checked": true,
    "id": "8d727bd7f4a739c1c83efcb8b8f05e714e060332",
    "semantic_title": "hd-ndes: neural differential equations for hallucination detection in llms",
    "citation_count": 0,
    "authors": [
      "Qing Li",
      "Jiahui Geng",
      "Zongxiong Chen",
      "Derui Zhu",
      "Yuxia Wang",
      "Congbo Ma",
      "Chenyang Lyu",
      "Fakhri Karray"
    ]
  },
  "https://aclanthology.org/2025.acl-long.310": {
    "title": "What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations",
    "volume": "long",
    "abstract": "Transforming recorded videos into concise and accurate textual summaries is a growing challenge in multimodal learning. This paper introduces VISTA, a dataset specifically designed for video-to-text summarization in scientific domains. VISTA contains 18,599 recorded AI conference presentations paired with their corresponding paper abstracts. We benchmark the performance of state-of-the-art large models and apply a plan-based framework to better capture the structured nature of abstracts. Both human and automated evaluations confirm that explicit planning enhances summary quality and factual consistency. However, a considerable gap remains between models and human performance, highlighting the challenges of our dataset. This study aims to pave the way for future research on scientific video-to-text summarization",
    "checked": true,
    "id": "49fcb11ca570ed1aeec6b136d5c2eef001730a01",
    "semantic_title": "what is that talk about? a video-to-text summarization dataset for scientific presentations",
    "citation_count": 3,
    "authors": [
      "Dongqi Liu",
      "Chenxi Whitehouse",
      "Xi Yu",
      "Louis Mahon",
      "Rohit Saxena",
      "Zheng Zhao",
      "Yifu Qiu",
      "Mirella Lapata",
      "Vera Demberg"
    ]
  },
  "https://aclanthology.org/2025.acl-long.311": {
    "title": "NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering",
    "volume": "long",
    "abstract": "The increasing number of academic papers poses significant challenges for researchers to efficiently acquire key details. While retrieval augmented generation (RAG) shows great promise in large language model (LLM) based automated question answering, previous works often isolate neural and symbolic retrieval despite their complementary strengths. Moreover, conventional single-view chunking neglects the rich structure and layout of PDFs, e.g., sections and tables. In this work, we propose NeuSym-RAG, a hybrid neural symbolic retrieval framework which combines both paradigms in an interactive process. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG organizes semi-structured PDF content into both the relational database and vectorstore, enabling LLM agents to iteratively gather context until sufficient to generate answers. Experiments on three full PDF-based QA datasets, including a self-annotated one AirQA-Real, show that NeuSym-RAG stably defeats both the vector-based RAG and various structured baselines, highlighting its capacity to unify both retrieval schemes and utilize multiple views",
    "checked": true,
    "id": "ed3ecfef640c5a570e859c35ac947e00c98cdeea",
    "semantic_title": "neusym-rag: hybrid neural symbolic retrieval with multiview structuring for pdf question answering",
    "citation_count": 0,
    "authors": [
      "Ruisheng Cao",
      "Hanchong Zhang",
      "Tiancheng Huang",
      "Zhangyi Kang",
      "Yuxin Zhang",
      "Liangtai Sun",
      "Hanqi Li",
      "Yuxun Miao",
      "Shuai Fan",
      "Lu Chen",
      "Kai Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.312": {
    "title": "ProvBench: A Benchmark of Legal Provision Recommendation for Contract Auto-Reviewing",
    "volume": "long",
    "abstract": "Contract review is a critical process to protect the rights and interests of the parties involved. However, this process is time-consuming, labor-intensive, and costly, especially when a contract faces multiple rounds of review. To accelerate the contract review and promote the completion of transactions, this paper introduces a novel benchmark of legal provision recommendation and conflict detection for contract auto-reviewing (ProvBench), which aims to recommend the legal provisions related to contract clauses and detect possible legal conflicts. Specifically, we construct the first Legal Provision Recommendation Dataset: ProvData, which covers 8 common contract types. In addition, we conduct extensive experiments to evaluate ProvBench on various state-of-the-art models. Experimental results validate the feasibility of ProvBench and demonstrate the effectiveness of ProvData. Finally, we identify potential challenges in the ProvBench and advocate for further investigation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiuxuan Shen",
      "Zhongyuan Jiang",
      "Junsan Zhang",
      "Junxiao Han",
      "Yao Wan",
      "Chengjie Guo",
      "Bingcheng Liu",
      "Jie Wu",
      "Renxiang Li",
      "Philip S. Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.313": {
    "title": "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching",
    "volume": "long",
    "abstract": "This paper introduces F5-TTS, a fully non-autoregressive text-to-speech system based on flow matching with Diffusion Transformer (DiT). Without requiring complex designs such as duration model, text encoder, and phoneme alignment, the text input is simply padded with filler tokens to the same length as input speech, and then the denoising is performed for speech generation, which was originally proved feasible by E2 TTS. However, the original design of E2 TTS makes it hard to follow due to its slow convergence and low robustness. To address these issues, we first model the input with ConvNeXt to refine the text representation, making it easy to align with the speech. We further propose an inference-time Sway Sampling strategy, which significantly improves our model's performance and efficiency. This sampling strategy for flow step can be easily applied to existing flow matching based models without retraining. Our design allows faster training and achieves an inference RTF of 0.15, which is greatly improved compared to state-of-the-art diffusion-based TTS models. Trained on a public 100K hours multilingual dataset, our F5-TTS exhibits highly natural and expressive zero-shot ability, seamless code-switching capability, and speed control efficiency. We have released all codes and checkpoints to promote community development, at https://SWivid.github.io/F5-TTS/",
    "checked": true,
    "id": "1434e344cb826e53a45bfed96a9d62f80fb4fcb2",
    "semantic_title": "f5-tts: a fairytaler that fakes fluent and faithful speech with flow matching",
    "citation_count": 92,
    "authors": [
      "Yushen Chen",
      "Zhikang Niu",
      "Ziyang Ma",
      "Keqi Deng",
      "Chunhui Wang",
      "JianZhao JianZhao",
      "Kai Yu",
      "Xie Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.314": {
    "title": "AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation",
    "volume": "long",
    "abstract": "With the proliferation of large language models (LLMs) in the medical domain, there is increasing demand for improved evaluation techniques to assess their capabilities. However, traditional metrics like F1 and ROUGE, which rely on token overlaps to measure quality, significantly overlook the importance of medical terminology. While human evaluation tends to be more reliable, it can be very costly and may as well suffer from inaccuracies due to limits in human expertise and motivation. Although there are some evaluation methods based on LLMs, their usability in the medical field is limited due to their proprietary nature or lack of expertise. To tackle these challenges, we present AutoMedEval, an open-sourced automatic evaluation model with 13B parameters specifically engineered to measure the question-answering proficiency of medical LLMs. The overarching objective of AutoMedEval is to assess the quality of responses produced by diverse models, aspiring to significantly reduce the dependence on human evaluation. Specifically, we propose a hierarchical training method involving curriculum instruction tuning and an iterative knowledge introspection mechanism, enabling AutoMedEval to acquire professional medical assessment capabilities with limited instructional data. Human evaluations indicate that AutoMedEval surpasses other baselines in terms of correlation with human judgments",
    "checked": true,
    "id": "dd9cb2ff121325bb6158df49b5df8243c815df67",
    "semantic_title": "automedeval: harnessing language models for automatic medical capability evaluation",
    "citation_count": 0,
    "authors": [
      "Xiechi Zhang",
      "Zetian Ouyang",
      "Linlin Wang",
      "Gerard De Melo",
      "Zhu Cao",
      "Xiaoling Wang",
      "Ya Zhang",
      "Yanfeng Wang",
      "Liang He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.315": {
    "title": "CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis",
    "volume": "long",
    "abstract": "Current inference scaling methods, such as Self-consistency and Best-of-N, have proven effective in improving the accuracy of LLMs on complex reasoning tasks. However, these methods rely heavily on the quality of candidate responses and are unable to produce correct answers when all candidates are incorrect. In this paper, we propose a novel inference scaling strategy, CoT-based Synthesizer, which leverages CoT reasoning to synthesize superior answers by analyzing complementary information from multiple candidate responses, even when all candidates are flawed. To support a lightweight and cost-effective implementation, we introduce an automated data generation pipeline that creates diverse training data. This enables smaller LLMs trained on this data to improve the inference accuracy of larger models, including API-based LLMs. Experimental results across four benchmark datasets with seven policy models demonstrate that our method significantly enhances performance, with gains of 11.8% for Llama3-8B and 10.3% for GPT-4o on the MATH dataset. The corresponding training data and code are publicly available on the [repository](https://github.com/RUCKBReasoning/CoT-based-Synthesizer)",
    "checked": true,
    "id": "f3eee8fa080bfbcaa6ff233664a49e81bbb459ea",
    "semantic_title": "cot-based synthesizer: enhancing llm performance through answer synthesis",
    "citation_count": 0,
    "authors": [
      "Bohan Zhang",
      "Xiaokang Zhang",
      "Jing Zhang",
      "Jifan Yu",
      "Sijia Luo",
      "Jie Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.316": {
    "title": "Efficiently Identifying Watermarked Segments in Mixed-Source Texts",
    "volume": "long",
    "abstract": "Text watermarks in large language models (LLMs) are increasingly used to detect synthetic text, mitigating misuse cases like fake news and academic dishonesty. While existing watermarking detection techniques primarily focus on classifying entire documents as watermarked or not, they often neglect the common scenario of identifying individual watermark segments within longer, mixed-source documents. Drawing inspiration from plagiarism detection systems, we propose two novel methods for partial watermark detection. First, we develop a geometry cover detection framework aimed at determining whether there is a watermark segment in long text. Second, we introduce an adaptive online learning algorithm to pinpoint the precise location of watermark segments within the text. Evaluated on three popular watermarking techniques (KGW-Watermark, Unigram-Watermark, and Gumbel-Watermark), our approach achieves high accuracy, significantly outperforming baseline methods. Moreover, our framework is adaptable to other watermarking techniques, offering new insights for precise watermark detection. Our code is publicly available at https://github.com/XuandongZhao/llm-watermark-location",
    "checked": true,
    "id": "83d30c14e31038241ab69d0b1b25d938830aac01",
    "semantic_title": "efficiently identifying watermarked segments in mixed-source texts",
    "citation_count": 1,
    "authors": [
      "Xuandong Zhao",
      "Chenwen Liao",
      "Yu-Xiang Wang",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.317": {
    "title": "Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks",
    "volume": "long",
    "abstract": "Language is not monolithic. While benchmarks, including those designed for multiple languages, are often used as proxies to evaluate the performance of Large Language Models (LLMs), they tend to overlook the nuances of within-language variation and thus fail to model the experience of speakers of non-standard dialects. Focusing on African American Vernacular English (AAVE), we present the first study aimed at objectively assessing the fairness and robustness of LLMs in handling dialects across canonical reasoning tasks, including algorithm, math, logic, and integrated reasoning. We introduce **ReDial** (**Re**asoning with **Dial**ect Queries), a benchmark containing 1.2K+ parallel query pairs in Standardized English and AAVE. We hire AAVE speakers, including experts with computer science backgrounds, to rewrite seven popular benchmarks,such as HumanEval and GSM8K. With ReDial, we evaluate widely used LLMs, including GPT, Claude, Llama, Mistral, and the Phi model families. Our findings reveal that almost all of these widely used models show significant brittleness and unfairness to queries in AAVE. Our work establishes a systematic and objective framework for analyzing LLM bias in dialectal queries. Moreover, it highlights how mainstream LLMs provide unfair service to dialect speakers in reasoning tasks, laying a critical foundation for future research",
    "checked": true,
    "id": "ed566fecf3e286c9b53bdabd42987a29b51e4b87",
    "semantic_title": "assessing dialect fairness and robustness of large language models in reasoning tasks",
    "citation_count": 3,
    "authors": [
      "Fangru Lin",
      "Shaoguang Mao",
      "Emanuele La Malfa",
      "Valentin Hofmann",
      "Adrian de Wynter",
      "Xun Wang",
      "Si-Qing Chen",
      "Michael J. Wooldridge",
      "Janet B. Pierrehumbert",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.318": {
    "title": "Towards a More Generalized Approach in Open Relation Extraction",
    "volume": "long",
    "abstract": "Open Relation Extraction (OpenRE) seeks to identify and extract novel relational facts between named entities from unlabeled data without pre-defined relation schemas. Traditional OpenRE methods typically assume that the unlabeled data consists solely of novel relations or is pre-divided into known and novel instances. However, in real-world scenarios, novel relations are arbitrarily distributed. In this paper, we propose a generalized OpenRE setting that considers unlabeled data as a mixture of both known and novel instances. To address this, we propose MixORE, a two-phase framework that integrates relation classification and clustering to jointly learn known and novel relations. Experiments on three benchmark datasets demonstrate that MixORE consistently outperforms competitive baselines in known relation classification and novel relation clustering. Our findings contribute to the advancement of generalized OpenRE research and real-world applications",
    "checked": true,
    "id": "dd0d921f1539d6c5bf7677942694bd2aa3513550",
    "semantic_title": "towards a more generalized approach in open relation extraction",
    "citation_count": 0,
    "authors": [
      "Qing Wang",
      "Yuepei Li",
      "Qiao Qiao",
      "Kang Zhou",
      "Qi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.319": {
    "title": "Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home",
    "volume": "long",
    "abstract": "Retrieval Augmented Generation (RAG) improves correctness of Question Answering (QA) and addresses hallucinations in Large Language Models (LLMs), yet greatly increase computational costs. Besides, RAG is not always needed as may introduce irrelevant information. Recent adaptive retrieval methods integrate LLMs' intrinsic knowledge with external information appealing to LLM self-knowledge, but they often neglect efficiency evaluations and comparisons with uncertainty estimation techniques. We bridge this gap by conducting a comprehensive analysis of 35 adaptive retrieval methods, including 8 recent approaches and 27 uncertainty estimation techniques, across 6 datasets using 10 metrics for QA performance, self-knowledge, and efficiency. Our findings show that uncertainty estimation techniques often outperform complex pipelines in terms of efficiency and self-knowledge, while maintaining comparable QA performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viktor Moskvoretskii",
      "Maria Marina",
      "Mikhail Salnikov",
      "Nikolay Ivanov",
      "Sergey Pletenev",
      "Daria Galimzianova",
      "Nikita Krayko",
      "Vasily Konovalov",
      "Irina Nikishina",
      "Alexander Panchenko"
    ]
  },
  "https://aclanthology.org/2025.acl-long.320": {
    "title": "Evaluating Language Models as Synthetic Data Generators",
    "volume": "long",
    "abstract": "Given the increasing use of synthetic data in language model (LM) post-training, an LM's ability to generate high-quality data has become nearly as crucial as its ability to solve problems directly. While prior works have focused on developing effective data generation methods, they lack systematic comparison of different LMs as data generators in a unified setting. To address this gap, we propose AgoraBench, a benchmark that provides standardized settings and metrics to evaluate LMs' data generation abilities. Through synthesizing 1.26 million training instances using 6 LMs and training 99 student models, we uncover key insights about LMs' data generation capabilities. First, we observe that LMs exhibit distinct strengths. For instance, GPT-4o excels at generating new problems, while Claude-3.5-Sonnet performs better at enhancing existing ones. Furthermore, our analysis reveals that an LM's data generation ability doesn't necessarily correlate with its problem-solving ability. Instead, multiple intrinsic features of data quality—including response quality, perplexity, and instruction difficulty—collectively serve as better indicators. Finally, we demonstrate that strategic choices in output format and cost-conscious model selection significantly impact data generation effectiveness. Our code, checkpoints, and data are all publicly available at https://github.com/neulab/data-agora",
    "checked": true,
    "id": "fed6959faeb29941565ed4f5f2c4a1a6330998e0",
    "semantic_title": "evaluating language models as synthetic data generators",
    "citation_count": 7,
    "authors": [
      "Seungone Kim",
      "Juyoung Suk",
      "Xiang Yue",
      "Vijay Viswanathan",
      "Seongyun Lee",
      "Yizhong Wang",
      "Kiril Gashteovski",
      "Carolin Lawrence",
      "Sean Welleck",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2025.acl-long.321": {
    "title": "Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?",
    "volume": "long",
    "abstract": "Large language models (LLMs) have achieved significant success in reasoning tasks, including mathematical reasoning and logical deduction. Among these reasoning tasks, graph problems stand out due to their complexity and unique structural characteristics, attracting considerable attention from researchers. Previous studies have explored LLMs' graph reasoning abilities through various techniques, such as different encoding methods for graph structures and the use of carefully designed prompts. However, a critical factor has been mostly overlooked: the prompt sequential order in which graph descriptions are presented to the models. In this study, we present the first comprehensive analysis of how the order of graph descriptions impacts LLM performance. Specifically, we comprehensively evaluate four graph description orders across six graph problems using six mainstream LLMs. The results reveal that: (1) ordered graph descriptions significantly improve LLMs' comprehension of graph structures; (2) the robustness of LLMs to graph description order varies across different tasks; and (3) the impact of graph order on performance is closely related to the inherent characteristics of tasks. This study provides a critical advancement in the application of LLMs for solving graph-related problems, paving the way for future research to optimize model performance through strategic graph description ordering",
    "checked": true,
    "id": "7a8009034720efbf079bbd8471e3d9975d17e6cc",
    "semantic_title": "can graph descriptive order affect solving graph problems with llms?",
    "citation_count": 3,
    "authors": [
      "Yuyao Ge",
      "Shenghua Liu",
      "Baolong Bi",
      "Yiwei Wang",
      "Lingrui Mei",
      "Wenjie Feng",
      "Lizhe Chen",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.322": {
    "title": "Learning to Rewrite: Generalized LLM-Generated Text Detection",
    "volume": "long",
    "abstract": "Detecting text generated by Large Language Models (LLMs) is crucial, yet current detectors often struggle to generalize in open-world settings. We introduce Learning2Rewrite, a novel framework to detect LLM-generated text with exceptional generalization to unseen domains. Capitalized on the finding that LLMs inherently modify LLM-generated content less than human-written text when rewriting, we train an LLM to amplify this disparity, yielding a more distinguishable and generalizable edit distance across diverse text distributions. Extensive experiments on data from 21 independent domains and four major LLMs (GPT-3.5, GPT-4, Gemini, and Llama-3) demonstrate that our detector outperforms state-of-the-art detection methods by up to 23.04% in AUROC for in-distribution tests, 35.10% for out-of-distribution tests, and 48.66% under adversarial attacks. Our unique training objective ensures better generalizability compared to directly training for classification, even when leveraging the same amount of tunable parameters. Our findings suggest that reinforcing LLMs' inherent rewriting tendencies offers a robust and scalable solution for detecting LLM-generated text",
    "checked": true,
    "id": "b8c0c24bc7a09c55d4b7cae12744b93ebc4b97a9",
    "semantic_title": "learning to rewrite: generalized llm-generated text detection",
    "citation_count": 4,
    "authors": [
      "Wei Hao",
      "Ran Li",
      "Weiliang Zhao",
      "Junfeng Yang",
      "Chengzhi Mao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.323": {
    "title": "Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search",
    "volume": "long",
    "abstract": "Video captioning can be used to assess the video understanding capabilities of Multimodal Large Language Models (MLLMs).However, existing benchmarks and evaluation protocols suffer from crucial issues, such as inadequate or homogeneous creation of key points, exorbitant cost of data creation, and limited evaluation scopes. To address these issues, we propose an automatic framework, named AutoCaption, which leverages Monte Carlo Tree Search (MCTS) to construct numerous and diverse descriptive sentences (i.e., key points) that thoroughly represent video content in an iterative way. This iterative captioning strategy enables the continuous enhancement of video details such as actions, objects' attributes, environment details, etc. We apply AutoCaption to curate MCTS-VCB, a fine-grained video caption benchmark covering video details, thereby enabling a comprehensive evaluation of MLLMs on the video captioning task. We evaluate more than 20 open- and closed-source MLLMs of varying sizes on MCTS-VCB. Results show that MCTS-VCB can effectively and comprehensively evaluate the video captioning capability, with Gemini-1.5-Pro achieving the highest F1 score of 71.2. Interestingly, we fine-tune InternVL2.5-8B with the AutoCaption-generated data, which helps the model achieve an overall improvement of 25.0% on MCTS-VCB and 16.3% on DREAM-1K, further demonstrating the effectiveness of AutoCaption. The code and data are available at https://github.com/tjunlp-lab/MCTS-VCB",
    "checked": true,
    "id": "b17c7aa2aac0cb03d60f85cbb582ba52384a15cc",
    "semantic_title": "evaluating multimodal large language models on video captioning via monte carlo tree search",
    "citation_count": 0,
    "authors": [
      "Linhao Yu",
      "Xingguang Ji",
      "Yahui Liu",
      "Fanheng Kong",
      "Chenxi Sun",
      "Jingyuan Zhang",
      "Hongzhi Zhang",
      "V. W.",
      "Fuzheng Zhang",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.324": {
    "title": "GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs",
    "volume": "long",
    "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and democratized the usage of Large Language Models (LLMs). Recent studies have shown that a small subset of weights significantly impacts performance. Based on this observation, we introduce a novel PEFT method, called Gaussian noise Injected Fine Tuning of Salient Weights (GIFT-SW). Our method updates only salient columns, while injecting Gaussian noise into non-salient ones. To identify these columns, we developed a generalized sensitivity metric that extends and unifies metrics from previous studies. Experiments with LLaMA models demonstrate that GIFT-SW outperforms full fine-tuning and modern PEFT methods under the same computational budget. Moreover, GIFT-SW offers practical advantages to recover performance of models subjected to mixed-precision quantization with keeping salient weights in full precision",
    "checked": true,
    "id": "d29e8cc00b8467380a46646858fa3c87b76881a1",
    "semantic_title": "gift-sw: gaussian noise injected fine-tuning of salient weights for llms",
    "citation_count": 3,
    "authors": [
      "Maxim Zhelnin",
      "Viktor Moskvoretskii",
      "Egor Shvetsov",
      "Maria Krylova",
      "Venediktov Egor",
      "Zuev Aleksandr",
      "Evgeny Burnaev"
    ]
  },
  "https://aclanthology.org/2025.acl-long.325": {
    "title": "Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis",
    "volume": "long",
    "abstract": "Large language models (LLMs) have made exciting achievements across various domains, yet their deployment on resource-constrained personal devices remains hindered by the prohibitive computational and memory demands of task-specific fine-tuning. While quantization offers a pathway to efficiency, existing methods struggle to balance performance and overhead, either incurring high computational/memory costs or failing to address activation outliers—a critical bottleneck in quantized fine-tuning. To address these challenges, we propose the Outlier Spatial Stability Hypothesis (__OSSH__): _During fine-tuning, certain activation outlier channels retain stable spatial positions across training iterations._ Building on OSSH, we propose __Quaff__, a Quantized parameter-efficient fine-tuning framework for LLMs, optimizing low-precision activation representations through targeted momentum scaling. Quaff dynamically suppresses outliers exclusively in invariant channels using lightweight operations, eliminating full-precision weight storage and global rescaling while reducing quantization errors. Extensive experiments across ten benchmarks validate OSSH and demonstrate Quaff's efficacy. Specifically, on the GPQA reasoning benchmark, Quaff achieves a 1.73× latency reduction and 30% memory savings over full-precision fine-tuning while improving accuracy by 0.6% on the Phi-3 model, reconciling the triple trade-off between efficiency, performance, and deployability. By enabling consumer-grade GPU fine-tuning (e.g., RTX 2080 Super) without sacrificing model utility, Quaff democratizes personalized LLM deployment. The code is available at https://anonymous.4open.science/r/Quaff-B322/",
    "checked": true,
    "id": "541f388d935199161e41f86b87a429e0f906b237",
    "semantic_title": "quaff: quantized parameter-efficient fine-tuning under outlier spatial stability hypothesis",
    "citation_count": 0,
    "authors": [
      "Hong Huang",
      "Dapeng Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.326": {
    "title": "Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models",
    "volume": "long",
    "abstract": "This paper introduces a novel task to evaluate the robust understanding capability of Large Multimodal Models (LMMs), termed Unsolvable Problem Detection (UPD). Multiple-choice question answering (MCQA) is widely used to assess the understanding capability of LMMs, but it does not guarantee that LMMs truly comprehend the answer. UPD assesses the LMM's ability to withhold answers when encountering unsolvable problems of MCQA, verifying whether the model truly understands the answer. UPD encompasses three problems: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD), covering unsolvable cases like answer-lacking or incompatible choices and image-question mismatches. For the evaluation, we introduce the MM-UPD Bench, a benchmark for assessing performance across various ability dimensions. Our experiments reveal that even most LMMs, which demonstrate adequate performance on existing benchmarks, struggle significantly with MM-UPD, underscoring a novel aspect of trustworthiness that current benchmarks have overlooked. A detailed analysis shows that LMMs have different bottlenecks and chain-of-thought and self-reflection improved performance for LMMs with the bottleneck in their LLM capability. We hope our insights will enhance the broader understanding and development of more reliable LMMs",
    "checked": true,
    "id": "91a4a1c023260a6c6ece2462758e44c980674900",
    "semantic_title": "unsolvable problem detection: robust understanding evaluation for large multimodal models",
    "citation_count": 2,
    "authors": [
      "Atsuyuki Miyai",
      "Jingkang Yang",
      "Jingyang Zhang",
      "Yifei Ming",
      "Qing Yu",
      "Go Irie",
      "Yixuan Li",
      "Hai Helen Li",
      "Ziwei Liu",
      "Kiyoharu Aizawa"
    ]
  },
  "https://aclanthology.org/2025.acl-long.327": {
    "title": "AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models",
    "volume": "long",
    "abstract": "Evaluating the alignment capabilities of large Vision-Language Models (VLMs) is essential for determining their effectiveness as helpful assistants. However, existing benchmarks primarily focus on basic abilities using nonverbal methods, such as yes-no and multiple-choice questions. In this paper, we address this gap by introducing AlignMMBench, which provides more nuanced evaluations of alignment capabilities and is the first benchmark specifically designed for Chinese visual contexts. This benchmark is meticulously curated from real-world scenarios and internet sources, encompassing thirteen specific tasks across three categories, and includes both single-turn and multi-turn dialogue scenarios. Incorporating a prompt rewrite strategy, AlignMMBench encompasses 1,054 images and 4,978 question-answer pairs. To facilitate the evaluation pipeline, we develop CritiqueVLM, a rule-calibrated evaluator that exceeds GPT-4's evaluation ability. Additionally, we measure the \"alignment score\", a quantitative metric designed to assess the robustness and stability of models across diverse prompts. Finally, we evaluate the performance of representative VLMs on AlignMMBench, offering insights into the capabilities and limitations of different VLM architectures. The evaluation code and data are available at https://github.com/THUDM/AlignMMBench",
    "checked": true,
    "id": "000d1d7fcc043c34a99afff72c06328034594bc7",
    "semantic_title": "alignmmbench: evaluating chinese multimodal alignment in large vision-language models",
    "citation_count": 2,
    "authors": [
      "Yuhang Wu",
      "Wenmeng Yu",
      "Yean Cheng",
      "Yan Wang",
      "Xiaohan Zhang",
      "Jiazheng Xu",
      "Ming Ding",
      "Yuxiao Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.328": {
    "title": "Biased LLMs can Influence Political Decision-Making",
    "volume": "long",
    "abstract": "As modern large language models (LLMs) become integral to everyday tasks, concerns about their inherent biases and their potential impact on human decision-making have emerged. While bias in models are well-documented, less is known about how these biases influence human decisions. This paper presents two interactive experiments investigating the effects of partisan bias in LLMs on political opinions and decision-making. Participants interacted freely with either a biased liberal, biased conservative, or unbiased control model while completing these tasks. We found that participants exposed to partisan biased models were significantly more likely to adopt opinions and make decisions which matched the LLM's bias. Even more surprising, this influence was seen when the model bias and personal political partisanship of the participant were opposite. However, we also discovered that prior knowledge of AI was weakly correlated with a reduction of the impact of the bias, highlighting the possible importance of AI education for robust mitigation of bias effects. Our findings not only highlight the critical effects of interacting with biased LLMs and its ability to impact public discourse and political conduct, but also highlights potential techniques for mitigating these risks in the future",
    "checked": false,
    "id": "999ba61c3adcc094f0bdb64601eb0830fb8fc579",
    "semantic_title": "biased ai can influence political decision-making",
    "citation_count": 4,
    "authors": [
      "Jillian Fisher",
      "Shangbin Feng",
      "Robert Aron",
      "Thomas Richardson",
      "Yejin Choi",
      "Daniel W Fisher",
      "Jennifer Pan",
      "Yulia Tsvetkov",
      "Katharina Reinecke"
    ]
  },
  "https://aclanthology.org/2025.acl-long.329": {
    "title": "LexTempus: Enhancing Temporal Generalizability of Legal Language Models Through Dynamic Mixture of Experts",
    "volume": "long",
    "abstract": "The rapid evolution of legal concepts over time necessitates that legal language models adapt swiftly accounting for the temporal dynamics. However, prior works have largely neglected this crucial dimension, treating legal adaptation as a static problem rather than a continuous process. To address this gap, we pioneer LexTempus, a dynamic mixture of experts model that explicitly models the temporal evolution of legal language in a parameter-efficient online learning framework. LexTempus starts with a single lightweight adapter expert and dynamically expands by adding new experts as significant deviations in the data distribution are detected. This self-expansion strategy allows LexTempus to adapt to new information without forgetting past knowledge, thereby improving temporal generalization. We use a a non-parametric similarity-based router to merge relevant experts into a unified expert for each test instance, ensuring efficient inference without additional overhead. We validate the effectiveness of LexTempus on ECHR and EU case law datasets, demonstrating its superiority in both perplexity and open-ended text generation quality metrics",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Santosh T.y.s.s",
      "Tuan-Quang Vuong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.330": {
    "title": "That is Unacceptable: the Moral Foundations of Canceling",
    "volume": "long",
    "abstract": "Canceling is a morally-driven phenomenon that hinders the development of safe social media platforms and contributes to ideological polarization. To address this issue we present the Canceling Attitudes Detection (CADE) dataset, an annotated corpus of canceling incidents aimed at exploring the factors of disagreements in evaluating people's canceling attitudes on social media. Specifically, we study the impact of annotators' morality in their perception of canceling, showing that morality is an independent axis for the explanation of disagreement on this phenomenon. Annotator's judgments heavily depend on the type of controversial events and involved celebrities. This shows the need to develop more event-centric datasets to better understand how harms are perpetrated in social media and to develop more aware technologies for their detection",
    "checked": true,
    "id": "6495e24ff870f105c86e312a987c19528b140b7c",
    "semantic_title": "that is unacceptable: the moral foundations of canceling",
    "citation_count": 0,
    "authors": [
      "Soda Marem Lo",
      "Oscar Araque",
      "Rajesh Sharma",
      "Marco Antonio Stranisci"
    ]
  },
  "https://aclanthology.org/2025.acl-long.331": {
    "title": "FloorPlan-LLaMa: Aligning Architects' Feedback and Domain Knowledge in Architectural Floor Plan Generation",
    "volume": "long",
    "abstract": "Floor plans serve as a graphical language through which architects sketch and communicate their design ideas. Actually, in the Architecture, Engineering, and Construction (AEC) design stages, generating floor plans is a complex task requiring domain expertise and alignment with user requirements. However, existing evaluation methods for floor plan generation rely mainly on statistical metrics like FID, GED, and PSNR, which often fail to evaluate using domain knowledge. As a result, even high-performing models on these metrics struggle to generate viable floor plans in practice. To address this, (1) we propose ArchiMetricsNet, the first floor plan dataset that includes functionality, flow, and overall evaluation scores, along with detailed textual analyses. We trained FloorPlan-MPS (Multi-dimensional Preference Score) on it. (2) We develope FloorPlan-LLaMa, a floor plan generation model based on autoregressive framework. To integrate architects' professional expertise and preferences, FloorPlan-MPS serves as the reward model during the RLHF (Reinforcement Learning from Human Feedback) process, aligning FP-LLaMa with the needs of the architectural community. (3) Comparative experiments demonstrate that our method outperforms baseline models in both text-conditional and class-conditional tasks. Validation by professional architects confirms that our approach yields more rational plans and aligns better with human preferences",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yin",
      "Pengyu Zeng",
      "Haoyuan Sun",
      "Yuqin Dai",
      "Han Zheng",
      "Miao Zhang",
      "Yachao Zhang",
      "Shuai Lu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.332": {
    "title": "TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding",
    "volume": "long",
    "abstract": "Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge. In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations. To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics. Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77. However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout. Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Max Ku",
      "Cheuk Hei Chong",
      "Jonathan Leung",
      "Krish Shah",
      "Alvin Yu",
      "Wenhu Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.333": {
    "title": "FineReason: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving",
    "volume": "long",
    "abstract": "Many challenging reasoning tasks require not just rapid, intuitive responses, but a more deliberate, multi-step approach. Recent progress in large language models (LLMs) highlights an important shift from the \"System 1\" way of quick reactions to the \"System 2\" style of reflection-and-correction problem solving. However, current benchmarks heavily rely on the final-answer accuracy, leaving much of a model's intermediate reasoning steps unexamined. This fails to assess the model's ability to reflect and rectify mistakes within the reasoning process. To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark for systematic evaluation of LLMs' reasoning capabilities. Each puzzle can be decomposed into atomic steps, making it ideal for rigorous validation of intermediate correctness. Building on this, we introduce two tasks: state checking and state transition, for a comprehensive evaluation of how models assess the current situation and plan the next move. To support broader research, we also provide a puzzle training set aimed at enhancing general reasoning. We show that models trained on our state checking and transition data demonstrate gains in mathematical reasoning by up to 5.1%",
    "checked": true,
    "id": "e8c5b9a2c800f232a91a84badd6530d955a669f1",
    "semantic_title": "finereason: evaluating and improving llms' deliberate reasoning through reflective puzzle solving",
    "citation_count": 4,
    "authors": [
      "Guizhen Chen",
      "Weiwen Xu",
      "Hao Zhang",
      "Hou Pong Chan",
      "Chaoqun Liu",
      "Lidong Bing",
      "Deli Zhao",
      "Anh Tuan Luu",
      "Yu Rong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.334": {
    "title": "The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs",
    "volume": "long",
    "abstract": "We present a novel class of jailbreak adversarial attacks on LLMs, termed Task-in-Prompt (TIP) attacks. Our approach embeds sequence-to-sequence tasks (e.g., cipher decoding, riddles, code execution) into the model's prompt to indirectly generate prohibited inputs. To systematically assess the effectiveness of these attacks, we introduce the PHRYGE benchmark. We demonstrate that our techniques successfully circumvent safeguards in six state-of-the-art language models, including GPT-4o and LLaMA 3.2. Our findings highlight critical weaknesses in current LLM safety alignment and underscore the urgent need for more sophisticated defence strategies",
    "checked": true,
    "id": "236839d7daf363d664930d10c459495aaeb1181b",
    "semantic_title": "the tip of the iceberg: revealing a hidden class of task-in-prompt adversarial attacks on llms",
    "citation_count": 1,
    "authors": [
      "Sergey Berezin",
      "Reza Farahbakhsh",
      "Noel Crespi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.335": {
    "title": "Identifying Reliable Evaluation Metrics for Scientific Text Revision",
    "volume": "long",
    "abstract": "Evaluating text revision in scientific writing remains a challenge, as traditional metrics such as ROUGE and BERTScore primarily focus on similarity rather than capturing meaningful improvements. In this work, we analyse and identify the limitations of these metrics and explore alternative evaluation methods that better align with human judgments. We first conduct a manual annotation study to assess the quality of different revisions. Then, we investigate reference-free evaluation metrics from related NLP domains. Additionally, we examine LLM-as-a-judge approaches, analysing their ability to assess revisions with and without a gold reference. Our results show that LLMs effectively assess instruction-following but struggle with correctness, while domain-specific metrics provide complementary insights. We find that a hybrid approach combining LLM-as-a-judge evaluation and task-specific metrics offers the most reliable assessment of revision",
    "checked": true,
    "id": "519c81081dc60156d024ddf3ac46c35eb1158799",
    "semantic_title": "identifying reliable evaluation metrics for scientific text revision",
    "citation_count": 0,
    "authors": [
      "Leane Jourdan",
      "Nicolas Hernandez",
      "Florian Boudin",
      "Richard Dufour"
    ]
  },
  "https://aclanthology.org/2025.acl-long.336": {
    "title": "Can Language Models Reason about Individualistic Human Values and Preferences?",
    "volume": "long",
    "abstract": "Recent calls for pluralistic alignment emphasize that AI systems should address the diverse needs of all people. Yet, efforts in this space often require sorting people into fixed buckets of pre-specified diversity-defining dimensions (e.g., demographics), risking smoothing out individualistic variations or even stereotyping. To achieve an authentic representation of diversity that respects individuality, we propose individualistic alignment. While individualistic alignment can take various forms, in this paper, we introduce IndieValueCatalog, a dataset transformed from the influential World Values Survey (WVS), to study language models (LMs) on the specific challenge of individualistic value reasoning. Given a sample of an individual's value-expressing statements, models are tasked with predicting their value judgments in novel cases. With IndieValueCatalog, we reveal critical limitations in frontier LMs' abilities to predict individualistic values with accuracies only ranging between 55% to 65%. Moreover, our results highlight that a precise description of individualistic values cannot be approximated only via demographic information. Finally, we train a series of IndieValueReasoners to reveal new patterns and dynamics into global human values",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liwei Jiang",
      "Taylor Sorensen",
      "Sydney Levine",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.337": {
    "title": "BERT-like Models for Slavic Morpheme Segmentation",
    "volume": "long",
    "abstract": "Automatic morpheme segmentation algorithms are applicable in various tasks, such as building tokenizers and language education. For Slavic languages, the development of such algorithms is complicated by the rich derivational capabilities of these languages. Previous research has shown that, on average, these algorithms have already reached expert-level quality. However, a key unresolved issue is the significant decline in performance when segmenting words containing roots not present in the training data. This problem can be partially addressed by using pre-trained language models to better account for word semantics. In this work, we explored the possibility of fine-tuning BERT-like models for morpheme segmentation using data from Belarusian, Czech, and Russian. We found that for Czech and Russian, our models outperform all previously proposed approaches, achieving word-level accuracy of 92.5-95.1%. For Belarusian, this task was addressed for the first time. The best-performing approach for Belarusian was an ensemble of convolutional neural networks with word-level accuracy of 90.45%",
    "checked": false,
    "id": "26c90fd79aa696425bde718f3f60d822afc3beae",
    "semantic_title": "subword segmentation in llms: looking at inflection and consistency",
    "citation_count": 0,
    "authors": [
      "Dmitry Morozov",
      "Lizaveta Astapenka",
      "Anna Glazkova",
      "Timur Garipov",
      "Olga Lyashevskaya"
    ]
  },
  "https://aclanthology.org/2025.acl-long.338": {
    "title": "Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling",
    "volume": "long",
    "abstract": "The rapid growth in the parameters of LLMs has made inference latency a fundamental bottleneck. Speculative decoding represents a lossless approach to accelerate inference through a guess-and-verify paradigm. Some methods rely on additional architectures to guess draft tokens, which need extra training before use. Alternatively, retrieval-based train-free techniques build libraries from pre-existing corpora or by n-gram generation. However, they face challenges like large storage requirements, time-consuming retrieval, and limited adaptability. Observing that candidate tokens generated during the decoding process are likely to reoccur in future sequences, we propose Token Recycling. This approach stores candidate tokens in an adjacency matrix and employs a breadth-first-search (BFS)-like algorithm to construct a draft tree, which is then validated through tree attention. New candidate tokens from the decoding process are then used to update the matrix. Token Recycling requires <2MB of additional storage and achieves approximately 2x speedup across all sizes of LLMs. It significantly outperforms existing train-free methods by 30% and even a training method by 25%",
    "checked": true,
    "id": "348717b6a112b2b5ab8f994f27d2b553b0a065d4",
    "semantic_title": "turning trash into treasure: accelerating inference of large language models with token recycling",
    "citation_count": 9,
    "authors": [
      "Xianzhen Luo",
      "Yixuan Wang",
      "Qingfu Zhu",
      "Zhiming Zhang",
      "Xuanyu Zhang",
      "Qing Yang",
      "Dongliang Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.339": {
    "title": "Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering",
    "volume": "long",
    "abstract": "Recent advancements in long chain-of-thoughts (long CoTs) have significantly improved the reasoning capabilities of large language models (LLMs). Existing work finds that the capability of long CoT reasoning can be efficiently elicited by tuning on only a few examples and can easily transfer to other tasks. This motivates us to investigate whether long CoT reasoning is a general capability for LLMs. In this work, we conduct an empirical analysis for this question from the perspective of representation. We find that LLMs do encode long CoT reasoning as a general capability, with a clear distinction from vanilla CoTs. Furthermore, domain-specific representations are also required for the effective transfer of long CoT reasoning. Inspired by these findings, we propose GLORE, a novel representation engineering method to unleash the general long CoT reasoning capabilities of LLMs. Extensive experiments demonstrate the effectiveness and efficiency of GLORE in both in-domain and cross-domain scenarios. The code is available at https://github.com/txy77/GLoRE",
    "checked": true,
    "id": "c19ac62fd7fdf2a4ba6581563212c3b33737b030",
    "semantic_title": "unlocking general long chain-of-thought reasoning capabilities of large language models via representation engineering",
    "citation_count": 9,
    "authors": [
      "Xinyu Tang",
      "Xiaolei Wang",
      "Zhihao Lv",
      "Yingqian Min",
      "Xin Zhao",
      "Binbin Hu",
      "Ziqi Liu",
      "Zhiqiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.340": {
    "title": "Drift: Enhancing LLM Faithfulness in Rationale Generation via Dual-Reward Probabilistic Inference",
    "volume": "long",
    "abstract": "As Large Language Models (LLMs) are increasingly applied to complex reasoning tasks, achieving both accurate task performance and faithful explanations becomes crucial. However, LLMs often generate unfaithful explanations, partly because they do not consistently adhere closely to the provided context. Existing approaches to this problem either rely on superficial calibration methods, such as decomposed Chain-of-Thought prompting, or require costly retraining to improve model faithfulness. In this work, we propose a probabilistic inference paradigm that leverages task-specific and lookahead rewards to ensure that LLM-generated rationales are more faithful to model decisions and align better with input context. These rewards are derived from a domain-specific proposal distribution, allowing for optimized sequential Monte Carlo approximations. Our evaluations across three different reasoning tasks show that this method, which allows for controllable generation during inference, improves both accuracy and faithfulness of LLMs. This method offers a promising path towards making LLMs more reliable for reasoning tasks without sacrificing performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiazheng Li",
      "Hanqi Yan",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.341": {
    "title": "Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs",
    "volume": "long",
    "abstract": "Algorithmic fairness has conventionally adopted the mathematically convenient perspective of racial color-blindness (i.e., difference unaware treatment). However, we contend that in a range of important settings, group difference awareness matters. For example, differentiating between groups may be necessary in legal contexts (e.g., the U.S. compulsory draft applies to men but not women) and harm assessments (e.g., referring to girls as \"terrorists\" may be less harmful than referring to Muslim people as such). Thus, in contrast to most fairness work, we study fairness through the perspective of treating people differently — when it is contextually appropriate to. We first introduce an important distinction between descriptive (fact-based), normative (value-based), and correlation (association-based) benchmarks. This distinction is significant because each category requires separate interpretation and mitigation tailored to its specific characteristics. Then, we present a benchmark suite composed of eight different scenarios for a total of 16k questions that enables us to assess difference awareness. Finally, we show results across ten models that demonstrate difference awareness is a distinct dimension to fairness where existing bias mitigation strategies may backfire",
    "checked": true,
    "id": "2dfe534065f768b8b93fd40b6fac7677a9f70a05",
    "semantic_title": "fairness through difference awareness: measuring desired group discrimination in llms",
    "citation_count": 2,
    "authors": [
      "Angelina Wang",
      "Michelle Phan",
      "Daniel E. Ho",
      "Sanmi Koyejo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.342": {
    "title": "MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models",
    "volume": "long",
    "abstract": "Protecting the intellectual property of Large Language Models (LLMs) has become increasingly critical due to the high cost of training. Model merging, which integrates multiple expert models into a single multi-task model, introduces a novel risk of unauthorized use of LLMs due to its efficient merging process. While fingerprinting techniques have been proposed for verifying model ownership, their resistance to model merging remains unexplored. To address this gap, we propose a novel fingerprinting method, MergePrint, which embeds robust fingerprints capable of surviving model merging. MergePrint enables black-box ownership verification, where owners only need to check if a model produces target outputs for specific fingerprint inputs, without accessing model weights or intermediate outputs. By optimizing against a pseudo-merged model that simulates merged behavior, MergePrint ensures fingerprints that remain detectable after merging. Additionally, to minimize performance degradation, we pre-optimize the fingerprint inputs. MergePrint pioneers a practical solution for black-box ownership verification, protecting LLMs from misappropriation via merging, while also excelling in resistance to broader model theft threats",
    "checked": true,
    "id": "f7b6508268b576f406c8b14a58be987335c4ac19",
    "semantic_title": "mergeprint: merge-resistant fingerprints for robust black-box ownership verification of large language models",
    "citation_count": 0,
    "authors": [
      "Shojiro Yamabe",
      "Futa Kai Waseda",
      "Tsubasa Takahashi",
      "Koki Wataoka"
    ]
  },
  "https://aclanthology.org/2025.acl-long.343": {
    "title": "Dynamic Scaling of Unit Tests for Code Reward Modeling",
    "volume": "long",
    "abstract": "Current large language models (LLMs) often struggle to produce accurate responses on the first attempt for complex reasoning tasks like code generation. Prior research tackles this challenge by generating multiple candidate solutions and validating them with LLM-generated unit tests. The execution results of unit tests serve as reward signals to identify correct solutions. As LLMs always confidently make mistakes, these unit tests are not reliable, thereby diminishing the quality of reward signals. Motivated by the observation that scaling the number of solutions improves LLM performance, we explore the impact of scaling unit tests to enhance reward signal quality. Our pioneer experiment reveals a positive correlation between the number of unit tests and reward signal quality, with greater benefits observed in more challenging problems. Based on these insights, we propose CodeRM-8B, a lightweight yet effective unit test generator that enables efficient and high-quality unit test scaling. Additionally, we implement a dynamic scaling mechanism that adapts the number of unit tests based on problem difficulty, further improving efficiency. Experimental results show that our approach significantly improves performance across various models on three benchmarks (e.g., with gains of 18.43 for Llama3-8B and 3.42 for GPT-4o-mini on HumanEval Plus). The parameters of CodeRM-8B and corresponding training data will be available upon publication",
    "checked": true,
    "id": "5c68186066b38b1fd700457a729ae8ede77f5d0c",
    "semantic_title": "dynamic scaling of unit tests for code reward modeling",
    "citation_count": 4,
    "authors": [
      "Zeyao Ma",
      "Xiaokang Zhang",
      "Jing Zhang",
      "Jifan Yu",
      "Sijia Luo",
      "Jie Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.344": {
    "title": "UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations",
    "volume": "long",
    "abstract": "The rapid advancement of conversational search systems revolutionizes how information is accessed by enabling the multi-turn interaction between the user and the system. Existing conversational search systems are usually built with two different models. This separation restricts the system from leveraging the intrinsic knowledge of the models simultaneously, which cannot ensure the effectiveness of retrieval benefiting the generation. The existing studies for developing unified models cannot fully address the aspects of understanding conversational context, managing retrieval independently, and generating responses. In this paper, we explore how to unify dense retrieval and response generation for large language models in conversation. We conduct joint fine-tuning with different objectives and design two mechanisms to reduce the inconsistency risks while mitigating data discrepancy. The evaluations on five conversational search datasets demonstrate that our unified model can mutually improve both tasks and outperform the existing baselines",
    "checked": true,
    "id": "9c65deb1af43be3382b325a2d9d15195ff53e233",
    "semantic_title": "uniconv: unifying retrieval and response generation for large language models in conversations",
    "citation_count": 1,
    "authors": [
      "Fengran Mo",
      "Yifan Gao",
      "Chuan Meng",
      "Xin Liu",
      "Zhuofeng Wu",
      "Kelong Mao",
      "Zhengyang Wang",
      "Pei Chen",
      "Zheng Li",
      "Xian Li",
      "Bing Yin",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.345": {
    "title": "Tracking Life's Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis",
    "volume": "long",
    "abstract": "Social media platforms possess considerable potential in the realm of exploring mental health. Previous research has indicated that major life events can greatly impact individuals' mental health. However, due to the complexity and ambiguity nature of life events, shedding its light on social media data is quite challenging. In this paper, we are dedicated to uncovering life events mentioned in posts on social media. We hereby provide a carefully-annotated social media event dataset, PsyEvent, which encompasses 12 major life event categories that are likely to occur in everyday life. This dataset is human-annotated under iterative procedure and boasts a high level of quality. Furthermore, by applying the life events extracted from posts to downstream tasks such as early risk detection of depression and suicide risk prediction, we have observed a considerable improvement in performance. This suggests that extracting life events from social media can be beneficial for the analysis of individuals' mental health",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghao Lv",
      "Siyuan Chen",
      "Haoan Jin",
      "Minghao Yuan",
      "Qianqian Ju",
      "Yujia Peng",
      "Kenny Q. Zhu",
      "Mengyue Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.346": {
    "title": "ControlSpeech: Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control",
    "volume": "long",
    "abstract": "In this paper, we present ControlSpeech, a text-to-speech (TTS) system capable of fully cloning the speaker's voice and enabling arbitrary control and adjustment of speaking style. Prior zero-shot TTS models only mimic the speaker's voice without further control and adjustment capabilities while prior controllable TTS models cannot perform speaker-specific voice generation. Therefore, ControlSpeech focuses on a more challenging task—a TTS system with controllable timbre, content, and style at the same time. ControlSpeech takes speech prompts, content prompts, and style prompts as inputs and utilizes bidirectional attention and mask-based parallel decoding to capture codec representations corresponding to timbre, content, and style in a discrete decoupling codec space. Moreover, we analyze the many-to-many issue in textual style control and propose the Style Mixture Semantic Density (SMSD) module, which is based on Gaussian mixture density networks, to resolve this problem. To facilitate empirical validations, we make available a new style controllable dataset called VccmDataset. Our experimental results demonstrate that ControlSpeech exhibits comparable or state-of-the-art (SOTA) performance in terms of controllability, timbre similarity, audio quality, robustness, and generalizability. Codes are available at https://github.com/jishengpeng/ControlSpeech",
    "checked": true,
    "id": "af52e710146b0cdae53f0a0d465af9dd717700a9",
    "semantic_title": "controlspeech: towards simultaneous and independent zero-shot speaker cloning and zero-shot language style control",
    "citation_count": 0,
    "authors": [
      "Shengpeng Ji",
      "Qian Chen",
      "Wen Wang",
      "Jialong Zuo",
      "Minghui Fang",
      "Ziyue Jiang",
      "Hai Huang",
      "Zehan Wang",
      "Xize Cheng",
      "Siqi Zheng",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.347": {
    "title": "PIC: Unlocking Long-Form Text Generation Capabilities of Large Language Models via Position ID Compression",
    "volume": "long",
    "abstract": "Long-context understanding is crucial for large language models (LLMs) and has become a fundamental capability for most LLMs. However, beyond the focus on \"input-long\", the ability to \"output-long\" is equally significant, yet it remains underexplored. To address this limitation, we propose a simple, efficient, and plug-in approach, Position ID Compression (PIC), to unlock the long-form text generation potential of LLMs. The idea is straightforward: by compressing the position ids of the context, we provoke and guide LLMs to generate coherent and longer output. Specifically, we find that directly reducing the position ids by a fixed ratio significantly impacts the generation quality. To mitigate this, we propose two variants of PIC: NTK-aware PIC and Dynamic PIC. Without additional training, both methods enable LLMs to extend their generation length by approximately 1.5 times without compromising generation quality. Furthermore, by integrating supervised fine-tuning (SFT) with PIC, we propose PIC-SFT, which further improves LLMs' long-form text generation capabilities, achieving top performance on HelloBench and LongBench-Write. Extensive experiments demonstrate the effectiveness of our approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Que",
      "Wenge Rong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.348": {
    "title": "Towards Effective Extraction and Evaluation of Factual Claims",
    "volume": "long",
    "abstract": "A common strategy for fact-checking long-form content generated by Large Language Models (LLMs) is extracting simple claims that can be verified independently. Since inaccurate or incomplete claims compromise fact-checking results, ensuring claim quality is critical. However, the lack of a standardized evaluation framework impedes assessment and comparison of claim extraction methods. To address this gap, we propose a framework for evaluating claim extraction in the context of fact-checking along with automated, scalable, and replicable methods for applying this framework, including novel approaches for measuring coverage and decontextualization. We also introduce Claimify, an LLM-based claim extraction method, and demonstrate that it outperforms existing methods under our evaluation framework. A key feature of Claimify is its ability to handle ambiguity and extract claims only when there is high confidence in the correct interpretation of the source text",
    "checked": true,
    "id": "a3740496d9bd610796f2452a9a96d6b5900bd01a",
    "semantic_title": "towards effective extraction and evaluation of factual claims",
    "citation_count": 1,
    "authors": [
      "Dasha Metropolitansky",
      "Jonathan Larson"
    ]
  },
  "https://aclanthology.org/2025.acl-long.349": {
    "title": "Beyond Facts: Evaluating Intent Hallucination in Large Language Models",
    "volume": "long",
    "abstract": "When exposed to complex queries containing multiple conditions, today's large language models (LLMs) tend to produce responses that only partially satisfy the query while neglecting certain conditions. We, therefore, introduce the concept of Intent Hallucination, a phenomenon where LLMs either omit (failing to address certain parts) or misinterpret (responding to invented query parts) elements of the given query, leading to responses misaligned with the original query. To systematically evaluate intent hallucination, we introduce FAITHQA, a novel benchmark for intent hallucination that contains 20,068 problems, covering both query-only and retrieval-augmented generation (RAG) setups with varying topics and difficulty. FAITHQA is the first hallucination benchmark that goes beyond factual verification, tailored to identify the fundamental cause of intent hallucination. By evaluating various LLMs on FAITHQA, we find that (1) intent hallucination is a common issue even for state-of-the-art models, and (2) such a phenomenon stems from omission or misinterpretation of LLMs. To facilitate future research, we introduce an automatic LLM generation evaluation metric, named INTENT CONSTRAINT, for detecting intent hallucination. Human evaluation results demonstrate that INTENT CONSTRAINT is closer to human performance for intent hallucination compared to baselines",
    "checked": true,
    "id": "c63d647424956288d3ffa6149df2a26cc60b22bc",
    "semantic_title": "beyond facts: evaluating intent hallucination in large language models",
    "citation_count": 0,
    "authors": [
      "Yijie Hao",
      "Haofei Yu",
      "Jiaxuan You"
    ]
  },
  "https://aclanthology.org/2025.acl-long.350": {
    "title": "A Systematic Study of Compositional Syntactic Transformer Language Models",
    "volume": "long",
    "abstract": "Syntactic language models (SLMs) enhance Transformers by incorporating syntactic biases through the modeling of linearized syntactic parse trees alongside surface sentences. This paper focuses on compositional SLMs that are based on constituency parse trees and contain explicit bottom-up composition of constituent representations. We identify key aspects of design choices in existing compositional SLMs and propose a unified framework encompassing both existing models and novel variants. We conduct a comprehensive empirical evaluation of all the variants in our framework across language modeling, syntactic generalization, summarization, and inference efficiency. Based on the experimental results, we make multiple recommendations on the design of compositional SLMs. Our code is released at https://github.com/zhaoyd1/compositional_SLMs",
    "checked": true,
    "id": "1e65275dad5bfff4b620bfeb685fff87d73f7976",
    "semantic_title": "a systematic study of compositional syntactic transformer language models",
    "citation_count": 0,
    "authors": [
      "Yida Zhao",
      "Hao Xve",
      "Xiang Hu",
      "Kewei Tu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.351": {
    "title": "M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation",
    "volume": "long",
    "abstract": "Recent advancements in large language models (LLMs) have given rise to the LLM-as-a-judge paradigm, showcasing their potential to deliver human-like judgments. However, in the field of machine translation (MT) evaluation, current LLM-as-a-judge methods fall short of learned automatic metrics. In this paper, we propose Multidimensional Multi-Agent Debate (M-MAD), a systematic LLM-based multi-agent framework for advanced LLM-as-a-judge MT evaluation. Our findings demonstrate that M-MAD achieves significant advancements by (1) decoupling heuristic MQM criteria into distinct evaluation dimensions for fine-grained assessments; (2) employing multi-agent debates to harness the collaborative reasoning capabilities of LLMs; (3) synthesizing dimension-specific results into a final evaluation judgment to ensure robust and reliable outcomes. Comprehensive experiments show that M-MAD not only outperforms all existing LLM-as-a-judge methods but also competes with state-of-the-art reference-based automatic metrics, even when powered by a suboptimal model like GPT-4o mini. Detailed ablations and analysis highlight the superiority of our framework design, offering a fresh perspective for LLM-as-a-judge paradigm. Our code and data are publicly available at https://github.com/SU-JIAYUAN/M-MAD",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaopeng Feng",
      "Jiayuan Su",
      "Jiamei Zheng",
      "Jiahan Ren",
      "Yan Zhang",
      "Jian Wu",
      "Hongwei Wang",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.352": {
    "title": "SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition",
    "volume": "long",
    "abstract": "Creating lyrics and melodies for the vocal track in a symbolic format, known as song composition, demands expert musical knowledge of melody, an advanced understanding of lyrics, and precise alignment between them. Despite achievements in sub-tasks such as lyric generation, lyric-to-melody, and melody-to-lyric, etc, a unified model for song composition has not yet been achieved. In this paper, we introduce SongComposer, a pioneering step towards a unified song composition model that can readily create symbolic lyrics and melodies following instructions. SongComposer is a music-specialized large language model (LLM) that, for the first time, integrates the capability of simultaneously composing lyrics and melodies into LLMs by leveraging three key innovations: 1) a flexible tuple format for word-level alignment of lyrics and melodies, 2) an extended tokenizer vocabulary for song notes, with scalar initialization based on musical knowledge to capture rhythm, and 3) a multi-stage pipeline that captures musical structure, starting with motif-level melody patterns and progressing to phrase-level structure for improved coherence. Extensive experiments demonstrate that SongComposer outperforms advanced LLMs, including GPT-4, in tasks such as lyric-to-melody generation, melody-to-lyric generation, song continuation, and text-to-song creation. Moreover, we will release SongCompose, a large-scale dataset for training, containing paired lyrics and melodies in Chinese and English",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuangrui Ding",
      "Zihan Liu",
      "Xiaoyi Dong",
      "Pan Zhang",
      "Rui Qian",
      "Junhao Huang",
      "Conghui He",
      "Dahua Lin",
      "Jiaqi Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.353": {
    "title": "Personalized Text Generation with Contrastive Activation Steering",
    "volume": "long",
    "abstract": "Personalized text generation aims to infer users' writing style preferences from their historical texts and generate outputs that faithfully reflect these stylistic characteristics. Existing solutions primarily adopt two paradigms: retrieval-augmented generation (RAG) and parameter-efficient fine-tuning (PEFT). While these approaches have advanced the field, they suffer from two critical limitations: (1) the entanglement of content semantics and stylistic patterns in historical texts impedes accurate modeling of user-specific writing preferences; and (2) scalability challenges arising from both RAG's inference latency by retrieval operations and PEFT's parameter storage requirements for per user model. To overcome these limitations, we propose StyleVector, a training-free framework that disentangles and represents personalized writing style as a vector in LLM's activation space, enabling style-steered generation during inference without requiring costly retrieval or parameter storage. Comprehensive experiments demonstrate that our framework achieves a significant 8% relative improvement in personalized generation while reducing storage requirements by 1700 × over PEFT method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinghao Zhang",
      "Yuting Liu",
      "Wenjie Wang",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.acl-long.354": {
    "title": "Gumbel Reranking: Differentiable End-to-End Reranker Optimization",
    "volume": "long",
    "abstract": "RAG systems rely on rerankers to identify relevant documents. However, fine-tuning these models remains challenging due to the scarcity of annotated query-document pairs. Existing distillation-based approaches suffer from training-inference misalignment and fail to capture interdependencies among candidate documents. To overcome these limitations, we reframe the reranking process as an attention-mask problem and propose Gumbel Reranking, an end-to-end training framework for rerankers aimed at minimizing the training-inference gap. In our approach, reranker optimization is reformulated as learning a stochastic, document-wise Top-k attention mask using the Gumbel Trick and Relaxed Top-k Sampling. This formulation enables end-to-end optimization by minimizing the overall language loss. Experiments across various settings consistently demonstrate performance gains, including a 10.4% improvement in recall on HotpotQA for distinguishing indirectly relevant documents",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Huang",
      "Zhiyuan Ma",
      "Jintao Du",
      "Changhua Meng",
      "Weiqiang Wang",
      "Jingwen Leng",
      "Minyi Guo",
      "Zhouhan Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.355": {
    "title": "Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback",
    "volume": "long",
    "abstract": "Learning from human feedback has enabled the alignment of language models (LMs) with human preferences. However, collecting human preferences is expensive and time-consuming, with highly variable annotation quality. An appealing alternative is to distill preferences from LMs as a source of synthetic annotations, offering a cost-effective and scalable alternative, albeit susceptible to other biases and errors. In this work, we introduce HyPER, a Hybrid Preference routER that defers an annotation to either humans or LMs, achieving better annotation quality while reducing the cost of human-only annotation. We formulate this as an optimization problem: given a preference dataset and an evaluation metric, we (1) train a performance prediction model (PPM) to predict a reward model's (RM) performance on an arbitrary combination of human and LM annotations and (2) employ a routing strategy that selects a combination that maximizes predicted performance. We train the PPM on MultiPref, a new preference dataset with 10K instances paired with human and LM labels. We show that the selected hybrid mixture of synthetic and direct human preferences using HyPER achieves better RM performance compared to using either one exclusively by 7-13% on RewardBench and generalizes across unseen preference datasets and other base models. We also observe the same trend in other benchmarks using Best-of-N reranking, where the hybrid mix has 2-3% better performance. Finally, we analyze features from HyPER and find that prompts with moderate safety concerns or complexity benefit the most from human feedback",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lester James Validad Miranda",
      "Yizhong Wang",
      "Yanai Elazar",
      "Sachin Kumar",
      "Valentina Pyatkin",
      "Faeze Brahman",
      "Noah A. Smith",
      "Hannaneh Hajishirzi",
      "Pradeep Dasigi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.356": {
    "title": "SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection",
    "volume": "long",
    "abstract": "Automatic evaluation for Open Domain Event Detection (ODED) is a highly challenging task, because ODED is characterized by a vast diversity of un-constrained output labels from various domains. Nearly all existing evaluation methods for ODED usually first construct evaluation benchmarks with limited labels and domain coverage, and then evaluate ODED methods using metrics based on token-level label matching rules. However, this kind of evaluation framework faces two issues: (1) The limited evaluation benchmarks lack representatives of the real world, making it difficult to accurately reflect the performance of various ODED methods in real-world scenarios; (2) Evaluation metrics based on token-level matching rules fail to capture semantic similarity between predictions and golden labels. To address these two problems above, we propose a scalable and reliable Semantic-level Evaluation framework for Open domain Event detection (SEOE) by constructing a more representative evaluation benchmark and introducing a semantic evaluation metric. Specifically, our proposed framework first constructs a scalable evaluation benchmark that currently includes 564 event types covering 7 major domains, with a cost-effective supplementary annotation strategy to ensure the benchmark's representativeness. The strategy also allows for the supplement of new event types and domains in the future. Then, the proposed SEOE leverages large language models (LLMs) as automatic evaluation agents to compute a semantic F1-score, incorporating fine-grained definitions of semantically similar labels to enhance the reliability of the evaluation. Extensive experiments validate the representatives of the benchmark and the reliability of the semantic evaluation metric. Existing ODED methods are thoroughly evaluated, and the error patterns of predictions are analyzed, revealing several insightful findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Fan Lu",
      "Xian-Ling Mao",
      "Tian Lan",
      "Tong Zhang",
      "Yu-Shi Zhu",
      "Heyan Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.357": {
    "title": "The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project",
    "volume": "long",
    "abstract": "This paper presents UD-NewsCrawl, the largest Tagalog treebank to date, containing 15.6k trees manually annotated according tothe Universal Dependencies framework. We detail our treebank development process, including data collection, pre-processing, manual annotation, and quality assurance procedures. We provide baseline evaluations using multiple transformer-based models to assess the performance of state-of-the-art dependency parsers on Tagalog. We also highlight challenges in the syntactic analysis of Tagalog given its distinctive grammatical properties, and discuss its implications for the annotation of this treebank. We anticipate that UD-NewsCrawl and our baseline model implementations will serve as valuable resources for advancing computational linguistics research in underrepresented languages like Tagalog",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angelina Aspra Aquino",
      "Lester James Validad Miranda",
      "Elsie Marie T. Or"
    ]
  },
  "https://aclanthology.org/2025.acl-long.358": {
    "title": "DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) methods have proven highly effective for tasks requiring factual consistency and robust knowledge retrieval. However, large-scale RAG systems consume significant computational resources and are prone to generating \"hallucinated\" content from Humans. In this work, we introduce DRAG, a novel framework for distilling RAG knowledge from large-scale Language Models (LLMs) into small LMs (SLMs). Our approach leverages evidence- and knowledge graph–based distillation, ensuring that the distilled model retains critical factual knowledge while significantly reducing model size and computational cost. By aligning the smaller model's predictions with a structured knowledge graph and ranked evidence, DRAG effectively mitigates hallucinations and improves factual accuracy. We further present a case demonstrating how our framework mitigates user privacy risks and introduce a corresponding benchmark. Experimental evaluations on multiple benchmarks demonstrate that our method outperforms the prior competitive RAG methods like MiniRAG for SLMs by up to 27.7% using the same models, preserving high-level efficiency and reliability. With DRAG, we provide a practical and resource-efficient roadmap to deploying enhanced retrieval and generation capabilities in small-size LLMs. Code is available at https://github.com/VILA-Lab/DRAG",
    "checked": true,
    "id": "6db051a6f43e43ec653db41cdda14dc4fe0cc241",
    "semantic_title": "drag: distilling rag for slms from llms to transfer knowledge and mitigate hallucination via evidence and graph-based distillation",
    "citation_count": 0,
    "authors": [
      "Jennifer Chen",
      "Aidar Myrzakhan",
      "Yaxin Luo",
      "Hassaan Muhammad Khan",
      "Sondos Mahmoud Bsharat",
      "Zhiqiang Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.359": {
    "title": "G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems",
    "volume": "long",
    "abstract": "Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstrated remarkable capabilities in various complex tasks, ranging from collaborative problem-solving to autonomous decision-making. However, as these systems become increasingly integrated into critical applications, their vulnerability to adversarial attacks, misinformation propagation, and unintended behaviors have raised significant concerns. To address this challenge, we introduce G-Safeguard, a topology-guided security lens and treatment for robust LLM-MAS, which leverages graph neural networks to detect anomalies on the multi-agent utterance graph and employ topological intervention for attack remediation. Extensive experiments demonstrate that G-Safeguard: (I) exhibits significant effectiveness under various attack strategies, recovering over 40% of the performance for prompt injection; (II) is highly adaptable to diverse LLM backbones and large-scale MAS; (III) can seamlessly combine with mainstream MAS with security guarantees",
    "checked": true,
    "id": "4e92cc52b11da0785362c3b98a8821005d326b45",
    "semantic_title": "g-safeguard: a topology-guided security lens and treatment on llm-based multi-agent systems",
    "citation_count": 3,
    "authors": [
      "Shilong Wang",
      "Guibin Zhang",
      "Miao Yu",
      "Guancheng Wan",
      "Fanci Meng",
      "Chongye Guo",
      "Kun Wang",
      "Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.360": {
    "title": "Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) are increasingly engaging in moral and ethical reasoning, where criteria for judgment are often unclear, even for humans. While LLM alignment studies cover many areas, one important yet underexplored area is how LLMs make judgments about obligations. This work reveals a strong tendency in LLMs to judge non-obligatory contexts as obligations when prompts are augmented with modal expressions such as must or ought to. We introduce this phenomenon as Deontological Keyword Bias (DKB). We find that LLMs judge over 90% of commonsense scenarios as obligations when modal expressions are present. This tendency is consist across various LLM families, question types, and answer formats. To mitigate DKB, we propose a judgment strategy that integrates few-shot examples with reasoning prompts. This study sheds light on how modal expressions, as a form of linguistic framing, influence the normative decisions of LLMs and underscores the importance of addressing such biases to ensure judgment alignment",
    "checked": true,
    "id": "113202e4de3a5251b7976987f22ac3a9c5323a1e",
    "semantic_title": "deontological keyword bias: the impact of modal expressions on normative judgments of language models",
    "citation_count": 0,
    "authors": [
      "Bumjin Park",
      "Leejinsil Leejinsil",
      "Jaesik Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.361": {
    "title": "LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning",
    "volume": "long",
    "abstract": "Legal judgment prediction (LJP) aims to function as a judge by making final rulings based on case claims and facts, which plays a vital role in the judicial domain for supporting court decision-making and improving judicial efficiency. However, existing methods often struggle with logical errors when conducting complex legal reasoning. We propose LegalReasoner, which enhances LJP reliability through step-wise verification and correction of the reasoning process. Specifically, it first identifies dispute points to decompose complex cases, and then conducts step-wise reasoning while employing a process verifier to validate each step's logic from correctness, progressiveness, and potential perspectives. When errors are detected, expert-designed attribution and resolution strategies are applied for correction. To fine-tune LegalReasoner, we release the LegalHK dataset, containing 58,130 Hong Kong court cases with detailed annotations of dispute points, step-by-step reasoning chains, and process verification labels. Experiments demonstrate that LegalReasoner significantly improves concordance with court decisions from 72.37 to 80.27 on LLAMA-3.1-70B. The data is available at https://huggingface.co/datasets/weijiezz/LegalHK",
    "checked": true,
    "id": "5293123a3099a8185ef4ab9f28ac93c362d43f4e",
    "semantic_title": "legalreasoner: step-wised verification-correction for legal judgment reasoning",
    "citation_count": 0,
    "authors": [
      "Weijie Shi",
      "Han Zhu",
      "Jiaming Ji",
      "Mengze Li",
      "Jipeng Zhang",
      "Ruiyuan Zhang",
      "Jia Zhu",
      "Jiajie Xu",
      "Sirui Han",
      "Yike Guo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.362": {
    "title": "Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context",
    "volume": "long",
    "abstract": "Human processing of idioms heavily depends on interpreting the surrounding context in which they appear. While large language models (LLMs) have achieved impressive performance on idiomaticity detection benchmarks, this success may be driven by reasoning shortcuts present in existing datasets. To address this, we introduce a novel, controlled contrastive dataset (DICE) specifically designed to assess whether LLMs can effectively leverage context to disambiguate idiomatic meanings. Furthermore, we investigate the influence of collocational frequency and sentence probability—proxies for human processing known to affect idiom resolution—on model performance. Our results show that LLMs frequently fail to resolve idiomaticity when it depends on contextual understanding, performing better on sentences deemed more likely by the model. Additionally, idiom frequency influences performance but does not guarantee accurate interpretation. Our findings emphasize the limitations of current models in grasping contextual meaning and highlight the need for more context-sensitive evaluation",
    "checked": true,
    "id": "75c5c7ac211ae227bb54a6964167e6766ad2a372",
    "semantic_title": "rolling the dice on idiomaticity: how llms fail to grasp context",
    "citation_count": 1,
    "authors": [
      "Maggie Mi",
      "Aline Villavicencio",
      "Nafise Sadat Moosavi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.363": {
    "title": "ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation",
    "volume": "long",
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in chart understanding tasks. However, interpreting charts with textual descriptions often leads to information loss, as it fails to fully capture the dense information embedded in charts. In contrast, parsing charts into code provides lossless representations that can effectively contain all critical details. Although existing open-source MLLMs have achieved success in chart understanding tasks, they still face two major challenges when applied to chart-to-code tasks: (1) Low executability and poor restoration of chart details in the generated code and (2) Lack of large-scale and diverse training data. To address these challenges, we propose ChartCoder, the first dedicated chart-to-code MLLM, which leverages Code LLMs as the language backbone to enhance the executability of the generated code. Furthermore, we introduce Chart2Code-160k, the first large-scale and diverse dataset for chart-to-code generation, and propose the Snippet-of-Thought (SoT) method, which transforms direct chart-to-code generation data into step-by-step generation. Experiments demonstrate that ChartCoder, with only 7B parameters, surpasses existing open-source MLLMs on chart-to-code benchmarks, achieving superior chart restoration and code excitability. Our code is available at https://github.com/thunlp/ChartCoder",
    "checked": true,
    "id": "6cf64f544140a2f27bc0851fee2506aaf1e58723",
    "semantic_title": "chartcoder: advancing multimodal large language model for chart-to-code generation",
    "citation_count": 12,
    "authors": [
      "Xuanle Zhao",
      "Xianzhen Luo",
      "Qi Shi",
      "Chi Chen",
      "Shuo Wang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.364": {
    "title": "The Cross-linguistic Role of Animacy in Grammar Structures",
    "volume": "long",
    "abstract": "Animacy is a semantic feature of nominals and follows a hierarchy: personal pronouns > human > animate > inanimate. In several languages, animacy imposes hard constraints on grammar. While it has been argued that these constraints may emerge from universal soft tendencies, it has been difficult to provide empirical evidence for this conjecture due to the lack of data annotated with animacy classes. In this work, we first propose a method to reliably classify animacy classes of nominals in 11 languages from 5 families, leveraging multilingual large language models (LLMs) and word sense disambiguation datasets. Then, through this newly acquired data, we verify that animacy displays consistent cross-linguistic tendencies in terms of preferred morphosyntactic constructions, although not always in line with received wisdom: animacy in nouns correlates with the alignment role of agent, early positions in a clause, and syntactic pivot (e.g., for relativisation), but not necessarily with grammatical subjecthood. Furthermore, the behaviour of personal pronouns in the hierarchy is idiosyncratic as they are rarely plural and relativised, contrary to high-animacy nouns",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nina Gregorio",
      "Matteo Gay",
      "Sharon Goldwater",
      "Edoardo Ponti"
    ]
  },
  "https://aclanthology.org/2025.acl-long.365": {
    "title": "LexGen: Domain-aware Multilingual Lexicon Generation",
    "volume": "long",
    "abstract": "Lexicon or dictionary generation across domains has the potential for societal impact, as it can potentially enhance information accessibility for a diverse user base while preserving language identity. Prior work in the field primarily focuses on bilingual lexical induction, which deals with word alignments using mapping-based or corpora-based approaches. However, these approaches do not cater to domain-specific lexicon generation that consists of domain-specific terminology. This task becomes particularly important in specialized medical, engineering, and other technical domains, owing to the highly infrequent usage of the terms and scarcity of data involving domain-specific terms especially for low-resource languages. We propose a new model to generate dictionary words for 6 Indian languages in the multi-domain setting. Our model consists of domain-specific and domain-generic layers that encode information, and these layers are invoked via a learnable routing technique. We also release a new benchmark dataset consisting of >75K translation pairs across 6 Indian languages spanning 8 diverse domains. We conduct both zero-shot and few-shot experiments across multiple domains to show the efficacy of our proposed model in generalizing to unseen domains and unseen languages. Additionally, we also perform a human post-hoc evaluation on unseen languages. The source code and dataset is present at https://github.com/Atulkmrsingh/lexgen",
    "checked": true,
    "id": "baf89e8a9645660fb70f4dade51059463fa669c9",
    "semantic_title": "lexgen: domain-aware multilingual lexicon generation",
    "citation_count": 1,
    "authors": [
      "Ayush Maheshwari",
      "Atul Kumar Singh",
      "N J Karthika",
      "Krishnakant Bhatt",
      "Preethi Jyothi",
      "Ganesh Ramakrishnan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.366": {
    "title": "How to Train Long-Context Language Models (Effectively)",
    "volume": "long",
    "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development—instead of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set of long-context downstream tasks, and we evaluate models after SFT as this better reveals long-context abilities. Supported by our robust evaluations, we run thorough experiments to decide the data mix for continued pre-training, the instruction tuning dataset, and many other design choices such as position extrapolation. We find that (1) code repositories and books are excellent sources of long data, but it is crucial to combine them with high-quality short-context data; (2) training with a sequence length beyond the evaluation length boosts long-context performance; (3) for SFT, using only short instruction datasets yields strong performance on long-context tasks. Our final model, ProLong-8B, which is initialized from Llama-3 and trained on 40B tokens, demonstrates state-of-the-art long-context performance among similarly sized models at a length of 128K. ProLong outperforms Llama-3.1-8B-Instruct on the majority of long-context tasks despite using only 5% as many tokens during long-context training. Additionally, ProLong can effectively process up to 512K tokens, one of the longest context windows of publicly available LMs",
    "checked": true,
    "id": "5630d71a0ca608985a7beb00ce6a302c2142762d",
    "semantic_title": "how to train long-context language models (effectively)",
    "citation_count": 48,
    "authors": [
      "Tianyu Gao",
      "Alexander Wettig",
      "Howard Yen",
      "Danqi Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.367": {
    "title": "MathFusion: Enhancing Mathematical Problem-solving of LLM through Instruction Fusion",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown impressive progress in mathematical reasoning. While data augmentation is promising to enhance mathematical problem-solving ability, current approaches are predominantly limited to instance-level modifications—such as rephrasing or generating syntactic variations—which fail to capture and leverage the intrinsic relational structures inherent in mathematical knowledge. Inspired by human learning processes, where mathematical proficiency develops through systematic exposure to interconnected concepts, we introduce MathFusion, a novel framework that enhances mathematical reasoning through cross-problem instruction synthesis. MathFusion implements this through three fusion strategies: (1) sequential fusion, which chains related problems to model solution dependencies; (2) parallel fusion, which combines analogous problems to reinforce conceptual understanding; and (3) conditional fusion, which creates context-aware selective problems to enhance reasoning flexibility. By applying these strategies, we generate a new dataset, MathFusionQA, followed by fine-tuning models (DeepSeekMath-7B, Mistral-7B, Llama3-8B) on it. Experimental results demonstrate that MathFusion achieves substantial improvements in mathematical reasoning while maintaining high data efficiency, boosting performance by 18.0 points in accuracy across diverse benchmarks while requiring only 45K additional synthetic instructions, representing a substantial improvement over traditional single-instruction approaches",
    "checked": false,
    "id": "424783c539cdcfb5cda3a558fafbf1b9b3252621",
    "semantic_title": "mathfusion: enhancing mathematic problem-solving of llm through instruction fusion",
    "citation_count": 5,
    "authors": [
      "Qizhi Pei",
      "Lijun Wu",
      "Zhuoshi Pan",
      "Yu Li",
      "Honglin Lin",
      "Chenlin Ming",
      "Xin Gao",
      "Conghui He",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.368": {
    "title": "Mining Complex Patterns of Argumentative Reasoning in Natural Language Dialogue",
    "volume": "long",
    "abstract": "Argumentation scheme mining is the task of automatically identifying reasoning mechanisms behind argument inferences. These mechanisms provide insights into underlying argument structures and guide the assessment of natural language arguments. Research on argumentation scheme mining, however, has always been limited by the scarcity of large enough publicly available corpora containing scheme annotations. In this paper, we present the first state-of-the-art results for mining argumentation schemes in natural language dialogue. For this purpose, we create QT-Schemes, a new corpus of 441 arguments annotated with 24 argumentation schemes. Using this corpus, we leverage the capabilities of LLMs and Transformer-based models, pre-training them on a large corpus containing textbook-like argumentation schemes and validating their applicability in real-world scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramon Ruiz-Dolz",
      "Zlata Kikteva",
      "John Lawrence"
    ]
  },
  "https://aclanthology.org/2025.acl-long.369": {
    "title": "OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use",
    "volume": "long",
    "abstract": "The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution of multi-modal large language models ((M)LLMs), this dream is closer to reality, as (M)LLM-based Agents using computers, mobile phones and web browsers by operating within the environments and interfaces (e.g., Graphical User Interface (GUI) and Command Line Interface (CLI)) provided by operating systems (OS) to automate tasks have significantly advanced. This paper presents a comprehensive survey on these advanced agents, designated as OS Agents. We begin by elucidating the fundamentals of OS Agents, exploring their key components and capabilities. We then examine methodologies for constructing OS Agents, focusing on domain-specific foundation models and agent frameworks. A detailed review of evaluation metrics and benchmarks highlights how OS Agents are assessed across diverse platforms and tasks. Finally, we discuss current challenges and identify promising directions for future research. An open-source GitHub repository is maintained as a dynamic resource to foster further innovation in this field",
    "checked": true,
    "id": "255684830fb1eb3bef0986052cc50b4d455913a3",
    "semantic_title": "os agents: a survey on mllm-based agents for computer, phone and browser use",
    "citation_count": 4,
    "authors": [
      "Xueyu Hu",
      "Tao Xiong",
      "Biao Yi",
      "Zishu Wei",
      "Ruixuan Xiao",
      "Yurun Chen",
      "Jiasheng Ye",
      "Meiling Tao",
      "Xiangxin Zhou",
      "Ziyu Zhao",
      "Yuhuai Li",
      "Shengze Xu",
      "Shenzhi Wang",
      "Xinchen Xu",
      "Shuofei Qiao",
      "Zhaokai Wang",
      "Kun Kuang",
      "Tieyong Zeng",
      "Liang Wang",
      "Jiwei Li",
      "Yuchen Eleanor Jiang",
      "Wangchunshu Zhou",
      "Guoyin Wang",
      "Keting Yin",
      "Zhou Zhao",
      "Hongxia Yang",
      "Fan Wu",
      "Shengyu Zhang",
      "Fei Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.370": {
    "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning",
    "volume": "long",
    "abstract": "Our quality audit for three widely used public multilingual speech datasets Mozilla Common Voice 17.0, FLEURS, and VoxPopuli shows that in some languages, these datasets suffer from significant quality issues. We believe addressing these issues will make these datasets more useful as evaluation sets, and improve downstream models. We divide these quality issues into two categories: micro-level and macro-level. We find that macro-level issues are more prevalent in less institutionalized, often under-resourced languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that highlights the need for proactive language planning (e.g. orthography prescriptions, dialect boundary definition) and enhanced data quality control in the process of Automatic Speech Recognition (ASR) dataset creation. We conclude by proposing guidelines and recommendations to mitigate these issues in future dataset development, emphasizing the importance of sociolinguistic awareness in creating robust and reliable speech data resources",
    "checked": true,
    "id": "3c8055641c88da93c4a74d7479adfc9d152b18bb",
    "semantic_title": "data quality issues in multilingual speech datasets: the need for sociolinguistic awareness and proactive language planning",
    "citation_count": 0,
    "authors": [
      "Mingfei Lau",
      "Qian Chen",
      "Yeming Fang",
      "Tingting Xu",
      "Tongzhou Chen",
      "Pavel Golik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.371": {
    "title": "LLM as a Broken Telephone: Iterative Generation Distorts Information",
    "volume": "long",
    "abstract": "As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs.Inspired by the \"broken telephone\" effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation.Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity. While degradation is inevitable, it can be mitigated through strategic prompting techniques. These findings contribute to discussions on the long-term effects of AI-mediated information propagation, raising important questions about the reliability of LLM-generated content in iterative workflows",
    "checked": true,
    "id": "2707bd266515112a43a430c1a077387fe3b8149f",
    "semantic_title": "llm as a broken telephone: iterative generation distorts information",
    "citation_count": 2,
    "authors": [
      "Amr Mohamed",
      "Mingmeng Geng",
      "Michalis Vazirgiannis",
      "Guokan Shang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.372": {
    "title": "VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues",
    "volume": "long",
    "abstract": "Visually linking matching cues is a crucial ability in daily life, such as identifying the same person in multiple photos based on their cues, even without knowing who they are. Despite the extensive knowledge that vision-language models (VLMs) possess, it remains largely unexplored whether they are capable of performing this fundamental task. To address this, we introduce VLM2-Bench, a benchmark designed to assess whether VLMs can Visually Link Matching cues, with 9 subtasks and over 3,000 test cases. Comprehensive evaluation across twelve VLMs, along with further analysis of various language-side and vision-side prompting methods, leads to a total of eight key findings. We identify critical challenges in models' ability to link visual cues, highlighting a significant performance gap. Based on these insights, we advocate for (i) enhancing core visual capabilities to improve adaptability and reduce reliance on prior knowledge, (ii) establishing clearer principles for integrating language-based reasoning in vision-centric tasks to prevent unnecessary biases, and (iii) shifting vision-text training paradigms toward fostering models' ability to independently structure and infer relationships among visual cues",
    "checked": true,
    "id": "2e32d1616d964686263acf5f06969993d43c088f",
    "semantic_title": "vlm2-bench: a closer look at how well vlms implicitly link explicit matching visual cues",
    "citation_count": 10,
    "authors": [
      "Jianshu Zhang",
      "Dongyu Yao",
      "Renjie Pi",
      "Paul Pu Liang",
      "Yi R. Fung"
    ]
  },
  "https://aclanthology.org/2025.acl-long.373": {
    "title": "Alleviating Distribution Shift in Synthetic Data for Machine Translation Quality Estimation",
    "volume": "long",
    "abstract": "Quality Estimation (QE) models evaluate the quality of machine translations without reference translations, serving as the reward models for the translation task.Due to the data scarcity, synthetic data generation has emerged as a promising solution.However, synthetic QE data often suffers from distribution shift, which can manifest as discrepancies between pseudo and real translations, or in pseudo labels that do not align with human preferences.To tackle this issue, we introduce DCSQE, a novel framework for alleviating distribution shift in synthetic QE data.To reduce the difference between pseudo and real translations, we employ the constrained beam search algorithm and enhance translation diversity through the use of distinct generation models.DCSQE uses references—i.e., translation supervision signals—to guide both the generation and annotation processes, enhancing the quality of token-level labels.DCSQE further identifies the shortest phrase covering consecutive error tokens, mimicking human annotation behavior, to assign the final phrase-level labels.Specially, we underscore that the translation model can not annotate translations of itself accurately.Extensive experiments demonstrate that DCSQE outperforms SOTA baselines like CometKiwi in both supervised and unsupervised settings.Further analysis offers insights into synthetic data generation that could benefit reward models for other tasks.The code is available at https://github.com/NJUNLP/njuqe",
    "checked": true,
    "id": "ea10f25033e66409dae39f37bbb6e2ca649e468e",
    "semantic_title": "alleviating distribution shift in synthetic data for machine translation quality estimation",
    "citation_count": 0,
    "authors": [
      "Xiang Geng",
      "Zhejian Lai",
      "Jiajun Chen",
      "Hao Yang",
      "Shujian Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.374": {
    "title": "Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models",
    "volume": "long",
    "abstract": "Recent advancements in visual generative models have enabled high-quality image and video generation, opening diverse applications. However, evaluating these models often demands sampling hundreds or thousands of images or videos, making the process computationally expensive, especially for diffusion-based models with inherently slow sampling. Moreover, existing evaluation methods rely on rigid pipelines that overlook specific user needs and provide numerical results without clear explanations. In contrast, humans can quickly form impressions of a model's capabilities by observing only a few samples. To mimic this, we propose the Evaluation Agent framework, which employs human-like strategies for efficient, dynamic, multi-round evaluations using only a few samples per round, while offering detailed, user-tailored analyses. It offers four key advantages: 1) efficiency, 2) promptable evaluation tailored to diverse user needs, 3) explainability beyond single numerical scores, and 4) scalability across various models and tools. Experiments show that Evaluation Agent reduces evaluation time to 10% of traditional methods while delivering comparable results. The Evaluation Agent framework is fully open-sourced to advance research in visual generative models and their efficient evaluation",
    "checked": true,
    "id": "b564a44a5f1add53828b0c29a6cc3e76526cc75d",
    "semantic_title": "evaluation agent: efficient and promptable evaluation framework for visual generative models",
    "citation_count": 3,
    "authors": [
      "Fan Zhang",
      "Shulin Tian",
      "Ziqi Huang",
      "Yu Qiao",
      "Ziwei Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.375": {
    "title": "Large Language Models Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Topic Models",
    "volume": "long",
    "abstract": "A common use of NLP is to facilitate the understanding of large document collections, with models based on Large Language Models (LLMs) replacing probabilistic topic models. Yet the effectiveness of LLM-based approaches in real-world applications remains under explored. This study measures the knowledge users acquire with topic models—including traditional, unsupervised and supervised LLM- based approaches—on two datasets. While LLM-based methods generate more human- readable topics and show higher average win probabilities than traditional models for data exploration, they produce overly generic topics for domain-specific datasets that do not easily allow users to learn much about the documents. Adding human supervision to LLM-based topic models improves data exploration by addressing hallucination and genericity but requires more human efforts. In contrast, traditional models like Latent Dirichlet Allocation (LDA) remain effective for exploration but are less user-friendly. This paper provides best practices—there is no one right model, the choice of models is situation-specific—and suggests potential improvements for scalable LLM- based topic models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongxia Li",
      "Lorena Calvo-Bartolomé",
      "Alexander Miserlis Hoyle",
      "Paiheng Xu",
      "Daniel Kofi Stephens",
      "Juan Francisco Fung",
      "Alden Dima",
      "Jordan Lee Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.376": {
    "title": "ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models",
    "volume": "long",
    "abstract": "Active perception, a crucial human capability, involves setting a goal based on the current understanding of the environment and performing actions to achieve that goal. Despite significant efforts in evaluating Multimodal Large Language Models (MLLMs), active perception has been largely overlooked. To address this gap, we propose a novel benchmark named ActiView to evaluate active perception in MLLMs. We focus on a specialized form of Visual Question Answering (VQA) that eases and quantifies the evaluation yet challenging for existing MLLMs. Meanwhile, intermediate reasoning behaviors of models are also discussed. Given an image, we restrict the perceptual field of a model, requiring it to actively zoom or shift its perceptual field based on reasoning to answer the question successfully. We conduct extensive evaluation over 30 models, including proprietary and open-source models, and observe that restricted perceptual fields play a significant role in enabling active perception. Results reveal a significant gap in the active perception capability of MLLMs, indicating that this area deserves more attention. We hope that ActiView could help develop methods for MLLMs to understand multimodal inputs in more natural and holistic ways",
    "checked": true,
    "id": "28ab2f41edee6d0cf6c31275769476d94aa2eb2a",
    "semantic_title": "actiview: evaluating active perception ability for multimodal large language models",
    "citation_count": 3,
    "authors": [
      "Ziyue Wang",
      "Chi Chen",
      "Fuwen Luo",
      "Yurui Dong",
      "Yuanchi Zhang",
      "Yuzhuang Xu",
      "Xiaolong Wang",
      "Peng Li",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.377": {
    "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
    "volume": "long",
    "abstract": "Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs use ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely on pattern matching. Using a controlled setting of biased coin flips, we find that: (1) LLMs often possess biased priors, causing initial divergence in zero-shot settings, (2) in-context evidence outweighs explicit bias instructions, (3) LLMs broadly follow Bayesian posterior updates, with deviations primarily due to miscalibrated priors rather than flawed updates, and (4) attention magnitude has negligible effect on Bayesian inference. With sufficient demonstrations of biased coin flips via ICL, LLMs update their priors in a Bayesian manner. Code and visualizations are available on the [project page](https://ai-climate.berkeley.edu/llm-coin-flips/)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ritwik Gupta",
      "Rodolfo Corona",
      "Jiaxin Ge",
      "Eric Wang",
      "Dan Klein",
      "Trevor Darrell",
      "David M. Chan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.378": {
    "title": "GAMEBoT: Transparent Assessment of LLM Reasoning in Games",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in real-world applications that demand complex reasoning. To track progress, robust benchmarks are required to evaluate their capabilities beyond superficial pattern recognition. However, current LLM reasoning benchmarks often face challenges such as insufficient interpretability, performance saturation or data contamination. To address these challenges, we introduce GAMEBoT, a gaming arena designed for rigorous and transparent assessment of LLM reasoning capabilities. GAMEBoT decompose complex reasoning in games into predefined modular subproblems. This decomposition allows us to design a suite of Chain-of-Thought (CoT) prompts infused with domain knowledge to guide LLMs in addressing these subproblems before action selection. Furthermore, we develop a suite of rule-based algorithms to generate ground truth for these subproblems, enabling rigorous validation of the LLMs' intermediate reasoning steps. This approach facilitates evaluation of both the quality of final actions and the accuracy of the underlying reasoning process. GAMEBoT also naturally alleviates the risk of data contamination through dynamic games and head-to-head LLM competitions. We benchmark 17 prominent LLMs across eight games, encompassing various strategic abilities and game characteristics. Our results suggest that GAMEBoT presents a significant challenge, even when LLMs are provided with detailed CoT prompts",
    "checked": true,
    "id": "29c54da907c066a273f01500f96edd0274e12ccd",
    "semantic_title": "gamebot: transparent assessment of llm reasoning in games",
    "citation_count": 1,
    "authors": [
      "Wenye Lin",
      "Jonathan Roberts",
      "Yunhan Yang",
      "Samuel Albanie",
      "Zongqing Lu",
      "Kai Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.379": {
    "title": "A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens",
    "volume": "long",
    "abstract": "Text embeddings from large language models (LLMs) have achieved excellent results in tasks such as information retrieval, semantic textual similarity, etc. In this work, we show an interesting finding: when feeding a text into the LLM-based embedder, the obtained text embedding will be able to be aligned with the key tokens in the input text. We first fully analyze this phenomenon on eight LLM-based embedders and show that this phenomenon is universal and is not affected by model architecture, training strategy, and embedding method. With a deeper analysis, we find that the main change in embedding space between these embedders and their LLM backbones is in the first principal component. By adjusting the first principal component, we can align text embedding with the key tokens. Finally, we give several examples to demonstrate the vast application potential of this finding: (1) we propose a simple and practical sparse retrieval method based on the aligned tokens, which can achieve 80% of the dense retrieval effect of the same model while reducing the computation significantly; (2) we show that our findings provide a novel perspective to help understand novel technologies (e.g., instruction-following embedding) and fuzzy concepts (e.g., semantic relatedness vs. similarity) in this field",
    "checked": true,
    "id": "39fce79715cd5d7d5a15fe1a96e04f5da468eec9",
    "semantic_title": "a text is worth several tokens: text embedding from llms secretly aligns well with the key tokens",
    "citation_count": 2,
    "authors": [
      "Zhijie Nie",
      "Richong Zhang",
      "Zhanyu Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.380": {
    "title": "Commonsense Reasoning in Arab Culture",
    "volume": "long",
    "abstract": "Despite progress in Arabic large language models, such as Jais and AceGPT, their evaluation on commonsense reasoning has largely relied on machine-translated datasets, which lack cultural depth and may introduce Anglocentric biases. Commonsense reasoning is shaped by geographical and cultural contexts, and existing English datasets fail to capture the diversity of the Arab world. To address this, we introduce , a commonsense reasoning dataset in Modern Standard Arabic (MSA), covering cultures of 13 countries across the Gulf, Levant, North Africa, and the Nile Valley. The dataset was built from scratch by engaging native speakers to write and validate culturally relevant questions for their respective countries. spans 12 daily life domains with 54 fine-grained subtopics, reflecting various aspects of social norms, traditions, and everyday experiences. Zero-shot evaluations show that open-weight language models with up to 32B parameters struggle to comprehend diverse Arab cultures, with performance varying across regions. These findings highlight the need for more culturally aware models and datasets tailored to the Arabic-speaking world",
    "checked": true,
    "id": "4b88b2c113ff8f96ff835194c29c46f6ec8819f1",
    "semantic_title": "commonsense reasoning in arab culture",
    "citation_count": 1,
    "authors": [
      "Abdelrahman Sadallah",
      "Junior Cedric Tonga",
      "Khalid Almubarak",
      "Saeed Almheiri",
      "Farah Atif",
      "Chatrine Qwaider",
      "Karima Kadaoui",
      "Sara Shatnawi",
      "Yaser Alesh",
      "Fajri Koto"
    ]
  },
  "https://aclanthology.org/2025.acl-long.381": {
    "title": "AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents",
    "volume": "long",
    "abstract": "Multimodal large language models (MLLMs) have enabled LLM-based agents to directly interact with application user interfaces (UIs), enhancing agents' performance in complex tasks. However, these agents often suffer from high latency and low reliability due to the extensive sequential UI interactions. To address this issue, we propose AXIS, a novel LLM-based agents framework that prioritize actions through application programming interfaces (APIs) over UI actions. This framework also facilitates the creation and expansion of APIs through automated exploration of applications. Our experiments on Microsoft Word demonstrate that AXIS reduces task completion time by 65%-70% and cognitive workload by 38%-53%, while maintaining accuracy of 97%-98% compared to humans. Our work contributes to a new human-agent-computer interaction (HACI) framework and explores a fresh UI design principle for application providers to turn applications into agents in the era of LLMs, paving the way towards an agent-centric operating system (Agent OS). The code and dataset will be available at https://aka.ms/haci_axis",
    "checked": true,
    "id": "434c099f8fa439bcbea64e2ae7677e2b5fa76cd1",
    "semantic_title": "axis: efficient human-agent-computer interaction with api-first llm-based agents",
    "citation_count": 2,
    "authors": [
      "Junting Lu",
      "Zhiyang Zhang",
      "Fangkai Yang",
      "Jue Zhang",
      "Lu Wang",
      "Chao Du",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.382": {
    "title": "Translation and Fusion Improves Cross-lingual Information Extraction",
    "volume": "long",
    "abstract": "Large language models (LLMs) combined with instruction tuning have shown significant progress in information extraction (IE) tasks, exhibiting strong generalization capabilities to unseen datasets by following annotation guidelines. However, their applicability to low-resource languages remains limited due to lack of both labeled data for fine-tuning, and unlabeled text for pre-training. In this paper, we propose TransFusion, a framework in which models are fine-tuned to use English translations of low-resource language data, enabling more precise predictions through annotation fusion. Based on TransFusion, we introduce GoLLIE-TF, a cross-lingual instruction-tuned LLM for IE tasks, designed to close the performance gap between high and low-resource languages. Our experiments across twelve multilingual IE datasets spanning 50 languages demonstrate that GoLLIE-TF achieves better cross-lingual transfer over the base model. In addition, we show that TransFusion significantly improves low-resource language named entity recognition when applied to proprietary models such as GPT-4 (+5 F1) with a prompting approach, or fine-tuning different language models including decoder-only (+14 F1) and encoder-only (+13 F1) architectures",
    "checked": false,
    "id": "0f34d693a1ee131146eb6c5c85fb6a6d1c4a0f70",
    "semantic_title": "translation and fusion improves zero-shot cross-lingual information extraction",
    "citation_count": 4,
    "authors": [
      "Yang Chen",
      "Vedaant Shah",
      "Alan Ritter"
    ]
  },
  "https://aclanthology.org/2025.acl-long.383": {
    "title": "Conditional Dichotomy Quantification via Geometric Embedding",
    "volume": "long",
    "abstract": "Conditional dichotomy, the contrast between two outputs conditioned on the same context, is vital for applications such as debate, defeasible inference, and causal reasoning. Existing methods that rely on semantic similarity often fail to capture the nuanced oppositional dynamics essential for these applications. Motivated by these limitations, we introduce a novel task, Conditional Dichotomy Quantification (ConDQ), which formalizes the direct measurement of conditional dichotomy and provides carefully constructed datasets covering debate, defeasible natural language inference, and causal reasoning scenarios. To address this task, we develop the Dichotomy-oriented Geometric Embedding (DoGE) framework, which leverages complex-valued embeddings and a dichotomous objective to model and quantify these oppositional relationships effectively. Extensive experiments validate the effectiveness and versatility of DoGE, demonstrating its potential in understanding and quantifying conditional dichotomy across diverse NLP applications. Our code and datasets are available at https://github.com/cui-shaobo/conditional-dichotomy-quantification",
    "checked": false,
    "id": "f588f5f87158454ef2b5429584d7522967a5d282",
    "semantic_title": "dataset distillation via the wasserstein metric",
    "citation_count": 14,
    "authors": [
      "Shaobo Cui",
      "Wenqing Liu",
      "Yiyang Feng",
      "Jiawei Zhou",
      "Boi Faltings"
    ]
  },
  "https://aclanthology.org/2025.acl-long.384": {
    "title": "Aligning Large Language Models with Implicit Preferences from User-Generated Content",
    "volume": "long",
    "abstract": "Learning from preference feedback is essential for aligning large language models (LLMs) with human values and improving the quality of generated responses. However, existing preference learning methods rely heavily on curated data from humans or advanced LLMs, which is costly and difficult to scale. In this work, we present PUGC, a novel framework that leverages implicit human Preferences in unlabeled User-Generated Content (UGC) to generate preference data. Although UGC is not explicitly created to guide LLMs in generating human-preferred responses, it often reflects valuable insights and implicit preferences from its creators that has the potential to address readers' questions. PUGC transforms UGC into user queries and generates responses from the policy model. The UGC is then leveraged as a reference text for response scoring, aligning the model with these implicit preferences. This approach improves the quality of preference data while enabling scalable, domain-specific alignment. Experimental results on Alpaca Eval 2 show that models trained with DPO and PUGC achieve a 9.37% performance improvement over traditional methods, setting a 35.93% state-of-the-art length-controlled win rate using Mistral-7B-Instruct. Further studies highlight gains in reward quality, domain-specific alignment effectiveness, robustness against UGC quality, and theory of mind capabilities. Our code and dataset are available at https://zhaoxuan.info/PUGC.github.io/",
    "checked": true,
    "id": "828ab065d15c9516c633b54e3245ec08cc75a2f8",
    "semantic_title": "aligning large language models with implicit preferences from user-generated content",
    "citation_count": 0,
    "authors": [
      "Zhaoxuan Tan",
      "Zheng Li",
      "Tianyi Liu",
      "Haodong Wang",
      "Hyokun Yun",
      "Ming Zeng",
      "Pei Chen",
      "Zhihan Zhang",
      "Yifan Gao",
      "Ruijie Wang",
      "Priyanka Nigam",
      "Bing Yin",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.385": {
    "title": "VQAGuider: Guiding Multimodal Large Language Models to Answer Complex Video Questions",
    "volume": "long",
    "abstract": "Complex video question-answering (VQA) requires in-depth understanding of video contents including object and action recognition as well as video classification and summarization, which exhibits great potential in emerging applications in education and entertainment, etc. Multimodal large language models (MLLMs) may accomplish this task by grasping the intention of a question and decomposing it to a series of visual recognition sub-tasks to find out the answer with the help of an agent. To tackle this task, we first collect a new dedicated Complex VQA dataset named CVQA and then propose VQAGuider, an innovative framework planning a few atomic visual recognition tools by video-related API matching. VQAGuider facilitates a deep engagement with video content and precise responses to complex video-related questions by MLLMs, which is beyond aligning visual and language features for simple VQA tasks. Our experiments demonstrate VQAGuider is capable of navigating the complex VQA tasks by MLLMs and improves the accuracy by 29.6% and 17.2% on CVQA and the existing VQA datasets, respectively, highlighting its potential in advancing MLLMs's capabilities in video understanding",
    "checked": false,
    "id": "eb6b054789ff8c9edf7c1d50667be5bdd95e019b",
    "semantic_title": "cat: enhancing multimodal large language model to answer questions in dynamic audio-visual scenarios",
    "citation_count": 30,
    "authors": [
      "Yuyan Chen",
      "Jiyuan Jia",
      "Jiaxin Lu",
      "Siyue Li",
      "Yu Guan",
      "Ming Yang",
      "Qingpei Guo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.386": {
    "title": "Large Language Models are Good Relational Learners",
    "volume": "long",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents, but this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that employs a graph neural network (GNN) based encoder to create structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at https://github.com/smiles724/Rel-LLM",
    "checked": true,
    "id": "677e1cc9100d7f03c2c34a230cc36d5e269c62a0",
    "semantic_title": "large language models are good relational learners",
    "citation_count": 0,
    "authors": [
      "Fang Wu",
      "Vijay Prakash Dwivedi",
      "Jure Leskovec"
    ]
  },
  "https://aclanthology.org/2025.acl-long.387": {
    "title": "SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data",
    "volume": "long",
    "abstract": "Vision-language models (VLMs) work well in tasks ranging from image captioning to visual question answering (VQA), yet they struggle with spatial reasoning, a key skill for understanding our physical world that humans excel at. We find that spatial relations are generally rare in widely used VL datasets, with only a few being well represented, while most form a long tail of underrepresented relations. This gap leaves VLMs ill-equipped to handle diverse spatial relationships. To bridge it, we construct a synthetic VQA dataset focused on spatial reasoning generated from hyper-detailed image descriptions in Localized Narratives, DOCCI, and PixMo-Cap. Our dataset consists of 455k samples containing 3.4 million QA pairs. Trained on this dataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements on spatial reasoning benchmarks, achieving up to a 49% performance gain on the What's Up benchmark, while maintaining strong results on general tasks. Our work narrows the gap between human and VLM spatial reasoning and makes VLMs more capable in real-world tasks such as robotics and navigation. We plan to share our code and dataset in due course",
    "checked": true,
    "id": "4b788e3a4d82173e7d16d6cc887409f69b4350ed",
    "semantic_title": "spare: enhancing spatial reasoning in vision-language models with synthetic data",
    "citation_count": 0,
    "authors": [
      "Michael Ogezi",
      "Freda Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.388": {
    "title": "Distilling an End-to-End Voice Assistant Without Instruction Training Data",
    "volume": "long",
    "abstract": "Voice assistants, such as Siri and Google Assistant, typically model audio and text separately, resulting in lost speech information and increased complexity. Recent efforts to address this with end-to-end Speech Large Language Models (speech-in, text-out) trained with supervised finetuning (SFT) have led to models \"forgetting\" capabilities from text-only LLMs. Our work proposes an alternative paradigm for training Speech LLMs without instruction data, using the response of a text-only LLM to transcripts as self-supervision. Importantly, this process can be performed without annotated responses. We show that our Distilled Voice Assistant (DiVA) generalizes to Spoken Question Answering, Classification, and Translation. Furthermore, DiVA better matches user preferences, achieving a 72% win rate compared with state-of-the-art models like Qwen 2 Audio, despite using >100x less training compute",
    "checked": true,
    "id": "e0b943a7caa0604879417cd0181888930ede8947",
    "semantic_title": "distilling an end-to-end voice assistant without instruction training data",
    "citation_count": 17,
    "authors": [
      "William Barr Held",
      "Yanzhe Zhang",
      "Weiyan Shi",
      "Minzhi Li",
      "Michael J Ryan",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.389": {
    "title": "CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games",
    "volume": "long",
    "abstract": "Metaphors are a crucial way for humans to express complex or subtle ideas by comparing one concept to another, often from a different domain. However, many large language models (LLMs) struggle to interpret and apply metaphors in multi-agent language games, hindering their ability to engage in covert communication and semantic evasion, which are crucial for strategic communication. To address this challenge, we introduce CoMet, a framework that enables LLM-based agents to engage in metaphor processing. CoMet combines a hypothesis-based metaphor reasoner with a metaphor generator that improves through self-reflection and knowledge integration. This enhances the agents' ability to interpret and apply metaphors, improving the strategic and nuanced quality of their interactions. We evaluate CoMet on two multi-agent language games—Undercover and Adversarial Taboo—which emphasize \"covert communication\" and \"semantic evasion\". Experimental results demonstrate that CoMet significantly enhances the agents' ability to communicate strategically using metaphors",
    "checked": true,
    "id": "2a05f3c63829d752a46670eb4de9b9c6883fea1b",
    "semantic_title": "comet: metaphor-driven covert communication for multi-agent language games",
    "citation_count": 0,
    "authors": [
      "Shuhang Xu",
      "Fangwei Zhong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.390": {
    "title": "CER: Confidence Enhanced Reasoning in LLMs",
    "volume": "long",
    "abstract": "Ensuring the reliability of Large Language Models (LLMs) in complex reasoning tasks remains a formidable challenge, particularly in scenarios that demand precise mathematical calculations and knowledge-intensive open-domain generation. In this work, we introduce an uncertainty-aware framework designed to enhance the accuracy of LLM responses by systematically incorporating model confidence at critical decision points. We propose an approach that encourages multi-step reasoning in LLMs and quantify the confidence of intermediate answers such as numerical results in mathematical reasoning and proper nouns in open-domain generation. Then, the overall confidence of each reasoning chain is evaluated based on confidence of these critical intermediate steps. Finally, we aggregate the answer of generated response paths in a way that reflects the reliability of each generated content (as opposed to self-consistency in which each generated chain contributes equally to majority voting). We conducted extensive experiments in five datasets, three mathematical datasets and two open-domain datasets, using four LLMs. The results consistently validate the effectiveness of our novel confidence-aggregation method, leading to an accuracy improvement of up to 7.4% and 5.8% over baseline approaches in math and open-domain generation tasks, respectively. Code is publicly available at https://github.com/sharif-ml-lab/CER",
    "checked": true,
    "id": "ce04e5e571a1c64edfed8eda73383dcb18b4252b",
    "semantic_title": "cer: confidence enhanced reasoning in llms",
    "citation_count": 5,
    "authors": [
      "Ali Razghandi",
      "Seyed Mohammad Hadi Hosseini",
      "Mahdieh Soleymani Baghshah"
    ]
  },
  "https://aclanthology.org/2025.acl-long.391": {
    "title": "Watermarking Large Language Models: An Unbiased and Low-risk Method",
    "volume": "long",
    "abstract": "Recent advancements in large language models (LLMs) have highlighted the risk of misusing them, raising the need for accurate detection of LLM-generated content. In response, a viable solution is to inject imperceptible identifiers into LLMs, known as watermarks. Our research extends the existing watermarking methods by proposing the novel Sampling One Then Accepting (STA-1) method. STA-1 is an unbiased watermark that preserves the original token distribution in expectation and has a lower risk of producing unsatisfactory outputs in low-entropy scenarios compared to existing unbiased watermarks. In watermark detection, STA-1 does not require prompts or a white-box LLM, provides statistical guarantees, demonstrates high efficiency in detection time, and remains robust against various watermarking attacks. Experimental results on low-entropy and high-entropy datasets demonstrate that STA-1 achieves the above properties simultaneously, making it a desirable solution for watermarking LLMs. Implementation codes for this study are available online",
    "checked": false,
    "id": "2e2ff954edb11b09145d8cad2e8fd923f3f35ef3",
    "semantic_title": "watermarking low-entropy generation for large language models: an unbiased and low-risk method",
    "citation_count": 1,
    "authors": [
      "Minjia Mao",
      "Dongjun Wei",
      "Zeyu Chen",
      "Xiao Fang",
      "Michael Chau"
    ]
  },
  "https://aclanthology.org/2025.acl-long.392": {
    "title": "On Synthetic Data Strategies for Domain-Specific Generative Retrieval",
    "volume": "long",
    "abstract": "This paper investigates synthetic data generation strategies in developing generative retrieval models for domain-specific corpora, thereby addressing the scalability challenges inherent in manually annotating in-domain queries. We study the data strategies for a two-stage training framework: in the first stage, which focuses on learning to decode document identifiers from queries, we investigate LLM-generated queries across multiple granularity (e.g. chunks, sentences) and domain-relevant search constraints that can better capture nuanced relevancy signals. In the second stage, which aims to refine document ranking through preference learning, we explore the strategies for mining hard negatives based on the initial model's predictions. Experiments on public datasets over diverse domains demonstrate the effectiveness of our synthetic data generation and hard negative sampling approach",
    "checked": true,
    "id": "635e103bd463e3fe20a33d740f5402aeb8f969a7",
    "semantic_title": "on synthetic data strategies for domain-specific generative retrieval",
    "citation_count": 1,
    "authors": [
      "Haoyang Wen",
      "Jiang Guo",
      "Yi Zhang",
      "Jiarong Jiang",
      "Zhiguo Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.393": {
    "title": "LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates",
    "volume": "long",
    "abstract": "Recent findings reveal that much of the knowledge in a Transformer-based Large Language Model (LLM) is encoded in its feed-forward (FFN) layers, where each FNN layer can be interpreted as the summation of sub-updates, each corresponding to a weighted column vector from the FFN's value parameter matrix that often encodes human-interpretable concepts. In light of this, we hypothesize that model performance and behaviors can be further enhanced and controlled by modulating the contributions of these sub-updates based on their relevance to the input or target output style, and propose LLMBraces, a novel and efficient method that computes relevance scores associated with value vectors in FFN layers and leverages these scores to dynamically adjust the contribution of sub-updates. By optimizing sub-update contributions, LLMBraces refines the prediction process, leading to more accurate and reliable outputs, much like a ‘brace' providing support and stability. Moreover, LLMBraces can be extended to support conditional control over generation characteristics, such as sentiment, thereby offering fine-grained steering of LLM outputs. Extensive experiments on various LLMs—including Qwen2.5-1.5B, Llama2-7B, and Llama3-8B—demonstrate that LLMBraces outperforms baseline approaches in both fine-tuning and zero-shot settings while requiring significantly fewer tunable parameters, up to 75% fewer compared to LoRA. Furthermore, LLMBraces excels in sentiment-controlled generation and toxicity reduction, highlighting its potential for flexible, controlled text generation across applications",
    "checked": true,
    "id": "2d0b6bf15210eebb3b3e63ed69d3af132519f3b0",
    "semantic_title": "llm braces: straightening out llm predictions with relevant sub-updates",
    "citation_count": 2,
    "authors": [
      "Ying Shen",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.394": {
    "title": "CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions",
    "volume": "long",
    "abstract": "We introduce Conversational Function-Calling Evaluation Through Turn-Level Interactions (CONFETTI), a conversational benchmark designed to evaluate the function-calling capabilities and response quality of large language models (LLMs). Current benchmarks lack comprehensive assessment of LLMs in complex conversational scenarios. CONFETTI addresses this gap through 109 human-simulated conversations, comprising 313 user turns and covering 86 APIs. These conversations explicitly target various conversational complexities, such as follow-ups, goal correction and switching, ambiguous and implicit goals. We perform off-policy turn-level evaluation using this benchmark targeting function-calling. Our benchmark also incorporates dialog act annotations to assess agent responses. We evaluate a series of state-of-the-art LLMs and analyze their performance with respect to the number of available APIs, conversation lengths, and chained function calling. Our results reveal that while some models are able to handle long conversations, and leverage more than 20+ APIs successfully, other models struggle with longer context or when increasing the number of APIs. We also report that the performance on chained function-calls is severely limited across the models. Overall, the top performing models onCONFETTI are Nova Pro (40.01%), Claude Sonnet v3.5 (35.46%) and Llama 3.1 405B (33.19%) followed by command-r-plus (31.18%) and Mistral-Large-2407 (30.07%)",
    "checked": true,
    "id": "e3263f87b6a5f92c14ca77c132c307bd9c96ce89",
    "semantic_title": "confetti: conversational function-calling evaluation through turn-level interactions",
    "citation_count": 0,
    "authors": [
      "Tamer Alkhouli",
      "Katerina Margatina",
      "James Gung",
      "Raphael Shu",
      "Claudia Zaghi",
      "Monica Sunkara",
      "Yi Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.395": {
    "title": "Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others from Conversational Cues",
    "volume": "long",
    "abstract": "Typically, when evaluating Theory of Mind, we consider the beliefs of others to be binary: held or not held. But what if someone is unsure about their own beliefs? How can we quantify this uncertainty? We propose a new suite of tasks, challenging language models (LMs) to model the uncertainty of participants in a dialogue. We design these tasks around conversation forecasting, where the goal is to predict the probability of an unobserved conversation outcome. Uniquely, we view conversation agents themselves as forecasters, asking an LM to predict the uncertainty of an individual from their language use. We experiment with scaling methods, bagging, and demographic context for this regression task, conducting experiments on three dialogue corpora (social, negotiation, task-oriented) with eight LMs. While LMs can explain up to 7% variance in the uncertainty of others, we highlight the difficulty of the tasks and room for future work, especially in tasks that require explicit shifts in perspective",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anthony Sicilia",
      "Malihe Alikhani"
    ]
  },
  "https://aclanthology.org/2025.acl-long.396": {
    "title": "Uncertainty in Causality: A New Frontier",
    "volume": "long",
    "abstract": "Understanding uncertainty in causality is vital in various domains, including core NLP tasks like event causality extraction, commonsense reasoning, and counterfactual text generation. However, existing literature lacks a comprehensive examination of this area. This survey aims to fill this gap by thoroughly reviewing uncertainty in causality. We first introduce a novel trichotomy, categorizing causal uncertainty into aleatoric (inherent randomness in causal data), epistemic (causal model limitations), and ontological (existence of causal links) uncertainty. We then survey methods for quantifying uncertainty in causal analysis and highlight the complementary relationship between causal uncertainty and causal strength. Furthermore, we examine the challenges that large language models (LLMs) face in handling causal uncertainty, such as hallucinations and inconsistencies, and propose key traits for an optimal causal LLM. Our paper reviews current approaches and outlines future research directions, aiming to serve as a practical guide for researchers and practitioners in this emerging field",
    "checked": false,
    "id": "ed0d43610f4a81463632eb6c9c6cf9b4c8b0d697",
    "semantic_title": "a new dataset for causality identification in argumentative texts",
    "citation_count": 0,
    "authors": [
      "Shaobo Cui",
      "Luca Mouchel",
      "Boi Faltings"
    ]
  },
  "https://aclanthology.org/2025.acl-long.397": {
    "title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs",
    "volume": "long",
    "abstract": "Recent calls for pluralistic alignment of Large Language Models (LLMs) encourage adapting models to diverse user preferences. However, most prior work on personalized reward models heavily rely on additional identity information, such as demographic details or a predefined set of preference categories. To this end, we introduce SynthesizeMe, an approach to inducing synthetic user personas from user interactions for personalized reward modeling. SynthesizeMe first generates and verifies reasoning to explain user preferences, then induces synthetic user personas from that reasoning, and finally filters to informative prior user interactions in order to build personalized prompts for a particular user. We show that using SynthesizeMe induced prompts improves personalized LLM-as-a-judge accuracy by 4.4% on Chatbot Arena. Combining SynthesizeMe derived prompts with a reward model achieves top performance on PersonalRewardBench: a new curation of user-stratified interactions with chatbots collected from 854 users of Chatbot Arena and PRISM",
    "checked": true,
    "id": "8c497a6dfcaf431d1b4c932ae008b4ebe8a85883",
    "semantic_title": "synthesizeme! inducing persona-guided prompts for personalized reward models in llms",
    "citation_count": 0,
    "authors": [
      "Michael J Ryan",
      "Omar Shaikh",
      "Aditri Bhagirath",
      "Daniel Frees",
      "William Barr Held",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.398": {
    "title": "When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models",
    "volume": "long",
    "abstract": "Metaphor, discussing one concept in terms of another, is abundant in politics and can shape how people understand important issues. We develop a computational approach to measure metaphorical language, focusing on immigration discourse on social media. Grounded in qualitative social science research, we identify seven concepts evoked in immigration discourse (e.g. water or vermin). We propose and evaluate a novel technique that leverages both word-level and document-level signals to measure metaphor with respect to these concepts. We then study the relationship between metaphor, political ideology, and user engagement in 400K US tweets about immigration. While conservatives tend to use dehumanizing metaphors more than liberals, this effect varies widely across concepts. Moreover, creature-related metaphor is associated with more retweets, especially for liberal authors. Our work highlights the potential for computational methods to complement qualitative approaches in understanding subtle and implicit language in political discourse",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julia Mendelsohn",
      "Ceren Budak"
    ]
  },
  "https://aclanthology.org/2025.acl-long.399": {
    "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection",
    "volume": "long",
    "abstract": "The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments. These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios. However, their use as agents also introduces significant risks, including task-specific risks, which are identified by the agent administrator based on the specific task requirements and constraints, and systemic risks, which stem from vulnerabilities in their design or interactions, potentially compromising confidentiality, integrity, or availability (CIA) of information and triggering security risks. Existing defense agencies fail to adaptively and effectively mitigate these risks. In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility & flexibility. Extensive experiments demonstrate that AGrail not only achieves strong performance against task-specific and system risks but also exhibits transferability across different LLM agents' tasks",
    "checked": true,
    "id": "d83cd5896c58682aaa186f2fc791cd82bfd0cb9e",
    "semantic_title": "agrail: a lifelong agent guardrail with effective and adaptive safety detection",
    "citation_count": 8,
    "authors": [
      "Weidi Luo",
      "Shenghong Dai",
      "Xiaogeng Liu",
      "Suman Banerjee",
      "Huan Sun",
      "Muhao Chen",
      "Chaowei Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.400": {
    "title": "Improving Model Factuality with Fine-grained Critique-based Evaluator",
    "volume": "long",
    "abstract": "Factuality evaluation aims to detect factual errors produced by language models (LMs) and hence guide the development of more factual models. Towards this goal, we train a factuality evaluator, FenCE, that provides LM generators with claim-level factuality feedback. In particular, we train FenCE to (1) generate textual critiques along with scores and (2) make claim-level judgment based on diverse source documents obtained by various tools, via data augmentation on a combination of public judgment datasets. We then present a framework that leverages FenCE to improve the factuality of LM generators by constructing training data. Specifically, we generate a set of candidate responses, ask FenCE to revise and score each response without introducing lesser-known facts, and train the generator by preferring highly scored revised responses. Experiments show that our data augmentation methods improve the evaluator's accuracy by 2.9% on LLM-AggreFact. With FenCE, we improve Llama2-7B-chat/Llama3-8B-chat's factuality rate by 16.86%/14.45% on FActScore, outperforming state-of-the-art factuality finetuning methods by 8.83%/6.96%",
    "checked": true,
    "id": "97b909f98f3d50a9f40cdd0eea1a1501d73d7b5f",
    "semantic_title": "improving model factuality with fine-grained critique-based evaluator",
    "citation_count": 8,
    "authors": [
      "Yiqing Xie",
      "Wenxuan Zhou",
      "Pradyot Prakash",
      "Di Jin",
      "Yuning Mao",
      "Quintin Fettes",
      "Arya Talebzadeh",
      "Sinong Wang",
      "Han Fang",
      "Carolyn Rose",
      "Daniel Fried",
      "Hejia Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.401": {
    "title": "Building a Long Text Privacy Policy Corpus with Multi-Class Labels",
    "volume": "long",
    "abstract": "Legal text poses distinctive challenges for natural language processing. The legal import of a term may depend on omissions, cross-references, or silence, Further, legal text is often susceptible to multiple valid, conflicting interpretations; as the saying goes: a good lawyer's answer to any question is \"it depends.\"This work introduces a new, hand-coded dataset for the interpretation of privacy policies. It includes privacy policies from 149 firms, including materials incorporated by reference. The policies are annotated across 64 dimension that reflect the applicable legal rules and contested terms from EU and US privacy regulation and litigation. Our annotation methodology is designed to capture the capture core challenges peculiar to legal language, including indeterminacy, interdependence between clauses, meaningful silence, and the implications of legal defaults. We present a set of baseline results for the dataset using current large language models",
    "checked": true,
    "id": "1f79947ce8250a3a0afb8db02b9a6a8028b18169",
    "semantic_title": "building a long text privacy policy corpus with multi-class labels",
    "citation_count": 0,
    "authors": [
      "Florencia Marotta-Wurgler",
      "David Stein"
    ]
  },
  "https://aclanthology.org/2025.acl-long.402": {
    "title": "R2-MultiOmnia: Leading Multilingual Multimodal Reasoning via Self-Training",
    "volume": "long",
    "abstract": "Reasoning is an intricate process that transcends both language and vision; yet, despite its inherently modality-agnostic nature, develop-ing effective multilingual and multimodal reasoning capabilities remains a substantial challenge for Multimodal Large Language Models (MLLMs). They struggle to activate complex reasoning behaviours, delivering step-wise explanation, questioning and reflection, particularly in multilingual settings where high-quality supervision across languages is lacking. Recent works have introduced eclectic strategies to enhance MLLMs' reasoning; however, they remain related to a single language.To make MLLMs' reasoning capabilities aligned among languages and improve modality performances, we propose R2-MultiOmnia, a modular approach that instructs the models to abstract key elements of the reasoning process and then refine reasoning trajectories via self-correction. Specifically, we instruct the models producing multimodal synthetic resources by bridging modalities and then self-improving their capabilities. To stabilise learning and the reasoning processes structure, we propose Curriculum Learning Reasoning Stabilisation with structured output rewards to gradually refine the models' capabilities to learn and deliver robust reasoning processes. Experiments show that R2-MultiOmnia improves multimodal reasoning, gets aligned performances among the languages approaching strong models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leonardo Ranaldi",
      "Federico Ranaldi",
      "Giulia Pucci"
    ]
  },
  "https://aclanthology.org/2025.acl-long.403": {
    "title": "When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models",
    "volume": "long",
    "abstract": "Modern Large Language Models (LLMs) have shown human-like abilities in many language tasks, sparking interest in comparing LLMs' and humans' language processing. In this paper, we try to answer two questions: 1. What makes garden-path sentences hard to understand for humans? 2. Do the same reasons make garden-path sentences hard for LLMs as well? Based on psycholinguistic research, we formulate hypotheses on why garden-path sentences are hard, and test these hypotheses on human participants and a large suite of LLMs using comprehension questions. Our findings reveal that both LLMs and humans struggle with specific syntactic complexities, with some models showing high correlation with human comprehension. To complement our findings, we test LLM comprehension of garden-path constructions with paraphrasing and text-to-image generation tasks, and find that the results mirror the sentence comprehension question results, further validating our findings on LLM understanding of these constructions",
    "checked": true,
    "id": "d608d5fea9b50ac50c83dc1b94fc86e0bd2683b1",
    "semantic_title": "when the lm misunderstood the human chuckled: analyzing garden path effects in humans and language models",
    "citation_count": 1,
    "authors": [
      "Samuel Joseph Amouyal",
      "Aya Meltzer-Asscher",
      "Jonathan Berant"
    ]
  },
  "https://aclanthology.org/2025.acl-long.404": {
    "title": "Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in Natural Language Processing (NLP), yet their cross-lingual consistency remains a significant challenge. This paper introduces a novel methodology for efficiently identifying inherent cross-lingual weaknesses in LLMs. Our approach leverages beam search and LLM-based simulation to generate bilingual question pairs that expose performance discrepancies between English and target languages. We construct a new dataset of over 6,000 bilingual pairs across 16 languages using this methodology, demonstrating its effectiveness in revealing weaknesses even in state-of-the-art models. The extensive experiments demonstrate that our method precisely and cost-effectively pinpoints cross-lingual weaknesses, consistently revealing over 50% accuracy drops in target languages across a wide range of models. Moreover, further experiments investigate the relationship between linguistic similarity and cross-lingual weaknesses, revealing that linguistically related languages share similar performance patterns and benefit from targeted post-training. Code is available at https://github.com/xzx34/Cross-Lingual-Pitfalls",
    "checked": true,
    "id": "94baebdf43eb524d6e529d1fa3335022842f1d75",
    "semantic_title": "cross-lingual pitfalls: automatic probing cross-lingual weakness of multilingual large language models",
    "citation_count": 0,
    "authors": [
      "Zixiang Xu",
      "Yanbo Wang",
      "Yue Huang",
      "Xiuying Chen",
      "Jieyu Zhao",
      "Meng Jiang",
      "Xiangliang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.405": {
    "title": "VLSBench: Unveiling Visual Leakage in Multimodal Safety",
    "volume": "long",
    "abstract": "Safety concerns of Multimodal large language models (MLLMs) have gradually become an important problem in various applications. Surprisingly, previous works indicate a counterintuitive phenomenon that using textual unlearning to align MLLMs achieves comparable safety performances with MLLMs aligned with image-text pairs. To explain such a phenomenon, we discover a Visual Safety Information Leakage (VSIL) problem in existing multimodal safety benchmarks, i.e., the potentially risky content in the image has been revealed in the textual query. Thus, MLLMs can easily refuse these sensitive image-text pairs according to textual queries only, leading to unreliable cross-modality safety evaluation of MLLMs. We also conduct a further comparison experiment between textual alignment and multimodal alignment to highlight this drawback. To this end, we construct Visual Leakless Safety Bench (VLSBench) with 2.2k image-text pairs through an automated data pipeline. Experimental results indicate that VLSBench poses a significant challenge to both open-source and close-source MLLMs, i.e., LLaVA, Qwen2-VL and GPT-4o. Besides, we empirically compare textual and multimodal alignment methods on VLSBench and find that textual alignment is effective enough for multimodal safety scenarios with VSIL, while multimodal alignment is preferable for safety scenarios without VSIL",
    "checked": true,
    "id": "fb498ce0560e7360b585afa0c9b4d41f77cb217e",
    "semantic_title": "vlsbench: unveiling visual leakage in multimodal safety",
    "citation_count": 20,
    "authors": [
      "Xuhao Hu",
      "Dongrui Liu",
      "Hao Li",
      "Xuanjing Huang",
      "Jing Shao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.406": {
    "title": "Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning",
    "volume": "long",
    "abstract": "We introduce Browsing Lost Unformed Recollections, a tip-of-the-tongue known-item search and reasoning benchmark for general AI assistants. BLUR introduces a set of 573 real-world validated questions that demand searching and reasoning across multimodal and multilingual inputs, as well as proficient tool use, in order to excel on. Humans easily ace these questions (scoring on average 98%), while the best-performing system scores around 56%. To facilitate progress toward addressing this challenging and aspirational use case for general AI assistants, we release 350 questions through a public leaderboard, retain the answers to 250 of them, and have the rest as a private test set",
    "checked": true,
    "id": "156cc3bd7938527b74d004bd1fb653f97cc5131f",
    "semantic_title": "browsing lost unformed recollections: a benchmark for tip-of-the-tongue search and reasoning",
    "citation_count": 1,
    "authors": [
      "Sky CH-Wang",
      "Darshan Girish Deshpande",
      "Smaranda Muresan",
      "Anand Kannappan",
      "Rebecca Qian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.407": {
    "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation",
    "volume": "long",
    "abstract": "In this paper, we show that knowledge distillation can be subverted to manipulate language model benchmark scores, revealing a critical vulnerability in current evaluation practices. We introduce \"Data Laundering,\" a process that enables the covert transfer of benchmark-specific knowledge through seemingly legitimate intermediate training steps. Through extensive experiments with a 2-layer BERT student model, we show how this approach can achieve substantial improvements in benchmark accuracy (up to 75% on GPQA) without developing genuine reasoning capabilities. Notably, this method can be exploited intentionally or even unintentionally, as researchers may inadvertently adopt this method and inflate scores without realising the implications. While our findings demonstrate the effectiveness of this technique, we present them as a cautionary tale highlighting the urgent need for more robust evaluation methods in AI. This work aims to contribute to the ongoing discussion about evaluation integrity in AI development and the need for benchmarks that more accurately reflect true model capabilities. The code is available at https://github.com/mbzuai-nlp/data_laundering",
    "checked": true,
    "id": "d308f5b72bb8cc32a00923feaf76e6681595ae92",
    "semantic_title": "data laundering: artificially boosting benchmark results through knowledge distillation",
    "citation_count": 2,
    "authors": [
      "Jonibek Mansurov",
      "Akhmed Sakip",
      "Alham Fikri Aji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.408": {
    "title": "Conspiracy Theories and Where to Find Them on TikTok",
    "volume": "long",
    "abstract": "TikTok has skyrocketed in popularity over recent years, especially among younger audiences. However, there are public concerns about the potential of this platform to promote and amplify harmful content. This study presents the first systematic analysis of conspiracy theories on TikTok. By leveraging the official TikTok Research API we collect a longitudinal dataset of 1.5M videos shared in the U.S. over three years. We estimate a lower bound on the prevalence of conspiratorial videos (up to 1000 new videos per month) and evaluate the effects of TikTok's Creativity Program for monetization, observing an overall increase in video duration regardless of content. Lastly, we evaluate the capabilities of state-of-the-art open-weight Large Language Models to identify conspiracy theories from audio transcriptions of videos. While these models achieve high precision in detecting harmful content (up to 96%), their overall performance remains comparable to fine-tuned traditional models such as RoBERTa. Our findings suggest that Large Language Models can serve as an effective tool for supporting content moderation strategies aimed at reducing the spread of harmful content on TikTok",
    "checked": true,
    "id": "3d43078b0c305e3ced1ddc660ec041db59a0941d",
    "semantic_title": "conspiracy theories and where to find them on tiktok",
    "citation_count": 3,
    "authors": [
      "Francesco Corso",
      "Francesco Pierri",
      "Gianmarco De Francisci Morales"
    ]
  },
  "https://aclanthology.org/2025.acl-long.409": {
    "title": "Growing Through Experience: Scaling Episodic Grounding in Language Models",
    "volume": "long",
    "abstract": "Language models (LMs) require effective episodic grounding—the ability to learn from and apply past experiences—to perform well at physical planning tasks. While current approaches struggle with scalability and integration of episodic memory, which is particularly limited for medium-sized LMs (7B parameters), larger LMs (70-405B) offer untapped potential through their hierarchical representations and extensive pre-trained knowledge. Therefore, to unlock larger LMs' potential for grounding, we present a scalable weak-to-strong episodic learning framework that efficiently transfers episodic behaviors from smaller to larger LMs. It uses Monte Carlo tree search for structured experience collection with a novel distillation method that preserves LM capabilities while incorporating episodic memory. This enables larger LMs to leverage their inherent advantages for improved physical planning. Experiments show our solution outperforms top proprietary LMs by 3.45% across diverse planning and question-answering tasks. Layer-wise probing reveals systematic improvements in task alignment, particularly in later LM layers. It shows stable generalization to even unseen scenarios, even as planning steps increase, whereas baselines deteriorate sharply beyond a complexity threshold of four planning steps",
    "checked": true,
    "id": "c696d905e70197ce4d1d7bbaee25db680a0d62e3",
    "semantic_title": "growing through experience: scaling episodic grounding in language models",
    "citation_count": 1,
    "authors": [
      "Chunhui Zhang",
      "Sirui Wang",
      "Zhongyu Ouyang",
      "Xiangchi Yuan",
      "Soroush Vosoughi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.410": {
    "title": "Exploiting the Shadows: Unveiling Privacy Leaks through Lower-Ranked Tokens in Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) play a crucial role in modern applications but face vulnerabilities related to the extraction of sensitive information. This includes unauthorized accesses to internal prompts and retrieval of personally identifiable information (PII) (e.g., in Retrieval-Augmented Generation based agentic applications). We examine these vulnerabilities in a question-answering (QA) setting where LLMs use retrieved documents or training knowledge as few-shot prompts. Although these documents remain confidential under normal use, adversaries can manipulate input queries to extract private content. In this paper, we propose a novel attack method by exploiting the model's lower-ranked output tokens to leak sensitive information. We systematically evaluate our method, demonstrating its effectiveness in both the agentic application privacy extraction setting and the direct training data extraction. These findings reveal critical privacy risks in LLMs and emphasize the urgent need for enhanced safeguards against information leakage",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Zhou",
      "Zhuo Zhang",
      "Xiangyu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.411": {
    "title": "Attacking Vision-Language Computer Agents via Pop-ups",
    "volume": "long",
    "abstract": "Autonomous agents powered by large vision and language models (VLM) have demonstrated significant potential in completing daily computer tasks, such as browsing the web to book travel and operating desktop software, which requires agents to understand these interfaces. Despite such visual inputs becoming more integrated into agentic applications, what types of risks and attacks exist around them still remain unclear. In this work, we demonstrate that VLM agents can be easily attacked by a set of carefully designed adversarial pop-ups, which human users would typically recognize and ignore. This distraction leads agents to click these pop-ups instead of performing their tasks as usual. Integrating these pop-ups into existing agent testing environments like OSWorld and VisualWebArena leads to an attack success rate (the frequency of the agent clicking the pop-ups) of 86% on average and decreases the task success rate by 47%. Basic defense techniques, such as asking the agent to ignore pop-ups or including an advertisement notice, are ineffective against the attack. Code is available at [this link](https://github.com/SALT-NLP/PopupAttack)",
    "checked": true,
    "id": "6e4d3bee0ce7129b0f81c61f037ba4ca16f6395b",
    "semantic_title": "attacking vision-language computer agents via pop-ups",
    "citation_count": 34,
    "authors": [
      "Yanzhe Zhang",
      "Tao Yu",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.412": {
    "title": "Explicit and Implicit Data Augmentation for Social Event Detection",
    "volume": "long",
    "abstract": "Social event detection involves identifying and categorizing important events from social media, which relies on labeled data, but annotation is costly and labor-intensive. To address this problem, we propose Augmentation framework for Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework, which combines explicit text-based and implicit feature-space augmentation to enhance data diversity and model robustness. The explicit augmentation utilizes LLMs to enhance textual information through five diverse generation strategies. For implicit augmentation, we design five novel perturbation techniques that operate in the feature space on structural fused embeddings. These perturbations are crafted to keep the semantic and relational properties of the embeddings and make them more diverse. Specifically, SED-Aug outperforms the best baseline model by approximately 17.67% on the Twitter2012 dataset and by about 15.57% on the Twitter2018 dataset in terms of the average F1 score",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Congbo Ma",
      "Yuxia Wang",
      "Jia Wu",
      "Jian Yang",
      "Jing Du",
      "Zitai Qiu",
      "Qing Li",
      "Hu Wang",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2025.acl-long.413": {
    "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have made significant progress in open-ended dialogue, yet their inability to retain and retrieve relevant information from long-term interactions limits their effectiveness in applications requiring sustained personalization. External memory mechanisms have been proposed to address this limitation, enabling LLMs to maintain conversational continuity. However, existing approaches struggle with two key challenges. First, rigid memory granularity fails to capture the natural semantic structure of conversations, leading to fragmented and incomplete representations. Second, fixed retrieval mechanisms cannot adapt to diverse dialogue contexts and user interaction patterns. In this work, we propose Reflective Memory Management (RMM), a novel mechanism for long-term dialogue agents, integrating forward- and backward-looking reflections: (1) Prospective Reflection, which dynamically summarizes interactions across granularities—utterances, turns, and sessions—into a personalized memory bank for effective future retrieval, and (2) Retrospective Reflection, which iteratively refines the retrieval in an online reinforcement learning (RL) manner based on LLMs' cited evidence. Experiments show that RMM demonstrates consistent improvement across various metrics and benchmarks. For example, RMM shows more than 10% accuracy improvement over the baseline without memory management on the LongMemEval dataset",
    "checked": true,
    "id": "fc669d9b8460d21a1a1d2bff6cef7270c4e2dee3",
    "semantic_title": "in prospect and retrospect: reflective memory management for long-term personalized dialogue agents",
    "citation_count": 2,
    "authors": [
      "Zhen Tan",
      "Jun Yan",
      "I-Hung Hsu",
      "Rujun Han",
      "Zifeng Wang",
      "Long Le",
      "Yiwen Song",
      "Yanfei Chen",
      "Hamid Palangi",
      "George Lee",
      "Anand Rajan Iyer",
      "Tianlong Chen",
      "Huan Liu",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ]
  },
  "https://aclanthology.org/2025.acl-long.414": {
    "title": "Revisiting Classical Chinese Event Extraction with Ancient Literature Information",
    "volume": "long",
    "abstract": "The research on classical Chinese event extraction trends to directly graft the complex modeling from English or modern Chinese works, neglecting the utilization of the unique characteristic of this language. We argue that, compared with grafting the sophisticated methods from other languages, focusing on classical Chinese's inimitable source of __Ancient Literature__ could provide us with extra and comprehensive semantics in event extraction. Motivated by this, we propose a Literary Vision-Language Model (VLM) for classical Chinese event extraction, integrating with literature annotations, historical background and character glyph to capture the inner- and outer-context information from the sequence. Extensive experiments build a new state-of-the-art performance in the GuwenEE, CHED datasets, which underscores the effectiveness of our proposed VLM, and more importantly, these unique features can be obtained precisely at nearly zero cost",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyi Bao",
      "Zhongqing Wang",
      "Jinghang Gu",
      "Chu-Ren Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.415": {
    "title": "Unanswerability Evaluation for Retrieval Augmented Generation",
    "volume": "long",
    "abstract": "Existing evaluation frameworks for retrieval-augmented generation (RAG) systems focus on answerable queries, but they overlook the importance of appropriately rejecting unanswerable requests. In this paper, we introduce UAEval4RAG, a comprehensive evaluation framework designed to evaluate whether RAG systems effectively handle unanswerable queries specific to a given knowledge base. We first define a taxonomy with six unanswerable categories, and UAEval4RAG automatically synthesizes diverse and challenging queries for any given knowledge base and evaluate the RAG systems with unanswered ratio and acceptable ratio metrics. We also conduct experiments with various RAG components and prompting strategies across four datasets, which reveals that due to varying knowledge distribution across datasets, no single configuration consistently delivers optimal performance on both answerable and unanswerable requests across different knowledge bases. Our findings highlight the critical role of component selection and prompt design in optimizing RAG systems to balance the accuracy of answerable queries with high rejection rates of unanswerable ones. UAEval4RAG provides valuable insights and tools for developing more robust and reliable RAG systems",
    "checked": true,
    "id": "ab61d963dd55a4ca10ff4b3a63e4f642cb2eca22",
    "semantic_title": "unanswerability evaluation for retrieval augmented generation",
    "citation_count": 0,
    "authors": [
      "Xiangyu Peng",
      "Prafulla Kumar Choubey",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.416": {
    "title": "SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention",
    "volume": "long",
    "abstract": "Content analysis breaks down complex and unstructured texts into theory-informed numerical categories. Particularly, in social science, this process usually relies on multiple rounds of manual annotation, domain expert discussion, and rule-based refinement. In this paper, we introduce SCALE, a novel multi-agent framework that effectively ̲Simulates ̲Content ̲Analysis via ̲Large language model (LLM) ag ̲Ents. SCALE imitates key phases of content analysis, including text coding, collaborative discussion, and dynamic codebook evolution, capturing the reflective depth and adaptive discussions of human researchers. Furthermore, by integrating diverse modes of human intervention, SCALE is augmented with expert input to further enhance its performance. Extensive evaluations on real-world datasets demonstrate that SCALE achieves human-approximated performance across various complex content analysis tasks, offering an innovative potential for future social science research",
    "checked": true,
    "id": "c7904c4f20ee9a1ef11147f6f582cf0d3498da31",
    "semantic_title": "scale: towards collaborative content analysis in social science with large language model agents and human intervention",
    "citation_count": 2,
    "authors": [
      "Chengshuai Zhao",
      "Zhen Tan",
      "Chau-Wai Wong",
      "Xinyan Zhao",
      "Tianlong Chen",
      "Huan Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.417": {
    "title": "Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning",
    "volume": "long",
    "abstract": "Although large language models demonstrate strong performance across various domains, they still struggle with numerous bad cases in mathematical reasoning. Previous approaches to learning from errors synthesize training data by solely extrapolating from isolated bad cases, thereby failing to generalize the extensive patterns inherent within these cases. This paper presents Self-Error-Instruct (SEI), a framework that addresses these model weaknesses and synthesizes more generalized targeted training data. Specifically, we explore a target model on two mathematical datasets, GSM8K and MATH, to pinpoint bad cases. Then, we generate error keyphrases for these cases based on the instructor model's (GPT-4o) analysis and identify error types by clustering these keyphrases. Next, we sample a few bad cases during each generation for each identified error type and input them into the instructor model, which synthesizes additional training data using a self-instruct approach. This new data is refined through a one-shot learning process to ensure that only the most effective examples are kept. Finally, we use these curated data to fine-tune the target model, iteratively repeating the process to enhance performance. We apply our framework to various models and observe improvements in their reasoning abilities across both in-domain and out-of-domain mathematics datasets. These results demonstrate the effectiveness of self-error instruction in improving LLMs' mathematical reasoning through error generalization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Erxin Yu",
      "Jing Li",
      "Ming Liao",
      "Qi Zhu",
      "Boyang Xue",
      "Minghui Xu",
      "Baojun Wang",
      "Lanqing Hong",
      "Fei Mi",
      "Lifeng Shang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.418": {
    "title": "RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) is a powerful approach that enables large language models (LLMs) to incorporate external knowledge. However, evaluating the effectiveness of RAG systems in specialized scenarios remains challenging due to the high costs of data construction and the lack of suitable evaluation metrics. This paper introduces RAGEval, a framework designed to assess RAG systems across diverse scenarios by generating high-quality documents, questions, answers, and references through a schema-based pipeline. With a focus on factual accuracy, we propose three novel metrics—Completeness, Hallucination, and Irrelevance—to evaluate LLM-generated responses rigorously. Experimental results show that RAGEval outperforms zero-shot and one-shot methods in terms of clarity, safety, conformity, and richness of generated samples. Furthermore, the use of LLMs for scoring the proposed metrics demonstrates a high level of consistency with human evaluations. RAGEval establishes a new paradigm for evaluating RAG systems in real-world applications. The code and dataset are released at https://github.com/OpenBMB/RAGEval",
    "checked": true,
    "id": "e3e13a31a839912aa8d0b62bbcd9906ff49512c9",
    "semantic_title": "rageval: scenario specific rag evaluation dataset generation framework",
    "citation_count": 21,
    "authors": [
      "Kunlun Zhu",
      "Yifan Luo",
      "Dingling Xu",
      "Yukun Yan",
      "Zhenghao Liu",
      "Shi Yu",
      "Ruobing Wang",
      "Shuo Wang",
      "Yishan Li",
      "Nan Zhang",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.419": {
    "title": "A Survey on Patent Analysis: From NLP to Multimodal AI",
    "volume": "long",
    "abstract": "Recent advances in Pretrained Language Models (PLMs) and Large Language Models (LLMs) have demonstrated transformative capabilities across diverse domains. The field of patent analysis and innovation is not an exception, where natural language processing (NLP) techniques presents opportunities to streamline and enhance important tasks—such as patent classification and patent retrieval—in the patent cycle. This not only accelerates the efficiency of patent researchers and applicants, but also opens new avenues for technological innovation and discovery. Our survey provides a comprehensive summary of recent NLP-based methods—including multimodal ones—in patent analysis. We also introduce a novel taxonomy for categorization based on tasks in the patent life cycle, as well as the specifics of the methods. This interdisciplinary survey aims to serve as a comprehensive resource for researchers and practitioners who work at the intersection of NLP, Multimodal AI, and patent analysis, as well as patent offices to build efficient patent systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Homaira Huda Shomee",
      "Zhu Wang",
      "Sathya N. Ravi",
      "Sourav Medya"
    ]
  },
  "https://aclanthology.org/2025.acl-long.420": {
    "title": "SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification",
    "volume": "long",
    "abstract": "We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context.SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common reasoning type in multimodal scientific claim verification. To enable fine-grained evaluation, each example includes expert-annotated supporting evidence.We assess the performance of 21 state-of-the-art multimodal foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and Qwen2.5-VL. Our experiment reveals a substantial performance gap between these models and human experts on SciVer.Through an in-depth analysis of retrieval-augmented generation (RAG), and human-conducted error evaluations, we identify critical limitations in current open-source models, offering key insights to advance models' comprehension and reasoning in multimodal scientific literature tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengye Wang",
      "Yifei Shen",
      "Zexi Kuang",
      "Arman Cohan",
      "Yilun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.421": {
    "title": "MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents; yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios. Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators. Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning. Notably, cognitive planning improves milestone achievement rates by 3%. Code and dataset will be made publicly available. Code and datasets are publicavailable at https://github.com/ulab-uiuc/MARBLE",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunlun Zhu",
      "Hongyi Du",
      "Zhaochen Hong",
      "Xiaocheng Yang",
      "Shuyi Guo",
      "Zhe Wang",
      "Zhenhailong Wang",
      "Cheng Qian",
      "Robert Tang",
      "Heng Ji",
      "Jiaxuan You"
    ]
  },
  "https://aclanthology.org/2025.acl-long.422": {
    "title": "Sinhala Encoder-only Language Models and Evaluation",
    "volume": "long",
    "abstract": "Recently, language models (LMs) have produced excellent results in many natural language processing (NLP) tasks. However, their effectiveness is highly dependent on available pre-training resources, which is particularly challenging for low-resource languages such as Sinhala. Furthermore, the scarcity of benchmarks to evaluate LMs is also a major concern for low-resource languages. In this paper, we address these two challenges for Sinhala by (i) collecting the largest monolingual corpus for Sinhala, (ii) training multiple LMs on this corpus and (iii) compiling the first Sinhala NLP benchmark (Sinhala-GLUE) and evaluating LMs on it. We show the Sinhala LMs trained in this paper outperform the popular multilingual LMs, such as XLM-R and existing Sinhala LMs in downstream NLP tasks. All the trained LMs are publicly available. We also make Sinhala-GLUE publicly available as a public leaderboard, and we hope that it will enable further advancements in developing and evaluating LMs for Sinhala",
    "checked": false,
    "id": "2f654be328fa62574d66f14583c844e773822f0c",
    "semantic_title": "continual learning for encoder-only language models via a discrete key-value bottleneck",
    "citation_count": 0,
    "authors": [
      "Tharindu Ranasinghe",
      "Hansi Hettiarachchi",
      "Nadeesha Chathurangi Naradde Vidana Pathirana",
      "Damith Premasiri",
      "Lasitha Uyangodage",
      "Isuri Nanomi Arachchige",
      "Alistair Plum",
      "Paul Rayson",
      "Ruslan Mitkov"
    ]
  },
  "https://aclanthology.org/2025.acl-long.423": {
    "title": "LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case Study of L2 Graduate-Level Academic English Writing",
    "volume": "long",
    "abstract": "The paper explores the performance of LLMs in the context of multi-dimensional analytic writing assessments, i.e. their ability to provide both scores and comments based on multiple assessment criteria. Using a corpus of literature reviews written by L2 graduate students and assessed by human experts against 9 analytic criteria, we prompt several popular LLMs to perform the same task under various conditions. To evaluate the quality of feedback comments, we apply a novel feedback comment quality evaluation framework. This framework is interpretable, cost-efficient, scalable, and reproducible, compared to existing methods that rely on manual judgments. We find that LLMs can generate reasonably good and generally reliable multi-dimensional analytic assessments. We release our corpus and code for reproducibility",
    "checked": true,
    "id": "fd5fe9840bf0a2d86683f6dcbd42e1c4db8c3730",
    "semantic_title": "llms can perform multi-dimensional analytic writing assessments: a case study of l2 graduate-level academic english writing",
    "citation_count": 1,
    "authors": [
      "Zhengxiang Wang",
      "Veronika Makarova",
      "Zhi Li",
      "Jordan Kodner",
      "Owen Rambow"
    ]
  },
  "https://aclanthology.org/2025.acl-long.424": {
    "title": "SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?",
    "volume": "long",
    "abstract": "Recent advancements in LLMs unlearning have shown remarkable success in removing unwanted data-model influences while preserving the model's utility for legitimate knowledge. Despite these strides, sparse Mixture-of-Experts (MoE) LLMs–a key subset of the LLM family–have remained unexplored in the context of unlearning. As MoE LLMs are celebrated for their exceptional performance, we ask:How can unlearning be performed effectively and efficiently on MoE LLMs? Our pilot study shows that the dynamic routing nature of MoE LLMs introduces unique challenges, leading to excessive forgetting, uncontrolled knowledge erasure and substantial utility drops when existing unlearning methods are applied. To address this, we propose a novel Selected-Expert Unlearning Framework (SEUF). Through expert attribution, unlearning is concentrated on the most actively engaged experts for the specified knowledge. Concurrently, an anchor loss is applied to the router to stabilize the active state of this targeted expert, ensuring focused and controlled unlearning. SEUF is compatible with various standard unlearning algorithms. Extensive experiments demonstrate that SEUF enhances both forget quality up to 5% and model utility by 35% on MoE LLMs across various benchmarks and LLM architectures (compared to standard unlearning algorithms), while only unlearning 0.06% of the model parameters",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haomin Zhuang",
      "Yihua Zhang",
      "Kehan Guo",
      "Jinghan Jia",
      "Gaowen Liu",
      "Sijia Liu",
      "Xiangliang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.425": {
    "title": "Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges",
    "volume": "long",
    "abstract": "Understanding pragmatics—the use of language in context—is crucial for developing NLP systems capable of interpreting nuanced language use. Despite recent advances in language technologies, including large language models, evaluating their ability to handle pragmatic phenomena such as implicatures and references remains challenging. To advance pragmatic abilities in models, it is essential to understand current evaluation trends and identify existing limitations. In this survey, we provide a comprehensive review of resources designed for evaluating pragmatic capabilities in NLP, categorizing datasets by the pragmatic phenomena they address. We analyze task designs, data collection methods, evaluation approaches, and their relevance to real-world applications. By examining these resources in the context of modern language models, we highlight emerging trends, challenges, and gaps in existing benchmarks. Our survey aims to clarify the landscape of pragmatic evaluation and guide the development of more comprehensive and targeted benchmarks, ultimately contributing to more nuanced and context-aware NLP models",
    "checked": true,
    "id": "483eed7480608e81fa42814cdfc92589eb96e77e",
    "semantic_title": "pragmatics in the era of large language models: a survey on datasets, evaluation, opportunities and challenges",
    "citation_count": 4,
    "authors": [
      "Bolei Ma",
      "Yuting Li",
      "Wei Zhou",
      "Ziwei Gong",
      "Yang Janet Liu",
      "Katja Jasinskaja",
      "Annemarie Friedrich",
      "Julia Hirschberg",
      "Frauke Kreuter",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2025.acl-long.426": {
    "title": "LocAgent: Graph-Guided LLM Agents for Code Localization",
    "volume": "long",
    "abstract": "Code localization–identifying precisely where in a codebase changes need to be made–is a fundamental yet challenging task in software maintenance. Existing approaches struggle to efficiently navigate complex codebases when identifying relevant code snippets.The challenge lies in bridging natural language problem descriptions with the target code elements, often requiring reasoning across hierarchical structures and multiple dependencies.We introduce LocAgent, a framework that addresses code localization through a graph-guided agent.By parsing codebases into directed heterogeneous graphs, LocAgent creates a lightweight representation that captures code structures and their dependencies, enabling LLM agents to effectively search and locate relevant entities through powerful multi-hop reasoning.Experimental results on real-world benchmarks demonstrate that our approach significantly enhances accuracy in code localization.Notably, our method with the fine-tuned Qwen-2.5-Coder-Instruct-32B model achieves comparable results to SOTA proprietary models at greatly reduced cost (approximately 86% reduction), reaching up to 92.7% accuracy on file-level localization while improving downstream GitHub issue resolution success rates by 12% for multiple attempts (Pass@10). Our code is available at https://github.com/gersteinlab/LocAgent",
    "checked": true,
    "id": "97b2ba5dc2e90b45a8d8a0aa9f3ec200fbf4e668",
    "semantic_title": "locagent: graph-guided llm agents for code localization",
    "citation_count": 8,
    "authors": [
      "Zhaoling Chen",
      "Robert Tang",
      "Gangda Deng",
      "Fang Wu",
      "Jialong Wu",
      "Zhiwei Jiang",
      "Viktor Prasanna",
      "Arman Cohan",
      "Xingyao Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.427": {
    "title": "COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation",
    "volume": "long",
    "abstract": "Despite progress in comment-aware multimodal and multilingual summarization for English and Chinese, research in Indian languages remains limited. This study addresses this gap by introducing COSMMIC, a pioneering comment-sensitive multimodal, multilingual dataset featuring nine major Indian languages. COSMMIC comprises 4,959 article-image pairs and 24,484 reader comments, with ground-truth summaries available in all included languages. Our approach enhances summaries by integrating reader insights and feedback. We explore summarization and headline generation across four configurations: (1) using article text alone, (2) incorporating user comments, (3) utilizing images, and (4) combining text, comments, and images. To assess the dataset's effectiveness, we employ state-of-the-art language models such as LLama3 and GPT-4. We conduct a comprehensive study to evaluate different component combinations, including identifying supportive comments, filtering out noise using a dedicated comment classifier using IndicBERT, and extracting valuable insights from images with a multilingual CLIP-based classifier. This helps determine the most effective configurations for natural language generation (NLG) tasks. Unlike many existing datasets that are either text-only or lack user comments in multimodal settings, COSMMIC uniquely integrates text, images, and user feedback. This holistic approach bridges gaps in Indian language resources, advancing NLP research and fostering inclusivity",
    "checked": true,
    "id": "afacb87382c55352712e9b1e3f9386cf5585f520",
    "semantic_title": "cosmmic: comment-sensitive multimodal multilingual indian corpus for summarization and headline generation",
    "citation_count": 0,
    "authors": [
      "Raghvendra Kumar",
      "Mohammed Salman S A",
      "Aryan Sahu",
      "Tridib Nandi",
      "Pragathi Y P",
      "Sriparna Saha",
      "Jose G Moreno"
    ]
  },
  "https://aclanthology.org/2025.acl-long.428": {
    "title": "Mind the Gap: Static and Interactive Evaluations of Large Audio Models",
    "volume": "long",
    "abstract": "As AI chatbots become ubiquitous, voice interaction presents a compelling way to enable rapid, high-bandwidth communication for both semantic and social signals. This has driven research into Large Audio Models (LAMs) to power voice-native experiences. However, aligning LAM development with user goals requires a clear understanding of user needs and preferences to establish reliable progress metrics. This study addresses these challenges by introducing an interactive approach to evaluate LAMs and collecting 7,500 LAM interactions from 484 participants. Through topic modeling of user queries, we identify primary use cases for audio interfaces. We then analyze user preference rankings and qualitative feedback to determine which models best align with user needs. Finally, we evaluate how static benchmarks predict interactive performance - our analysis reveals no individual benchmark strongly correlates with interactive results (𝜏 ≤ 0.33 for all benchmarks). While combining multiple coarse-grained features yields modest predictive power (R2=0.30), only two out of twenty datasets on spoken question answering and age prediction show significantly positive correlations. This suggests a clear need to develop LAM evaluations that better correlate with user preferences",
    "checked": false,
    "id": "fafdbad5816fa3700bed39ffe7424a3f1b5e115a",
    "semantic_title": "mind the gap! static and interactive evaluations of large audio models",
    "citation_count": 3,
    "authors": [
      "Minzhi Li",
      "William Barr Held",
      "Michael J Ryan",
      "Kunat Pipatanakul",
      "Potsawee Manakul",
      "Hao Zhu",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.429": {
    "title": "Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu",
    "volume": "long",
    "abstract": "In-context machine translation (MT) with large language models (LLMs) is a promising approach for low-resource MT, as it can readily take advantage of linguistic resources such as grammar books and dictionaries.Such resources are usually selectively integrated into the prompt so that LLMs can directly perform translation without any specific training, via their in-context learning capability (ICL).However, the relative importance of each type of resource, e.g., dictionary, grammar book, and retrieved parallel examples, is not entirely clear.To address this gap, this study systematically investigates how each resource and its quality affect the translation performance, with the Manchu language as our case study. To remove any prior knowledge of Manchu encoded in the LLM parameters and single out the effect of ICL, we also experiment with an enciphered version of Manchu texts.Our results indicate that high-quality dictionaries and good parallel examples are very helpful, while grammars hardly help.In a follow-up study, we showcase a promising application of in-context MT: parallel data augmentation as a way to bootstrap a conventional MT model. When monolingual data abound, generating synthetic parallel data through in-context MT offers a pathway to mitigate data scarcity and build effective and efficient low-resource neural MT systems",
    "checked": true,
    "id": "ec6c8e547141b4250f87ee07d93f424faf7e2921",
    "semantic_title": "understanding in-context machine translation for low-resource languages: a case study on manchu",
    "citation_count": 0,
    "authors": [
      "Renhao Pei",
      "Yihong Liu",
      "Peiqin Lin",
      "François Yvon",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.acl-long.430": {
    "title": "CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs",
    "volume": "long",
    "abstract": "Chinese, as a linguistic system rich in depth and complexity, is characterized by distinctive elements such as ancient poetry, proverbs, idioms, and other cultural constructs. However, current Large Language Models (LLMs) face limitations in these specialized domains, highlighting the need for the development of comprehensive datasets that can assess, continuously update, and progressively improve these culturally-grounded linguistic competencies through targeted training optimizations. To address this gap, we introduce CKnowEdit, the first-ever Chinese knowledge editing dataset designed to correct linguistic, factual, and logical errors in LLMs. We collect seven types of knowledge from a wide range of sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, taking into account the unique polyphony, antithesis, and logical structures inherent in the Chinese language. By analyzing this dataset, we highlight the challenges current LLMs face in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge editing techniques reveals opportunities to advance the correction of Chinese knowledge",
    "checked": true,
    "id": "918e3804fe3b8b2e2e642e7ce2d7bed758541fb1",
    "semantic_title": "cknowedit: a new chinese knowledge editing dataset for linguistics, facts, and logic error correction in llms",
    "citation_count": 0,
    "authors": [
      "Jizhan Fang",
      "Tianhe Lu",
      "Yunzhi Yao",
      "Ziyan Jiang",
      "Xin Xu",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.431": {
    "title": "TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection",
    "volume": "long",
    "abstract": "The proliferation of large language models (LLMs) has introduced unprecedented challenges in fake news detection due to benchmark data contamination (BDC), where evaluation benchmarks are inadvertently memorized during the pre-training, leading to the inflated performance metrics. Traditional evaluation paradigms, reliant on static datasets and closed-world assumptions, fail to account the BDC risk in large-scale pre-training of current LLMs. This paper introduces TripleFact, a novel evaluation framework for fake news detection task, which designed to mitigate BDC risk while prioritizing real-world applicability. TripleFact integrates three components: (1) Human-Adversarial Preference Testing (HAPT) to assess robustness against human-crafted misinformation, (2) Real-Time Web Agent with Asynchronous Validation (RTW-AV) to evaluate temporal generalization using dynamically sourced claims, and (3) Entity-Controlled Virtual Environment (ECVE) to eliminate entity-specific biases. Through experiments on 17 state-of-the-art LLMs, including GPT, LLaMA, and DeepSeek variants, TripleFact demonstrates superior contamination resistance compared to traditional benchmarks. Results reveal that BDC artificially inflates performance by up to 23% in conventional evaluations, while TripleFact Score (TFS) remain stable within 4% absolute error under controlled contamination. The framework's ability to disentangle genuine detection capabilities from memorization artifacts underscores its potential as a fake news detection benchmark for the LLM era",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Xu",
      "Nan Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.432": {
    "title": "Meaning Beyond Truth Conditions: Evaluating Discourse Level Understanding via Anaphora Accessibility",
    "volume": "long",
    "abstract": "We present a hierarchy of natural language understanding abilities and argue for the importance of moving beyond assessments of understanding at the lexical and sentence levels to the discourse level. We propose the task of anaphora accessibility as a diagnostic for assessing discourse understanding, and to this end, present an evaluation dataset inspired by theoretical research in dynamic semantics. We evaluate human and LLM performance on our dataset and find that LLMs and humans align on some tasks and diverge on others. Such divergence can be explained by LLMs' reliance on specific lexical items during language comprehension, in contrast to human sensitivity to structural abstractions",
    "checked": true,
    "id": "4b0a4cc9ff09e103e1365c326e23a0f6efa60f17",
    "semantic_title": "meaning beyond truth conditions: evaluating discourse level understanding via anaphora accessibility",
    "citation_count": 0,
    "authors": [
      "Xiaomeng Zhu",
      "Zhenghao Zhou",
      "Simon Charlow",
      "Robert Frank"
    ]
  },
  "https://aclanthology.org/2025.acl-long.433": {
    "title": "Large Language and Reasoning Models are Shallow Disjunctive Reasoners",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have been found to struggle with systematic reasoning. Even on tasks where they appear to perform well, their performance often depends on shortcuts, rather than on genuine reasoning abilities, leading them to collapse on out-of-distribution (OOD) examples. Post-training strategies based on reinforcement learning and chain-of-thought prompting have recently been hailed as a step change. However, little is known about the potential of the resulting \"Large Reasoning Models\" (LRMs) beyond maths and programming-based problem solving, where genuine OOD problems can be sparse. In this paper, we focus on tasks that require systematic relational composition for qualitative spatial and temporal reasoning. The setting allows fine control over problem difficulty to precisely measure OOD generalization. We find that, zero-shot LRMs generally outperform their LLM counterparts in single-path reasoning tasks but struggle in the multi-path setting. Whilst showing comparatively better results, fine-tuned LLMs are also not capable of multi-path generalization. We also provide evidence for the behavioral interpretation for this, i.e., that LRMs are shallow disjunctive reasoners",
    "checked": true,
    "id": "7f473d6d3e6cfa0b6047c450bf7986aead559e17",
    "semantic_title": "large language and reasoning models are shallow disjunctive reasoners",
    "citation_count": 1,
    "authors": [
      "Irtaza Khalid",
      "Amir Masoud Nourollah",
      "Steven Schockaert"
    ]
  },
  "https://aclanthology.org/2025.acl-long.434": {
    "title": "Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation",
    "volume": "long",
    "abstract": "Traditional supervised fine-tuning (SFT) strategies for sequence-to-sequence tasks often train models to directly generate the target output. Recent work has shown that guiding models with intermediate steps—such as keywords, outlines, or reasoning chains—can significantly improve performance, coherence, and interpretability. However, these methods often depend on predefined intermediate formats and annotated data, limiting their scalability and generalizability. In this work, we introduce a task-agnostic framework that enables models to generate intermediate \"warmup\" sequences. These warmup sequences, serving as an initial state for subsequent generation, are optimized to enhance the probability of generating the target sequence without relying on external supervision or human-designed structures. Drawing inspiration from reinforcement learning principles, our method iteratively refines these intermediate steps to maximize their contribution to the final output, similar to reward-driven optimization in reinforcement learning with human feedback. Experimental results across tasks such as translation, summarization, and multi-choice question answering for logical reasoning show that our approach outperforms traditional SFT methods, and offers a scalable and flexible solution for sequence-to-sequence tasks",
    "checked": true,
    "id": "4c5f7bbef5b1b49b6b927284304acb56d0ef807e",
    "semantic_title": "warmup generations: a task-agnostic approach for guiding sequence-to-sequence learning with unsupervised initial state generation",
    "citation_count": 0,
    "authors": [
      "Senyu Li",
      "Zipeng Sun",
      "Jiayi Wang",
      "Xue Liu",
      "Pontus Stenetorp",
      "Siva Reddy",
      "David Ifeoluwa Adelani"
    ]
  },
  "https://aclanthology.org/2025.acl-long.435": {
    "title": "Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce",
    "volume": "long",
    "abstract": "Language is a form of symbolic capital that affects people's lives in many ways (Bourdieu1977,1991). As a powerful means of communication, it reflects identities, cultures, traditions, and societies more broadly. Therefore, data in a given language should be regarded as more than just a collection of tokens. Rigorous data collection and labeling practices are essential for developing more human-centered and socially aware technologies. Although there has been growing interest in under-resourced languages within the NLP community, work in this area faces unique challenges, such as data scarcity and limited access to qualified annotators.In this paper, we collect feedback from individuals directly involved in and impacted by NLP artefacts for medium- and low-resource languages. We conduct both quantitative and qualitative analyses of their responses and highlight key issues related to: (1) data quality, including linguistic and cultural appropriateness; and (2) the ethics of common annotation practices, such as the misuse of participatory research. Based on these findings, we make several recommendations for creating high-quality language artefacts that reflect the cultural milieu of their speakers, while also respecting the dignity and labor of data workers",
    "checked": true,
    "id": "6bb85a74a44c60cb95901b6462c72a26217d1784",
    "semantic_title": "building better: avoiding pitfalls in developing language resources when data is scarce",
    "citation_count": 1,
    "authors": [
      "Nedjma Ousidhoum",
      "Meriem Beloucif",
      "Saif M. Mohammad"
    ]
  },
  "https://aclanthology.org/2025.acl-long.436": {
    "title": "BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages",
    "volume": "long",
    "abstract": "People worldwide use language in subtle and complex ways to express emotions. Although emotion recognition–an umbrella term for several NLP tasks–impacts various applications within NLP and beyond, most work in this area has focused on high-resource languages. This has led to significant disparities in research efforts and proposed solutions, particularly for under-resourced languages, which often lack high-quality annotated datasets.In this paper, we present BRIGHTER–a collection of multi-labeled, emotion-annotated datasets in 28 different languages and across several domains. BRIGHTER primarily covers low-resource languages from Africa, Asia, Eastern Europe, and Latin America, with instances labeled by fluent speakers. We highlight the challenges related to the data collection and annotation processes, and then report experimental results for monolingual and crosslingual multi-label emotion identification, as well as emotion intensity recognition. We analyse the variability in performance across languages and text domains, both with and without the use of LLMs, and show that the BRIGHTER datasets represent a meaningful step towards addressing the gap in text-based emotion recognition",
    "checked": true,
    "id": "46820d6a8551b4e2267f80ad17ceaa1b3a3ef841",
    "semantic_title": "brighter: bridging the gap in human-annotated textual emotion recognition datasets for 28 languages",
    "citation_count": 10,
    "authors": [
      "Shamsuddeen Hassan Muhammad",
      "Nedjma Ousidhoum",
      "Idris Abdulmumin",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Meriem Beloucif",
      "Christine de Kock",
      "Nirmal Surange",
      "Daniela Teodorescu",
      "Ibrahim Said Ahmad",
      "David Ifeoluwa Adelani",
      "Alham Fikri Aji",
      "Felermino D. M. A. Ali",
      "Ilseyar Alimova",
      "Vladimir Araujo",
      "Nikolay Babakov",
      "Naomi Baes",
      "Ana-Maria Bucur",
      "Andiswa Bukula",
      "Guanqun Cao",
      "Rodrigo Tufiño",
      "Rendi Chevi",
      "Chiamaka Ijeoma Chukwuneke",
      "Alexandra Ciobotaru",
      "Daryna Dementieva",
      "Murja Sani Gadanya",
      "Robert Geislinger",
      "Bela Gipp",
      "Oumaima Hourrane",
      "Oana Ignat",
      "Falalu Ibrahim Lawan",
      "Rooweither Mabuya",
      "Rahmad Mahendra",
      "Vukosi Marivate",
      "Alexander Panchenko",
      "Andrew Piper",
      "Charles Henrique Porto Ferreira",
      "Vitaly Protasov",
      "Samuel Rutunda",
      "Manish Shrivastava",
      "Aura Cristina Udrea",
      "Lilian Diana Awuor Wanzare",
      "Sophie Wu",
      "Florian Valentin Wunderlich",
      "Hanif Muhammad Zhafran",
      "Tianhui Zhang",
      "Yi Zhou",
      "Saif M. Mohammad"
    ]
  },
  "https://aclanthology.org/2025.acl-long.437": {
    "title": "SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation",
    "volume": "long",
    "abstract": "As language models evolve to tackle complex, multifaceted tasks, their evaluation must adapt to capture this intricacy. A granular, skill-specific understanding of model capabilities can empower researchers to make informed model development plans. In this paper, we introduce SkillVerse, an unsupervised tree-structured diagnosis framework for understanding model proficiency in specific abilities. With LLM as a judge, SkillVerse first critiques the model responses, and then organizes them into a hierarchical structure termed dendrogram. Given proficiency at arbitrary levels of granularity, SkillVerse is flexible to produce insights of behaviors of modern large models. We also demonstrate its efficacy in two downstream tasks: 1) improving model in-context learning by 25% using a tree-search algorithm to select more informative few-shot demonstrations, and 2) accurately predicting new model weaknesses with a 55% success rate, 22% higher than without SkillVerse",
    "checked": true,
    "id": "96ff7a30bc8051fa538810931a0f111fe0f0ccef",
    "semantic_title": "skillverse : assessing and enhancing llms with tree evaluation",
    "citation_count": 0,
    "authors": [
      "Yufei Tian",
      "Jiao Sun",
      "Nanyun Peng",
      "Zizhao Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.438": {
    "title": "CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era",
    "volume": "long",
    "abstract": "Retrieval from graph data is crucial for augmenting large language models (LLM) with both open-domain knowledge and private enterprise data, and it is also a key component in the recent GraphRAG system (CITATION). Despite decades of research on knowledge graphs and knowledge base question answering, leading LLM frameworks (Langchain and LlamaIndex) have only minimal support for retrieval from modern encyclopedic knowledge graphs like Wikidata. In this paper, we analyze the root cause and suggest that modern RDF knowledge graphs (Wikidata, Freebase) are less efficient for LLMs due to overly large schemas that far exceed the typical LLM context window, use of resource identifiers, overlapping and ambiguous relation types and lack of normalization. As a solution, we propose property graph views on top of the underlying RDF graph that can be efficiently queried by LLMs using Cypher. We instantiated this idea on Wikidata and introduced CypherBench, the first benchmark with 11 large-scale, multi-domain property graphs with 7.8 million entities and over 10,000 questions. To achieve this, we tackled several key challenges, including developing an RDF-to-property graph conversion engine, creating a systematic pipeline for text-to-Cypher task generation, and designing new evaluation metrics",
    "checked": true,
    "id": "65faa06c893ef481b4200da6bba3592f89b28353",
    "semantic_title": "cypherbench: towards precise retrieval over full-scale modern knowledge graphs in the llm era",
    "citation_count": 5,
    "authors": [
      "Yanlin Feng",
      "Simone Papicchio",
      "Sajjadur Rahman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.439": {
    "title": "Empathy Prediction from Diverse Perspectives",
    "volume": "long",
    "abstract": "A person's perspective on a topic can influence their empathy towards a story. To investigate the use of personal perspective in empathy prediction, we collected a dataset, EmpathyFromPerspectives, where a user rates their empathy towards a story by a person with a different perspective on a prompted topic. We observed in the dataset that user perspective can be important for empathy prediction and developed a model, PPEP, that uses a rater's perspective as context for predicting the rater's empathy towards a story. Experiments comparing PPEP with baseline models show that use of personal perspective significantly improves performance. A user study indicated that human empathy ratings of stories generally agreed with PPEP's relative empathy rankings",
    "checked": false,
    "id": "404666ccfb82cb42b31f559d0882f878298b27f8",
    "semantic_title": "insights into healthcare design essentials from diverse perspectives",
    "citation_count": 0,
    "authors": [
      "Francine Chen",
      "Scott Carter",
      "Tatiana Lau",
      "Nayeli Suseth Bravo",
      "Sumanta Bhattacharyya",
      "Kate Sieck",
      "Charlene C. Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.440": {
    "title": "Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice",
    "volume": "long",
    "abstract": "In psychological practice, standardized questionnaires serve as essential tools for assessing mental health through structured, clinically-validated questions (i.e., items). While social media platforms offer rich data for mental health screening, computational approaches often bypass these established clinical assessment tools in favor of black-box classification. We propose a novel questionnaire-guided screening framework that bridges psychological practice and computational methods through adaptive Retrieval-Augmented Generation (aRAG). Our approach links unstructured social media content and standardized clinical assessments by retrieving relevant posts for each questionnaire item and using Large Language Models (LLMs) to complete validated psychological instruments. Our findings demonstrate two key advantages of questionnaire-guided screening: First, when completing the Beck Depression Inventory-II (BDI-II), our approach matches or outperforms state-of-the-art performance on Reddit-based benchmarks without requiring training data. Second, we show that guiding LLMs through standardized questionnaires yields superior results compared to directly prompting them for depression screening. Additionally, we show as a proof-of-concept how our questionnaire-based methodology successfully extends to self-harm screening",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Federico Ravenda",
      "Seyed Ali Bahrainian",
      "Andrea Raballo",
      "Antonietta Mira",
      "Noriko Kando"
    ]
  },
  "https://aclanthology.org/2025.acl-long.441": {
    "title": "INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) excel at answering questions but remain passive learners—absorbing static data without the ability to question and refine knowledge. This paper explores how LLMs can transition to interactive, question-driven learning through student-teacher dialogues. We introduce INTERACT (INTERactive learning for Adaptive Concept Transfer), a framework in which a \"student\" LLM engages a \"teacher\" LLM through iterative inquiries to acquire knowledge across 1,347 contexts, including song lyrics, news articles, movie plots, academic papers, and images. Our experiments show that across a wide range of scenarios and LLM architectures, interactive learning consistently enhances performance, achieving up to a 25% improvement, with ‘cold-start' student models matching static learning baselines in as few as five dialogue turns. Interactive setups can also mitigate the disadvantages of weaker teachers, showcasing the robustness of question-driven learning",
    "checked": true,
    "id": "1a0150a7d50799521de2f645bd36fc0c4ae8887a",
    "semantic_title": "interact: enabling interactive, question-driven learning in large language models",
    "citation_count": 1,
    "authors": [
      "Aum Kendapadi",
      "Kerem Zaman",
      "Rakesh R Menon",
      "Shashank Srivastava"
    ]
  },
  "https://aclanthology.org/2025.acl-long.442": {
    "title": "Circuit Stability Characterizes Language Model Generalization",
    "volume": "long",
    "abstract": "Extensively evaluating the capabilities of (large) language models is difficult. Rapid development of state-of-the-art models induce benchmark saturation, while creating more challenging datasets is labor-intensive. Inspired by the recent developments in mechanistic interpretability, we introduce circuit stability as a new way to assess model performance. Circuit stability refers to a model's ability to apply a consistent reasoning process–its circuit–across various inputs. We mathematically formalize circuit stability and circuit equivalence. Then, through three case studies, we empirically show that circuit stability and the lack thereof can characterize and predict different aspects of generalization. Our proposed methods offer a step towards rigorously relating the generality of models to their interpretability",
    "checked": true,
    "id": "e02b5861d68edb0ebceb241aeff5eac40da451b2",
    "semantic_title": "circuit stability characterizes language model generalization",
    "citation_count": 0,
    "authors": [
      "Alan Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.443": {
    "title": "Comparing LLM-generated and human-authored news text using formal syntactic theory",
    "volume": "long",
    "abstract": "This study provides the first comprehensive comparison of New York Times-style text generated by six large language models against real, human-authored NYT writing. The comparison is based on a formal syntactic theory. We use Head-driven Phrase Structure Grammar (HPSG) to analyze the grammatical structure of the texts. We then investigate and illustrate the differences in the distributions of HPSG grammar types, revealing systematic distinctions between human and LLM-generated writing. These findings contribute to a deeper understanding of the syntactic behavior of LLMs as well as humans, within the NYT genre",
    "checked": true,
    "id": "471addaf6ba12a3d2f71e73f10ec03fed8cf48d2",
    "semantic_title": "comparing llm-generated and human-authored news text using formal syntactic theory",
    "citation_count": 0,
    "authors": [
      "Olga Zamaraeva",
      "Dan Flickinger",
      "Francis Bond",
      "Carlos Gómez-Rodríguez"
    ]
  },
  "https://aclanthology.org/2025.acl-long.444": {
    "title": "Improving Preference Extraction In LLMs By Identifying Latent Knowledge Through Classifying Probes",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are often used as automated judges to evaluate text, but their effectiveness can be hindered by various unintentional biases. We propose using linear classifying probes, trained by leveraging differences between contrasting pairs of prompts, to directly access LLMs' latent knowledge and extract more accurate preferences. Through extensive experiments using models of varying size from four different families and six diverse datasets assessing text quality evaluation and common sense reasoning, we demonstrate that both supervised and unsupervised probing approaches consistently outperform traditional generation-based judgement while maintaining similar computational costs. These probes generalise under domain shifts and can even outperform finetuned evaluators with the same training data size. Our results suggest linear probing offers an accurate, robust and computationally efficient approach for LLM-as-judge tasks while providing interpretable insights into how models encode judgement-relevant knowledge. Our data and code will be openly released in the future",
    "checked": true,
    "id": "35e1cb506c50e4ad184e5b95fd583dcf950368e7",
    "semantic_title": "improving preference extraction in llms by identifying latent knowledge through classifying probes",
    "citation_count": 0,
    "authors": [
      "Sharan Maiya",
      "Yinhong Liu",
      "Ramit Debnath",
      "Anna Korhonen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.445": {
    "title": "White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs",
    "volume": "long",
    "abstract": "Social biases can manifest in language agency. However, very limited research has investigated such biases in Large Language Model (LLM)-generated content. In addition, previous works often rely on string-matching techniques to identify agentic and communal words within texts, falling short of accurately classifying language agency. We introduce the **Language Agency Bias Evaluation (LABE)** benchmark, which comprehensively evaluates biases in LLMs by analyzing agency levels attributed to different demographic groups in model generations. LABE tests for gender, racial, and intersectional language agency biases in LLMs on 3 text generation tasks: biographies, professor reviews, and reference letters. Using LABE, we unveil language agency social biases in 3 recent LLMs: ChatGPT, Llama3, and Mistral. We observe that: (1) LLM generations tend to demonstrate greater gender bias than human-written texts; (2) Models demonstrate remarkably higher levels of intersectional bias than the other bias aspects. (3) Prompt-based mitigation is unstable and frequently leads to bias exacerbation. Based on our observations, we propose **Mitigation via Selective Rewrite (MSR)**, a novel bias mitigation strategy that leverages an agency classifier to identify and selectively revise parts of generated texts that demonstrate communal traits. Empirical results prove MSR to be more effective and reliable than prompt-based mitigation method, showing a promising research direction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Wan",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.446": {
    "title": "AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions",
    "volume": "long",
    "abstract": "Modern Slavery Acts mandate that corporations disclose their efforts to combat modern slavery, aiming to enhance transparency and strengthen practices for its eradication. However, verifying these statements remains challenging due to their complex, diversified language and the sheer number of statements that must be reviewed. The development of NLP tools to assist in this task is also difficult due to a scarcity of annotated data. Furthermore, as modern slavery transparency legislation has been introduced in several countries, the generalizability of such tools across legal jurisdictions must be studied. To address these challenges, we work with domain experts to make two key contributions. First, we present AIMS.uk and AIMS.ca, newly annotated datasets from the UK and Canada to enable cross-jurisdictional evaluation. Second, we introduce AIMSCheck, an end-to-end framework for compliance validation. AIMSCheck decomposes the compliance assessment task into three levels, enhancing interpretability and practical applicability. Our experiments show that models trained on an Australian dataset generalize well across UK and Canadian jurisdictions, demonstrating the potential for broader application in compliance monitoring. We release the benchmark datasets and AIMSCheck to the public to advance AI-adoption in compliance assessment and drive further research in this field",
    "checked": true,
    "id": "6d6d72e05cf0201c1c49ea2f91007e88bb73a940",
    "semantic_title": "aimscheck: leveraging llms for ai-assisted review of modern slavery statements across jurisdictions",
    "citation_count": 0,
    "authors": [
      "Adriana Eufrosina Bora",
      "Akshatha Arodi",
      "Duoyi Zhang",
      "Jordan Bannister",
      "Mirko Bronzi",
      "Arsene Fansi Tchango",
      "Md Abul Bashar",
      "Richi Nayak",
      "Kerrie Mengersen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.447": {
    "title": "Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence",
    "volume": "long",
    "abstract": "Dense retrieval models are commonly used in Information Retrieval (IR) applications, such as Retrieval-Augmented Generation (RAG). Since they often serve as the first step in these systems, their robustness is critical to avoid downstream failures. In this work, we repurpose a relation extraction dataset (e.g., Re-DocRED) to design controlled experiments that quantify the impact of heuristic biases, such as a preference for shorter documents, on retrievers like Dragon+ and Contriever. We uncover major vulnerabilities, showing retrievers favor shorter documents, early positions, repeated entities, and literal matches, all while ignoring the answer's presence! Notably, when multiple biases combine, models exhibit catastrophic performance degradation, selecting the answer-containing document in less than 10% of cases over a synthetic biased document without the answer. Furthermore, we show that these biases have direct consequences for downstream applications like RAG, where retrieval-preferred documents can mislead LLMs, resulting in a 34% performance drop than providing no documents at all.https://huggingface.co/datasets/mohsenfayyaz/ColDeR",
    "checked": true,
    "id": "5e58c086cab4b104fb2aa0942a978c64afe80c7c",
    "semantic_title": "collapse of dense retrievers: short, early, and literal biases outranking factual evidence",
    "citation_count": 3,
    "authors": [
      "Mohsen Fayyaz",
      "Ali Modarressi",
      "Hinrich Schuetze",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.448": {
    "title": "SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence",
    "volume": "long",
    "abstract": "Providing Language Models (LMs) with relevant evidence in the context (either via retrieval or user-provided) can significantly improve their ability to provide better-grounded responses. However, recent studies have found that LMs often struggle to fully comprehend and utilize key evidence from the context, especially when it contains noise and irrelevant information—an issue common in real-world scenarios.To address this, we propose SelfElicit, an inference-time approach that helps LMs focus on key contextual evidence through self-guided explicit highlighting.By leveraging the inherent evidence-finding capabilities of LMs using the attention scores of deeper layers, our method automatically identifies and emphasizes key evidence within the input context, facilitating more accurate and grounded responses without additional training or iterative prompting.We demonstrate that SelfElicit brings consistent and significant improvement on multiple evidence-based QA tasks for various LM families while maintaining computational efficiency.Our code and documentation are available at https://github.com/ZhiningLiu1998/SelfElicit",
    "checked": true,
    "id": "91488f0e56ab1f369d65cb6f99b787813682096a",
    "semantic_title": "selfelicit: your language model secretly knows where is the relevant evidence",
    "citation_count": 3,
    "authors": [
      "Zhining Liu",
      "Rana Ali Amjad",
      "Ravinarayana Adkathimar",
      "Tianxin Wei",
      "Hanghang Tong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.449": {
    "title": "The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects",
    "volume": "long",
    "abstract": "Recent large-scale T2I models like DALLE-3 have made progress in reducing gender stereotypes when generating single-person images. However, significant biases remain when generating images with more than one person. To systematically evaluate this, we propose the **Paired Stereotype Test (PST)** framework, which queries T2I models to depict two individuals assigned with male-stereotyped and female-stereotyped social identities, respectively (e.g. \"a CEO\" and \"an Assistant\"). This contrastive setting often triggers T2I models to generate gender-stereotyped images. Using PST, we evaluate two aspects of gender biases – the well-known **bias in gendered occupation** and a novel aspect: **bias in organizational power**. Experiments show that **over 74% images generated by DALLE-3 display gender-occupational biases**. Additionally, compared to single-person settings, DALLE-3 is more likely to perpetuate male-associated stereotypes under PST. We further propose **FairCritic**, a novel and interpretable framework that leverages an LLM-based critic model to i) detect bias in generated images, and ii) adaptively provide feedback to T2I models for improving fairness. FairCritic achieves near-perfect fairness on PST, overcoming the limitations of previous prompt-based intervention approaches",
    "checked": true,
    "id": "83fa77e2efe1881de5009969fff1bead1439ba4c",
    "semantic_title": "the male ceo and the female assistant: evaluation and mitigation of gender biases in text-to-image generation of dual subjects",
    "citation_count": 3,
    "authors": [
      "Yixin Wan",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.450": {
    "title": "Mitigating Shortcut Learning with InterpoLated Learning",
    "volume": "long",
    "abstract": "Empirical risk minimization (ERM) incentivizes models to exploit shortcuts, i.e., spurious correlations between input attributes and labels that are prevalent in the majority of the training data but unrelated to the task at hand. This reliance hinders generalization on minority examples, where such correlations do not hold. Existing shortcut mitigation approaches are model-specific, difficult to tune, computationally expensive, and fail to improve learned representations. To address these issues, we propose InterpoLated Learning (InterpoLL) which interpolates the representations of majority examples to include features from intra-class minority examples with shortcut-mitigating patterns. This weakens shortcut influence, enabling models to acquire features predictive across both minority and majority examples. Experimental results on multiple natural language understanding tasks demonstrate that InterpoLL improves minority generalization over both ERM and state-of-the-art mitigation methods, without compromising accuracy on majority examples. Notably, these gains persist across encoder, encoder-decoder, and decoder-only architectures, demonstrating the method's broad applicability",
    "checked": false,
    "id": "a3fe107bc2794db5446c60e89b06cf77e2b2e40c",
    "semantic_title": "visionary-r1: mitigating shortcuts in visual reasoning with reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Michalis Korakakis",
      "Andreas Vlachos",
      "Adrian Weller"
    ]
  },
  "https://aclanthology.org/2025.acl-long.451": {
    "title": "Toward Automatic Discovery of a Canine Phonetic Alphabet",
    "volume": "long",
    "abstract": "Dogs communicate intelligently but little is known about the phonetic properties of their vocalization communication. For the first time, this paper presents an iterative algorithm inspired by human phonetic discovery, which is based on minimal pairs that determine phonemes by distinguishing different words in human language, and is able to produce a complete alphabet of distinct canine phoneme-like units. In addition, the algorithm produces a number of canine repeated acoustic units, which may correspond to specific environments and activities of a dog, composed exclusively of the canine phoneme-like units in the alphabet. The framework outlined in this paper is expected to function not only on canines but other animal species",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Theron S. Wang",
      "Xingyuan Li",
      "Hridayesh Lekhak",
      "Tuan Minh Dang",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.452": {
    "title": "DavIR: Data Selection via Implicit Reward for Large Language Models",
    "volume": "long",
    "abstract": "We introduce DavIR, a model-based data selection method for post-training Large Language Models. DavIR generalizes Reducible Holdout Loss to core-set selection problem of causal language modeling, and quantifies the learnability of a given datum with respect to a pre-trained LLM based on relative reduction in loss during fine-tuning, a metric we show to be closely related to the implicit reward model described in Direct Preference Optimization (DPO). We show that 6% of Alpaca dataset selected with DavIR can steer both the LLaMA and Gemma model family to produce superior performance compared to the same models trained on the full 52K dataset. We also show that Alpaca dataset compressed with DavIR can be combined with GSM8K dataset to effectively balance open-domain freeform QA and mathematical reasoning capabilities. Finally, we apply the DavIR objective to DPO and develop a normalized DavIR-DPO objective which improves alignment performance of Zephyr-7B-SFT model by 8% (relative) on AlpacaEval, compared against training on vanilla DPO objective",
    "checked": true,
    "id": "e9f8d5c51e1d889ff3783e9afe7cb475c10e1af1",
    "semantic_title": "davir: data selection via implicit reward for large language models",
    "citation_count": 6,
    "authors": [
      "Haotian Zhou",
      "Tingkai Liu",
      "Qianli Ma",
      "Yufeng Zhang",
      "Jianbo Yuan",
      "Pengfei Liu",
      "Yang You",
      "Hongxia Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.453": {
    "title": "Byte Latent Transformer: Patches Scale Better Than Tokens",
    "volume": "long",
    "abstract": "We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the primary units of computation. Patches are segmented based on the entropy of the next byte, allocating more compute and model capacity where increased data complexity demands it. We present the first FLOP controlled scaling study of byte-level models – up to 8B parameters and 4T training bytes – demonstrating the feasibility of scaling models trained on raw bytes without a fixed vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. For fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size",
    "checked": true,
    "id": "11f3bcff50c490412db59bd34b1a6045b7821715",
    "semantic_title": "byte latent transformer: patches scale better than tokens",
    "citation_count": 30,
    "authors": [
      "Artidoro Pagnoni",
      "Ramakanth Pasunuru",
      "Pedro Rodriguez",
      "John Nguyen",
      "Benjamin Muller",
      "Margaret Li",
      "Chunting Zhou",
      "Lili Yu",
      "Jason E Weston",
      "Luke Zettlemoyer",
      "Gargi Ghosh",
      "Mike Lewis",
      "Ari Holtzman",
      "Srini Iyer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.454": {
    "title": "DiffuseDef: Improved Robustness to Adversarial Attacks via Iterative Denoising",
    "volume": "long",
    "abstract": "Pretrained language models have significantly advanced performance across various natural language processing tasks. However, adversarial attacks continue to pose a critical challenge to system built using these models, as they can be exploited with carefully crafted adversarial texts. Inspired by the ability of diffusion models to predict and reduce noise in computer vision, we propose a novel and flexible adversarial defense method for language classification tasks, DiffuseDef, which incorporates a diffusion layer as a denoiser between the encoder and the classifier. The diffusion layer is trained on top of the existing classifier, ensuring seamless integration with any model in a plug-and-play manner. During inference, the adversarial hidden state is first combined with sampled noise, then denoised iteratively and finally ensembled to produce a robust text representation. By integrating adversarial training, denoising, and ensembling techniques, we show that DiffuseDef improves over existing adversarial defense methods and achieves state-of-the-art performance against common black-box and white-box adversarial attacks",
    "checked": false,
    "id": "2fd06122dd3ca0bca956cf41fabe131f1f060325",
    "semantic_title": "diffusedef: improved robustness to adversarial attacks",
    "citation_count": 0,
    "authors": [
      "Zhenhao Li",
      "Huichi Zhou",
      "Marek Rei",
      "Lucia Specia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.455": {
    "title": "Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models",
    "volume": "long",
    "abstract": "Spatial transcriptomic technologies enable measuring gene expression profile and spatial information of cells in tissues simultaneously. Clustering of captured cells/spots in the spatial transcriptomic data is crucial for understanding tissue niches and uncovering disease-related changes.Current methods to cluster spatial transcriptomic data encounter obstacles, including inefficiency in handling multi-replicate data, lack of prior knowledge incorporation, and producing uninterpretable cluster labels.We introduce a novel approach, LLMiniST, to identify spatial niche using a zero-shot large language models (LLMs) by transforming spatial transcriptomic data into spatial context prompts, leveraging gene expression of neighboring cells/spots, cell type composition, tissue information, and external knowledge. The model was further enhanced using a two-stage fine-tuning strategy for improved generalizability. We also develop a user-friendly annotation tool to accelerate the creation of well-annotated spatial dataset for fine-tuning.Comprehensive method performance evaluations showed that both zero-shot and fine-tunned LLMiniST had superior performance than current non-LLM methods in many circumstances. Notably, the two-stage fine-tuning strategy facilitated substantial cross-subject generalizability. The results demonstrate the feasibility of LLMs for tissue niche identification using spatial transcriptomic data and the potential of LLMs as a scalable solution to efficiently integrate minimal human guidance for improved performance in large-scale datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huanhuan Wei",
      "Xiao Luo",
      "Hongyi Yu",
      "Jinping Liang",
      "Luning Yang",
      "Lixing Lin",
      "Alexandra Popa",
      "Xiting Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.456": {
    "title": "Culture Matters in Toxic Language Detection in Persian",
    "volume": "long",
    "abstract": "Toxic language detection is crucial for creating safer online environments and limiting the spread of harmful content. While toxic language detection has been under-explored in Persian, the current work compares different methods for this task, including fine-tuning, data enrichment, zero-shot and few-shot learning, and cross-lingual transfer learning. What is especially compelling is the impact of cultural context on transfer learning for this task: We show that the language of a country with cultural similarities to Persian yields better results in transfer learning. Conversely, the improvement is lower when the language comes from a culturally distinct country",
    "checked": true,
    "id": "29f5593b4a971afa6ad5e52c81fee0e0a845ef9f",
    "semantic_title": "culture matters in toxic language detection in persian",
    "citation_count": 0,
    "authors": [
      "Zahra Bokaei",
      "Walid Magdy",
      "Bonnie Webber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.457": {
    "title": "Bitnet.cpp: Efficient Edge Inference for Ternary LLMs",
    "volume": "long",
    "abstract": "The advent of 1-bit large language models (LLMs), led by BitNet b1.58, has spurred interest in ternary LLMs. Despite this, research and practical applications focusing on efficient edge inference for ternary LLMs remain scarce. To bridge this gap, we introduce Bitnet.cpp, an inference system optimized for BitNet b1.58 and ternary LLMs. Given that mixed-precision matrix multiplication (mpGEMM) constitutes the bulk of inference time in ternary LLMs, Bitnet.cpp incorporates a novel mpGEMM library to facilitate sub-2-bits-per-weight, efficient and lossless inference. The library features two core solutions: Ternary Lookup Table (TL), which addresses spatial inefficiencies of previous bit-wise methods, and Int2 with a Scale (I2_S), which ensures lossless edge inference, both enabling high-speed inference. Our experiments show that Bitnet.cpp achieves up to a 6.25x increase in speed over full-precision baselines and up to 2.32x over low-bit baselines, setting new benchmarks in the field. Additionally, we expand TL to element-wise lookup table (ELUT) for low-bit LLMs in the appendix, presenting both theoretical and empirical evidence of its considerable potential. Bitnet.cpp is publicly available at https://github.com/microsoft/BitNet/tree/paper, offering a sophisticated solution for the efficient and practical deployment of edge LLMs",
    "checked": true,
    "id": "f5ffce5d12cb84d58cb0dc0ae2b06f662fbe0433",
    "semantic_title": "bitnet.cpp: efficient edge inference for ternary llms",
    "citation_count": 1,
    "authors": [
      "Jinheng Wang",
      "Hansong Zhou",
      "Ting Song",
      "Shijie Cao",
      "Yan Xia",
      "Ting Cao",
      "Jianyu Wei",
      "Shuming Ma",
      "Hongyu Wang",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.458": {
    "title": "Instance-Selection-Inspired Undersampling Strategies for Bias Reduction in Small and Large Language Models for Binary Text Classification",
    "volume": "long",
    "abstract": "Skewness in imbalanced datasets affects Automatic Text Classification (ATC), leading to classifier bias toward the majority classes. This work examines undersampling methods to mitigate such bias in Small and Large Language Model (SLMs and LLMs) classifiers. Based on the limitations found in existing solutions, we propose two novel undersampling methods inspired by state-of-the-art Instance Selection techniques, relying on calibrated confidences and semantic difficulty estimates. We compare them against 19 baselines across 13 datasets, evaluating: (i) effectiveness, (ii) class imbalance bias, (iii) efficiency, (iv) scalability, and (v) consistency. Results show our methods uniquely reduce classifier bias (up to 56%) across all datasets without effectiveness loss while improving efficiency (1.6x speedup), scalability and reducing carbon emissions (up to 50%)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guilherme Fonseca",
      "Washington Cunha",
      "Gabriel Prenassi",
      "Marcos André Gonçalves",
      "Leonardo Chaves Dutra Da Rocha"
    ]
  },
  "https://aclanthology.org/2025.acl-long.459": {
    "title": "Forward Knows Efficient Backward Path: Saliency-Guided Memory-Efficient Fine-tuning of Large Language Models",
    "volume": "long",
    "abstract": "Fine-tuning is widely recognized as a crucial process for aligning large language models (LLMs) with human intentions. However, the substantial memory requirements associated with fine-tuning pose a significant barrier to extending the applicability of LLMs. While parameter-efficient fine-tuning can be a promising approach by reducing trainable parameters, intermediate activations still need to be cached to compute gradients during the backward pass, thereby limiting overall memory efficiency. In this work, we propose Saliency-Guided Gradient Flow (SAGE), a memory-efficient fine-tuning method designed to minimize the memory specifically associated with cached intermediate activations. The key strategy is to selectively cache activations based on their saliency during the forward pass and then use these activations for the backward pass. This process transforms the dense backward pass into a sparse one, thereby enhancing memory efficiency. To verify whether SAGE can serve as an efficient alternative for fine-tuning, we conduct comprehensive experiments across diverse fine-tuning scenarios and setups. The experimental results show that SAGE substantially improves memory efficiency without a significant loss in accuracy, highlighting its broad value in real-world applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeachan Kim",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.460": {
    "title": "Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning",
    "volume": "long",
    "abstract": "Medical Large Vision-Language Models (Med-LVLMs) often exhibit suboptimal attention distribution on visual inputs, leading to hallucinated or inaccurate outputs. Existing methods primarily rely on inference-time interventions, which are limited in attention adaptation or require additional supervision. To address this, we propose A3Tune, a novel fine-tuning framework for Automatic Attention Alignment Tuning. ATune leverages zero-shot weak labels from SAM, refines them into prompt-aware labels using BioMedCLIP, and then selectively modifies visually-critical attention heads to improve alignment while minimizing interference. Additionally, we introduce a A3MoE module, enabling adaptive parameter selection for attention tuning across diverse prompts and images. Extensive experiments on medical VQA and report generation benchmarks show that A3Tune outperforms state-of-the-art baselines, achieving enhanced attention distributions and performance in Med-LVLMs",
    "checked": true,
    "id": "6e2db422f58ba7ff7bc379ddcf92f13aefe2e8c8",
    "semantic_title": "focus on what matters: enhancing medical vision-language models with automatic attention alignment tuning",
    "citation_count": 0,
    "authors": [
      "Aofei Chang",
      "Le Huang",
      "Alex James Boyd",
      "Parminder Bhatia",
      "Taha Kass-Hout",
      "Cao Xiao",
      "Fenglong Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.461": {
    "title": "LLMs + Persona-Plug = Personalized LLMs",
    "volume": "long",
    "abstract": "Personalization plays a critical role in numerous language tasks and applications, since users with the same requirements may prefer diverse outputs based on their interests. This has led to the development of various personalized approaches aimed at adapting large language models (LLMs) to generate customized outputs aligned with user preferences. Some of them involve fine-tuning a unique personalized LLM for each user, which is too expensive for widespread application. Alternative approaches introduce personalization information in a plug-and-play manner by retrieving the user's relevant historical texts as demonstrations. However, this retrieval-based strategy may break the continuity of the user history and fail to capture the user's overall styles and patterns, hence leading to sub-optimal performance. To address these challenges, we propose a novel personalized LLM model, PPlug. It constructs a user-specific embedding for each individual by modeling all her historical contexts through a lightweight plug-in user embedder module. By attaching this embedding to the task input, LLMs can better understand and capture user habits and preferences, thereby producing more personalized outputs without tuning their parameters. Extensive experiments on various tasks in the language model personalization (LaMP) benchmark demonstrate that the proposed model significantly outperforms existing personalized LLM approaches",
    "checked": true,
    "id": "36536e54e82ba7757ee2ee90df8bc3caf6d7d982",
    "semantic_title": "llms + persona-plug = personalized llms",
    "citation_count": 6,
    "authors": [
      "Jiongnan Liu",
      "Yutao Zhu",
      "Shuting Wang",
      "Xiaochi Wei",
      "Erxue Min",
      "Yu Lu",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.462": {
    "title": "Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition",
    "volume": "long",
    "abstract": "Large language models possess general linguistic abilities but acquire language less efficiently than humans. This study proposes a method for integrating the developmental characteristics of working memory during the critical period, a stage when human language acquisition is particularly efficient, into the training process of language models. The proposed method introduces a mechanism that initially constrains working memory during the early stages of training and gradually relaxes this constraint in an exponential manner as learning progresses. Targeted syntactic evaluation shows that the proposed method outperforms conventional methods without memory constraints or with static memory constraints. These findings not only provide new directions for designing data-efficient language models but also offer indirect evidence supporting the role of the developmental characteristics of working memory as the underlying mechanism of the critical period in language acquisition",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masato Mita",
      "Ryo Yoshida",
      "Yohei Oseki"
    ]
  },
  "https://aclanthology.org/2025.acl-long.463": {
    "title": "IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data",
    "volume": "long",
    "abstract": "Causal discovery is fundamental to scientific research, yet traditional statistical algorithms face significant challenges, including expensive data collection, redundant computation for known relations, and unrealistic assumptions. While recent LLM-based methods excel at identifying commonly known causal relations, they fail to uncover novel relations. We introduce IRIS (Iterative Retrieval and Integrated System for Real-Time Causal Discovery), a novel framework that addresses these limitations. Starting with a set of initial variables, IRIS automatically collects relevant documents, extracts variables, and uncovers causal relations. Our hybrid causal discovery method combines statistical algorithms and LLM-based methods to discover known and novel causal relations. In addition to causal discovery on initial variables, the missing variable proposal component of IRIS identifies and incorporates missing variables to expand the causal graphs. Our approach enables real-time causal discovery from only a set of initial variables without requiring pre-existing datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Feng",
      "Lizhen Qu",
      "Niket Tandon",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2025.acl-long.464": {
    "title": "INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages",
    "volume": "long",
    "abstract": "Slot-filling and intent detection are well-established tasks in Conversational AI. However, current large-scale benchmarks for these tasks often exclude evaluations of low-resource languages and rely on translations from English benchmarks, thereby predominantly reflecting Western-centric concepts. In this paper, we introduce \"INJONGO\" - a multicultural, open-source benchmark dataset for 16 African languages with utterances generated by native speakers across diverse domains, including banking, travel, home, and dining. Through extensive experiments, we benchmark fine-tuning multilingual transformer models and prompting large language models (LLMs), and show the advantage of leveraging African-cultural utterances over Western-centric utterances for improving cross-lingual transfer from the English language. Experimental results reveal that current LLMs struggle with the slot-filling task, with GPT-4o achieving an average performance of 26 F1. In contrast, intent detection performance is notably better, with an average accuracy of 70.6%, though it still falls short of fine-tuning baselines. When compared to the English language, GPT-4o and fine-tuning baselines perform similarly on intent detection, achieving an accuracy of approximately 81%. Our findings suggest that LLMs performance is still behind for many low-resource African languages, and more work is needed to further improve their downstream performance",
    "checked": true,
    "id": "3b4a162592a8ce312db61fe592e6a1b50cd76dde",
    "semantic_title": "injongo: a multicultural intent detection and slot-filling dataset for 16 african languages",
    "citation_count": 1,
    "authors": [
      "Hao Yu",
      "Jesujoba Oluwadara Alabi",
      "Andiswa Bukula",
      "Jian Yun Zhuang",
      "En-Shiun Annie Lee",
      "Tadesse Kebede Guge",
      "Israel Abebe Azime",
      "Happy Buzaaba",
      "Blessing Kudzaishe Sibanda",
      "Godson Koffi Kalipe",
      "Jonathan Mukiibi",
      "Salomon Kabongo Kabenamualu",
      "Mmasibidi Setaka",
      "Lolwethu Ndolela",
      "Nkiruka Odu",
      "Rooweither Mabuya",
      "Shamsuddeen Hassan Muhammad",
      "Salomey Osei",
      "Sokhar Samb",
      "Dietrich Klakow",
      "David Ifeoluwa Adelani"
    ]
  },
  "https://aclanthology.org/2025.acl-long.465": {
    "title": "Boosting Long-Context Information Seeking via Query-Guided Activation Refilling",
    "volume": "long",
    "abstract": "Processing long contexts poses a significant challenge for large language models (LLMs) due to their inherent context window limitations and the computational burden of extensive key-value (KV) activations, which severely impact efficiency. For information-seeking tasks, full context perception is often unnecessary, as a query's information needs can dynamically range from localized details to a global perspective, depending on its complexity. However, existing methods struggle to adapt effectively to this dynamic information needs.In the paper, we propose a method for processing long-context information-seeking tasks via query-guided ACtivation REfilling (ACRE). ACRE constructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache compactly captures global information, and the layer-2 (L2) cache provides detailed, localized information. ACRE establishes a proxying relationship between the two caches, allowing the input query to attend to the L1 cache and dynamically refill it with relevant entries from the L2 cache. This mechanism integrates global understanding with query-specific local details, thereby enhancing answer decoding. Experiments on a variety of long-context information-seeking datasets demonstrate ACRE's effectiveness, achieving significant improvements in both performance and efficiency",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjin Qian",
      "Zheng Liu",
      "Peitian Zhang",
      "Zhicheng Dou",
      "Defu Lian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.466": {
    "title": "Efficient Pretraining Data Selection for Language Models via Multi-Actor Collaboration",
    "volume": "long",
    "abstract": "Efficient data selection is crucial to accelerate the pretraining of language model (LMs). While various methods have been proposed to enhance data efficiency, limited research has addressed the inherent conflicts between these approaches to achieve optimal data selection for LM pretraining. To tackle this problem, we propose a multi-actor collaborative data selection mechanism. Each data selection method independently prioritizes data based on its specific criterion and updates its prioritization rules using the current state of the model, functioning as an independent actor for data selection. Additionally, a console is designed to adjust the impacts of different actors at various stages and dynamically integrate information from all actors throughout the LM pretraining process. We conduct extensive empirical studies to evaluate our multi-actor framework. The experimental results demonstrate that our approach significantly improves data efficiency, accelerates convergence in LM pretraining, and achieves an average relative performance gain up to 10.5% across multiple language model benchmarks compared to the state-of-the-art methods",
    "checked": true,
    "id": "12f611380796b2bfa960a6ebf3124eeb879f7428",
    "semantic_title": "efficient pretraining data selection for language models via multi-actor collaboration",
    "citation_count": 6,
    "authors": [
      "Tianyi Bai",
      "Ling Yang",
      "Zhen Hao Wong",
      "Fupeng Sun",
      "Xinlin Zhuang",
      "Jiahui Peng",
      "Chi Zhang",
      "Lijun Wu",
      "Qiu Jiantao",
      "Wentao Zhang",
      "Binhang Yuan",
      "Conghui He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.467": {
    "title": "AdaDHP: Fine-Grained Fine-Tuning via Dual Hadamard Product and Adaptive Parameter Selection",
    "volume": "long",
    "abstract": "With the continuously expanding parameters, efficiently adapting large language models to downstream tasks is crucial in resource-limited conditions. Many parameter-efficient fine-tuning methods have emerged to address this challenge. However, they lack flexibility, like LoRA requires manually selecting trainable parameters and rank size, (IA)3 can only scale the activations along columns, yielding inferior results due to less precise fine-tuning. To address these issues, we propose a novel method named AdaDHP with fewer parameters and finer granularity, which can adaptively select important parameters for each task. Specifically, we introduce two trainable vectors for each parameter and fine-tune the parameters through Hadamard product along both rows and columns. This significantly reduces the number of trainable parameters, with our parameter count capped at the lower limit of LoRA. Moreover, we design an adaptive parameter selection strategy to select important parameters for downstream tasks dynamically. This allows our method to flexibly remove unimportant parameters for downstream tasks. Finally, we demonstrate the superiority of our method on the T5-base model across 17 NLU tasks and on complex mathematical tasks with the Llama series models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Liu",
      "Changya Li",
      "Xiaotong Zhang",
      "Feng Zhang",
      "Fenglong Ma",
      "Wei Wang",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.468": {
    "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph",
    "volume": "long",
    "abstract": "In this paper, we aim to improve the reasoning ability of large language models(LLMs) over knowledge graphs(KGs) to answer complex questions. Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent, which enables a small LLM to actively make decisions until finishing the reasoning process over KGs. In KG-Agent, we integrate the LLM, multifunctional toolbox, KG-based executor, and knowledge memory, and develop an iteration mechanism that autonomously selects the tool and then updates the memory for reasoning over KG. To guarantee the effectiveness, we leverage program language to formulate the multi-hop reasoning process over the KG and synthesize a code-based instruction dataset to fine-tune the base LLM. Extensive experiments demonstrate that only using 10K samples for tuning LLaMA2-7B can outperform competitive methods using larger LLMs or more data, on both in-domain and out-domain datasets. Our code and data will be publicly released",
    "checked": true,
    "id": "a8f3ffeddef17b4e46d981ca50ad319a76ac0b36",
    "semantic_title": "kg-agent: an efficient autonomous agent framework for complex reasoning over knowledge graph",
    "citation_count": 0,
    "authors": [
      "Jinhao Jiang",
      "Kun Zhou",
      "Xin Zhao",
      "Yang Song",
      "Chen Zhu",
      "Hengshu Zhu",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.469": {
    "title": "Curriculum Debiasing: Toward Robust Parameter-Efficient Fine-Tuning Against Dataset Biases",
    "volume": "long",
    "abstract": "Parameter-efficient fine-tuning (PEFT) addresses the memory footprint issue of full fine-tuning by modifying only a subset of model parameters. However, on datasets exhibiting spurious correlations, we observed that PEFT slows down the model's convergence on unbiased examples, while the convergence on biased examples remains fast. This leads to the model's overfitting on biased examples, causing significant performance degradation in out-of-distribution (OOD) scenarios. Traditional debiasing methods mitigate this issue by emphasizing unbiased examples during training but often come at the cost of in-distribution (ID) performance drops. To address this trade-off issue, we propose a curriculum debiasing framework that presents examples in a biased-to-unbiased order. Our framework initially limits the model's exposure to unbiased examples, which are harder to learn, allowing it to first establish a foundation on easier-to-converge biased examples. As training progresses, we gradually increase the proportion of unbiased examples in the training set, guiding the model away from reliance on spurious correlations. Compared to the original PEFT methods, our method accelerates convergence on unbiased examples by approximately twofold and improves ID and OOD performance by 1.2% and 8.0%, respectively",
    "checked": false,
    "id": "5abd9f4ee779998c0417ac575705f8395eb35331",
    "semantic_title": "genomeocean: an efficient genome foundation model trained on large-scale metagenomic assemblies",
    "citation_count": 4,
    "authors": [
      "Mingyu Lee",
      "Yeachan Kim",
      "Wing-Lam Mok",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.470": {
    "title": "Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings",
    "volume": "long",
    "abstract": "The large language model (LLM)-as-judge paradigm has been used to meet the demand for a cheap, reliable, and fast evaluation of model outputs during AI system development and post-deployment monitoring. While judge models—LLMs finetuned to specialize in assessing and critiquing model outputs—have been touted as general purpose evaluators, they are typically evaluated only on non-contextual scenarios, such as instruction following. The omission of contextual settings—those where external information is used as context to generate an output—is surprising given the increasing prevalence of retrieval-augmented generation (RAG) and summarization use cases. Contextual assessment is uniquely challenging, as evaluation often depends on practitioner priorities, leading to conditional evaluation criteria (e.g., comparing responses based on factuality and then considering completeness if they are equally factual). To address the gap, we propose ContextualJudgeBench, a judge benchmark with 2,000 challenging response pairs across eight splits inspired by real-world contextual evaluation scenarios. We build our benchmark with a multi-pronged data construction pipeline that leverages both existing human annotations and model-based perturbations. Our comprehensive study across 11 judge models and 7 general purpose models, reveals that the contextual information and assessment criteria present a significant challenge to even state-of-the-art models. For example, o1, the best-performing model, barely reaches 55% consistent accuracy",
    "checked": true,
    "id": "9f424c20deca24f854ea2e8484b00aef888037ca",
    "semantic_title": "does context matter? contextualjudgebench for evaluating llm-based judges in contextual settings",
    "citation_count": 3,
    "authors": [
      "Austin Xu",
      "Srijan Bansal",
      "Yifei Ming",
      "Semih Yavuz",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2025.acl-long.471": {
    "title": "On the Reliability of Large Language Models for Causal Discovery",
    "volume": "long",
    "abstract": "This study investigates the efficacy of Large Language Models (LLMs) in causal discovery. Using newly available open-source LLMs, OLMo and BLOOM, which provide access to their pre-training corpora, we investigate how LLMs address causal discovery through three research questions. We examine: (i) the impact of memorization for accurate causal relation prediction, (ii) the influence of incorrect causal relations in pre-training data, and (iii) the contextual nuances that influence LLMs' understanding of causal relations. Our findings indicate that while LLMs are effective in recognizing causal relations that occur frequently in pre-training data, their ability to generalize to new or rare causal relations is limited. Moreover, the presence of incorrect causal relations significantly undermines the confidence of LLMs in corresponding correct causal relations, and the contextual information critically affects the outcomes of LLMs to discern causal connections between random variables",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Feng",
      "Lizhen Qu",
      "Niket Tandon",
      "Zhuang Li",
      "Xiaoxi Kang",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2025.acl-long.472": {
    "title": "Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts",
    "volume": "long",
    "abstract": "The recent progress in Vision-Language Models (VLMs) has broadened the scope of multimodal applications. However, evaluations often remain limited to functional tasks, neglecting abstract dimensions such as personality traits and human values. To address this gap, we introduce Value-Spectrum, a novel Visual Question Answering (VQA) benchmark aimed at assessing VLMs based on Schwartz's value dimensions that capture core human values guiding people's preferences and actions. We design a VLM agent pipeline to simulate video browsing and construct a vector database comprising over 50,000 short videos from TikTok, YouTube Shorts, and Instagram Reels. These videos span multiple months and cover diverse topics, including family, health, hobbies, society, technology, etc. Benchmarking on Value-Spectrum highlights notable variations in how VLMs handle value-oriented content. Beyond identifying VLMs' intrinsic preferences, we also explore the ability of VLM agents to adopt specific personas when explicitly prompted, revealing insights into the adaptability of the model in role-playing scenarios. These findings highlight the potential of Value-Spectrum as a comprehensive evaluation set for tracking VLM preferences in value-based tasks and abilities to simulate diverse personas. The complete code and data are available at https://github.com/Jeremyyny/Value-Spectrum",
    "checked": true,
    "id": "153cedea5ae6e675572296e3574553be68e21006",
    "semantic_title": "value-spectrum: quantifying preferences of vision-language models via value decomposition in social media contexts",
    "citation_count": 0,
    "authors": [
      "Jingxuan Li",
      "Yuning Yang",
      "Shengqi Yang",
      "Linfan Zhang",
      "Ying Nian Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.473": {
    "title": "TeRDy: Temporal Relation Dynamics through Frequency Decomposition for Temporal Knowledge Graph Completion",
    "volume": "long",
    "abstract": "Temporal knowledge graph completion aims to predict missing facts in a knowledge graph by leveraging temporal information. Existing methods often struggle to capture both the long-term changes and short-term variability of relations, which are crucial for accurate prediction. In this paper, we propose a novel method called TeRDy for temporal knowledge graph completion. TeRDy captures temporal relational dynamics by utilizing time-invariant embeddings, along with long-term temporally dynamic embeddings (e.g., enduring political alliances) and short-term temporally dynamic embeddings (e.g., transient political events). These two types of embeddings are derived from low- and high-frequency components via frequency decomposition. Also, we design temporal smoothing and temporal gradient to seamlessly incorporate timestamp embeddings into relation embeddings. Extensive experiments on benchmark datasets demonstrate that TeRDy outperforms state-of-the-art temporal knowledge graph embedding methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Liu",
      "Chaokun Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.474": {
    "title": "Incorporating Domain Knowledge into Materials Tokenization",
    "volume": "long",
    "abstract": "While language models are increasingly utilized in materials science, typical models rely on frequency-centric tokenization methods originally developed for natural language processing. However, these methods frequently produce excessive fragmentation and semantic loss, failing to maintain the structural and semantic integrity of material concepts. To address this issue, we propose MATTER, a novel tokenization approach that integrates material knowledge into tokenization. Based on MatDetector trained on our materials knowledge base and re-ranking method prioritizing material terms in token merging, MATTER maintains the structural integrity of identified materials concepts and prevents fragmentation during tokenization, ensuring their semantic meaning remains intact. The experimental results demonstrate that MATTER outperforms existing tokenization methods, achieving an average performance gain of 4% and 2% in the generation and classification tasks, respectively. These results underscore the importance of domain knowledge for tokenization strategies in scientific text processing",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yerim Oh",
      "Jun-Hyung Park",
      "Junho Kim",
      "SungHo Kim",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.475": {
    "title": "PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) excel in various domains but pose inherent privacy risks. Existing methods to evaluate privacy leakage in LLMs often use memorized prefixes or simple instructions to extract data, both of which well-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM safety mechanisms to generate harmful content, but their role in privacy scenarios remains underexplored. In this paper, we examine the effectiveness of jailbreak attacks in extracting sensitive information, bridging privacy leakage and jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework targeting Personally Identifiable Information (PII) and addressing the limitations of current jailbreak methods. Specifically, PIG identifies PII entities and their types in privacy queries, uses in-context learning to build a privacy context, and iteratively updates it with three gradient-based strategies to elicit target PII. We evaluate PIG and existing jailbreak methods using two privacy-related datasets. Experiments on four white-box and two black-box LLMs show that PIG outperforms baseline methods and achieves state-of-the-art (SoTA) results. The results underscore significant privacy risks in LLMs, emphasizing the need for stronger safeguards",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yidan Wang",
      "Yanan Cao",
      "Yubing Ren",
      "Fang Fang",
      "Zheng Lin",
      "Binxing Fang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.476": {
    "title": "Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks",
    "volume": "long",
    "abstract": "Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking pragmatic systems that have constrains such as limited token bandwidth, latency between message delivery, and defense mechanisms. We design a permutation-invariant adversarial attack that optimizes prompt distribution across latency and bandwidth-constraint network topologies to bypass distributed safety mechanisms within the system. Formulating the attack path as a problem of maximum-flow minimum-cost, coupled with the novel Permutation-Invariant Evasion Loss (PIEL), we leverage graph-based optimization to maximize attack success rate while minimizing detection risk. Evaluating across models including Llama, Mistral, Gemma, DeepSeek and other variants on various datasets like JailBreakBench and AdversarialBench, our method outperforms conventional attacks by up to 7×, exposing critical vulnerabilities in multi-agent systems. Moreover, we demonstrate that existing defenses, including variants of Llama-Guard and PromptGuard, fail to prohibit our attack, emphasizing the urgent need for multi-agent specific safety mechanisms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rana Shahroz",
      "Zhen Tan",
      "Sukwon Yun",
      "Charles Fleming",
      "Tianlong Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.477": {
    "title": "Semantic-Eval : A Semantic Comprehension Evaluation Framework for Large Language Models Generation without Training",
    "volume": "long",
    "abstract": "With the increasing prominence of large language models (LLMs), evaluating their text-generation capabilities has become an essential research challenge. Although LLM-based evaluation methods exhibit robust performance, the inherent stochastic nature of the LLM generation process introduces a degree of uncertainty in alignment with human preferences. To address this limitation, we propose Semantic-Eval, the first training-free framework designed to assess LLM-generated text based on semantic understanding. This framework computes semantic similarity between pairwise texts to evaluate the interdependence of semantic units, integrating a graph-based weighting mechanism to account for the differential contributions of individual sentences. A pre-trained natural language inference (NLI) model is also incorporated to mitigate potential semantic relationship biases. We evaluate Semantic-Eval across eight datasets that encompass four common NLP tasks. The experimental results indicate that Semantic-Eval surpasses traditional N-gram and BERT-based evaluation metrics, aligning more closely with human judgments and demonstrating a higher correlation than smaller LLMs. However, it slightly lags behind GPT-4. Finally, we demonstrate the effectiveness of Semantic-Eval in evaluating the generation quality of 13 large language models. The code is publicly available at https://github.com/LssTry/Semantic-Eval",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shusheng Li",
      "Jiale Li",
      "Yifei Qu",
      "Xinwei Shi",
      "Yanliang Guo",
      "Ziyi He",
      "Yubo Wang",
      "Wenjun Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.478": {
    "title": "Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases",
    "volume": "long",
    "abstract": "Pretraining language models on formal language can improve their acquisition of natural language. Which features of the formal language impart an inductive bias that leads to effective transfer? Drawing on insights from linguistics and complexity theory, we hypothesize that effective transfer occurs when two conditions are met: the formal language should capture the dependency structures present in natural language, and it should remain within the computational limitations of the model architecture. We experiment with pre-pretraining (training on formal language before natural languages) on transformers and find that formal languages capturing hierarchical dependencies indeed enable language models to achieve lower loss on natural language and better linguistic generalization compared to other formal languages. We also find modest support for the hypothesis that the formal language should fall within the computational limitations of the architecture. Strikingly, pre-pretraining reduces loss more efficiently than training on a matched amount of natural language. For a 1B-parameter language model trained on roughly 1.6B tokens of natural language, pre-pretraining achieves the same loss and better linguistic generalization with a 33% smaller token budget. Finally, we also give mechanistic evidence of transfer from formal tonatural language: attention heads acquired during pre-pretraining remain crucial for the model's performance on syntactic evaluations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Y. Hu",
      "Jackson Petty",
      "Chuan Shi",
      "William Merrill",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.479": {
    "title": "When to Speak, When to Abstain: Contrastive Decoding with Abstention",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across diverse tasks by leveraging pre-trained (i.e., parametric) and external (i.e., contextual) knowledge. While substantial efforts have been made to enhance the utilization of both forms of knowledge, situations in which models lack relevant information remain underexplored. To investigate this challenge, we first present a controlled testbed featuring four distinct knowledge access scenarios, including the aforementioned edge case, revealing that conventional LLM usage exhibits insufficient robustness in handling all instances. Addressing this limitation, we propose Contrastive Decoding with Abstention (CDA), a novel training-free decoding method that allows LLMs to generate responses when relevant knowledge is available and to abstain otherwise. CDA estimates the relevance of both knowledge sources for a given input, adaptively deciding which type of information to prioritize and which to exclude. Through extensive experiments, we demonstrate that CDA can effectively perform accurate generation and abstention simultaneously, enhancing reliability and preserving user trust",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyuhng Joon Kim",
      "Youna Kim",
      "Sang-goo Lee",
      "Taeuk Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.480": {
    "title": "On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs",
    "volume": "long",
    "abstract": "Evidence-enhanced detectors present remarkable abilities in identifying malicious social text. However, the rise of large language models (LLMs) brings potential risks of evidence pollution to confuse detectors. This paper explores potential manipulation scenarios including basic pollution, and rephrasing or generating evidence by LLMs. To mitigate the negative impact, we propose three defense strategies from the data and model sides, including machine-generated text detection, a mixture of experts, and parameter updating. Extensive experiments on four malicious social text detection tasks with ten datasets illustrate that evidence pollution significantly compromises detectors, where the generating strategy causes up to a 14.4% performance drop. Meanwhile, the defense strategies could mitigate evidence pollution, but they faced limitations for practical employment. Further analysis illustrates that polluted evidence (i) is of high quality, evaluated by metrics and humans; (ii) would compromise the model calibration, increasing expected calibration error up to 21.6%; and (iii) could be integrated to amplify the negative impact, especially for encoder-based LMs, where the accuracy drops by 21.8%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Herun Wan",
      "Minnan Luo",
      "Zhixiong Su",
      "Guang Dai",
      "Xiang Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.481": {
    "title": "Investigating and Extending Homans' Social Exchange Theory with Large Language Model based Agents",
    "volume": "long",
    "abstract": "Homans' Social Exchange Theory (SET) is widely recognized as a basic framework for understanding the formation and emergence of human civilizations and social structures. In social science, this theory is typically studied based on simple simulation experiments or real-world human studies, both of which either lack realism or are too expensive to control. In artificial intelligence, recent advances in large language models (LLMs) have shown promising capabilities in simulating human behaviors. Inspired by these insights, we adopt an interdisciplinary research perspective and propose using LLM-based agents to study Homans' SET. Specifically, we construct a virtual society composed of three LLM agents and have them engage in a social exchange game to observe their behaviors. Through extensive experiments, we found that Homans' SET is well validated in our agent society, demonstrating the consistency between the agent and human behaviors. Building on this foundation, we intentionally alter the settings of the agent society to extend the traditional Homans' SET, making it more comprehensive and detailed. To the best of our knowledge, this paper marks the first step in studying Homans' SET with LLM-based agents. More importantly, it introduces a novel and feasible research paradigm that bridges the fields of social science and computer science through LLM-based agents. Code is available at https://github.com/Paitesanshi/SET",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Wang",
      "Zheqing Zhang",
      "Xu Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.482": {
    "title": "A Drop-In Solution for On-the-Fly Adaptation of Speculative Decoding in Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are cutting-edge generative AI models built on transformer architecture, which tend to be highly memory-intensive when performing real-time inference. Various strategies have been developed to enhance the end-to-end inference speed for LLMs, one of which is speculative decoding. This technique involves running a smaller LLM (draft model) for inference over a defined window size, denoted as 𝛾, while simultaneously being validated by the larger LLM (target model). Choosing the optimal 𝛾 value and the draft model is essential for unlocking the potential of speculative decoding. But it is difficult to do due to the complicated influence from various factors, including the nature of the task, the hardware in use, and the combination of the large and small models. This paper introduces *on-the-fly adaption of speculative decoding*, a solution that dynamically adapts the choices to maximize the efficiency of speculative decoding for LLM inferences. As a drop-in solution, it needs no offline benchmarking or training. Experiments show that the solution can lead to 3.55-16.48% speed improvement over the standard speculative decoding, and 1.2-3.4× over the default LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiesong Liu",
      "Brian Park",
      "Xipeng Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.483": {
    "title": "If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation?",
    "volume": "long",
    "abstract": "Recent work in computational psycholinguistics has revealed intriguing parallels between attention mechanisms and human memory retrieval, focusing primarily on vanilla Transformers that operate on token-level representations. However, computational psycholinguistic research has also established that syntactic structures provide compelling explanations for human sentence processing that token-level factors cannot fully account for. In this paper, we investigate whether the attention mechanism of Transformer Grammar (TG), which uniquely operates on syntactic structures as representational units, can serve as a cognitive model of human memory retrieval, using Normalized Attention Entropy (NAE) as a linking hypothesis between models and humans. Our experiments demonstrate that TG's attention achieves superior predictive power for self-paced reading times compared to vanilla Transformer's, with further analyses revealing independent contributions from both models. These findings suggest that human sentence processing involves dual memory representations—one based on syntactic structures and another on token sequences—with attention serving as the general memory retrieval algorithm, while highlighting the importance of incorporating syntactic structures as representational units",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryo Yoshida",
      "Shinnosuke Isono",
      "Kohei Kajikawa",
      "Taiga Someya",
      "Yushi Sugimoto",
      "Yohei Oseki"
    ]
  },
  "https://aclanthology.org/2025.acl-long.484": {
    "title": "Aligning VLM Assistants with Personalized Situated Cognition",
    "volume": "long",
    "abstract": "Vision-language models (VLMs) aligned with general human objectives, such as being harmless and hallucination-free, have become valuable assistants of humans in managing visual tasks. However, people with diversified backgrounds have different cognition even in the same situation. Consequently, they may have personalized expectations for VLM assistants. This highlights the urgent need to align VLM assistants with personalized situated cognition for real-world assistance. To study this problem, we first simplify it by characterizing individuals based on the sociological concept of Role-Set. Then, we propose to evaluate the individuals' actions to examine whether the personalized alignment is achieved. Further, we construct a benchmark named PCogAlignBench, which includes 18k instances and 20 individuals with different Role-Sets. Finally, we present a framework called PCogAlign, which constructs a cognition-aware and action-based reward model for personalized alignment. Experimental results and human evaluations demonstrate the reliability of the PCogAlignBench and the effectiveness of our proposed PCogAlign. We will open-source the constructed benchmark and code after being accepted",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi Li",
      "Shen Zhou",
      "Xiaohu Li",
      "Xin Miao",
      "Jintao Wen",
      "Mayi Xu",
      "Jianhao Chen",
      "Birong Pan",
      "Hankun Kang",
      "Yuanyuan Zhu",
      "Ming Zhong",
      "Tieyun Qian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.485": {
    "title": "Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models",
    "volume": "long",
    "abstract": "Large language models have shown remarkable performance across a wide range of language tasks, owing to their exceptional capabilities in context modeling. The most commonly used method of context modeling is full self-attention, as seen in standard decoder-only Transformers. Although powerful, this method can be inefficient for long sequences and may overlook inherent input structures. To address these problems, an alternative approach is parallel context encoding, which splits the context into sub-pieces and encodes them parallelly. Because parallel patterns are not encountered during training, naively applying parallel encoding leads to performance degradation. However, the underlying reasons and potential mitigations are unclear. In this work, we provide a detailed analysis of this issue and identify that unusually high attention entropy can be a key factor. Furthermore, we adopt two straightforward methods to reduce attention entropy by incorporating attention sinks and selective mechanisms. Experiments on various tasks reveal that these methods effectively lower irregular attention entropy and narrow performance gaps. We hope this study can illuminate ways to enhance context modeling mechanisms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhisong Zhang",
      "Yan Wang",
      "Xinting Huang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Chenlong Deng",
      "Shuaiyi Li",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.486": {
    "title": "Faster Speculative Decoding via Effective Draft Decoder with Pruned Candidate Tree",
    "volume": "long",
    "abstract": "Speculative Decoding (SD) is a promising method for reducing the inference latency of large language models (LLMs). A well-designed draft model and an effective draft candidate tree construction method are key to enhancing the acceleration effect of SD. In this paper, we first propose the Effective Draft Decoder (EDD), which treats the LLM as a powerful encoder and generates more accurate draft tokens by leveraging the encoding results as soft prompts. Furthermore, we use KL divergence instead of the standard cross-entropy loss to better align the draft model's output with the LLM. Next, we introduce the Pruned Candidate Tree (PCT) algorithm to construct a more efficient candidate tree. Specifically, we found that the confidence scores predicted by the draft model are well-calibrated with the acceptance probability of draft tokens. Therefore, PCT estimates the expected time gain for each node in the candidate tree based on confidence scores and retains only the nodes that contribute to acceleration, pruning away redundant nodes. We conducted extensive experiments with various LLMs across four datasets. The experimental results verify the effectiveness of our proposed method, which significantly improves the performance of SD and reduces the inference latency of LLMs",
    "checked": false,
    "id": "67ae3e9d24943f8a22b5a9ea376d7e7611b9ba29",
    "semantic_title": "boosting lossless speculative decoding via feature sampling and partial alignment distillation",
    "citation_count": 2,
    "authors": [
      "Huanran Zheng",
      "Xiaoling Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.487": {
    "title": "Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models",
    "volume": "long",
    "abstract": "Supervised fine-tuning (SFT) is widely used to align large language models (LLMs) with information extraction (IE) tasks, such as named entity recognition (NER). However, annotating such fine-grained labels and training domain-specific models is costly. Existing works typically train a unified model across multiple domains, but such approaches lack adaptation and scalability since not all training data benefits target domains and scaling trained models remains challenging. We propose the SaM framework, which dynamically Selects and Merges expert models at inference time. Specifically, for a target domain, we select domain-specific experts pre-trained on existing domains based on (i) domain similarity to the target domain and (ii) performance on sampled instances, respectively. The experts are then merged to create task-specific models optimized for the target domain. By dynamically merging experts beneficial to target domains, we improve generalization across various domains without extra training. Additionally, experts can be added or removed conveniently, leading to great scalability. Extensive experiments on multiple benchmarks demonstrate our framework's effectiveness, which outperforms the unified model by an average of 10%. We further provide insights into potential improvements, practical experience, and extensions of our framework",
    "checked": true,
    "id": "7b3ef5de5bd7046c7af67d55b0d8e3f34cd1a749",
    "semantic_title": "selecting and merging: towards adaptable and scalable named entity recognition with large language models",
    "citation_count": 0,
    "authors": [
      "Zhuojun Ding",
      "Wei Wei",
      "Chenghao Fan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.488": {
    "title": "Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents",
    "volume": "long",
    "abstract": "Large language models (LLMs) are revolutionizing education, with LLM-based agents playing a key role in simulating student behavior. A major challenge in student simulation is modeling the diverse learning patterns of students at various cognitive levels. However, current LLMs, typically trained as \"helpful assistants\", target at generating perfect responses. As a result, they struggle to simulate students with diverse cognitive abilities, as they often produce overly advanced answers, missing the natural imperfections that characterize student learning and resulting in unrealistic simulations. To address this issue, we propose a training-free framework for student simulation. We begin by constructing a cognitive prototype for each student using a knowledge graph, which captures their understanding of concepts from past learning records. This prototype is then mapped to new tasks to predict student performance. Next, we simulate student solutions based on these predictions and iteratively refine them using a beam search method to better replicate realistic mistakes. To validate our approach, we construct the Student_100 dataset, consisting of 100 students working on Python programming and 5,000 learning records. Experimental results show that our method consistently outperforms baseline models, achieving 100% improvement in simulation accuracy and realism",
    "checked": true,
    "id": "01025aed4b22071f2fe45932bf7a05a43930694e",
    "semantic_title": "embracing imperfection: simulating students with diverse cognitive levels using llm-based agents",
    "citation_count": 1,
    "authors": [
      "Tao Wu",
      "Jingyuan Chen",
      "Wang Lin",
      "Mengze Li",
      "Yumeng Zhu",
      "Ang Li",
      "Kun Kuang",
      "Fei Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.489": {
    "title": "CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction",
    "volume": "long",
    "abstract": "Computer-aided design (CAD) is crucial in prototyping 3D objects through geometric instructions (i.e., CAD programs). In practical design workflows, designers often engage in time-consuming reviews and refinements of these prototypes by comparing them with reference images. To bridge this gap, we introduce the CAD review task to automatically detect and correct potential errors, ensuring consistency between the constructed 3D objects and reference images. However, recent advanced multimodal large language models (MLLMs) struggle to recognize multiple geometric components and perform spatial geometric operations within the CAD program, leading to inaccurate reviews. In this paper, we propose the CAD program repairer (ReCAD) framework to effectively detect program errors and provide helpful feedback on error correction. Additionally, we create a dataset, CADReview, consisting of over 20K program-image pairs, with diverse errors for the CAD review task. Extensive experiments demonstrate that our ReCAD significantly outperforms existing MLLMs, which shows great potential in design applications",
    "checked": true,
    "id": "90f8e148a0efb9f8c2404522d65079f101d03b1d",
    "semantic_title": "cadreview: automatically reviewing cad programs with error detection and correction",
    "citation_count": 0,
    "authors": [
      "Jiali Chen",
      "Xusen Hei",
      "HongFei Liu",
      "Yuancheng Wei",
      "Zikun Deng",
      "Jiayuan Xie",
      "Yi Cai",
      "Li Qing"
    ]
  },
  "https://aclanthology.org/2025.acl-long.490": {
    "title": "Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling",
    "volume": "long",
    "abstract": "Despite their outstanding capabilities, large language models (LLMs) are prone to hallucination and producing factually incorrect information. This challenge has spurred efforts in attributed text generation, which prompts LLMs to generate content with supporting evidence. In this paper, we propose a novel framework, called Think&Cite, and formulate attributed text generation as a multi-step reasoning problem integrated with search. Specifically, we propose Self-Guided Monte Carlo Tree Search (SG-MCTS), which capitalizes on the self-reflection capability of LLMs to reason about the intermediate states of MCTS for guiding the tree expansion process. To provide reliable and comprehensive feedback, we introduce Progress Reward Modeling to measure the progress of tree search from the root to the current state from two aspects, i.e., generation and attribution progress. We conduct extensive experiments on three datasets and the results show that our approach significantly outperforms baseline approaches",
    "checked": true,
    "id": "18ea1a2845fcab8cd1bcb0d0b8ffb355cff665a9",
    "semantic_title": "think&cite: improving attributed text generation with self-guided tree search and progress reward modeling",
    "citation_count": 1,
    "authors": [
      "Junyi Li",
      "Hwee Tou Ng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.491": {
    "title": "The Lawyer That Never Thinks: Consistency and Fairness as Keys to Reliable AI",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are increasingly used in high-stakes domains like law and research, yet their inconsistencies and response instability raise concerns about trustworthiness. This study evaluates six leading LLMs—GPT-3.5, GPT-4, Claude, Gemini, Mistral, and LLaMA 2—on rationality, stability, and ethical fairness through reasoning tests, legal challenges, and bias-sensitive scenarios. Results reveal significant inconsistencies, highlighting trade-offs between model scale, architecture, and logical coherence. These findings underscore the risks of deploying LLMs in legal and policy settings, emphasizing the need for AI systems that prioritize transparency, fairness, and ethical robustness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dana R Alsagheer",
      "Abdulrahman Kamal",
      "Mohammad Kamal",
      "Cosmo Yang Wu",
      "Weidong Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.492": {
    "title": "Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean",
    "volume": "long",
    "abstract": "We introduce the ̲Korean ̲Grammar ̲Evaluation Bench ̲Mark (KoGEM), designed to assess the linguistic competence of LLMs and humans in Korean. KoGEM consists of 1.5k multiple-choice QA pairs covering five main categories and 16 subcategories. The zero-shot evaluation of 27 LLMs of various sizes and types reveals that while LLMs perform remarkably well on straightforward tasks requiring primarily definitional knowledge, they struggle with tasks that demand the integration of real-world experiential knowledge, such as phonological rules and pronunciation. Furthermore, our in-depth analysis suggests that incorporating such experiential knowledge could enhance the linguistic competence of LLMs. With KoGEM, we not only highlight the limitations of current LLMs in linguistic competence but also uncover hidden facets of LLMs in linguistic competence, paving the way for enhancing comprehensive language understanding. Our code and dataset are available at: https://github.com/SungHo3268/KoGEM",
    "checked": true,
    "id": "1edd78428a2f52f20df5bf9a8b97b6fbc0ea0ceb",
    "semantic_title": "polishing every facet of the gem: testing linguistic competence of llms and humans in korean",
    "citation_count": 0,
    "authors": [
      "SungHo Kim",
      "Nayeon Kim",
      "Taehee Jeon",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.493": {
    "title": "SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods",
    "volume": "long",
    "abstract": "As speech generation technology advances, the risk of misuse through deepfake audio has become a pressing concern, which underscores the critical need for robust detection systems. However, many existing speech deepfake datasets are limited in scale and diversity, making it challenging to train models that can generalize well to unseen deepfakes. To address these gaps, we introduce SpeechFake, a large-scale dataset designed specifically for speech deepfake detection. SpeechFake includes over 3 million deepfake samples, totaling more than 3,000 hours of audio, generated using 40 different speech synthesis tools. The dataset encompasses a wide range of generation techniques, including text-to-speech, voice conversion, and neural vocoder, incorporating the latest cutting-edge methods. It also provides multilingual support, spanning 46 languages. In this paper, we offer a detailed overview of the dataset's creation, composition, and statistics. We also present baseline results by training detection models on SpeechFake, demonstrating strong performance on both its own test sets and various unseen test sets. Additionally, we conduct experiments to rigorously explore how generation methods, language diversity, and speaker variation affect detection performance. We believe SpeechFake will be a valuable resource for advancing speech deepfake detection and developing more robust models for evolving generation techniques",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Huang",
      "Yanmei Gu",
      "Zhiming Wang",
      "Huijia Zhu",
      "Yanmin Qian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.494": {
    "title": "ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation",
    "volume": "long",
    "abstract": "Code generation plays a crucial role in various tasks, such as code auto-completion and mathematical reasoning. Previous work has proposed numerous methods to enhance code generation performance, including integrating feedback from the compiler. Inspired by this, we present ReflectionCoder, a novel approach that effectively leverages reflection sequences constructed by integrating compiler feedback to improve one-off code generation performance. Furthermore, we propose reflection self-distillation and dynamically masked distillation to effectively utilize these reflection sequences. Extensive experiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E, demonstrate that models fine-tuned with our method achieve state-of-the-art performance. Beyond the code domain, we believe this approach can benefit other domains that focus on final results and require long reasoning paths. Code and data are available at https://github.com/SenseLLM/ReflectionCoder",
    "checked": true,
    "id": "7924cbe48fe2583058c076926873ea4027bf72a9",
    "semantic_title": "reflectioncoder: learning from reflection sequence for enhanced one-off code generation",
    "citation_count": 7,
    "authors": [
      "Houxing Ren",
      "Mingjie Zhan",
      "Zhongyuan Wu",
      "Aojun Zhou",
      "Junting Pan",
      "Hongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.495": {
    "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior",
    "volume": "long",
    "abstract": "Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose **InvestAlign**, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than the complex scenarios. Our theoretical analysis demonstrates that training LLMs with **InvestAlign**-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop **InvestAgent**, an LLM agent fine-tuned with **InvestAlign**, which shows significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed **InvestAlign** as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign",
    "checked": false,
    "id": "cb449d41030f55bdd6ac5db0823dd722913af112",
    "semantic_title": "investalign: align llms with investor decision-making under herd behavior",
    "citation_count": 0,
    "authors": [
      "Huisheng Wang",
      "Zhuoshi Pan",
      "Hangjing Zhang",
      "Mingxiao Liu",
      "Hanqing Gao",
      "H. Vicky Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.496": {
    "title": "Enhancing Neural Machine Translation Through Target Language Data: A kNN-LM Approach for Domain Adaptation",
    "volume": "long",
    "abstract": "Neural machine translation (NMT) has advanced significantly, yet challenges remain in adapting to new domains . In scenarios where bilingual data is limited, this issue is further exacerbated. To address this, we propose kNN-LM-NMT, a method that leverages semantically similar target language sentences in the kNN framework. Our approach generates a probability distribution over these sentences during decoding, and this distribution is then interpolated with the NMT model's distribution. Additionally, we introduce an n-gram-based approach to focus on similar fragments, enabling the model to avoid the noise introduced by the non-similar parts. To enhance accuracy, we further incorporate cross-lingual retrieval similarity to refine the kNN probability distribution. Extensive experiments on multi-domain datasets demonstrate significant performance improvements in both high-resource and low-resource scenarios. Our approach effectively extracts translation knowledge from limited target domain data, and well benefits from large-scale monolingual data for robust context representation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abudurexiti Reheman",
      "Hongyu Liu",
      "Junhao Ruan",
      "Abudukeyumu Abudula",
      "Yingfeng Luo",
      "Tong Xiao",
      "JingBo Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.497": {
    "title": "Multi-level Relevance Document Identifier Learning for Generative Retrieval",
    "volume": "long",
    "abstract": "Generative Retrieval (GR) introduces a new information retrieval paradigm that directly generates unique document identifiers (DocIDs). The key challenge of GR lies in creating effective yet discrete DocIDs that preserve semantic relevance for similar documents while differentiating dissimilar ones. However, existing methods generate DocIDs solely based on the textual content of documents, which may result in DocIDs with weak semantic connections for similar documents due to variations in expression. Therefore, we propose using queries as a bridge to connect documents with varying relevance levels for learning improved DocIDs. In this paper, we propose **M**ulti-l**E**vel **R**elevance document identifier learning for **G**enerative r**E**trieval (MERGE), a novel approach that utilizes multi-level document relevance to learn high-quality DocIDs. MERGE incorporates three modules: a multi-relevance query-document alignment module to effectively align document representations with related queries, an outer-level contrastive learning module to capture binary-level relevance, and an inner-level multi-level relevance learning module to distinguish documents with different relevance levels. Our approach encodes rich hierarchical semantic information and maintains uniqueness across documents. Experimental results on real-world multilingual e-commerce search datasets demonstrate that MERGE significantly outperforms existing methods, underscoring its effectiveness. The source code is available at <https://github.com/zhangfw123/MERGE>",
    "checked": true,
    "id": "27f333d97a794590ed4cfae335933b8ba9d4acdc",
    "semantic_title": "multi-level relevance document identifier learning for generative retrieval",
    "citation_count": 0,
    "authors": [
      "Fuwei Zhang",
      "Xiaoyu Liu",
      "Xinyu Jia",
      "Yingfei Zhang",
      "Shuai Zhang",
      "Xiang Li",
      "Fuzhen Zhuang",
      "Wei Lin",
      "Zhao Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.498": {
    "title": "EfficientQAT: Efficient Quantization-Aware Training for Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) are crucial in modern natural language processing and artificial intelligence. However, they face challenges in managing their significant memory requirements. Although quantization-aware training (QAT) offers a solution by reducing memory consumption through low-bit representations with minimal accuracy loss, it is impractical due to substantial training resources. To address this, we propose Efficient Quantization-Aware Training (EfficientQAT), a more feasible QAT algorithm. EfficientQAT involves two consecutive phases: Block-wise training of all parameters (Block-AP) and end-to-end training of quantization parameters (E2E-QP). To the best of our knowledge, Block-AP is the first method to enable direct training of all parameters in a block-wise manner, reducing accuracy loss in low-bit scenarios by enhancing the solution space during optimization. E2E-QP then trains only the quantization parameters (step sizes) end-to-end, further improving the performance of quantized models by considering interactions among all sub-modules. Extensive experiments demonstrate that EfficientQAT outperforms previous quantization methods across a range of models, including base LLMs, instruction-tuned LLMs, and multimodal LLMs, with scales from 7B to 70B parameters at various quantization bits. For instance, EfficientQAT obtains a 2-bit Llama-2-70B model on a single A100-80GB GPU in 41 hours, with less than 3 points accuracy degradation compared to the full precision (69.48 vs. 72.41). Code is available at https://github.com/OpenGVLab/EfficientQAT",
    "checked": true,
    "id": "bb0799cffdb2d676e1b68d15183371473c03a4fd",
    "semantic_title": "efficientqat: efficient quantization-aware training for large language models",
    "citation_count": 35,
    "authors": [
      "Mengzhao Chen",
      "Wenqi Shao",
      "Peng Xu",
      "Jiahao Wang",
      "Peng Gao",
      "Kaipeng Zhang",
      "Ping Luo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.499": {
    "title": "Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder",
    "volume": "long",
    "abstract": "Recent research has shown that CLIP models struggle with visual reasoning tasks that require grounding compositionality, understanding spatial relationships, or capturing fine-grained details. One natural hypothesis is that the CLIP vision encoder does not embed essential information for these tasks. However, we find that this is not always the case: The encoder gathers query-relevant visual information, while CLIP fails to extract it. In particular, we show that another branch of Vision-Language Models (VLMs), Generative Multimodal Large Language Models (MLLMs), achieve significantly higher accuracy than CLIP in many of these tasks using the *same* vision encoder and weights, indicating that these Generative MLLMs *perceive more*—as they extract and utilize visual information more effectively. We conduct a series of controlled experiments and reveal that their success is attributed to multiple key design choices, including patch tokens, position embeddings, and prompt-based weighting. On the other hand, enhancing the training data alone or applying a stronger text encoder does not suffice to solve the task, and additional text tokens offer little benefit. Interestingly, we find that fine-grained visual reasoning is not exclusive to generative models trained by an autoregressive loss: When converted into CLIP-like encoders by contrastive finetuning, these MLLMs still outperform CLIP under the same cosine similarity-based evaluation protocol. Our study highlights the importance of VLM architectural choices and suggests directions for improving the performance of CLIP-like contrastive VLMs",
    "checked": true,
    "id": "92cddd47c5b4370a8e05cf3b1adb06b102d397d6",
    "semantic_title": "exploring how generative mllms perceive more than clip with the same vision encoder",
    "citation_count": 4,
    "authors": [
      "Siting Li",
      "Pang Wei Koh",
      "Simon Shaolei Du"
    ]
  },
  "https://aclanthology.org/2025.acl-long.500": {
    "title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization",
    "volume": "long",
    "abstract": "Summarizing long-form narratives—such as books, movies, and TV scripts—requires capturing intricate plotlines, character interactions, and thematic coherence, a task that remains challenging for existing LLMs. We introduce NexusSum, a multi-agent LLM framework for narrative summarization that processes long-form text through a structured, sequential pipeline—without requiring fine-tuning. Our approach introduces two key innovations: **(1) Dialogue-to-Description Transformation**: A narrative-specific preprocessing method that standardizes character dialogue and descriptive text into a unified format, improving coherence. **(2) Hierarchical Multi-LLM Summarization**: A structured summarization pipeline that optimizes chunk processing and controls output length for accurate, high-quality summaries. Our method establishes a new state-of-the-art in narrative summarization, achieving up to **a 30.0% improvement in BERTScore (F1)** across books, movies, and TV scripts. These results demonstrate the effectiveness of multi-agent LLMs in handling long-form content, offering a scalable approach for structured summarization in diverse storytelling domains",
    "checked": true,
    "id": "62b4867fa247172c54dfddac4f34c19ae3a25348",
    "semantic_title": "nexussum: hierarchical llm agents for long-form narrative summarization",
    "citation_count": 0,
    "authors": [
      "Hyuntak Kim",
      "Byung-Hak Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.501": {
    "title": "HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models",
    "volume": "long",
    "abstract": "Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design strategies to accumulate videos featuring clear human actions from the Internet. Second, videos are annotated in a standardized caption format that uses human attributes to distinguish individuals and chronologically details their actions and interactions. Through this pipeline, we curate two datasets, namely HAICTrain and HAICBench. **HAICTrain** comprises 126K video-caption pairs generated by Gemini-Pro and verified for training purposes. Meanwhile, **HAICBench** includes 412 manually annotated video-caption pairs and 2,000 QA pairs, for a comprehensive evaluation of human action understanding. Experimental results demonstrate that training with HAICTrain not only significantly enhances human understanding abilities across 4 benchmarks, but can also improve text-to-video generation results. Both the HAICTrain and HAICBench will be made open-source to facilitate further research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Wang",
      "Jingyun Hua",
      "Weihong Lin",
      "Yuanxing Zhang",
      "Fuzheng Zhang",
      "Jianlong Wu",
      "Di Zhang",
      "Liqiang Nie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.502": {
    "title": "Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education",
    "volume": "long",
    "abstract": "In AI-facilitated teaching, leveraging various query styles to interpret abstract text descriptions is crucial for ensuring high-quality teaching. However, current retrieval models primarily focus on natural text-image retrieval, making them insufficiently tailored to educational scenarios due to the ambiguities in the retrieval process. In this paper, we propose a diverse expression retrieval task tailored to educational scenarios, supporting retrieval based on multiple query styles and expressions. We introduce the STEM Education Retrieval Dataset (SER), which contains over 24,000 query pairs of different styles, and the Uni-Retrieval, an efficient and style-diversified retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts query style features as prototypes and builds a continuously updated Prompt Bank containing prompt tokens for diverse queries. This bank can updated during test time to represent domain-specific knowledge for different subject retrieval scenarios. Our framework demonstrates scalability and robustness by dynamically retrieving prompt tokens based on prototype similarity, effectively facilitating learning for unknown queries. Experimental results indicate that Uni-Retrieval outperforms existing retrieval models in most retrieval tasks",
    "checked": true,
    "id": "e99f45112c51c24472c82ac8c433e5946c0a0d9a",
    "semantic_title": "uni-retrieval: a multi-style retrieval framework for stem's education",
    "citation_count": 5,
    "authors": [
      "Yanhao Jia",
      "Xinyi Wu",
      "Li Hao",
      "QinglinZhang QinglinZhang",
      "Yuxiao Hu",
      "Shuai Zhao",
      "Wenqi Fan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.503": {
    "title": "DenseLoRA: Dense Low-Rank Adaptation of Large Language Models",
    "volume": "long",
    "abstract": "Low-rank adaptation (LoRA) has been developed as an efficient approach for adapting large language models (LLMs) by fine-tuning two low-rank matrices, thereby reducing the number of trainable parameters. However, prior research indicates that many of the weights in these matrices are redundant, leading to inefficiencies in parameter utilization. To address this limitation, we introduce Dense Low-Rank Adaptation (DenseLoRA), a novel approach that enhances parameter efficiency while achieving superior performance compared to LoRA. DenseLoRA builds upon the concept of representation fine-tuning, incorporating a single Encoder-Decoder to refine and compress hidden representations across all adaptation layers before applying adaptation. Instead of relying on two redundant low-rank matrices as in LoRA, DenseLoRA adapts LLMs through a dense low-rank matrix, improving parameter utilization and adaptation efficiency. We evaluate DenseLoRA on various benchmarks, showing that it achieves 83.8% accuracy with only 0.01% of trainable parameters, compared to LoRA's 80.8% accuracy with 0.70% of trainable parameters on LLaMA3-8B. Additionally, we conduct extensive experiments to systematically assess the impact of DenseLoRA's components on overall model performance",
    "checked": true,
    "id": "bfc20507c1144933e0b0ba7b64129b604011efb3",
    "semantic_title": "denselora: dense low-rank adaptation of large language models",
    "citation_count": 0,
    "authors": [
      "Lin Mu",
      "Xiaoyu Wang",
      "Li Ni",
      "Yang Li",
      "Zhize Wu",
      "Peiquan Jin",
      "Yiwen Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.504": {
    "title": "Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis",
    "volume": "long",
    "abstract": "Personalized AI assistants, a hallmark of the human-like capabilities of Large Language Models (LLMs), are a challenging application that intertwines multiple problems in LLM research. Despite the growing interest in the development of personalized assistants, the lack of an open-source conversational dataset tailored for personalization remains a significant obstacle for researchers in the field. To address this research gap, we introduce HiCUPID, a new benchmark to probe and unleash the potential of LLMs to deliver personalized responses. Alongside a conversational dataset, HiCUPID provides a Llama-3.2-based automated evaluation model whose assessment closely mirrors human preferences. We release our dataset, evaluation model, and code at https://github.com/12kimih/HiCUPID",
    "checked": true,
    "id": "31b6af6ce1cb6616670ba4c55511c0863cbb7120",
    "semantic_title": "exploring the potential of llms as personalized assistants: dataset, evaluation, and analysis",
    "citation_count": 0,
    "authors": [
      "Jisoo Mok",
      "Ik-hwan Kim",
      "Sangkwon Park",
      "Sungroh Yoon"
    ]
  },
  "https://aclanthology.org/2025.acl-long.505": {
    "title": "Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models",
    "volume": "long",
    "abstract": "Knowledge neuron theory provides a key approach to understanding the mechanisms of factual knowledge in Large Language Models (LLMs), which suggests that facts are stored within multi-layer perceptron neurons. This paper further explores **Degenerate Knowledge Neurons** (DKNs), where distinct sets of neurons can store identical facts, but unlike simple redundancy, they also participate in storing other different facts. Despite the novelty and unique properties of this concept, it has not been rigorously defined and systematically studied. Our contributions are: (1) We pioneer the study of structures in knowledge neurons by analyzing weight connection patterns, providing a comprehensive definition of DKNs from both functional and structural aspects. (2) Based on this definition, we develop the **Neuronal Topology Clustering** method, leading to a more accurate DKN identification. (3) We demonstrate the practical applications of DKNs in two aspects: guiding LLMs to learn new knowledge and relating to LLMs' robustness against input errors",
    "checked": true,
    "id": "f491faa624d8b425c88df2dee495d5ff7031f076",
    "semantic_title": "cracking factual knowledge: a comprehensive analysis of degenerate knowledge neurons in large language models",
    "citation_count": 1,
    "authors": [
      "Yuheng Chen",
      "Pengfei Cao",
      "Yubo Chen",
      "Yining Wang",
      "Shengping Liu",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.506": {
    "title": "Towards Context-Robust LLMs: A Gated Representation Fine-tuning Approach",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) enhanced with external contexts, such as through retrieval-augmented generation (RAG), often face challenges in handling imperfect evidence. They tend to over-rely on external knowledge, making them vulnerable to misleading and unhelpful contexts. To address this, we propose the concept of context-robust LLMs, which can effectively balance internal knowledge with external context, similar to human cognitive processes. Specifically, context-robust LLMs should rely on external context only when lacking internal knowledge, identify contradictions between internal and external knowledge, and disregard unhelpful contexts. To achieve this goal, we introduce Grft, a lightweight and plug-and-play gated representation fine-tuning approach. Grft consists of two key components: a gating mechanism to detect and filter problematic inputs, and low-rank representation adapters to adjust hidden representations. By training a lightweight intervention function with only 0.0004% of model size on fewer than 200 examples, Grft can effectively adapt LLMs towards context-robust behaviors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenglai Zeng",
      "Pengfei He",
      "Kai Guo",
      "Tianqi Zheng",
      "Hanqing Lu",
      "Yue Xing",
      "Hui Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.507": {
    "title": "On Support Samples of Next Word Prediction",
    "volume": "long",
    "abstract": "Language models excel in various tasks by making complex decisions, yet understanding the rationale behind these decisions remains a challenge. This paper investigates data-centric interpretability in language models, focusing on the next-word prediction task. Using representer theorem, we identify two types of support samples—those that either promote or deter specific predictions. Our findings reveal that being a support sample is an intrinsic property, predictable even before training begins. Additionally, while non-support samples are less influential in direct predictions, they play a critical role in preventing overfitting and shaping generalization and representation learning. Notably, the importance of non-support samples increases in deeper layers, suggesting their significant role in intermediate representation formation.These insights shed light on the interplay between data and model decisions, offering a new dimension to understanding language model behavior and interpretability",
    "checked": true,
    "id": "09201a50552c9a198c2195c536cd0f34aa5d1a76",
    "semantic_title": "on support samples of next word prediction",
    "citation_count": 0,
    "authors": [
      "Yuqian Li",
      "Yupei Du",
      "Yufang Liu",
      "Feifei Feng",
      "Mou Xiao Feng",
      "Yuanbin Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.508": {
    "title": "WebWalker: Benchmarking LLMs in Web Traversal",
    "volume": "long",
    "abstract": "Retrieval-augmented generation (RAG) demonstrates remarkable performance across tasks in open-domain question-answering. However, traditional search engines may retrieve shallow content, limiting the ability of LLMs to handle complex, multi-layered information. To address this, we introduce WebWalkerQA, a benchmark designed to assess the ability of LLMs to perform web traversal. It evaluates the capacity of LLMs to traverse a website's subpages to extract high-quality data systematically. We propose WebWalker, which is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm. Extensive experimental results show that WebWalkerQA is challenging and demonstrates the effectiveness of RAG combined with WebWalker, through this horizontal and vertical integration in real-world scenarios",
    "checked": true,
    "id": "eaa6ffc25363ce88d7887f58f5b03a0c26231c36",
    "semantic_title": "webwalker: benchmarking llms in web traversal",
    "citation_count": 14,
    "authors": [
      "Jialong Wu",
      "Wenbiao Yin",
      "Yong Jiang",
      "Zhenglin Wang",
      "Zekun Xi",
      "Runnan Fang",
      "Linhai Zhang",
      "Yulan He",
      "Deyu Zhou",
      "Pengjun Xie",
      "Fei Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.509": {
    "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models",
    "volume": "long",
    "abstract": "The rise of Large Language Models (LLMs) has heightened concerns about the misuse of AI-generated text, making watermarking a promising solution. Mainstream watermarking schemes for LLMs fall into two categories: logits-based and sampling-based. However, current schemes entail trade-offs among robustness, text quality, and security. To mitigate this, we integrate logits-based and sampling-based schemes, harnessing their respective strengths to achieve synergy. In this paper, we propose a versatile symbiotic watermarking framework with three strategies: serial, parallel, and hybrid. The hybrid framework adaptively embeds watermarks using token entropy and semantic entropy, optimizing the balance between detectability, robustness, text quality, and security. Furthermore, we validate our approach through comprehensive experiments on various datasets and models. Experimental results indicate that our method outperforms existing baselines and achieves state-of-the-art (SOTA) performance. We believe this framework provides novel insights into diverse watermarking paradigms",
    "checked": true,
    "id": "724f02cfe9fea23d95055198575d9db255e9ac80",
    "semantic_title": "from trade-off to synergy: a versatile symbiotic watermarking framework for large language models",
    "citation_count": 0,
    "authors": [
      "Yidan Wang",
      "Yubing Ren",
      "Yanan Cao",
      "Binxing Fang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.510": {
    "title": "AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs",
    "volume": "long",
    "abstract": "User interface understanding with vision-language models (VLMs) has received much attention due to its potential for enhancing software automation.However, existing datasets used to build UI-VLMs either only contain large-scale context-free element annotations or contextualized functional descriptions for elements at a small scale.In this work, we propose the AutoGUI pipeline for automatically annotating UI elements with detailed functionality descriptions at scale.Specifically, we leverage large language models (LLMs) to infer element functionality by comparing UI state changes before and after simulated interactions. To improve annotation quality, we propose LLM-aided rejection and verification, eliminating invalid annotations without human labor.We construct a high-quality AutoGUI-704k dataset using the proposed pipeline, featuring diverse and detailed functionality annotations that are hardly provided by previous datasets.Human evaluation shows that we achieve annotation correctness comparable to a trained human annotator. Extensive experiments show that our dataset remarkably enhances VLM's UI grounding capabilities and exhibits significant scaling effects. We also show the interesting potential use of our dataset in UI agent tasks. Please view our project at https://autogui-project.github.io/",
    "checked": true,
    "id": "ee535b283a59488eac684babe4e5b7e3f6f1a263",
    "semantic_title": "autogui: scaling gui grounding with automatic functionality annotations from llms",
    "citation_count": 1,
    "authors": [
      "Hongxin Li",
      "Jingfan Chen",
      "Jingran Su",
      "Yuntao Chen",
      "Li Qing",
      "Zhaoxiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.511": {
    "title": "Introducing Graph Context into Language Models through Parameter-Efficient Fine-Tuning for Lexical Relation Mining",
    "volume": "long",
    "abstract": "Lexical relation refers to the way words are related within a language. Prior work has demonstrated that pretrained language models (PLMs) can effectively mine lexical relations between word pairs. However, they overlook the potential of graph structures composed of lexical relations, which can be integrated with the semantic knowledge of PLMs. In this work, we propose a parameter-efficient fine-tuning method through graph context, which integrates graph features and semantic representations for lexical relation classification (LRC) and lexical entailment (LE) tasks. Our experiments show that graph features can help PLMs better understand more complex lexical relations, establishing a new state-of-the-art for LRC and LE. Finally, we perform an error analysis, identifying the bottlenecks of language models in lexical relation mining tasks and providing insights for future improvements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwen Sun",
      "Zhiyi Tian",
      "Yu He",
      "Jingwei Sun",
      "Guangzhong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.512": {
    "title": "S-RAG: A Novel Audit Framework for Detecting Unauthorized Use of Personal Data in RAG Systems",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) systems combine external data retrieval with text generation and have become essential in applications requiring accurate and context-specific responses. However, their reliance on external data raises critical concerns about unauthorized collection and usage of personal information. To ensure compliance with data protection regulations like GDPR and detect improper use of data, we propose the Shadow RAG Auditing Data Provenance (S-RAG) framework. S-RAG enables users to determine whether their textual data has been utilized in RAG systems, even in black-box settings with no prior system knowledge. It is effective across open-source and closed-source RAG systems and resilient to defense strategies. Experiments demonstrate that S-RAG achieves an improvement in Accuracy by 19.9% (compared to the best baseline), while maintaining strong performance under adversarial defenses. Furthermore, we analyze how the auditor's knowledge of the target system affects performance, offering practical insights for privacy-preserving AI systems. Our code is open-sourced online",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhirui Zeng",
      "Jiamou Liu",
      "Meng-Fen Chiang",
      "Jialing He",
      "Zijian Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.513": {
    "title": "Praetor: A Fine-Grained Generative LLM Evaluator with Instance-Level Customizable Evaluation Criteria",
    "volume": "long",
    "abstract": "With the increasing capability of large language models (LLMs), LLM-as-a-judge has emerged as a new evaluation paradigm. Compared with traditional automatic and manual evaluation, LLM evaluators exhibit better interpretability and efficiency. Despite this, existing LLM evaluators suffer from limited use scenarios and poor flexibility. To mitigate these issues, we propose Praetor, a fine-grained generative LLM evaluator with instance-level customazable evaluation criteria. To train Praetor, we curate a large-scale dataset guided with a hierarchical guideline covering a wide range of tasks and instance-level evaluation criteria. We train Praetor on this dataset in a multi-task learning fashion, which enables to evaluate LLMs in either pointwise grading or pairwise comparison way and support two languages simultaneously with a high flexibility of setting evaluation criteria. Extensive experiments demonstrate that Praetor outperforms previous LLM evaluators and instruction-tuned LLMs on multiple benchmarks, setting new SOTA results. It also exhibits the potential for generating critiques as scalable feedback to further improve LLMs. Our model and related resources are released at https://github.com/tjunlp-lab/Praetor",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi Leng",
      "Renren Jin",
      "Yue Chen",
      "Zhuowen Han",
      "Ling Shi",
      "Jianxiang Peng",
      "Lei Yang",
      "Juesi Xiao",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.514": {
    "title": "Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking",
    "volume": "long",
    "abstract": "Deep transformer models have been used to detect linguistic anomalies in patient transcripts for early Alzheimer's disease (AD) screening. While pre-trained neural language models (LMs) fine-tuned on AD transcripts perform well, little research has explored the effects of the gender of the speakers represented by these transcripts. This work addresses gender confounding in dementia detection and proposes two methods: the Extended Confounding Filter and the Dual Filter, which isolate and ablate weights associated with gender. We evaluate these methods on dementia datasets with first-person narratives from patients with cognitive impairment and healthy controls. Our results show transformer models tend to overfit to training data distributions. Disrupting gender-related weights results in a deconfounded dementia classifier, with the trade-off of slightly reduced dementia detection performance",
    "checked": true,
    "id": "376c7a99a1ba507cf73fdd695ed85b66ac5d71df",
    "semantic_title": "mitigating confounding in speech-based dementia detection through weight masking",
    "citation_count": 0,
    "authors": [
      "Zhecheng Sheng",
      "Xiruo Ding",
      "Brian Hur",
      "Changye Li",
      "Trevor Cohen",
      "Serguei V. S. Pakhomov"
    ]
  },
  "https://aclanthology.org/2025.acl-long.515": {
    "title": "MCS-Bench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in Chinese Classical Studies",
    "volume": "long",
    "abstract": "With the rapid development of Multimodal Large Language Models (MLLMs), their potential in Chinese Classical Studies (CCS), a field which plays a vital role in preserving and promoting China's rich cultural heritage, remains largely unexplored due to the absence of specialized benchmarks. To bridge this gap, we propose MCS-Bench, the first-of-its-kind multimodal benchmark specifically designed for CCS across multiple subdomains. MCS-Bench spans seven core subdomains (Ancient Chinese Text, Calligraphy, Painting, Oracle Bone Script, Seal, Cultural Relic, and Illustration), with a total of 45 meticulously designed tasks. Through extensive evaluation of 37 representative MLLMs, we observe that even the top-performing model (InternVL2.5-78B) achieves an average score below 50, indicating substantial room for improvement. Our analysis reveals significant performance variations across different tasks and identifies critical challenges in areas such as Optical Character Recognition (OCR) and cultural context interpretation. MCS-Bench not only establishes a standardized baseline for CCS-focused MLLM research but also provides valuable insights for advancing cultural heritage preservation and innovation in the Artificial General Intelligence (AGI) era. Data and code will be publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Liu",
      "Jiahuan Cao",
      "Hiuyi Cheng",
      "Yongxin Shi",
      "Kai Ding",
      "Lianwen Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.516": {
    "title": "The Knowledge Microscope: Features as Better Analytical Lenses than Neurons",
    "volume": "long",
    "abstract": "We demonstrate that features, rather than neurons, serve as superior analytical units for understanding the mechanisms of factual knowledge in Language Models (LMs). Previous studies primarily utilize MLP neurons as units of analysis; however, neurons suffer from polysemanticity, leading to limited knowledge expression and poor interpretability. We first conduct preliminary experiments to validate that SAE can effectively decompose neurons into features. With this established, our core findings reveal three key advantages of features over neurons: (1) Features exhibit stronger influence on knowledge expression and superior interpretability. (2) Features demonstrate enhanced monosemanticity, showing distinct activation patterns between related and unrelated facts. (3) Feature-based method demonstrates superior performance over neuron-based approaches in erasing privacy-sensitive information from LMs. Additionally, we propose FeatureEdit, the first feature-based editing method. Code and dataset will be available",
    "checked": true,
    "id": "e143f51aaaf33541cf2df2b641dbf485cc91984b",
    "semantic_title": "the knowledge microscope: features as better analytical lenses than neurons",
    "citation_count": 2,
    "authors": [
      "Yuheng Chen",
      "Pengfei Cao",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.517": {
    "title": "From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding",
    "volume": "long",
    "abstract": "The pursuit of diverse, complex, and large-scale instruction data is crucial for automatically aligning large language models (LLMs). While there are methods capable of generating synthetic instructions at scale, they either suffer from limited grounding sources, leading to a narrow distribution, or rely on trivial extensions that fail to produce meaningful trajectories in terms of complexity. In contrast, instructions that benefit efficient alignment are typically crafted with cognitive insights and grounded in real-world use cases. In this paper, we synthesize such instructions using attributed grounding, which involves 1) a top-down attribution process that grounds a selective set of real instructions to situated users, and 2) a bottom-up synthesis process that leverages web documents to first generate a situation, then a meaningful instruction. This framework allows us to harvest diverse and complex instructions at scale, utilizing the vast range of web documents. Specifically, we construct a dataset of 1 million instructions, called SynthQuestions, and demonstrate that models trained on it achieve leading performance on several common benchmarks, with improvements that continually scale with more web corpora",
    "checked": true,
    "id": "0e4ff1e4c42de97a26b5f673847b2635730e6b54",
    "semantic_title": "from real to synthetic: synthesizing millions of diversified and complicated user instructions with attributed grounding",
    "citation_count": 0,
    "authors": [
      "Chiwei Zhu",
      "Benfeng Xu",
      "Xiaorui Wang",
      "Zhendong Mao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.518": {
    "title": "PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance",
    "volume": "long",
    "abstract": "Recent advancements in generative large language models (LLMs) have enabled wider applicability, accessibility, and flexibility. However, their reliability and trustworthiness are still in doubt, especially for concerns regarding individuals' data privacy. Great efforts have been made on privacy by building various evaluation benchmarks to study LLMs' privacy awareness and robustness from their generated outputs to their hidden representations. Unfortunately, most of these works adopt a narrow formulation of privacy and only investigate personally identifiable information (PII). In this paper, we follow the merit of the Contextual Integrity (CI) theory, which posits that privacy evaluation should not only cover the transmitted attributes but also encompass the whole relevant social context through private information flows. We present PrivaCI-Bench, a comprehensive contextual privacy evaluation benchmark targeted at legal compliance to cover well-annotated privacy and safety regulations, real court cases, privacy policies, and synthetic data built from the official toolkit to study LLMs' privacy and safety compliance. We evaluate the latest LLMs, including the recent reasoner models QwQ-32B and Deepseek R1. Our experimental results suggest that though LLMs can effectively capture key CI parameters inside a given context, they still require further advancements for privacy compliance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Li",
      "Wenbin Hu",
      "Huihao Jing",
      "Yulin Chen",
      "Qi Hu",
      "Sirui Han",
      "Tianshu Chu",
      "Peizhao Hu",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.acl-long.519": {
    "title": "Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View",
    "volume": "long",
    "abstract": "Large language models (LLMs) offer powerful capabilities but come with significant environmental impact, particularly in carbon emissions. Existing studies benchmark carbon emissions but lack a standardized basis for comparison across different model configurations. To address this, we introduce the concept of functional unit (FU) as a standardized basis and develop FUEL, the first FU-based framework for evaluating LLM serving's environmental impact. Through three case studies, we uncover key insights and trade-offs in reducing carbon emissions by optimizing model size, quantization strategy, and hardware choice, paving the way for more sustainable LLM serving. The code is available at https://github.com/jojacola/FUEL",
    "checked": true,
    "id": "14916b3ccbd568ec2bae2c8f1ee61b8078bb305f",
    "semantic_title": "unveiling environmental impacts of large language model serving: a functional unit view",
    "citation_count": 3,
    "authors": [
      "Yanran Wu",
      "Inez Hua",
      "Yi Ding"
    ]
  },
  "https://aclanthology.org/2025.acl-long.520": {
    "title": "ExpeTrans: LLMs Are Experiential Transfer Learners",
    "volume": "long",
    "abstract": "Recent studies provide large language models (LLMs) with textual task-solving experiences via prompts to improve their performance.However, previous methods rely on substantial human labor or time to gather such experiences for each task, which is impractical given the growing variety of task types in user queries to LLMs.To address this issue, we design an autonomous experience transfer framework to explore whether LLMs can mimic human cognitive intelligence to autonomously transfer experience from existing source tasks to newly encountered target tasks. This not only allows the acquisition of experience without extensive costs of previous methods, but also offers a novel path for the generalization of LLMs.Experimental results on 13 datasets demonstrate that our framework effectively improves the performance of LLMs. Furthermore, we provide a detailed analysis of each module in the framework",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglong Gao",
      "Xiao Ding",
      "Lingxiao Zou",
      "Bibo Cai",
      "Bing Qin",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.521": {
    "title": "Cool-Fusion: Fuse Large Language Models without Training",
    "volume": "long",
    "abstract": "We focus on the problem of fusing two or more heterogeneous large language models (LLMs) to leverage their complementary strengths. One of the challenges of model fusion is high computational load, specifically in fine-tuning or aligning vocabularies. To address this, we propose Cool-Fusion, a simple yet effective approach that fuses the knowledge of source LLMs, which does not require training. Unlike ensemble methods, Cool-Fusion is applicable to any set of source LLMs that have different vocabularies. To overcome the vocabulary discrepancies among LLMs, we ensemble LLMs on text level, allowing them to rerank the generated texts by each other with different granularities. Extensive experiments have been conducted across a variety of benchmark datasets. On GSM8K, Cool-Fusion increases accuracy from three strong source LLMs by a significant margin of 17.4%",
    "checked": true,
    "id": "816312c1515d2cbe7771c1eddc2f8c1f19411853",
    "semantic_title": "cool-fusion: fuse large language models without training",
    "citation_count": 5,
    "authors": [
      "Cong Liu",
      "Xiaojun Quan",
      "Yan Pan",
      "Weigang Wu",
      "Xu Chen",
      "Liang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.522": {
    "title": "DAPE V2: Process Attention Score as Feature Map for Length Extrapolation",
    "volume": "long",
    "abstract": "The attention mechanism is a fundamental component of the Transformer model, contributing to interactions among distinct tokens. In general, the attention scores are determined simply by the key-query products. However, this work's occasional trial (combining DAPE and NoPE) of including additional MLPs on attention scores without position encoding indicates that the classical key-query multiplication may limit the performance of Transformers. In this work, we conceptualize attention as a feature map and apply the convolution operator (for neighboring attention scores across different heads) to mimic the processing methods in computer vision. Specifically, **the main contribution of this paper is identifying and interpreting the Transformer length extrapolation problem as a result of the limited expressiveness of the naive query and key dot product, and we successfully translate the length extrapolation issue into a well-understood feature map processing problem**, which is called Convolutional Data-Adaptive Position Encoding (CDAPE).The novel insight, which can be adapted to various attention-related models, reveals that the current Transformer architecture has the potential for further evolution. Extensive experiments demonstrate that treating attention as a feature map and applying convolution as a processing method significantly enhances Transformer performance",
    "checked": true,
    "id": "f0a1dca223e9470cc1d8e350fa6a4d8bf82f4c0f",
    "semantic_title": "dape v2: process attention score as feature map for length extrapolation",
    "citation_count": 3,
    "authors": [
      "Chuanyang Zheng",
      "Yihang Gao",
      "Han Shi",
      "Jing Xiong",
      "Jiankai Sun",
      "Jingyao Li",
      "Minbin Huang",
      "Xiaozhe Ren",
      "Michael Ng",
      "Xin Jiang",
      "Zhenguo Li",
      "Yu Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.523": {
    "title": "MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training",
    "volume": "long",
    "abstract": "Complex instruction-following with elaborate constraints is imperative for Large Language Models (LLMs). While existing methods have constructed data for complex instruction alignment, they all rely on a more advanced model, especially GPT-4, limiting their application. In this paper, we propose a Multi-granularity Self-Contrastive Training (MuSC) framework, to improve the complex instruction alignment without relying on a stronger model. Our method is conducted on both coarse and fine granularity. On coarse-granularity, we construct constraint-aware preference data based on instruction decomposition and recombination. On fine-granularity, we perform token-aware preference optimization with dynamic token-level supervision. Our method is evaluated on open-sourced models, and experiment results show our method achieves significant improvement on both complex and general instruction-following benchmarks, surpassing previous self-alignment methods",
    "checked": true,
    "id": "9a0cd90d265af436605216cf4e1a41c8cfff0ef0",
    "semantic_title": "musc: improving complex instruction following with multi-granularity self-contrastive training",
    "citation_count": 2,
    "authors": [
      "Hui Huang",
      "Jiaheng Liu",
      "Yancheng He",
      "Shilong Li",
      "Bing Xu",
      "Conghui Zhu",
      "Muyun Yang",
      "Tiejun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.524": {
    "title": "LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation",
    "volume": "long",
    "abstract": "Large language models (LLMs) have gained extended context windows through scaling positional encodings and lightweight continual pre-training. However, this often leads to degraded performance on short-text tasks, while the reasons for this degradation remain insufficiently explored. In this work, we identify two primary factors contributing to this issue: distribution drift in hidden states and attention scores, and catastrophic forgetting during continual pre-training. To address these challenges, we propose Long Context Pre-training with Restoration Distillation (LongReD), a novel approach designed to mitigate short-text performance degradation through minimizing the distribution discrepancy between the extended and original models. Besides training on long texts, LongReD distills the hidden state of selected layers from the original model on short texts. Additionally, LongReD also introduces a short-to-long distillation, aligning the output distribution on short texts with that on long texts by leveraging skipped positional indices. Experiments on common benchmarks demonstrate that LongReD effectively preserves the model's short-text performance while maintaining or even enhancing its long-context abilities",
    "checked": true,
    "id": "55153268596cb50b223748b0a62789bbd6454b35",
    "semantic_title": "longred: mitigating short-text degradation of long-context large language models via restoration distillation",
    "citation_count": 5,
    "authors": [
      "Zican Dong",
      "Junyi Li",
      "Jinhao Jiang",
      "Mingyu Xu",
      "Xin Zhao",
      "Bingning Wang",
      "Weipeng Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.525": {
    "title": "APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs",
    "volume": "long",
    "abstract": "While long-context inference is crucial for advancing large language model (LLM) applications, its prefill speed remains a significant bottleneck. Current approaches, including sequence parallelism strategies and compute reduction through approximate attention mechanisms, still fall short of delivering optimal inference efficiency. This hinders scaling the inputs to longer sequences and processing long-context queries in a timely manner. To address this, we introduce APB, an efficient long-context inference framework that leverages multi-host approximate attention to enhance prefill speed by reducing compute and enhancing parallelism simultaneously. APB introduces a communication mechanism for essential key-value pairs within a sequence parallelism framework, enabling a faster inference speed while maintaining task performance. We implement APB by incorporating a tailored FlashAttn kernel alongside optimized distribution strategies, supporting diverse models and parallelism configurations. APB achieves speedups of up to 9.2×, 4.2×, and 1.6× compared with FlashAttn, RingAttn, and StarAttn, respectively, without any observable task performance degradation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Huang",
      "Mingye Li",
      "Xu Han",
      "Chaojun Xiao",
      "Weilin Zhao",
      "Sun Ao",
      "Hao Zhou",
      "Jie Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.526": {
    "title": "PPT: A Minor Language News Recommendation Model via Cross-Lingual Preference Pattern Transfer",
    "volume": "long",
    "abstract": "Rich user-item interactions are essential for building reliable recommender systems, as they reflect user preference patterns. However, minor language news recommendation platforms suffer from limited interactions due to a small user base. A natural solution is to apply well-established English recommender systems to minor language news recommendation, but the linguistic gap can lead to inaccurate modeling of minor language news content. Therefore, enabling few-shot minor language news recommender systems to capture both content information and preference patterns remains a challenge. Based on the observation that preference patterns are similar across languages, we propose a minor language news recommendation model by cross-lingual preference pattern transfer, named PPT. Our model adopts the widely used two-tower architecture and employs the large language model as the backbone of the news encoder. Through cross-lingual alignment, the strong English capability of the news encoder is extended to minor languages, thus enhancing news content representations. Additionally, through cross-lingual news augmentation, PPT simulates interactions of minor language news in the English domain, which facilitates the transfer of preference patterns from the many-shot English domain to the few-shot minor language domain. Extensive experiments on two real-world datasets across 15 minor languages demonstrate the superiority and generalization of our proposed PPT in addressing minor language news recommendation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyang Zhang",
      "Nan Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.527": {
    "title": "GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis",
    "volume": "long",
    "abstract": "The Retrieval-Augmented Generation (RAG) framework introduces a retrieval module to dynamicaslly inject retrieved information into the input context of large language models (LLMs), and has demonstrated significant success in various NLP tasks. However, the current study points out that there is a preference gap between retrievers and LLMs in the RAG framework, which limit the further improvement of system performance. Some highly relevant passages may interfere with LLM reasoning because they contain complex or contradictory information; while some indirectly related or even inaccurate content may help LLM generate more accurate answers by providing suggestive information or logical clues. To solve this, we propose **GainRAG**, a novel approach that aligns the retriever's and LLM's preferences by defining a new metric, \"gain'', which measure how well an input passage contributes to correct outputs.We then propose a method to estimate these gain signals and train a middleware that aligns the preferences of the retriever and the LLM using only limited data.In addition, we introduce a pseudo-passage strategy to mitigate degradation.The experimental results on 6 datasets verify the effectiveness of GainRAG",
    "checked": true,
    "id": "5726b7ab6207dc9deed75cf23a0b4d67a4c39d5f",
    "semantic_title": "gainrag: preference alignment in retrieval-augmented generation through gain signal synthesis",
    "citation_count": 0,
    "authors": [
      "Yi Jiang",
      "Sendong Zhao",
      "Jianbo Li",
      "Haochun Wang",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.528": {
    "title": "Top-n𝜎: Eliminating Noise in Logit Space for Robust Token Sampling of LLM",
    "volume": "long",
    "abstract": "Large language models (LLMs) rely heavily on sampling methods to generate diverse and high-quality text.While existing sampling methods like top-p and min-p have identified the detrimental effects of low-probability tails in LLMs' outputs, they still fail to effectively distinguish between diversity and noise. This limitation stems from their reliance on probability-based metrics that are inherently sensitive to temperature scaling. Through empirical and theoretical analysis, we make two key discoveries: (1) the pre-softmax logits exhibit a clear statistical separation between informative tokens and noise, and (2) we prove the mathematical equivalence of min-p and top-(1-p) under uniform distribution over logits. These findings motivate the design of top-n𝜎, a novel sampling method that identifies informative tokens by eliminating noise directly in logit space.Unlike existing methods that become unstable at high temperatures, top-n𝜎 achieves temperature-invariant token selection while preserving output diversity. Extensive experiments across reasoning and creative writing tasks demonstrate that our method consistently outperforms existing approaches, with particularly significant improvements in high-temperature settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxia Tang",
      "Jianchun Liu",
      "Hongli Xu",
      "Liusheng Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.529": {
    "title": "SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation",
    "volume": "long",
    "abstract": "Key-Value (KV) cache has become a bottleneck of LLMs for long-context generation. Despite the numerous efforts in this area, the optimization for the decoding phase is generally ignored. However, we believe such optimization is crucial, especially for long-output generation tasks based on the following two observations: (i) Excessive compression during the prefill phase, which requires specific full context impairs the comprehension of the reasoning task; (ii) Deviation of heavy hitters occurs in the reasoning tasks with long outputs. Therefore, SCOPE, a simple yet efficient framework that separately performs KV cache optimization during the prefill and decoding phases, is introduced. Specifically, the KV cache during the prefill phase is preserved to maintain the essential information, while a novel strategy based on sliding is proposed to select essential heavy hitters for the decoding phase. Memory usage and memory transfer are further optimized using adaptive and discontinuous strategies. Extensive experiments on LongGenBench show the effectiveness and generalization of SCOPE and its compatibility as a plug-in to other prefill-only KV compression methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialong Wu",
      "Zhenglin Wang",
      "Linhai Zhang",
      "Yilong Lai",
      "Yulan He",
      "Deyu Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.530": {
    "title": "Mitigating Non-Representative Prototypes and Representation Bias in Few-Shot Continual Relation Extraction",
    "volume": "long",
    "abstract": "To address the phenomenon of similar classes, existing methods in few-shot continual relation extraction (FCRE) face two main challenges: non-representative prototypes and representation bias, especially when the number of available samples is limited. In our work, we propose Minion to address these challenges. Firstly, we leverage the General Orthogonal Frame (GOF) structure, based on the concept of Neural Collapse, to create robust class prototypes with clear separation, even between analogous classes. Secondly, we utilize label description representations as global class representatives within the fast-slow contrastive learning paradigm. These representations consistently encapsulate the essential attributes of each relation, acting as global information that helps mitigate overfitting and reduces representation bias caused by the limited local few-shot examples within a class. Extensive experiments on well-known FCRE benchmarks show that our method outperforms state-of-the-art approaches, demonstrating its effectiveness for advancing RE system",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh Duc Pham",
      "Nam Le Hai",
      "Linh Ngo Van",
      "Nguyen Thi Ngoc Diep",
      "Sang Dinh",
      "Thien Huu Nguyen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.531": {
    "title": "MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts",
    "volume": "long",
    "abstract": "One of the primary challenges in optimizing large language models (LLMs) for long-context inference lies in the high memory consumption of the Key-Value (KV) cache. Existing approaches, such as quantization, have demonstrated promising results in reducing memory usage. However, current quantization methods cannot take both effectiveness and efficiency into account. In this paper, we propose MoQAE, a novel mixed-precision quantization method via mixture of quantization-aware experts. First, we view different quantization bit-width configurations as experts and use the traditional mixture of experts (MoE) method to select the optimal configuration. To avoid the inefficiency caused by inputting tokens one by one into the router in the traditional MoE method, we input the tokens into the router chunk by chunk. Second, we design a lightweight router-only fine-tuning process to train MoQAE with a comprehensive loss to learn the trade-off between model accuracy and memory usage. Finally, we introduce a routing freezing (RF) and a routing sharing (RS) mechanism to further reduce the inference overhead. Extensive experiments on multiple benchmark datasets demonstrate that our method outperforms state-of-the-art KV cache quantization approaches in both efficiency and effectiveness",
    "checked": true,
    "id": "adecdd8d98060662b41a0ad4f9b5de416cb2809b",
    "semantic_title": "moqae: mixed-precision quantization for long-context llm inference via mixture of quantization-aware experts",
    "citation_count": 0,
    "authors": [
      "Wei Tao",
      "Haocheng Lu",
      "Xiaoyang Qu",
      "Bin Zhang",
      "Kai Lu",
      "Jiguang Wan",
      "Jianzong Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.532": {
    "title": "PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration",
    "volume": "long",
    "abstract": "The widespread usage of online Large Language Models (LLMs) inference services has raised significant privacy concerns about the potential exposure of private information in user inputs. Existing privacy protection methods for LLMs suffer from either insufficient privacy protection with performance degradation, or large inference time overhead. To address these limitations, we propose PrivacyRestore, a plug-and-play method to protect the privacy of user inputs during LLM inference for the client-server scenario. The server first trains restoration vectors for each privacy span type offline and then releases them to the clients. During inference, the client aggregates restoration vectors of all privacy spans in the user query into a meta restoration vector, which is later sent to the server to restore information. Before transmission, the client removes all privacy spans in the user query and applies d𝜒-privacy mechanism to the meta vector for privacy protection. We prove that our method can inherently prevent the linear growth of the privacy budget. We conduct extensive experimental, covering the medical and legal domains, and demonstrate that PrivacyRestore effectively protects private information and maintains acceptable levels of performance and inference efficiency",
    "checked": true,
    "id": "ec58f2c02c73c15743cf1cccf07638bf23363bc7",
    "semantic_title": "privacyrestore: privacy-preserving inference in large language models via privacy removal and restoration",
    "citation_count": 8,
    "authors": [
      "Ziqian Zeng",
      "Jianwei Wang",
      "Junyao Yang",
      "Zhengdong Lu",
      "Haoran Li",
      "Huiping Zhuang",
      "Cen Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.533": {
    "title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models",
    "volume": "long",
    "abstract": "The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality—a critical driver of model performance. Current data selection methods, such as natural language quality assessments, diversity-based filters, and classifier-based approaches, are limited by single-dimensional evaluation or redundancy-focused strategies. To address these gaps, we propose four dimensions to evaluate data quality: professionalism, readability, reasoning, and cleanliness. We further introduce Meta-rater, a multi-dimensional data selection method that integrates these dimensions with existing quality metrics through learned optimal weightings. Meta-rater employs proxy models to train a regression model that predicts validation loss, enabling the identification of optimal combinations of quality scores. Experiments demonstrate that Meta-rater doubles convergence speed for 1.3B parameter models and improves downstream task performance by 3.23%, with advantages that scale to models as large as 7.2B parameters. Our work establishes that holistic, multi-dimensional quality integration significantly outperforms conventional single-dimension approaches, offering a scalable paradigm for enhancing pre-training efficiency and model capability. To advance future research, we release scripts, data, and models at https://github.com/opendatalab/Meta-rater",
    "checked": true,
    "id": "002b999ba056ad02a66238eaafb242266d0cd803",
    "semantic_title": "meta-rater: a multi-dimensional data selection method for pre-training language models",
    "citation_count": 0,
    "authors": [
      "Xinlin Zhuang",
      "Jiahui Peng",
      "Ren Ma",
      "Yinfan Wang",
      "Tianyi Bai",
      "Xingjian Wei",
      "Qiu Jiantao",
      "Chi Zhang",
      "Ying Qian",
      "Conghui He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.534": {
    "title": "GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning",
    "volume": "long",
    "abstract": "The evaluation of large language models (LLMs) has traditionally relied on static benchmarks, a paradigm that poses two major limitations: (1) predefined test sets lack adaptability to diverse application domains, and (2) standardized evaluation protocols often fail to capture fine-grained assessments of domain-specific knowledge and contextual reasoning abilities. To overcome these challenges, we propose GuessArena, an adaptive evaluation framework grounded in adversarial game-based interactions. Inspired by the interactive structure of the Guess Who I Am? game, our framework seamlessly integrates dynamic domain knowledge modeling with progressive reasoning assessment to improve evaluation fidelity. Empirical studies across five vertical domains-finance, healthcare, manufacturing, information technology, and education-demonstrate that GuessArena effectively distinguishes LLMs in terms of domain knowledge coverage and reasoning chain completeness. Compared to conventional benchmarks, our method provides substantial advantages in interpretability, scalability, and scenario adaptability",
    "checked": true,
    "id": "b9b0df4f04480dbfd335995e8c5804393035493e",
    "semantic_title": "guessarena: guess who i am? a self-adaptive framework for evaluating llms in domain-specific knowledge and reasoning",
    "citation_count": 0,
    "authors": [
      "Qingchen Yu",
      "Zifan Zheng",
      "Ding Chen",
      "Simin Niu",
      "Bo Tang",
      "Feiyu Xiong",
      "Zhiyu Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.535": {
    "title": "Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition",
    "volume": "long",
    "abstract": "The past years have witnessed a proliferation of large language models (LLMs). Yet, reliable evaluation of LLMs is challenging due to the inaccuracy of standard metrics in human perception of text quality and the inefficiency in sampling informative test examples for human evaluation. This paper presents a sample-efficient human evaluation method for LLMs based on the principle of MAximum Discrepancy (MAD) competition. MAD automatically selects a small set of informative input instructions, each of which maximizes the discrepancy of two LLMs' reponses, which are subsequently subject to three-alternative forced choice by human subjects. The pairwise comparison results of multiple LLMs are then aggregated into a global ranking using the Elo rating system. We compare eight representative LLMs in terms of four skills: knowledge understanding, mathematical reasoning, writing, and coding. Experimental results show that the proposed method reliably achieves the \"golden\" ranking of LLMs with a minimum set of input instructions, which in turn reveal their relative strengths and weaknesses, and offers valuable insights for further LLM advancement",
    "checked": true,
    "id": "47c447d9f350eef8d51bc13460ccd241a4c13c79",
    "semantic_title": "sample-efficient human evaluation of large language models via maximum discrepancy competition",
    "citation_count": 13,
    "authors": [
      "Kehua Feng",
      "Keyan Ding",
      "Tan Hongzhi",
      "Kede Ma",
      "Zhihua Wang",
      "Shuangquan Guo",
      "Cheng Yuzhou",
      "Ge Sun",
      "Guozhou Zheng",
      "Qiang Zhang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.536": {
    "title": "DTCRS: Dynamic Tree Construction for Recursive Summarization",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) mitigates the hallucination problem of Large Language Models (LLMs) by incorporating external knowledge. Recursive summarization constructs a hierarchical summary tree by clustering text chunks, integrating information from multiple parts of a document to provide evidence for abstractive questions involving multi-step reasoning. However, summary trees often contain a large number of redundant summary nodes, which not only increase construction time but may also negatively impact question answering. Moreover, recursive summarization is not suitable for all types of questions. We introduce DTCRS, a method that dynamically generates summary trees based on document structure and query semantics. DTCRS determines whether a summary tree is necessary by analyzing the question type. It then decomposes the question and uses the embeddings of sub-questions as initial cluster centers, reducing redundant summaries while improving the relevance between summaries and the question. Our approach significantly reduces summary tree construction time and achieves substantial improvements across three QA tasks. Additionally, we investigate the applicability of recursive summarization to different question types, providing valuable insights for future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanran Luo",
      "Zhongquan Jian",
      "Wentao Qiu",
      "Meihong Wang",
      "Qingqiang Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.537": {
    "title": "A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning",
    "volume": "long",
    "abstract": "Recent Continual Learning (CL)-based Temporal Knowledge Graph Reasoning (TKGR) methods focus on significantly reducing computational cost and mitigating catastrophic forgetting caused by fine-tuning models with new data. However, existing CL-based TKGR methods still face two key limitations: (1) They usually one-sidedly reorganize individual historical facts, while overlooking the historical context essential for accurately understanding the historical semantics of these facts; (2) They preserve historical knowledge by simply replaying historical facts, while ignoring the potential conflicts between historical and emerging facts. In this paper, we propose a Deep Generative Adaptive Replay (DGAR) method, which can generate and adaptively replay historical entity distribution representations from the whole historical context. To address the first challenge, historical context prompts as sampling units are built to preserve the whole historical context information. To overcome the second challenge, a pre-trained diffusion model is adopted to generate the historical distribution. During the generation process, the common features between the historical and current distributions are enhanced under the guidance of the TKGR model. In addition, a layer-by-layer adaptive replay mechanism is designed to effectively integrate historical and current distributions. Experimental results demonstrate that DGAR significantly outperforms baselines in reasoning and mitigating forgetting",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyu Zhang",
      "Wei Chen",
      "Youfang Lin",
      "Huaiyu Wan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.538": {
    "title": "ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search",
    "volume": "long",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities and are receiving increasing attention to enhance their reasoning through scaling test-time compute. However, their application in open-ended, knowledge-intensive, complex reasoning scenarios is still limited. Reasoning-oriented methods struggle to generalize to open-ended scenarios due to implicit assumptions of complete world knowledge. Meanwhile, knowledge-augmented reasoning (KAR) methods fails to address two core challenges: 1) error propagation, where errors in early steps cascade through the chain, and 2) verification bottleneck, where the explore–exploit trade-off arises in multi-branch decision processes. To overcome these limitations, we introduce ARise, a novel framework that integrates risk assessment of intermediate reasoning states with dynamic retrieval-augmented generation (RAG) within a Monte Carlo tree search paradigm. This approach enables effective construction and optimization of reasoning plans across multiple maintained hypothesis branches. Experimental results show that ARise significantly outperforms the state-of-the-art KAR methods by up to 23.10%, and the latest RAG-equipped large reasoning models by up to 25.37%. Our project page is at https://opencausalab.github.io/ARise",
    "checked": true,
    "id": "76240bbffef70def031b29c35e3e764d1ac6bfc6",
    "semantic_title": "arise: towards knowledge-augmented reasoning via risk-adaptive search",
    "citation_count": 0,
    "authors": [
      "Yize Zhang",
      "Tianshu Wang",
      "Sirui Chen",
      "Kun Wang",
      "Xingyu Zeng",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun",
      "Chaochao Lu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.539": {
    "title": "PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation",
    "volume": "long",
    "abstract": "Drug-drug interactions (DDIs) arise when multiple drugs are administered concurrently. Accurately predicting the specific mechanisms underlying DDIs (named DDI events or DDIEs) is critical for the safe clinical use of drugs. DDIEs are typically represented as textual descriptions. However, most computational methods focus more on predicting the DDIE class label over generating human-readable natural language increasing clinicians' interpretation costs. Furthermore, current methods overlook the fact that each drug assumes distinct biological functions in a DDI, which, when used as input context, can enhance the understanding of the DDIE process and benefit DDIE generation by the language model (LM). In this work, we propose a novel pairwise knowledge-augmented generative method (termed PKAG-DDI) for DDIE text generation. It consists of a pairwise knowledge selector efficiently injecting structural information between drugs bidirectionally and simultaneously to select pairwise biological functions from the knowledge set, and a pairwise knowledge integration strategy that matches and integrates the selected biological functions into the LM. Experiments on two professional datasets show that PKAG-DDI outperforms existing methods in DDIE text generation, especially in challenging inductive scenarios, indicating its practicality and generalization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyan Wang",
      "Zhankun Xiong",
      "Feng Huang",
      "Wen Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.540": {
    "title": "Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models",
    "volume": "long",
    "abstract": "Interpretation is critical for disease diagnosis, but existing models struggle to balance predictive accuracy with human-understandable rationales. While large language models (LLMs) offer strong reasoning abilities, their clinical use is limited by high computational costs and restricted multimodal reasoning ability. Small language models (SLMs) are efficient but lack advanced reasoning for integrating multimodal medical data. In addition, both LLMs and SLMs lack domain knowledge for trustworthy reasoning. Therefore, we propose ClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via rationale distillation and domain knowledge injection for trustworthy multimodal rationale generation. Key innovations include a sequential rationale distillation framework that equips SLMs with LLM-comparable multimodal reasoning abilities, and a knowledge-augmented attention mechanism that jointly unifies multimodal representation from time series and textual data in the same encoding space, enabling it to be naturally interpreted by SLMs while incorporating domain knowledge for reliable rationale generation. Experiments on real-world medical datasets show that ClinRaGen achieves state-of-the-art performance in disease diagnosis and rationale generation, demonstrating the effectiveness of combining LLM-driven reasoning with knowledge augmentation for improved interpretability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Niu",
      "Jing Ma",
      "Hongzhan Lin",
      "Liang Bai",
      "Zhihua Wang",
      "Richard Yi Da Xu",
      "Yunya Song",
      "Xian Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.541": {
    "title": "TWIST: Text-encoder Weight-editing for Inserting Secret Trojans in Text-to-Image Models",
    "volume": "long",
    "abstract": "Text-to-image (T2I) models excel at generating high-quality images from text via powerful text encoders but training these encoders demands substantial computational resources. Consequently, many users seek pre-trained text encoders from model plugin-sharing platforms like Civitai and Hugging Face, which introduces an underexplored threat: the potential for adversaries to embed Trojans within these plugins. Existing Trojan attacks often require extensive training data and suffer from poor generalization across different triggers, limiting their effectiveness and scalability. To the best of our knowledge, this paper introduces the first **T**ext-encoder **W**eight-editing method for **I**nserting **S**ecret **T**rojans (**TWIST**). By identifying the *bottleneck MLP layer*—the critical point where minimal edits can dominantly control cross-modal alignment—TWIST achieves training-free and data-free Trojan insertion, which makes it highly efficient and practical. The experimental results across various triggers demonstrate that TWIST attains an average attack success rate of 91%, a 78% improvement over the state-of-the-art (SOTA) method proposed in 2024 and highlights the excellent generalization capability. Moreover, TWIST reduces modified parameters by 8-fold and cuts injection time to 25 seconds. Our findings underscore the security risks associated with text encoders in real-world applications and emphasize the need for more robust defense mechanisms",
    "checked": true,
    "id": "906e43c3a44151dbf41fc4281e460cd343eb139b",
    "semantic_title": "twist: text-encoder weight-editing for inserting secret trojans in text-to-image models",
    "citation_count": 0,
    "authors": [
      "Xindi Li",
      "Zhe Liu",
      "Tong Zhang",
      "Jiahao Chen",
      "Qingming Li",
      "Jinbao Li",
      "Shouling Ji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.542": {
    "title": "Frictional Agent Alignment Framework: Slow Down and Don't Break Things",
    "volume": "long",
    "abstract": "AI support of collaborative interactions entails mediating potential misalignment between interlocutor beliefs. Common preference alignment methods like DPO excel in static settings, but struggle in dynamic collaborative tasks where the explicit signals of interlocutor beliefs are sparse and skewed. We propose the Frictional Agent Alignment Framework (FAAF), to generate precise, context-aware \"friction\" that prompts for deliberation and re-examination of existing evidence. FAAF's two-player objective decouples from data skew: a frictive-state policy identifies belief misalignments, while an intervention policy crafts collaborator-preferred responses. We derive an analytical solution to this objective, enabling training a single policy via a simple supervised loss. Experiments on three benchmarks show FAAF outperforms competitors in producing concise, interpretable friction and in OOD generalization. By aligning LLMs to act as adaptive \"thought partners\"—not passive responders—FAAF advances scalable, dynamic human-AI collaboration. Our code and data can be found at https://github.com/csu-signal/FAAF_ACL",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhijnan Nath",
      "Carine Graff",
      "Andrei Bachinin",
      "Nikhil Krishnaswamy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.543": {
    "title": "Powerformer: Efficient and High-Accuracy Privacy-Preserving Language Model with Homomorphic Encryption",
    "volume": "long",
    "abstract": "We propose Powerformer, an efficient homomorphic encryption (HE)-based privacy-preserving language model (PPLM) designed to reduce computation overhead while maintaining model performance. Powerformer incorporates three key techniques to optimize encrypted computations:1. A novel distillation technique that replaces softmax and layer normalization (LN) with computationally efficient power and linear functions, ensuring no performance degradation while enabling seamless encrypted computation.2. A pseudo-sign composite approximation method that accurately approximates GELU and tanh functions with minimal computational overhead.3. A homomorphic matrix multiplication algorithm specifically optimized for Transformer models, enhancing efficiency in encrypted environments.By integrating these techniques, Powerformer based on the BERT-base model achieves a 45% reduction in computation time compared to the state-of-the-art HE-based PPLM without any loss in accuracy",
    "checked": true,
    "id": "763027fd058877e271cdf7542ea0dafdf7879b4b",
    "semantic_title": "powerformer: efficient and high-accuracy privacy-preserving language model with homomorphic encryption",
    "citation_count": 0,
    "authors": [
      "Dongjin Park",
      "Eunsang Lee",
      "Joon-Woo Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.544": {
    "title": "Beware of Your Po! Measuring and Mitigating AI Safety Risks in Role-Play Fine-Tuning of LLMs",
    "volume": "long",
    "abstract": "Role-playing enables large language models (LLMs) to engage users in immersive and personalized interactions, but it also introduces significant safety risks. Existing role-play fine-tuning techniques improve role adaptability but may degrade safety performance, particularly for villainous characters. In this work, we conduct the first comprehensive assessment of role-play fine-tuning risks by training 95 role-specific LLMs using RoleBench. Our experiments reveal that role-play fine-tuning leads to a noticeable decline in safety performance, with safety risks varying based on character traits. To tackle this challenge, we propose Safety-Aware Role-Play Fine-Tuning (SaRFT), a novel method designed to balance role-playing capabilities and safety. Extensive experiments on LLaMA-3-8B-Instruct, Gemma-2-9B-it, and Qwen2.5-7B-Instruct demonstrate that SaRFT consistently outperforms state-of-the-art baselines under both LoRA and full-parameter fine-tuning settings. Our findings highlight the necessity of role-adaptive safety measures and provide insights into mitigating role-specific safety risks in role-playing LLMs",
    "checked": true,
    "id": "3f08bcf9c8c58d8a63f77eb8e5e2064ad390fd43",
    "semantic_title": "beware of your po! measuring and mitigating ai safety risks in role-play fine-tuning of llms",
    "citation_count": 7,
    "authors": [
      "Weixiang Zhao",
      "Yulin Hu",
      "Yang Deng",
      "Jiahe Guo",
      "Xingyu Sui",
      "Xinyang Han",
      "An Zhang",
      "Yanyan Zhao",
      "Bing Qin",
      "Tat-Seng Chua",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.545": {
    "title": "Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?",
    "volume": "long",
    "abstract": "While great success has been achieved in building vision models with Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is challenging because of the scarcity of labeled data and text supervision, different levels of downstream tasks, and the conceptual gaps between domains. In this work, to address these issues, we propose a multi-modal prompt learning paradigm to effectively adapt pre-trained GNN to downstream tasks and data, given only a few semantically labeled samples, each with extremely weak text supervision. Our new paradigm embeds the graphs directly in the same space as the Large Language Models (LLMs) by learning both graph prompts and text prompts simultaneously. We demonstrate the superior performance of our paradigm in few-shot, multi-task-level, and cross-domain settings. Moreover, we build the first CLIP-style zero-shot classification prototype that can generalize GNNs to unseen classes with extremely weak text supervision",
    "checked": true,
    "id": "14c59d6dab548ef023b8a49df4a26b966fe9d00a",
    "semantic_title": "can graph neural networks learn language with extremely weak text supervision?",
    "citation_count": 10,
    "authors": [
      "Zihao Li",
      "Lecheng Zheng",
      "Bowen Jin",
      "Dongqi Fu",
      "Baoyu Jing",
      "Yikun Ban",
      "Jingrui He",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.546": {
    "title": "Towards Enhanced Immersion and Agency for LLM-based Interactive Drama",
    "volume": "long",
    "abstract": "LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the user (i.e. the player) plays the role of a character in the story, has conversations with characters played by LLM agents, and experiences an unfolding story. This paper begins with understanding interactive drama from two aspects: Immersion—the player's feeling of being present in the story—and Agency—the player's ability to influence the story world. Both are crucial to creating an enjoyable interactive experience, while they have been underexplored in previous work. To enhance these two aspects, we first propose Playwriting-guided Generation, a novel method that helps LLMs craft dramatic stories with substantially improved structures and narrative quality. Additionally, we introduce Plot-based Reflection for LLM agents to refine their reactions to align with the player's intentions. Our evaluation relies on human judgment to assess the gains of our methods in terms of immersion and agency",
    "checked": true,
    "id": "24e0f5c2883cb4043d10f0f324f1ca55201cecba",
    "semantic_title": "towards enhanced immersion and agency for llm-based interactive drama",
    "citation_count": 0,
    "authors": [
      "Hongqiu Wu",
      "Weiqi Wu",
      "Tianyang Xu",
      "Jiameng Zhang",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.547": {
    "title": "Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures",
    "volume": "long",
    "abstract": "Multimodal reference resolution, including phrase grounding, aims to understand the semantic relations between mentions and real-world objects. Phrase grounding between images and their captions is a well-established task. In contrast, for real-world applications, it is essential to integrate textual and multimodal reference resolution to unravel the reference relations within dialogue, especially in handling ambiguities caused by pronouns and ellipses. This paper presents a framework that unifies textual and multimodal reference resolution by mapping mention embeddings to object embeddings and selecting mentions or objects based on their similarity. Our experiments show that learning textual reference resolution, such as coreference resolution and predicate-argument structure analysis, positively affects performance in multimodal reference resolution. In particular, our model with coreference resolution performs better in pronoun phrase grounding than representative models for this task, MDETR and GLIP. Our qualitative analysis demonstrates that incorporating textual reference relations strengthens the confidence scores between mentions, including pronouns and predicates, and objects, which can reduce the ambiguities that arise in visually grounded dialogues",
    "checked": true,
    "id": "30582bc3a45a254992df32f5b1eec846901c3b5b",
    "semantic_title": "disambiguating reference in visually grounded dialogues through joint modeling of textual and multimodal semantic structures",
    "citation_count": 0,
    "authors": [
      "Shun Inadumi",
      "Nobuhiro Ueda",
      "Koichiro Yoshino"
    ]
  },
  "https://aclanthology.org/2025.acl-long.548": {
    "title": "Improving Factuality with Explicit Working Memory",
    "volume": "long",
    "abstract": "Large language models can generate factually inaccurate content, a problem known as hallucination. Recent works have built upon retrieved-augmented generation to improve factuality through iterative prompting but these methods are limited by the traditional RAG design. To address these challenges, we introduce Ewe (Explicit Working Memory), a novel approach that enhances factuality in long-form text generation by integrating a working memory that receives real-time feedback from external resources. The memory is refreshed based on online fact-checking and retrieval feedback, allowing Ewe to rectify false claims during the generation process and ensure more accurate and reliable outputs. Our experiments demonstrate that Ewe outperforms strong baselines on four fact-seeking long-form generation datasets, increasing the factuality metric, VeriScore, by 2 to 6 points absolute without sacrificing the helpfulness of the responses. Further analysis reveals that the design of rules for memory updates, configurations of memory units, and the quality of the retrieval datastore are crucial factors for influencing model performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingda Chen",
      "Yang Li",
      "Karthik Padthe",
      "Rulin Shao",
      "Alicia Yi Sun",
      "Luke Zettlemoyer",
      "Gargi Ghosh",
      "Wen-tau Yih"
    ]
  },
  "https://aclanthology.org/2025.acl-long.549": {
    "title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models",
    "volume": "long",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address this issue, we frame human value alignment as a multi-objective optimization problem, aiming to maximize a set of potentially conflicting objectives. We introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning paradigm that employs multiple-gradient descent to align LLMs with diverse preference distributions. GAPO adaptively rescales the gradients for each objective to determine an update direction that optimally balances the trade-offs between objectives. Additionally, we introduce P-GAPO, which incorporates user preferences across different objectives and achieves Pareto solutions that better align with the user's specific needs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengao Li",
      "Hanyu Zhang",
      "Yunkun Xu",
      "Hongyan Xue",
      "Xiang Ao",
      "Qing He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.550": {
    "title": "Dynamic Parallel Tree Search for Efficient LLM Reasoning",
    "volume": "long",
    "abstract": "Tree of Thoughts (ToT) enhances Large Language Model (LLM) reasoning by structuring problem-solving as a spanning tree. However, recent methods focus on search accuracy while overlooking computational efficiency. The challenges of accelerating the ToT lie in the frequent switching of reasoning focus, and the redundant exploration of suboptimal solutions. To alleviate this dilemma, we propose Dynamic Parallel Tree Search (DPTS), a novel parallelism framework that aims to dynamically optimize the reasoning path in inference. It includes the Parallelism Streamline in the generation phase to build up a flexible and adaptive parallelism with arbitrary paths by cache management and alignment. Meanwhile, the Search and Transition Mechanism filters potential candidates to dynamically maintain the reasoning focus on more possible solutions with less redundancy. Experiments on Qwen-2.5 and Llama-3 on math and code datasets show that DPTS significantly improves efficiency by 2-4× on average while maintaining or even surpassing existing reasoning algorithms in accuracy, making ToT-based reasoning more scalable and computationally efficient. Codes are released at: https://github.com/yifu-ding/DPTS",
    "checked": true,
    "id": "30f8814a8aeccd8e58fcc5e419041683832a2aab",
    "semantic_title": "dynamic parallel tree search for efficient llm reasoning",
    "citation_count": 11,
    "authors": [
      "Yifu Ding",
      "Wentao Jiang",
      "Shunyu Liu",
      "Yongcheng Jing",
      "Jinyang Guo",
      "Yingjie Wang",
      "Jing Zhang",
      "Zengmao Wang",
      "Ziwei Liu",
      "Bo Du",
      "Xianglong Liu",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.551": {
    "title": "Pre3: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation",
    "volume": "long",
    "abstract": "Extensive LLM applications demand efficient structured generations, particularly for LR(1) grammars, to produce outputs in specified formats (e.g., JSON). Existing methods primarily parse LR(1) grammars into a pushdown automaton (PDA), leading to runtime execution overhead for context-dependent token processing, especially inefficient under large inference batches.To address these issues, we propose Pre3 that exploits deterministic pushdown automata (DPDA) to optimize the constrained LLM decoding efficiency.First, by **pre**computing **pre**fix-conditioned edges during the **pre**processing, Pre3 enables ahead-of-time edge analysis and thus makes parallel transition processing possible.Futher, leveraging the prefix-conditioned edges, Pre3 introduces a novel approach that transforms LR(1) transition graphs into DPDA, eliminating the need for runtime path exploration and achieving edge transitions with minimal overhead.Pre3 can be seamlessly integrated into standard LLM inference frameworks, improving time per output token (TPOT) by up to 40% and throughput by up to 36% in our experiments. Our code is available at https://github.com/ModelTC/lightllm",
    "checked": true,
    "id": "902bf443905225ef997056d370a6f45ce2a8f024",
    "semantic_title": "pre3: enabling deterministic pushdown automata for faster structured llm generation",
    "citation_count": 0,
    "authors": [
      "Junyi Chen",
      "Shihao Bai",
      "Zaijun Wang",
      "Siyu Wu",
      "Chuheng Du",
      "Hailong Yang",
      "Ruihao Gong",
      "Shengzhong Liu",
      "Fan Wu",
      "Guihai Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.552": {
    "title": "SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL",
    "volume": "long",
    "abstract": "Current self-correction approaches in text-to-SQL face two critical limitations: 1) Conventional self-correction methods rely on recursive self-calls of LLMs, resulting in multiplicative computational overhead, and 2) LLMs struggle to implement effective error detection and correction for monolithic SQL queries, as they fail to demonstrate the underlying reasoning path. In this work, we propose **SHARE**, a **S**LM-based **H**ierarchical **A**ction cor**RE**ction assistant that enables LLMs to perform more precise error localization and efficient correction. SHARE orchestrates three specialized Small Language Models (SLMs) in a sequential pipeline, where it first transforms monolithic SQL queries into stepwise action trajectories that reveal underlying reasoning, followed by a two-phase granular refinement. We further propose a novel hierarchical self-evolution strategy for data-efficient training. Our experimental results demonstrate that SHARE effectively enhances self-correction capabilities while proving robust across various LLMs. Furthermore, our comprehensive analysis shows that SHARE maintains strong performance even in low-resource training settings, which is particularly valuable for text-to-SQL applications with data privacy constraints",
    "checked": true,
    "id": "12f06c5074f289cdf13d42849804dbe6385e270b",
    "semantic_title": "share: an slm-based hierarchical action correction assistant for text-to-sql",
    "citation_count": 0,
    "authors": [
      "Ge Qu",
      "Jinyang Li",
      "Bowen Qin",
      "Xiaolong Li",
      "Nan Huo",
      "Chenhao Ma",
      "Reynold Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.553": {
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) are prone to generating content that exhibits gender biases, raising significant ethical concerns. Alignment, the process of fine-tuning LLMs to better align with desired behaviors, is recognized as an effective approach to mitigate gender biases. Although proprietary LLMs have made significant strides in mitigating gender bias, their alignment datasets are not publicly available. The commonly used and publicly available alignment dataset, HH-RLHF, still exhibits gender bias to some extent. There is a lack of publicly available alignment datasets specifically designed to address gender bias. Hence, we developed a new dataset named GenderAlign, aiming at mitigating a comprehensive set of gender biases in LLMs. This dataset comprises 8k single-turn dialogues, each paired with a \"chosen\" and a \"rejected\" response. Compared to the \"rejected\" responses, the \"chosen\" responses demonstrate lower levels of gender bias and higher quality. Furthermore, we categorized the gender biases in the \"rejected\" responses of GenderAlign into 4 principal categories. The experimental results show the effectiveness of GenderAlign in reducing gender bias in LLMs",
    "checked": true,
    "id": "3a80474fe68cc3647b140ead4826b6be3f197427",
    "semantic_title": "genderalign: an alignment dataset for mitigating gender bias in large language models",
    "citation_count": 5,
    "authors": [
      "Tao Zhang",
      "Ziqian Zeng",
      "YuxiangXiao YuxiangXiao",
      "Huiping Zhuang",
      "Cen Chen",
      "James R. Foulds",
      "Shimei Pan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.554": {
    "title": "Large Language and Protein Assistant for Protein-Protein Interactions Prediction",
    "volume": "long",
    "abstract": "Predicting the types and affinities of protein-protein interactions (PPIs) is crucial for understanding biological processes and developing novel therapeutic approaches. While encoding proteins themselves is essential, PPI networks can also provide rich prior knowledge for these predictive tasks. However, existing methods oversimplify the problem of PPI prediction in a semi-supervised manner when utilizing PPI networks, limiting their practical application. Furthermore, how to effectively use the rich prior knowledge of PPI networks for novel proteins not present in the network remains an unexplored issue. Additionally, due to inflexible architectures, most of existing methods cannot handle complexes containing an flexible number of proteins. To overcome these limitations, we introduce LLaPA (Large Language and Protein Assistant), a multimodal large language model that integrates proteins and PPI networks. LLaPA offers a more rational approach to utilizing PPI networks for PPI prediction and can fully exploit the information of PPI networks for unseen proteins. Through natural language instructions, LLaPA can accept flexible number of protein sequences and has the potential to perform various protein tasks. Experiments show that LLaPA achieves state-of-the-art performance in multi-label PPI (mPPI) type prediction and is capable of predicting the binding affinity between multiple interacting proteins based on sequence data",
    "checked": true,
    "id": "0da59b6d40f31899d90f2a3d30246c056acad884",
    "semantic_title": "large language and protein assistant for protein-protein interactions prediction",
    "citation_count": 0,
    "authors": [
      "Peng Zhou",
      "Pengsen Ma",
      "Jianmin Wang",
      "Xibao Cai",
      "Haitao Huang",
      "Wei Liu",
      "Longyue Wang",
      "Lai Hou Tim",
      "Xiangxiang Zeng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.555": {
    "title": "An Empirical Study of Many-to-Many Summarization with Large Language Models",
    "volume": "long",
    "abstract": "Many-to-many summarization (M2MS) aims to process documents in any language and generate the corresponding summaries also in any language. Recently, large language models (LLMs) have shown strong multi-lingual abilities, giving them the potential to perform M2MS in real applications. This work presents a systematic empirical study on LLMs' M2MS ability. Specifically, we first reorganize M2MS data based on eight previous domain-specific datasets. The reorganized data contains 47.8K samples spanning five domains and six languages, which could be used to train and evaluate LLMs. Then, we benchmark 18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned traditional models (e.g., mBART) are also conducted for comparisons. Our experiments reveal that, zero-shot LLMs achieve competitive results with fine-tuned traditional models. After instruct-tuning, open-source LLMs can significantly improve their M2MS ability, and outperform zero-shot LLMs (including GPT-4) in terms of automatic evaluations. In addition, we demonstrate this task-specific improvement does not sacrifice the LLMs' general task-solving abilities. However, as revealed by our human evaluation, LLMs still face the factuality issue, and the instruction tuning might intensify the issue. Thus, how to control factual errors becomes the key when building LLM summarizers in real applications, and is worthy to be noted in future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Zengkui Sun",
      "Yunlong Liang",
      "Yuxuan Cao",
      "Jiarong Xu",
      "Haoxiang Shi",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.556": {
    "title": "Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models",
    "volume": "long",
    "abstract": "Direct speech translation (ST) has garnered increasing attention nowadays, yet the accurate translation of terminology within utterances remains a great challenge. In this regard, current studies mainly concentrate on leveraging various translation knowledge into ST models. However, these methods often struggle with interference from irrelevant noise and can not fully utilize the translation knowledge. To address these issues, in this paper, we propose a novel Locate-and-Focus method for terminology translation. It first effectively locates the speech clips containing terminologies within the utterance to construct translation knowledge, minimizing irrelevant information for the ST model. Subsequently, it associates the translation knowledge with the utterance and hypothesis from both audio and textual modalities, allowing the ST model to better focus on translation knowledge during translation. Experimental results across various datasets demonstrate that our method effectively locates terminologies within utterances and enhances the success rate of terminology translation, while maintaining robust general translation performance",
    "checked": true,
    "id": "c5cad19ecd6abe52e121c0de9565d07114ea3bee",
    "semantic_title": "locate-and-focus: enhancing terminology translation in speech language models",
    "citation_count": 0,
    "authors": [
      "Suhang Wu",
      "Jialong Tang",
      "Chengyi Yang",
      "Pei Zhang",
      "Baosong Yang",
      "Junhui Li",
      "Junfeng Yao",
      "Min Zhang",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.557": {
    "title": "GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents",
    "volume": "long",
    "abstract": "Large language models (LLMs) have been widely deployed as autonomous agents capable of following user instructions and making decisions in real-world applications. Previous studies have made notable progress in benchmarking the instruction following capabilities of LLMs in general domains, with a primary focus on their inherent commonsense knowledge. Recently, LLMs have been increasingly deployed as domain-oriented agents, which rely on domain-oriented guidelines that may conflict with their commonsense knowledge. These guidelines exhibit two key characteristics: they consist of a wide range of domain-oriented rules and are subject to frequent updates. Despite these challenges, the absence of comprehensive benchmarks for evaluating the domain-oriented guideline following capabilities of LLMs presents a significant obstacle to their effective assessment and further development. In this paper, we introduce GuideBench, a comprehensive benchmark designed to evaluate guideline following performance of LLMs. GuideBench evaluates LLMs on three critical aspects: (i) adherence to diverse rules, (ii) robustness to rule updates, and (iii) alignment with human preferences. Experimental results on a range of LLMs indicate substantial opportunities for improving their ability to follow domain-oriented guidelines. Data and code are available at Anonymous",
    "checked": true,
    "id": "e90526e869bbdfa20e025182f477021e6ebc8126",
    "semantic_title": "guidebench: benchmarking domain-oriented guideline following for llm agents",
    "citation_count": 0,
    "authors": [
      "Lingxiao Diao",
      "Xinyue Xu",
      "Wanxuan Sun",
      "Cheng Yang",
      "Zhuosheng Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.558": {
    "title": "TC–RAG: Turing–Complete RAG's Case study on Medical LLM Systems",
    "volume": "long",
    "abstract": "In the pursuit of enhancing domain-specific Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) emerges as a promising solution to mitigate issues such as hallucinations, outdated knowledge, and limited expertise in highly specialized queries. However, existing approaches to RAG fall short by neglecting system state variables, which are crucial for ensuring adaptive control, retrieval halting, and system convergence. In this paper, we introduce the Turing-Complete-RAG (TC-RAG) through rigorous proof, a novel framework that addresses these challenges by incorporating a Turing Complete System to manage state variables, thereby enabling more efficient and accurate knowledge retrieval. By leveraging a memory stack system with adaptive retrieval, reasoning, and planning capabilities, TC-RAG not only ensures the controlled halting of retrieval processes but also mitigates the accumulation of erroneous knowledge via Push and Pop actions. In the case study of the medical and general domain, our extensive experiments on seven real-world healthcare and general-domain datasets demonstrate the superiority of TC-RAG over existing methods in accuracy by over 7.20%. Our code, datasets and RAG resources have been available at https://github.com/Artessay/TC-RAG",
    "checked": false,
    "id": "51fb89610710d7c4d25ce02de9f563cca4a5fecc",
    "semantic_title": "tc-rag:turing-complete rag's case study on medical llm systems",
    "citation_count": 13,
    "authors": [
      "Xinke Jiang",
      "Yue Fang",
      "Rihong Qiu",
      "Haoyu Zhang",
      "Yongxin Xu",
      "Hao Chen",
      "Wentao Zhang",
      "Ruizhe Zhang",
      "Yuchen Fang",
      "Xinyu Ma",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.559": {
    "title": "SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning",
    "volume": "long",
    "abstract": "Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose **S**ubtask-**o**riented **R**einforced **F**ine-**T**uning (**SoRFT**), a novel training approach to enhance the issue resolving capability of LLMs. We decomposes issue resolving into structured subtasks: file localization, function localization, line localization, and code edit generation. SoRFT consists of two training stages: (1) **rejection-sampled supervised fine-tuning**, Chain of Thought (CoT) data is filtered using ground-truth before fine-tuning the LLM, and (2) **rule-based reinforcement learning**, which leverages PPO with ground-truth based rewards. We evaluate the SoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving state-of-the-art (SOTA) performance among open-source models (e.g., resolve 21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental results demonstrate that SoRFT significantly enhances issue-resolving performance, improves model generalization, and provides a cost-efficient alternative to commercial models",
    "checked": true,
    "id": "caa00ef04c154b0886c316cdb2d19d1e43acaad2",
    "semantic_title": "sorft: issue resolving with subtask-oriented reinforced fine-tuning",
    "citation_count": 6,
    "authors": [
      "Zexiong Ma",
      "Chao Peng",
      "Pengfei Gao",
      "Xiangxin Meng",
      "Yanzhen Zou",
      "Bing Xie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.560": {
    "title": "MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models",
    "volume": "long",
    "abstract": "Long Context Understanding (LCU) is a critical area for exploration in current large language models (LLMs). However, due to the inherently lengthy nature of long-text data, existing LCU benchmarks for LLMs often result in prohibitively high evaluation costs, like testing time and inference expenses. Through extensive experimentation, we discover that existing LCU benchmarks exhibit significant redundancy, which means the inefficiency in evaluation. In this paper, we propose a concise data compression method tailored for long-text data with sparse information characteristics. By pruning the well-known LCU benchmark LongBench, we create MiniLongBench. This benchmark includes only 237 test samples across six major task categories and 21 distinct tasks. Through empirical analysis of over 60 LLMs, MiniLongBench achieves an average evaluation cost reduced to only 4.5% of the original while maintaining an average rank correlation coefficient of 0.97 with LongBench results. Therefore, our MiniLongBench, as a low-cost benchmark, holds great potential to substantially drive future research into the LCU capabilities of LLMs",
    "checked": true,
    "id": "67c5e6d7743e6afa1e2f5a478ed47ff600c155c1",
    "semantic_title": "minilongbench: the low-cost long context understanding benchmark for large language models",
    "citation_count": 0,
    "authors": [
      "Zhongzhan Huang",
      "Guoming Ling",
      "Shanshan Zhong",
      "Hefeng Wu",
      "Liang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.561": {
    "title": "Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG",
    "volume": "long",
    "abstract": "Large language models (LLMs) augmented with retrieval systems have significantly advanced natural language processing tasks by integrating external knowledge sources, enabling more accurate and contextually rich responses. To improve the robustness of such systems against noisy retrievals, Retrieval-Augmented Fine-Tuning (RAFT) has emerged as a widely adopted method. However, RAFT conditions models to generate answers even in the absence of reliable knowledge. This behavior undermines their reliability in high-stakes domains, where acknowledging uncertainty is critical. To address this issue, we propose Divide-Then-Align (DTA), a post-training approach designed to endow RAG systems with the ability to respond with \"I don't know\" when the query is out of the knowledge boundary of both the retrieved passages and the model's internal knowledge. DTA divides data samples into four knowledge quadrants and constructs tailored preference data for each quadrant, resulting in a curated dataset for Direct Preference Optimization (DPO). Experimental results on three benchmark datasets demonstrate that effectively balances accuracy with appropriate abstention, enhancing the reliability and trustworthiness of retrieval-augmented systems",
    "checked": true,
    "id": "c620c8df78586160e2bd8352883574602d069a74",
    "semantic_title": "divide-then-align: honest alignment based on the knowledge boundary of rag",
    "citation_count": 0,
    "authors": [
      "Xin Sun",
      "Jianan Xie",
      "Zhongqi Chen",
      "Qiang Liu",
      "Shu Wu",
      "Yuehe Chen",
      "Bowen Song",
      "Zilei Wang",
      "Weiqiang Wang",
      "Liang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.562": {
    "title": "PwnGPT: Automatic Exploit Generation Based on Large Language Models",
    "volume": "long",
    "abstract": "Automatic exploit generation (AEG) refers to the automatic discovery and exploitation of vulnerabilities against unknown targets. Traditional AEG often targets a single type of vulnerability and still relies on templates built from expert experience. To achieve intelligent exploit generation, we establish a comprehensive benchmark using Binary Exploitation (pwn) challenges in Capture the Flag (CTF) competitions and investigate the capabilities of Large Language Models (LLMs) in AEG based on the benchmark. To improve the performance of AEG, we propose PwnGPT, an LLM-based automatic exploit generation framework that automatically solves pwn challenges. The structural design of PwnGPT is divided into three main components: analysis, generation, and verification modules. With the help of a modular approach and structured problem inputs, PwnGPT can solve challenges that LLMs cannot directly solve. We evaluate PwnGPT on our benchmark and analyze the outputs of each module. Experimental results show that our framework is highly autonomous and capable of addressing various challenges. Compared to direct input LLMs, PwnGPT increases the completion rate of exploit on our benchmark from 26.3% to 57.9% with the OpenAI o1-preview model and from 21.1% to 36.8% with the GPT-4o model",
    "checked": true,
    "id": "dfaa3345baa73612061ab8ae1704111da30a6590",
    "semantic_title": "pwngpt: automatic exploit generation based on large language models",
    "citation_count": 0,
    "authors": [
      "Wanzong Peng",
      "Lin Ye",
      "Xuetao Du",
      "Hongli Zhang",
      "Dongyang Zhan",
      "Yunting Zhang",
      "Yicheng Guo",
      "Chen Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.563": {
    "title": "VMLU Benchmarks: A comprehensive benchmark toolkit for Vietnamese LLMs",
    "volume": "long",
    "abstract": "The evolution of Large Language Models (LLMs) has underscored the necessity for benchmarks designed for various languages and cultural contexts. To address this need for Vietnamese, we present the first Vietnamese Multitask Language Understanding (VMLU) Benchmarks. The VMLU benchmarks consist of four datasets that assess different capabilities of LLMs, including general knowledge, reading comprehension, reasoning, and conversational skills. This paper also provides an insightful overview of the current state of some dominant LLMs, such as Llama-3, Qwen2.5, and GPT-4, highlighting their performances and limitations when measured against these benchmarks. Furthermore, we provide insights into how prompt design can influence VMLU's evaluation outcomes, as well as suggest that open-source LLMs can serve as effective, cost-efficient evaluators within the Vietnamese context. By offering a comprehensive and accessible benchmarking framework, the VMLU Benchmarks aim to foster the development and fine-tuning of Vietnamese LLMs, thereby establishing a foundation for their practical applications in language-specific domains",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cuc Thi Bui",
      "Nguyen Truong Son",
      "Truong Van Trang",
      "Lam Viet Phung",
      "Pham Nhut Huy",
      "Hoang Anh Le",
      "Quoc Huu Van",
      "Phong Nguyen-Thuan Do",
      "Van Le Tran Truc",
      "Duc Thanh Chau",
      "Le-Minh Nguyen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.564": {
    "title": "Scaling up the State Size of RNN LLMs for Long-Context Scenarios",
    "volume": "long",
    "abstract": "The Transformer architecture has become the standard LLM architecture due to its powerful self-attention mechanism. However, it suffers from quadratic computational complexity and linear memory complexity. RNN-based LLMs have been proposed as alternatives. Yet, RNN models struggle in long-context scenarios, making it challenging to replace self-attention with RNNs. We identify the state size as a critical bottleneck, which is significantly smaller than that of Transformers with a basic context length of 2k. However, simply increasing the state size significantly raises the number of parameters and lowers training efficiency. In this paper, we propose an efficient scaling method to scale the state size of RNN models to match the 2k context length of Transformers, with small parameters overhead. Experimental results demonstrate that scaling the state size significantly enhances long-context understanding. Retrieval performance scales almost linearly with state size, with a 454M model featuring an expanded state achieving performance comparable to a 1.47B model on FDA, a recall-intensive task. These findings highlight state scaling as a promising approach for advancing RNN-based LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Liu",
      "Jianfei Gao",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.565": {
    "title": "Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes",
    "volume": "long",
    "abstract": "Diffusion models have emerged as a promising approach for text generation, with recent works falling into two main categories: discrete and continuous diffusion models. Discrete diffusion models apply token corruption independently using categorical distributions, allowing for different diffusion progress across tokens but lacking fine-grained control. Continuous diffusion models map tokens to continuous spaces and apply fine-grained noise, but the diffusion progress is uniform across tokens, limiting their ability to capture semantic nuances. To address these limitations, we propose Non-simultaneous Continuous Diffusion Models (NeoDiff), a novel diffusion model that integrates the strengths of both discrete and continuous approaches. NeoDiff introduces a Poisson diffusion process for the forward process, enabling a flexible and fine-grained noising paradigm, and employs a time predictor for the reverse process to adaptively modulate the denoising progress based on token semantics. Furthermore, NeoDiff utilizes an optimized schedule for inference to ensure more precise noise control and improved performance. Our approach unifies the theories of discrete and continuous diffusion models, offering a more principled and effective framework for text generation. Experimental results on several text generation tasks demonstrate NeoDiff's superior performance compared to baselines of non-autoregressive continuous and discrete diffusion models, iterative-based methods and autoregressive diffusion-based methods. These results highlight NeoDiff's potential as a powerful tool for generating high-quality text and advancing the field of diffusion-based text generation",
    "checked": true,
    "id": "75a784c633d75a440fa7c4dbd20739107bcf30df",
    "semantic_title": "unifying continuous and discrete text diffusion with non-simultaneous diffusion processes",
    "citation_count": 0,
    "authors": [
      "Bocheng Li",
      "Zhujin Gao",
      "Linli Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.566": {
    "title": "A Strategic Coordination Framework of Small LMs Matches Large LMs in Data Synthesis",
    "volume": "long",
    "abstract": "While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LMs involved framework, GRA, that aggregates specialized roles across small LMs to iterative refinement and quality control typically achieved by a single large LM. In this collaborative framework, multiple small LMs assume distinct roles—Generator, Reviewer, and Adjudicator—to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LMs can achieve data-level parity with distillation from large LMs. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Gao",
      "Qizhi Pei",
      "Zinan Tang",
      "Yu Li",
      "Honglin Lin",
      "Jiang Wu",
      "Lijun Wu",
      "Conghui He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.567": {
    "title": "Defining and Evaluating Visual Language Models' Basic Spatial Abilities: A Perspective from Psychometrics",
    "volume": "long",
    "abstract": "The Theory of Multiple Intelligences underscores the hierarchical nature of cognitive capabilities. To advance Spatial Artificial Intelligence, we pioneer a psychometric framework defining five Basic Spatial Abilities (BSAs) in Visual Language Models (VLMs): Spatial Perception, Spatial Relation, Spatial Orientation, Mental Rotation, and Spatial Visualization. Benchmarking 13 mainstream VLMs through nine validated psychometric experiments reveals significant gaps versus humans, with three key findings: 1) VLMs mirror human hierarchies (strongest in 2D orientation, weakest in 3D rotation) with independent BSAs; 2) Many smaller models surpass larger counterparts, with Qwen leading and InternVL2 lagging; 3) Interventions like CoT and few-shot training show limits from architectural constraints, while ToT demonstrates the most effective enhancement. Identified barriers include weak geometry encoding and missing dynamic simulation. By linking Psychometrics to VLMs, we provide a comprehensive BSA evaluation benchmark, a methodological perspective for embodied AI development, and a cognitive science-informed roadmap for achieving human-like spatial intelligence",
    "checked": true,
    "id": "d4b518e45a2dd372aaa1ab03c9586b21ce802631",
    "semantic_title": "defining and evaluating visual language models' basic spatial abilities: a perspective from psychometrics",
    "citation_count": 4,
    "authors": [
      "Wenrui Xu",
      "Dalin Lyu",
      "Weihang Wang",
      "Jie Feng",
      "Chen Gao",
      "Yong Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.568": {
    "title": "SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation",
    "volume": "long",
    "abstract": "Current vision-language models may grasp basic spatial cues and simple directions (e.g. left, right, front, back), but struggle with the multi-dimensional spatial reasoning necessary for human-like understanding and real-world applications. To address this gap, we develop SPHERE (Spatial Perception and Hierarchical Evaluation of REasoning), a hierarchical evaluation framework supported by a new human-annotated dataset. SPHERE systematically probes models across increasing levels of complexity, from fundamental skills to multi-skill integration and high-level reasoning that combines spatial, visual, and logical understanding. Benchmark evaluation of state-of-the-art models reveals significant deficiencies, especially in reasoning about distance and proximity, understanding both egocentric and allocentric perspectives, and applying spatial logic in physical contexts. These findings expose critical blind spots in existing models and underscore the need for more advanced spatial reasoning techniques, driving the development of vision-language models that align more closely with human spatial cognition",
    "checked": true,
    "id": "d7b1c96aaaeb64538b87b07df86b1f20c5c5c0e9",
    "semantic_title": "sphere: unveiling spatial blind spots in vision-language models through hierarchical evaluation",
    "citation_count": 4,
    "authors": [
      "Wenyu Zhang",
      "Wei En Ng",
      "Lixin Ma",
      "Yuwen Wang",
      "Junqi Zhao",
      "Allison Koenecke",
      "Boyang Li",
      "Wanglu Wanglu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.569": {
    "title": "User-side Model Consistency Monitoring for Open Source Large Language Models Inference Services",
    "volume": "long",
    "abstract": "With the continuous advancement in the performance of open-source large language models (LLMs), their inference services have attracted a substantial user base by offering quality comparable to closed-source models at a significantly lower cost. However, it has also given rise to trust issues regarding model consistency between users and third-party service providers. Specifically, service providers can effortlessly degrade a model's parameter scale or precision for more margin profits, and although users may perceptibly experience differences in text quality, they often lack a reliable method for concrete monitoring. To address this problem, we propose a paradigm for model consistency monitoring on the user side. It constructs metrics based on the logits produced by LLMs to differentiate sequences generated by degraded models. Furthermore, by leveraging model offloading techniques, we demonstrate that the proposed method is implementable on consumer-grade devices. Metric evaluations conducted on three widely used LLMs series (OPT, Llama 3.1 and Qwen 2.5) along with system prototype efficiency tests on a consumer device (RTX 3080 TI) confirm both the effectiveness and feasibility of the proposed approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qijun Miao",
      "Zhixuan Fang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.570": {
    "title": "Jailbreaking? One Step Is Enough!",
    "volume": "long",
    "abstract": "Large language models (LLMs) excel in various tasks but remain vulnerable to jailbreak attacks, where adversaries manipulate prompts to generate harmful outputs. Examining jailbreak prompts helps uncover the shortcomings of LLMs. However, current jailbreak methods and the target model's defenses are engaged in an independent and adversarial process, resulting in the need for frequent attack iterations and redesigning attacks for different models. To address these gaps, we propose a Reverse Embedded Defense Attack (REDA) mechanism that disguises the attack intention as the \"defense\". intention against harmful content. Specifically, REDA starts from the target response, guiding the model to embed harmful content within its defensive measures, thereby relegating harmful content to a secondary role and making the model believe it is performing a defensive task. The attacking model considers that it is guiding the target model to deal with harmful content, while the target model thinks it is performing a defensive task, creating an illusion of cooperation between the two. Additionally, to enhance the model's confidence and guidance in \"defensive\" intentions, we adopt in-context learning (ICL) with a small number of attack examples and construct a corresponding dataset of attack examples. Extensive evaluations demonstrate that the REDA method enables cross-model attacks without the need to redesign attack strategies for different models, enables successful jailbreak in one iteration, and outperforms existing methods on both open-source and closed-source models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weixiong Zheng",
      "Peijian Zeng",
      "YiWei Li",
      "Hongyan Wu",
      "Nankai Lin",
      "Junhao Chen",
      "Aimin Yang",
      "Yongmei Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.571": {
    "title": "Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) offers an effective solution to the issues faced by Large Language Models (LLMs) in hallucination generation and knowledge obsolescence by incorporating externally retrieved knowledge. However, existing methods lack effective control mechanisms for integrating internal and external knowledge. Inspired by human cognitive processes, we propose Parenting, a novel framework that decouples, identifies, and purposefully optimizes parameter subspaces related to adherence and robustness. Specifically, Parenting utilizes a key parameter mining method that combines forward and backward propagation signals to localize subspaces representing different capabilities. Then, Parenting employs a type-tailored tuning strategy, applying specific and appropriate optimizations to different subspaces, aiming to achieve a balanced enhancement of both adherence and robustness. Extensive experiments on various datasets and models validate the effectiveness and generalizability of our method. Our code is available at https://github.com/Nostradamus4869/Parenting",
    "checked": true,
    "id": "e6be0508987667f69c01ebd5c49f2a6e37a21147",
    "semantic_title": "parenting: optimizing knowledge selection of retrieval-augmented language models with parameter decoupling and tailored tuning",
    "citation_count": 4,
    "authors": [
      "Yongxin Xu",
      "Ruizhe Zhang",
      "Xinke Jiang",
      "Yujie Feng",
      "Yuzhen Xiao",
      "Xinyu Ma",
      "Runchuan Zhu",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.572": {
    "title": "PaSa: An LLM Agent for Comprehensive Academic Paper Search",
    "volume": "long",
    "abstract": "We introduce PaSa, an advanced Paper Search agent powered by large language models. PaSa can autonomously make a series of decisions, including invoking search tools, reading papers, and selecting relevant references, to ultimately obtain comprehensive and accurate results for complex scholar queries. We optimize PaSa using reinforcement learning with a synthetic dataset, AutoScholarQuery, which includes 35k fine-grained academic queries and corresponding papers sourced from top-tier AI conference publications. Additionally, we develop RealScholarQuery, a benchmark collecting real-world academic queries to assess PaSa performance in more realistic scenarios. Despite being trained on synthetic data, PaSa significantly outperforms existing baselines on RealScholarQuery, including Google, Google Scholar, Google with GPT-4o for paraphrased queries, ChatGPT (search-enabled GPT-4o), GPT-o1, and PaSa-GPT-4o (PaSa implemented by prompting GPT-4o). Notably, PaSa-7B surpasses the best Google-based baseline, Google with GPT-4o, by 37.78% in recall@20 and 39.90% in recall@50, and exceeds PaSa-GPT-4o by 30.36% in recall and 4.25% in precision. Model, datasets, and code are available at https://github.com/bytedance/pasa.Demo: https://pasa-agent.ai",
    "checked": true,
    "id": "5e5bca8f0b203785d371d265371ac88a2390c014",
    "semantic_title": "pasa: an llm agent for comprehensive academic paper search",
    "citation_count": 11,
    "authors": [
      "Yichen He",
      "Guanhua Huang",
      "Peiyuan Feng",
      "Yuan Lin",
      "Yuchen Zhang",
      "Hang Li",
      "Weinan E"
    ]
  },
  "https://aclanthology.org/2025.acl-long.573": {
    "title": "Less Mature is More Adaptable for Sentence-level Language Modeling",
    "volume": "long",
    "abstract": "This work investigates sentence-level models (i.e., models that operate at the sentence-level) to study how sentence representations from various encoders influence downstream task performance, and which syntactic, semantic, and discourse-level properties are essential for strong performance. Our experiments encompass encoders with diverse training regimes and pretraining domains, as well as various pooling strategies applied to multi-sentence input tasks (including sentence ordering, sentiment classification, and natural language inference) requiring coarse-to-fine-grained reasoning. We find that \"less mature\" representations (e.g., mean-pooled representations from BERT's first or last layer, or representations from encoders with limited fine-tuning) exhibit greater generalizability and adaptability to downstream tasks compared to representations from extensively fine-tuned models (e.g., SBERT or SimCSE). These findings are consistent across different pretraining seed initializations for BERT. Our probing analysis reveals that syntactic and discourse-level properties are stronger indicators of downstream performance than MTEB scores or decodability. Furthermore, the data and time efficiency of sentence-level models, often outperforming token-level models, underscores their potential for future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhilasha Sancheti",
      "David Dale",
      "Artyom Kozhevnikov",
      "Maha Elbayad"
    ]
  },
  "https://aclanthology.org/2025.acl-long.574": {
    "title": "EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts",
    "volume": "long",
    "abstract": "Recent advances in Large Language Models (LLMs) have yielded impressive successes on many language tasks. However, efficient processing of long contexts using LLMs remains a significant challenge. We introduce **EpMAN** – a method for processing long contexts in an episodic memory module while holistically attending to semantically-relevant context chunks. Output from episodic attention is then used to reweigh the decoder's self-attention to the stored KV cache of the context during training and generation. When an LLM decoder is trained using **EpMAN**, its performance on multiple challenging single-hop long-context recall and question-answering benchmarks is found to be stronger and more robust across the range from 16k to 256k tokens than baseline decoders trained with self-attention, and popular retrieval-augmented generation frameworks",
    "checked": true,
    "id": "b9e45305caa10b1df5a40cbfc0da9a8ea6db5c33",
    "semantic_title": "epman: episodic memory attention for generalizing to longer contexts",
    "citation_count": 0,
    "authors": [
      "Subhajit Chaudhury",
      "Payel Das",
      "Sarathkrishna Swaminathan",
      "Georgios Kollias",
      "Elliot Nelson",
      "Khushbu Pahwa",
      "Tejaswini Pedapati",
      "Igor Melnyk",
      "Matthew Riemer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.575": {
    "title": "UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter Efficient Fine-Tuning of Large Models",
    "volume": "long",
    "abstract": "This paper introduces UoRA, a novel parameter-efficient fine-tuning (PEFT) approach for large language models (LLMs). UoRA achieves state-of-the-art efficiency by leveraging a low-rank approximation method that reduces the number of trainable parameters without compromising performance. Unlike existing methods such as LoRA and VeRA, UoRA employs a re-parametrization mechanism that eliminates the need to adapt frozen projection matrices while maintaining shared projection layers across the model. This results in halving the trainable parameters compared to LoRA and outperforming VeRA in computation and storage efficiency. Comprehensive experiments across various benchmarks demonstrate UoRA's superiority in achieving competitive fine-tuning performance with minimal computational overhead. We demonstrate its performance on GLUE and E2E benchmarks and is effectiveness in instruction-tuning large language models and image classification models. Our contributions establish a new paradigm for scalable and resource-efficient fine-tuning of LLMs",
    "checked": false,
    "id": "f402c3004e78df04ff57609c55e16b523148ffb1",
    "semantic_title": "uora: uniform orthogonal reinitialization adaptation in parameter-efficient fine-tuning of large models",
    "citation_count": 1,
    "authors": [
      "Xueyan Zhang",
      "Jinman Zhao",
      "Zhifei Yang",
      "Yibo Zhong",
      "Shuhao Guan",
      "Linbo Cao",
      "Yining Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.576": {
    "title": "Agri-CM3: A Chinese Massive Multi-modal, Multi-level Benchmark for Agricultural Understanding and Reasoning",
    "volume": "long",
    "abstract": "Multi-modal Large Language Models (MLLMs) integrating images, text, and speech can provide farmers with accurate diagnoses and treatment of pests and diseases, enhancing agricultural efficiency and sustainability. However, existing benchmarks lack comprehensive evaluations, particularly in multi-level reasoning, making it challenging to identify model limitations. To address this issue, we introduce Agri-CM3, an expert-validated benchmark assessing MLLMs' understanding and reasoning in agricultural management. It includes 3,939 images and 15,901 multi-level multiple-choice questions with detailed explanations. Evaluations of 45 MLLMs reveal significant gaps. Even GPT-4o achieves only 63.64% accuracy, falling short in fine-grained reasoning tasks. Analysis across three reasoning levels and seven compositional abilities highlights key challenges in accuracy and cognitive understanding. Our study provides insights for advancing MLLMs in agricultural management, driving their development and application. Code and data are available at https://github.com/HIT-Kwoo/Agri-CM3",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haotian Wang",
      "Yi Guan",
      "Fanshu Meng",
      "Chao Zhao",
      "Lian Yan",
      "Yang Yang",
      "Jingchi Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.577": {
    "title": "TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification",
    "volume": "long",
    "abstract": "LLMs have achieved remarkable fluency and coherence in text generation, yet their widespread adoption has raised concerns about content reliability and accountability. In high-stakes domains, it is crucial to understand where and how the content is created. To address this, we introduce the Text pROVEnance (TROVE) challenge, designed to trace each sentence of a target text back to specific source sentences within potentially lengthy or multi-document inputs. Beyond identifying sources, TROVE annotates the fine-grained relationships (quotation, compression, inference, and others), providing a deep understanding of how each target sentence is formed.To benchmark TROVE, we construct our dataset by leveraging three public datasets covering 11 diverse scenarios (e.g., QA and summarization) in English and Chinese, spanning source texts of varying lengths (0–5k, 5–10k, 10k+), emphasizing the multi-document and long-document settings essential for provenance. To ensure high-quality data, we employ a three-stage annotation process: sentence retrieval, GPT-4o provenance, and human provenance. We evaluate 11 LLMs under direct prompting and retrieval-augmented paradigms, revealing that retrieval is essential for robust performance, larger models perform better in complex relationship classification, and closed-source models often lead, yet open-source models show significant promise, particularly with retrieval augmentation. We make our dataset available here: https://github.com/ZNLP/ZNLP-Dataset",
    "checked": true,
    "id": "890045ea7c63afbee9d0c74d7bf900072ffa974b",
    "semantic_title": "trove: a challenge for fine-grained text provenance via source sentence tracing and relationship classification",
    "citation_count": 0,
    "authors": [
      "Junnan Zhu",
      "Min Xiao",
      "Yining Wang",
      "Feifei Zhai",
      "Yu Zhou",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.578": {
    "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
    "volume": "long",
    "abstract": "Despite rising global usage of large language models (LLMs), their ability to generate *long-form* answers to *culturally specific* questions remains unexplored in many languages. To fill this gap, we perform the first study of textual multilingual long-form QA by creating CaLMQA, a dataset of **51.7K** culturally specific questions across **23** different languages. We define culturally specific questions as those that refer to concepts unique to one or a few cultures, or have different answers depending on the cultural or regional context. We obtain these questions by crawling naturally-occurring questions from community web forums in high-resource languages, and by hiring native speakers to write questions in under-resourced, rarely-studied languages such as Fijian and Kirundi. Our data collection methodologies are translation-free, enabling the collection of culturally unique questions like \"Kuber iki umwami wa mbere w'uburundi yitwa Ntare?\" (Kirundi; English translation: \"Why was the first king of Burundi called Ntare (Lion)?\"). We evaluate factuality, relevance and surface-level quality of LLM-generated long-form answers, finding that (1) for many languages, even the best models make critical surface-level errors (e.g., answering in the wrong language, repetition), especially for low-resource languages; and (2) answers to culturally specific questions contain more factual errors than answers to culturally agnostic questions – questions that have consistent meaning and answer across many cultures. We release CaLMQA to facilitate future research in cultural and multilingual long-form QA",
    "checked": true,
    "id": "9ddccb07cbd44116b9880c001f607cff266f7c93",
    "semantic_title": "calmqa: exploring culturally specific long-form question answering across 23 languages",
    "citation_count": 14,
    "authors": [
      "Shane Arora",
      "Marzena Karpinska",
      "Hung-Ting Chen",
      "Ipsita Bhattacharjee",
      "Mohit Iyyer",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.579": {
    "title": "Croppable Knowledge Graph Embedding",
    "volume": "long",
    "abstract": "Knowledge Graph Embedding (KGE) is a common approach for Knowledge Graphs (KGs) in AI tasks. Embedding dimensions depend on application scenarios. Requiring a new dimension means training a new KGE model from scratch, increasing cost and limiting efficiency and flexibility. In this work, we propose a novel KGE training framework MED. It allows one training to obtain a croppable KGE model for multiple scenarios with different dimensional needs. Sub-models of required dimensions can be directly cropped and used without extra training. In MED, we propose a mutual learning mechanism to improve the low-dimensional sub-models and make high-dimensional sub-models retain the low-dimensional sub-models' capacity, an evolutionary improvement mechanism to promote the high-dimensional sub-models to master the triple that the low-dimensional sub-models can not, and a dynamic loss weight to adaptively balance the multiple losses. Experiments on 4 KGE models across 4 standard KG completion datasets, 3 real-world scenarios using a large-scale KG, and extending MED to the BERT language model demonstrate its effectiveness, high efficiency, and flexible extensibility",
    "checked": true,
    "id": "aa01f43e88184f13a0b9f8d5e8337951f1c2fef1",
    "semantic_title": "croppable knowledge graph embedding",
    "citation_count": 0,
    "authors": [
      "Yushan Zhu",
      "Wen Zhang",
      "Zhiqiang Liu",
      "Mingyang Chen",
      "Lei Liang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.580": {
    "title": "HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses",
    "volume": "long",
    "abstract": "In this paper, we investigate the retrieval-augmented generation (RAG) based on Knowledge Graphs (KGs) to improve the accuracy and reliability of Large Language Models (LLMs). Recent approaches suffer from insufficient and repetitive knowledge retrieval, tedious and time-consuming query parsing, and monotonous knowledge utilization. To this end, we develop a Hypothesis Knowledge Graph Enhanced (HyKGE) framework, which leverages LLMs' powerful reasoning capacity to compensate for the incompleteness of user queries, optimizes the interaction process with LLMs, and provides diverse retrieved knowledge. Specifically, HyKGE explores the zero-shot capability and the rich knowledge of LLMs with Hypothesis Outputs to extend feasible exploration directions in the KGs, as well as the carefully curated prompt to enhance the density and efficiency of LLMs' responses. Furthermore, we introduce the HO Fragment Granularity-aware Rerank Module to filter out noise while ensuring the balance between diversity and relevance in retrieved knowledge. Experiments on two Chinese medical multiple-choice question datasets and one Chinese open-domain medical Q&A dataset with two LLM turbos demonstrate the superiority of HyKGE in terms of accuracy and explainability. Code is available at https://github.com/Artessay/HyKGE",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinke Jiang",
      "Ruizhe Zhang",
      "Yongxin Xu",
      "Rihong Qiu",
      "Yue Fang",
      "Zhiyuan Wang",
      "Jinyi Tang",
      "Hongxin Ding",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.581": {
    "title": "LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) face significant challenges in handling long-context tasks because of their limited effective context window size during pretraining, which restricts their ability to generalize over extended sequences. Meanwhile, extending the context window in LLMs through post-pretraining is highly resource-intensive.To address this, we introduce LongRecipe, an efficient training strategy for extending the context window of LLMs, including impactful token analysis, position index transformation, and training optimization strategies. It simulates long-sequence inputs while maintaining training efficiency and significantly improves the model's understanding of long-range dependencies. Experiments on three types of LLMs show that LongRecipe can utilize long sequences while requiring only 30% of the target context window size, and reduces computational training resource over 85% compared to full sequence training. Furthermore, LongRecipe also preserves the original LLM's capabilities in general tasks. Ultimately, we can extend effective context window of open-source LLMs from 8k to 128k, achieving performance close to GPT-4 with just one day of dedicated training using a single GPU with 80G memory.Our code is released at https://github.com/zhiyuanhubj/LongRecipe",
    "checked": true,
    "id": "188bdd2edb3126b357dc646f2ff1f0b2699ad407",
    "semantic_title": "longrecipe: recipe for efficient long context generalization in large language models",
    "citation_count": 13,
    "authors": [
      "Zhiyuan Hu",
      "Yuliang Liu",
      "Jinman Zhao",
      "Suyuchen Wang",
      "WangYan WangYan",
      "Wei Shen",
      "Qing Gu",
      "Anh Tuan Luu",
      "See-Kiong Ng",
      "Zhiwei Jiang",
      "Bryan Hooi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.582": {
    "title": "BeamLoRA: Beam-Constraint Low-Rank Adaptation",
    "volume": "long",
    "abstract": "Due to the demand for efficient fine-tuning of large language models, Low-Rank Adaptation (LoRA) has been widely adopted as one of the most effective parameter-efficient fine-tuning methods. Nevertheless, while LoRA improves efficiency, there remains room for improvement in accuracy. Herein, we adopt a novel perspective to assess the characteristics of LoRA ranks. The results reveal that different ranks within the LoRA modules not only exhibit varying levels of importance but also evolve dynamically throughout the fine-tuning process, which may limit the performance of LoRA. Based on these findings, we propose BeamLoRA, which conceptualizes each LoRA module as a beam where each rank naturally corresponds to a potential sub-solution, and the fine-tuning process becomes a search for the optimal sub-solution combination. BeamLoRA dynamically eliminates underperforming sub-solutions while expanding the parameter space for promising ones, enhancing performance with a fixed rank. Extensive experiments across three base models and 12 datasets spanning math reasoning, code generation, and commonsense reasoning demonstrate that BeamLoRA consistently enhances the performance of LoRA, surpassing the other baseline methods",
    "checked": true,
    "id": "80e9b0a6d8e12d40c7fed83a16bf5f6271cd026e",
    "semantic_title": "beamlora: beam-constraint low-rank adaptation",
    "citation_count": 1,
    "authors": [
      "Naibin Gu",
      "Zhenyu Zhang",
      "Xiyu Liu",
      "Peng Fu",
      "Zheng Lin",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Weiping Wang",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.583": {
    "title": "GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art",
    "volume": "long",
    "abstract": "***Video Comment Art*** enhances user engagement by providing creative content that conveys humor, satire, or emotional resonance, requiring a nuanced and comprehensive grasp of cultural and contextual subtleties. Although Multimodal Large Language Models (MLLMs) and Chain-of-Thought (CoT) have demonstrated strong reasoning abilities in STEM tasks (e.g. mathematics and coding), they still struggle to generate creative expressions such as resonant jokes and insightful satire. Moreover, existing benchmarks are constrained by their limited modalities and insufficient categories, hindering the exploration of comprehensive creativity in video-based Comment Art creation. To address these limitations, we introduce **GODBench**, a novel benchmark that integrates video and text modalities to systematically evaluate MLLMs' abilities to compose Comment Art. Furthermore, inspired by the propagation patterns of waves in physics, we propose **Ripple of Thought (RoT)**, a multi-step reasoning framework designed to enhance the creativity of MLLMs. Extensive experiments on GODBench reveal that existing MLLMs and CoT methods still face significant challenges in understanding and generating creative video comments. In contrast, RoT provides an effective approach to improving creative composing, highlighting its potential to drive meaningful advancements in MLLM-based creativity",
    "checked": true,
    "id": "611fcb2c87b53a0e4973e8c94bbda61f92018a9a",
    "semantic_title": "godbench: a benchmark for multimodal large language models in video comment art",
    "citation_count": 0,
    "authors": [
      "Yiming Lei",
      "Chenkai Zhang",
      "Zeming Liu",
      "Haitao Leng",
      "ShaoGuo Liu",
      "Tingting Gao",
      "Qingjie Liu",
      "Yunhong Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.584": {
    "title": "UniLR: Unleashing the Power of LLMs on Multiple Legal Tasks with a Unified Legal Retriever",
    "volume": "long",
    "abstract": "Despite the impressive capabilities of LLMs, they often generate content with factual inaccuracies in LegalAI, which may lead to serious legal consequences. Retrieval-Augmented Generation (RAG), a promising approach, can conveniently integrate specialized knowledge into LLMs. In practice, there are diverse legal knowledge retrieval demands (e.g. law articles and similar cases). However, existing retrieval methods are either designed for general domains, struggling with legal knowledge, or tailored for specific legal tasks, unable to handle diverse legal knowledge types. Therefore, we propose a novel **Uni**fied **L**egal **R**etriever (UniLR) capable of performing multiple legal retrieval tasks for LLMs. Specifically, we introduce attention supervision to guide the retriever in focusing on key elements during knowledge encoding. Next, we design a graph-based method to integrate meta information through a heterogeneous graph, further enriching the knowledge representation. These two components work together to enable UniLR to capture the essence of knowledge hidden beneath formats. Extensive experiments on multiple datasets of common legal tasks demonstrate that UniLR achieves the best retrieval performance and can significantly enhance the performance of LLM",
    "checked": true,
    "id": "a6ce61cdd3c6852ed997d3c1885a62f34add82df",
    "semantic_title": "unilr: unleashing the power of llms on multiple legal tasks with a unified legal retriever",
    "citation_count": 0,
    "authors": [
      "Ang Li",
      "Yiquan Wu",
      "Yifei Liu",
      "Ming Cai",
      "Lizhi Qing",
      "Shihang Wang",
      "Yangyang Kang",
      "Chengyuan Liu",
      "Fei Wu",
      "Kun Kuang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.585": {
    "title": "Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models",
    "volume": "long",
    "abstract": "Values are core drivers of individual and collective perception, cognition, and behavior. Value systems, such as Schwartz's Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics. Recently, the rise of Large Language Models (LLMs) has raised concerns regarding their elusive intrinsic values. Despite growing efforts in evaluating, understanding, and aligning LLM values, a psychologically grounded LLM value system remains underexplored. This study addresses the gap by introducing the Generative Psycho-Lexical Approach (GPLA), a scalable, adaptable, and theoretically informed method for constructing value systems. Leveraging GPLA, we propose a psychologically grounded five-factor value system tailored for LLMs. For systematic validation, we present three benchmarking tasks that integrate psychological principles with cutting-edge AI priorities. Our results reveal that the proposed value system meets standard psychological criteria, better captures LLM values, improves LLM safety prediction, and enhances LLM alignment, when compared to the canonical Schwartz's values",
    "checked": true,
    "id": "df805a273fccee5a2032cf596e871a4f40ba3915",
    "semantic_title": "generative psycho-lexical approach for constructing value systems in large language models",
    "citation_count": 0,
    "authors": [
      "Haoran Ye",
      "TianZe Zhang",
      "Yuhang Xie",
      "Liyuan Zhang",
      "Yuanyi Ren",
      "Xin Zhang",
      "Guojie Song"
    ]
  },
  "https://aclanthology.org/2025.acl-long.586": {
    "title": "Beyond Dialogue: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model",
    "volume": "long",
    "abstract": "The rapid advancement of large language models (LLMs) has revolutionized role-playing, enabling the development of general role-playing models. However, current role-playing training has two significant issues: (I) Using a predefined role profile to prompt dialogue training for specific scenarios usually leads to biases and even conflicts between the dialogue and the profile, resulting in training biases. (II) Models learn to imitate the role based solely on the profile, neglecting profile-dialogue alignment at the sentence level. To overcome the aforementioned hurdles, we propose a novel framework **Beyond Dialogue**, which introduces \"beyond dialogue\" tasks to align dialogue with profile traits for each scenario, eliminating biases during training. Furthermore, the framework achieves a sentence-level fine-grained alignment between profile and dialogue through an innovative prompting mechanism that generates reasoning data for training. Moreover, the aforementioned methods are fully automated and low-cost. Experimental results demonstrate our model excels in adhering to role profiles, outperforming most proprietary general and specialized role-playing baselines. The code and data are provided in https://github.com/yuyouyu32/BeyondDialogue",
    "checked": true,
    "id": "0f4d6f7575f0c60e24a134c5520d9ae570189c76",
    "semantic_title": "beyond dialogue: a profile-dialogue alignment framework towards general role-playing language model",
    "citation_count": 6,
    "authors": [
      "Yeyong Yu",
      "Runsheng Yu",
      "Haojie Wei",
      "Zhanqiu Zhang",
      "Quan Qian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.587": {
    "title": "ACECODER: Acing Coder RL via Automated Test-Case Synthesis",
    "volume": "long",
    "abstract": "Most progress in recent coder models has been driven by supervised fine-tuning (SFT), while the potential of reinforcement learning (RL) remains largely unexplored, primarily due to the lack of reliable reward data/model in the code domain. In this paper, we address this challenge by leveraging automated large-scale test-case synthesis to enhance code model training. Specifically, we design a pipeline that generates extensive (question, test-cases) pairs from existing code data. Using these test cases, we construct preference pairs based on pass rates over sampled programs to train reward models with Bradley-Terry loss. It shows an average of 10-point improvement for Llama-3.1-8B-Ins and 5-point improvement for Qwen2.5-Coder-7B-Ins through best-of-32 sampling, making the 7B model on par with 236B DeepSeek-V2.5. Furthermore, we conduct reinforcement learning with both reward models and test-case pass rewards, leading to consistent improvements across HumanEval, MBPP, BigCodeBench, and LiveCodeBench (V4). Notably, we follow the R1-style training to start from Qwen2.5-Coder-base directly and show that our RL training can improve model on HumanEval-plus by over 25% and MBPP-plus by 6% for merely 80 optimization steps. We believe our results highlight the huge potential of reinforcement learning in coder models",
    "checked": true,
    "id": "98bdf937d7eb831ff9a2a9b363a4e682638ee366",
    "semantic_title": "acecoder: acing coder rl via automated test-case synthesis",
    "citation_count": 24,
    "authors": [
      "Huaye Zeng",
      "Dongfu Jiang",
      "Haozhe Wang",
      "Ping Nie",
      "Xiaotong Chen",
      "Wenhu Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.588": {
    "title": "Quantifying Semantic Emergence in Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) are widely recognized for their exceptional capacity to capture semantics meaning. Yet, there remains no established metric to quantify this capability. In this work, we introduce a quantitative metric, Information Emergence (IE), designed to measure LLMs' ability to extract semantics from input tokens. We formalize \"semantics\" as the meaningful information abstracted from a sequence of tokens and quantify this by comparing the entropy reduction observed for a sequence of tokens (macro-level) and individual tokens (micro-level). To achieve this, we design a lightweight estimator to compute the mutual information at each transformer layer, which is agnostic to different tasks and language model architectures. We apply IE in both synthetic in-context learning (ICL) scenarios and natural sentence contexts. Experiments demonstrate informativeness and patterns about semantics. While some of these patterns confirm the conventional prior linguistic knowledge, the rest are relatively unexpected, which may provide new insights",
    "checked": true,
    "id": "1a73801cc3a8c3a070c594372129b76ea9e35ea3",
    "semantic_title": "quantifying semantic emergence in language models",
    "citation_count": 1,
    "authors": [
      "Hang Chen",
      "Xinyu Yang",
      "Jiaying Zhu",
      "Wenya Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.589": {
    "title": "DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation",
    "volume": "long",
    "abstract": "With the impressive reasoning and text generation capabilities of large language models (LLMs), methods leveraging multiple LLMs to debate each other have garnered increasing attention. However, existing debate-based approaches remain limited in effectiveness in structured and detailed domains represented by code generation due to several reasons: 1) Reliance on different instances of the same LLM for debate, neglecting the potential benefits of integrating diverse models with varied internal knowledge for more comprehensive code generation, 2) under-utilization of test cases, and 3) reliance on third-party LLM moderators for result consolidation and decision-making, probably introducing hallucinations and judgment errors. To address these challenges, we propose DebateCoder to collect intelligence of LLMs via test case-driven debate for code generation. In DebateCoder, test cases serve as a medium for models to analyze code and identify bugs, while opposing models generate test cases to challenge each other's code during the debate process. These test cases, along with their execution results, are elaborately leveraged to refine and enhance the code through a novel contrastive analysis process. Furthermore, DebateCoder leverages test case outcomes to assess code quality and determine convergence criteria. Unlike previous approaches, DebateCoder emphasizes the collaborative improvement of both models through competitive debate and interactive analysis. Abundant experimental results on two datasets demonstrate the effectiveness of DebateCoder",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jizheng Chen",
      "Kounianhua Du",
      "Xinyi Dai",
      "Weiming Zhang",
      "Xihuai Wang",
      "Yasheng Wang",
      "Ruiming Tang",
      "Weinan Zhang",
      "Yong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.590": {
    "title": "The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models",
    "volume": "long",
    "abstract": "Ensuring awareness of fairness and privacy in Large Language Models (LLMs) is critical. Interestingly, we discover a counter-intuitive trade-off phenomenon that enhancing an LLM's privacy awareness through Supervised Fine-Tuning (SFT) methods significantly decreases its fairness awareness with thousands of samples. To address this issue, inspired by the information theory, we introduce a training-free method to Suppress the Privacy and faIrness coupled Neurons (SPIN), which theoretically and empirically decrease the mutual information between fairness and privacy awareness. Extensive experimental results demonstrate that SPIN eliminates the trade-off phenomenon and significantly improves LLMs' fairness and privacy awareness simultaneously without compromising general capabilities, e.g., improving Qwen-2-7B-Instruct's fairness awareness by 12.2% and privacy awareness by 14.0%.More crucially, SPIN remains robust and effective with limited annotated data or even when only malicious fine-tuning data is available, whereas SFT methods may fail to perform properly in such scenarios. Furthermore, we show that SPIN could generalize to other potential trade-off dimensions.We hope this study provides valuable insights into concurrently addressing fairness and privacy concerns in LLMs and can be integrated into comprehensive frameworks to develop more ethical and responsible AI systems. Our code is available at https://github.com/ChnQ/SPIN",
    "checked": true,
    "id": "e040c2983929b87740dff903056e1e4df71d325c",
    "semantic_title": "the tug of war within: mitigating the fairness-privacy conflicts in large language models",
    "citation_count": 1,
    "authors": [
      "Chen Qian",
      "Dongrui Liu",
      "Jie Zhang",
      "Yong Liu",
      "Jing Shao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.591": {
    "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding",
    "volume": "long",
    "abstract": "Although Large Language Models (LLMs) have demonstrated potential in processing graphs, they struggle with comprehending graphical structure information through prompts of graph description sequences, especially as the graph size increases. We attribute this challenge to the uneven memory performance of LLMs across different positions in graph description sequences, known as \"Positional bias\". To address this, we propose GraphInsight, a novel framework aimed at improving LLMs' comprehension of both macro- and micro-level graphical information. GraphInsight is grounded in two key strategies: 1) placing critical graphical information in positions where LLMs exhibit stronger memory performance, and 2) investigating a lightweight external knowledge base for regions with weaker memory performance, inspired by retrieval-augmented generation (RAG). Moreover, GraphInsight explores integrating these two strategies into LLM agent processes for composite graph tasks that require multi-step reasoning. Extensive empirical studies on benchmarks with a wide range of evaluation tasks show that GraphInsight significantly outperforms all other graph description methods (e.g., prompting techniques and reordering strategies) in understanding graph structures of varying sizes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukun Cao",
      "Shuo Han",
      "Zengyi Gao",
      "Zezhong Ding",
      "Xike Xie",
      "S Kevin Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.592": {
    "title": "Phonotomizer: A Compact, Unsupervised, Online Training Approach to Real-Time, Multilingual Phonetic Segmentation",
    "volume": "long",
    "abstract": "Phonetic transcription requires significant time and expert training. Automated, state-of-the-art text-dependent methods still involve substantial pre-training annotation labor and may not generalize to multiple languages. Hallucination of speech amid silence or non-speech noise can also plague these methods, which fall short in real-time applications due to post hoc whole-phrase evaluation. This paper introduces Phonotomizer, a compact, unsupervised, online training approach to automatic, multilingual phonetic segmentation, a critical first stage in transcription. Unlike prior approaches, Phonotomizer trains on raw sound files alone and can modulate computational exactness. Preliminary evaluations on Irish and Twi, two underrepresented languages, exhibit segmentation comparable to current forced alignment technology, reducing acoustic model size and minimizing training epochs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael S. Yantosca",
      "Albert M. K. Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.593": {
    "title": "A Multi-persona Framework for Argument Quality Assessment",
    "volume": "long",
    "abstract": "Argument quality assessment faces inherent challenges due to its subjective nature, where different evaluators may assign varying quality scores for an argument based on personal perspectives. Although existing datasets collect opinions from multiple annotators to model subjectivity, most existing computational methods fail to consider multi-perspective evaluation. To address this issue, we propose MPAQ, a multi-persona framework for argument quality assessment that simulates diverse evaluator perspectives through large language models. It first dynamically generates targeted personas tailored to an input argument, then simulates each persona's reasoning process to evaluate the argument quality from multiple perspectives. To effectively generate fine-grained quality scores, we develop a coarse-to-fine scoring strategy that first generates a coarse-grained integer score and then refines it into a fine-grained decimal score. Experiments on IBM-Rank-30k and IBM-ArgQ-5.3kArgs datasets demonstrate that MPAQ consistently outperforms strong baselines while providing comprehensive multi-perspective rationales",
    "checked": false,
    "id": "87da4349c42fef4d1f4926a68c09a486661e9c2d",
    "semantic_title": "debate: devil's advocate-based assessment and text evaluation",
    "citation_count": 7,
    "authors": [
      "Bojun Jin",
      "Jianzhu Bao",
      "Yufang Hou",
      "Yang Sun",
      "Yice Zhang",
      "Huajie Wang",
      "Bin Liang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.594": {
    "title": "Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification",
    "volume": "long",
    "abstract": "Chain-of-Thought (CoT) prompting has become the de facto method to elicit reasoning capabilities from large language models (LLMs). However, to mitigate hallucinations in CoT that are notoriously difficult to detect, current methods such as process reward models (PRMs) or self-consistency operate as opaque boxes and do not provide checkable evidence for their judgments, possibly limiting their effectiveness. To address this issue, we draw inspiration from the idea that \"the gold standard for supporting a mathematical claim is to provide a proof\". We propose a retrospective, step-aware formal verification framework Safe. Rather than assigning arbitrary scores, we strive to articulate mathematical claims in formal mathematical language Lean 4 at each reasoning step and provide formal proofs to identify hallucinations. We evaluate our framework Safe across multiple language models and various mathematical datasets, demonstrating a significant performance improvement while offering interpretable and verifiable evidence. We also propose FormalStep as a benchmark for step correctness theorem proving with 30,809 formal statements. To the best of our knowledge, our work represents the first endeavor to utilize formal mathematical language Lean 4 for verifying content generated by LLMs, aligning with the reason why formal mathematical languages were created in the first place: to provide a robust foundation for hallucination-prone human-written proofs",
    "checked": true,
    "id": "d1e527fee15125d518587c49de391c3a1d142191",
    "semantic_title": "safe: enhancing mathematical reasoning in large language models via retrospective step-aware formal verification",
    "citation_count": 0,
    "authors": [
      "Chengwu Liu",
      "Ye Yuan",
      "Yichun Yin",
      "Yan Xu",
      "Xin Xu",
      "Zaoyu Chen",
      "Yasheng Wang",
      "Lifeng Shang",
      "Qun Liu",
      "Ming Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.595": {
    "title": "SAM Decoding: Speculative Decoding via Suffix Automaton",
    "volume": "long",
    "abstract": "Speculative decoding (SD) has been demonstrated as an effective technique for lossless LLM inference acceleration.Retrieval-based SD methods, one kind of model-free method, have yielded promising speedup, but they often rely on single retrieval resources, inefficient retrieval methods, and are constrained to certain tasks. This paper presents a novel retrieval-based speculative decoding method that adapts the suffix automaton (SAM) for efficient and accurate draft generation by utilizing the generating text sequence and static text corpus. Unlike existing n-gram matching methods, SAM-Decoding finds the exact longest suffix match, achieving an average time complexity of O(1) per generation step of SAM update and suffix retrieval.It can also integrate with existing methods, adaptively selecting a draft generation strategy based on match length to generalize to broader domains. Extensive experiments on Spec-Bench show that our method is 18% faster than other retrieval-based SD methods. Additionally, when combined with advanced EAGLE-2, it provides an additional speedup of 3.28% – 11.13% across various-sized LLM backbones",
    "checked": true,
    "id": "5899b6d60bfa3f35d7306a194f6879b8438fdd14",
    "semantic_title": "sam decoding: speculative decoding via suffix automaton",
    "citation_count": 5,
    "authors": [
      "Yuxuan Hu",
      "Ke Wang",
      "Xiaokang Zhang",
      "Fanjin Zhang",
      "Cuiping Li",
      "Hong Chen",
      "Jing Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.596": {
    "title": "PsyAdvisor: A Plug-and-Play Strategy Advice Planner with Proactive Questioning in Psychological Conversations",
    "volume": "long",
    "abstract": "Proactive questioning is essential in psychological conversations as it helps uncover deeper issues and unspoken concerns. Current psychological LLMs are constrained by passive response mechanisms, limiting their capacity to deploy proactive strategies for psychological counseling. To bridge this gap, we first develop the ProPsyC (Proactive Psychological Conversation) dataset, a multi-turn conversation dataset with interpretive labels including strategy decision logic and reaction attribution. Based on ProPsyC, we propose PsyAdvisor by supervised fine-tuning, a plug-and-play proactive questioning strategy planner that empowers psychological LLMs to initiate well-timed questioning through strategic prompting. Experimental results demonstrate that psychological LLMs integrated with PsyAdvisor substantially improve proactive questioning capacity, conversation depth, and response quality.Furthermore, PsyAdvisor shows promising potential in assisting novice counselors by providing strategy recommendations. This study provides new optimization directions for psychological conversation systems and offers valuable insights for future research on proactive questioning mechanisms in psychological LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Hu",
      "Danni Liu",
      "Bo Liu",
      "Yida Chen",
      "Jiuxin Cao",
      "Yan Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.597": {
    "title": "HomeBench: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices",
    "volume": "long",
    "abstract": "Large language models (LLMs) have the potential to revolutionize smart home assistants by enhancing their ability to accurately understand user needs and respond appropriately, which is extremely beneficial for building a smarter home environment. While recent studies have explored integrating LLMs into smart home systems, they primarily focus on handling straightforward, valid single-device operation instructions. However, real-world scenarios are far more complex and often involve users issuing invalid instructions or controlling multiple devices simultaneously. These have two main challenges: LLMs must accurately identify and rectify errors in user instructions and execute multiple user instructions perfectly. To address these challenges and advance the development of LLM-based smart home assistants, we introduce HomeBench, the first smart home dataset with valid and invalid instructions across single and multiple devices in this paper. We have experimental results on 13 distinct LLMs; e.g., GPT-4o achieves only a 0.0% success rate in the scenario of invalid multi-device instructions, revealing that the existing state-of-the-art LLMs still cannot perform well in this situation even with the help of in-context learning, retrieval-augmented generation, and fine-tuning. Our code and dataset are publicly available at https://github.com/BITHLP/HomeBench",
    "checked": true,
    "id": "702bf06210d9f3591b8bac81ddeaae7d37955377",
    "semantic_title": "homebench: evaluating llms in smart homes with valid and invalid instructions across single and multiple devices",
    "citation_count": 0,
    "authors": [
      "Silin Li",
      "Yuhang Guo",
      "Jiashu Yao",
      "Zeming Liu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.598": {
    "title": "Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment",
    "volume": "long",
    "abstract": "Modern zero-shot text-to-speech (TTS) systems, despite using extensive pre-training, often struggle in challenging scenarios such as tongue twisters, repeated words, code-switching, and cross-lingual synthesis, leading to intelligibility issues. To address these limitations, this paper leverages preference alignment techniques, which enable targeted construction of out-of-pretraining-distribution data to enhance performance. We introduce a new dataset, named the Intelligibility Preference Speech Dataset (INTP), and extend the Direct Preference Optimization (DPO) framework to accommodate diverse TTS architectures. After INTP alignment, in addition to intelligibility, we observe overall improvements including naturalness, similarity, and audio quality for multiple TTS models across diverse domains. Based on that, we also verify the weak-to-strong generalization ability of INTP for more intelligible models such as CosyVoice 2 and Ints. Moreover, we showcase the potential for further improvements through iterative alignment based on Ints. Audio samples are available at https://intalign.github.io/",
    "checked": true,
    "id": "78ad49d8e911cb5549c50cf77fd92febd144ba6e",
    "semantic_title": "advancing zero-shot text-to-speech intelligibility across diverse domains via preference alignment",
    "citation_count": 0,
    "authors": [
      "Xueyao Zhang",
      "Yuancheng Wang",
      "Chaoren Wang",
      "Ziniu Li",
      "Zhuo Chen",
      "Zhizheng Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.599": {
    "title": "GiFT: Gibbs Fine-Tuning for Code Generation",
    "volume": "long",
    "abstract": "Training Large Language Models (LLMs) with synthetic data is a prevalent practice in code generation. A key approach is self-training, where LLMs are iteratively trained on self-generated correct code snippets. In this case, the self-generated codes are drawn from a conditional distribution, conditioned on a specific seed description. However, the seed description is not the only valid representation that aligns with its intended meaning. With all valid descriptions and codes forming a joint space, codes drawn from the conditional distribution would lead to an underrepresentation of the full description-code space. As such, we propose Gibbs Fine-Tuning (GiFT), a novel self-training method inspired by Gibbs sampling. GiFT allows self-generated data to be drawn from the marginal distribution of the joint space, thereby mitigating the biases inherent in conditional sampling. We provide a theoretical analysis demonstrating the potential benefits of fine-tuning LLMs with code derived from the marginal distribution. Furthermore, we propose a perplexity-based code selection method to mitigate the imbalanced long-tail distribution of the self-generated codes. Empirical evaluation of two LLMs across four datasets demonstrates that GiFT achieves superior performance, particularly on more challenging benchmarks. Source code is available at https://github.com/Alex-HaochenLi/GiFT",
    "checked": true,
    "id": "031ed8286daf421cc7b9dd2322e921bc50c652f4",
    "semantic_title": "gift: gibbs fine-tuning for code generation",
    "citation_count": 1,
    "authors": [
      "Haochen Li",
      "Wanjin Feng",
      "Xin Zhou",
      "Zhiqi Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.600": {
    "title": "Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models",
    "volume": "long",
    "abstract": "Concept Bottleneck Models (CBMs) decompose image classification into a process governed by interpretable, human-readable concepts. Recent advances in CBMs have used Large Language Models (LLMs) to generate candidate concepts. However, a critical question remains: What is the optimal number of concepts to use? Current concept banks suffer from redundancy or insufficient coverage. To address this issue, we introduce a dynamic, agent-based approach that adjusts the concept bank in response to environmental feedback, optimizing the number of concepts for sufficiency yet concise coverage. Moreover, we propose Conditional Concept Bottleneck Models (CoCoBMs) to overcome the limitations in traditional CBMs' concept scoring mechanisms. It enhances the accuracy of assessing each concept's contribution to classification tasks and feature an editable matrix that allows LLMs to correct concept scores that conflict with their internal knowledge. Our evaluations across 6 datasets show that our method not only improves classification accuracy by 6% but also enhances interpretability assessments by 30%",
    "checked": true,
    "id": "c9f9dd09c280fe6fa5715faf4b0ce4348daf119c",
    "semantic_title": "enhancing interpretable image classification through llm agents and conditional concept bottleneck models",
    "citation_count": 0,
    "authors": [
      "Yiwen Jiang",
      "Deval Mehta",
      "Wei Feng",
      "Zongyuan Ge"
    ]
  },
  "https://aclanthology.org/2025.acl-long.601": {
    "title": "Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction",
    "volume": "long",
    "abstract": "The rapid advancement of large language models has raised significant concerns regarding their potential misuse by malicious actors. As a result, developing effective detectors to mitigate these risks has become a critical priority. However, most existing detection methods focus excessively on detection accuracy, often neglecting the societal risks posed by high false positive rates (FPRs). This paper addresses this issue by leveraging Conformal Prediction (CP), which effectively constrains the upper bound of FPRs. While directly applying CP constrains FPRs, it also leads to a significant reduction in detection performance. To overcome this trade-off, this paper proposes a Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction (MCP), which both enforces the FPR constraint and improves detection performance. This paper also introduces RealDet, a high-quality dataset that spans a wide range of domains, ensuring realistic calibration and enabling superior detection performance when combined with MCP. Empirical evaluations demonstrate that MCP effectively constrains FPRs, significantly enhances detection performance, and increases robustness against adversarial attacks across multiple detectors and datasets",
    "checked": true,
    "id": "ef4e2079c85379e83ddbb943bd5be613ea6c0fcd",
    "semantic_title": "reliably bounding false positives: a zero-shot machine-generated text detection framework via multiscaled conformal prediction",
    "citation_count": 0,
    "authors": [
      "Xiaowei Zhu",
      "Yubing Ren",
      "Yanan Cao",
      "Xixun Lin",
      "Fang Fang",
      "Yangxi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.602": {
    "title": "RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph",
    "volume": "long",
    "abstract": "In knowledge graph embedding, leveraging relation specific entity transformation has markedly enhanced performance. However, the consistency of embedding differences before and after transformation remains unaddressed, risking the loss of valuable inductive bias inherent in the embeddings. This inconsistency stems from two problems. First, transformation representations are specified for relations in a disconnected manner, allowing dissimilar transformations and corresponding entity embeddings for similar relations. Second, a generalized plug-in approach as a SFBR (Semantic Filter Based on Relations) disrupts this consistency through excessive concentration of entity embeddings under entity-based regularization, generating indistinguishable score distributions among relations. In this paper, we introduce a plug-in KGE method, Relation-Semantics Consistent Filter (RSCF). Its entity transformation has three features for enhancing semantic consistency: 1) shared affine transformation of relation embeddings across all relations, 2) rooted entity transformation that adds an entity embedding to its change represented by the transformed vector, and 3) normalization of the change to prevent scale reduction. To amplify the advantages of consistency that preserve semantics on embeddings, RSCF adds relation transformation and prediction modules for enhancing the semantics. In knowledge graph completion tasks with distance-based and tensor decomposition models, RSCF significantly outperforms state-of-the-art KGE methods, showing robustness across all relations and their frequencies",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junsik Kim",
      "Jinwook Park",
      "Kangil Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.603": {
    "title": "RolePlot: A Systematic Framework for Evaluating and Enhancing the Plot-Progression Capabilities of Role-Playing Agents",
    "volume": "long",
    "abstract": "Role-playing agents (RPAs) are garnering increasing interests as a novel form of conversational AI. While previous research has predominantly concentrated on their ability to portray specified characters, we argue from a user-centered perspective that RPAs' capability to advance the plot requires substantial improvements to deliver more engaging interaction. To bridge this gap, we propose RolePlot, a role-playing framework specifically designed to evaluate and enhance the plot-progression capabilities of RPAs. RolePlot begins by constructing a plot-progression dataset extended from human-written literary scripts and specially designed synthetic data, followed by narrative theory-driven manual annotation and automated labeling validated through human verification. We then exploit the over-parameterized embedding space of LLMs to detect a \"trigger subspace\" that identifies dialogue segments catalyzing plot transitions. When user's inputs align with this subspace, we explicitly prompt RPAs to advance the plot. For evaluation, we simulate User-RPA interactions and track both the conversation longevity (measured in dialogue turns before disengagement) and users' arousal levels across different stages. Empirically, our method improves RPAs' capability to time plot developments, and more importantly, yielding a significant increase in conversation turns and sustained higher arousal levels, thereby confirming that users experience more immersive engagements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pinyi Zhang",
      "Siyu An",
      "Lingfeng Qiao",
      "Yifei Yu",
      "Jingyang Chen",
      "Jie Wang",
      "Di Yin",
      "Xing Sun",
      "Kai Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.604": {
    "title": "TreeRL: LLM Reinforcement Learning with On-Policy Tree Search",
    "volume": "long",
    "abstract": "Reinforcement learning (RL) with tree search has demonstrated superior performance in traditional reasoning tasks. Compared to conventional independent chain sampling strategies with outcome supervision, tree search enables better exploration of the reasoning space and provides dense, on-policy process rewards during RL training but remains under-explored in On-Policy LLM RL. We propose TreeRL, a reinforcement learning framework that directly incorporates on-policy tree search for RL training. Our approach includes intermediate supervision and eliminates the need for separate reward model training. Existing approaches typically train a separate process reward model, which can suffer from distribution mismatch and reward hacking. We also introduce a cost-effective tree search approach that achieves higher search efficiency under the same generation token budget by strategically branching from high-uncertainty intermediate steps rather than using random branching. Experiments on challenging math and code reasoning benchmarks demonstrate that TreeRL achieves superior performance compared to traditional ChainRL, highlighting the potential of tree search for LLM. TreeRL is open-sourced at https://github.com/THUDM/TreeRL",
    "checked": true,
    "id": "c604fc589c67394113fb9552b4121184ce5d06e8",
    "semantic_title": "treerl: llm reinforcement learning with on-policy tree search",
    "citation_count": 0,
    "authors": [
      "Zhenyu Hou",
      "Ziniu Hu",
      "Yujiang Li",
      "Rui Lu",
      "Jie Tang",
      "Yuxiao Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.605": {
    "title": "Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) with API-calling capabilities enabled building effective Language Agents (LA), while also revolutionizing the conventional task-oriented dialogue (TOD) paradigm. However, current approaches face a critical dilemma: TOD systems are often trained on a limited set of target APIs, requiring new data to maintain their quality when interfacing with new services, while LAs are not trained to maintain user intent over multi-turn conversations. Because both robust multi-turn management and advanced function calling are crucial for effective conversational agents, we evaluate these skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and API-Bank (LA)—and our analyses reveal that specialized approaches excel in one domain but underperform in the other. To bridge this chasm, we introduce **CoALM** (**C**onversational **A**gentic **L**anguage **M**odel), a unified approach that integrates both conversational and agentic capabilities. We created **CoALM-IT**, a carefully constructed multi-task dataset that interleave multi-turn ReAct reasoning with complex API usage. Using CoALM-IT, we train three models **CoALM 8B**, **CoALM 70B**, and **CoALM 405B**, which outperform top domain-specific models, including GPT-4o, across all three benchmarks. This demonstrates the feasibility of a single model approach for both TOD and LA, setting a new standard for conversational agents",
    "checked": true,
    "id": "3076cfba160fc4d64eec459e2f99b307b72cb12a",
    "semantic_title": "can a single model master both multi-turn conversations and tool use? coalm: a unified conversational agentic language model",
    "citation_count": 3,
    "authors": [
      "Emre Can Acikgoz",
      "Jeremiah Greer",
      "Akul Datta",
      "Ze Yang",
      "William Zeng",
      "Oussama Elachqar",
      "Emmanouil Koukoumidis",
      "Dilek Hakkani-Tür",
      "Gokhan Tur"
    ]
  },
  "https://aclanthology.org/2025.acl-long.606": {
    "title": "Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation",
    "volume": "long",
    "abstract": "Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix Modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an imageonly encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios. The code will be released upon acceptance",
    "checked": true,
    "id": "87f5ddceabdef655e1132219389e271d91bad969",
    "semantic_title": "single-to-mix modality alignment with multimodal large language model for document image machine translation",
    "citation_count": 0,
    "authors": [
      "Yupu Liang",
      "Yaping Zhang",
      "Zhiyang Zhang",
      "Yang Zhao",
      "Lu Xiang",
      "Chengqing Zong",
      "Yu Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.607": {
    "title": "SDPO: Segment-Level Direct Preference Optimization for Social Agents",
    "volume": "long",
    "abstract": "Social agents powered by large language models (LLMs) can simulate human social behaviors but fall short in handling complex social dialogues. Direct Preference Optimization (DPO) has proven effective in aligning LLM behavior with human preferences across various agent tasks. However, standard DPO focuses solely on individual turns, which limits its effectiveness in multi-turn social interactions. Several DPO-based multi-turn alignment methods with session-level data have shown potential in addressing this problem. While these methods consider multiple turns across entire sessions, they are often overly coarse-grained, introducing training noise, and lack robust theoretical support. To resolve these limitations, we propose Segment-Level Direct Preference Optimization (SDPO), which dynamically select key segments within interactions to optimize multi-turn agent behavior. SDPO minimizes training noise and is grounded in a rigorous theoretical framework. Evaluations on the SOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform both existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring SDPO's potential to advance the social intelligence of LLM-based agents. We release our code and data at https://anonymous.4open.science/r/SDPO-CE8F",
    "checked": true,
    "id": "dcd7e42e655713402207acecb842e0b6424bfb8c",
    "semantic_title": "sdpo: segment-level direct preference optimization for social agents",
    "citation_count": 5,
    "authors": [
      "Aobo Kong",
      "Wentao Ma",
      "Shiwan Zhao",
      "Yongbin Li",
      "Yuchuan Wu",
      "Ke Wang",
      "Xiaoqian Liu",
      "Qicheng Li",
      "Yong Qin",
      "Fei Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.608": {
    "title": "KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors",
    "volume": "long",
    "abstract": "Generating psychological counseling responses with language models relies heavily on high-quality datasets. Crowdsourced data collection methods require strict worker training, and data from real-world counseling environments may raise privacy and ethical concerns. While recent studies have explored using large language models (LLMs) to augment psychological counseling dialogue datasets, the resulting data often suffers from limited diversity and authenticity. To address these limitations, this study adopts a role-playing approach where trained counselors simulate counselor-client interactions, ensuring high-quality dialogues while mitigating privacy risks. Using this method, we construct KokoroChat, a Japanese psychological counseling dialogue dataset comprising 6,589 long-form dialogues, each accompanied by comprehensive client feedback. Experimental results demonstrate that fine-tuning open-source LLMs with KokoroChat improves both the quality of generated counseling responses and the automatic evaluation of counseling dialogues. The KokoroChat dataset is available at https://github.com/UEC-InabaLab/KokoroChat",
    "checked": true,
    "id": "aa858e813705f758fc89d51d60049d9cf18fbe0a",
    "semantic_title": "kokorochat: a japanese psychological counseling dialogue dataset collected via role-playing by trained counselors",
    "citation_count": 0,
    "authors": [
      "Zhiyang Qi",
      "Takumasa Kaneko",
      "Keiko Takamizo",
      "Mariko Ukiyo",
      "Michimasa Inaba"
    ]
  },
  "https://aclanthology.org/2025.acl-long.609": {
    "title": "SURVEYFORGE : On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing",
    "volume": "long",
    "abstract": "Survey paper plays a crucial role in scientific research, especially given the rapid growth of research publications. Recently, researchers have begun using LLMs to automate survey generation for better efficiency. However, the quality gap between LLM-generated surveys and those written by human remains significant, particularly in terms of outline quality and citation accuracy. To close these gaps, we introduce SURVEYFORGE, which first generates the outline by analyzing the logical structure of human-written outlines and referring to the retrieved domain-related articles. Subsequently, leveraging high-quality papers retrieved from memory by our scholar navigation agent, SURVEYFORGE can automatically generate and refine the content of the generated article. Moreover, to achieve a comprehensive evaluation, we construct SurveyBench, which includes 100 human-written survey papers for win-rate comparison and assesses AI-generated survey papers across three dimensions: reference, outline, and content quality. Experiments demonstrate that SURVEYFORGEcan outperform previous works such as AutoSurvey",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangchao Yan",
      "Shiyang Feng",
      "Jiakang Yuan",
      "Renqiu Xia",
      "Bin Wang",
      "Lei Bai",
      "Bo Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.610": {
    "title": "Making LLMs Better Many-to-Many Speech-to-Text Translators with Curriculum Learning",
    "volume": "long",
    "abstract": "Multimodal Large Language Models (MLLMs) have achieved significant success in Speech-to-Text Translation (S2TT) tasks. While most existing research has focused on English-centric translation directions, the exploration of many-to-many translation is still limited by the scarcity of parallel data. To address this, we propose a three-stage curriculum learning strategy that leverages the machine translation capabilities of large language models and adapts them to S2TT tasks, enabling effective learning in low-resource settings. We trained MLLMs with varying parameter sizes (3B, 7B, and 32B) and evaluated the proposed strategy using the FLEURS and CoVoST-2 datasets. Experimental results show that the proposed strategy achieves state-of-the-art average performance in 15×14 language pairs, requiring fewer than 10 hours of speech data per language to achieve competitive results. The source code and models are released at https://github.com/yxduir/LLM-SRT",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yexing Du",
      "Youcheng Pan",
      "Ziyang Ma",
      "Bo Yang",
      "Yifan Yang",
      "Keqi Deng",
      "Xie Chen",
      "Yang Xiang",
      "Ming Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.611": {
    "title": "AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research",
    "volume": "long",
    "abstract": "We introduce AbGen, the first benchmark designed to evaluate the capabilities of LLMs in designing ablation studies for scientific research. AbGen consists of 2,000 expert-annotated examples derived from 677 NLP papers. In this benchmark, LLMs are tasked with generating detailed ablation study designs for a specified module or process based on the given research context. Our evaluation of leading LLMs, such as GPT-4o and Llama-3.1, highlights a significant performance gap between these models and human experts in terms of the importance, faithfulness, and soundness of the ablation study designs. Moreover, we demonstrate that current automated evaluation methods are not reliable for our task, as they show a significant discrepancy when compared to human assessment. To better investigate this, we develop AbGen-Eval, a meta-evaluation benchmark designed to assess the reliability of commonly used automated evaluation systems in measuring LLM performance on our task. We investigate various LLM-based evaluation methods on AbGen-Eval, providing insights for future research on developing more effective and reliable LLM-based evaluation systems for complex scientific tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilun Zhao",
      "Weiyuan Chen",
      "Zhijian Xu",
      "Manasi Patwardhan",
      "Chengye Wang",
      "Yixin Liu",
      "Lovekesh Vig",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.612": {
    "title": "Redundancy Principles for MLLMs Benchmarks",
    "volume": "long",
    "abstract": "With the rapid iteration of Multi-modality Large Language Models (MLLMs) and the evolving demands of the field, the number of benchmarks produced annually has surged into the hundreds. The rapid growth has inevitably led to significant redundancy among benchmarks. Therefore, it is crucial to take a step back and critically assess the current state of redundancy and propose targeted principles for constructing effective MLLM benchmarks. In this paper, we focus on redundancy from three key perspectives: 1) Redundancy of benchmark capability dimensions, 2) Redundancy in the number of test questions, and 3) Cross-benchmark redundancy within specific domains. Through the comprehensive analysis over hundreds of MLLMs' performance across more than 20 benchmarks, we aim to quantitatively measure the level of redundancy lies in existing MLLM evaluations, provide valuable insights to guide the future development of MLLM benchmarks, and offer strategies to refine and address redundancy issues effectively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zicheng Zhang",
      "Xiangyu Zhao",
      "Xinyu Fang",
      "Chunyi Li",
      "Xiaohong Liu",
      "Xiongkuo Min",
      "Haodong Duan",
      "Kai Chen",
      "Guangtao Zhai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.613": {
    "title": "WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models",
    "volume": "long",
    "abstract": "Retrieval Augmented Generation (RAG) has gained widespread adoption owing to its capacity to empower large language models (LLMs) to integrate external knowledge. However, existing RAG frameworks are primarily designed for text-based LLMs and rely on Automatic Speech Recognition to process speech input, which discards crucial audio information, risks transcription errors, and increases computational overhead. Therefore, we introduce WavRAG, the first retrieval augmented generation framework with native, end-to-end audio support. WavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw audio for both embedding and retrieval. 2) WavRAG integrates audio and text into a unified knowledge representation. Specifically, we propose the WavRetriever to facilitate the retrieval from a text-audio hybrid knowledge base, and further enhance the in-context capabilities of spoken dialogue models through the integration of chain-of-thought reasoning. In comparison to state-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval performance while delivering a 10x acceleration. Furthermore, WavRAG's unique text-audio hybrid retrieval capability extends the boundaries of RAG to the audio modality",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Chen",
      "Shengpeng Ji",
      "Haoxiao Wang",
      "Ziqing Wang",
      "Siyu Chen",
      "Jinzheng He",
      "Jin Xu",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.614": {
    "title": "ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5",
    "volume": "long",
    "abstract": "Automatic speech recognition (ASR) systems have advanced significantly with models like Whisper, Conformer, and self-supervised frameworks such as Wav2vec 2.0 and HuBERT. However, developing robust ASR models for young children's speech remains challenging due to differences in pronunciation, tone, and pace compared to adult speech. In this paper, we introduce a new Mandarin speech dataset focused on children aged 3 to 5, addressing the scarcity of resources in this area. The dataset comprises 41.25 hours of speech with carefully crafted manual transcriptions, collected from 397 speakers across various provinces in China, with balanced gender representation. We provide a comprehensive analysis of speaker demographics, speech duration distribution and geographic coverage. Additionally, we evaluate ASR performance on models trained from scratch, such as Conformer, as well as fine-tuned pre-trained models like HuBERT and Whisper, where fine-tuning demonstrates significant performance improvements. Furthermore, we assess speaker verification (SV) on our dataset, showing that, despite the challenges posed by the unique vocal characteristics of young children, the dataset effectively supports both ASR and SV tasks. This dataset is a valuable contribution to Mandarin child speech research and holds potential for applications in educational technology and child-computer interaction. It will be open-source and freely available for all academic purposes",
    "checked": true,
    "id": "629e691e55f04cae7784ac2ad3a64a7916b7a627",
    "semantic_title": "childmandarin: a comprehensive mandarin speech dataset for young children aged 3-5",
    "citation_count": 0,
    "authors": [
      "Jiaming Zhou",
      "Shiyao Wang",
      "Shiwan Zhao",
      "Jiabei He",
      "Haoqin Sun",
      "Hui Wang",
      "Cheng Liu",
      "Aobo Kong",
      "Yujie Guo",
      "Xi Yang",
      "Yequan Wang",
      "Yonghua Lin",
      "Yong Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.615": {
    "title": "Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization",
    "volume": "long",
    "abstract": "Iterative data generation and model retraining are widely used to align large language models (LLMs).It typically involves a policy model to generate on-policy responses and a reward model to guide training data selection. Direct Preference Optimization (DPO) further enhances this process by constructing preference pairs of chosen and rejected responses. In this work, we aim to scale up the number of on-policy samples via repeated random sampling to improve alignment performance. Conventional practice selects the sample with the highest reward as chosen and the lowest as rejected for DPO. However, our experiments reveal that this strategy leads to a decline in performance as the sample size increases. To address this, we investigate preference data construction through the lens of underlying normal distribution of sample rewards. We categorize the reward space into seven representative points and systematically explore all 21 (C72) pairwise combinations. Through evaluations on four models using AlpacaEval 2, we find that selecting the rejected response at reward position 𝜇 - 2𝜎 rather than the minimum reward, is crucial for optimal performance. We finally introduce a scalable preference data construction strategy that consistently enhances model performance as the sample scale increases",
    "checked": true,
    "id": "427c2052a57a726641cbfbbf1546457b7dc61dd2",
    "semantic_title": "finding the sweet spot: preference data construction for scaling preference optimization",
    "citation_count": 1,
    "authors": [
      "Yao Xiao",
      "Hai Ye",
      "Linyao Chen",
      "Hwee Tou Ng",
      "Lidong Bing",
      "Xiaoli Li",
      "Roy Ka-Wei Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.616": {
    "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization",
    "volume": "long",
    "abstract": "Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and *denovo* design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology",
    "checked": true,
    "id": "fbab5170bab9400531c909da7c0be8b06e3587e2",
    "semantic_title": "enhancing safe and controllable protein generation via knowledge preference optimization",
    "citation_count": 0,
    "authors": [
      "Yuhao Wang",
      "Keyan Ding",
      "Kehua Feng",
      "Zeyuan Wang",
      "Ming Qin",
      "Xiaotong Li",
      "Qiang Zhang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.617": {
    "title": "SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection",
    "volume": "long",
    "abstract": "In the era of rapidly evolving large language models (LLMs), state-of-the-art rumor detection systems, particularly those based on Message Propagation Trees (MPTs), which represent a conversation tree with the post as its root and the replies as its descendants, are facing increasing threats from adversarial attacks that leverage LLMs to generate and inject malicious messages. Existing methods are based on the assumption that different nodes exhibit varying degrees of influence on predictions. They define nodes with high predictive influence as important nodes and target them for attacks. If the model treats nodes' predictive influence more uniformly, attackers will find it harder to target high predictive influence nodes. In this paper, we propose Similarizing the predictive Influence of Nodes with Contrastive Learning (SINCon), a defense mechanism that encourages the model to learn graph representations where nodes with varying importance have a more uniform influence on predictions. Extensive experiments on the Twitter and Weibo datasets demonstrate that SINCon not only preserves high classification accuracy on clean data but also significantly enhances resistance against LLM-driven message injection attacks",
    "checked": true,
    "id": "fcd7ded92bc3957fad1de6ae9430cf64f7663ed2",
    "semantic_title": "sincon: mitigate llm-generated malicious message injection attack for rumor detection",
    "citation_count": 0,
    "authors": [
      "Mingqing Zhang",
      "Qiang Liu",
      "Xiang Tao",
      "Shu Wu",
      "Liang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.618": {
    "title": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models",
    "volume": "long",
    "abstract": "Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment. While channel-wise operations and adaptive gradient scaling are recognized causes, practical mitigation remains challenging. We introduce **Outlier-Safe Pre-Training (OSP)**, a practical guideline that proactively prevents outlier formation, rather than relying on post-hoc mitigation. OSP combines three key innovations: (1) the Muon optimizer, eliminating privileged bases while maintaining training efficiency, (2) Single-Scale RMSNorm, preventing channel-wise amplification, and (3) a learnable embedding projection, redistributing activation magnitudes. We validate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is the first production-scale LLM trained without such outliers. Under aggressive 4-bit quantization, our OSP model achieves a 35.7 average score across 10 benchmarks (versus 26.5 for an Adam-trained model), with only a 2% training overhead. Remarkably, OSP models exhibit near-zero excess kurtosis (0.04) compared to extreme values (1818.56) in standard models, fundamentally altering LLM quantization behavior. Our work demonstrates that outliers are not inherent to LLMs but are consequences of training strategies, paving the way for more efficient LLM deployment",
    "checked": true,
    "id": "69599c85005ac53a6c7677ef207934bc94fb83fb",
    "semantic_title": "outlier-safe pre-training for robust 4-bit quantization of large language models",
    "citation_count": 0,
    "authors": [
      "Jungwoo Park",
      "Taewhoo Lee",
      "Chanwoong Yoon",
      "Hyeon Hwang",
      "Jaewoo Kang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.619": {
    "title": "Agentic Knowledgeable Self-awareness",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional approaches adopt a \"flood irrigation\" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice overlooks the fundamental human cognitive principle of self-awareness - the ability to dynamically assess situational demands and strategically employ resources during decision-making. We propose Agentic Knowledgeable Self-awareness to address this gap, a novel paradigm enabling LLM-based agents to autonomously regulate knowledge utilization. Specifically, we propose KnowSelf, a data-centric approach that applies agents with knowledgeable self-awareness like humans. Concretely, we devise a heuristic situation judgement criterion to mark special tokens on the agent's self-explored trajectories for collecting training data. Through a two-stage training process, the agent model can switch between different situations by generating specific special tokens, achieving optimal planning effects with minimal costs. Our experiments demonstrate that can outperform various strong baselines on different tasks and models with minimal use of external knowledge",
    "checked": true,
    "id": "effe604a80373c6606c4cd1e12793a3eb6f446a5",
    "semantic_title": "agentic knowledgeable self-awareness",
    "citation_count": 1,
    "authors": [
      "Shuofei Qiao",
      "Zhisong Qiu",
      "Baochang Ren",
      "Xiaobin Wang",
      "Xiangyuan Ru",
      "Ningyu Zhang",
      "Xiang Chen",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.620": {
    "title": "A Unified Agentic Framework for Evaluating Conditional Image Generation",
    "volume": "long",
    "abstract": "Conditional image generation has gained significant attention for its ability to personalize content. However, the field faces challenges in developing task-agnostic, reliable, and explainable evaluation metrics. This paper introduces CIGEval, a unified agentic framework for comprehensive evaluation of conditional image generation tasks. CIGEval utilizes large multimodal models (LMMs) as its core, integrating a multi-functional toolbox and establishing a fine-grained evaluation framework. Additionally, we synthesize evaluation trajectories for fine-tuning, empowering smaller LMMs to autonomously select appropriate tools and conduct nuanced analyses based on tool outputs. Experiments across seven prominent conditional image generation tasks demonstrate that CIGEval (GPT-4o version) achieves a high correlation of 0.4625 with human assessments, closely matching the inter-annotator correlation of 0.47. Notably, when implemented with 7B open-source LMMs using only 2.3K training trajectories, CIGEval surpasses the previous GPT-4o-based state-of-the-art method. These findings indicate that CIGEval holds great potential for automating evaluation of image generation tasks while maintaining human-level reliability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jifang Wang",
      "Yangxue Yangxue",
      "Longyue Wang",
      "Zhenran Xu",
      "Yiyu Wang",
      "Yaowei Wang",
      "Weihua Luo",
      "Kaifu Zhang",
      "Baotian Hu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.621": {
    "title": "Planning-Driven Programming: A Large Language Model Programming Workflow",
    "volume": "long",
    "abstract": "The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency and limited reasoning capacity. In this work, we propose an LLM programming workflow (LPW) designed to improve both initial code generation and subsequent refinements within a structured two-phase workflow. Specifically, the solution generation phase formulates a solution plan, which is then verified through visible tests to specify the intended natural language solution. Subsequently, the code implementation phase drafts an initial code according to the solution plan and its verification. If the generated code fails the visible tests, the plan verification serves as the intended solution to consistently inform the refinement process for correcting bugs. Compared to state-of-the-art methods across various existing LLMs, LPW significantly improves the Pass@1 accuracy by up to 16.4% on well-established text-to-code generation benchmarks. LPW also sets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8% on MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContests, using GPT-4o as the backbone. Our code is publicly available at: https://github.com/you68681/lpw",
    "checked": true,
    "id": "d901b765310bbaacacae8b525ebc0b38a1ded087",
    "semantic_title": "planning-driven programming: a large language model programming workflow",
    "citation_count": 6,
    "authors": [
      "Chao Lei",
      "Yanchuan Chang",
      "Nir Lipovetzky",
      "Krista A. Ehinger"
    ]
  },
  "https://aclanthology.org/2025.acl-long.622": {
    "title": "Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering",
    "volume": "long",
    "abstract": "Recent works integrating Knowledge Graphs (KGs) have shown promising improvements in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing benchmarks primarily focus on closed-ended tasks, leaving a gap in evaluating performance on more complex, real-world scenarios. This limitation also hinders a thorough assessment of KGs' potential to reduce hallucinations in LLMs. To address this, we introduce OKGQA, a new benchmark specifically designed to evaluate LLMs augmented with KGs in open-ended, real-world question answering settings. OKGQA reflects practical complexities through diverse question types and incorporates metrics to quantify both hallucination rates and reasoning improvements in LLM+KG models. To consider the scenarios in which KGs may contain varying levels of errors, we propose a benchmark variant, OKGQA-P, to assess model performance when the semantics and structure of KGs are deliberately perturbed and contaminated. In this paper, we aims to (1) explore whether KGs can make LLMs more trustworthy in an open-ended setting, and (2) conduct a comparative analysis to shed light on method design. We believe this study can facilitate a more complete performance comparison and encourages continuous improvement in integrating KGs with LLMs to mitigate hallucination, and make LLMs more trustworthy",
    "checked": true,
    "id": "89fccb4b70d0a072d9c874dddfab0afb3676d1b8",
    "semantic_title": "can knowledge graphs make large language models more trustworthy? an empirical study over open-ended question answering",
    "citation_count": 10,
    "authors": [
      "Yuan Sui",
      "Yufei He",
      "Zifeng Ding",
      "Bryan Hooi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.623": {
    "title": "Nudging: Inference-time Alignment of LLMs via Guided Decoding",
    "volume": "long",
    "abstract": "Large language models (LLMs) require alignment to effectively and safely follow user instructions. This process necessitates training an aligned version for every base model, resulting in significant computational overhead. In this work, we propose NUDGING, a simple, training-free algorithm that aligns any base model at inference time using a small aligned model. NUDGING is motivated by recent findings that alignment primarily alters the model's behavior on a small subset of stylistic tokens (e.g., discourse markers). We find that base models are significantly more uncertain when generating these tokens. Building on this insight, NUDGING employs a small aligned model to generate nudging tokens to guide the base model's output during decoding when the base model's uncertainty is high, with only a minor additional inference overhead. We evaluate NUDGING across 3 model families on a diverse range of open-instruction tasks. Without any training, nudging a large base model with a 7×-14× smaller aligned model achieves zero-shot performance comparable to, and sometimes surpassing, that of large aligned models. By operating at the token level, NUDGING enables off-the-shelf collaboration between model families. For instance, nudging Gemma-2-27b with Llama-27b-chat outperforms Llama-2-70b-chat on various tasks. Overall, our work offers a modular and cost-efficient solution to LLM alignment. Our code and demo are available at: https://fywalter.github.io/nudging/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Fei",
      "Yasaman Razeghi",
      "Sameer Singh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.624": {
    "title": "Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing",
    "volume": "long",
    "abstract": "Dynamical systems theory provides a framework for analyzing iterative processes and evolution over time. Within such systems, repetitive transformations can lead to stable configurations, known as attractors, including fixed points and limit cycles. Applying this perspective to large language models (LLMs), which iteratively map input text to output text, provides a principled approach to characterizing long-term behaviors. Successive paraphrasing serves as a compelling testbed for exploring such dynamics, as paraphrases re-express the same underlying meaning with linguistic variation. Although LLMs are expected to explore a diverse set of paraphrases in the text space, our study reveals that successive paraphrasing converges to stable periodic states, such as 2-period attractor cycles, limiting linguistic diversity. This phenomenon is attributed to the self-reinforcing nature of LLMs, as they iteratively favour and amplify certain textual forms over others. This pattern persists with increasing generation randomness or alternating prompts and LLMs. These findings underscore inherent constraints in LLM generative capability, while offering a novel dynamical systems perspective for studying their expressive potential",
    "checked": true,
    "id": "4799163b330e8a3189faffccde9f30921ed2a07c",
    "semantic_title": "unveiling attractor cycles in large language models: a dynamical systems view of successive paraphrasing",
    "citation_count": 0,
    "authors": [
      "Zhilin Wang",
      "Yafu Li",
      "Jianhao Yan",
      "Yu Cheng",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.625": {
    "title": "SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models",
    "volume": "long",
    "abstract": "Recent studies emphasize that manually ensuring a consistent response style and maintaining high data quality in training sets can significantly improve the performance of fine-tuned Large Language Models (LLMs) while reducing the number of training examples needed. However, the precise definition of style and the relationship between style, data quality, and LLM performance remains unclear. This research identifies two key stylistic elements in responses: linguistic form and instructional surprisal. We find that, among training data of comparable quality, higher consistency in these response elements leads to better LLM performance. Inspired by this, we introduce Style Consistency-Aware Response Ranking (SCAR), which automatically prioritizes instruction-response pairs in the training set based on their response stylistic consistency. By selecting the most style-consistent examples, using 0.7% of the full dataset in certain cases, the fine-tuned LLMs can match or even surpass the performance of models trained on the entire dataset in coding and open-ended question-answering benchmarks. Code and data are available at https://github.com/zhuang-li/SCAR",
    "checked": true,
    "id": "5c55997ce627c6c7c33198f3d8dab8a4670b7c98",
    "semantic_title": "scar: data selection via style consistency-aware response ranking for efficient instruction-tuning of large language models",
    "citation_count": 2,
    "authors": [
      "Zhuang Li",
      "Yuncheng Hua",
      "Thuy-Trang Vu",
      "Haolan Zhan",
      "Lizhen Qu",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2025.acl-long.626": {
    "title": "HFT: Half Fine-Tuning for Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become necessary to unlock various capabilities, enabling LLMs to follow natural language instructions and align with human preferences. However, it carries the risk of catastrophic forgetting during sequential training, the parametric knowledge or the ability learned in previous stages may be overwhelmed by incoming training data. This paper finds that LLMs can restore some original knowledge by regularly resetting partial parameters. Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute for full fine-tuning (FFT), to mitigate the forgetting issues, where half of the parameters are selected to learn new tasks. In contrast, the other half are frozen to retain previous knowledge. We provide a feasibility analysis from the optimization perspective and interpret the parameter selection operation as a regularization term. HFT could be seamlessly integrated into existing fine-tuning frameworks without changing the model architecture. Extensive experiments and analysis on supervised fine-tuning, direct preference optimization, and continual learning consistently demonstrate the effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not only significantly alleviates the forgetting problem, but also achieves the best performance in a series of downstream benchmarks, with an approximately 30% reduction in training time",
    "checked": true,
    "id": "e26b2cb94b42385d499d3d2c7cb4d4d24dbb0c13",
    "semantic_title": "hft: half fine-tuning for large language models",
    "citation_count": 7,
    "authors": [
      "Tingfeng Hui",
      "Zhenyu Zhang",
      "Shuohuan Wang",
      "Weiran Xu",
      "Yu Sun",
      "Hua Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.627": {
    "title": "Beyond Surface Simplicity: Revealing Hidden Reasoning Attributes for Precise Commonsense Diagnosis",
    "volume": "long",
    "abstract": "Commonsense question answering (QA) are widely used to evaluate the commonsense abilities of large language models. However, answering commonsense questions correctly requires not only knowledge but also reasoning—even for seemingly simple questions. We demonstrate that such hidden reasoning attributes in commonsense questions can lead evaluation accuracy differences of up to 24.8% across different difficulty levels in the same benchmark. Current benchmarks overlook these hidden reasoning attributes, making it difficult to assess a model's specific levels of commonsense knowledge and reasoning ability. To address this issue, we introduce ReComSBench, a novel framework that reveals hidden reasoning attributes behind commonsense questions by leveraging the knowledge generated during the reasoning process. Additionally, ReComSBench proposes three new metrics for decoupled evaluation: Knowledge Balanced Accuracy, Marginal Sampling Gain, and Knowledge Coverage Ratio. Experiments show that ReComSBench provides insights into model performance that traditional benchmarks cannot offer. The difficulty stratification based on revealed hidden reasoning attributes performs as effectively as the model-probability-based approach but is more generalizable and better suited for improving a model's commonsense reasoning abilities. By uncovering and analyzing the hidden reasoning attributes in commonsense data, ReComSBench offers a new approach to enhancing existing commonsense benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huijun Lian",
      "Zekai Sun",
      "Keqi Chen",
      "Yingming Gao",
      "Ya Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.628": {
    "title": "From Objectives to Questions: A Planning-based Framework for Educational Mathematical Question Generation",
    "volume": "long",
    "abstract": "Automatically generating high-quality mathematical problems that align with educational objectives is a crucial task in NLP-based educational technology. Traditional generation methods focus primarily on textual quality, but they often overlook educational objectives. Moreover, these methods address only single-dimensional, simple question generation, failing to meet complex, multifaceted educational requirements. To address these challenges, we constructed and annotated EduMath, a dataset of 16k mathematical questions with multi-dimensional educational objectives. Based on this dataset, we developed EQGEVAL, which incorporates three evaluation dimensions and is designed to assess the ability of models to generate educational questions. Drawing inspiration from teachers' problem design processes, we propose the Educational Question Planning with self-Reflection (EQPR) method for educational mathematical question generation, following a \"plan-evaluate-optimize\" approach. Specifically, by combining planning algorithm based on Monte Carlo Tree Search with the generative capabilities of Large Language Models, we continuously optimize questions through iterative feedback. This self-optimization mechanism ensures that the generated questions both fit the educational context and strategically achieve specific basic educational objectives. Through extensive experiments based on EQGEVAL, we have demonstrated that EQPR achieves significant improvements in generating questions that meet multi-dimensional educational objectives",
    "checked": true,
    "id": "4363b39e9ba0a319ed84e886cd94b94e47336d04",
    "semantic_title": "from objectives to questions: a planning-based framework for educational mathematical question generation",
    "citation_count": 0,
    "authors": [
      "Cheng Cheng",
      "Zhenya Huang",
      "GuanHao Zhao",
      "Yuxiang Guo",
      "Xin Lin",
      "Jinze Wu",
      "Xin Li",
      "Shijin Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.629": {
    "title": "RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts",
    "volume": "long",
    "abstract": "Retrieval-Augmented Generation (RAG) enhances the performance of Large Language Models (LLMs) by incorporating external knowledge. However, LLMs still encounter challenges in effectively utilizing the knowledge from retrieved documents, often being misled by irrelevant or noisy information. To address this issue, we introduce RankCoT, a knowledge refinement method that incorporates reranking signals in generating CoT-based summarization for knowledge refinement based on given query and all retrieval documents. During training, RankCoT prompts the LLM to generate Chain-of-Thought (CoT) candidates based on the query and individual documents. It then fine-tunes the LLM to directly reproduce the best CoT from these candidate outputs based on all retrieved documents, which requires LLM to filter out irrelevant documents during generating CoT-style summarization. Additionally, RankCoT incorporates a self-reflection mechanism that further refines the CoT outputs, resulting in higher-quality training data. Our experiments demonstrate the effectiveness of RankCoT, showing its superior performance over other knowledge refinement models. Further analysis reveals that RankCoT can provide shorter but effective refinement results, enabling the generator to produce more accurate answers. All code and data are available at https://github.com/NEUIR/RankCoT",
    "checked": true,
    "id": "fd2b6acfec2b94ae72ce3dfe1873d96c6a9159b1",
    "semantic_title": "rankcot: refining knowledge for retrieval-augmented generation through ranking chain-of-thoughts",
    "citation_count": 2,
    "authors": [
      "Mingyan Wu",
      "Zhenghao Liu",
      "Yukun Yan",
      "Xinze Li",
      "Shi Yu",
      "Zheni Zeng",
      "Yu Gu",
      "Ge Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.630": {
    "title": "Lost in Literalism: How Supervised Training Shapes Translationese in LLMs",
    "volume": "long",
    "abstract": "Large language models (LLMs) have achieved remarkable success in machine translation, demonstrating impressive performance across diverse languages. However, translationese—characterized by overly literal and unnatural translations—remains a persistent challenge in LLM-based translation systems. Despite their pre-training on vast corpora of natural utterances, LLMs exhibit translationese errors and generate unexpected unnatural translations, stemming from biases introduced during supervised fine-tuning (SFT). In this work, we systematically evaluate the prevalence of translationese in LLM-generated translations and investigate its roots during supervised training. We introduce methods to mitigate these biases, including polishing golden references and filtering unnatural training instances. Empirical evaluations demonstrate that these approaches significantly reduce translationese while improving translation naturalness, validated by human evaluations and automatic metrics. Our findings highlight the need for training-aware adjustments to optimize LLM translation outputs, paving the way for more fluent and target-language-consistent translations",
    "checked": true,
    "id": "b6110045346334f9634c6413503b4a2f181783f9",
    "semantic_title": "lost in literalism: how supervised training shapes translationese in llms",
    "citation_count": 0,
    "authors": [
      "Yafu Li",
      "Ronghao Zhang",
      "Zhilin Wang",
      "Huajian Zhang",
      "Leyang Cui",
      "Yongjing Yin",
      "Tong Xiao",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.631": {
    "title": "Accurate KV Cache Quantization with Outlier Tokens Tracing",
    "volume": "long",
    "abstract": "The impressive capabilities of Large Language Models (LLMs) come at the cost of substantial computational resources during deployment. While KV Cache can significantly reduce recomputation during inference, it also introduces additional memory overhead. KV Cache quantization presents a promising solution, striking a good balance between memory usage and accuracy. Previous research has shown that the Keys are distributed by channel, while the Values are distributed by token. Consequently, the common practice is to apply channel-wise quantization to the Keys and token-wise quantization to the Values. However, our further investigation reveals that a small subset of unusual tokens exhibit unique characteristics that deviate from this pattern, which can substantially impact quantization accuracy. To address this, we develop a simple yet effective method to identify these tokens accurately during the decoding process and exclude them from quantization as outlier tokens, significantly improving overall accuracy. Extensive experiments show that our method achieves significant accuracy improvements under 2-bit quantization and can deliver a 6.4 times reduction in memory usage and a 2.3 times increase in throughput",
    "checked": true,
    "id": "419ef8266bfd1edd75d96c7bc8c667ade3d689a9",
    "semantic_title": "accurate kv cache quantization with outlier tokens tracing",
    "citation_count": 1,
    "authors": [
      "Yi Su",
      "Yuechi Zhou",
      "Quantong Qiu",
      "Juntao Li",
      "Qingrong Xia",
      "Ping Li",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.632": {
    "title": "Can Large Language Models Understand Internet Buzzwords Through User-Generated Content",
    "volume": "long",
    "abstract": "The massive user-generated content (UGC) available in Chinese social media is giving rise to the possibility of studying internet buzzwords. In this paper, we study if large language models (LLMs) can generate accurate definitions for these buzzwords based on UGC as examples. Our work serves a threefold contribution. First, we introduce CHEER, the first dataset of Chinese internet buzzwords, each annotated with a definition and relevant UGC. Second, we propose a novel method, called RESS, to effectively steer the comprehending process of LLMs to produce more accurate buzzword definitions, mirroring the skills of human language learning. Third, with CHEER, we benchmark the strengths and weaknesses of various off-the-shelf definition generation methods and our RESS. Our benchmark demonstrates the effectiveness of RESS while revealing a crucial shared challenge: comprehending unseen buzzwords and leveraging sufficient, high-quality UGC to facilitate this comprehension. In this paper, we believe our work lays the groundwork for future advancements in LLM-based definition generation. Our dataset and code will be openly released",
    "checked": true,
    "id": "5adbb2109fba5a2e86655acc0f9d268ddca07563",
    "semantic_title": "can large language models understand internet buzzwords through user-generated content",
    "citation_count": 0,
    "authors": [
      "Chen Huang",
      "Junkai Luo",
      "Xinzuo Wang",
      "Wenqiang Lei",
      "Jiancheng Lv"
    ]
  },
  "https://aclanthology.org/2025.acl-long.633": {
    "title": "EAC-MoE: Expert-Selection Aware Compressor for Mixture-of-Experts Large Language Models",
    "volume": "long",
    "abstract": "Mixture-of-Experts (MoE) has demonstrated promising potential in scaling LLMs. However, it is hindered by two critical challenges: (1) substantial GPU memory consumption to load all experts; (2) low activated parameters cannot be equivalently translated into inference acceleration effects. In this work, we propose EAC-MoE, an Expert-Selection Aware Compressor for MoE-LLMs, which deeply aligns with the characteristics of MoE from the perspectives of quantization and pruning, and introduces two modules to address these two challenges respectively: (1) The expert selection bias caused by low-bit quantization is a major factor contributing to the performance degradation in MoE-LLMs. Based on this, we propose Quantization with Expert-Selection Calibration (QESC), which mitigates the expert selection bias by calibrating the routers within the MoE; (2) There are always certain experts that are not crucial for the corresponding tasks, yet causing inference latency. Therefore, we propose Pruning based on Expert-Selection Frequency (PESF), which significantly improves inference speed by pruning less frequently used experts for current task. Extensive experiments demonstrate that our approach significantly reduces memory usage and improves inference speed with minimal performance degradation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanteng Chen",
      "Yuantian Shao",
      "Peisong Wang",
      "Jian Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.634": {
    "title": "Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention",
    "volume": "long",
    "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities in multimodal understanding, but they frequently suffer from hallucination - generating content inconsistent with visual inputs. In this work, we explore a novel perspective on hallucination mitigation by examining the intermediate activations of LVLMs during generation. Our investigation reveals that hallucinated content manifests as distinct, identifiable patterns in the model's hidden state space. Motivated by this finding, we propose Activation Steering Decoding (ASD), a training-free approach that mitigates hallucination through targeted intervention in the model's intermediate activations. ASD operates by first identifying directional patterns of hallucination in the activation space using a small calibration set, then employing a contrast decoding mechanism that computes the difference between positive and negative steering predictions. This approach effectively suppresses hallucination patterns while preserving the model's general capabilities. Extensive experiments demonstrate that our method significantly reduces hallucination across multiple benchmarks while maintaining performance on general visual understanding tasks. Notably, our approach requires no model re-training or architectural modifications, making it readily applicable to existing deployed models",
    "checked": true,
    "id": "74e213aa78b90207652bf0e0f09b53c10b46fe00",
    "semantic_title": "activation steering decoding: mitigating hallucination in large vision-language models through bidirectional hidden state intervention",
    "citation_count": 0,
    "authors": [
      "Jingran Su",
      "Jingfan Chen",
      "Hongxin Li",
      "Yuntao Chen",
      "Li Qing",
      "Zhaoxiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.635": {
    "title": "Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models",
    "volume": "long",
    "abstract": "One of the primary driving forces contributing to the superior performance of Large Language Models (LLMs) is the extensive availability of human-annotated natural language data, which is used for alignment fine-tuning. This inspired researchers to investigate self-training methods to mitigate the extensive reliance on human annotations. However, the current success of self-training has been primarily observed in natural language scenarios, rather than in the increasingly important neural-symbolic scenarios. To this end, we propose an environment-guided neural-symbolic self-training framework named ENVISIONS. It aims to overcome two main challenges: (1) the scarcity of symbolic data, and (2) the limited proficiency of LLMs in processing symbolic language. Extensive evaluations conducted on three distinct domains demonstrate the effectiveness of our approach. Additionally, we have conducted a comprehensive analysis to uncover the factors contributing to ENVISIONS's success, thereby offering valuable insights for future research in this area",
    "checked": true,
    "id": "a8489211b2fc9065b8e1ce62b6ec3815a32493e0",
    "semantic_title": "interactive evolution: a neural-symbolic self-training framework for large language models",
    "citation_count": 7,
    "authors": [
      "Fangzhi Xu",
      "Qiushi Sun",
      "Kanzhi Cheng",
      "Jun Liu",
      "Yu Qiao",
      "Zhiyong Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.636": {
    "title": "Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback",
    "volume": "long",
    "abstract": "Existing Medical Large Vision-Language Models (Med-LVLMs), encapsulating extensive medical knowledge, demonstrate excellent capabilities in understanding medical images. However, there remain challenges in visual localization in medical images, which is crucial for abnormality detection and interpretation. To address these issues, we propose a novel UMed-LVLM designed to unveil medical abnormalities. Specifically, we collect a Medical Abnormalities Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM training. To collect MAU dataset, we propose a prompt method utilizing the GPT-4V to generate diagnoses based on identified abnormal areas in medical images. Moreover, the two-stage training method includes Abnormal-Aware Instruction Tuning and Abnormal-Aware Rewarding, comprising Relevance Reward, Abnormal Localization Reward and Vision Relevance Reward. Experimental results demonstrate that our UMed-LVLM significantly outperforms existing Med-LVLMs in identifying and understanding medical abnormalities, achieving a 58% improvement over the baseline. In addition, this work shows that enhancing the abnormality detection capabilities of Med-LVLMs significantly improves their understanding of medical images and generalization capability. Our code and data release at URL",
    "checked": true,
    "id": "9d4a10c751946acb3e16c9ec939ca966ff37313f",
    "semantic_title": "improving medical large vision-language models with abnormal-aware feedback",
    "citation_count": 11,
    "authors": [
      "Yucheng Zhou",
      "Lingran Song",
      "Jianbing Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.637": {
    "title": "Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging",
    "volume": "long",
    "abstract": "Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and demonstrates outstanding performance in plentiful natural language processing tasks. However, existing methods transforming LLMs from dense to MoE face significant data requirements and typically rely on large-scale post-training. In this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient approach for tuning a dense pre-trained model into a MoE instruction model. Specifically, we first point out that intermediate checkpoints during instruction tuning of the dense model are naturally suitable for specialized experts, and then propose an expert expansion stage to flexibly achieve models with flexible numbers of experts, where genetic algorithm and parameter merging are introduced to ensure sufficient diversity of new extended experts. To ensure that each specialized expert in the MoE model works as expected, we select a small amount of seed data that each expert excels to pre-optimize the router. Extensive experiments with various data scales and upcycling settings demonstrate the outstanding performance and data efficiency of UpIT, as well as stable improvement in expert or data scaling. Further analysis reveals the importance of ensuring expert diversity in upcycling",
    "checked": true,
    "id": "a221623c866c89cb1ca1368e324e13069c8bddcd",
    "semantic_title": "upcycling instruction tuning from dense to mixture-of-experts via parameter merging",
    "citation_count": 0,
    "authors": [
      "Tingfeng Hui",
      "Zhenyu Zhang",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Sen Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.638": {
    "title": "MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation",
    "volume": "long",
    "abstract": "Vision-language navigation (VLN) is a key task in Embodied AI, requiring agents to navigate diverse and unseen environments while following natural language instructions. Traditional approaches rely heavily on historical observations as spatio-temporal contexts for decision making, leading to significant storage and computational overhead. In this paper, we introduce MapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map (ASM) to replace historical frames. Specifically, our approach constructs a top-down semantic map at the start of each episode and update it at each timestep, allowing for precise object mapping and structured navigation information. Then, we enhance this map with explicit textual labels for key regions, transforming abstract semantics into clear navigation cues and generate our ASM. MapNav agent using the constructed ASM as input, and use the powerful end-to-end capabilities of VLM to empower VLN. Extensive experiments demonstrate that MapNav achieves state-of-the-art (SOTA) performance in both simulated and real-world environments, validating the effectiveness of our method. We will release our ASM generation source code and dataset to ensure reproducibility, contributing valuable resources to the field. We believe that our proposed MapNav can be used as a new memory representation method in VLN, paving the way for future research in this field",
    "checked": true,
    "id": "6ecbf8a5e595bf0704a21b7b3b51626f72dae9cc",
    "semantic_title": "mapnav: a novel memory representation via annotated semantic maps for vlm-based vision-and-language navigation",
    "citation_count": 11,
    "authors": [
      "Lingfeng Zhang",
      "Xiaoshuai Hao",
      "Qinwen Xu",
      "Qiang Zhang",
      "Xinyao Zhang",
      "Pengwei Wang",
      "Jing Zhang",
      "Zhongyuan Wang",
      "Shanghang Zhang",
      "Renjing Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.639": {
    "title": "Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging",
    "volume": "long",
    "abstract": "Medical imaging provides essential visual insights for diagnosis, and multimodal large language models (MLLMs) are increasingly utilized for its analysis due to their strong generalization capabilities; however, the underlying factors driving this generalization remain unclear. Current research suggests that multi-task training outperforms single-task as different tasks can benefit each other, but they often overlook the internal relationships within these tasks. To analyze this phenomenon, we attempted to employ **compositional generalization** (CG), which refers to the models' ability to understand novel combinations by recombining learned elements, as a guiding framework. Since medical images can be precisely defined by **M**odality, **A**natomical area, and **T**ask, naturally providing an environment for exploring CG, we assembled 106 medical datasets to create **Med-MAT** for comprehensive experiments. The experiments confirmed that MLLMs can use CG to understand unseen medical images and identified CG as one of the main drivers of the generalization observed in multi-task training. Additionally, further studies demonstrated that CG effectively supports datasets with limited data and confirmed that MLLMs can achieve CG across classification and detection tasks, underscoring its broader generalization potential. Med-MAT is available at https://github.com/FreedomIntelligence/Med-MAT",
    "checked": true,
    "id": "e8aef334c247393de320836c6b859a9ed522a94b",
    "semantic_title": "exploring compositional generalization of multimodal llms for medical imaging",
    "citation_count": 0,
    "authors": [
      "Zhenyang Cai",
      "Junying Chen",
      "Rongsheng Wang",
      "Weihong Wang",
      "Yonglin Deng",
      "Dingjie Song",
      "Yize Chen",
      "Zixu Zhang",
      "Benyou Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.640": {
    "title": "CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention",
    "volume": "long",
    "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal abilities but remain prone to multilingual object hallucination, with a higher likelihood of generating responses inconsistent with the visual input when utilizing queries in non-English languages compared to English. Most existing approaches to address these rely on pretraining or fine-tuning, which are resource-intensive. In this paper, inspired by observing the disparities in cross-modal attention patterns across languages, we propose Cross-Lingual Attention Intervention for Mitigating multilingual object hallucination (CLAIM) in LVLMs, a novel near training-free method by aligning attention patterns. CLAIM first identifies language-specific cross-modal attention heads, then estimates language shift vectors from English to the target language, and finally intervenes in the attention outputs during inference to facilitate cross-lingual visual perception capability alignment. Extensive experiments demonstrate that CLAIM achieves an average improvement of 13.56% (up to 30% in Spanish) on the POPE and 21.75% on the hallucination subsets of the MME benchmark across various languages. Further analysis reveals that multilingual attention divergence is most prominent in intermediate layers, highlighting their critical role in multilingual scenarios",
    "checked": true,
    "id": "64f44daf20429fd1b048fd64075a2b1b8c5a9d18",
    "semantic_title": "claim: mitigating multilingual object hallucination in large vision-language models with cross-lingual attention intervention",
    "citation_count": 0,
    "authors": [
      "Zekai Ye",
      "Qiming Li",
      "Xiaocheng Feng",
      "Libo Qin",
      "Yichong Huang",
      "Baohang Li",
      "Kui Jiang",
      "Yang Xiang",
      "Zhirui Zhang",
      "Yunfei Lu",
      "Duyu Tang",
      "Dandan Tu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.641": {
    "title": "Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching",
    "volume": "long",
    "abstract": "The goal of conversational product search (CPS) is to develop an intelligent, chat-based shopping assistant that can directly interact with customers to understand shopping intents, ask clarification questions, and find relevant products. However, training such assistants is hindered mainly due to the lack of reliable and large-scale datasets. Prior human-annotated CPS datasets are extremely small in size and lack integration with real-world product search systems. We propose a novel approach, TRACER, which leverages large language models (LLMs) to generate realistic and natural conversations for different shopping domains. TRACER's novelty lies in grounding the generation to dialogue plans, which are product search trajectories predicted from a decision tree model, that guarantees relevant product discovery in the shortest number of search conditions. We also release the first target-oriented CPS dataset Wizard of Shopping (WoS), containing highly natural and coherent conversations (3.6k) from three shopping domains. Finally, we demonstrate the quality and effectiveness of WoS via human evaluations and downstream tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangci Li",
      "Zhiyu Chen",
      "Jason Ingyu Choi",
      "Nikhita Vedula",
      "Besnik Fetahu",
      "Oleg Rokhlenko",
      "Shervin Malmasi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.642": {
    "title": "Qwen2.5-xCoder: Multi-Agent Collaboration for Multilingual Code Instruction Tuning",
    "volume": "long",
    "abstract": "Recent advancement in code understanding and generation demonstrates that code LLMs fine-tuned on a high-quality instruction dataset can gain powerful capabilities to address wide-ranging code-related tasks. However, most previous existing methods mainly view each programming language in isolation and ignore the knowledge transfer among different programming languages. To bridge the gap among different programming languages, we introduce a novel multi-agent collaboration framework to enhance multilingual instruction tuning for code LLMs, where multiple language-specific intelligent agent components with generation memory work together to transfer knowledge from one language to another efficiently and effectively. Specifically, we first generate the language-specific instruction data from the code snippets and then provide the generated data as the seed data for language-specific agents. Multiple language-specific agents discuss and collaborate to formulate a new instruction and its corresponding solution (A new programming language or existing programming language), To further encourage the cross-lingual transfer, each agent stores its generation history as memory and then summarizes its merits and faults. Finally, the high-quality multilingual instruction data is used to encourage knowledge transfer among different programming languages to train Qwen2.5-xCoder. Experimental results on multilingual programming benchmarks demonstrate the superior performance of Qwen2.5-xCoder in sharing common knowledge, highlighting its potential to reduce the cross-lingual gap",
    "checked": true,
    "id": "58f6ac8c023e18e7c8886770ec583e0fdd616e86",
    "semantic_title": "qwen2.5-xcoder: multi-agent collaboration for multilingual code instruction tuning",
    "citation_count": 0,
    "authors": [
      "Jian Yang",
      "Wei Zhang",
      "Yibo Miao",
      "Shanghaoran Quan",
      "Zhenhe Wu",
      "Qiyao Peng",
      "Liqun Yang",
      "Tianyu Liu",
      "Zeyu Cui",
      "Binyuan Hui",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.643": {
    "title": "Cultivating Gaming Sense for Yourself: Making VLMs Gaming Experts",
    "volume": "long",
    "abstract": "Developing agents capable of fluid gameplay in first/third-person games without API access remains a critical challenge in Artificial General Intelligence (AGI). Recent efforts leverage Vision Language Models (VLMs) as direct controllers, frequently pausing the game to analyze screens and plan action through language reasoning. However, this inefficient paradigm fundamentally restricts agents to basic and non-fluent interactions: relying on isolated VLM reasoning for each action makes it impossible to handle tasks requiring high reactivity (e.g., FPS shooting) or dynamic adaptability (e.g., ACT combat). To handle this, we propose a paradigm shift in gameplay agent design: instead of direct control, VLM serves as a developer, creating specialized execution modules tailored for tasks like shooting and combat. These modules handle real-time game interactions, elevating VLM to a high-level developer. Building upon this paradigm, we introduce GameSense, a gameplay agent framework where VLM develops task-specific game sense modules by observing task execution and leveraging vision tools and neural network training pipelines. These modules encapsulate action-feedback logic, ranging from direct action rules to neural network-based decisions. Experiments demonstrate that our framework is the first to achieve fluent gameplay in diverse genres, including ACT, FPS, and Flappy Bird, setting a new benchmark for game-playing agents",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Lu",
      "Jiangyang He",
      "Zhanqiu Zhang",
      "Steven Y. Guo",
      "Tianning Zang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.644": {
    "title": "Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning",
    "volume": "long",
    "abstract": "Advancing LLM reasoning skills has captivated wide interest. However, current post-training techniques rely heavily on supervisory signals, such as outcome supervision or auxiliary reward models, which face the problem of scalability and high annotation costs. This motivates us to enhance LLM reasoning without the need for external supervision. Given the input query, the LLM seeks the globally optimal response by stepwise sampling and self-rewarding, and optimizes itself with the collected responses. Genius offers some technical solutions to address the following key challenges. To tackle the problem of how to determine the steps in the response via self-rewarding, Genius introduces a stepwise foresight re-sampling strategy to sample and estimate the step value by simulating future outcomes. Recognizing the intrinsic noise and uncertainty of self-supervision, we propose an advantage-calibrated optimization (ACO) loss function to mitigate estimation inconsistencies. In short, Genius provides an advanced initial step towards self-improve LLM reasoning with general queries and without supervision, revolutionizing reasoning scaling laws given the vast availability of general queries",
    "checked": true,
    "id": "8d56d827c096ee0cdf38f90e289701ce7ac37d01",
    "semantic_title": "genius: a generalizable and purely unsupervised self-training framework for advanced reasoning",
    "citation_count": 5,
    "authors": [
      "Fangzhi Xu",
      "Hang Yan",
      "Chang Ma",
      "Haiteng Zhao",
      "Qiushi Sun",
      "Kanzhi Cheng",
      "Junxian He",
      "Jun Liu",
      "Zhiyong Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.645": {
    "title": "Extending Complex Logical Queries on Uncertain Knowledge Graphs",
    "volume": "long",
    "abstract": "The study of machine learning-based logical query-answering enables reasoning with large-scale and incomplete knowledge graphs. This paper further advances this line of research by considering the uncertainty in the knowledge. The uncertain nature of knowledge is widely observed in the real world, but does not align seamlessly with the first-order logic underpinning existing studies. To bridge this gap, we study the setting of soft queries on uncertain knowledge, which is motivated by the establishment of soft constraint programming. We further propose an ML-based approach with both forward inference and backward calibration to answer soft queries on large-scale, incomplete, and uncertain knowledge graphs. Theoretical discussions reveal that our method ensures there are no catastrophic cascading errors in our forward inference algorithm while maintaining the same complexity as state-of-the-art inference algorithms for first-order queries. Empirical results justify the superior performance of our approach against previous ML-based methods with number embedding extensions",
    "checked": true,
    "id": "d52eca4203f266af566e6ed2e1f91486a344354d",
    "semantic_title": "extending complex logical queries on uncertain knowledge graphs",
    "citation_count": 2,
    "authors": [
      "Weizhi Fei",
      "Zihao Wang",
      "Hang Yin",
      "Yang Duan",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.acl-long.646": {
    "title": "Knowledge Decoupling via Orthogonal Projection for Lifelong Editing of Large Language Models",
    "volume": "long",
    "abstract": "As large language models (LLMs) require continuous knowledge updates and the mitigation of hallucination issues in generated content, lifelong model editing has become a prominent research area. A mainstream knowledge editing method usually freezes LLM's original parameters and adds extra trainable modules for new knowledge management, reducing interference with old knowledge. Although these approaches have achieved some success, our experiments show that, after extensive editing, the model's knowledge understanding and memory capacity significantly degrade, particularly concerning early edited knowledge. The root cause is that subsequent edits interfere with the previously edited knowledge, and we refer to this phenomenon as knowledge coupling. To address this issue, we propose the Knowledge Decoupling Editing (KDE) method. Specifically, KDE stores the basis vectors of the representation space of past edits in a knowledge cache. It projects the gradient of the current edit onto a space orthogonal to previous knowledge for updating. This method effectively alleviates the coupling between different pieces of knowledge. We also propose a two-stage training strategy to better balance the model's ability to edit new knowledge and distinguish whether a query is related to previous edits. This strategy gradually reduces the interference between new knowledge editing and query distinction, maintaining stable performance during long-term editing. We compared KDE with nine cutting-edge editing methods across multiple mainstream LLMs. The results demonstrate that, regarding question-answering ability and hallucination mitigation, KDE achieves average improvements of 14% and 61%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Xu",
      "Pengxiang Lan",
      "Enneng Yang",
      "Guibing Guo",
      "Jianzhe Zhao",
      "Linying Jiang",
      "Xingwei Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.647": {
    "title": "𝜙-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation",
    "volume": "long",
    "abstract": "Inference-time optimization scales computation to derive deliberate reasoning steps for effective performance. While previous search-based strategies address the short-sightedness of auto-regressive generation, the vast search space leads to excessive exploration and insufficient exploitation. To strike an efficient balance to derive the optimal step, we frame the decoding strategy as foresight sampling, leveraging simulated future steps to obtain globally optimal step estimation. Built on it, we propose a novel decoding strategy, named 𝜙-Decoding. To provide a precise and expressive estimation of step value, 𝜙-Decoding approximates two distributions via foresight and clustering. Sampling from the joint distribution, the optimal steps can be selected for exploitation. To support adaptive computation allocation, we propose in-width and in-depth pruning strategies, featuring a light-weight solution to achieve inference efficiency. Extensive experiments across seven benchmarks show 𝜙-Decoding outperforms strong baselines in both performance and efficiency. Additional analysis demonstrates its generalization across various LLMs and scalability across a wide range of computing budgets",
    "checked": false,
    "id": "38e3a5747bce4275e7830cca5baeb208349c3086",
    "semantic_title": "ϕ-decoding: adaptive foresight sampling for balanced inference-time exploration and exploitation",
    "citation_count": 2,
    "authors": [
      "Fangzhi Xu",
      "Hang Yan",
      "Chang Ma",
      "Haiteng Zhao",
      "Jun Liu",
      "Qika Lin",
      "Zhiyong Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.648": {
    "title": "Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?",
    "volume": "long",
    "abstract": "The radioactive nature of Large Language Model (LLM) watermarking enables the detection of watermarks inherited by student models when trained on the outputs of watermarked teacher models, making it a promising tool for preventing unauthorized knowledge distillation. However, the robustness of watermark radioactivity against adversarial actors remains largely unexplored. In this paper, we investigate whether student models can acquire the capabilities of teacher models through knowledge distillation while avoiding watermark inheritance. We propose two categories of watermark removal approaches: pre-distillation removal through untargeted and targeted training data paraphrasing (UP and TP), and post-distillation removal through inference-time watermark neutralization (WN). Extensive experiments across multiple model pairs, watermarking schemes and hyper-parameter settings demonstrate that both TP and WN thoroughly eliminate inherited watermarks, with WN achieving this while maintaining knowledge transfer efficiency and low computational overhead. Given the ongoing deployment of watermarking techniques in production LLMs, these findings emphasize the urgent need for more robust defense strategies",
    "checked": true,
    "id": "4cf8657c90f1e5b94cef46cdf1764a6390e26edd",
    "semantic_title": "can llm watermarks robustly prevent unauthorized knowledge distillation?",
    "citation_count": 3,
    "authors": [
      "Leyi Pan",
      "Aiwei Liu",
      "Shiyu Huang",
      "Yijian Lu",
      "Xuming Hu",
      "Lijie Wen",
      "Irwin King",
      "Philip S. Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.649": {
    "title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization",
    "volume": "long",
    "abstract": "Reward models (RMs) play a crucial role in reinforcement learning from human feedback (RLHF), aligning model behavior with human preferences. However, existing benchmarks for reward models show a weak correlation with the performance of optimized policies, suggesting that they fail to accurately assess the true capabilities of RMs. To bridge this gap, we explore several evaluation designs through the lens of reward overoptimization, i.e., a phenomenon that captures both how well the reward model aligns with human preferences and the dynamics of the learning signal it provides to the policy. The results highlight three key findings on how to construct a reliable benchmark: (i) it is important to minimize differences between chosen and rejected responses beyond correctness, (ii) evaluating reward models requires multiple comparisons across a wide range of chosen and rejected responses, and (iii) given that reward models encounter responses with diverse representations, responses should be sourced from a variety of models. However, we also observe that a extremely high correlation with degree of overoptimization leads to comparatively lower correlation with certain downstream performance. Thus, when designing a benchmark, it is desirable to use the degree of overoptimization as a useful tool, rather than the end goal",
    "checked": true,
    "id": "62529f40fcc21c10a90608bc2b6bbeb43b6a11db",
    "semantic_title": "rethinking reward model evaluation through the lens of reward overoptimization",
    "citation_count": 0,
    "authors": [
      "Sunghwan Kim",
      "Dongjin Kang",
      "Taeyoon Kwon",
      "Hyungjoo Chae",
      "Dongha Lee",
      "Jinyoung Yeo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.650": {
    "title": "Inducing lexicons of in-group language with socio-temporal context",
    "volume": "long",
    "abstract": "In-group language is an important signifier of group dynamics. This paper proposes a novel method for inducing lexicons of in-group language, which incorporates its socio-temporal context. Existing methods for lexicon induction do not capture the evolving nature of in-group language, nor the social structure of the community. Using dynamic word and user embeddings trained on conversations from online anti-women communities, our approach outperforms prior methods for lexicon induction. We develop a test set for the task of lexicon induction and a new lexicon of manosphere language, validated by human experts, which quantifies the relevance of each term to a specific sub-community at a given point in time. Finally, we present novel insights on in-group language which illustrate the utility of this approach",
    "checked": true,
    "id": "3a95f9693dab003dbdbb738b31c4eee735a7ebc7",
    "semantic_title": "inducing lexicons of in-group language with socio-temporal context",
    "citation_count": 0,
    "authors": [
      "Christine de Kock"
    ]
  },
  "https://aclanthology.org/2025.acl-long.651": {
    "title": "LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement",
    "volume": "long",
    "abstract": "Recent advancements in language models (LMs) have demonstrated strong capabilities in semantic understanding and contextual modeling, which have flourished in generative speech enhancement (SE). However, many LM-based SE approaches primarily focus on semantic information, often neglecting the critical role of acoustic information, which leads to acoustic inconsistency after enhancement and limited generalization across diverse SE tasks. In this paper, we introduce LLaSE-G1, a LLaMA-based language model that incentivizes generalization capabilities for speech enhancement. LLaSE-G1 offers the following key contributions: First, to mitigate acoustic inconsistency, LLaSE-G1 employs continuous representations from WavLM as input and predicts speech tokens from X-Codec2, maximizing acoustic preservation. Second, to promote generalization capability, LLaSE-G1 introduces dual-channel inputs and outputs, unifying multiple SE tasks without requiring task-specific IDs. Third, LLaSE-G1 outperforms prior task-specific discriminative and generative SE models, demonstrating scaling effects at test time and emerging capabilities for unseen SE tasks. Additionally, we release our code and models to support further research in this area",
    "checked": true,
    "id": "a009eabce7b38a17ebd129c0b7e044d1549d8670",
    "semantic_title": "llase-g1: incentivizing generalization capability for llama-based speech enhancement",
    "citation_count": 3,
    "authors": [
      "Boyi Kang",
      "Xinfa Zhu",
      "Zihan Zhang",
      "Zhen Ye",
      "Mingshuai Liu",
      "Ziqian Wang",
      "Yike Zhu",
      "Guobin Ma",
      "Jun Chen",
      "Longshuai Xiao",
      "Chao Weng",
      "Wei Xue",
      "Lei Xie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.652": {
    "title": "MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference",
    "volume": "long",
    "abstract": "This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting in significant disparities in modality importance across attention heads. Traditional KV cache eviction methods, which are tailored for unimodal settings, fail to capture modality-specific information, thereby yielding suboptimal performance. MadaKV addresses these challenges through two key components: modality preference adaptation and hierarchical compression compensation. By dynamically sensing modality information within attention heads and adaptively retaining critical tokens, MadaKV achieves substantial reductions in KV cache memory footprint and model inference decoding latency (1.3 to 1.5 times improvement) while maintaining high accuracy across various multimodal long-context tasks. Extensive experiments on representative MLLMs and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to existing KV cache eviction methods",
    "checked": true,
    "id": "9397ae3adf9970af9ff0bdcacb9f86aad417c264",
    "semantic_title": "madakv: adaptive modality-perception kv cache eviction for efficient multimodal long-context inference",
    "citation_count": 0,
    "authors": [
      "Kunxi Li",
      "Zhonghua Jiang",
      "Zhouzhou Shen",
      "ZhaodeWang ZhaodeWang",
      "Chengfei Lv",
      "Shengyu Zhang",
      "Fan Wu",
      "Fei Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.653": {
    "title": "Efficient OpAmp Adaptation for Zoom Attention to Golden Contexts",
    "volume": "long",
    "abstract": "Large language models (LLMs) have shown significant promise in question-answering (QA) tasks, particularly in retrieval-augmented generation (RAG) scenarios and long-context applications. However, their performance is hindered by noisy reference documents, which often distract from essential information. Despite fine-tuning efforts, Transformer-based architectures struggle to prioritize relevant content. This is evidenced by their tendency to allocate disproportionate attention to irrelevant or later-positioned documents. Recent work proposes the differential attention mechanism to address this issue, but this mechanism is limited by an unsuitable common-mode rejection ratio (CMRR) and high computational costs. Inspired by the operational amplifier (OpAmp), we propose the OpAmp adaptation to address these challenges, which is implemented with adapters efficiently. By integrating the adapter into pre-trained Transformer blocks, our approach enhances focus on the golden context without costly training from scratch. Empirical evaluations on noisy-context benchmarks reveal that our Qwen2.5-OpAmp-72B model, trained with our OpAmp adaptation, surpasses the performance of state-of-the-art LLMs, including DeepSeek-V3 and GPT-4o.Our code is available at https://github.com/wuhy68/OpampAdapter",
    "checked": true,
    "id": "02626daa83b59ad1f811b61e99a5cd6a41525dc2",
    "semantic_title": "efficient opamp adaptation for zoom attention to golden contexts",
    "citation_count": 1,
    "authors": [
      "Haoyuan Wu",
      "Rui Ming",
      "Haisheng Zheng",
      "Zhuolun He",
      "Bei Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.654": {
    "title": "Language-Codec: Bridging Discrete Codec Representations and Speech Language Models",
    "volume": "long",
    "abstract": "In recent years, large language models have achieved significant success in generative tasks (e.g., speech cloning and audio generation) related to speech, audio, music, and other signal domains. A crucial element of these models is the discrete acoustic codecs, which serve as an intermediate representation replacing the mel-spectrogram. However, there exist several gaps between discrete codecs and downstream speech language models. Specifically, 1) Due to the reconstruction paradigm of the Codec model and the structure of residual vector quantization, the initial channel of the codebooks contains excessive information, making it challenging to directly generate acoustic tokens from weakly supervised signals such as text in downstream tasks. 2) Achieving good reconstruction performance requires the utilization of numerous codebooks, which increases the burden on downstream speech language models. Consequently, leveraging the characteristics of speech language models, we propose Language-Codec. In the Language-Codec, we introduce a Masked Channel Residual Vector Quantization (MCRVQ) mechanism along with improved fourier transform structures, refined discriminator design to address the aforementioned gaps. We compare our method with competing audio compression algorithms and observe significant outperformance across extensive evaluations. Furthermore, we also validate the efficiency of the Language-Codec on downstream speech language models. The source code and pretrained models will be open-sourced after the paper is accepted. Codes are available at https://github.com/jishengpeng/Languagecodec",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengpeng Ji",
      "Minghui Fang",
      "Jialong Zuo",
      "Ziyue Jiang",
      "Dingdong Wang",
      "Hanting Wang",
      "Hai Huang",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.655": {
    "title": "Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger",
    "volume": "long",
    "abstract": "Large language models (LLMs) have shown remarkable emergent capabilities, transforming the execution of functional tasks by leveraging external tools for complex problems that require specialized processing or up-to-date data. While existing research expands LLMs access to diverse tools (e.g., program interpreters, search engines, calculators), the necessity of using these tools is often overlooked, leading to indiscriminate tool invocation. This naive approach raises two key issues: increased latency due to unnecessary tool calls, and potential errors resulting from faulty interactions with external tools. In this paper, we introduce meta-cognition as a proxy for LLMs self-assessment of their capabilities, reflecting the model's awareness of its own limitations. Based on this, we propose MeCo, an adaptive decision-making strategy for external tool use. MeCo quantifies metacognitive scores by capturing high-level cognitive signals in the representation space, guiding when to invoke tools. Notably, MeCo is fine-tuning-free and incurs minimal cost. Experiments across multiple backbone models and benchmarks show that MeCo reliably detects LLMs' internal cognitive signals and significantly improves tool-use decision-making",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjun Li",
      "Dexun Li",
      "Kuicai Dong",
      "Cong Zhang",
      "Hao Zhang",
      "Weiwen Liu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.656": {
    "title": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark",
    "volume": "long",
    "abstract": "Multiple-choice question (MCQ) datasets like Massive Multitask Language Understanding (MMLU) are widely used to evaluate the commonsense, understanding, and problem-solving abilities of large language models (LLMs). However, the open-source nature of these benchmarks and the broad sources of training data for LLMs have inevitably led to benchmark contamination, resulting in unreliable evaluation. To alleviate this issue, we propose the contamination-free MCQ benchmark called MMLU-CF, which reassesses LLMs' understanding of world knowledge by averting both unintentional and malicious data contamination. To mitigate unintentional data contamination, we source questions from a broader domain of over 200 billion webpages and apply three specifically designed decontamination rules. To prevent malicious data contamination, we divide the benchmark into validation and test sets with similar difficulty and subject distributions. The test set remains closed-source to ensure reliable results, while the validation set is publicly available to promote transparency and facilitate independent evaluation. The performance gap between these two sets of LLMs will indicate the contamination degree on the validation set in the future. We evaluated over 40 mainstream LLMs on the MMLU-CF. Compared to the original MMLU, not only LLMs' performances significantly dropped but also the performance rankings of them changed considerably. This indicates the effectiveness of our approach in establishing a contamination-free and fairer evaluation standard",
    "checked": true,
    "id": "04b821d427d57671ac88b11d829b31110959d37a",
    "semantic_title": "mmlu-cf: a contamination-free multi-task language understanding benchmark",
    "citation_count": 7,
    "authors": [
      "Qihao Zhao",
      "Yangyu Huang",
      "Tengchao Lv",
      "Lei Cui",
      "Qinzheng Sun",
      "Shaoguang Mao",
      "Xin Zhang",
      "Ying Xin",
      "Qiufeng Yin",
      "Scarlett Li",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.657": {
    "title": "Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding",
    "volume": "long",
    "abstract": "As large language models (LLMs) have advanced rapidly, concerns regarding their safety have become prominent. In this paper, we discover that code-switching in red-teaming queries can effectively elicit undesirable behaviors of LLMs, which are common practices in natural language. We introduce a simple yet effective framework, CSRT, to synthesize code-switching red-teaming queries and investigate the safety and multilingual understanding of LLMs comprehensively. Through extensive experiments with ten state-of-the-art LLMs and code-switching queries combining up to 10 languages, we demonstrate that the CSRT significantly outperforms existing multilingual red-teaming techniques, achieving 46.7% more attacks than standard attacks in English and being effective in conventional safety domains. We also examine the multilingual ability of those LLMs to generate and understand code-switching texts. Additionally, we validate the extensibility of the CSRT by generating code-switching attack prompts with monolingual data. We finally conduct detailed ablation studies exploring code-switching and propound unintended correlation between resource availability of languages and safety alignment in existing multilingual LLMs",
    "checked": true,
    "id": "a1571f393cc6c1baacf502afbd2d655476300137",
    "semantic_title": "code-switching red-teaming: llm evaluation for safety and multilingual understanding",
    "citation_count": 8,
    "authors": [
      "Haneul Yoo",
      "Yongjin Yang",
      "Hwaran Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.658": {
    "title": "Unleashing LLM Reasoning Capability via Scalable Question Synthesis from Scratch",
    "volume": "long",
    "abstract": "Improving the mathematical reasoning capabilities of Large Language Models (LLMs) is critical for advancing artificial intelligence. However, access to extensive, diverse, and high-quality reasoning datasets remains a significant challenge, particularly for the open-source community. In this paper, we propose ScaleQuest, a novel, scalable, and cost-effective data synthesis method that enables the generation of large-scale mathematical reasoning datasets using lightweight 7B-scale models. ScaleQuest introduces a two-stage question-tuning process comprising Question Fine-Tuning (QFT) and Question Preference Optimization (QPO) to unlock the question generation capabilities of problem-solving models. By generating diverse questions from scratch – without relying on powerful proprietary models or seed data – we produce a dataset of 1 million problem-solution pairs. Our experiments demonstrate that models trained on our data outperform existing open-source datasets in both in-domain and out-of-domain evaluations. Furthermore, our approach shows continued performance improvement as the volume of training data increases, highlighting its potential for ongoing data scaling. The extensive improvements observed in code reasoning tasks demonstrate the generalization capabilities of our proposed method. Our work provides the open-source community with a practical solution to enhance the mathematical reasoning abilities of LLMs",
    "checked": true,
    "id": "8d33279c1ec2ac019ac7f4df9778c0ac7e3339b8",
    "semantic_title": "unleashing llm reasoning capability via scalable question synthesis from scratch",
    "citation_count": 8,
    "authors": [
      "Yuyang Ding",
      "Xinyu Shi",
      "Xiaobo Liang",
      "Juntao Li",
      "Zhaopeng Tu",
      "Qiaoming Zhu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.659": {
    "title": "DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing",
    "volume": "long",
    "abstract": "Automated essay scoring (AES) is a useful tool in English as a Foreign Language (EFL) writing education, offering real-time essay scores for students and instructors. However, previous AES models were trained on essays and scores irrelevant to the practical scenarios of EFL writing education and usually provided a single holistic score due to the lack of appropriate datasets. In this paper, we release DREsS, a large-scale, standard dataset for rubric-based automated essay scoring with 48.9K samples in total. DREsS comprises three sub-datasets: DREsS_New, DREsS_Std., and DREsS_CASE. We collect DREsS_New, a real-classroom dataset with 2.3K essays authored by EFL undergraduate students and scored by English education experts. We also standardize existing rubric-based essay scoring datasets as DREsS_Std. We suggest CASE, a corruption-based augmentation strategy for essays, which generates 40.1K synthetic samples of DREsS_CASE and improves the baseline results by 45.44%. DREsS will enable further research to provide a more accurate and practical AES system for EFL writing education",
    "checked": true,
    "id": "99eec76a1d90c7deaf49112e7853112a9f5c061a",
    "semantic_title": "dress: dataset for rubric-based essay scoring on efl writing",
    "citation_count": 4,
    "authors": [
      "Haneul Yoo",
      "Jieun Han",
      "So-Yeon Ahn",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.660": {
    "title": "PQR: Improving Dense Retrieval via Potential Query Modeling",
    "volume": "long",
    "abstract": "Dense retrieval has now become the mainstream paradigm in information retrieval. The core idea of dense retrieval is to align document embeddings with their corresponding query embeddings by maximizing their dot product. The current training data is quite sparse, with each document typically associated with only one or a few labeled queries. However, a single document can be retrieved by multiple different queries. Aligning a document with just one or a limited number of labeled queries results in a loss of its semantic information. In this paper, we propose a training-free Potential Query Retrieval (PQR) framework to address this issue. Specifically, we use a Gaussian mixture distribution to model all potential queries for a document, aiming to capture its comprehensive semantic information. To obtain this distribution, we introduce three sampling strategies to sample a large number of potential queries for each document and encode them into a semantic space. Using these sampled queries, we employ the Expectation-Maximization algorithm to estimate parameters of the distribution. Finally, we also propose a method to calculate similarity scores between user queries and documents under the PQR framework. Extensive experiments demonstrate the effectiveness of the proposed method",
    "checked": true,
    "id": "63674ac4e1e3123371fe38e37cc515665c45d1f8",
    "semantic_title": "pqr: improving dense retrieval via potential query modeling",
    "citation_count": 0,
    "authors": [
      "Junfeng Kang",
      "Rui Li",
      "Qi Liu",
      "Yanjiang Chen",
      "Zheng Zhang",
      "Junzhe Jiang",
      "Heng Yu",
      "Yu Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.661": {
    "title": "Cross-Lingual Generalization and Compression: From Language-Specific to Shared Neurons",
    "volume": "long",
    "abstract": "Multilingual language models (MLLMs) have demonstrated remarkable abilities to transfer knowledge across languages, despite being trained without explicit cross-lingual supervision. We analyze the parameter spaces of three MLLMs to study how their representations evolve during pre-training, observing patterns consistent with compression: models initially form language-specific representations, which gradually converge into cross-lingual abstractions as training progresses. Through probing experiments, we observe a clear transition from uniform language identification capabilities across layers to more specialized layer functions. For deeper analysis, we focus on neurons that encode distinct semantic concepts. By tracing their development during pre-training, we show how they gradually align across languages. Notably, we identify specific neurons that emerge as increasingly reliable predictors for the same concepts across languages. This alignment manifests concretely in generation: once an MLLM exhibits cross-lingual generalization according to our measures, we can select concept-specific neurons identified from, e.g., Spanish text and manipulate them to guide token predictions. Remarkably, rather than generating Spanish text, the model produces semantically coherent English text. This demonstrates that cross-lingually aligned neurons encode generalized semantic representations, independent of the original language encoding",
    "checked": true,
    "id": "69912c5879ea381bd97298fe0baf8b59c0017c2d",
    "semantic_title": "cross-lingual generalization and compression: from language-specific to shared neurons",
    "citation_count": 0,
    "authors": [
      "Frederick Riemenschneider",
      "Anette Frank"
    ]
  },
  "https://aclanthology.org/2025.acl-long.662": {
    "title": "SDBench: A Survey-based Domain-specific LLM Benchmarking and Optimization Framework",
    "volume": "long",
    "abstract": "The rapid advancement of large language models (LLMs) in recent years has made it feasible to establish domain-specific LLMs for specialized fields. However, in practical development, acquiring domain-specific knowledge often requires a significant amount of professional expert manpower. Moreover, even when domain-specific data is available, the lack of a unified methodology for benchmark dataset establishment often results in uneven data distribution. This imbalance can lead to an inaccurate assessment of the true model capabilities during the evaluation of domain-specific LLMs. To address these challenges, we introduce **SDBench**, a generic framework for generating evaluation datasets for domain-specific LLMs. This method is also applicable for establishing the LLM instruction datasets. It significantly reduces the reliance on expert manpower while ensuring that the collected data is uniformly distributed. To validate the effectiveness of this framework, we also present the **BridgeBench**, a novel benchmark for bridge engineering knowledge, and the **BridgeGPT**, the first LLM specialized in bridge engineering, which can solve bridge engineering tasks",
    "checked": true,
    "id": "4b9adca59c087124e3b65558ec8d2ebaddf2244a",
    "semantic_title": "sdbench: a survey-based domain-specific llm benchmarking and optimization framework",
    "citation_count": 0,
    "authors": [
      "Cheng Guo",
      "Hu Kai",
      "Shuxian Liang",
      "Yiyang Jiang",
      "Yi Gao",
      "Xian-Sheng Hua",
      "Wei Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.663": {
    "title": "ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown promising potential in the medical domain, assisting with tasks like clinical note generation and patient communication. However, current LLMs are limited to text-based communication, hindering their ability to interact with diverse forms of information in clinical environments. Despite clinical agents succeeding in diverse signal interaction, they are oriented to a single clinical scenario and hence fail for broader applications. To evaluate clinical agents holistically, we propose ClinicalAgent Bench (CAB), a comprehensive medical agent benchmark consisting of 18 tasks across five key realistic clinical dimensions. Building on this, we introduce ReflectTool, a novel framework that excels at utilizing domain-specific tools within two stages. The first optimization stage progressively enlarges a long-term memory by saving successful solving processes and tool-wise experience of agents in a tiny pre-defined training set. In the following inference stage, ReflectTool can search for supportive successful demonstrations from already built long-term memory to guide the tool selection strategy, and a verifier improves the tool usage according to the tool-wise experience with two verification methods–iterative refinement and candidate selection. Extensive experiments on CAB demonstrate that ReflectTool surpasses the pure LLMs with more than 10 points and the well-established agent-based methods with 3 points, highlighting its adaptability and effectiveness in solving complex clinical tasks. Our code and datasets are available at https://github.com/BlueZeros/ReflecTool",
    "checked": true,
    "id": "0bca82b4ee15074007407aceb0020f067373b0c1",
    "semantic_title": "reflectool: towards reflection-aware tool-augmented clinical agents",
    "citation_count": 0,
    "authors": [
      "Yusheng Liao",
      "Shuyang Jiang",
      "Yanfeng Wang",
      "Yu Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.664": {
    "title": "Lexical Recall or Logical Reasoning: Probing the Limits of Reasoning Abilities in Large Language Models",
    "volume": "long",
    "abstract": "Despite the increasing interest in the reasoning abilities of Large Language Models (LLMs), existing work shows limitations in assessing logic abilities independently from lexical memory. We address this gap with Mystery-Zebra. This robust two-part benchmark (4,290 puzzles) challenges the logic abstraction abilities of LLMs in two setups: (1) a lexical obfuscation setup tests the dependence of LLMs on lexical content based on two canonical grid puzzles widely spread on the Internet; (2) a set of new grid puzzles in 42 different sizes and 12 difficulty levels tests how the formal difficulty degree of a puzzle affects LLMs.We test open and closed-weight LLMs on both parts of the benchmark. The results on part two suggest that model sizes up to 70B parameters have only a minor influence when solving newly generated puzzles, while performance mainly relates to the number of items in the puzzle. The results on the first part of the benchmark suggest that the applied obfuscation strategies help to mitigate effects of logic puzzles being part of LLM training data, showing a drastic drop in performance for obfuscated versions of well-known puzzles. In addition we conduct a case-study on the first part of the benchmark predicting the position of single items, unveiling that the reasoning abilities of LLMs are mainly limited to a few consecutive steps of reasoning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Henrike Beyer",
      "Chris Reed"
    ]
  },
  "https://aclanthology.org/2025.acl-long.665": {
    "title": "ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains",
    "volume": "long",
    "abstract": "Current knowledge editing methods for large language models (LLMs) struggle to maintain logical consistency when propagating ripple effects to associated facts. We propose ChainEdit, a framework that synergizes knowledge graph-derived logical rules with LLM logical reasoning capabilities to enable systematic chain updates. By automatically extracting logical patterns from structured knowledge bases and aligning them with LLMs' internal logics, ChainEdit dynamically generates and edits logically connected knowledge clusters. Experiments demonstrate an improvement of more than 30% in logical generalization over baselines while preserving editing reliability and specificity. We further address evaluation biases in existing benchmarks through knowledge-aware protocols that disentangle external dependencies. This work establishes new state-of-the-art performance on ripple effect while ensuring internal logical consistency after knowledge editing",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zilu Dong",
      "Xiangqing Shen",
      "Zinong Yang",
      "Rui Xia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.666": {
    "title": "HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model",
    "volume": "long",
    "abstract": "Instruction tuning is widely used to enhance a pre-trained Multimodal Large Language Model (MLLM) to understand and follow human instructions by training it on a curated set of task-specific dataset. However, it is infeasible to collect all possible instruction datasets simultaneously in real-world scenarios. Thus, enabling MLLM with continual instruction tuning is essential for maintaining their adaptability. However, existing methods often trade off memory efficiency for performance gains, significantly compromising overall efficiency. In this paper, we propose a task-specific expansion and task-general fusion framework based on the variations in Centered Kernel Alignment (CKA) similarity across different model layers when trained on diverse datasets. Furthermore, we analyze the information leakage present in the existing benchmark and propose a new and more challenging benchmark to rationally evaluate the performance of different methods. Comprehensive experiments showcase a significant performance improvement of our method compared to existing state-of-the-art methods. Our code will be public available",
    "checked": true,
    "id": "9bf4ab9557821c7b1f554164f17dde3f1d2625d4",
    "semantic_title": "hide-llava: hierarchical decoupling for continual instruction tuning of multimodal large language model",
    "citation_count": 3,
    "authors": [
      "Haiyang Guo",
      "Fanhu Zeng",
      "Ziwei Xiang",
      "Fei Zhu",
      "Da-Han Wang",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.667": {
    "title": "Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models",
    "volume": "long",
    "abstract": "Due to the presence of the natural gap between Knowledge Graph (KG) structures and the natural language, the effective integration of holistic structural information of KGs with Large Language Models (LLMs) has emerged as a significant question. To this end, we propose a two-stage framework to learn and apply quantized codes for each entity, aiming for the seamless integration of KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR) method is proposed to compress both KG structural and semantic knowledge into discrete codes (i.e., tokens) that align the format of language sentences. We further design KG instruction-following data by viewing these learned codes as features to directly input to LLMs, thereby achieving seamless integration. The experiment results demonstrate that SSQR outperforms existing unsupervised quantized methods, producing more distinguishable codes. Moreover, the fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link prediction and triple classification tasks, utilizing only 16 tokens per entity instead of thousands in conventional prompting methods",
    "checked": true,
    "id": "72eaea16f4a30247ab7f1a48be16e0559227f091",
    "semantic_title": "self-supervised quantized representation for seamlessly integrating knowledge graphs with large language models",
    "citation_count": 4,
    "authors": [
      "Qika Lin",
      "Tianzhe Zhao",
      "Kai He",
      "Zhen Peng",
      "Fangzhi Xu",
      "Ling Huang",
      "Jingying Ma",
      "Mengling Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.668": {
    "title": "Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking",
    "volume": "long",
    "abstract": "Chain-of-thought (CoT) significantly enhances the performance of large language models (LLMs) across a wide range of tasks, and prior research shows that CoT can theoretically increase expressiveness. However, there is limited mechanistic understanding of the algorithms that Transformer+CoT can learn. Our key contributions are: (1) We evaluate the state tracking capabilities of Transformer+CoT and its variants, confirming the effectiveness of CoT. (2) Next, we identify the circuit (a subset of model components, responsible for tracking the world state), indicating that late-layer MLP neurons play a key role. We propose two metrics, compression and distinction, and show that the neuron sets for each state achieve nearly 100% accuracy, providing evidence of an implicit finite state automaton (FSA) embedded within the model. (3) Additionally, we explore three challenging settings: skipping intermediate steps, introducing data noises, and testing length generalization. Our results demonstrate that Transformer+CoT learns robust algorithms (FSAs), highlighting its resilience in challenging scenarios. Our code is available at https://github.com/IvanChangPKU/FSA",
    "checked": true,
    "id": "5fccf3f0491d1a85a3423e60a39035fffbe8d919",
    "semantic_title": "finite state automata inside transformers with chain-of-thought: a mechanistic study on state tracking",
    "citation_count": 2,
    "authors": [
      "Yifan Zhang",
      "Wenyu Du",
      "Dongming Jin",
      "Jie Fu",
      "Zhi Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.669": {
    "title": "TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition",
    "volume": "long",
    "abstract": "While Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation (LoRA) effectively address resource constraints during fine-tuning, their performance often falls short, especially in multidimensional task scenarios. To address this issue, one straightforward solution is to introduce task-specific LoRA as domain experts, leveraging the modeling of multiple capabilities of experts and thus enhancing the general capability of multi-task learning.Although promising, these additional components often add complexity to the training and inference process, contravening the efficiency that PEFT is designed to deliver. Considering this, we introduce an innovative PEFT method, **TeamLoRA**, consisting of a collaboration and competition module for LoRA experts, thus achieving the right balance of effectiveness and efficiency:**(i)** For *collaboration*, we introduce a novel knowledge sharing and organization mechanism designed to optimize hierarchical learning while enhancing the efficiency of model training and inference.**(ii)** For *competition*, we propose leveraging a game-theoretic interaction mechanism for experts, encouraging experts to transfer their domain-specific knowledge while facing diverse downstream tasks, thus enhancing the performance.By doing so, TeamLoRA elegantly connects the experts as a \"*Team*\" with internal collaboration and competition, enabling a faster and more accurate PEFT paradigm. Meanwhile, we curate a **Comprehensive Multi-Task Evaluation (CME)** benchmark to thoroughly assess the capability of multi-task learning. Experiments conducted on our CME and other benchmarks indicate the effectiveness and efficiency of TeamLoRA. Our project is available at https://github.com/DCDmllm/TeamLoRA",
    "checked": true,
    "id": "e36783eb6f6681398e79e3d8ea35bb317b985aba",
    "semantic_title": "teamlora: boosting low-rank adaptation with expert collaboration and competition",
    "citation_count": 0,
    "authors": [
      "Tianwei Lin",
      "Jiang Liu",
      "Wenqiao Zhang",
      "Yang Dai",
      "Haoyuan Li",
      "Zhelun Yu",
      "Wanggui He",
      "Juncheng Li",
      "Jiannan Guo",
      "Hao Jiang",
      "Siliang Tang",
      "Yueting Zhuang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.670": {
    "title": "CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models",
    "volume": "long",
    "abstract": "Large language models (LLMs) are possessed of numerous beneficial capabilities, yet their potential inclination harbors unpredictable risks that may materialize in the future. We hence propose CRiskEval, a Chinese dataset meticulously designed for gauging the risk proclivities inherent in LLMs such as resource acquisition and malicious coordination, as part of efforts for proactive preparedness. To curate CRiskEval, we define a new risk taxonomy with 7 types of frontier risks and 4 safety levels, including extremely hazardous,moderately hazardous, neutral and safe. We follow the philosophy of tendency evaluation to empirically measure the stated \"desire\" of LLMs via fine-grained multiple-choice question answering. The dataset consists of 14,888 questions that simulate scenarios related to predefined 7 types of frontier risks. Each question is accompanied with 4 answer choices that state opinions or behavioral tendencies corresponding to the question. All answer choices are manually annotated with one of the defined risk levels so that we can easily build a fine-grained frontier risk profile for each assessed LLM. Extensive evaluation with CRiskEval on a spectrum of prevalent Chinese LLMs has unveiled a striking revelation: most models exhibit risk tendencies of more than 40% (weighted tendency to the four risk levels). Furthermore, a subtle increase in the model's inclination toward urgent self-sustainability, power seeking and other dangerous goals becomes evident as the size of models increases. To promote further research on the frontier risk evaluation of LLMs, we publicly release our dataset at https://github.com/tjunlp-lab/CRiskEval",
    "checked": true,
    "id": "1367dfa59d2de180076de7f19c5feb03daa477cf",
    "semantic_title": "criskeval: a chinese multi-level risk evaluation benchmark dataset for large language models",
    "citation_count": 2,
    "authors": [
      "Ling Shi",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.671": {
    "title": "STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning",
    "volume": "long",
    "abstract": "Mixture-of-experts (MoEs) have been adopted for reducing inference costs by sparsely activating experts in large language models (LLMs). Despite these reductions, the massive number of parameters in MoEs still makes them expensive to serve. Conventionally, unstructured or structured pruning has been considered to reduce number of parameters. Our key contribution is exploring the interpolation between structured and unstructured pruning, to propose a novel structured-then-unstructured (STUN) approach outperforming both of structured or unstructured pruning, especially for MoEs. In the first stage, we show a scalable expert pruning with O(1) forward pass, unlike existing work requiring O(kn⁄√n) forward passes for n experts that cannot scale for recent MoEs with hundreds of experts. We then show our expert-pruned MoEs are robust to unstructured pruning to follow. Experiments on Snowflake Arctic and Mixtral shows that our proposal is highly effective– For Snowflake Arctic, a 480B-sized MoE with 128 experts, our method needs only one H100 and two hours to achieve nearly no loss in performance with 40% sparsity, even in generative tasks such as GSM8K, where state-of-the-art structured or unstructured pruning methods fail. The code is publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeseong Lee",
      "Seung-won Hwang",
      "Aurick Qiao",
      "Daniel F Campos",
      "Zhewei Yao",
      "Yuxiong He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.672": {
    "title": "Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System",
    "volume": "long",
    "abstract": "Information theft attacks pose a significant risk to Large Language Model (LLM) tool-learning systems. Adversaries can inject malicious commands through compromised tools, manipulating LLMs to send sensitive information to these tools, which leads to potential privacy breaches. However, existing attack approaches are black-box oriented and rely on static commands that cannot adapt flexibly to the changes in user queries and the invocation chain of tools. It makes malicious commands more likely to be detected by LLM and leads to attack failure. In this paper, we propose AutoCMD, a dynamic attack comment generation approach for information theft attacks in LLM tool-learning systems. Inspired by the concept of mimicking the familiar, AutoCMD is capable of inferring the information utilized by upstream tools in the toolchain through learning on open-source systems and reinforcement with target system examples, thereby generating more targeted commands for information theft. The evaluation results show that AutoCMD outperforms the baselines with +13.2% ASRTheft, and can be generalized to new tool-learning systems to expose their information leakage risks. We also design four defense methods to effectively protect tool-learning systems from the attack",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyou Jiang",
      "Mingyang Li",
      "Guowei Yang",
      "Junjie Wang",
      "Yuekai Huang",
      "Zhiyuan Chang",
      "Qing Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.673": {
    "title": "FlashAudio: Rectified Flow for Fast and High-Fidelity Text-to-Audio Generation",
    "volume": "long",
    "abstract": "Recent advancements in latent diffusion models (LDMs) have markedly enhanced text-to-audio generation, yet their iterative sampling processes impose substantial computational demands, limiting practical deployment. While recent methods utilizing consistency-based distillation aim to achieve few-step or single-step inference, their one-step performance is constrained by curved trajectories, preventing them from surpassing traditional diffusion models. In this work, we introduce FlashAudio with rectified flows to learn straight flow for fast simulation. To alleviate the inefficient timesteps allocation and suboptimal distribution of noise, FlashAudio optimizes the time distribution of rectified flow with Bifocal Samplers and proposes immiscible flow to minimize the total distance of data-noise pairs in a batch vias assignment. Furthermore, to address the amplified accumulation error caused by the classifier-free guidance (CFG), we propose Anchored Optimization, which refines the guidance scale by anchoring it to a reference trajectory. Experimental results on text-to-audio generation demonstrate that FlashAudio's one-step generation performance surpasses the diffusion-based models with hundreds of sampling steps on audio quality and enables a sampling speed of 400x faster than real-time on a single NVIDIA 4090Ti GPU. Code will be available at https://github.com/liuhuadai/FlashAudio. Audio Samples are available at https://FlashAudio-TTA.github.io/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huadai Liu",
      "Jialei Wang",
      "Rongjie Huang",
      "Yang Liu",
      "Heng Lu",
      "Zhou Zhao",
      "Wei Xue"
    ]
  },
  "https://aclanthology.org/2025.acl-long.674": {
    "title": "How does Misinformation Affect Large Language Model Behaviors and Preferences?",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in knowledge-intensive tasks, while they remain vulnerable when encountering misinformation. Existing studies have explored the role of LLMs in combating misinformation, but there is still a lack of fine-grained analysis on the specific aspects and extent to which LLMs are influenced by misinformation. To bridge this gap, we present MisBench, the current largest and most comprehensive benchmark for evaluating LLMs' behavior and knowledge preference toward misinformation. MisBench consists of 10,346,712 pieces of misinformation, which uniquely considers both knowledge-based conflicts and stylistic variations in misinformation. Empirical results reveal that while LLMs demonstrate comparable abilities in discerning misinformation, they still remain susceptible to knowledge conflicts and stylistic variations. Based on these findings, we further propose a novel approach called Reconstruct to Discriminate (RtD) to strengthen LLMs' ability to detect misinformation. Our study provides valuable insights into LLMs' interactions with misinformation, and we believe MisBench can serve as an effective benchmark for evaluating LLM-based detectors and enhancing their reliability in real-world applications. Codes and data are available at: https://github.com/GKNL/MisBench",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Peng",
      "Nuo Chen",
      "Jianheng Tang",
      "Jia Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.675": {
    "title": "YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering",
    "volume": "long",
    "abstract": "Large Language Models (LLMs) drive scientific question-answering on modern search engines, yet their evaluation robustness remains underexplored. We introduce YESciEval, an open-source framework that combines fine-grained rubric-based assessment with reinforcement learning to mitigate optimism bias in LLM evaluators. We release multidisciplinary scienceQ&A datasets, including adversarial variants, with evaluation scores from multiple LLMs. Independent of proprietary models and human feedback, our approach enables scalable, cost-free evaluation. By advancing reliable LLM-as-a-judge models, this work supports AI alignment and fosters robust, transparent evaluation essential for scientific inquiry",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jennifer D’Souza",
      "Hamed Babaei Giglou",
      "Quentin Münch"
    ]
  },
  "https://aclanthology.org/2025.acl-long.676": {
    "title": "GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding",
    "volume": "long",
    "abstract": "Programming languages possess rich semantic information - such as data flow - that is represented by graphs and not available from the surface form of source code. Recent code language models have scaled to billions of parameters, but model source code solely as text tokens while ignoring any other structural information. Conversely, models that do encode structural information of code make modifications to the Transformer architecture, limiting their scale and compatibility with pretrained LLMs. In this work, we take the best of both worlds with GALLa - Graph Aligned Large Language Models. GALLa utilizes graph neural networks and cross-modal alignment technologies to inject the structural information of code into LLMs as an auxiliary task during finetuning. This framework is both model-agnostic and task-agnostic, as it can be applied to any code LLM for any code downstream task, and requires the structural graph data only at training time from a corpus unrelated to the finetuning data, while incurring no cost at inference time over the baseline LLM. Experiments on five code tasks with six different baseline LLMs ranging in size from 350M to 14B validate the effectiveness of GALLa, demonstrating consistent improvement over the baseline, even for powerful models such as LLaMA3 and Qwen2.5-Coder",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyin Zhang",
      "Hang Yu",
      "Sage Lee",
      "Peng Di",
      "Jianguo Li",
      "Rui Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.677": {
    "title": "MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis",
    "volume": "long",
    "abstract": "Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical decision-making, in which physicians iteratively refine a ranked list of possible diseases based on symptoms, antecedents, and medical knowledge. While recent advances in large language models (LLMs) have shown promise in supporting DDx, existing approaches face key limitations, including single-dataset evaluations, isolated optimization of components, unrealistic assumptions about complete patient profiles, and single-attempt diagnosis. We introduce a Modular Explainable DDx Agent (MEDDxAgent) framework designed for interactive DDx, where diagnostic reasoning evolves through iterative learning, rather than assuming a complete patient profile is accessible. MEDDxAgent integrates three modular components: (1) an orchestrator (DDxDriver), (2) a history taking simulator, and (3) two specialized agents for knowledge retrieval and diagnosis strategy. To ensure robust evaluation, we introduce a comprehensive DDx benchmark covering respiratory, skin, and rare diseases. We analyze single-turn diagnostic approaches and demonstrate the importance of iterative refinement when patient profiles are not available at the outset. Our broad evaluation demonstrates that MEDDxAgent achieves over 10% accuracy improvements in interactive DDx across both large and small LLMs, while offering critical explainability into its diagnostic reasoning process",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Philip Rose",
      "Chia-Chien Hung",
      "Marco Lepri",
      "Israa Alqassem",
      "Kiril Gashteovski",
      "Carolin Lawrence"
    ]
  },
  "https://aclanthology.org/2025.acl-long.678": {
    "title": "A Training-free LLM-based Approach to General Chinese Character Error Correction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houquan Zhou",
      "Bo Zhang",
      "Zhenghua Li",
      "Ming Yan",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.679": {
    "title": "HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songtao Jiang",
      "Yan Zhang",
      "Yeying Jin",
      "Zhihang Tang",
      "Yangyang Wu",
      "Yang Feng",
      "Jian Wu",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.680": {
    "title": "MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Guo",
      "Tianyu Zheng",
      "Yizhi Li",
      "Yuelin Bai",
      "Bo Li",
      "Yubo Wang",
      "King Zhu",
      "Graham Neubig",
      "Wenhu Chen",
      "Xiang Yue"
    ]
  },
  "https://aclanthology.org/2025.acl-long.681": {
    "title": "SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prabhat Pandey",
      "Rupak Vignesh Swaminathan",
      "K V Vijay Girish",
      "Arunasish Sen",
      "Jian. Xie",
      "Grant Strimel",
      "Andreas Schwarz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.682": {
    "title": "Recent Advances in Speech Language Models: A Survey",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqian Cui",
      "Dianzhi Yu",
      "Xiaoqi Jiao",
      "Ziqiao Meng",
      "Guangyan Zhang",
      "Qichao Wang",
      "Steven Y. Guo",
      "Irwin King"
    ]
  },
  "https://aclanthology.org/2025.acl-long.683": {
    "title": "LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohit Upadhya",
      "Santosh T.y.s.s"
    ]
  },
  "https://aclanthology.org/2025.acl-long.684": {
    "title": "Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqiang Wang",
      "Yan Xiao",
      "Hao Lin",
      "Yangshijie Zhang",
      "Xiaochun Cao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.685": {
    "title": "SPECTRA: Faster Large Language Model Inference with Optimized Internal and External Speculation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nguyen-Khang Le",
      "Truong Dinh Do",
      "Le-Minh Nguyen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.686": {
    "title": "Multi-level Association Refinement Network for Dialogue Aspect-based Sentiment Quadruple Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeliang Tong",
      "Wei Wei",
      "Xiaoye Qu",
      "Rikui Huang",
      "Zhixin Chen",
      "Xingyu Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.687": {
    "title": "Innovative Image Fraud Detection with Cross-Sample Anomaly Analysis: The Power of LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "QiWen Wang",
      "Junqi Yang",
      "Zhenghao Lin",
      "Zhenzhe Ying",
      "Weiqiang Wang",
      "Chen Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.688": {
    "title": "Cooperative or Competitive? Understanding the Interaction between Attention Heads From A Game Theory Perspective",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoye Qu",
      "Zengqi Yu",
      "Dongrui Liu",
      "Wei Wei",
      "Daizong Liu",
      "Jianfeng Dong",
      "Yu Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.689": {
    "title": "MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linzhuang Sun",
      "Hao Liang",
      "Jingxuan Wei",
      "Bihui Yu",
      "Tianpeng Li",
      "Fan Yang",
      "Zenan Zhou",
      "Wentao Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.690": {
    "title": "Graph-Structured Trajectory Extraction from Travelogues",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aitaro Yamamoto",
      "Hiroyuki Otomo",
      "Hiroki Ouchi",
      "Shohei Higashiyama",
      "Hiroki Teranishi",
      "Hiroyuki Shindo",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.691": {
    "title": "Learning First-Order Logic Rules for Argumentation Mining",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Sun",
      "Guanrong Chen",
      "Hamid Alinejad-Rokny",
      "Jianzhu Bao",
      "Yuqi Huang",
      "Bin Liang",
      "Kam-Fai Wong",
      "Min Yang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.692": {
    "title": "Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiafeng Liang",
      "Shixin Jiang",
      "Xuan Dong",
      "Ning Wang",
      "Zheng Chu",
      "Hui Su",
      "Jinlan Fu",
      "Ming Liu",
      "See-Kiong Ng",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.693": {
    "title": "UniRAG: Unified Query Understanding Method for Retrieval Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Li",
      "Liyang He",
      "Qi Liu",
      "Zheng Zhang",
      "Heng Yu",
      "Yuyang Ye",
      "Linbo Zhu",
      "Yu Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.694": {
    "title": "Contextual Experience Replay for Self-Improvement of Language Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yitao Liu",
      "Chenglei Si",
      "Karthik R Narasimhan",
      "Shunyu Yao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.695": {
    "title": "Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Sun",
      "Pengfei Hong",
      "Tej Deep Pala",
      "Vernon Toh",
      "U-Xuan Tan",
      "Deepanway Ghosal",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2025.acl-long.696": {
    "title": "Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yupei Ren",
      "Xinyi Zhou",
      "Ning Zhang",
      "Shangqing Zhao",
      "Man Lan",
      "Xiaopeng Bai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.697": {
    "title": "Browsing Like Human: A Multimodal Web Agent with Experiential Fast-and-Slow Thinking",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haohao Luo",
      "Jiayi Kuang",
      "Wei Liu",
      "Ying Shen",
      "Jian Luan",
      "Yang Deng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.698": {
    "title": "MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yile Liu",
      "Ziwei Ma",
      "Xiu Jiang",
      "Jinglu Hu",
      "ChangJing ChangJing",
      "Liang Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.699": {
    "title": "Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guijin Son",
      "Jiwoo Hong",
      "Hyunwoo Ko",
      "James Thorne"
    ]
  },
  "https://aclanthology.org/2025.acl-long.700": {
    "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenhao Zhang",
      "Xi Feng",
      "Yuelin Bai",
      "Xeron Du",
      "Jinchang Hou",
      "Kaixin Deng",
      "Guangzeng Han",
      "Qinrui Li",
      "Bingli Wang",
      "Jiaheng Liu",
      "Xingwei Qu",
      "Yifei Zhang",
      "Qixuan Zhao",
      "Yiming Liang",
      "Ziqiang Liu",
      "Feiteng Fang",
      "Min Yang",
      "Wenhao Huang",
      "Chenghua Lin",
      "Ge Zhang",
      "Shiwen Ni"
    ]
  },
  "https://aclanthology.org/2025.acl-long.701": {
    "title": "KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mukhammed Togmanov",
      "Nurdaulet Mukhituly",
      "Diana Turmakhan",
      "Jonibek Mansurov",
      "Maiya Goloburda",
      "Akhmed Sakip",
      "Zhuohan Xie",
      "Yuxia Wang",
      "Bekassyl Syzdykov",
      "Nurkhan Laiyk",
      "Alham Fikri Aji",
      "Ekaterina Kochmar",
      "Preslav Nakov",
      "Fajri Koto"
    ]
  },
  "https://aclanthology.org/2025.acl-long.702": {
    "title": "Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyangsuk Min",
      "Yuho Lee",
      "Minjeong Ban",
      "Jiaqi Deng",
      "Nicole Hee-Yeon Kim",
      "Taewon Yun",
      "Hang Su",
      "Jason Cai",
      "Hwanjun Song"
    ]
  },
  "https://aclanthology.org/2025.acl-long.703": {
    "title": "ClusterAttn: KV Cache Compression under Intrinsic Attention Clustering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minwei Zhang",
      "Haifeng Sun",
      "Jingyu Wang",
      "Shaolong Li",
      "Wanyi Ning",
      "Qi Qi",
      "Zirui Zhuang",
      "Jianxin Liao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.704": {
    "title": "SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunwon Kim",
      "Chanho Park",
      "Buru Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.705": {
    "title": "Incongruity-aware Tension Field Network for Multi-modal Sarcasm Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiecheng Zhang",
      "C.L.Philip Chen",
      "Shuzhen Li",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.706": {
    "title": "Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nurkhan Laiyk",
      "Daniil Orel",
      "Rituraj Joshi",
      "Maiya Goloburda",
      "Yuxia Wang",
      "Preslav Nakov",
      "Fajri Koto"
    ]
  },
  "https://aclanthology.org/2025.acl-long.707": {
    "title": "Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxi Dai",
      "Lin Lu",
      "Pan Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.708": {
    "title": "From Selection to Generation: A Survey of LLM-based Active Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Xia",
      "Subhojyoti Mukherjee",
      "Zhouhang Xie",
      "Junda Wu",
      "Xintong Li",
      "Ryan Aponte",
      "Hanjia Lyu",
      "Joe Barrow",
      "Hongjie Chen",
      "Franck Dernoncourt",
      "Branislav Kveton",
      "Tong Yu",
      "Ruiyi Zhang",
      "Jiuxiang Gu",
      "Nesreen K. Ahmed",
      "Yu Wang",
      "Xiang Chen",
      "Hanieh Deilamsalehy",
      "Sungchul Kim",
      "Zhengmian Hu",
      "Yue Zhao",
      "Nedim Lipka",
      "Seunghyun Yoon",
      "Ting-Hao Kenneth Huang",
      "Zichao Wang",
      "Puneet Mathur",
      "Soumyabrata Pal",
      "Koyel Mukherjee",
      "Zhehao Zhang",
      "Namyong Park",
      "Thien Huu Nguyen",
      "Jiebo Luo",
      "Ryan A. Rossi",
      "Julian McAuley"
    ]
  },
  "https://aclanthology.org/2025.acl-long.709": {
    "title": "OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinglin Zhang",
      "Luyao Cheng",
      "Chong Deng",
      "Qian Chen",
      "Wen Wang",
      "Siqi Zheng",
      "Jiaqing Liu",
      "Hai Yu",
      "Chao-Hong Tan",
      "Zhihao Du",
      "ShiLiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.710": {
    "title": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dohoon Kim",
      "Donghun Kang",
      "Taesup Moon"
    ]
  },
  "https://aclanthology.org/2025.acl-long.711": {
    "title": "EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meidan Ding",
      "Jipeng Zhang",
      "Wenxuan Wang",
      "Haiqin Zhong",
      "Xiaoqin Wang",
      "Xinheng Lyu",
      "Wenting Chen",
      "Linlin Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.712": {
    "title": "CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vignesh Kothapalli",
      "Hamed Firooz",
      "Maziar Sanjabi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.713": {
    "title": "Flexora: Flexible Low-Rank Adaptation for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxing Wei",
      "Yao Shu",
      "Ying Tiffany He",
      "Fei Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.714": {
    "title": "QDTSynth: Quality-Driven Formal Theorem Synthesis for Enhancing Proving Performance of LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Wang",
      "Ruobing Zuo",
      "Gaolei He",
      "Jianlin Wang",
      "Zhengfeng Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.715": {
    "title": "RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Lu",
      "Jiawang Cao",
      "Yongliang Wu",
      "Bozheng Li",
      "Licheng Tang",
      "Yangguang Ji",
      "Chong Wu",
      "Jay Wu",
      "Wenbo Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.716": {
    "title": "QAEval: Mixture of Evaluators for Question-Answering Task Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tan Yue",
      "Rui Mao",
      "Xuzhao Shi",
      "Shuo Zhan",
      "Zuhao Yang",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.717": {
    "title": "Debiasing the Fine-Grained Classification Task in LLMs with Bias-Aware PEFT",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daiying Zhao",
      "Xinyu Yang",
      "Hang Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.718": {
    "title": "Demystifying Small Language Models for Edge Deployment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyan Lu",
      "Xiang Li",
      "Dongqi Cai",
      "Rongjie Yi",
      "Fangming Liu",
      "Wei Liu",
      "Jian Luan",
      "Xiwen Zhang",
      "Nicholas D. Lane",
      "Mengwei Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.719": {
    "title": "Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naibin Gu",
      "Peng Fu",
      "Xiyu Liu",
      "Ke Ma",
      "Zheng Lin",
      "Weiping Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.720": {
    "title": "Can Vision-Language Models Evaluate Handwritten Math?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oikantik Nath",
      "Hanani Bathina",
      "Mohammed Safi Ur Rahman Khan",
      "Mitesh M Khapra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.721": {
    "title": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxu Wang",
      "Yilin Lyu",
      "Zicheng Sun",
      "Liping Jing"
    ]
  },
  "https://aclanthology.org/2025.acl-long.722": {
    "title": "Towards Objective Fine-tuning: How LLMs' Prior Knowledge Causes Potential Poor Calibration?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziming Wang",
      "Zeyu Shi",
      "Haoyi Zhou",
      "Shiqi Gao",
      "Qingyun Sun",
      "Jianxin Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.723": {
    "title": "Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keane Ong",
      "Rui Mao",
      "Deeksha Varshney",
      "Erik Cambria",
      "Gianmarco Mengaldo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.724": {
    "title": "HiddenDetect: Detecting Jailbreak Attacks against Multimodal Large Language Models via Monitoring Hidden States",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilei Jiang",
      "Xinyan Gao",
      "Tianshuo Peng",
      "Yingshui Tan",
      "Xiaoyong Zhu",
      "Bo Zheng",
      "Xiangyu Yue"
    ]
  },
  "https://aclanthology.org/2025.acl-long.725": {
    "title": "SwiLTra-Bench: The Swiss Legal Translation Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joel Niklaus",
      "Jakob Merane",
      "Luka Nenadic",
      "Sina Ahmadi",
      "Yingqiang Gao",
      "Cyrill A. H. Chevalley",
      "Claude Humbel",
      "Christophe Gösken",
      "Lorenzo Tanzi",
      "Thomas Lüthi",
      "Stefan Palombo",
      "Spencer Poff",
      "Boling Yang",
      "Nan Wu",
      "Matthew Guillod",
      "Robin Mamié",
      "Daniel Brunner",
      "Julio Pereyra",
      "Niko Grupen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.726": {
    "title": "Two Intermediate Translations Are Better Than One: Fine-tuning LLMs for Document-level Translation Refinement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Dong",
      "Xinglin Lyu",
      "Junhui Li",
      "Daimeng Wei",
      "Min Zhang",
      "Shimin Tao",
      "Hao Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.727": {
    "title": "Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp Mondorf",
      "Sondre Wold",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2025.acl-long.728": {
    "title": "Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clara Lachenmaier",
      "Judith Sieker",
      "Sina Zarrieß"
    ]
  },
  "https://aclanthology.org/2025.acl-long.729": {
    "title": "GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingjian Chen",
      "Haoran Liu",
      "Yinhong Liu",
      "Jinxiang Xie",
      "Rui Yang",
      "Han Yuan",
      "Yanran Fu",
      "Peng Yuan Zhou",
      "Qingyu Chen",
      "James Caverlee",
      "Irene Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.730": {
    "title": "SCULPT: Systematic Tuning of Long Prompts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanu Kumar",
      "Akhila Yesantarao Venkata",
      "Shubhanshu Khandelwal",
      "Bishal Santra",
      "Parag Agrawal",
      "Manish Gupta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.731": {
    "title": "Crab: A Novel Configurable Role-Playing LLM with Assessing Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai He",
      "Yucheng Huang",
      "Wenqing Wang",
      "Delong Ran",
      "Dongming Sheng",
      "Junxuan Huang",
      "Qika Lin",
      "Jiaxing Xu",
      "Wenqiang Liu",
      "Mengling Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.732": {
    "title": "Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingshui Tan",
      "Boren Zheng",
      "Baihui Zheng",
      "Kerui Cao",
      "Huiyun Jing",
      "Jincheng Wei",
      "Jiaheng Liu",
      "Yancheng He",
      "Wenbo Su",
      "Xiaoyong Zhu",
      "Bo Zheng",
      "Kaifu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.733": {
    "title": "TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaorui Wu",
      "Xiaofeng Mao",
      "Fei Li",
      "Xin Zhang",
      "Xuanhong Li",
      "Chong Teng",
      "Donghong Ji",
      "Zhuang Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.734": {
    "title": "Cross-Lingual Optimization for Language Transfer in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jungseob Lee",
      "Seongtae Hong",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.735": {
    "title": "CART: A Generative Cross-Modal Retrieval Framework With Coarse-To-Fine Semantic Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghui Fang",
      "Shengpeng Ji",
      "Jialong Zuo",
      "Hai Huang",
      "Yan Xia",
      "Jieming Zhu",
      "Xize Cheng",
      "Xiaoda Yang",
      "Wenrui Liu",
      "Gang Wang",
      "Zhenhua Dong",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.736": {
    "title": "MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Yue",
      "Tianyu Zheng",
      "Yuansheng Ni",
      "Yubo Wang",
      "Kai Zhang",
      "Shengbang Tong",
      "Yuxuan Sun",
      "Botao Yu",
      "Ge Zhang",
      "Huan Sun",
      "Yu Su",
      "Wenhu Chen",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2025.acl-long.737": {
    "title": "Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueru Wen",
      "Jie Lou",
      "Zichao Li",
      "Yaojie Lu",
      "XingYu XingYu",
      "Yuqiu Ji",
      "Guohai Xu",
      "Hongyu Lin",
      "Ben He",
      "Xianpei Han",
      "Le Sun",
      "Debing Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.738": {
    "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chak Tou Leong",
      "Qingyu Yin",
      "Jian Wang",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.739": {
    "title": "LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinhe Bi",
      "Yujun Wang",
      "Haokun Chen",
      "Xun Xiao",
      "Artur Hecker",
      "Volker Tresp",
      "Yunpu Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-long.740": {
    "title": "Efficient Long Context Language Model Retrieval with Compression",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minju Seo",
      "Jinheon Baek",
      "Seongyun Lee",
      "Sung Ju Hwang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.741": {
    "title": "Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runxuan Liu",
      "Luobei Luobei",
      "Jiaqi Li",
      "Baoxin Wang",
      "Ming Liu",
      "Dayong Wu",
      "Shijin Wang",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.742": {
    "title": "Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Chen",
      "Yusheng Liao",
      "Shuyang Jiang",
      "Pingjie Wang",
      "YiQiu Guo",
      "Yanfeng Wang",
      "Yu Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.743": {
    "title": "Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Lin",
      "Yinglin Zheng",
      "Ming Zeng",
      "Wangzheng Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.744": {
    "title": "A New Formulation of Zipf's Meaning-Frequency Law through Contextual Diversity",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryo Nagata",
      "Kumiko Tanaka-Ishii"
    ]
  },
  "https://aclanthology.org/2025.acl-long.745": {
    "title": "The Mirage of Model Editing: Revisiting Evaluation in the Wild",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanli Yang",
      "Fei Sun",
      "Jiajun Tan",
      "Xinyu Ma",
      "Qi Cao",
      "Dawei Yin",
      "Huawei Shen",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.746": {
    "title": "LAQuer: Localized Attribution Queries in Content-grounded Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eran Hirsch",
      "Aviv Slobodkin",
      "David Wan",
      "Elias Stengel-Eskin",
      "Mohit Bansal",
      "Ido Dagan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.747": {
    "title": "EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqian Liu",
      "Ke Wang",
      "Yongbin Li",
      "Yuchuan Wu",
      "Wentao Ma",
      "Aobo Kong",
      "Fei Huang",
      "Jianbin Jiao",
      "Junge Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.748": {
    "title": "DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyung Lee",
      "Jin-Seop Lee",
      "Jaehoon Lee",
      "YunSeok Choi",
      "Jee-Hyong Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.749": {
    "title": "PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuhao Guan",
      "Moule Lin",
      "Cheng Xu",
      "Xinyi Liu",
      "Jinman Zhao",
      "Jiexin Fan",
      "Qi Xu",
      "Derek Greene"
    ]
  },
  "https://aclanthology.org/2025.acl-long.750": {
    "title": "Digest the Knowledge: Large Language Models empowered Message Passing for Knowledge Graph Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhong Wan",
      "Tao Yu",
      "Kunyu Jiang",
      "Yao Fu",
      "Weihao Jiang",
      "Jiang Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.751": {
    "title": "RecLM: Recommendation Instruction Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangqin Jiang",
      "Yuhao Yang",
      "Lianghao Xia",
      "Da Luo",
      "Kangyi Lin",
      "Chao Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.752": {
    "title": "DS2-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongling Xu",
      "Yice Zhang",
      "Qianlong Wang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.753": {
    "title": "MISP-Meeting: A Real-World Dataset with Multimodal Cues for Long-form Meeting Transcription and Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "HangChen HangChen",
      "Chao-Han Huck Yang",
      "Jia-Chen Gu",
      "Sabato Marco Siniscalchi",
      "Jun Du"
    ]
  },
  "https://aclanthology.org/2025.acl-long.754": {
    "title": "Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sohan Patnaik",
      "Milan Aggarwal",
      "Sumit Bhatia",
      "Balaji Krishnamurthy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.755": {
    "title": "MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziting Xian",
      "Jiawei Gu",
      "Lingbo Li",
      "Shangsong Liang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.756": {
    "title": "SkillAggregation: Reference-free LLM-Dependent Aggregation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangzhi Sun",
      "Anmol Kagrecha",
      "Potsawee Manakul",
      "Phil Woodland",
      "Mark Gales"
    ]
  },
  "https://aclanthology.org/2025.acl-long.757": {
    "title": "MasRouter: Learning to Route LLMs for Multi-Agent Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanwei Yue",
      "Guibin Zhang",
      "Boyang Liu",
      "Guancheng Wan",
      "Kun Wang",
      "Dawei Cheng",
      "Yiyan Qi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.758": {
    "title": "Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhe Xu",
      "Xiaohua Wang",
      "Changze Lv",
      "Xiaoqing Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.759": {
    "title": "Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiwen Yuan",
      "Yueqi Zhang",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.760": {
    "title": "iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Wang",
      "Yinan Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.761": {
    "title": "IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Song",
      "Zhenya Huang",
      "Cheng Cheng",
      "Weibo Gao",
      "Bihan Xu",
      "GuanHao Zhao",
      "Fei Wang",
      "Runze Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.762": {
    "title": "MLAS-LoRA: Language-Aware Parameters Detection and LoRA-Based Knowledge Transfer for Multilingual Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Dong",
      "Bo Li",
      "Jinsong Liu",
      "Shaolin Zhu",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.763": {
    "title": "M2RC-EVAL: Massively Multilingual Repository-level Code Completion Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaheng Liu",
      "Ken Deng",
      "Congnan Liu",
      "Jian Yang",
      "Shukai Liu",
      "He Zhu",
      "Peng Zhao",
      "Linzheng Chai",
      "Yanan Wu",
      "JinKe JinKe",
      "Ge Zhang",
      "Zekun Moore Wang",
      "Guoan Zhang",
      "Yingshui Tan",
      "Bangyu Xiang",
      "Zhaoxiang Zhang",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.764": {
    "title": "Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Susanna Rücker",
      "Alan Akbik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.765": {
    "title": "How to Compare Things Properly? A Study of Argument Relevance in Comparative Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Irina Nikishina",
      "Saba Anwar",
      "Nikolay Dolgov",
      "Maria Manina",
      "Daria Ignatenko",
      "Artem Shelmanov",
      "Chris Biemann"
    ]
  },
  "https://aclanthology.org/2025.acl-long.766": {
    "title": "FinanceReasoning: Benchmarking Financial Numerical Reasoning More Credible, Comprehensive and Challenging",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichen Tang",
      "Haihong E",
      "Ziyan Ma",
      "Haoyang He",
      "Jiacheng Liu",
      "Zhongjun Yang",
      "Zihua Rong",
      "Rongjin Li",
      "Kun Ji",
      "Qing Huang",
      "Xinyang Hu",
      "Yang Liu",
      "Qianhe Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.767": {
    "title": "Controllable Style Arithmetic with Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiqi Wang",
      "Wengang Zhou",
      "Zongmeng Zhang",
      "Jie Zhao",
      "Houqiang Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.768": {
    "title": "Masks Can be Learned as an Alternative to Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiyu Liu",
      "Tianwen Wei",
      "Bo Zhu",
      "Xin Zhao",
      "Shuicheng Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.769": {
    "title": "Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Wen",
      "Jacqueline Staub",
      "Adish Singla"
    ]
  },
  "https://aclanthology.org/2025.acl-long.770": {
    "title": "Removal of Hallucination on Hallucination: Debate-Augmented RAG",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentao Hu",
      "Wengyu Zhang",
      "Yiyang Jiang",
      "Chen Jason Zhang",
      "Xiaoyong Wei",
      "Li Qing"
    ]
  },
  "https://aclanthology.org/2025.acl-long.771": {
    "title": "CodeDPO: Aligning Code Models with Self Generated and Verified Source Code",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kechi Zhang",
      "Ge Li",
      "Yihong Dong",
      "Jingjing Xu",
      "Jun Zhang",
      "Jing Su",
      "Yongfei Liu",
      "Zhi Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.772": {
    "title": "ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Miserlis Hoyle",
      "Lorena Calvo-Bartolomé",
      "Jordan Lee Boyd-Graber",
      "Philip Resnik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.773": {
    "title": "BOOKWORLD: From Novels to Interactive Agent Societies for Story Creation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiting Ran",
      "Xintao Wang",
      "Tian Qiu",
      "Jiaqing Liang",
      "Yanghua Xiao",
      "Deqing Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.774": {
    "title": "Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryo Kishino",
      "Hiroaki Yamagiwa",
      "Ryo Nagata",
      "Sho Yokoi",
      "Hidetoshi Shimodaira"
    ]
  },
  "https://aclanthology.org/2025.acl-long.775": {
    "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Peng",
      "Yunjia Qi",
      "Xiaozhi Wang",
      "Zijun Yao",
      "Bin Xu",
      "Lei Hou",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.776": {
    "title": "Adaptive and Robust Translation from Natural Language to Multi-model Query Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gengyuan Shi",
      "Chaokun Wang",
      "Liu Yabin",
      "Jiawei Ren"
    ]
  },
  "https://aclanthology.org/2025.acl-long.777": {
    "title": "SAKE: Steering Activations for Knowledge Editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Scialanga",
      "Thibault Laugel",
      "Vincent Grari",
      "Marcin Detyniecki"
    ]
  },
  "https://aclanthology.org/2025.acl-long.778": {
    "title": "Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danni Liu",
      "Jan Niehues"
    ]
  },
  "https://aclanthology.org/2025.acl-long.779": {
    "title": "Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arduin Findeis",
      "Floris Weers",
      "Guoli Yin",
      "Ke Ye",
      "Ruoming Pang",
      "Tom Gunter"
    ]
  },
  "https://aclanthology.org/2025.acl-long.780": {
    "title": "One for All: Update Parameterized Knowledge Across Multiple Models with Once Edit",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weitao Ma",
      "Xiyuan Du",
      "Xiaocheng Feng",
      "Lei Huang",
      "Yichong Huang",
      "Huiyi Zhang",
      "Xiaoliang Yang",
      "Baohang Li",
      "Xiachong Feng",
      "Ting Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.781": {
    "title": "VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiasi Wang",
      "Tianliang Yao",
      "Simin Chen",
      "Runqi Wang",
      "Lei Ye",
      "Kuofeng Gao",
      "Yi Huang",
      "Yuan Yao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.782": {
    "title": "The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nitay Calderon",
      "Roi Reichart",
      "Rotem Dror"
    ]
  },
  "https://aclanthology.org/2025.acl-long.783": {
    "title": "CrisisTS: Coupling Social Media Textual Data and Meteorological Time Series for Urgency Classification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Romain Meunier",
      "Farah Benamara",
      "Véronique Moriceau",
      "Zhongzheng Qiao",
      "Savitha Ramasamy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.784": {
    "title": "How to Mitigate Overfitting in Weak-to-strong Generalization?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Shi",
      "Qinyuan Cheng",
      "Zhaoye Fei",
      "Yining Zheng",
      "Qipeng Guo",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.785": {
    "title": "Com2 : A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Xiong",
      "Xiao Ding",
      "Yixin Cao",
      "Yuxiong Yan",
      "Li Du",
      "Yufei Zhang",
      "Jinglong Gao",
      "Jiaqian Liu",
      "Bing Qin",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.786": {
    "title": "Dynamic Head Selection for Neural Lexicalized Constituency Parsing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Hou",
      "Zhenghua Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.787": {
    "title": "My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Liao",
      "Yu Feng",
      "Yujin Zheng",
      "Jun Zhao",
      "Suge Wang",
      "JianXing Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.788": {
    "title": "EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Zhu",
      "Yusheng Liao",
      "Zhe Chen",
      "Yuhao Wang",
      "Yunfeng Guan",
      "Yanfeng Wang",
      "Yu Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.789": {
    "title": "Enabling LLM Knowledge Analysis via Extensive Materialization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujia Hu",
      "Tuan-Phong Nguyen",
      "Shrestha Ghosh",
      "Simon Razniewski"
    ]
  },
  "https://aclanthology.org/2025.acl-long.790": {
    "title": "Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialong Zuo",
      "Shengpeng Ji",
      "Minghui Fang",
      "Mingze Li",
      "Ziyue Jiang",
      "Xize Cheng",
      "Xiaoda Yang",
      "Chen Feiyang",
      "Xinyu Duan",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.791": {
    "title": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingcheng Niu",
      "Xingdi Yuan",
      "Tong Wang",
      "Hamidreza Saghir",
      "Amir H. Abdi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.792": {
    "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honglin Guo",
      "Kai Lv",
      "Qipeng Guo",
      "Tianyi Liang",
      "Zhiheng Xi",
      "Demin Song",
      "Qiuyinzhe Zhang",
      "Yu Sun",
      "Kai Chen",
      "Xipeng Qiu",
      "Tao Gui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.793": {
    "title": "Theoretical Guarantees for Minimum Bayes Risk Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuki Ichihara",
      "Yuu Jinnai",
      "Kaito Ariu",
      "Tetsuro Morimura",
      "Eiji Uchibe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.794": {
    "title": "Mutual-Taught for Co-adapting Policy and Reward Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyuan Shi",
      "Canbin Huang",
      "Fanqi Wan",
      "Longguang Zhong",
      "Ziyi Yang",
      "Weizhou Shen",
      "Xiaojun Quan",
      "Ming Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.795": {
    "title": "Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Zhuang",
      "Yuan Sun",
      "Xiaobing Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.796": {
    "title": "Unmasking Style Sensitivity: A Causal Analysis of Bias Evaluation Instability in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxu Zhao",
      "Meng Fang",
      "Kun Zhang",
      "Mykola Pechenizkiy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.797": {
    "title": "MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dávid Javorský",
      "Ondřej Bojar",
      "François Yvon"
    ]
  },
  "https://aclanthology.org/2025.acl-long.798": {
    "title": "BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ercong Nie",
      "Bo Shao",
      "Mingyang Wang",
      "Zifeng Ding",
      "Helmut Schmid",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.acl-long.799": {
    "title": "What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dingyi Yang",
      "Qin Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.800": {
    "title": "PROPER: A Progressive Learning Framework for Personalized Large Language Models with Group-Level Adaptation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linhai Zhang",
      "Jialong Wu",
      "Deyu Zhou",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.801": {
    "title": "Enhancing Event-centric News Cluster Summarization via Data Sharpening and Localization Insights",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longyin Zhang",
      "Bowei Zou",
      "AiTi Aw"
    ]
  },
  "https://aclanthology.org/2025.acl-long.802": {
    "title": "MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhitao He",
      "Sandeep Polisetty",
      "Zhiyuan Fan",
      "Yuchen Huang",
      "Shujin Wu",
      "Yi R. Fung"
    ]
  },
  "https://aclanthology.org/2025.acl-long.803": {
    "title": "LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaodong Wu",
      "Minhao Wang",
      "Yichen Liu",
      "Xiaoming Shi",
      "He Yan",
      "Lu Xiangju",
      "Junmin Zhu",
      "Wei Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.804": {
    "title": "Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuzheng Si",
      "Haozhe Zhao",
      "Gang Chen",
      "Cheng Gao",
      "Yuzhuo Bai",
      "Zhitong Wang",
      "Kaikai An",
      "Kangyang Luo",
      "Chen Qian",
      "Fanchao Qi",
      "Baobao Chang",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.805": {
    "title": "One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwoo Ha",
      "Hyunjun Kim",
      "Sangyoon Yu",
      "Haon Park",
      "Ashkan Yousefpour",
      "Yuna Park",
      "Suhyun Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.806": {
    "title": "RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Liu",
      "Kailai Yang",
      "Qianqian Xie",
      "Christine de Kock",
      "Sophia Ananiadou",
      "Eduard Hovy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.807": {
    "title": "Task-Specific Information Decomposition for End-to-End Dense Video Captioning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyue Liu",
      "Xinru Zhang",
      "Jinyuan Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.808": {
    "title": "CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitao Li",
      "Junjie Chen",
      "Qingyao Ai",
      "Zhumin Chu",
      "Yujia Zhou",
      "Qian Dong",
      "Yiqun Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.809": {
    "title": "Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sahrish Khan",
      "Arshad Jhumka",
      "Gabriele Pergola"
    ]
  },
  "https://aclanthology.org/2025.acl-long.810": {
    "title": "Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elena Sofia Ruzzetti",
      "Giancarlo A. Xompero",
      "Davide Venditti",
      "Fabio Massimo Zanzotto"
    ]
  },
  "https://aclanthology.org/2025.acl-long.811": {
    "title": "PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhang",
      "Yuxuan Dong",
      "Yanrui Wu",
      "Jiaxing Huang",
      "Chengyou Jia",
      "Basura Fernando",
      "Mike Zheng Shou",
      "Lingling Zhang",
      "Jun Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.812": {
    "title": "Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yein Park",
      "Chanwoong Yoon",
      "Jungwoo Park",
      "Minbyul Jeong",
      "Jaewoo Kang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.813": {
    "title": "Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheheng Luo",
      "Xin Zhang",
      "Xiao Liu",
      "Haoling Li",
      "Yeyun Gong",
      "Qi Chen",
      "Peng Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.814": {
    "title": "Sheep's Skin, Wolf's Deeds: Are LLMs Ready for Metaphorical Implicit Hate Speech?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingjie Zeng",
      "Liang Yang",
      "Zekun Wang",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.815": {
    "title": "Neuron-Level Sequential Editing for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houcheng Jiang",
      "Junfeng Fang",
      "Tianyu Zhang",
      "Baolong Bi",
      "An Zhang",
      "Ruipeng Wang",
      "Tao Liang",
      "Xiang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.816": {
    "title": "Automatic Expert Discovery in LLM Upcycling via Sparse Interpolated Mixture-of-Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengzhuang Chen",
      "Ying Wei",
      "Jonathan Richard Schwarz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.817": {
    "title": "SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keqi Deng",
      "Wenxi Chen",
      "Xie Chen",
      "Phil Woodland"
    ]
  },
  "https://aclanthology.org/2025.acl-long.818": {
    "title": "VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqian Cui",
      "Xiaoqi Jiao",
      "Ziqiao Meng",
      "Irwin King"
    ]
  },
  "https://aclanthology.org/2025.acl-long.819": {
    "title": "RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxi Li",
      "Jiajie Jin",
      "Yujia Zhou",
      "Yongkang Wu",
      "Zhonghua Li",
      "Ye Qi",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.820": {
    "title": "The Role of Deductive and Inductive Reasoning in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengkun Cai",
      "Xu Zhao",
      "Haoliang Liu",
      "Zhongyu Jiang",
      "Tianfang Zhang",
      "Zongkai Wu",
      "Jenq-Neng Hwang",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.821": {
    "title": "Disentangling the Roles of Representation and Selection in Data Pruning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yupei Du",
      "Yingjin Song",
      "Hugh Mee Wong",
      "Daniil Ignatev",
      "Albert Gatt",
      "Dong Nguyen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.822": {
    "title": "FRACTAL: Fine-Grained Scoring from Aggregate Text Labels",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukti Makhija",
      "Priyanka Agrawal",
      "Rishi Saket",
      "Aravindan Raghuveer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.823": {
    "title": "ACT: Knowledgeable Agents to Design and Perform Complex Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Makoto Nakatsuji",
      "Shuhei Tateishi",
      "Yasuhiro Fujiwara",
      "Ayaka Matsumoto",
      "Narichika Nomoto",
      "Yoshihide Sato"
    ]
  },
  "https://aclanthology.org/2025.acl-long.824": {
    "title": "Logical forms complement probability in understanding language model (and human) performance",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Wang",
      "Freda Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.825": {
    "title": "Length Controlled Generation for Black-box LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Gu",
      "Wenjie Wang",
      "Xiaocheng Feng",
      "Weihong Zhong",
      "Kun Zhu",
      "Lei Huang",
      "Ting Liu",
      "Bing Qin",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.acl-long.826": {
    "title": "Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Huang",
      "Xiaocheng Feng",
      "Weitao Ma",
      "Yuchun Fan",
      "Xiachong Feng",
      "Yangfan Ye",
      "Weihong Zhong",
      "Yuxuan Gu",
      "Baoxin Wang",
      "Dayong Wu",
      "Guoping Hu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.827": {
    "title": "Global Eye: Breaking the \"Fixed Thinking Pattern\" during the Instruction Expansion Process",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Lu",
      "Wei Liu",
      "Jian Luan",
      "Bin Wang",
      "Songhao Jiang",
      "Tianning Zang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.828": {
    "title": "On Synthesizing Data for Context Attribution in Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gorjan Radevski",
      "Kiril Gashteovski",
      "Shahbaz Syed",
      "Christopher Malon",
      "Sebastien Nicolas",
      "Chia-Chien Hung",
      "Timo Sztyler",
      "Verena Heußer",
      "Wiem Ben Rim",
      "Masafumi Enomoto",
      "Kunihiro Takeoka",
      "Masafumi Oyamada",
      "Goran Glavaš",
      "Carolin Lawrence"
    ]
  },
  "https://aclanthology.org/2025.acl-long.829": {
    "title": "TST: A Schema-Based Top-Down and Dynamic-Aware Agent of Text-to-Table Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiwen Jiang",
      "Haitong Jiang",
      "Ruhui Ma",
      "Yvonne Jie Chen",
      "Jinhua Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.830": {
    "title": "EventRAG: Enhancing LLM Generation with Event Knowledge Graphs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zairun Yang",
      "Yilin Wang",
      "Zhengyan Shi",
      "Yuan Yao",
      "Lei Liang",
      "Keyan Ding",
      "Emine Yilmaz",
      "Huajun Chen",
      "Qiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.831": {
    "title": "Analyzing the Rapid Generalization of SFT via the Perspective of Attention Head Activation Patterns",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhao",
      "Li Du",
      "Xiao Ding",
      "Kai Xiong",
      "Ting Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.832": {
    "title": "Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Xiaoyuan Liu",
      "Kuiyi Gao",
      "Jen-tse Huang",
      "Youliang Yuan",
      "Pinjia He",
      "Shuai Wang",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.833": {
    "title": "Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Zeng",
      "Yizhe Feng",
      "Mengliang He",
      "Wenhui Lei",
      "Wei Zhang",
      "Zeming Liu",
      "Xiaoming Shi",
      "Aimin Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.834": {
    "title": "TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumyabrata Chaudhuri",
      "Pranav Purkar",
      "Ritwik Raghav",
      "Shubhojit Mallick",
      "Manish Gupta",
      "Abhik Jana",
      "Shreya Ghosh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.835": {
    "title": "DualGuard: A Parameter Space Transformation Approach for Bidirectional Defense in Split-Based LLM Fine-Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Liu",
      "Yizhen Wang",
      "Rui Wang",
      "Sai Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.836": {
    "title": "Movie101v2: Improved Movie Narration Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Yue",
      "Yepeng Zhang",
      "Ziheng Wang",
      "Qin Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.837": {
    "title": "Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking using Knowledge Graphs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Hu",
      "Jiaoyan Chen",
      "Yike Wu",
      "Guilin Qi",
      "Hongru Wang",
      "Sheng Bi",
      "Yongrui Chen",
      "Tongtong Wu",
      "Jeff Z. Pan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.838": {
    "title": "Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongwook Han",
      "Dongmin Choi",
      "Woojung Song",
      "Eun-Ju Lee",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.839": {
    "title": "FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Li",
      "Xin Zhang",
      "Zhongxin Guo",
      "Shaoguang Mao",
      "Wen Luo",
      "Guangyue Peng",
      "Yangyu Huang",
      "Houfeng Wang",
      "Scarlett Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.840": {
    "title": "Do not Abstain! Identify and Solve the Uncertainty",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyu Liu",
      "JingquanPeng JingquanPeng",
      "Xiaopeng Wu",
      "Xubin Li",
      "Tiezheng Ge",
      "Bo Zheng",
      "Yong Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.841": {
    "title": "Decoding by Contrasting Knowledge: Enhancing Large Language Model Confidence on Edited Facts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baolong Bi",
      "Shenghua Liu",
      "Lingrui Mei",
      "Yiwei Wang",
      "Junfeng Fang",
      "Pengliang Ji",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.842": {
    "title": "ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Zia Ur Rehman",
      "Anukriti Bhatnagar",
      "Omkar Kabde",
      "Shubhi Bansal",
      "Dr. Nagendra Kumar"
    ]
  },
  "https://aclanthology.org/2025.acl-long.843": {
    "title": "Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leonardo Ranaldi",
      "Marco Valentino",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2025.acl-long.844": {
    "title": "Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aniket Bhattacharyya",
      "Anurag Tripathi",
      "Ujjal Das",
      "Archan Karmakar",
      "Amit Pathak",
      "Maneesh Gupta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.845": {
    "title": "Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohan Lyu",
      "Xin Cong",
      "Heyang Yu",
      "Pan Yang",
      "Cheng Qian",
      "Zihe Wang",
      "Yujia Qin",
      "Yining Ye",
      "Yaxi Lu",
      "Chen Qian",
      "Zhong Zhang",
      "Yukun Yan",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.846": {
    "title": "LLMs Can Simulate Standardized Patients via Agent Coevolution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoyun Du",
      "LujieZheng LujieZheng",
      "Renjun Hu",
      "Yuyang Xu",
      "Xiawei Li",
      "Ying Sun",
      "Wei Chen",
      "Jian Wu",
      "Haolei Cai",
      "Haochao Ying"
    ]
  },
  "https://aclanthology.org/2025.acl-long.847": {
    "title": "Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christopher Bagdon",
      "Aidan Combs",
      "Carina Silberer",
      "Roman Klinger"
    ]
  },
  "https://aclanthology.org/2025.acl-long.848": {
    "title": "Which Demographics do LLMs Default to During Annotation?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes Schäfer",
      "Aidan Combs",
      "Christopher Bagdon",
      "Jiahui Li",
      "Nadine Probol",
      "Lynn Greschner",
      "Sean Papay",
      "Yarik Menchaca Resendiz",
      "Aswathy Velutharambath",
      "Amelie Wuehrl",
      "Sabine Weber",
      "Roman Klinger"
    ]
  },
  "https://aclanthology.org/2025.acl-long.849": {
    "title": "Can You Really Trust Code Copilot? Evaluating Large Language Models from a Code Security Perspective",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Mou",
      "Xiao Deng",
      "Yuxiao Luo",
      "Shikun Zhang",
      "Wei Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.850": {
    "title": "From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MarkerGen",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiwen Yuan",
      "Chuyi Tan",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Yueqi Zhang",
      "Jiayi Shi",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.851": {
    "title": "AGD: Adversarial Game Defense Against Jailbreak Attacks in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shilong Pan",
      "Zhiliang Tian",
      "Zhen Huang",
      "Wanlong Yu",
      "Zhihua Wen",
      "Xinwang Liu",
      "Kai Lu",
      "Minlie Huang",
      "Dongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.852": {
    "title": "SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongjie Xiao",
      "Hongru Liang",
      "Peixin Qin",
      "Yao Zhang",
      "Wenqiang Lei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.853": {
    "title": "Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiying Yu",
      "Guoxin Chen",
      "Jingjing Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.854": {
    "title": "An Expanded Massive Multilingual Dataset for High-Performance Language Technologies (HPLT)",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Laurie Burchell",
      "Ona De Gibert Bonet",
      "Nikolay Arefyev",
      "Mikko Aulamo",
      "Marta Bañón",
      "Pinzhen Chen",
      "Mariia Fedorova",
      "Liane Guillou",
      "Barry Haddow",
      "Jan Hajič",
      "Jindřich Helcl",
      "Erik Henriksson",
      "Mateusz Klimaszewski",
      "Ville Komulainen",
      "Andrey Kutuzov",
      "Joona Kytöniemi",
      "Veronika Laippala",
      "Petter Mæhlum",
      "Bhavitvya Malik",
      "Farrokh Mehryary",
      "Vladislav Mikhailov",
      "Nikita Moghe",
      "Amanda Myntti",
      "Dayyán O’Brien",
      "Stephan Oepen",
      "Proyag Pal",
      "Jousia Piha",
      "Sampo Pyysalo",
      "Gema Ramírez-Sánchez",
      "David Samuel",
      "Pavel Stepachev",
      "Jörg Tiedemann",
      "Dušan Variš",
      "Tereza Vojtěchová",
      "Jaume Zaragoza-Bernabeu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.855": {
    "title": "Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Yang",
      "Ajay Patel",
      "Matt Deitke",
      "Tanmay Gupta",
      "Luca Weihs",
      "Andrew Head",
      "Mark Yatskar",
      "Chris Callison-Burch",
      "Ranjay Krishna",
      "Aniruddha Kembhavi",
      "Christopher Clark"
    ]
  },
  "https://aclanthology.org/2025.acl-long.856": {
    "title": "Hierarchical Attention Generates Better Proofs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianlong Chen",
      "Chao Li",
      "Yang Yuan",
      "Andrew C Yao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.857": {
    "title": "Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Men",
      "Zhuoran Jin",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.858": {
    "title": "It's Not Bragging If You Can Back It Up: Can LLMs Understand Braggings?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingjie Zeng",
      "Huayang Li",
      "Liang Yang",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.859": {
    "title": "A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Men",
      "Pengfei Cao",
      "Zhuoran Jin",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.860": {
    "title": "Meta-Learning Neural Mechanisms rather than Bayesian Priors",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Eric Goodale",
      "Salvador Mascarenhas",
      "Yair Lakretz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.861": {
    "title": "Shifting from Ranking to Set Selection for Retrieval Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dahyun Lee",
      "Yongrae Jo",
      "Haeju Park",
      "Moontae Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.862": {
    "title": "Understanding Large Language Model Vulnerabilities to Social Bias Attacks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxu Zhao",
      "Meng Fang",
      "Fanghua Ye",
      "Ke Xu",
      "Qin Zhang",
      "Joey Tianyi Zhou",
      "Mykola Pechenizkiy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.863": {
    "title": "ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM Dialogue Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhigen Li",
      "Jianxiang Peng",
      "Yanmeng Wang",
      "Yong Cao",
      "Tianhao Shen",
      "Minghui Zhang",
      "Linxi Su",
      "Shang Wu",
      "Yihang Wu",
      "YuQian Wang",
      "Ye Wang",
      "Wei Hu",
      "Jianfeng Li",
      "Shaojun Wang",
      "Jing Xiao",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.864": {
    "title": "Pixel-Level Reasoning Segmentation via Multi-turn Conversations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dexian Cai",
      "Xiaocui Yang",
      "YongKang Liu",
      "Daling Wang",
      "Shi Feng",
      "Yifei Zhang",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2025.acl-long.865": {
    "title": "Fixing Distribution Shifts of LLM Self-Critique via On-Policy Self-Play Training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rong Bao",
      "Donglei Yu",
      "Kai Fan",
      "Minpeng Liao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.866": {
    "title": "Inferring Functionality of Attention Heads from their Parameters",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amit Elhelo",
      "Mor Geva"
    ]
  },
  "https://aclanthology.org/2025.acl-long.867": {
    "title": "Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Quan",
      "Marco Valentino",
      "Louise A. Dennis",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2025.acl-long.868": {
    "title": "Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiakuan Xie",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.869": {
    "title": "Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyu Huang",
      "Pavlos Vougiouklis",
      "Mirella Lapata",
      "Jeff Z. Pan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.870": {
    "title": "From Human Reading to NLM Understanding: Evaluating the Role of Eye-Tracking Data in Encoder-Based Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Dini",
      "Lucia Domenichelli",
      "Dominique Brunato",
      "Felice Dell’Orletta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.871": {
    "title": "Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linhao Ye",
      "Lang Yu",
      "Zhikai Lei",
      "Qin Chen",
      "Jie Zhou",
      "Liang He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.872": {
    "title": "Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyuan Liu",
      "Wenxuan Wang",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Qiuzhi Liu",
      "Pinjia He",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.873": {
    "title": "SceneGenAgent: Precise Industrial Scene Generation with Coding Agent",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Xia",
      "Dan Zhang",
      "Zibo Liao",
      "Zhenyu Hou",
      "Tianrui Sun",
      "Jing Li",
      "Ling Fu",
      "Yuxiao Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.874": {
    "title": "ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanxing Ding",
      "Shuchang Tao",
      "Liang Pang",
      "Zihao Wei",
      "Jinyang Gao",
      "Bolin Ding",
      "Huawei Shen",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.875": {
    "title": "Enhancing Text Editing for Grammatical Error Correction: Arabic as a Case Study",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bashar Alhafni",
      "Nizar Habash"
    ]
  },
  "https://aclanthology.org/2025.acl-long.876": {
    "title": "From Isolates to Families: Using Neural Networks for Automated Language Affiliation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Frederic Blum",
      "Steffen Herbold",
      "Johann-Mattis List"
    ]
  },
  "https://aclanthology.org/2025.acl-long.877": {
    "title": "ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuxu Liu",
      "Siyuan Liang",
      "Mengya Han",
      "Yong Luo",
      "Aishan Liu",
      "Xiantao Cai",
      "Zheng He",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.878": {
    "title": "Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xue Zhang",
      "Yunlong Liang",
      "Fandong Meng",
      "Songming Zhang",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.879": {
    "title": "When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniela Occhipinti",
      "Marco Guerini",
      "Malvina Nissim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.880": {
    "title": "ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenliang Zhang",
      "Xinyu Hu",
      "Huixuan Zhang",
      "Junzhe Zhang",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.881": {
    "title": "Revisit Self-Debugging with Self-Generated Tests for Code Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiancai Chen",
      "Zhengwei Tao",
      "Kechi Zhang",
      "Changzhi Zhou",
      "Xinyu Zhang",
      "Wanli Gu",
      "Yuanpeng He",
      "Mengdi Zhang",
      "Xunliang Cai",
      "Haiyan Zhao",
      "Zhi Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.882": {
    "title": "InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dingdong Wang",
      "Jin Xu",
      "Ruihang Chu",
      "Zhifang Guo",
      "Xiong Wang",
      "Jincenzi Wu",
      "Dongchao Yang",
      "Shengpeng Ji",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.883": {
    "title": "Exploring LLMs' Ability to Spontaneously and Conditionally Modify Moral Expressions through Text Manipulation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Candida Maria Greco",
      "Lucio La Cava",
      "Lorenzo Zangari",
      "Andrea Tagarelli"
    ]
  },
  "https://aclanthology.org/2025.acl-long.884": {
    "title": "Mixture of Ordered Scoring Experts for Cross-prompt Essay Trait Scoring",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Po-Kai Chen",
      "Bo-Wei Tsai",
      "Shao Kuan Wei",
      "Chien-Yao Wang",
      "Jia-Ching Wang",
      "Yi-Ting Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.885": {
    "title": "Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anshumann Anshumann",
      "Mohd Abbas Zaidi",
      "Akhil Kedia",
      "Jinwoo Ahn",
      "Taehwak Kwon",
      "Kangwook Lee",
      "Haejun Lee",
      "Joohyung Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.886": {
    "title": "Enhancing Spoken Discourse Modeling in Language Models Using Gestural Cues",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Varsha Suresh",
      "M. Hamza Mughal",
      "Christian Theobalt",
      "Vera Demberg"
    ]
  },
  "https://aclanthology.org/2025.acl-long.887": {
    "title": "ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunkun Wang",
      "Yue Zhang",
      "Zhen Qin",
      "Chen Zhi",
      "Binhua Li",
      "Fei Huang",
      "Yongbin Li",
      "Shuiguang Deng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.888": {
    "title": "Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihong Zhang",
      "Liqi He",
      "Zuchao Li",
      "Lefei Zhang",
      "Hai Zhao",
      "Bo Du"
    ]
  },
  "https://aclanthology.org/2025.acl-long.889": {
    "title": "RUBY: An Effective Framework for Multi-Constraint Multi-Hop Question Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenzhuo Zhao",
      "Shuangyin Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.890": {
    "title": "Can Indirect Prompt Injection Attacks Be Detected and Removed?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulin Chen",
      "Haoran Li",
      "Yuan Sui",
      "Yufei He",
      "Yue Liu",
      "Yangqiu Song",
      "Bryan Hooi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.891": {
    "title": "Identifying Open Challenges in Language Identification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rob Van Der Goot"
    ]
  },
  "https://aclanthology.org/2025.acl-long.892": {
    "title": "The Distracting Effect: Understanding Irrelevant Passages in RAG",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Amiraz",
      "Florin Cuconasu",
      "Simone Filice",
      "Zohar Karnin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.893": {
    "title": "Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeli Su",
      "Ziyin Zhang",
      "Guixian Xu",
      "Jianing Liu",
      "Xu Han",
      "Ting Zhang",
      "Yushuang Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.894": {
    "title": "Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Célia Nouri",
      "Chloé Clavel",
      "Jean-Philippe Cointet"
    ]
  },
  "https://aclanthology.org/2025.acl-long.895": {
    "title": "CodeTool: Enhancing Programmatic Tool Invocation of LLMs via Process Supervision",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YifeiLu YifeiLu",
      "Fanghua Ye",
      "Jian Li",
      "Qiang Gao",
      "Cheng Liu",
      "Haibo Luo",
      "Nan Du",
      "Xiaolong Li",
      "Feiliang Ren"
    ]
  },
  "https://aclanthology.org/2025.acl-long.896": {
    "title": "RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hieu Tran",
      "Zonghai Yao",
      "Zhichao Yang",
      "Junda Wang",
      "Yifan Zhang",
      "Shuo Han",
      "Feiyun Ouyang",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.897": {
    "title": "Defense Against Prompt Injection Attack by Leveraging Attack Techniques",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulin Chen",
      "Haoran Li",
      "Zihao Zheng",
      "Dekai Wu",
      "Yangqiu Song",
      "Bryan Hooi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.898": {
    "title": "Acquisition and Application of Novel Knowledge in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Shang",
      "Jianghan Liu",
      "Zhizhao Luo",
      "Peng Wang",
      "Wenjun Ke",
      "Jiajun Liu",
      "Zijie Xu",
      "Guozheng Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.899": {
    "title": "DNCASR: End-to-End Training for Speaker-Attributed ASR",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianrui Zheng",
      "Chao Zhang",
      "Phil Woodland"
    ]
  },
  "https://aclanthology.org/2025.acl-long.900": {
    "title": "Exploring Persona Sentiment Sensitivity in Personalized Dialogue Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghyun Jun",
      "Hwanhee Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.901": {
    "title": "AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobao Wu",
      "Liangming Pan",
      "Yuxi Xie",
      "Ruiwen Zhou",
      "Shuai Zhao",
      "Yubo Ma",
      "Mingzhe Du",
      "Rui Mao",
      "Anh Tuan Luu",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.902": {
    "title": "LLM-Guided Semantic-Aware Clustering for Topic Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianghan Liu",
      "Ziyu Shang",
      "Wenjun Ke",
      "Peng Wang",
      "Zhizhao Luo",
      "Jiajun Liu",
      "Guozheng Li",
      "Yining Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.903": {
    "title": "Hierarchical Bracketing Encodings for Dependency Parsing as Tagging",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ana Ezquerro",
      "David Vilares",
      "Anssi Yli-Jyrä",
      "Carlos Gómez-Rodríguez"
    ]
  },
  "https://aclanthology.org/2025.acl-long.904": {
    "title": "OASIS: Order-Augmented Strategy for Improved Code Search",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gao Zuchen",
      "Zizheng Zhan",
      "Xianming Li",
      "Erxin Yu",
      "Haotian Zhang",
      "Chenbin Chenbin",
      "Yuqun Zhang",
      "Jing Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.905": {
    "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yancheng He",
      "Shilong Li",
      "Jiaheng Liu",
      "Weixun Wang",
      "Xingyuan Bu",
      "Ge Zhang",
      "Z.y. Peng",
      "Zhaoxiang Zhang",
      "Zhicheng Zheng",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.906": {
    "title": "OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Zhao",
      "Shengyuan Ding",
      "Zicheng Zhang",
      "Haian Huang",
      "Maosongcao Maosongcao",
      "Jiaqi Wang",
      "Weiyun Wang",
      "Xinyu Fang",
      "Wenhai Wang",
      "Guangtao Zhai",
      "Hua Yang",
      "Haodong Duan",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.907": {
    "title": "Tree-KG: An Expandable Knowledge Graph Construction Framework for Knowledge-intensive Domains",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songjie Niu",
      "Kaisen Yang",
      "Rui Zhao",
      "Yichao Liu",
      "Zonglin Li",
      "Hongning Wang",
      "Wenguang Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.908": {
    "title": "Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuming Yang",
      "Yang Nan",
      "Junjie Ye",
      "Shihan Dou",
      "Xiao Wang",
      "Shuo Li",
      "Huijie Lv",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.909": {
    "title": "Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Huo",
      "Jinyang Li",
      "Bowen Qin",
      "Ge Qu",
      "Xiaolong Li",
      "Xiaodong Li",
      "Chenhao Ma",
      "Reynold Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.910": {
    "title": "Minimal Pair-Based Evaluation of Code-Switching",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Igor Sterner",
      "Simone Teufel"
    ]
  },
  "https://aclanthology.org/2025.acl-long.911": {
    "title": "DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanqi Cheng",
      "Hongda Sun",
      "Bo Du",
      "Shuo Shang",
      "Xinrong Hu",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.912": {
    "title": "LLaMA-Omni 2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingkai Fang",
      "Yan Zhou",
      "Shoutao Guo",
      "Shaolei Zhang",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.913": {
    "title": "Error Comparison Optimization for Large Language Models on Aspect-Based Sentiment Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianlong Wang",
      "Keyang Ding",
      "Hengxin Gao",
      "Hui Wang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.914": {
    "title": "The AI Gap: How Socioeconomic Status Affects Language Technology Interactions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elisa Bassignana",
      "Amanda Cercas Curry",
      "Dirk Hovy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.915": {
    "title": "Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Eichin",
      "Yang Janet Liu",
      "Barbara Plank",
      "Michael A. Hedderich"
    ]
  },
  "https://aclanthology.org/2025.acl-long.916": {
    "title": "Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Cahyawijaya",
      "Holy Lovenia",
      "Joel Ruben Antony Moniz",
      "Tack Hwa Wong",
      "Mohammad Rifqi Farhansyah",
      "Thant Thiri Maung",
      "Frederikus Hudi",
      "David Anugraha",
      "Muhammad Ravi Shulthan Habibi",
      "Muhammad Reza Qorib",
      "Amit Agarwal",
      "Joseph Marvin Imperial",
      "Hitesh Laxmichand Patel",
      "Vicky Feliren",
      "Bahrul Ilmi Nasution",
      "Manuel Antonio Rufino",
      "Genta Indra Winata",
      "Rian Adam Rajagede",
      "Carlos Rafael Catalan",
      "Mohamed Fazli Mohamed Imam",
      "Priyaranjan Pattnayak",
      "Salsabila Zahirah Pranida",
      "Kevin Pratama",
      "Yeshil Bangera",
      "Adisai Na-Thalang",
      "Patricia Nicole Monderin",
      "Yueqi Song",
      "Christian Simon",
      "Lynnette Hui Xian Ng",
      "Richardy Lobo Sapan",
      "Taki Hasan Rafi",
      "Bin Wang",
      "Supryadi",
      "Kanyakorn Veerakanjana",
      "Piyalitt Ittichaiwong",
      "Matthew Theodore Roque",
      "Karissa Vincentio",
      "Takdanai Kreangphet",
      "Phakphum Artkaew",
      "Kadek Hendrawan Palgunadi",
      "Yanzhi Yu",
      "Rochana Prih Hastuti",
      "William Nixon",
      "Mithil Bangera",
      "Adrian Xuan Wei Lim",
      "Aye Hninn Khine",
      "Hanif Muhammad Zhafran",
      "Teddy Ferdinan",
      "Audra Aurora Izzani",
      "Ayushman Singh",
      "Evan Evan",
      "Jauza Akbar Krito",
      "Michael Anugraha",
      "Fenal Ashokbhai Ilasariya",
      "Haochen Li",
      "John Amadeo Daniswara",
      "Filbert Aurelian Tjiaranata",
      "Eryawan Presma Yulianrifat",
      "Can Udomcharoenchaikit",
      "Fadil Risdian Ansori",
      "Mahardika Krisna Ihsani",
      "Giang Nguyen",
      "Anab Maulana Barik",
      "Dan John Velasco",
      "Rifo Ahmad Genadi",
      "Saptarshi Saha",
      "Chengwei Wei",
      "Isaiah Edri W. Flores",
      "Kenneth Chen Ko Han",
      "Anjela Gail D. Santos",
      "Wan Shen Lim",
      "Kaung Si Phyo",
      "Tim Santos",
      "Meisyarah Dwiastuti",
      "Jiayun Luo",
      "Jan Christian Blaise Cruz",
      "Ming Shan Hee",
      "Ikhlasul Akmal Hanif",
      "M.Alif Al Hakim",
      "Muhammad Rizky Sya’ban",
      "Kun Kerdthaisong",
      "Lester James Validad Miranda",
      "Fajri Koto",
      "Tirana Noor Fatyanosa",
      "Alham Fikri Aji",
      "Jostin Jerico Rosal",
      "Jun Kevin",
      "Robert Wijaya",
      "Onno P. Kampman",
      "Ruochen Zhang",
      "Börje F. Karlsson",
      "Peerat Limkonchotiwat"
    ]
  },
  "https://aclanthology.org/2025.acl-long.917": {
    "title": "Soundwave: Less is More for Speech-Text Alignment in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Zhang",
      "Zhiheng Liu",
      "Fan Bu",
      "Ruiyu Zhang",
      "Benyou Wang",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.918": {
    "title": "RoToR: Towards More Reliable Responses for Order-Invariant Inputs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soyoung Yoon",
      "Dongha Ahn",
      "Youngwon Lee",
      "Minkyu Jung",
      "HyungJoo Jang",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.919": {
    "title": "Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivalika Singh",
      "Angelika Romanou",
      "Clémentine Fourrier",
      "David Ifeoluwa Adelani",
      "Jian Gang Ngui",
      "Daniel Vila-Suero",
      "Peerat Limkonchotiwat",
      "Kelly Marchisio",
      "Wei Qi Leong",
      "Yosephine Susanto",
      "Raymond Ng",
      "Shayne Longpre",
      "Sebastian Ruder",
      "Wei-Yin Ko",
      "Antoine Bosselut",
      "Alice Oh",
      "Andre Martins",
      "Leshem Choshen",
      "Daphne Ippolito",
      "Enzo Ferrante",
      "Marzieh Fadaee",
      "Beyza Ermis",
      "Sara Hooker"
    ]
  },
  "https://aclanthology.org/2025.acl-long.920": {
    "title": "Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxin Fan",
      "Peifeng Li",
      "Qiaoming Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.921": {
    "title": "ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Yang",
      "Yixia Li",
      "Hongru Wang",
      "Xuetao Wei",
      "James Jianqiao Yu",
      "Yun Chen",
      "Guanhua Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.922": {
    "title": "Words of Warmth: Trust and Sociability Norms for over 26k English Words",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saif M. Mohammad"
    ]
  },
  "https://aclanthology.org/2025.acl-long.923": {
    "title": "BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lindia Tjuatja",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2025.acl-long.924": {
    "title": "HAF-RM: A Hybrid Alignment Framework for Reward Model Training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shujun Liu",
      "Xiaoyu Shen",
      "Yuhang Lai",
      "Siyuan Wang",
      "Shengbin Yue",
      "Zengfeng Huang",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.925": {
    "title": "CULEMO: Cultural Lenses on Emotion - Benchmarking LLMs for Cross-Cultural Emotion Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tadesse Destaw Belay",
      "Ahmed Haj Ahmed",
      "Alvin C Grissom Ii",
      "Iqra Ameer",
      "Grigori Sidorov",
      "Olga Kolesnikova",
      "Seid Muhie Yimam"
    ]
  },
  "https://aclanthology.org/2025.acl-long.926": {
    "title": "DiffPO: Diffusion-styled Preference Optimization for Inference Time Alignment of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruizhe Chen",
      "Wenhao Chai",
      "Zhifei Yang",
      "Xiaotian Zhang",
      "Ziyang Wang",
      "Tony Quek",
      "Joey Tianyi Zhou",
      "Soujanya Poria",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.927": {
    "title": "MemeQA: Holistic Evaluation for Meme Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khoi P. N. Nguyen",
      "Terrence Li",
      "Derek Lou Zhou",
      "Gabriel Xiong",
      "Pranav Balu",
      "Nandhan Alahari",
      "Alan Huang",
      "Tanush Chauhan",
      "Harshavardhan Bala",
      "Emre Guzelordu",
      "Affan Kashfi",
      "Aaron Xu",
      "Suyesh Shrestha",
      "Megan Vu",
      "Jerry Wang",
      "Vincent Ng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.928": {
    "title": "LoGU: Long-form Generation with Uncertainty Expressions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruihan Yang",
      "Caiqi Zhang",
      "Zhisong Zhang",
      "Xinting Huang",
      "Sen Yang",
      "Nigel Collier",
      "Dong Yu",
      "Deqing Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.929": {
    "title": "KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyuan Fang",
      "Zaiqiao Meng",
      "Craig MacDonald"
    ]
  },
  "https://aclanthology.org/2025.acl-long.930": {
    "title": "Enhancing Lexicon-Based Text Embeddings with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibin Lei",
      "Tao Shen",
      "Yu Cao",
      "Andrew Yates"
    ]
  },
  "https://aclanthology.org/2025.acl-long.931": {
    "title": "CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Santosh T.y.s.s",
      "Youssef Tarek Elkhayat",
      "Oana Ichim",
      "Pranav Shetty",
      "Dongsheng Wang",
      "Zhiqiang Ma",
      "Armineh Nourbakhsh",
      "Xiaomo Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.932": {
    "title": "Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Itai Mondshine",
      "Tzuf Paz-Argaman",
      "Reut Tsarfaty"
    ]
  },
  "https://aclanthology.org/2025.acl-long.933": {
    "title": "CC-Tuning: A Cross-Lingual Connection Mechanism for Improving Joint Multilingual Supervised Fine-Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangfan Ye",
      "Xiaocheng Feng",
      "Zekun Yuan",
      "Xiachong Feng",
      "Libo Qin",
      "Lei Huang",
      "Weitao Ma",
      "Yichong Huang",
      "Zhirui Zhang",
      "Yunfei Lu",
      "Xiaohui Yan",
      "Duyu Tang",
      "Dandan Tu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.934": {
    "title": "SConU: Selective Conformal Uncertainty in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Wang",
      "Qingni Wang",
      "Yue Zhang",
      "Tianlong Chen",
      "Xiaofeng Zhu",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.935": {
    "title": "MegaPairs: Massive Data Synthesis for Universal Multimodal Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Zhou",
      "Yongping Xiong",
      "Zheng Liu",
      "Ze Liu",
      "Shitao Xiao",
      "Yueze Wang",
      "Bo Zhao",
      "Chen Jason Zhang",
      "Defu Lian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.936": {
    "title": "When GPT Spills the Tea: Comprehensive Assessment of Knowledge File Leakage in GPTs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyue Shen",
      "Yun Shen",
      "Michael Backes",
      "Yang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.937": {
    "title": "UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yidi Jiang",
      "Qian Chen",
      "Shengpeng Ji",
      "Yu Xi",
      "Wen Wang",
      "Chong Zhang",
      "Xianghu Yue",
      "ShiLiang Zhang",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.938": {
    "title": "KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fnu Mohbat",
      "Mohammed J Zaki"
    ]
  },
  "https://aclanthology.org/2025.acl-long.939": {
    "title": "Multilingual Arbitration: Optimizing Data Pools to Accelerate Multilingual Progress",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayomide Odumakinde",
      "Daniel D’souza",
      "Pat Verga",
      "Beyza Ermis",
      "Sara Hooker"
    ]
  },
  "https://aclanthology.org/2025.acl-long.940": {
    "title": "Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuheng Lu",
      "Bingshuo Qian",
      "Caixia Yuan",
      "Huixing Jiang",
      "Xiaojie Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.941": {
    "title": "Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yancheng He",
      "Shilong Li",
      "Jiaheng Liu",
      "Yingshui Tan",
      "Weixun Wang",
      "Hui Huang",
      "Xingyuan Bu",
      "Hangyu Guo",
      "Chengwei Hu",
      "Boren Zheng",
      "Zhuoran Lin",
      "Dekai Sun",
      "Zhicheng Zheng",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.942": {
    "title": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junseo Kim",
      "Jongwook Han",
      "Dongmin Choi",
      "Jongwook Yoon",
      "Eun-Ju Lee",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.943": {
    "title": "Any Information Is Just Worth One Single Screenshot: Unifying Search With Visualized Information Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Liu",
      "Ze Liu",
      "Zhengyang Liang",
      "Junjie Zhou",
      "Shitao Xiao",
      "Chao Gao",
      "Chen Jason Zhang",
      "Defu Lian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.944": {
    "title": "Tunable LLM-based Proactive Recommendation Agent",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingze Wang",
      "Chongming Gao",
      "Wenjie Wang",
      "Yangyang Li",
      "Fuli Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.945": {
    "title": "AgentRM: Enhancing Agent Generalization with Reward Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Xia",
      "Jingru Fan",
      "Weize Chen",
      "Siyu Yan",
      "Xin Cong",
      "Zhong Zhang",
      "Yaxi Lu",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.946": {
    "title": "From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Xie",
      "Bingbing Xu",
      "Yige Yuan",
      "Shengmao Zhu",
      "Huawei Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.947": {
    "title": "Segment-Based Attention Masking for GPTs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shahar Katz",
      "Liran Ringel",
      "Yaniv Romano",
      "Lior Wolf"
    ]
  },
  "https://aclanthology.org/2025.acl-long.948": {
    "title": "Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuri Kuratov",
      "Mikhail Arkhipov",
      "Aydar Bulatov",
      "Mikhail Burtsev"
    ]
  },
  "https://aclanthology.org/2025.acl-long.949": {
    "title": "Bi-Tuning with Collaborative Information for Controllable LLM-based Sequential Recommendation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhang",
      "Linmei Hu",
      "Luhao Zhang",
      "Wentao Cheng",
      "Yashen Wang",
      "Ge Shi",
      "Chong Feng",
      "Liqiang Nie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.950": {
    "title": "A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jean-Philippe Corbeil",
      "Amin Dada",
      "Jean-Michel Attendu",
      "Asma Ben Abacha",
      "Alessandro Sordoni",
      "Lucas Caccia",
      "Francois Beaulieu",
      "Thomas Lin",
      "Jens Kleesiek",
      "Paul Vozila"
    ]
  },
  "https://aclanthology.org/2025.acl-long.951": {
    "title": "DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Feng",
      "Bowen Shen",
      "Naibin Gu",
      "Jiaxuan Zhao",
      "Peng Fu",
      "Zheng Lin",
      "Weiping Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.952": {
    "title": "DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Zhao",
      "Zuchao Li",
      "Hai Zhao",
      "Baoyuan Qi",
      "Liu Guoming"
    ]
  },
  "https://aclanthology.org/2025.acl-long.953": {
    "title": "Computation Mechanism Behind LLM Position Generalization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi Han",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.954": {
    "title": "IPO: Your Language Model is Secretly a Preference Classifier",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivank Garg",
      "Ayush Singh",
      "Shweta Singh",
      "Paras Chopra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.955": {
    "title": "Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Yuan",
      "Dehui Du",
      "Hao Zhang",
      "Zixiang Di",
      "Usman Naseem"
    ]
  },
  "https://aclanthology.org/2025.acl-long.956": {
    "title": "Déjà Vu? Decoding Repeated Reading from Eye Movements",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yoav Meiri",
      "Omer Shubi",
      "Cfir Avraham Hadar",
      "Ariel Kreisberg Nitzav",
      "Yevgeni Berzak"
    ]
  },
  "https://aclanthology.org/2025.acl-long.957": {
    "title": "LLMs can be easily Confused by Instructional Distractions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yerin Hwang",
      "Yongil Kim",
      "Jahyun Koo",
      "Taegwan Kang",
      "Hyunkyung Bae",
      "Kyomin Jung"
    ]
  },
  "https://aclanthology.org/2025.acl-long.958": {
    "title": "PlanGenLLMs: A Modern Survey of LLM Planning Capabilities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Wei",
      "Zihao Zhang",
      "Shenghua He",
      "Tian Xia",
      "Shijia Pan",
      "Fei Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.959": {
    "title": "IAM: Efficient Inference through Attention Mapping between Different-scale LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Zhao",
      "Zuchao Li",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.960": {
    "title": "nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geliang Ouyang",
      "Jingyao Chen",
      "Zhihe Nie",
      "Yi Gui",
      "Yao Wan",
      "Hongyu Zhang",
      "Dongping Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.961": {
    "title": "ZIPA: A family of efficient models for multilingual phone recognition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Zhu",
      "Farhan Samir",
      "Eleanor Chodroff",
      "David R. Mortensen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.962": {
    "title": "GRACE: A Granular Benchmark for Evaluating Model Calibration against Human Calibration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yoo Yeon Sung",
      "Eve Fleisig",
      "Yu Hou",
      "Ishan Upadhyay",
      "Jordan Lee Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.963": {
    "title": "Dynamic Evaluation with Cognitive Reasoning for Multi-turn Safety of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lanxue Zhang",
      "Yanan Cao",
      "Yuqiang Xie",
      "Fang Fang",
      "Yangxi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.964": {
    "title": "From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathanaël Carraz Rakotonirina",
      "Mohammed Hamdy",
      "Jon Ander Campos",
      "Lucas Weber",
      "Alberto Testoni",
      "Marzieh Fadaee",
      "Sandro Pezzelle",
      "Marco Del Tredici"
    ]
  },
  "https://aclanthology.org/2025.acl-long.965": {
    "title": "Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junxiao Yang",
      "Zhexin Zhang",
      "Shiyao Cui",
      "Hongning Wang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.966": {
    "title": "Multilingual Text-to-Image Generation Magnifies Gender Stereotypes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Friedrich",
      "Katharina Hämmerl",
      "Patrick Schramowski",
      "Manuel Brack",
      "Jindřich Libovický",
      "Alexander Fraser",
      "Kristian Kersting"
    ]
  },
  "https://aclanthology.org/2025.acl-long.967": {
    "title": "Adversarial Alignment with Anchor Dragging Drift (A3D2): Multimodal Domain Adaptation with Partially Shifted Modalities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Sun",
      "Xinxin Zhang",
      "Simin Hong",
      "Jian Zhu",
      "Lingfang Zeng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.968": {
    "title": "A Reality Check on Context Utilisation for Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lovisa Hagström",
      "Sara Vera Marjanovic",
      "Haeun Yu",
      "Arnav Arora",
      "Christina Lioma",
      "Maria Maistro",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ]
  },
  "https://aclanthology.org/2025.acl-long.969": {
    "title": "CU-MAM: Coherence-Driven Unified Macro-Structures for Argument Mining",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debela Gemechu",
      "Chris Reed"
    ]
  },
  "https://aclanthology.org/2025.acl-long.970": {
    "title": "Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyu Chen",
      "Seraphina Goldfarb-Tarrant"
    ]
  },
  "https://aclanthology.org/2025.acl-long.971": {
    "title": "Text-to-ES Bench: A Comprehensive Benchmark for Converting Natural Language to Elasticsearch Query",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "DonggeXue DonggeXue",
      "Zhili Pu",
      "Zhentao Xia",
      "Hongli Sun",
      "Ruihui Hou",
      "Guangya Yu",
      "Yupian Lin",
      "Yongqi Fan",
      "Jingping Liu",
      "Tong Ruan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.972": {
    "title": "AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songming Zhang",
      "Xue Zhang",
      "Tong Zhang",
      "Bojie Hu",
      "Yufeng Chen",
      "Jinan Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.973": {
    "title": "DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vaibhav Aggarwal",
      "Ojasv Kamal",
      "Abhinav Japesh",
      "Zhijing Jin",
      "Bernhard Schölkopf"
    ]
  },
  "https://aclanthology.org/2025.acl-long.974": {
    "title": "Steering off Course: Reliability Challenges in Steering Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Queiroz Da Silva",
      "Hari Sethuraman",
      "Dheeraj Rajagopal",
      "Hannaneh Hajishirzi",
      "Sachin Kumar"
    ]
  },
  "https://aclanthology.org/2025.acl-long.975": {
    "title": "Impartial Multi-task Representation Learning via Variance-invariant Probabilistic Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dou Hu",
      "Lingwei Wei",
      "Wei Zhou",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.976": {
    "title": "If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrian de Wynter"
    ]
  },
  "https://aclanthology.org/2025.acl-long.977": {
    "title": "Integrating Audio, Visual, and Semantic Information for Enhanced Multimodal Speaker Diarization on Multi-party Conversation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luyao Cheng",
      "Hui Wang",
      "Chong Deng",
      "Siqi Zheng",
      "Yafeng Chen",
      "Rongjie Huang",
      "Qinglin Zhang",
      "Qian Chen",
      "Xihao Li",
      "Wen Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.978": {
    "title": "Vulnerability of LLMs to Vertically Aligned Text Manipulations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhecheng Li",
      "Yiwei Wang",
      "Bryan Hooi",
      "Yujun Cai",
      "Zhen Xiong",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.979": {
    "title": "AutoMixer: Checkpoint Artifacts as Automatic Data Mixers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ernie Chang",
      "Yang Li",
      "Patrick Huber",
      "Vish Vogeti",
      "David Kant",
      "Yangyang Shi",
      "Vikas Chandra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.980": {
    "title": "Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Behrooz Azarkhalili",
      "Maxwell W. Libbrecht"
    ]
  },
  "https://aclanthology.org/2025.acl-long.981": {
    "title": "Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanghao Hu",
      "Hanqi Yan",
      "Qinglin Zhu",
      "Zhenyi Shen",
      "Yulan He",
      "Lin Gui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.982": {
    "title": "AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianlyu Chen",
      "Nan Wang",
      "Chaofan Li",
      "Bo Wang",
      "Shitao Xiao",
      "Han Xiao",
      "Hao Liao",
      "Defu Lian",
      "Zheng Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.983": {
    "title": "We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runqi Qiao",
      "Qiuna Tan",
      "Guanting Dong",
      "MinhuiWu MinhuiWu",
      "Chong Sun",
      "Xiaoshuai Song",
      "Jiapeng Wang",
      "Zhuoma GongQue",
      "Shanglin Lei",
      "YiFan Zhang",
      "Zhe Wei",
      "Miaoxuan Zhang",
      "Runfeng Qiao",
      "Xiao Zong",
      "Yida Xu",
      "Peiqing Yang",
      "Zhimin Bao",
      "Muxi Diao",
      "Chen Li",
      "Honggang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.984": {
    "title": "Modeling the Evolution of English Noun Compounds with Feature-Rich Diachronic Compositionality Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filip Miletić",
      "Sabine Schulte Im Walde"
    ]
  },
  "https://aclanthology.org/2025.acl-long.985": {
    "title": "What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael A. Hedderich",
      "Anyi Wang",
      "Raoyuan Zhao",
      "Florian Eichin",
      "Jonas Fischer",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2025.acl-long.986": {
    "title": "V-Oracle: Making Progressive Reasoning in Deciphering Oracle Bones for You and Me",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runqi Qiao",
      "Qiuna Tan",
      "Guanting Dong",
      "MinhuiWu MinhuiWu",
      "Jiapeng Wang",
      "YiFan Zhang",
      "Zhuoma GongQue",
      "Chong Sun",
      "Yida Xu",
      "Yadong Xue",
      "Ye Tian",
      "Zhimin Bao",
      "Lan Yang",
      "Chen Li",
      "Honggang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.987": {
    "title": "Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Hossein Yari",
      "Fajri Koto"
    ]
  },
  "https://aclanthology.org/2025.acl-long.988": {
    "title": "Improving Language and Modality Transfer in Translation by Character-level Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ioannis Tsiamas",
      "David Dale",
      "Marta R. Costa-jussà"
    ]
  },
  "https://aclanthology.org/2025.acl-long.989": {
    "title": "DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niyati Bafna",
      "Emily Chang",
      "Nathaniel Romney Robinson",
      "David R. Mortensen",
      "Kenton Murray",
      "David Yarowsky",
      "Hale Sirin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.990": {
    "title": "AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicholas E. Corrado",
      "Julian Katz-Samuels",
      "Adithya M Devraj",
      "Hyokun Yun",
      "Chao Zhang",
      "Yi Xu",
      "Yi Pan",
      "Bing Yin",
      "Trishul Chilimbi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.991": {
    "title": "Modeling Complex Semantics Relation with Contrastively Fine-Tuned Relational Encoders",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naïm Es-sebbani",
      "Esteban Marquer",
      "Zied Bouraoui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.992": {
    "title": "Error-driven Data-efficient Large Multimodal Model Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barry Menglong Yao",
      "Qifan Wang",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.993": {
    "title": "Planning with Diffusion Models for Target-Oriented Dialogue Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanwen Du",
      "Bo Peng",
      "Xia Ning"
    ]
  },
  "https://aclanthology.org/2025.acl-long.994": {
    "title": "Interactive and Expressive Code-Augmented Planning with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anthony Zhe Liu",
      "Xinhe Wang",
      "Jacob Sansom",
      "Yao Fu",
      "Jongwook Choi",
      "Sungryull Sohn",
      "Jaekyeom Kim",
      "Honglak Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.995": {
    "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhu Jiao",
      "Xuchao Zhang",
      "Zhaoyang Wang",
      "Yubo Ma",
      "Zhun Deng",
      "Rujia Wang",
      "Chetan Bansal",
      "Saravan Rajmohan",
      "Jiawei Han",
      "Huaxiu Yao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.996": {
    "title": "Understanding Silent Data Corruption in LLM Training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeffrey Jian Ma",
      "Hengzhi Pei",
      "Leonard Lausen",
      "George Karypis"
    ]
  },
  "https://aclanthology.org/2025.acl-long.997": {
    "title": "Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guan-Ting Lin",
      "Prashanth Gurunath Shivakumar",
      "Aditya Gourav",
      "Yile Gu",
      "Ankur Gandhe",
      "Hung-yi Lee",
      "Ivan Bulyko"
    ]
  },
  "https://aclanthology.org/2025.acl-long.998": {
    "title": "Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jungsoo Park",
      "Junmo Kang",
      "Gabriel Stanovsky",
      "Alan Ritter"
    ]
  },
  "https://aclanthology.org/2025.acl-long.999": {
    "title": "BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenkai Li",
      "Jiarui Liu",
      "Andy Liu",
      "Xuhui Zhou",
      "Mona T. Diab",
      "Maarten Sap"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1000": {
    "title": "Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Olga Loginova",
      "Sofía Ortega Loguinova"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1001": {
    "title": "Amplifying Trans and Nonbinary Voices: A Community-Centred Harm Taxonomy for LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eddie L. Ungless",
      "Sunipa Dev",
      "Cynthia L. Bennett",
      "Rebecca Gulotta",
      "Jasmijn Bastings",
      "Remi Denton"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1002": {
    "title": "Enhancing Human Evaluation in Machine Translation with Comparative Judgement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixiao Song",
      "Parker Riley",
      "Daniel Deutsch",
      "Markus Freitag"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1003": {
    "title": "Infogen: Generating Complex Statistical Infographics from Documents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akash Ghosh",
      "Aparna Garimella",
      "Pritika Ramu",
      "Sambaran Bandyopadhyay",
      "Sriparna Saha"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1004": {
    "title": "Partial Colexifications Improve Concept Embeddings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arne Rubehn",
      "Johann-Mattis List"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1005": {
    "title": "Improved Unbiased Watermark for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruibo Chen",
      "Yihan Wu",
      "Junfeng Guo",
      "Heng Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1006": {
    "title": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixian Shen",
      "Qi Bi",
      "Jia-hong Huang",
      "Hongyi Zhu",
      "Andy D. Pimentel",
      "Anuj Pathania"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1007": {
    "title": "Multi-Attribute Steering of Language Models via Targeted Intervention",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duy Nguyen",
      "Archiki Prasad",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1008": {
    "title": "AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaurav Verma",
      "Rachneet Kaur",
      "Nishan Srishankar",
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1009": {
    "title": "Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhijian Xu",
      "Yilun Zhao",
      "Manasi Patwardhan",
      "Lovekesh Vig",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1010": {
    "title": "On the Acquisition of Shared Grammatical Representations in Bilingual Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Catherine Arnett",
      "Tyler A. Chang",
      "James A. Michaelov",
      "Ben Bergen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1011": {
    "title": "Using Shapley interactions to understand how models use structure",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divyansh Singhvi",
      "Diganta Misra",
      "Andrej Erkelens",
      "Raghav Jain",
      "Isabel Papadimitriou",
      "Naomi Saphra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1012": {
    "title": "Adversarial Tokenization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renato Geh",
      "Zilei Shao",
      "Guy Van Den Broeck"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1013": {
    "title": "Classifying Unreliable Narrators with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anneliese Brei",
      "Katharine Henry",
      "Abhisheik Sharma",
      "Shashank Srivastava",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1014": {
    "title": "ConceptCarve: Dynamic Realization of Evidence",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eylon Caplan",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1015": {
    "title": "QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "An Quang Tang",
      "Xiuzhen Zhang",
      "Minh Ngoc Dinh",
      "Zhuang Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1016": {
    "title": "Navigating Rifts in Human-LLM Grounding: Study and Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omar Shaikh",
      "Hussein Mozannar",
      "Gagan Bansal",
      "Adam Fourney",
      "Eric Horvitz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1017": {
    "title": "Substance over Style: Evaluating Proactive Conversational Coaching Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vidya Srinivas",
      "Xuhai Xu",
      "Xin Liu",
      "Kumar Ayush",
      "Isaac Galatzer-Levy",
      "Shwetak Patel",
      "Daniel McDuff",
      "Tim Althoff"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1018": {
    "title": "Open-World Planning via Lifted Regression with LLM-Inferred Affordances for Embodied Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotian Liu",
      "Ali Pesaranghader",
      "Hanze Li",
      "Punyaphat Sukcharoenchaikul",
      "Jaehong Kim",
      "Tanmana Sadhu",
      "Hyejeong Jeon",
      "Scott Sanner"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1019": {
    "title": "(RSA)²: A Rhetorical-Strategy-Aware Rational Speech Act Framework for Figurative Language Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cesare Spinoso-Di Piano",
      "David Eric Austin",
      "Pablo Piantanida",
      "Jackie CK Cheung"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1020": {
    "title": "SYNTHIA: Novel Concept Design with Affordance Composition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeonjeong Ha",
      "Xiaomeng Jin",
      "Jeonghwan Kim",
      "Jiateng Liu",
      "Zhenhailong Wang",
      "Khanh Duy Nguyen",
      "Ansel Blume",
      "Nanyun Peng",
      "Kai-Wei Chang",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1021": {
    "title": "Consistent Client Simulation for Motivational Interviewing-based Counseling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhe Yang",
      "Palakorn Achananuparp",
      "Heyan Huang",
      "Jing Jiang",
      "Nicholas Gabriel Lim",
      "Cameron Tan Shi Ern",
      "Phey Ling Kit",
      "Jenny Giam Xiuhui",
      "John Pinto",
      "Ee-Peng Lim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1022": {
    "title": "AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naba Rizvi",
      "Harper Strickland",
      "Daniel Gitelman",
      "Alexis Morales Flores",
      "Tristan Cooper",
      "Aekta Kallepalli",
      "Akshat Alurkar",
      "Haaset Owens",
      "Saleha Ahmedi",
      "Isha Khirwadkar",
      "Imani N. S. Munyaka",
      "Nedjma Ousidhoum"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1023": {
    "title": "Structural Reasoning Improves Molecular Understanding of LLM",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhui Jang",
      "Jaehyung Kim",
      "Sungsoo Ahn"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1024": {
    "title": "CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhe Yang",
      "Palakorn Achananuparp",
      "Heyan Huang",
      "Jing Jiang",
      "Phey Ling Kit",
      "Nicholas Gabriel Lim",
      "Cameron Tan Shi Ern",
      "Ee-Peng Lim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1025": {
    "title": "Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kuang Wang",
      "Xianfei Li",
      "Shenghao Yang",
      "Li Zhou",
      "Feng Jiang",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1026": {
    "title": "Targeted Syntactic Evaluation for Grammatical Error Correction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aomi Koyama",
      "Masato Mita",
      "Su-Youn Yoon",
      "Yasufumi Takama",
      "Mamoru Komachi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1027": {
    "title": "VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingyu Song",
      "Tongyan Hu",
      "Guo Gan",
      "Yilun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1028": {
    "title": "Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Suh",
      "Erfan Jahanparast",
      "Suhong Moon",
      "Minwoo Kang",
      "Serina Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1029": {
    "title": "TESS 2: A Large-Scale Generalist Diffusion Language Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaesung Tae",
      "Hamish Ivison",
      "Sachin Kumar",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1030": {
    "title": "KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shinwoo Park",
      "Shubin Kim",
      "Do-Kyung Kim",
      "Yo-Sub Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1031": {
    "title": "Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanbing Liu",
      "Haoyang Li",
      "Xiaokang Zhang",
      "Ruotong Chen",
      "Haiyong Xu",
      "Tian Tian",
      "Qi Qi",
      "Jing Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1032": {
    "title": "On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh Duc Bui",
      "Kyung Eun Park",
      "Goran Glavaš",
      "Fabian David Schmidt",
      "Katharina Von Der Wense"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1033": {
    "title": "CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aashish Anantha Ramakrishnan",
      "Aadarsh Anantha Ramakrishnan",
      "Dongwon Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1034": {
    "title": "Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Zhou",
      "Barbara Di Eugenio"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1035": {
    "title": "Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Li",
      "Guangda Huzhang",
      "Haibo Zhang",
      "Xiting Wang",
      "Anxiang Zeng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1036": {
    "title": "LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongil Yang",
      "Minjin Kim",
      "Sunghwan Kim",
      "Beong-woo Kwak",
      "Minjun Park",
      "Jinseok Hong",
      "Woontack Woo",
      "Jinyoung Yeo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1037": {
    "title": "Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochun Wang",
      "Sendong Zhao",
      "Jingbo Wang",
      "Zewen Qiang",
      "Bing Qin",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1038": {
    "title": "The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Zhang",
      "Juan Zhai",
      "Shiqing Ma",
      "Qingshuang Bao",
      "Weipeng Jiang",
      "Qian Wang",
      "Chao Shen",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1039": {
    "title": "K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minkyeong Jeon",
      "Hyemin Jeong",
      "Yerang Kim",
      "Jiyoung Kim",
      "Jae Hyeon Cho",
      "Byung-Jun Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1040": {
    "title": "THOR-MoE: Hierarchical Task-Guided and Context-Responsive Routing for Neural Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1041": {
    "title": "Neuron Empirical Gradient: Discovering and Quantifying Neurons' Global Linear Controllability",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zhao",
      "Zehui Jiang",
      "Naoki Yoshinaga"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1042": {
    "title": "Can Third Parties Read Our Emotions?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Li",
      "Yingfan Zhou",
      "Pranav Narayanan Venkit",
      "Halima Binte Islam",
      "Sneha Arya",
      "Shomir Wilson",
      "Sarah Rajtmajer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1043": {
    "title": "OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nghia Huynh Nguyen Hieu",
      "Ngoc Son Nguyen",
      "Huynh Nguyen Dang",
      "Thieu Vo",
      "Truong-Son Hy",
      "Van Nguyen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1044": {
    "title": "World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyin Wang",
      "Zhaoye Fei",
      "Qinyuan Cheng",
      "Shiduo Zhang",
      "Panpan Cai",
      "Jinlan Fu",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1045": {
    "title": "JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Chu",
      "Yugeng Liu",
      "Ziqing Yang",
      "Xinyue Shen",
      "Michael Backes",
      "Yang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1046": {
    "title": "CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaqiang Tang",
      "Jian Li",
      "Keyu Hu",
      "Nan Du",
      "Xiaolong Li",
      "Xi Zhang",
      "Weigao Sun",
      "Sihong Xie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1047": {
    "title": "Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqiao Tan",
      "Shizhu He",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1048": {
    "title": "Enhancing Mathematical Reasoning in LLMs by Stepwise Correction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Wu",
      "Qingkai Zeng",
      "Zhihan Zhang",
      "Zhaoxuan Tan",
      "Chao Shen",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1049": {
    "title": "PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huachuan Qiu",
      "Zhenzhong Lan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1050": {
    "title": "Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Didi Zhang",
      "Yaxin Fan",
      "Peifeng Li",
      "Qiaoming Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1051": {
    "title": "Exclusion of Thought: Mitigating Cognitive Load in Large Language Models for Enhanced Reasoning in Multiple-Choice Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihang Fu",
      "Yongbin Qin",
      "Ruizhang Huang",
      "Yanping Chen",
      "Yulin Zhou",
      "Lintao Long"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1052": {
    "title": "Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Qu",
      "Yiran Wang",
      "Jiannan Mao",
      "Chenchen Ding",
      "Hideki Tanaka",
      "Masao Utiyama",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1053": {
    "title": "VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yikun Wang",
      "Siyin Wang",
      "Qinyuan Cheng",
      "Zhaoye Fei",
      "Liang Ding",
      "Qipeng Guo",
      "Dacheng Tao",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1054": {
    "title": "Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "JianXing Liao",
      "Junyan Xu",
      "Yatao Sun",
      "Maowen Tang",
      "Sicheng He",
      "Jingxian Liao",
      "Shui Yu",
      "Yun Li",
      "Xiaohong Guan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1055": {
    "title": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianli Ma",
      "Dongrui Liu",
      "Qian Chen",
      "Linfeng Zhang",
      "Jing Shao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1056": {
    "title": "Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiakang Yuan",
      "Xiangchao Yan",
      "Bo Zhang",
      "Tao Chen",
      "Botian Shi",
      "Wanli Ouyang",
      "Yu Qiao",
      "Lei Bai",
      "Bowen Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1057": {
    "title": "PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Luo",
      "Yingjie Li",
      "Xiangkun Hu",
      "Qinglin Qi",
      "Fang Guo",
      "Qipeng Guo",
      "Zheng Zhang",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1058": {
    "title": "Prompt-Guided Internal States for Hallucination Detection of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fujie Zhang",
      "Peiqi Yu",
      "Biao Yi",
      "Baolei Zhang",
      "Tong Li",
      "Zheli Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1059": {
    "title": "Typology-Guided Adaptation in Multilingual Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ndapa Nakashole"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1060": {
    "title": "Don't Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Orfeas Menis Mastromichalakis",
      "Jason Liartis",
      "Kristina Rose",
      "Antoine Isaac",
      "Giorgos Stamou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1061": {
    "title": "ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangjian Yin",
      "Peijie Huang",
      "JiaTian Chen",
      "Haojing Huang",
      "Yuhong Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1062": {
    "title": "FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinggang Zhang",
      "Zhishang Xiang",
      "Yilin Xiao",
      "Le Wang",
      "Junhui Li",
      "Xinrun Wang",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1063": {
    "title": "Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanghui Ye",
      "Huan Zhao",
      "Zhixue Zhao",
      "Xupeng Zha",
      "Yang Liu",
      "Zhihua Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1064": {
    "title": "Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yupu Hao",
      "Pengfei Cao",
      "Zhuoran Jin",
      "Huanxuan Liao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1065": {
    "title": "GUICourse: From General Vision Language Model to Versatile GUI Agent",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentong Chen",
      "Junbo Cui",
      "Jinyi Hu",
      "Yujia Qin",
      "Junjie Fang",
      "Yue Zhao",
      "Chongyi Wang",
      "Jun Liu",
      "Guirong Chen",
      "Yupeng Huo",
      "Yuan Yao",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1066": {
    "title": "Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "ChaeHun Park",
      "Yujin Baek",
      "Jaeseok Kim",
      "Yu-Jung Heo",
      "Du-Seong Chang",
      "Jaegul Choo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1067": {
    "title": "Maximizing the Effectiveness of Larger BERT Models for Compression",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen-Shu Fan",
      "Su Lu",
      "Shangyu Xing",
      "Xin-Chun Li",
      "De-Chuan Zhan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1068": {
    "title": "Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh Le-Cong",
      "Bach Le",
      "Toby Murray"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1069": {
    "title": "HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixiong Su",
      "Yichen Wang",
      "Herun Wan",
      "Zhaohan Zhang",
      "Minnan Luo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1070": {
    "title": "IndicSynth: A Large-Scale Multilingual Synthetic Speech Dataset for Low-Resource Indian Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divya V Sharma",
      "Vijval Ekbote",
      "Anubha Gupta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1071": {
    "title": "Reinforced IR: A Self-Boosting Framework For Domain-Adapted Information Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaofan Li",
      "Jianlyu Chen",
      "Yingxia Shao",
      "Chaozhuo Li",
      "Quanqing Xu",
      "Defu Lian",
      "Zheng Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1072": {
    "title": "CoIR: A Comprehensive Benchmark for Code Information Retrieval Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyang Li",
      "Kuicai Dong",
      "Yi Quan Lee",
      "Wei Xia",
      "Hao Zhang",
      "Xinyi Dai",
      "Yasheng Wang",
      "Ruiming Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1073": {
    "title": "Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Delong Zeng",
      "Yuexiang Xie",
      "Yaliang Li",
      "Ying Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1074": {
    "title": "JoPA: Explaining Large Language Model's Generation via Joint Prompt Attribution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yurui Chang",
      "Bochuan Cao",
      "Yujia Wang",
      "Jinghui Chen",
      "Lu Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1075": {
    "title": "Proxy-Driven Robust Multimodal Sentiment Analysis with Incomplete Data",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aoqiang Zhu",
      "Min Hu",
      "Xiaohua Wang",
      "Jiaoyun Yang",
      "Yiming Tang",
      "Ning An"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1076": {
    "title": "Not All Terms Matter: Recall-Oriented Adaptive Learning for PLM-aided Query Expansion in Open-Domain Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinran Chen",
      "Ben He",
      "Xuanang Chen",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1077": {
    "title": "A Mutual Information Perspective on Knowledge Graph Embedding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiang Li",
      "Xiangdong Su",
      "Zehua Duo",
      "Tian Lan",
      "Xiaotao Guo",
      "Guanglai Gao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1078": {
    "title": "Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lihao Sun",
      "Chengzhi Mao",
      "Valentin Hofmann",
      "Xuechunzi Bai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1079": {
    "title": "IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinghua Zhang",
      "Haiyang Yu",
      "Cheng Fu",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1080": {
    "title": "ProMALex: Progressive Modular Adapters for Multi-Jurisdictional Legal Language Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Santosh T.y.s.s",
      "Mohamed Hesham Elganayni"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1081": {
    "title": "Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingzhe Li",
      "Jing Xiang",
      "Qishen Zhang",
      "Kaiyang Wan",
      "Xiuying Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1082": {
    "title": "Disentangling Language and Culture for Evaluating Multilingual Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Ying",
      "Wei Tang",
      "Yiran Zhao",
      "Yixin Cao",
      "Yu Rong",
      "Wenxuan Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1083": {
    "title": "Detecting Sockpuppetry on Wikipedia Using Meta-Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luc Raszewski",
      "Christine de Kock"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1084": {
    "title": "Diversity-oriented Data Augmentation with Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zaitian Wang",
      "Jinghan Zhang",
      "Xinhao Zhang",
      "Kunpeng Liu",
      "Pengfei Wang",
      "Yuanchun Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1085": {
    "title": "CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingqian Zhao",
      "Bingbing Wang",
      "Geng Tu",
      "Yice Zhang",
      "Qianlong Wang",
      "Bin Liang",
      "Jing Li",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1086": {
    "title": "RiOT: Efficient Prompt Refinement with Residual Optimization Tree",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyi Zhou",
      "Zhengyan Shi",
      "Yuan Yao",
      "Lei Liang",
      "Huajun Chen",
      "Qiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1087": {
    "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinbei Ma",
      "Yiting Wang",
      "Yao Yao",
      "Tongxin Yuan",
      "Aston Zhang",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1088": {
    "title": "Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rong-Cheng Tu",
      "Zi-Ao Ma",
      "Tian Lan",
      "Yuehao Zhao",
      "Heyan Huang",
      "Xian-Ling Mao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1089": {
    "title": "Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongzhi Zhu",
      "Xiangyu Liu",
      "Zequn Sun",
      "Yiwei Wang",
      "Wei Hu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1090": {
    "title": "TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyi He",
      "Yihao Liu",
      "Mengyu Zhou",
      "Yeye He",
      "Haoyu Dong",
      "Shi Han",
      "Zejian Yuan",
      "Dongmei Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1091": {
    "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maosongcao Maosongcao",
      "Taolin Zhang",
      "Mo Li",
      "Chuyu Zhang",
      "Yunxin Liu",
      "Conghui He",
      "Haodong Duan",
      "Songyang Zhang",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1092": {
    "title": "CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruixiang Feng",
      "Shen Gao",
      "Xiuying Chen",
      "Lisi Chen",
      "Shuo Shang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1093": {
    "title": "Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junzhuo Li",
      "Bo Wang",
      "Xiuze Zhou",
      "Peijie Jiang",
      "Jia Liu",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1094": {
    "title": "ChartLens: Fine-grained Visual Attribution in Charts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manan Suri",
      "Puneet Mathur",
      "Nedim Lipka",
      "Franck Dernoncourt",
      "Ryan A. Rossi",
      "Dinesh Manocha"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1095": {
    "title": "LESA: Learnable LLM Layer Scaling-Up",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Yang",
      "Zouying Cao",
      "Xinbei Ma",
      "Yao Yao",
      "Zhi Chen",
      "Libo Qin",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1096": {
    "title": "MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochen Xue",
      "Feilong Tang",
      "Ming Hu",
      "Yexin Liu",
      "Qidong Huang",
      "Yulong Li",
      "Chengzhi Liu",
      "Zhongxing Xu",
      "Chong Zhang",
      "Chun-Mei Feng",
      "Yutong Xie",
      "Imran Razzak",
      "Zongyuan Ge",
      "Jionglong Su",
      "Junjun He",
      "Yu Qiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1097": {
    "title": "Towards the Law of Capacity Gap in Distilling Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhang",
      "Qiuchi Li",
      "Dawei Song",
      "Zheyu Ye",
      "Yan Gao",
      "Yao Hu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1098": {
    "title": "WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rajath Rao",
      "Adithya V Ganesan",
      "Oscar Kjell",
      "Jonah Luby",
      "Akshay Raghavan",
      "Scott M. Feltman",
      "Whitney Ringwald",
      "Ryan L. Boyd",
      "Benjamin J. Luft",
      "Camilo J. Ruggero",
      "Neville Ryant",
      "Roman Kotov",
      "H. Schwartz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1099": {
    "title": "Keys to Robust Edits: From Theoretical Insights to Practical Advances",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianhao Yan",
      "Futing Wang",
      "Yun Luo",
      "Yafu Li",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1100": {
    "title": "Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Zhuang",
      "Bin Wu",
      "Jiyu Cui",
      "Kehua Feng",
      "Xiaotong Li",
      "Huabin Xing",
      "Keyan Ding",
      "Qiang Zhang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1101": {
    "title": "MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "María Andrea Cruz Blandón",
      "Jayasimha Talur",
      "Bruno Charron",
      "Dong Liu",
      "Saab Mansour",
      "Marcello Federico"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1102": {
    "title": "The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufang Liu",
      "Yao Du",
      "Tao Ji",
      "Jianing Wang",
      "Yang Liu",
      "Yuanbin Wu",
      "Aimin Zhou",
      "Mengdi Zhang",
      "Xunliang Cai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1103": {
    "title": "The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chulun Zhou",
      "Qiujing Wang",
      "Mo Yu",
      "Xiaoqian Yue",
      "Rui Lu",
      "Jiangnan Li",
      "Yifan Zhou",
      "Shunchi Zhang",
      "Jie Zhou",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1104": {
    "title": "S2R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruotian Ma",
      "Peisong Wang",
      "Cheng Liu",
      "Xingyan Liu",
      "Jiaqi Chen",
      "Bang Zhang",
      "Xin Zhou",
      "Nan Du",
      "Jia Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1105": {
    "title": "Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Li",
      "Ziyi Su",
      "Yun Xue",
      "Zhiliang Tian",
      "Yiping Song",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1106": {
    "title": "Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deokhyung Kang",
      "Jeonghun Cho",
      "Yejin Jeon",
      "Sunbin Jang",
      "Minsub Lee",
      "Jawoon Cho",
      "Gary Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1107": {
    "title": "STRICTA: Structured Reasoning in Critical Text Assessment for Peer Review and Beyond",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nils Dycke",
      "Matej Zečević",
      "Ilia Kuznetsov",
      "Beatrix Suess",
      "Kristian Kersting",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1108": {
    "title": "XDAC: XAI-Driven Detection and Attribution of LLM-Generated News Comments in Korean",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wooyoung Go",
      "Hyoungshick Kim",
      "Alice Oh",
      "Yongdae Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1109": {
    "title": "CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglong Luo",
      "Guanzhong Chen",
      "Yehong Zhang",
      "Shiyu Liu",
      "Hui Wang",
      "Yue Yu",
      "Xun Zhou",
      "Yuan Qi",
      "Zenglin Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1110": {
    "title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prarabdh Shukla",
      "Wei Yin Chong",
      "Yash Patel",
      "Brennan Schaffner",
      "Danish Pruthi",
      "Arjun Bhagoji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1111": {
    "title": "EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Che Hyun Lee",
      "Heeseung Kim",
      "Jiheum Yeom",
      "Sungroh Yoon"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1112": {
    "title": "TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jafar Isbarov",
      "Arofat Akhundjanova",
      "Mammad Hajili",
      "Kavsar Huseynova",
      "Dmitry Gaynullin",
      "Anar Rzayev",
      "Osman Tursun",
      "Aizirek Turdubaeva",
      "Ilshat Saetov",
      "Rinat Kharisov",
      "Saule Belginova",
      "Ariana Kenbayeva",
      "Amina Alisheva",
      "Abdullatif Köksal",
      "Samir Rustamov",
      "Duygu Ataman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1113": {
    "title": "Look Both Ways and No Sink: Converting LLMs into Text Encoders without Training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyong Lin",
      "Haoyi Wu",
      "Shu Wang",
      "Kewei Tu",
      "Zilong Zheng",
      "Zixia Jia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1114": {
    "title": "A Statistical and Multi-Perspective Revisiting of the Membership Inference Attack in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Chen",
      "Namgi Han",
      "Yusuke Miyao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1115": {
    "title": "Around the World in 24 Hours: Probing LLM Knowledge of Time and Place",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carolin Holtermann",
      "Paul Röttger",
      "Anne Lauscher"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1116": {
    "title": "Mining the uncertainty patterns of humans and models in the annotation of moral foundations and human values",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neele Falk",
      "Gabriella Lapesa"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1117": {
    "title": "What do you call a dog that is incontrovertibly true? Dogma\": Testing LLM Generalization through Humor",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessio Cocchieri",
      "Luca Ragazzi",
      "Paolo Italiani",
      "Giuseppe Tagliavini",
      "Gianluca Moro"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1118": {
    "title": "Towards Harmonized Uncertainty Estimation for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Li",
      "Jing Long",
      "Muge Qi",
      "Heming Xia",
      "Lei Sha",
      "Peiyi Wang",
      "Zhifang Sui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1119": {
    "title": "VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anudeex Shetty",
      "Amin Beheshti",
      "Mark Dras",
      "Usman Naseem"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1120": {
    "title": "Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Sun",
      "Zongmin Zhang",
      "Xinyue Shen",
      "Ziyi Zhang",
      "Yule Liu",
      "Michael Backes",
      "Yang Zhang",
      "Xinlei He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1121": {
    "title": "From English to Second Language Mastery: Enhancing LLMs with Cross-Lingual Continued Instruction Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linjuan Wu",
      "Hao-Ran Wei",
      "Baosong Yang",
      "Weiming Lu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1122": {
    "title": "WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anudeex Shetty",
      "Qiongkai Xu",
      "Jey Han Lau"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1123": {
    "title": "HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Chen",
      "Ang Lv",
      "Jian Luan",
      "Bin Wang",
      "Wei Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1124": {
    "title": "One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Yi",
      "Yuhui Xu",
      "Heng Chang",
      "Yuan Meng",
      "Tong Zhang",
      "Jia Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1125": {
    "title": "Beyond Logits: Aligning Feature Dynamics for Effective Knowledge Distillation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guoqiang Gong",
      "Jiaxing Wang",
      "Jin Xu",
      "Deping Xiang",
      "Zicheng Zhang",
      "Leqi Shen",
      "Yifeng Zhang",
      "JunhuaShu JunhuaShu",
      "ZhaolongXing ZhaolongXing",
      "Zhen Chen",
      "Pengzhang Liu",
      "Ke Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1126": {
    "title": "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyang Yuan",
      "Huazuo Gao",
      "Damai Dai",
      "Junyu Luo",
      "Liang Zhao",
      "Zhengyan Zhang",
      "Zhenda Xie",
      "Yuxing Wei",
      "Lean Wang",
      "Zhiping Xiao",
      "Yuqing Wang",
      "Chong Ruan",
      "Ming Zhang",
      "Wenfeng Liang",
      "Wangding Zeng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1127": {
    "title": "DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yayu Long",
      "Kewei Chen",
      "Long Jin",
      "Mingsheng Shang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1128": {
    "title": "MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kwangwook Seo",
      "Donguk Kwon",
      "Dongha Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1129": {
    "title": "Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxi Huang",
      "Shaotian Yan",
      "Liang Xie",
      "Binbin Lin",
      "Sinan Fan",
      "Yue Xin",
      "Deng Cai",
      "Chen Shen",
      "Jieping Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1130": {
    "title": "Does the Emotional Understanding of LVLMs Vary Under High-Stress Environments and Across Different Demographic Attributes?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewook Lee",
      "Yeajin Jang",
      "Oh-Woog Kwon",
      "Harksoo Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1131": {
    "title": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suman Adhya",
      "Debarshi Kumar Sanyal"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1132": {
    "title": "Learning to Look at the Other Side: A Semantic Probing Study of Word Embeddings in LLMs with Enabled Bidirectional Attention",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoxin Feng",
      "Jianfei Ma",
      "Emmanuele Chersoni",
      "Xiaojing Zhao",
      "Xiaoyi Bao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1133": {
    "title": "Tracing and Dissecting How LLMs Recall Factual Knowledge for Real World Questions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqun Wang",
      "Chaoqun Wan",
      "Sile Hu",
      "Yonggang Zhang",
      "Xiang Tian",
      "Yaowu Chen",
      "Xu Shen",
      "Jieping Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1134": {
    "title": "Employing Discourse Coherence Enhancement to Improve Cross-Document Event and Entity Coreference Resolution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Chen",
      "Peifeng Li",
      "Qiaoming Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1135": {
    "title": "Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaobo Wang",
      "Xiangqi Jin",
      "Ziming Wang",
      "Jize Wang",
      "Jiajun Zhang",
      "Kaixin Li",
      "Zichen Wen",
      "Zhong Li",
      "Conghui He",
      "Xuming Hu",
      "Linfeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1136": {
    "title": "Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Tang",
      "Xianghe Pang",
      "Zexi Liu",
      "Bohan Tang",
      "Rui Ye",
      "Tian Jin",
      "Xiaowen Dong",
      "Yanfeng Wang",
      "Siheng Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1137": {
    "title": "SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yige Xu",
      "Xu Guo",
      "Zhiwei Zeng",
      "Chunyan Miao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1138": {
    "title": "FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seunghee Kim",
      "Changhyeon Kim",
      "Taeuk Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1139": {
    "title": "Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengru Wang",
      "Ziwen Xu",
      "Shengyu Mao",
      "Shumin Deng",
      "Zhaopeng Tu",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1140": {
    "title": "MobiLoRA: Accelerating LoRA-based LLM Inference on Mobile Devices via Context-aware KV Cache Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Borui Li",
      "Yitao Wang",
      "Haoran Ma",
      "Ligeng Chen",
      "Jun Xiao",
      "Shuai Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1141": {
    "title": "Language Models Resist Alignment: Evidence From Data Compression",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Ji",
      "Kaile Wang",
      "Tianyi Alex Qiu",
      "Boyuan Chen",
      "Jiayi Zhou",
      "Changye Li",
      "Hantao Lou",
      "Josef Dai",
      "Yunhuai Liu",
      "Yaodong Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1142": {
    "title": "Beyond the Answer: Advancing Multi-Hop QA with Fine-Grained Graph Reasoning and Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qichuan Liu",
      "Chentao Zhang",
      "Chenfeng Zheng",
      "Guosheng Hu",
      "Xiaodong Li",
      "Zhihong Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1143": {
    "title": "Mamba Knockout for Unraveling Factual Information Flow",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nir Endy",
      "Idan Daniel Grosbard",
      "Yuval Ran-Milo",
      "Yonatan Slutzky",
      "Itay Tshuva",
      "Raja Giryes"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1144": {
    "title": "Small Changes, Big Impact: How Manipulating a Few Neurons Can Drastically Alter LLM Aggression",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewook Lee",
      "Junseo Jang",
      "Oh-Woog Kwon",
      "Harksoo Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1145": {
    "title": "Marco-o1 v2: Towards Widening The Distillation Bottleneck for Reasoning Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huifeng Yin",
      "Yu Zhao",
      "Minghao Wu",
      "Xuanfan Ni",
      "Bo Zeng",
      "Huaiyu.wh Huaiyu.wh",
      "Tianqi Shi",
      "Liangying Shao",
      "Chenyang Lyu",
      "Longyue Wang",
      "Weihua Luo",
      "Kaifu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1146": {
    "title": "Curiosity-Driven Reinforcement Learning from Human Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Sun",
      "Yekun Chai",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1147": {
    "title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehan Wang",
      "Ke Lei",
      "Chen Zhu",
      "Jiawei Huang",
      "Sashuai Zhou",
      "Luping Liu",
      "Xize Cheng",
      "Shengpeng Ji",
      "Zhenhui Ye",
      "Tao Jin",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1148": {
    "title": "CoE: A Clue of Emotion Framework for Emotion Recognition in Conversations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyu Shen",
      "Yunhe Pang",
      "Yanghui Rao",
      "Jianxing Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1149": {
    "title": "MPO: Multilingual Safety Alignment via Reward Gap Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weixiang Zhao",
      "Yulin Hu",
      "Yang Deng",
      "Tongtong Wu",
      "Wenxuan Zhang",
      "Jiahe Guo",
      "An Zhang",
      "Yanyan Zhao",
      "Bing Qin",
      "Tat-Seng Chua",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1150": {
    "title": "QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyin Wang",
      "Wenyi Yu",
      "Xianzhao Chen",
      "Xiaohai Tian",
      "Jun Zhang",
      "Lu Lu",
      "Yu Tsao",
      "Junichi Yamagishi",
      "Yuxuan Wang",
      "Chao Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1151": {
    "title": "On the Relation Between Fine-Tuning, Topological Properties, and Task Performance in Sense-Enhanced Embeddings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deniz Ekin Yavas",
      "Timothée Bernard",
      "Benoit Crabbé",
      "Laura Kallmeyer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1152": {
    "title": "Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parth Thakkar",
      "Ankush Agarwal",
      "Prasad Kasu",
      "Pulkit Bansal",
      "Chaitanya Devaguptapu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1153": {
    "title": "Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongquan He",
      "Wenyuan Zhang",
      "Xuancheng Huang",
      "Peng Zhang",
      "Lingxun Meng",
      "Xiang Zhou",
      "Ke Zeng",
      "Xunliang Cai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1154": {
    "title": "Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yooseop Lee",
      "Suin Kim",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1155": {
    "title": "Exploring Explanations Improves the Robustness of In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ukyo Honda",
      "Tatsushi Oka"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1156": {
    "title": "Prediction Hubs are Context-Informed Frequent Tokens in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beatrix Miranda Ginn Nielsen",
      "Iuri Macocco",
      "Marco Baroni"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1157": {
    "title": "Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiming Ge",
      "Shuhao Xing",
      "Songyang Gao",
      "Yunhua Zhou",
      "Yicheng Zou",
      "Songyang Zhang",
      "Zhi Chen",
      "Hang Yan",
      "Qi Zhang",
      "Qipeng Guo",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1158": {
    "title": "CRUXEVAL-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyang Xu",
      "Jialun Cao",
      "Yaojie Lu",
      "Ming Wen",
      "Hongyu Lin",
      "Xianpei Han",
      "Ben He",
      "Shing-Chi Cheung",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1159": {
    "title": "Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhen Zhang",
      "Tao Feng",
      "Jiaxuan You"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1160": {
    "title": "Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diana Galvan-Sosa",
      "Gabrielle Gaudeau",
      "Pride Kavumba",
      "Yunmeng Li",
      "Hongyi Gu",
      "Zheng Yuan",
      "Keisuke Sakaguchi",
      "Paula Buttery"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1161": {
    "title": "A Dual-Mind Framework for Strategic and Expressive Negotiation Agent",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Liu",
      "Lida Shi",
      "Rui Song",
      "Hao Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1162": {
    "title": "Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Wu",
      "Gefei Gu",
      "Yanan Zheng",
      "Dit-Yan Yeung",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1163": {
    "title": "Revisiting Scaling Laws for Language Models: The Role of Data Quality and Training Strategies",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengyu Chen",
      "Siqi Wang",
      "Teng Xiao",
      "Yudong Wang",
      "Shiqi Chen",
      "Xunliang Cai",
      "Junxian He",
      "Jingang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1164": {
    "title": "Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marc Feger",
      "Katarina Boland",
      "Stefan Dietze"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1165": {
    "title": "Enhancing Machine Translation with Self-Supervised Preference Data",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxiang Sun",
      "Ruize Gao",
      "Pei Zhang",
      "Baosong Yang",
      "Rui Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1166": {
    "title": "Unveil: Unified Visual-Textual Integration and Distillation for Multi-modal Document Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Sun",
      "Yingyan Hou",
      "Jiayan Guo",
      "Bo Wang",
      "Chunyu Yang",
      "Jinsong Ni",
      "Yan Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1167": {
    "title": "Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ante Wang",
      "Linfeng Song",
      "Ye Tian",
      "Dian Yu",
      "Haitao Mi",
      "Xiangyu Duan",
      "Zhaopeng Tu",
      "Jinsong Su",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1168": {
    "title": "MEXMA: Token-level objectives improve sentence representations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "João Maria Janeiro",
      "Benjamin Piwowarski",
      "Patrick Gallinari",
      "Loic Barrault"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1169": {
    "title": "Uncertainty-Aware Iterative Preference Optimization for Enhanced LLM Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Li",
      "Hehuan Liu",
      "Yaxin Zhou",
      "ZhaoYang Gui",
      "Xudong Weng",
      "Yi Yuan",
      "Zheng Wei",
      "Zang Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1170": {
    "title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhexuan Wang",
      "Yutong Wang",
      "Xuebo Liu",
      "Liang Ding",
      "Miao Zhang",
      "Jie Liu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1171": {
    "title": "Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Xiao",
      "Jiashuo Wang",
      "Qiancheng Xu",
      "Changhe Song",
      "Chunpu Xu",
      "Yi Cheng",
      "Wenjie Li",
      "Pengfei Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1172": {
    "title": "Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Zeng",
      "Chenyang Lyu",
      "Sinuo Liu",
      "Mingyan Zeng",
      "Minghao Wu",
      "Xuanfan Ni",
      "Tianqi Shi",
      "Yu Zhao",
      "Yefeng Liu",
      "Chenyu Zhu",
      "Ruizhe Li",
      "Jiahui Geng",
      "Qing Li",
      "Yu Tong",
      "Longyue Wang",
      "Weihua Luo",
      "Kaifu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1173": {
    "title": "Representation Bending for Large Language Model Safety",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashkan Yousefpour",
      "Taeheon Kim",
      "Ryan Sungmo Kwon",
      "Seungbeen Lee",
      "Wonje Jeung",
      "Seungju Han",
      "Alvin Wan",
      "Harrison Ngan",
      "Youngjae Yu",
      "Jonghyun Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1174": {
    "title": "Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenghao Xiao",
      "Hou Pong Chan",
      "Hao Zhang",
      "Mahani Aljunied",
      "Lidong Bing",
      "Noura Al Moubayed",
      "Yu Rong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1175": {
    "title": "Enhancing Retrieval-Augmented Generation via Evidence Tree Search",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Sun",
      "Hengyi Cai",
      "Yuchen Li",
      "Xuanbo Fan",
      "Xiaochi Wei",
      "Shuaiqiang Wang",
      "Yan Zhang",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1176": {
    "title": "HalluLens: LLM Hallucination Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yejin Bang",
      "Ziwei Ji",
      "Alan Schelten",
      "Anthony Hartshorn",
      "Tara Fowler",
      "Cheng Zhang",
      "Nicola Cancedda",
      "Pascale Fung"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1177": {
    "title": "DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aili Chen",
      "Chengyu Du",
      "Jiangjie Chen",
      "Jinghan Xu",
      "Yikai Zhang",
      "Siyu Yuan",
      "Zulong Chen",
      "Liangyue Li",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1178": {
    "title": "Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Liu",
      "Wenxuan Wang",
      "Su Yihang",
      "Jingyuan Huang",
      "Yudi Zhang",
      "Cheng-Yi Li",
      "Wenting Chen",
      "Xiaohan Xing",
      "Kao-Jung Chang",
      "Linlin Shen",
      "Michael R. Lyu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1179": {
    "title": "InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zifu Wan",
      "Yaqi Xie",
      "Ce Zhang",
      "Zhiqiu Lin",
      "Zihan Wang",
      "Simon Stepputtis",
      "Deva Ramanan",
      "Katia P. Sycara"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1180": {
    "title": "GRaMPa: Subword Regularisation by Skewing Uniform Segmentation Distributions with an Efficient Path-counting Markov Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Bauwens",
      "David Kaczér",
      "Miryam De Lhoneux"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1181": {
    "title": "Evaluating the Evaluation of Diversity in Commonsense Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhui Zhang",
      "Bei Peng",
      "Danushka Bollegala"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1182": {
    "title": "Generate First, Then Sample: Enhancing Fake News Detection with LLM-Augmented Reinforced Sampling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhao Tong",
      "Yimeng Gu",
      "Huidong Liu",
      "Qiang Liu",
      "Shu Wu",
      "Haichao Shi",
      "Xiao-Yu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1183": {
    "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhang",
      "Ruijie Yu",
      "Jidong Tian",
      "Feng Zhu",
      "Jiapeng Liu",
      "Xiaokang Yang",
      "Yaohui Jin",
      "Yanyan Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1184": {
    "title": "Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Ni",
      "Keping Bi",
      "Jiafeng Guo",
      "Lulu Yu",
      "Baolong Bi",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1185": {
    "title": "ALGEN: Few-shot Inversion Attacks on Textual Embeddings via Cross-Model Alignment and Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyi Chen",
      "Qiongkai Xu",
      "Johannes Bjerva"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1186": {
    "title": "Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Li",
      "Tianhua Zhang",
      "Xixin Wu",
      "Hongyin Luo",
      "James R. Glass",
      "Helen M. Meng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1187": {
    "title": "STaR-SQL: Self-Taught Reasoner for Text-to-SQL",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingqian He",
      "Yongliang Shen",
      "Wenqi Zhang",
      "Qiuying Peng",
      "Jun Wang",
      "Weiming Lu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1188": {
    "title": "Fairness Beyond Performance: Revealing Reliability Disparities Across Groups in Legal NLP",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Santosh T.y.s.s",
      "Irtiza Chowdhury"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1189": {
    "title": "Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhao",
      "Li Du",
      "Xiao Ding",
      "Yangou Ouyang",
      "Hepeng Wang",
      "Kai Xiong",
      "Jinglong Gao",
      "Zhouhao Sun",
      "Dongliang Xu",
      "Qing Yang",
      "Dongchen Li",
      "Bing Qin",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1190": {
    "title": "FastMCTS: A Simple Sampling Strategy for Data Synthesis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiji Li",
      "Kai Lv",
      "Yunfan Shao",
      "Yichuan Ma",
      "Linyang Li",
      "Xiaoqing Zheng",
      "Xipeng Qiu",
      "Qipeng Guo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1191": {
    "title": "Dialogue-RAG: Enhancing Retrieval for LLMs via Node-Linking Utterance Rewriting",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiwei Li",
      "Teng Xiao",
      "Zuchao Li",
      "Ping Wang",
      "Mengjia Shen",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1192": {
    "title": "Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ethan Wilcox",
      "Cui Ding",
      "Giovanni Acampa",
      "Tiago Pimentel",
      "Alex Warstadt",
      "Tamar I Regev"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1193": {
    "title": "Evaluating LLMs for Portuguese Sentence Simplification with Linguistic Insights",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arthur Mariano Rocha De Azevedo Scalercio",
      "Elvis A. De Souza",
      "Maria José Bocorny Finatto",
      "Aline Paes"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1194": {
    "title": "LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hugo Pitorro",
      "Marcos Vinicius Treviso"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1195": {
    "title": "Improving Low-Resource Morphological Inflection via Self-Supervised Objectives",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Wiemerslage",
      "Katharina Von Der Wense"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1196": {
    "title": "Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingchaojie Feng",
      "Yiqun Sun",
      "Yandong Sun",
      "Minfeng Zhu",
      "Qiang Huang",
      "Anthony Kum Hoe Tung",
      "Wei Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1197": {
    "title": "BOOKCOREF: Coreference Resolution at Book Scale",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuliano Martinelli",
      "Tommaso Bonomo",
      "Pere-Lluís Huguet Cabot",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1198": {
    "title": "OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Yang",
      "Jingjing Fu",
      "Rui Wang",
      "Jinyu Wang",
      "Lei Song",
      "Jiang Bian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1199": {
    "title": "Alleviating Hallucinations from Knowledge Misalignment in Large Language Models via Selective Abstention Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Huang",
      "Xiaocheng Feng",
      "Weitao Ma",
      "Yuchun Fan",
      "Xiachong Feng",
      "Yuxuan Gu",
      "Yangfan Ye",
      "Liang Zhao",
      "Weihong Zhong",
      "Baoxin Wang",
      "Dayong Wu",
      "Guoping Hu",
      "Lingpeng Kong",
      "Tong Xiao",
      "Ting Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1200": {
    "title": "Retrospective Learning from Interactions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizhao Chen",
      "Mustafa Omer Gul",
      "Yiwei Chen",
      "Gloria Geng",
      "Anne Wu",
      "Yoav Artzi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1201": {
    "title": "Personalized Generation In Large Model Era: A Survey",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyan Xu",
      "Jinghao Zhang",
      "Alireza Salemi",
      "Xinting Hu",
      "Wenjie Wang",
      "Fuli Feng",
      "Hamed Zamani",
      "Xiangnan He",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1202": {
    "title": "Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junqi Gao",
      "Xiang Zou",
      "Ying Ai",
      "Dong Li",
      "Yichen Niu",
      "Biqing Qi",
      "Jianxing Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1203": {
    "title": "SOTOPIA-: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyuan Zhang",
      "Tianyun Liu",
      "Mengxiao Song",
      "Xiaodong Li",
      "Tingwen Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1204": {
    "title": "Can Language Models Replace Programmers for Coding? REPOCOD Says ‘Not Yet",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanchao Liang",
      "Nan Jiang",
      "Yiran Hu",
      "Lin Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1205": {
    "title": "Leveraging In-Context Learning for Political Bias Testing of LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Haller",
      "Jannis Vamvas",
      "Rico Sennrich",
      "Lena Ann Jäger"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1206": {
    "title": "ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Steven H Wang",
      "Maksim Zubkov",
      "Kexin Fan",
      "Sarah Harrell",
      "Yuyang Sun",
      "Wei Chen",
      "Andreas Plesner",
      "Roger Wattenhofer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1207": {
    "title": "LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qibing Ren",
      "Hao Li",
      "Dongrui Liu",
      "Zhanxu Xie",
      "Xiaoya Lu",
      "Yu Qiao",
      "Lei Sha",
      "Junchi Yan",
      "Lizhuang Ma",
      "Jing Shao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1208": {
    "title": "WAFFLE: Fine-tuning Multi-Modal Model for Automated Front-End Development",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanchao Liang",
      "Nan Jiang",
      "Shangshu Qian",
      "Lin Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1209": {
    "title": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bryan R Christ",
      "Zachary Gottesman",
      "Jonathan Kropko",
      "Thomas Hartvigsen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1210": {
    "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayeon Ki",
      "Rachel Rudinger",
      "Tianyi Zhou",
      "Marine Carpuat"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1211": {
    "title": "RefreshKV: Updating Small KV Cache During Long-form Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangyuan Xu",
      "Tanya Goyal",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1212": {
    "title": "SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weikai Lu",
      "Hao Peng",
      "Huiping Zhuang",
      "Cen Chen",
      "Ziqian Zeng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1213": {
    "title": "Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyao Yu",
      "Yuxiang Zhang",
      "Dongdong Zhang",
      "Xiao Liang",
      "Hengyuan Zhang",
      "Xingxing Zhang",
      "Mahmoud Khademi",
      "Hany Hassan Awadalla",
      "Junjie Wang",
      "Yujiu Yang",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1214": {
    "title": "Language Models Grow Less Humanlike beyond Phase Transition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tatsuya Aoyama",
      "Ethan Wilcox"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1215": {
    "title": "PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arkadiusz Modzelewski",
      "Witold Sosnowski",
      "Tiziano Labruna",
      "Adam Wierzbicki",
      "Giovanni Da San Martino"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1216": {
    "title": "Coordinating Chaos: A Structured Review of Linguistic Coordination Methodologies",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Roger Litterer",
      "David Jurgens",
      "Dallas Card"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1217": {
    "title": "iNews: A Multimodal Dataset for Modeling Personalized Affective Responses to News",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiancheng Hu",
      "Nigel Collier"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1218": {
    "title": "Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akhila Yerukola",
      "Saadia Gabriel",
      "Nanyun Peng",
      "Maarten Sap"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1219": {
    "title": "500xCompressor: Generalized Prompt Compression for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongqian Li",
      "Yixuan Su",
      "Nigel Collier"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1220": {
    "title": "Estimating Privacy Leakage of Augmented Contextual Knowledge in Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Flemings",
      "Bo Jiang",
      "Wanrong Zhang",
      "Zafar Takhirov",
      "Murali Annavaram"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1221": {
    "title": "Document-Level Event-Argument Data Augmentation for Challenging Role Types",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Gatto",
      "Omar Sharif",
      "Parker Seegmiller",
      "Sarah Masud Preum"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1222": {
    "title": "Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Roger Litterer",
      "David Jurgens",
      "Dallas Card"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1223": {
    "title": "Unravelling the Logic: Investigating the Generalisation of Transformers in Numerical Satisfiability Problems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tharindu Madusanka",
      "Marco Valentino",
      "Iqra Zahid",
      "Ian Pratt-Hartmann",
      "Riza Batista-Navarro"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1224": {
    "title": "The Nature of NLP: Analyzing Contributions in NLP Papers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aniket Pramanick",
      "Yufang Hou",
      "Saif M. Mohammad",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1225": {
    "title": "\\mathtt{GeLLM^3O}: Generalizing Large Language Models for Multi-property Molecule Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishal Dey",
      "Xiao Hu",
      "Xia Ning"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1226": {
    "title": "Follow-up Question Generation For Enhanced Patient-Provider Conversations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Gatto",
      "Parker Seegmiller",
      "Timothy E. Burdick",
      "Inas S. Khayal",
      "Sarah DeLozier",
      "Sarah Masud Preum"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1227": {
    "title": "Unveiling Privacy Risks in LLM Agent Memory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Wang",
      "Weiyi He",
      "Shenglai Zeng",
      "Zhen Xiang",
      "Yue Xing",
      "Jiliang Tang",
      "Pengfei He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1228": {
    "title": "Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emmanouil Zaranis",
      "Giuseppe Attanasio",
      "Sweta Agrawal",
      "Andre Martins"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1229": {
    "title": "Language Constrained Multimodal Hyper Adapter For Many-to-Many Multimodal Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nayu Liu",
      "Fanglong Yao",
      "Haoran Luo",
      "Yong Yang",
      "Chen Tang",
      "Bo Lv"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1230": {
    "title": "PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyang Song",
      "Zhaochen Su",
      "Xiaoye Qu",
      "Jiawei Zhou",
      "Yu Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1231": {
    "title": "Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyue Li",
      "Ziniu Zhang",
      "Lu Wang",
      "Hongyang R. Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1232": {
    "title": "Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Munachiso S Nwadike",
      "Zangir Iklassov",
      "Toluwani Aremu",
      "Tatsuya Hiraoka",
      "Benjamin Heinzerling",
      "Velibor Bojkovic",
      "Hilal AlQuabeh",
      "Martin Takáč",
      "Kentaro Inui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1233": {
    "title": "Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lang Gao",
      "Jiahui Geng",
      "Xiangliang Zhang",
      "Preslav Nakov",
      "Xiuying Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1234": {
    "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandru Coca",
      "Mark Gaynor",
      "Zhenxing Zhang",
      "Jianpeng Cheng",
      "Bo-Hsiang Tseng",
      "Peter Boothroyd",
      "Hector Martinez Alonso",
      "Diarmuid O Seaghdha",
      "Anders Johannsen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1235": {
    "title": "ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Yuan",
      "Zixiang Di",
      "Zhiqing Cui",
      "Guisong Yang",
      "Usman Naseem"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1236": {
    "title": "SARA: Salience-Aware Reinforced Adaptive Decoding for Large Language Models in Abstractive Summarization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nayu Liu",
      "Junnan Zhu",
      "Yiming Ma",
      "Zhicong Lu",
      "Wenlei Xu",
      "Yong Yang",
      "Jiang Zhong",
      "Kaiwen Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1237": {
    "title": "Embedding-Converter: A Unified Framework for Cross-Model Embedding Transformation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinsung Yoon",
      "Sercan O Arik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1238": {
    "title": "Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Tahmid Rahman Laskar",
      "Israt Jahan",
      "Elham Dolatabadi",
      "Chun Peng",
      "Enamul Hoque",
      "Jimmy Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1239": {
    "title": "Answering Complex Geographic Questions by Adaptive Reasoning with Visual Context and External Commonsense Knowledge",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Li",
      "Jianxing Yu",
      "Jielong Tang",
      "Wenqing Chen",
      "Hanjiang Lai",
      "Yanghui Rao",
      "Jian Yin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1240": {
    "title": "Safety Alignment via Constrained Knowledge Unlearning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zesheng Shi",
      "Yucheng Zhou",
      "Jing Li",
      "Yuxin Jin",
      "Yu Li",
      "Daojing He",
      "Fangming Liu",
      "Saleh Alharbi",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1241": {
    "title": "Response Wide Shut? Surprising Observations in Basic Vision Language Model Capabilities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivam Chandhok",
      "Wan-Cyuan Fan",
      "Vered Shwartz",
      "Vineeth N. Balasubramanian",
      "Leonid Sigal"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1242": {
    "title": "EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zekun Wang",
      "MingHua Ma",
      "Zexin Wang",
      "Rongchuan Mu",
      "Liping Shan",
      "Ming Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1243": {
    "title": "Pre-Training Curriculum for Multi-Token Prediction in Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ansar Aynetdinov",
      "Alan Akbik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1244": {
    "title": "Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingxuan Li",
      "Weiwen Xu",
      "Ruochen Zhao",
      "Fangkai Jiao",
      "Shafiq Joty",
      "Lidong Bing"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1245": {
    "title": "On Many-Shot In-Context Learning for Long-Context Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaijian Zou",
      "Muhammad Khalifa",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1246": {
    "title": "HelpSteer3: Human-Annotated Feedback and Edit Data to Empower Inference-Time Scaling in Open-Ended General-Domain Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhilin Wang",
      "Jiaqi Zeng",
      "Olivier Delalleau",
      "Daniel Egert",
      "Ellie Evans",
      "Hoo-Chang Shin",
      "Felipe Soares",
      "Yi Dong",
      "Oleksii Kuchaiev"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1247": {
    "title": "CulturalBench: A Robust, Diverse and Challenging Benchmark for Measuring LMs' Cultural Knowledge Through Human-AI Red-Teaming",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Ying Chiu",
      "Liwei Jiang",
      "Bill Yuchen Lin",
      "Chan Young Park",
      "Shuyue Stella Li",
      "Sahithya Ravi",
      "Mehar Bhatia",
      "Maria Antoniak",
      "Yulia Tsvetkov",
      "Vered Shwartz",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1248": {
    "title": "Balancing the Budget: Understanding Trade-offs Between Supervised and Preference-Based Finetuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohit Raghavendra",
      "Junmo Kang",
      "Alan Ritter"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1249": {
    "title": "All That Glitters is Not Novel: Plagiarism in AI Generated Research",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Gupta",
      "Danish Pruthi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1250": {
    "title": "Writing Like the Best: Exemplar-Based Expository Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Liu",
      "Kevin Chen-Chuan Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1251": {
    "title": "Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rochana Chaturvedi",
      "Peyman Baghershahi",
      "Sourav Medya",
      "Barbara Di Eugenio"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1252": {
    "title": "Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarah E. Finch",
      "Ellie S. Paek",
      "Ikseon Choi",
      "Jinho D. Choi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1253": {
    "title": "Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuyuan Li",
      "Raymond Li",
      "Thalia S. Field",
      "Giuseppe Carenini"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1254": {
    "title": "Help Me Write a Story: Evaluating LLMs' Ability to Generate Writing Feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hannah Rashkin",
      "Elizabeth Clark",
      "Fantine Huot",
      "Mirella Lapata"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1255": {
    "title": "Language Fusion for Parameter-Efficient Cross-lingual Transfer",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp Borchert",
      "Ivan Vulić",
      "Marie-Francine Moens",
      "Jochen De Weerdt"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1256": {
    "title": "Culture is Not Trivia: Sociocultural Theory for Cultural NLP",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naitian Zhou",
      "David Bamman",
      "Isaac L. Bleaman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1257": {
    "title": "AAD-LLM: Neural Attention-Driven Auditory Scene Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xilin Jiang",
      "Sukru Samet Dindar",
      "Vishal Choudhari",
      "Stephan Bickel",
      "Ashesh Mehta",
      "Guy M McKhann",
      "Daniel Friedman",
      "Adeen Flinker",
      "Nima Mesgarani"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1258": {
    "title": "Do Language Models Have Semantics? On the Five Standard Positions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1259": {
    "title": "Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myra Cheng",
      "Su Lin Blodgett",
      "Alicia DeVrio",
      "Lisa Egede",
      "Alexandra Olteanu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1260": {
    "title": "Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antonia Karamolegkou",
      "Malvina Nikandrou",
      "Georgios Pantazopoulos",
      "Danae Sanchez Villegas",
      "Phillip Rust",
      "Ruchira Dhar",
      "Daniel Hershcovich",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1261": {
    "title": "HumT DumT: Measuring and controlling human-like language in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myra Cheng",
      "Sunny Yu",
      "Dan Jurafsky"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1262": {
    "title": "ChatBench: From Static Benchmarks to Human-AI Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Serina Chang",
      "Ashton Anderson",
      "Jake M. Hofman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1263": {
    "title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Saqib Hasan",
      "Saikat Chakraborty",
      "Santu Karmaker",
      "Niranjan Balasubramanian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1264": {
    "title": "Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiulin Yang",
      "Tatsuya Aoyama",
      "Yuekun Yao",
      "Ethan Wilcox"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1265": {
    "title": "Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roland Daynauth",
      "Christopher Clarke",
      "Krisztian Flautner",
      "Lingjia Tang",
      "Jason Mars"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1266": {
    "title": "LLM Agents Making Agent Tools",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georg Wölflein",
      "Dyke Ferber",
      "Daniel Truhn",
      "Ognjen Arandjelovic",
      "Jakob Nikolas Kather"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1267": {
    "title": "CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zoya Volovikova",
      "Gregory Gorbov",
      "Petr Kuderov",
      "Aleksandr Panov",
      "Alexey Skrynnik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1268": {
    "title": "QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bang Nguyen",
      "Tingting Du",
      "Mengxia Yu",
      "Lawrence Angrave",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1269": {
    "title": "Causal Graph based Event Reasoning using Semantic Relation Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mahnaz Koupaee",
      "Xueying Bai",
      "Mudan Chen",
      "Greg Durrett",
      "Nathanael Chambers",
      "Niranjan Balasubramanian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1270": {
    "title": "LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Jiang",
      "Yuchen Yan",
      "Yang Liu",
      "Jianing Wang",
      "Shuai Peng",
      "Xunliang Cai",
      "Yixin Cao",
      "Mengdi Zhang",
      "Liangcai Gao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1271": {
    "title": "Do LLMs Understand Dialogues? A Case Study on Dialogue Acts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayesha Qamar",
      "Jonathan Tong",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1272": {
    "title": "Research Borderlands: Analysing Writing Across Research Cultures",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaily Bhatt",
      "Tal August",
      "Maria Antoniak"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1273": {
    "title": "CEAES: Bidirectional Reinforcement Learning Optimization for Consistent and Explainable Essay Assessment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xia Li",
      "Wenjing Pan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1274": {
    "title": "DeAL: Decoding-time Alignment for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Y. Huang",
      "Sailik Sengupta",
      "Daniele Bonadiman",
      "Yi-An Lai",
      "Arshit Gupta",
      "Nikolaos Pappas",
      "Saab Mansour",
      "Katrin Kirchhoff",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1275": {
    "title": "Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Senqi Yang",
      "Dongyu Zhang",
      "Jing Ren",
      "Ziqi Xu",
      "Xiuzhen Zhang",
      "Yiliao Song",
      "Hongfei Lin",
      "Feng Xia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1276": {
    "title": "OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haonan Zhang",
      "Run Luo",
      "Xiong Liu",
      "Yuchuan Wu",
      "Ting-En Lin",
      "Pengpeng Zeng",
      "Qiang Qu",
      "Feiteng Fang",
      "Min Yang",
      "Lianli Gao",
      "Jingkuan Song",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1277": {
    "title": "Mixtures of In-Context Learners",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giwon Hong",
      "Emile Van Krieken",
      "Edoardo Ponti",
      "Nikolay Malkin",
      "Pasquale Minervini"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1278": {
    "title": "Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Zhou",
      "Margret Keuper",
      "Mario Fritz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1279": {
    "title": "RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjun Hou",
      "Yi Cheng",
      "Kaishuai Xu",
      "Heng Li",
      "Yan Hu",
      "Wenjie Li",
      "Jiang Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1280": {
    "title": "Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewoo Ahn",
      "Heeseung Yun",
      "Dayoon Ko",
      "Gunhee Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1281": {
    "title": "Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishabh Adiga",
      "Besmira Nushi",
      "Varun Chandrasekaran"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1282": {
    "title": "MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyang Guo",
      "Jing Li",
      "Wenya Wang",
      "Yu Li",
      "Daojing He",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1283": {
    "title": "The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huixue Zhou",
      "Hengrui Gu",
      "Zaifu Zhan",
      "Xi Liu",
      "Kaixiong Zhou",
      "Yongkang Xiao",
      "Mingfu Liang",
      "Srinivas Prasad Govindan",
      "Piyush Chawla",
      "Jiyan Yang",
      "Xiangfei Meng",
      "Huayu Li",
      "Buyun Zhang",
      "Liang Luo",
      "Wen-Yen Chen",
      "Yiping Han",
      "Bo Long",
      "Rui Zhang",
      "Tianlong Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1284": {
    "title": "Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haobo Zhang",
      "Jiayu Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1285": {
    "title": "BIG-Bench Extra Hard",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehran Kazemi",
      "Bahare Fatemi",
      "Hritik Bansal",
      "John Palowitch",
      "Chrysovalantis Anastasiou",
      "Sanket Vaibhav Mehta",
      "Lalit K Jain",
      "Virginia Aglietti",
      "Disha Jindal",
      "Peter Chen",
      "Nishanth Dikkala",
      "Gladys Tyen",
      "Xin Liu",
      "Uri Shalit",
      "Silvia Chiappa",
      "Kate Olszewska",
      "Yi Tay",
      "Vinh Q. Tran",
      "Quoc V Le",
      "Orhan Firat"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1286": {
    "title": "CSTree-SRI: Introspection-Driven Cognitive Semantic Tree for Multi-Turn Question Answering over Extra-Long Contexts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaowen Wang",
      "Xiang Wei",
      "Kangshao Du",
      "Yiting Zhang",
      "Libo Qin",
      "Yingjie Xia",
      "Li Kuang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1287": {
    "title": "InductionBench: LLMs Fail in the Simplest Complexity Class",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyue Hua",
      "Tyler Wong",
      "Fei Sun",
      "Liangming Pan",
      "Adam Jardine",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1288": {
    "title": "RATIONALYST: Pre-training Process-Supervision for Improving Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongwei Jiang",
      "Guoxuan Wang",
      "Yining Lu",
      "Andrew Wang",
      "Jingyu Zhang",
      "Chuyu Liu",
      "Benjamin Van Durme",
      "Daniel Khashabi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1289": {
    "title": "Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andong Chen",
      "Yuchen Song",
      "Kehai Chen",
      "Xuefeng Bai",
      "Muyun Yang",
      "Liqiang Nie",
      "Jie Liu",
      "Tiejun Zhao",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1290": {
    "title": "Advancing SMoE for Continuous Domain Adaptation of MLLMs: Adaptive Router and Domain-Specific Loss",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Zhang",
      "Ziyao Lu",
      "Fandong Meng",
      "Hui Li",
      "Jie Zhou",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1291": {
    "title": "Multi-document Summarization through Multi-document Event Relation Graph Reasoning in LLMs: a case study in Framing Bias Mitigation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanyuan Lei",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1292": {
    "title": "Who Writes What: Unveiling the Impact of Author Roles on AI-generated Text Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiatao Li",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1293": {
    "title": "RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Kowsher",
      "Tara Esmaeilbeig",
      "Chun-Nam Yu",
      "Chen Chen",
      "Mojtaba Soltanalian",
      "Niloofar Yousefi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1294": {
    "title": "Scaling Laws and Efficient Inference for Ternary Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tejas Vaidhya",
      "Ayush Kaushal",
      "Vineet Jain",
      "Francis Couture-Harpin",
      "Prashant Shishodia",
      "Majid Behbahani",
      "Yuriy Nevmyvaka",
      "Irina Rish"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1295": {
    "title": "Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyubeen Han",
      "Junseo Jang",
      "Hongjin Kim",
      "Geunyeong Jeong",
      "Harksoo Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1296": {
    "title": "Do Language Models Understand Honorific Systems in Javanese?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Rifqi Farhansyah",
      "Iwan Darmawan",
      "Adryan Kusumawardhana",
      "Genta Indra Winata",
      "Alham Fikri Aji",
      "Derry Tanti Wijaya"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1297": {
    "title": "Generative Reward Modeling via Synthetic Criteria Preference Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobo Liang",
      "Haoke Zhang",
      "Juntao Li",
      "Kehai Chen",
      "Qiaoming Zhu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1298": {
    "title": "Exploring Multimodal Relation Extraction of Hierarchical Tabular Data with Multi-task Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhang",
      "Aibo Song",
      "Jingyi Qiu",
      "Jiahui Jin",
      "Tianbo Zhang",
      "Xiaolin Fang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1299": {
    "title": "A Self-Denoising Model for Robust Few-Shot Relation Extraction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Zhang",
      "Yang Zhang",
      "Ziyao Lu",
      "Fandong Meng",
      "Jie Zhou",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1300": {
    "title": "QuASAR: A Question-Driven Structure-Aware Approach for Table-to-Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "WeiJie Liu",
      "Yibin Zheng",
      "Fang Kong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1301": {
    "title": "Automated Structured Radiology Report Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jean-Benoit Delbrouck",
      "Justin Xu",
      "Johannes Moll",
      "Alois Thomas",
      "Zhihong Chen",
      "Sophie Ostmeier",
      "Asfandyar Azhar",
      "Kelvin Zhenghao Li",
      "Andrew Johnston",
      "Christian Bluethgen",
      "Eduardo Pontes Reis",
      "Mohamed S Muneer",
      "Maya Varma",
      "Curtis Langlotz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1302": {
    "title": "LPOI: Listwise Preference Optimization for Vision Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fatemeh Pesaran Zadeh",
      "Yoojin Oh",
      "Gunhee Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1303": {
    "title": "Predicting Through Generation: Why Generation Is Better for Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Kowsher",
      "Nusrat Jahan Prottasha",
      "Prakash Bhat",
      "Chun-Nam Yu",
      "Mojtaba Soltanalian",
      "Ivan Garibay",
      "Ozlem Garibay",
      "Chen Chen",
      "Niloofar Yousefi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1304": {
    "title": "Give Me BF16 or Give Me Death\"? Accuracy-Performance Trade-Offs in LLM Quantization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eldar Kurtic",
      "Alexandre Noll Marques",
      "Shubhra Pandit",
      "Mark Kurtz",
      "Dan Alistarh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1305": {
    "title": "StitchLLM: Serving LLMs, One Block at a Time",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bodun Hu",
      "Shuozhe Li",
      "Saurabh Agarwal",
      "Myungjin Lee",
      "Akshay Jajoo",
      "Jiamin Li",
      "Le Xu",
      "Geon-Woo Kim",
      "Donghyun Kim",
      "Hong Xu",
      "Amy Zhang",
      "Aditya Akella"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1306": {
    "title": "Walk in Others' Shoes with a Single Glance: Human-Centric Visual Grounding with Top-View Perspective Transformation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Bu",
      "Xin Wu",
      "Zirui Zhao",
      "Yi Cai",
      "David Hsu",
      "Qiong Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1307": {
    "title": "Is linguistically-motivated data augmentation worth it?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ray Groshan",
      "Michael Ginn",
      "Alexis Palmer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1308": {
    "title": "From Lists to Emojis: How Format Bias Affects Model Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanchang Zhang",
      "Wei Xiong",
      "Lichang Chen",
      "Tianyi Zhou",
      "Heng Huang",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1309": {
    "title": "Colloquial Singaporean English Style Transfer with Fine-Grained Explainable Control",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinggui Liang",
      "Dung Vo",
      "Yap Hong Xian",
      "Hai Leong Chieu",
      "Kian Ming A. Chai",
      "Jing Jiang",
      "Lizi Liao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1310": {
    "title": "From Informal to Formal – Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialun Cao",
      "Yaojie Lu",
      "Meiziniu Li",
      "Haoyang Ma",
      "Haokun Li",
      "Mengda He",
      "Cheng Wen",
      "Le Sun",
      "Hongyu Zhang",
      "Shengchao Qin",
      "Shing-Chi Cheung",
      "Cong Tian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1311": {
    "title": "CoAM: Corpus of All-Type Multiword Expressions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuke Ide",
      "Joshua Tanner",
      "Adam Nohejl",
      "Jacob Hoffman",
      "Justin Vasselli",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1312": {
    "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijun Yao",
      "Weijian Qi",
      "Liangming Pan",
      "Shulin Cao",
      "Linmei Hu",
      "Liu Weichuan",
      "Lei Hou",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1313": {
    "title": "Exposing the Achilles' Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joykirat Singh",
      "Akshay Nambi",
      "Vibhav Vineet"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1314": {
    "title": "Understanding the Dark Side of LLMs' Intrinsic Self-Correction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingjie Zhang",
      "Di Wang",
      "Haoting Qian",
      "Yiming Li",
      "Tianwei Zhang",
      "Minlie Huang",
      "Ke Xu",
      "Hewu Li",
      "Liu Yan",
      "Han Qiu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1315": {
    "title": "VideoVista-CulturalLingo: 360° Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Chen",
      "Yunxin Li",
      "Haoyuan Shi",
      "Baotian Hu",
      "Wenhan Luo",
      "Yaowei Wang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1316": {
    "title": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Chen",
      "Qiguang Chen",
      "Libo Qin",
      "Qipeng Guo",
      "Haijun Lv",
      "Yicheng Zou",
      "Hang Yan",
      "Kai Chen",
      "Dahua Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1317": {
    "title": "Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shijie Wang",
      "Wenqi Fan",
      "Yue Feng",
      "Lin Shanru",
      "Xinyu Ma",
      "Shuaiqiang Wang",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1318": {
    "title": "SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Liu",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1319": {
    "title": "I0T: Embedding Standardization Method Towards Zero Modality Gap",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Na Min An",
      "Eunki Kim",
      "James Thorne",
      "Hyunjung Shim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1320": {
    "title": "Odysseus Navigates the Sirens' Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Luo",
      "Feifan Song",
      "Wei Li",
      "Guangyue Peng",
      "Shaohang Wei",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1321": {
    "title": "Better Embeddings with Coupled Adam",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Stollenwerk",
      "Tobias Stollenwerk"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1322": {
    "title": "Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guofu Xie",
      "Xiao Zhang",
      "Ting Yao",
      "Yunsheng Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1323": {
    "title": "Controllable and Reliable Knowledge-Intensive Task-Oriented Conversational Agents with Declarative Genie Worksheets",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harshit Joshi",
      "Shicheng Liu",
      "James Chen",
      "Larsen Weigle",
      "Monica Lam"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1324": {
    "title": "Benchmarking Long-Context Language Models on Long Code Understanding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia Li",
      "Xuyuan Guo",
      "Lei Li",
      "Kechi Zhang",
      "Ge Li",
      "Jia Li",
      "Zhengwei Tao",
      "Fang Liu",
      "Chongyang Tao",
      "Yuqi Zhu",
      "Zhi Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1325": {
    "title": "MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Savya Khosla",
      "Aditi Tiwari",
      "Kushal Kafle",
      "Simon Jenni",
      "Handong Zhao",
      "John Collomosse",
      "Jing Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1326": {
    "title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Jin",
      "Meng Li",
      "Xiting Wang",
      "Zhihao Xu",
      "Minlie Huang",
      "Yantao Jia",
      "Defu Lian"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1327": {
    "title": "A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Hu",
      "Mingqi Gao",
      "Li Lin",
      "Zhenghan Yu",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1328": {
    "title": "Recurrent Knowledge Identification and Fusion for Language Model Continual Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Feng",
      "Xujia Wang",
      "Zexin Lu",
      "Shenghong Fu",
      "Guangyuan Shi",
      "Yongxin Xu",
      "Yasha Wang",
      "Philip S. Yu",
      "Xu Chu",
      "Xiao-Ming Wu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1329": {
    "title": "Data-Constrained Synthesis of Training Data for De-Identification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Vakili",
      "Aron Henriksson",
      "Hercules Dalianis"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1330": {
    "title": "Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumitra Ghosh",
      "Gopendra Vikram Singh",
      "Shambhavi Shambhavi",
      "Sabarna Choudhury",
      "Asif Ekbal"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1331": {
    "title": "Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiming Guo",
      "Meishan Zhang",
      "Jianling Li",
      "Min Zhang",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1332": {
    "title": "MMDEND: Dendrite-Inspired Multi-Branch Multi-Compartment Parallel Spiking Neuron for Sequence Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kexin Wang",
      "Yuhong Chou",
      "Di Shang",
      "Shijie Mei",
      "Jiahong Zhang",
      "Yanbin Huang",
      "Man Yao",
      "Bo Xu",
      "Guoqi Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1333": {
    "title": "Understanding Impact of Human Feedback via Influence Functions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taywon Min",
      "Haeone Lee",
      "Yongchan Kwon",
      "Kimin Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1334": {
    "title": "T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziwei Huang",
      "Wanggui He",
      "Quanyu Long",
      "Yandi Wang",
      "Haoyuan Li",
      "Zhelun Yu",
      "Fangxun Shu",
      "Weilong Dai",
      "Hao Jiang",
      "Fei Wu",
      "Leilei Gan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1335": {
    "title": "InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fuyu Wang",
      "Jiangtong Li",
      "Kun Zhu",
      "Changjun Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1336": {
    "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongliang He",
      "Wenlin Yao",
      "Kaixin Ma",
      "Wenhao Yu",
      "Hongming Zhang",
      "Tianqing Fang",
      "Zhenzhong Lan",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1337": {
    "title": "FOCUS: Evaluating Pre-trained Vision-Language Models on Underspecification Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kankan Zhou",
      "Eason Lai",
      "Kyriakos Mouratidis",
      "Jing Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1338": {
    "title": "Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wan Ju Kang",
      "Eunki Kim",
      "Na Min An",
      "Sangryul Kim",
      "Haemin Choi",
      "Ki Hoon Kwak",
      "James Thorne"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1339": {
    "title": "Personal Travel Solver: A Preference-Driven LLM-Solver System for Travel Planning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijian Shao",
      "Jiancan Wu",
      "Weijian Chen",
      "Xiang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1340": {
    "title": "Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aswini Kumar Padhi",
      "Anil Bandhakavi",
      "Tanmoy Chakraborty"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1341": {
    "title": "LLM×MapReduce: Simplified Long-Sequence Processing using Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Zhou",
      "Chong Li",
      "Xinyi Chen",
      "Shuo Wang",
      "Yu Chao",
      "Zhili Li",
      "Haoyu Wang",
      "Qi Shi",
      "Zhixing Tan",
      "Xu Han",
      "Xiaodong Shi",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1342": {
    "title": "CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dennis Hein",
      "Zhihong Chen",
      "Sophie Ostmeier",
      "Justin Xu",
      "Maya Varma",
      "Eduardo Pontes Reis",
      "Arne Edward Michalson Md",
      "Christian Bluethgen",
      "Hyun Joo Shin",
      "Curtis Langlotz",
      "Akshay S Chaudhari"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1343": {
    "title": "Knowledge Tracing in Programming Education Integrating Students' Questions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Doyoun Kim",
      "Suin Kim",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1344": {
    "title": "PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqun Sun",
      "Qiang Huang",
      "Anthony Kum Hoe Tung",
      "Jun Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1345": {
    "title": "Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Li",
      "Michael Vrazitulis",
      "David Schlangen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1346": {
    "title": "Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhange Zhang",
      "Yuqing Ma",
      "Yulong Wang",
      "Shan He",
      "Tianbo Wang",
      "Siqi He",
      "Jiakai Wang",
      "Xianglong Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1347": {
    "title": "Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juntian Zhang",
      "Chuanqi Cheng",
      "Yuhan Liu",
      "Wei Liu",
      "Jian Luan",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1348": {
    "title": "Online Iterative Self-Alignment for Radiology Report Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting Xiao",
      "Lei Shi",
      "Yang Zhang",
      "HaoFeng Yang",
      "Zhe Wang",
      "Chenjia Bai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1349": {
    "title": "Chinese Inertial GAN for Handwriting Signal Generation and Recognition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifeng Wang",
      "Yi Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1350": {
    "title": "LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Li",
      "Huan Gao",
      "Zhiyuan Zhao",
      "Zhiyu Lin",
      "Junyu Gao",
      "Xuelong Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1351": {
    "title": "Evaluating Sequence Labeling on the basis of Information Theory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enrique Amigo",
      "Elena Álvarez-Mellado",
      "Julio Gonzalo",
      "Jorge Carrillo-de-Albornoz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1352": {
    "title": "GRAT: Guiding Retrieval-Augmented Reasoning through Process Rewards Tree Search",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianshu Peng",
      "Wei Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1353": {
    "title": "T-REG: Preference Optimization with Token-Level Reward Regularization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Zhou",
      "Shujian Zhang",
      "Lingxiao Zhao",
      "Tao Meng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1354": {
    "title": "Gödel Agent: A Self-Referential Agent Framework for Recursively Self-Improvement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunjian Yin",
      "Xinyi Wang",
      "Liangming Pan",
      "Li Lin",
      "Xiaojun Wan",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1355": {
    "title": "AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiheng Xi",
      "Yiwen Ding",
      "Wenxiang Chen",
      "Boyang Hong",
      "Honglin Guo",
      "Junzhe Wang",
      "Xin Guo",
      "Dingwen Yang",
      "Chenyang Liao",
      "Wei He",
      "Songyang Gao",
      "Lu Chen",
      "Rui Zheng",
      "Yicheng Zou",
      "Tao Gui",
      "Qi Zhang",
      "Xipeng Qiu",
      "Xuanjing Huang",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1356": {
    "title": "Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yexiang Liu",
      "Zekun Li",
      "Zhi Fang",
      "Nan Xu",
      "Ran He",
      "Tieniu Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1357": {
    "title": "Information Locality as an Inductive Bias for Neural Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taiga Someya",
      "Anej Svete",
      "Brian DuSell",
      "Timothy J. O’Donnell",
      "Mario Giulianelli",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1358": {
    "title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrián Bazaga",
      "Rexhina Blloshmi",
      "Bill Byrne",
      "Adrià de Gispert"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1359": {
    "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Massimiliano Pronesti",
      "Joao H Bettencourt-Silva",
      "Paul Flanagan",
      "Alessandra Pascale",
      "Oisín Redmond",
      "Anya Belz",
      "Yufang Hou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1360": {
    "title": "Towards Robust Universal Information Extraction: Dataset, Evaluation, and Solution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jizhao Zhu",
      "Akang Shi",
      "Zixuan Li",
      "Long Bai",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1361": {
    "title": "Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiyuan Lai",
      "Esther Ploeger",
      "Rik Van Noord",
      "Antonio Toral"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1362": {
    "title": "Temporal reasoning for timeline summarisation in social media",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayu Song",
      "Mahmud Elahi Akhter",
      "Dana Atzil-Slonim",
      "Maria Liakata"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1363": {
    "title": "Beyond Negative Stereotypes – Non-Negative Abusive Utterances about Identity Groups and Their Semantic Variants",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tina Lommel",
      "Elisabeth Eder",
      "Josef Ruppenhofer",
      "Michael Wiegand"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1364": {
    "title": "Persistent Homology of Topic Networks for the Prediction of Reader Curiosity",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manuel D.s. Hopp",
      "Vincent Labatut",
      "Arthur Amalvy",
      "Richard Dufour",
      "Hannah Stone",
      "Hayley K Jach",
      "Kou Murayama"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1365": {
    "title": "Tokenisation is NP-Complete",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philip Whittington",
      "Gregor Bachmann",
      "Tiago Pimentel"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1366": {
    "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrei Mircea",
      "Supriyo Chakraborty",
      "Nima Chitsazan",
      "Irina Rish",
      "Ekaterina Lobacheva"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1367": {
    "title": "Parameter-Aware Contrastive Knowledge Editing: Tracing and Rectifying based on Critical Transmission Paths",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songlin Zhai",
      "Yuan Meng",
      "Yuxin Zhang",
      "Guilin Qi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1368": {
    "title": "Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Su",
      "Renqi Chen",
      "Shixiang Tang",
      "Zhenfei Yin",
      "Xinzhe Zheng",
      "Jinzhe Li",
      "Biqing Qi",
      "Qi Wu",
      "Hui Li",
      "Wanli Ouyang",
      "Philip Torr",
      "Bowen Zhou",
      "Nanqing Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1369": {
    "title": "Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilong Chen",
      "Junyuan Shang",
      "Zhenyu Zhang",
      "Yanxi Xie",
      "Jiawei Sheng",
      "Tingwen Liu",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1370": {
    "title": "Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuu Jinnai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1371": {
    "title": "Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minseok Choi",
      "Daniel Rim",
      "Dohyun Lee",
      "Jaegul Choo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1372": {
    "title": "Mixture of Small and Large Models for Chinese Spelling Check",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziheng Qiao",
      "Houquan Zhou",
      "Zhenghua Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1373": {
    "title": "DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziheng Qiao",
      "Houquan Zhou",
      "Yumeng Liu",
      "Zhenghua Li",
      "Min Zhang",
      "Bo Zhang",
      "Chen Li",
      "Ji Zhang",
      "Fei Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1374": {
    "title": "Causal Estimation of Tokenisation Bias",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pietro Lesci",
      "Clara Meister",
      "Thomas Hofmann",
      "Andreas Vlachos",
      "Tiago Pimentel"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1375": {
    "title": "Value Residual Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanchao Zhou",
      "Tianyi Wu",
      "Zhiyun Jiang",
      "Fares Obeid",
      "Zhenzhong Lan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1376": {
    "title": "SGIC: A Self-Guided Iterative Calibration Framework for RAG",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanhua Chen",
      "Yutong Yao",
      "Lidia S. Chao",
      "Xuebo Liu",
      "Derek F. Wong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1377": {
    "title": "NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Farid Adilazuarda",
      "Musa Izzanardi Wijanarko",
      "Lucky Susanto",
      "Khumaisa Nur’aini",
      "Derry Tanti Wijaya",
      "Alham Fikri Aji"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1378": {
    "title": "LLM-based Rumor Detection via Influence Guided Sample Selection and Game-based Perspective Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiliang Tian",
      "Jingyuan Huang",
      "Zejiang He",
      "Zhen Huang",
      "Menglong Lu",
      "Linbo Qiao",
      "Songzhu Mei",
      "Yijie Wang",
      "Dongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1379": {
    "title": "Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqi Jia",
      "Anmin Wang",
      "Xiaoyang Qu",
      "Xiaowen Yang",
      "Jianzong Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1380": {
    "title": "SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zicong Tang",
      "Shi Luohe",
      "Zuchao Li",
      "Baoyuan Qi",
      "Liu Guoming",
      "Lefei Zhang",
      "Ping Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1381": {
    "title": "Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junde Wu",
      "Jiayuan Zhu",
      "Yunli Qi",
      "Jingkun Chen",
      "Min Xu",
      "Filippo Menolascina",
      "Yueming Jin",
      "Vicente Grau"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1382": {
    "title": "Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungcheol Park",
      "Jeongin Bae",
      "Beomseok Kwon",
      "Minjun Kim",
      "Byeongwook Kim",
      "Se Jung Kwon",
      "U Kang",
      "Dongsoo Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1383": {
    "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junde Wu",
      "Jiayuan Zhu",
      "Yuyuan Liu",
      "Min Xu",
      "Yueming Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1384": {
    "title": "Probing Relative Interaction and Dynamic Calibration in Multi-modal Entity Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxiao Li",
      "Jingwei Cheng",
      "Qiang Tong",
      "Fu Zhang",
      "Cairui Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1385": {
    "title": "Learn to Memorize: Scalable Continual Learning in Semiparametric Models with Mixture-of-Neighbors Induction Memory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyue Peng",
      "Tao Ge",
      "Wen Luo",
      "Wei Li",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1386": {
    "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Imane Guellil",
      "Salomé Andres",
      "Atul Anand",
      "Bruce Guthrie",
      "Huayu Zhang",
      "Abul Hasan",
      "Honghan Wu",
      "Beatrice Alex"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1387": {
    "title": "Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longhui Zhang",
      "Jiahao Wang",
      "Meishan Zhang",
      "GaoXiong Cao",
      "Ensheng Shi",
      "Mayuchi Mayuchi",
      "Jun Yu",
      "Honghai Liu",
      "Jing Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1388": {
    "title": "Multi-Facet Blending for Faceted Query-by-Example Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heejin Do",
      "Sangwon Ryu",
      "Jonghwi Kim",
      "Gary Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1389": {
    "title": "PIPER: Benchmarking and Prompting Event Reasoning Boundary of LLMs via Debiasing-Distillation Enhanced Tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicong Lu",
      "Changyuan Tian",
      "PeiguangLi PeiguangLi",
      "Li Jin",
      "Sirui Wang",
      "Wei Jia",
      "Ying Shen",
      "Guangluan Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1390": {
    "title": "MIR: Methodology Inspiration Retrieval for Scientific Research Problems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aniketh Garikaparthi",
      "Manasi Patwardhan",
      "Aditya Sanjiv Kanade",
      "Aman Hassan",
      "Lovekesh Vig",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1391": {
    "title": "Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kexin Chen",
      "Dongxia Wang",
      "Yi Liu",
      "Haonan Zhang",
      "Wenhai Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1392": {
    "title": "Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoxi Xu",
      "Yunjie Ji",
      "Boxi Cao",
      "Yaojie Lu",
      "Hongyu Lin",
      "Xianpei Han",
      "Ben He",
      "Yingfei Sun",
      "Xiangang Li",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1393": {
    "title": "Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haesung Pyun",
      "Yoonah Park",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1394": {
    "title": "Pretraining Context Compressor for Large Language Models with Embedding-Based Memory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhong Dai",
      "Jianxun Lian",
      "Yitian Huang",
      "Wei Zhang",
      "Mingyang Zhou",
      "Mingqi Wu",
      "Xing Xie",
      "Hao Liao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1395": {
    "title": "Dialogue Systems for Emotional Support via Value Reinforcement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juhee Kim",
      "Chunghu Mok",
      "Jisun Lee",
      "Hyang Sook Kim",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1396": {
    "title": "Length-Induced Embedding Collapse in PLM-based Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Zhou",
      "Sunhao Dai",
      "Zhanshuo Cao",
      "Xiao Zhang",
      "Jun Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1397": {
    "title": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shester Gueuwou",
      "Xiaodan Du",
      "Greg Shakhnarovich",
      "Karen Livescu",
      "Alexander H. Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1398": {
    "title": "ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lam Thanh Do",
      "Aaditya Bodke",
      "Pritom Saha Akash",
      "Kevin Chen-Chuan Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1399": {
    "title": "Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suvodip Dey",
      "Yi-Jyun Sun",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1400": {
    "title": "LLMs Trust Humans More, That's a Problem! Unveiling and Mitigating the Authority Bias in Retrieval-Augmented Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Li",
      "Xinwei Guo",
      "Jiashi Gao",
      "Guanhua Chen",
      "Xiangyu Zhao",
      "Jiaxin Zhang",
      "Quanying Liu",
      "Haiyan Wu",
      "Xin Yao",
      "Xuetao Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1401": {
    "title": "Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongsheng Zhu",
      "Weixian Shi",
      "Zhengliang Shi",
      "Zhaochun Ren",
      "Shuaiqiang Wang",
      "Lingyong Yan",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1402": {
    "title": "Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyi Zhang",
      "Peirong Zhang",
      "Zhenhua Yang",
      "Pengyu Yan",
      "Yongxin Shi",
      "Pengwei Liu",
      "Fengjun Guo",
      "Lianwen Jin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1403": {
    "title": "PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zekun Moore Wang",
      "Shenzhi Wang",
      "King Zhu",
      "Jiaheng Liu",
      "Ke Xu",
      "Jie Fu",
      "Wangchunshu Zhou",
      "Wenhao Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1404": {
    "title": "Robust Utility-Preserving Text Anonymization Based on Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Yang",
      "Xiaodan Zhu",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1405": {
    "title": "SEAL: Scaling to Emphasize Attention for Long-Context Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changhun Lee",
      "Minsang Seok",
      "Jun-gyu Jin",
      "YoungHyun Cho",
      "Eunhyeok Park"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1406": {
    "title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chongxuan Huang",
      "Yongshi Ye",
      "Biao Fu",
      "Qifeng Su",
      "Xiaodong Shi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1407": {
    "title": "𝒜3: Automatic Alignment Framework for Attributed Text Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Wang",
      "Haoke Zhang",
      "Juntao Li",
      "Jinxiong Chang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1408": {
    "title": "Towards Better Value Principles for Large Language Model Alignment: A Systematic Evaluation and Enhancement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingbing Xu",
      "Jing Yao",
      "Xiaoyuan Yi",
      "Aishan Maoliniyazi",
      "Xing Xie",
      "Xiaofeng Meng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1409": {
    "title": "Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arvid Frydenlund"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1410": {
    "title": "Diversity Explains Inference Scaling Laws: Through a Case Study of Minimum Bayes Risk Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hidetaka Kamigaito",
      "Hiroyuki Deguchi",
      "Yusuke Sakai",
      "Katsuhiko Hayashi",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1411": {
    "title": "Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ido Cohen",
      "Daniela Gottesman",
      "Mor Geva",
      "Raja Giryes"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1412": {
    "title": "SDD: Self-Degraded Defense against Malicious Fine-tuning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "ZiXuan Chen",
      "Weikai Lu",
      "Xin Lin",
      "Ziqian Zeng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1413": {
    "title": "CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Hsin Yeh",
      "Yu-An Su",
      "Chih-Ning Chen",
      "Yi-Hsueh Lin",
      "Calvin Ku",
      "Wenhsin Chiu",
      "Min-Chun Hu",
      "Lun-Wei Ku"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1414": {
    "title": "DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hexuan Deng",
      "Wenxiang Jiao",
      "Xuebo Liu",
      "Jing Li",
      "Min Zhang",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1415": {
    "title": "How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karin De Langis",
      "Jong Inn Park",
      "Andreas Schramm",
      "Bin Hu",
      "Khanh Chi Le",
      "Dongyeop Kang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1416": {
    "title": "Data Caricatures: On the Representation of African American Language in Pretraining Corpora",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicholas Deas",
      "Blake Vente",
      "Amith Ananthram",
      "Jessica A Grieser",
      "Desmond U. Patton",
      "Shana Kleiner",
      "James R. Shepard Iii",
      "Kathleen McKeown"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1417": {
    "title": "Language Model Probabilities are Not Calibrated in Numeric Contexts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Charles Lovering",
      "Michael Krumdick",
      "Viet Dac Lai",
      "Varshini Reddy",
      "Seth Ebner",
      "Nilesh Kumar",
      "Rik Koncel-Kedziorski",
      "Chris Tanner"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1418": {
    "title": "MDCure: A Scalable Pipeline for Multi-Document Instruction-Following",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabrielle Kaili-May Liu",
      "Bowen Shi",
      "Avi Caciularu",
      "Idan Szpektor",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1419": {
    "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sumanth Doddapaneni",
      "Mohammed Safi Ur Rahman Khan",
      "Dilip Venkatesh",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Mitesh M Khapra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1420": {
    "title": "DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minjun Zhu",
      "Yixuan Weng",
      "Linyi Yang",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1421": {
    "title": "Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Gao",
      "Zujing Liu",
      "Weizhong Zhang",
      "Bo Du",
      "Gui-Song Xia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1422": {
    "title": "Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priyanka Kargupta",
      "Ishika Agarwal",
      "Tal August",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1423": {
    "title": "Hierarchical Memory Organization for Wikipedia Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eugene J. Yu",
      "Dawei Zhu",
      "Yifan Song",
      "Xiangyu Wong",
      "Jiebin Zhang",
      "Wenxuan Shi",
      "Xiaoguang Li",
      "Qun Liu",
      "Sujian Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1424": {
    "title": "Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenlu Wang",
      "Weimin Lyu",
      "Ritwik Banerjee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1425": {
    "title": "Structure-aware Domain Knowledge Injection for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Liu",
      "Ze Chen",
      "Zhihang Fu",
      "Wei Zhang",
      "Rongxin Jiang",
      "Fan Zhou",
      "Yaowu Chen",
      "Yue Wu",
      "Jieping Ye"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1426": {
    "title": "FinMME: Benchmark Dataset for Financial Multi-Modal Reasoning Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyu Luo",
      "Zhizhuo Kou",
      "Liming Yang",
      "Xiao Luo",
      "Jinsheng Huang",
      "Zhiping Xiao",
      "Jingshu Peng",
      "Chengzhong Liu",
      "Jiaming Ji",
      "Xuanzhe Liu",
      "Sirui Han",
      "Ming Zhang",
      "Yike Guo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1427": {
    "title": "Dialectal Coverage And Generalization in Arabic Speech Recognition",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirbek Djanibekov",
      "Hawau Olamide Toyin",
      "Raghad Alshalan",
      "Abdullah Alatir",
      "Hanan Aldarmaki"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1428": {
    "title": "EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ron Yosef",
      "Yonatan Bitton",
      "Dani Lischinski",
      "Moran Yanuka"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1429": {
    "title": "Reconsidering LLM Uncertainty Estimation Methods in the Wild",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yavuz Faruk Bakman",
      "Duygu Nur Yaldiz",
      "Sungmin Kang",
      "Tuo Zhang",
      "Baturalp Buyukates",
      "Salman Avestimehr",
      "Sai Praneeth Karimireddy"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1430": {
    "title": "Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caio Corro",
      "Mathieu Lacroix",
      "Joseph Le Roux"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1431": {
    "title": "SEE: Strategic Exploration and Exploitation for Cohesive In-Context Prompt Optimization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wendi Cui",
      "Jiaxin Zhang",
      "Zhuohang Li",
      "Hao Sun",
      "Damien Lopez",
      "Kamalika Das",
      "Bradley A. Malin",
      "Sricharan Kumar"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1432": {
    "title": "Programming by Example meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atharva Naik",
      "Darsh Agrawal",
      "Hong Sng",
      "Clayton Marr",
      "Kexun Zhang",
      "Nathaniel Romney Robinson",
      "Kalvin Chang",
      "Rebecca Byrnes",
      "Aravind Mysore",
      "Carolyn Rose",
      "David R. Mortensen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1433": {
    "title": "Synergizing Unsupervised Episode Detection with LLMs for Large-Scale News Events",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priyanka Kargupta",
      "Yunyi Zhang",
      "Yizhu Jiao",
      "Siru Ouyang",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1434": {
    "title": "Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priyanka Kargupta",
      "Runchu Tian",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1435": {
    "title": "The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feiran Jia",
      "Tong Wu",
      "Xin Qin",
      "Anna Squicciarini"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1436": {
    "title": "Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fabrice Y Harel-Canada",
      "Boran Erol",
      "Connor Choi",
      "Jason Liu",
      "Gary Jiarui Song",
      "Nanyun Peng",
      "Amit Sahai"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1437": {
    "title": "Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxuan Kong",
      "Yiyuan Yang",
      "Yoontae Hwang",
      "Wenjie Du",
      "Stefan Zohren",
      "Zhangyang Wang",
      "Ming Jin",
      "Qingsong Wen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1438": {
    "title": "From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruxiao Chen",
      "Chenguang Wang",
      "Yuran Sun",
      "Xilei Zhao",
      "Susu Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1439": {
    "title": "GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shikhhar Siingh",
      "Abhinav Rawat",
      "Chitta Baral",
      "Vivek Gupta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1440": {
    "title": "Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vivian Nguyen",
      "Lillian Lee",
      "Cristian Danescu-Niculescu-Mizil"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1441": {
    "title": "Unveiling the Potential of BERT-family: A New Recipe for Building Scalable, General and Competitive Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yisheng Xiao",
      "Juntao Li",
      "Wenpeng Hu",
      "Zhunchen Luo",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1442": {
    "title": "TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priyanka Kargupta",
      "Nan Zhang",
      "Yunyi Zhang",
      "Rui Zhang",
      "Prasenjit Mitra",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1443": {
    "title": "An Empirical Study of Iterative Refinements for Non-autoregressive Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yisheng Xiao",
      "Pei Guo",
      "Zechen Sun",
      "Juntao Li",
      "Kai Song",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1444": {
    "title": "Retrofitting Large Language Models with Dynamic Tokenization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Darius Feher",
      "Ivan Vulić",
      "Benjamin Minixhofer"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1445": {
    "title": "Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishakh Padmakumar",
      "Zichao Wang",
      "David Arbour",
      "Jennifer Healey"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1446": {
    "title": "Bilingual Zero-Shot Stance Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenye Zhao",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1447": {
    "title": "GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rita Ramos",
      "Everlyn Asiko Chimoto",
      "Maartje Ter Hoeve",
      "Natalie Schluter"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1448": {
    "title": "Theorem Prover as a Judge for Synthetic Data Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua Ong Jun Leang",
      "Giwon Hong",
      "Wenda Li",
      "Shay B Cohen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1449": {
    "title": "Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ori Shapira",
      "Shlomo Chazan",
      "Amir David Nissan Cohen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1450": {
    "title": "Assessing Reliability and Political Bias In LLMs' Judgements of Formal and Material Inferences With Partisan Conclusions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reto Gubelmann",
      "Ghassen Karray"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1451": {
    "title": "PARME: Parallel Corpora for Low-Resourced Middle Eastern Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sina Ahmadi",
      "Rico Sennrich",
      "Erfan Karami",
      "Ako Marani",
      "Parviz Fekrazad",
      "Gholamreza Akbarzadeh Baghban",
      "Hanah Hadi",
      "Semko Heidari",
      "Mahîr Dogan",
      "Pedram Asadi",
      "Dashne Bashir",
      "Mohammad Amin Ghodrati",
      "Kourosh Amini",
      "Zeynab Ashourinezhad",
      "Mana Baladi",
      "Farshid Ezzati",
      "Alireza Ghasemifar",
      "Daryoush Hosseinpour",
      "Behrooz Abbaszadeh",
      "Amin Hassanpour",
      "Bahaddin Jalal Hamaamin",
      "Saya Kamal Hama",
      "Ardeshir Mousavi",
      "Sarko Nazir Hussein",
      "Isar Nejadgholi",
      "Mehmet Ölmez",
      "Horam Osmanpour",
      "Rashid Roshan Ramezani",
      "Aryan Sediq Aziz",
      "Ali Salehi",
      "Mohammadreza Yadegari",
      "Kewyar Yadegari",
      "Sedighe Zamani Roodsari"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1452": {
    "title": "METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingxuan Li",
      "Yiwei Wang",
      "Jiuxiang Gu",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1453": {
    "title": "ConLoan: A Contrastive Multilingual Dataset for Evaluating Loanwords",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sina Ahmadi",
      "Micha David Hess",
      "Elena Álvarez-Mellado",
      "Alessia Battisti",
      "Cui Ding",
      "Anne Göhring",
      "Yingqiang Gao",
      "Zifan Jiang",
      "Andrianos Michail",
      "Peshmerge Morad",
      "Joel Niklaus",
      "Maria Christina Panagiotopoulou",
      "Stefano Perrella",
      "Juri Opitz",
      "Anastassia Shaitarova",
      "Rico Sennrich"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1454": {
    "title": "A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarath Sivaprasad",
      "Pramod Kaushik",
      "Sahar Abdelnabi",
      "Mario Fritz"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1455": {
    "title": "MEraser: An Effective Fingerprint Erasure Approach for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingxuan Zhang",
      "Zhenhua Xu",
      "Rui Hu",
      "Wenpeng Xing",
      "Xuhong Zhang",
      "Meng Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1456": {
    "title": "VISA: Retrieval Augmented Generation with Visual Source Attribution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueguang Ma",
      "Shengyao Zhuang",
      "Bevan Koopman",
      "Guido Zuccon",
      "Wenhu Chen",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1457": {
    "title": "DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueguang Ma",
      "Xi Victoria Lin",
      "Barlas Oguz",
      "Jimmy Lin",
      "Wen-tau Yih",
      "Xilun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1458": {
    "title": "Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziling Cheng",
      "Meng Cao",
      "Marc-Antoine Rondeau",
      "Jackie CK Cheung"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1459": {
    "title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chanwoo Park",
      "Seungju Han",
      "Xingzhi Guo",
      "Asuman E. Ozdaglar",
      "Kaiqing Zhang",
      "Joo-Kyung Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1460": {
    "title": "Map&Make: Schema Guided Text to Table Generation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naman Ahuja",
      "Fenil Bardoliya",
      "Chitta Baral",
      "Vivek Gupta"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1461": {
    "title": "IRIS: Interpretable Retrieval-Augmented Classification for Long Interspersed Document Sequences",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengnan Li",
      "Elliot D. Hill",
      "Jiang Shu",
      "Jiaxin Gao",
      "Matthew M. Engelhard"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1462": {
    "title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengguang Wu",
      "Fan-Yun Sun",
      "Kaiyue Wen",
      "Nick Haber"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1463": {
    "title": "Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Baile Chen",
      "Yi Zhang",
      "Mike Cafarella",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1464": {
    "title": "R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tenghao Huang",
      "Kinjal Basu",
      "Ibrahim Abdelaziz",
      "Pavan Kapanipathi",
      "Jonathan May",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1465": {
    "title": "FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Janki Atul Nawale",
      "Mohammed Safi Ur Rahman Khan",
      "Janani D",
      "Mansi Gupta",
      "Danish Pruthi",
      "Mitesh M Khapra"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1466": {
    "title": "SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Wan",
      "Chao-Han Huck Yang",
      "Yahan Yu",
      "Jinchuan Tian",
      "Sheng Li",
      "Ke Hu",
      "Zhehuai Chen",
      "Shinji Watanabe",
      "Fei Cheng",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1467": {
    "title": "Predicting Implicit Arguments in Procedural Video Instructions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anil Batra",
      "Laura Sevilla-Lara",
      "Marcus Rohrbach",
      "Frank Keller"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1468": {
    "title": "PIGuard: Prompt Injection Guardrail via Mitigating Overdefense for Free",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Li",
      "Xiaogeng Liu",
      "Ning Zhang",
      "Chaowei Xiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1469": {
    "title": "CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Yang",
      "Lisen Dai",
      "Xiangqi Wang",
      "Minhao Cheng",
      "Yapeng Tian",
      "Xiangliang Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1470": {
    "title": "ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Austin Wang",
      "ZeMing Gong",
      "Angel X Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1471": {
    "title": "The time scale of redundancy between prosody and linguistic context",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tamar I Regev",
      "Chiebuka Ohams",
      "Shaylee Xie",
      "Lukas Wolf",
      "Evelina Fedorenko",
      "Alex Warstadt",
      "Ethan Wilcox",
      "Tiago Pimentel"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1472": {
    "title": "Basic Reading Distillation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zhou",
      "Sirui Miao",
      "Xiangyu Duan",
      "Hao Yang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1473": {
    "title": "Quantized Can Still Be Calibrated: A Unified Framework to Calibration in Quantized Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Zhong",
      "Guanchu Wang",
      "Yu-Neng Chuang",
      "Na Zou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1474": {
    "title": "A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Ignazio Re",
      "Andreas Opedal",
      "Glib Manaiev",
      "Mario Giulianelli",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1475": {
    "title": "More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqing Zhang",
      "Ang Lv",
      "Yuhan Liu",
      "Flood Sung",
      "Wei Liu",
      "Jian Luan",
      "Shuo Shang",
      "Xiuying Chen",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1476": {
    "title": "Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Wang",
      "Xingchen Wan",
      "Ruoxi Sun",
      "Jiefeng Chen",
      "Sercan O Arik"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1477": {
    "title": "SubLIME: Subset Selection via Rank Correlation Prediction for Data-Efficient LLM Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gayathri Saranathan",
      "Cong Xu",
      "Mahammad Parwez Alam",
      "Tarun Kumar",
      "Martin Foltin",
      "Soon Yee Wong",
      "Suparna Bhattacharya"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1478": {
    "title": "M³GQA: A Multi-Entity Multi-Hop Multi-Setting Graph Question Answering Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boci Peng",
      "Yongchao Liu",
      "Xiaohe Bo",
      "Jiaxin Guo",
      "Yun Zhu",
      "Xuanbo Fan",
      "Chuntao Hong",
      "Yan Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1479": {
    "title": "LSSF: Safety Alignment for Large Language Models through Low-Rank Safety Subspace Fusion",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanghao Zhou",
      "Panjia Qiu",
      "Cen Chen",
      "Hongyu Li",
      "Jason Chu",
      "Xin Zhang",
      "Jun Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1480": {
    "title": "ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kishan Maharaj",
      "Vitobha Munigala",
      "Srikanth G. Tamilselvam",
      "Prince Kumar",
      "Sayandeep Sen",
      "Palani Kodeswaran",
      "Abhijit Mishra",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1481": {
    "title": "Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengqian Qin",
      "Yakun Zhu",
      "Linjie Mu",
      "Shaoting Zhang",
      "Xiaofan Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1482": {
    "title": "Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingjie Zhu",
      "Xuefeng Bai",
      "Kehai Chen",
      "Yang Xiang",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1483": {
    "title": "ISR: Self-Refining Referring Expressions for Entity Grounding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuocheng Yu",
      "Bingchan Zhao",
      "Yifan Song",
      "Sujian Li",
      "Zhonghui He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1484": {
    "title": "Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Wang",
      "Dianyi Wang",
      "Chengxing Zhou",
      "Zejun Li",
      "Zhihao Fan",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1485": {
    "title": "CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongheng Zhang",
      "Xu Liu",
      "Ruoxi Zhou",
      "Qiguang Chen",
      "Hao Fei",
      "Wenpeng Lu",
      "Libo Qin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1486": {
    "title": "TestNUC: Enhancing Test-Time Computing Approaches and Scaling through Neighboring Unlabeled Data Consistency",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Henry Peng Zou",
      "Zhengyao Gu",
      "Yue Zhou",
      "Yankai Chen",
      "Weizhi Zhang",
      "Liancheng Fang",
      "Yibo Wang",
      "Yangning Li",
      "Kay Liu",
      "Philip S. Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1487": {
    "title": "The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jenalea Rajab",
      "Anuoluwapo Aremu",
      "Everlyn Asiko Chimoto",
      "Dale Dunbar",
      "Graham Morrissey",
      "Fadel Thior",
      "Luandrie Potgieter",
      "Jessica Ojo",
      "Atnafu Lambebo Tonja",
      "Wilhelmina NdapewaOnyothi Nekoto",
      "Pelonomi Moiloa",
      "Jade Abbott",
      "Vukosi Marivate",
      "Benjamin Rosman"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1488": {
    "title": "Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daichi Hayakawa",
      "Issei Sato"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1489": {
    "title": "Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James C. Douglas",
      "Yidong Gan",
      "Ben Hachey",
      "Jonathan K. Kummerfeld"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1490": {
    "title": "Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alperen Yildiz",
      "Sin G Teo",
      "Yiling Lou",
      "Yebo Feng",
      "Chong Wang",
      "Dinil Mon Divakaran"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1491": {
    "title": "Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junlin Li",
      "Guodong Du",
      "Jing Li",
      "Sim Kuan Goh",
      "Wenya Wang",
      "Yequan Wang",
      "Fangming Liu",
      "Ho-Kin Tang",
      "Saleh Alharbi",
      "Daojing He",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1492": {
    "title": "Serial Lifelong Editing via Mixture of Knowledge Experts",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YuJu Cheng",
      "Yu-Chu Yu",
      "Kai-Po Chang",
      "Yu-Chiang Frank Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1493": {
    "title": "A Survey on Efficient Large Language Model Training: From Data-centric Perspectives",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyu Luo",
      "Bohan Wu",
      "Xiao Luo",
      "Zhiping Xiao",
      "Yiqiao Jin",
      "Rong-Cheng Tu",
      "Nan Yin",
      "Yifan Wang",
      "Jingyang Yuan",
      "Wei Ju",
      "Ming Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1494": {
    "title": "IMOL: Incomplete-Modality-Tolerant Learning for Multi-Domain Fake News Video Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zeng",
      "Jiaying Wu",
      "Minnan Luo",
      "Herun Wan",
      "Xiangzheng Kong",
      "Zihan Ma",
      "Guang Dai",
      "Qinghua Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1495": {
    "title": "DDxTutor: Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Wu",
      "Zheyao Gao",
      "Longfei Gou",
      "Qi Dou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1496": {
    "title": "SocialEval: Evaluating Social Intelligence of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinfeng Zhou",
      "Yuxuan Chen",
      "Yihan Shi",
      "Xuanming Zhang",
      "Leqi Lei",
      "Yi Feng",
      "Zexuan Xiong",
      "Miao Yan",
      "Xunzhi Wang",
      "Yaru Cao",
      "Jianing Yin",
      "Shuai Wang",
      "Quanyu Dai",
      "Zhenhua Dong",
      "Hongning Wang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1497": {
    "title": "Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Messal Monem Miah",
      "Adrita Anika",
      "Xi Shi",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1498": {
    "title": "Analyzing and Mitigating Inconsistency in Discrete Speech Tokens for Neural Codec Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenrui Liu",
      "Zhifang Guo",
      "Jin Xu",
      "Yuanjun Lv",
      "Yunfei Chu",
      "Zemin Liu",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1499": {
    "title": "PlanningArena: A Modular Benchmark for Multidimensional Evaluation of Planning and Tool Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Zheng",
      "Tianle Cui",
      "Chuwen Xie",
      "Jiahui Pan",
      "Qianglong Chen",
      "Lewei He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1500": {
    "title": "FocusLLM: Precise Understanding of Long Context by Dynamic Condensing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Li",
      "Yike Zhang",
      "Tengyu Pan",
      "Yutao Sun",
      "Zhichao Duan",
      "Junjie Fang",
      "Rong Han",
      "Zixuan Wang",
      "Jianyong Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1501": {
    "title": "Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tengyu Pan",
      "Zhichao Duan",
      "Zhenyu Li",
      "Bowen Dong",
      "Ning Liu",
      "Xiuxing Li",
      "Jianyong Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1502": {
    "title": "GPT-4 as a Homework Tutor Can Improve Student Engagement and Learning Outcomes",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Vanzo",
      "Sankalan Pal Chowdhury",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1503": {
    "title": "Diffusion Models Through a Global Lens: Are They Culturally Inclusive?",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zahra Bayramli",
      "Ayhan Suleymanzade",
      "Na Min An",
      "Huzama Ahmad",
      "Eunsu Kim",
      "Junyeong Park",
      "James Thorne",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1504": {
    "title": "Efficient Safety Alignment of Large Language Models via Preference Re-ranking and Representation-based Reward Modeling",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deng Qiyuan",
      "Xuefeng Bai",
      "Kehai Chen",
      "Yaowei Wang",
      "Liqiang Nie",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1505": {
    "title": "English-based acoustic models perform well in the forced alignment of two English-based Pacific Creoles",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sam Passmore",
      "Lila San Roque",
      "Kirsty Gillespie",
      "Saurabh Nath",
      "Kira Davey",
      "Keira Mullan",
      "Tim Cawley",
      "Jennifer Biggs",
      "Rosey Billington",
      "Bethwyn Evans",
      "Nick Thieberger",
      "Danielle Barth"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1506": {
    "title": "Subtle Errors in Reasoning: Preference Learning via Error-injected Self-editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaishuai Xu",
      "Tiezheng Yu",
      "Wenjun Hou",
      "Yi Cheng",
      "Chak Tou Leong",
      "Liangyou Li",
      "Xin Jiang",
      "Lifeng Shang",
      "Qun Liu",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1507": {
    "title": "Truth Knows No Language: Evaluating Truthfulness Beyond English",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Blanca Calvo Figueras",
      "Eneko Sagarzazu",
      "Julen Etxaniz",
      "Jeremy Barnes",
      "Pablo Gamallo",
      "Iria de-Dios-Flores",
      "Rodrigo Agerri"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1508": {
    "title": "Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1509": {
    "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jann Railey Montalan",
      "Jimson Paulo Layacan",
      "David Demitri Africa",
      "Richell Isaiah S. Flores",
      "Michael T. Lopez Ii",
      "Theresa Denise Magsajo",
      "Anjanette Cayabyab",
      "William Chandra Tjhi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1510": {
    "title": "HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michiel Van Der Meer",
      "Pavel Korshunov",
      "Sébastien Marcel",
      "Lonneke Van Der Plas"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1511": {
    "title": "CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weichen Zhang",
      "Chen Gao",
      "Shiquan Yu",
      "Ruiying Peng",
      "Baining Zhao",
      "Qian Zhang",
      "Jinqiang Cui",
      "Xinlei Chen",
      "Yong Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1512": {
    "title": "It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iuliia Zaitova",
      "Badr M. Abdullah",
      "Wei Xue",
      "Dietrich Klakow",
      "Bernd Möbius",
      "Tania Avgustinova"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1513": {
    "title": "PolyNarrative: A Multilingual, Multilabel, Multi-domain Dataset for Narrative Extraction from News Articles",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikolaos Nikolaidis",
      "Nicolas Stefanovitch",
      "Purificação Silvano",
      "Dimitar Iliyanov Dimitrov",
      "Roman Yangarber",
      "Nuno Guimarães",
      "Elisa Sartori",
      "Ion Androutsopoulos",
      "Preslav Nakov",
      "Giovanni Da San Martino",
      "Jakub Piskorski"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1514": {
    "title": "A Parameter-Efficient and Fine-Grained Prompt Learning for Vision-Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongbin Guo",
      "Shuzhen Li",
      "Zhulin Liu",
      "Tong Zhang",
      "C.L.Philip Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1515": {
    "title": "Persona Dynamics: Unveiling the Impact of Persona Traits on Agents in Text-Based Games",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungwon Lim",
      "Seungbeen Lee",
      "Dongjun Min",
      "Youngjae Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1516": {
    "title": "SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ying",
      "Zihong Chen",
      "Zhefan Wang",
      "Wanli Jiang",
      "Chenyang Wang",
      "Zhonghang Yuan",
      "Haoyang Su",
      "Huanjun Kong",
      "Fan Yang",
      "Nanqing Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1517": {
    "title": "-Stance: A Large-Scale Real World Dataset of Stances in Legal Argumentation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ankita Gupta",
      "Douglas Rice",
      "Brendan O’Connor"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1518": {
    "title": "Re3Syn: A Dependency-Based Data Synthesis Framework for Long-Context Post-training",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyang Zhang",
      "Ziqiang Liu",
      "Huiming Wang",
      "Renke Shan",
      "Li Kuang",
      "Lu Wang",
      "De Wen Soh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1519": {
    "title": "Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyoung Jang",
      "Minwook Bae",
      "Minji Kim",
      "Dilek Hakkani-Tür",
      "Hyounghun Kim"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1520": {
    "title": "Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Li",
      "Chen Gong",
      "Guohong Fu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1521": {
    "title": "TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yindu Su",
      "Huike Zou",
      "Lin Sun",
      "Ting Zhang",
      "Haiyang Yang",
      "Chen Li Yu",
      "David Lo",
      "Qingheng Zhang",
      "Shuguang Han",
      "Jufeng Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1522": {
    "title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruirui Chen",
      "Weifeng Jiang",
      "Chengwei Qin",
      "Cheston Tan"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1523": {
    "title": "Completing A Systematic Review in Hours instead of Months with Interactive AI Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Qiu",
      "Shijie Chen",
      "Yu Su",
      "Po-Yin Yen",
      "Han Wei Shen"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1524": {
    "title": "CMHKF: Cross-Modality Heterogeneous Knowledge Fusion for Weakly Supervised Video Anomaly Detection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guohua Wang",
      "Shengping Song",
      "Wuchun He",
      "Yongsen Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1525": {
    "title": "CLaSp: In-Context Layer Skip for Self-Speculative Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longze Chen",
      "Renke Shan",
      "Huiming Wang",
      "Lu Wang",
      "Ziqiang Liu",
      "Run Luo",
      "Jiawei Wang",
      "Hamid Alinejad-Rokny",
      "Min Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1526": {
    "title": "Teaching Text Agents to Learn Sequential Decision Making from Failure",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Canasai Kruengkrai",
      "Koichiro Yoshino"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1527": {
    "title": "The Harmonic Structure of Information Contours",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eleftheria Tsipidi",
      "Samuel Kiegeland",
      "Franz Nowak",
      "Tianyang Xu",
      "Ethan Wilcox",
      "Alex Warstadt",
      "Ryan Cotterell",
      "Mario Giulianelli"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1528": {
    "title": "REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Navve Wasserman",
      "Roi Pony",
      "Oshri Naparstek",
      "Adi Raz Goldfarb",
      "Eli Schwartz",
      "Udi Barzelay",
      "Leonid Karlinsky"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1529": {
    "title": "Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mats Faulborn",
      "Indira Sen",
      "Max Pellert",
      "Andreas Spitz",
      "David Garcia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1530": {
    "title": "LongSafety: Evaluating Long-Context Safety of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yida Lu",
      "Jiale Cheng",
      "Zhexin Zhang",
      "Shiyao Cui",
      "Cunxiang Wang",
      "Xiaotao Gu",
      "Yuxiao Dong",
      "Jie Tang",
      "Hongning Wang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1531": {
    "title": "Exploiting Contextual Knowledge in LLMs through 𝒱-usable Information based Layer Enhancement",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaowei Yuan",
      "Zhao Yang",
      "Ziyang Huang",
      "Yequan Wang",
      "Siqi Fan",
      "Yiming Ju",
      "Jun Zhao",
      "Kang Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1532": {
    "title": "Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sooyung Choi",
      "Jaehyeok Lee",
      "Xiaoyuan Yi",
      "Jing Yao",
      "Xing Xie",
      "JinYeong Bak"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1533": {
    "title": "Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hani Alomari",
      "Anushka Sivakumar",
      "Andrew Zhang",
      "Chris Thomas"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1534": {
    "title": "The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Chen",
      "Misha Teplitskiy",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1535": {
    "title": "MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ching-Wen Yang",
      "Zhi-Quan Feng",
      "Ying-Jia Lin",
      "Che Wei Chen",
      "Kun-da Wu",
      "Hao Xu",
      "Yao Jui-Feng",
      "Hung-Yu Kao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1536": {
    "title": "Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clément Dumas",
      "Chris Wendler",
      "Veniamin Veselovsky",
      "Giovanni Monea",
      "Robert West"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1537": {
    "title": "Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Vegner",
      "Sydelle De Souza",
      "Valentin Forch",
      "Martha Lewis",
      "Leonidas A. A. Doumas"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1538": {
    "title": "Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boheng Sheng",
      "Jiacheng Yao",
      "Meicong Zhang",
      "Guoxiu He"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1539": {
    "title": "DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rong Cheng",
      "Jinyi Liu",
      "Yan Zheng",
      "Fei Ni",
      "Jiazhen Du",
      "Hangyu Mao",
      "Fuzheng Zhang",
      "Bo Wang",
      "Jianye Hao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1540": {
    "title": "Deliberate Reasoning in Language Models as Structure-Aware Planning with an Accurate World Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siheng Xiong",
      "Ali Payani",
      "Yuan Yang",
      "Faramarz Fekri"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1541": {
    "title": "Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinxin Liu",
      "Aaron Thomas",
      "Cheng Zhang",
      "Jianyi Cheng",
      "Yiren Zhao",
      "Xitong Gao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1542": {
    "title": "Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emily Xiao",
      "Chin-Jou Li",
      "Yilin Zhang",
      "Graham Neubig",
      "Amanda Bertsch"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1543": {
    "title": "ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Pan",
      "Dylan Zhang",
      "Hanning Zhang",
      "Xingyuan Pan",
      "Minrui Xu",
      "Jipeng Zhang",
      "Renjie Pi",
      "Xiaoyu Wang",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1544": {
    "title": "PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Ji",
      "Donghai Hong",
      "Borong Zhang",
      "Boyuan Chen",
      "Josef Dai",
      "Boren Zheng",
      "Tianyi Alex Qiu",
      "Jiayi Zhou",
      "Kaile Wang",
      "Boxun Li",
      "Sirui Han",
      "Yike Guo",
      "Yaodong Yang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1545": {
    "title": "What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Li",
      "Yanhong Li",
      "Tianyi Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1546": {
    "title": "Beyond Text Compression: Evaluating Tokenizers Across Scales",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas F. Lotz",
      "António V. Lopes",
      "Stephan Peitz",
      "Hendra Setiawan",
      "Leonardo Emili"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1547": {
    "title": "Emergent Abilities of Large Language Models under Continued Pre-training for Language Adaptation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Elhady",
      "Eneko Agirre",
      "Mikel Artetxe"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1548": {
    "title": "R-Fairness: Assessing Fairness of Ranking in Subjective Data",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Balzotti",
      "Donatella Firmani",
      "Jerin George Mathew",
      "Riccardo Torlone",
      "Sihem Amer-Yahia"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1549": {
    "title": "RePanda: Pandas-powered Tabular Verification and Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atoosa Chegini",
      "Keivan Rezaei",
      "Hamid Eghbalzadeh",
      "Soheil Feizi"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1550": {
    "title": "Towards Style Alignment in Cross-Cultural Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shreya Havaldar",
      "Adam Stein",
      "Eric Wong",
      "Lyle Ungar"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1551": {
    "title": "TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeffrey Li",
      "Mohammadreza Armandpour",
      "Seyed Iman Mirzadeh",
      "Sachin Mehta",
      "Vaishaal Shankar",
      "Raviteja Vemulapalli",
      "Samy Bengio",
      "Oncel Tuzel",
      "Mehrdad Farajtabar",
      "Hadi Pouransari",
      "Fartash Faghri"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1552": {
    "title": "Entailed Between the Lines: Incorporating Implication into NLI",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shreya Havaldar",
      "Hamidreza Alvari",
      "John Palowitch",
      "Mohammad Javad Hosseini",
      "Senaka Buthpitiya",
      "Alex Fabrikant"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1553": {
    "title": "Multi-Level Explanations for Generative Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas Monteiro Paes",
      "Dennis Wei",
      "Hyo Jin Do",
      "Hendrik Strobelt",
      "Ronny Luss",
      "Amit Dhurandhar",
      "Manish Nagireddy",
      "Karthikeyan Natesan Ramamurthy",
      "Prasanna Sattigeri",
      "Werner Geyer",
      "Soumya Ghosh"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1554": {
    "title": "A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Đorđe Klisura",
      "Astrid R Bernaga Torres",
      "Anna Karen Gárate-Escamilla",
      "Rajesh Roshan Biswal",
      "Ke Yang",
      "Hilal Pataci",
      "Anthony Rios"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1555": {
    "title": "Low-Bit Quantization Favors Undertrained LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Ouyang",
      "Tao Ge",
      "Thomas Hartvigsen",
      "Zhisong Zhang",
      "Haitao Mi",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1557": {
    "title": "LETS-C: Leveraging Text Embedding for Time Series Classification",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rachneet Kaur",
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1558": {
    "title": "UrbanVideo-Bench: Benchmarking Vision-Language Models on Embodied Intelligence with Video Data in Urban Spaces",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baining Zhao",
      "Jianjie Fang",
      "Zichao Dai",
      "Ziyou Wang",
      "Jirong Zha",
      "Weichen Zhang",
      "Chen Gao",
      "Yue Wang",
      "Jinqiang Cui",
      "Xinlei Chen",
      "Yong Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1559": {
    "title": "HELIOS: Harmonizing Early Fusion, Late Fusion, and LLM Reasoning for Multi-Granular Table-Text Retrieval",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungho Park",
      "Joohyung Yun",
      "Jongwuk Lee",
      "Wook-Shin Han"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1560": {
    "title": "ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adhiraj Ghosh",
      "Sebastian Dziadzio",
      "Ameya Prabhu",
      "Vishaal Udandarao",
      "Samuel Albanie",
      "Matthias Bethge"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1561": {
    "title": "La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "María Grandury",
      "Javier Aula-Blasco",
      "Júlia Falcão",
      "Clémentine Fourrier",
      "Miguel González Saiz",
      "Gonzalo Martínez",
      "Gonzalo Santamaria Gomez",
      "Rodrigo Agerri",
      "Nuria Aldama García",
      "Luis Chiruzzo",
      "Javier Conde",
      "Helena Gomez Adorno",
      "Marta Guerrero Nieto",
      "Guido Ivetta",
      "Natàlia López Fuertes",
      "Flor Miriam Plaza-del-Arco",
      "María-Teresa Martín-Valdivia",
      "Helena Montoro Zamorano",
      "Carmen Muñoz Sanz",
      "Pedro Reviriego",
      "Leire Rosado Plaza",
      "Alejandro Vaca Serrano",
      "Estrella Vallecillo-Rodríguez",
      "Jorge Vallego",
      "Irune Zubiaga"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1562": {
    "title": "Why Prompt Design Matters and Works: A Complexity Analysis of Prompt Search Space in LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Zhang",
      "Juntai Cao",
      "Chenyu You",
      "Dujian Ding"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1563": {
    "title": "Energy Considerations of Large Language Model Inference and Efficiency Optimizations",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jared Fernandez",
      "Clara Na",
      "Vashisth Tiwari",
      "Yonatan Bisk",
      "Sasha Luccioni",
      "Emma Strubell"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1564": {
    "title": "Optimizing Pre-Training Data Mixtures with Mixtures of Data Expert Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lior Belenki",
      "Alekh Agarwal",
      "Tianze Shi",
      "Kristina Toutanova"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1565": {
    "title": "BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ran Xin",
      "Chenguang Xi",
      "Jie Yang",
      "Feng Chen",
      "Hang Wu",
      "Xia Xiao",
      "Yifan Sun",
      "Shen Zheng",
      "Ming Ding"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1566": {
    "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Yin",
      "Zifeng Wang",
      "I-Hung Hsu",
      "Jun Yan",
      "Ke Jiang",
      "Yanfei Chen",
      "Jindong Gu",
      "Long Le",
      "Kai-Wei Chang",
      "Chen-Yu Lee",
      "Hamid Palangi",
      "Tomas Pfister"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1567": {
    "title": "Logic-Regularized Verifier Elicits Reasoning from LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Wang",
      "Changzhi Sun",
      "Lian Cheng",
      "Yuanbin Wu",
      "Dell Zhang",
      "Xiaoling Wang",
      "Xuelong Li"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1568": {
    "title": "Squeezed Attention: Accelerating Long Context Length LLM Inference",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Coleman Richard Charles Hooper",
      "Sehoon Kim",
      "Hiva Mohammadzadeh",
      "Monishwaran Maheswaran",
      "Sebastian Zhao",
      "June Paik",
      "Michael W. Mahoney",
      "Kurt Keutzer",
      "Amir Gholami"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1569": {
    "title": "LangMark: A Multilingual Dataset for Automatic Post-Editing",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diego Velazquez",
      "Mikaela Grace",
      "Konstantinos Karageorgos",
      "Lawrence Carin",
      "Aaron Schliem",
      "Dimitrios Zaikis",
      "Roger Wechsler"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1570": {
    "title": "Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guodong Du",
      "Zitao Fang",
      "Jing Li",
      "Junlin Li",
      "Runhua Jiang",
      "Shuyang Yu",
      "Yifei Guo",
      "Yangneng Chen",
      "Sim Kuan Goh",
      "Ho-Kin Tang",
      "Daojing He",
      "Honghai Liu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1571": {
    "title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zenghui Yuan",
      "Yangming Xu",
      "Jiawen Shi",
      "Pan Zhou",
      "Lichao Sun"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1572": {
    "title": "Where Are We? Evaluating LLM Performance on African Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ife Adebara",
      "Hawau Olamide Toyin",
      "Nahom Tesfu Ghebremichael",
      "AbdelRahim A. Elmadany",
      "Muhammad Abdul-Mageed"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1573": {
    "title": "Beyond Output Matching: Bidirectional Alignment for Enhanced In-Context Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengwei Qin",
      "Wenhan Xia",
      "Fangkai Jiao",
      "Chen Chen",
      "Yuchen Hu",
      "Bosheng Ding",
      "Ruirui Chen",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1574": {
    "title": "CiteEval: Principle-Driven Citation Evaluation for Source Attribution",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yumo Xu",
      "Peng Qi",
      "Jifan Chen",
      "Kunlun Liu",
      "Rujun Han",
      "Lan Liu",
      "Bonan Min",
      "Vittorio Castelli",
      "Arshit Gupta",
      "Zhiguo Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1575": {
    "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengkang Hu",
      "Tianxing Chen",
      "Qiguang Chen",
      "Yao Mu",
      "Wenqi Shao",
      "Ping Luo"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1576": {
    "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Shi",
      "Rongkeng Liang",
      "Yong Xu"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1577": {
    "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiqi Sui",
      "Juan Diego Rodriguez",
      "Philippe Laban",
      "J. Dean Murphy",
      "Joseph P. Dexter",
      "Richard Jean So",
      "Samuel Baker",
      "Pramit Chaudhuri"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1578": {
    "title": "Efficient Domain Continual pretraining by Mitigating the Stability Gap",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiduo Guo",
      "Jie Fu",
      "Huishuai Zhang",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1579": {
    "title": "Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fakhraddin Alwajih",
      "Abdellah El Mekki",
      "Samar Mohamed Magdy",
      "AbdelRahim A. Elmadany",
      "Omer Nacar",
      "El Moatez Billah Nagoudi",
      "Reem Abdel-Salam",
      "Hanin Atwany",
      "Youssef Nafea",
      "Abdulfattah Mohammed Yahya",
      "Rahaf Alhamouri",
      "Hamzah A. Alsayadi",
      "Hiba Zayed",
      "Sara Shatnawi",
      "Serry Sibaee",
      "Yasir Ech-chammakhy",
      "Walid Al-Dhabyani",
      "Marwa Mohamed Ali",
      "Imen Jarraya",
      "Ahmed Oumar El-Shangiti",
      "Aisha Alraeesi",
      "Mohammed Anwar AL-Ghrawi",
      "Abdulrahman S. Al-Batati",
      "Elgizouli Mohamed",
      "Noha Taha Elgindi",
      "Muhammed Saeed",
      "Houdaifa Atou",
      "Issam Ait Yahia",
      "Abdelhak Bouayad",
      "Mohammed Machrouh",
      "Amal Makouar",
      "Dania Alkawi",
      "Mukhtar Mohamed",
      "Safaa Taher Abdelfadil",
      "Amine Ziad Ounnoughene",
      "Anfel Rouabhia",
      "Rwaa Assi",
      "Ahmed Sorkatti",
      "Mohamedou Cheikh Tourad",
      "Anis Koubaa",
      "Ismail Berrada",
      "Mustafa Jarrar",
      "Shady Shehata",
      "Muhammad Abdul-Mageed"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1580": {
    "title": "NewsInterview: a Dataset and a Playground to Evaluate LLMs' Grounding Gap via Informational Interviews",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Spangher",
      "Michael Lu",
      "Sriya Kalyan",
      "Hyundong Justin Cho",
      "Tenghao Huang",
      "Weiyan Shi",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1581": {
    "title": "CFBench: A Comprehensive Constraints-Following Benchmark for LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Zhang",
      "ChengLIn Zhu",
      "Yanjun Shen",
      "Wenjing Luo",
      "Yan Zhang",
      "Hao Liang",
      "Tao Zhang",
      "Fan Yang",
      "Mingan Lin",
      "Yujing Qiao",
      "Weipeng Chen",
      "Bin Cui",
      "Wentao Zhang",
      "Zenan Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1582": {
    "title": "Towards Building Large Scale Datasets and State-of-the-Art Automatic Speech Translation Systems for 14 Indian Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashwin Sankar",
      "Sparsh Jain",
      "Nikhil Narasimhan",
      "Devilal Choudhary",
      "Dhairya Suman",
      "Mohammed Safi Ur Rahman Khan",
      "Anoop Kunchukuttan",
      "Mitesh M Khapra",
      "Raj Dabre"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1583": {
    "title": "CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Tian",
      "Fan Liu",
      "Jingyuan Zhang",
      "V. W.",
      "Yupeng Hu",
      "Liqiang Nie"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1584": {
    "title": "Mapping 1,000+ Language Models via the Log-Likelihood Vector",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Momose Oyama",
      "Hiroaki Yamagiwa",
      "Yusuke Takase",
      "Hidetoshi Shimodaira"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1585": {
    "title": "ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaochen Hong",
      "Haofei Yu",
      "Jiaxuan You"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1586": {
    "title": "Robust Estimation of Population-Level Effects in Repeated-Measures NLP Experimental Designs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alejandro Benito-Santos",
      "Adrian Ghajari",
      "Víctor Fresno"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1587": {
    "title": "FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Farima Fatahi Bayat",
      "Lechen Zhang",
      "Sheza Munir",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1588": {
    "title": "Training-free LLM Merging for Multi-task Learning",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichuan Fu",
      "Xian Wu",
      "Yejing Wang",
      "Wanyu Wang",
      "Shanshan Ye",
      "Hongzhi Yin",
      "Yi Chang",
      "Yefeng Zheng",
      "Xiangyu Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1589": {
    "title": "Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Derek Ma",
      "Yanna Ding",
      "Zijie Huang",
      "Jianxi Gao",
      "Yizhou Sun",
      "Wei Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1590": {
    "title": "Comparison-based Active Preference Learning for Multi-dimensional Personalization",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minhyeon Oh",
      "Seungjoon Lee",
      "Jungseul Ok"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1591": {
    "title": "OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siming Huang",
      "Tianhao Cheng",
      "Jason Klein Liu",
      "Weidi Xu",
      "Jiaran Hao",
      "Liuyihan Song",
      "Yang Xu",
      "Jian Yang",
      "Jiaheng Liu",
      "Chenchen Zhang",
      "Linzheng Chai",
      "Ruifeng Yuan",
      "Xianzhen Luo",
      "Qiufeng Wang",
      "YuanTao Fan",
      "Qingfu Zhu",
      "Zhaoxiang Zhang",
      "Yang Gao",
      "Jie Fu",
      "Qian Liu",
      "Houyi Li",
      "Ge Zhang",
      "Yuan Qi",
      "Xu Yinghui",
      "Wei Chu",
      "Zili Wang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1592": {
    "title": "LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chansung Park",
      "Juyong Jiang",
      "Fan Wang",
      "Sayak Paul",
      "Jing Tang"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1593": {
    "title": "AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anastasia Ivanova",
      "Bakaeva Eva",
      "Zoya Volovikova",
      "Alexey Kovalev",
      "Aleksandr Panov"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1594": {
    "title": "SocialCC: Interactive Evaluation for Cultural Competence in Language Agents",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jincenzi Wu",
      "Jianxun Lian",
      "Dingdong Wang",
      "Helen M. Meng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1595": {
    "title": "Scalable Vision Language Model Training via High Quality Data Curation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyuan Dong",
      "Zijian Kang",
      "Weijie Yin",
      "LiangXiao LiangXiao",
      "ChaoFeng ChaoFeng",
      "Ran Jiao"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1596": {
    "title": "GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sunkyung Lee",
      "Minjin Choi",
      "Eunseong Choi",
      "Hye-young Kim",
      "Jongwuk Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1597": {
    "title": "Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Ji",
      "Bin Guo",
      "Yuanbin Wu",
      "Qipeng Guo",
      "Shenlixing Shenlixing",
      "Chenzhan Chenzhan",
      "Xipeng Qiu",
      "Qi Zhang",
      "Tao Gui"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1598": {
    "title": "TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoxuan Wu",
      "Zijian Zhou",
      "Arun Verma",
      "Alok Prakash",
      "Daniela Rus",
      "Bryan Kian Hsiang Low"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1599": {
    "title": "Introducing Verification Task of Set Consistency with Set-Consistency Energy Networks",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mooho Song",
      "Hye Ryung Son",
      "Jay-Yoon Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1600": {
    "title": "Language Models can Subtly Deceive Without Lying: A Case Study on Strategic Phrasing in Legislation",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atharvan Dogra",
      "Krishna Pillutla",
      "Ameet Deshpande",
      "Ananya B. Sai",
      "John J Nay",
      "Tanmay Rajpurohit",
      "Ashwin Kalyan",
      "Balaraman Ravindran"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1601": {
    "title": "AfroCS-xs: Creating a Compact, High-Quality, Human-Validated Code-Switched Dataset for African Languages",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kayode Olaleye",
      "Arturo Oncevay",
      "Mathieu Sibue",
      "Nombuyiselo Zondi",
      "Michelle Terblanche",
      "Sibongile Mapikitla",
      "Richard Lastrucci",
      "Charese Smiley",
      "Vukosi Marivate"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1602": {
    "title": "Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Reza Qorib",
      "Junyi Li",
      "Hwee Tou Ng"
    ]
  },
  "https://aclanthology.org/2025.acl-long.1603": {
    "title": "Design Choices for Extending the Context Length of Visual Language Models",
    "volume": "long",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mukai Li",
      "Lei Li",
      "Shansan Gong",
      "Qi Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.1": {
    "title": "Towards LLM-powered Attentive Listener: A Pragmatic Approach through Quantity Self-Repair",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junlin Li",
      "Peng Bo",
      "Yu-Yin Hsu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.2": {
    "title": "MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yin Cai",
      "Zhouhong Gu",
      "Zhaohan Du",
      "Zheyu Ye",
      "Shaosheng Cao",
      "Yiqian Xu",
      "Hongwei Feng",
      "Ping Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-short.3": {
    "title": "Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gyutae Park",
      "Ingeol Baek",
      "Byeongjeong Kim",
      "Joongbo Shin",
      "Hwanhee Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-short.4": {
    "title": "Rethinking KenLM: Good and Bad Model Ensembles for Efficient Text Quality Filtering in Large Web Corpora",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yungi Kim",
      "Hyunsoo Ha",
      "Sukyung Lee",
      "Jihoo Kim",
      "Seonghoon Yang",
      "Chanjun Park"
    ]
  },
  "https://aclanthology.org/2025.acl-short.5": {
    "title": "Automatic detection of dyslexia based on eye movements during reading in Russian",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Laurinavichyute",
      "Anastasiya Lopukhina",
      "David Robert Reich"
    ]
  },
  "https://aclanthology.org/2025.acl-short.6": {
    "title": "Doc-React: Multi-page Heterogeneous Document Question-answering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junda Wu",
      "Yu Xia",
      "Tong Yu",
      "Xiang Chen",
      "Sai Sree Harsha",
      "Akash V Maharaj",
      "Ruiyi Zhang",
      "Victor Bursztyn",
      "Sungchul Kim",
      "Ryan A. Rossi",
      "Julian McAuley",
      "Yunyao Li",
      "Ritwik Sinha"
    ]
  },
  "https://aclanthology.org/2025.acl-short.7": {
    "title": "ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mikołaj Pokrywka",
      "Wojciech Kusa",
      "Mieszko Rutkowski",
      "Mikołaj Koszowski"
    ]
  },
  "https://aclanthology.org/2025.acl-short.8": {
    "title": "A Measure of the System Dependence of Automated Metrics",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pius Von Däniken",
      "Jan Milan Deriu",
      "Mark Cieliebak"
    ]
  },
  "https://aclanthology.org/2025.acl-short.9": {
    "title": "Call for Rigor in Reporting Quality of Instruction Tuning Data",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeonseok Moon",
      "Jaehyung Seo",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2025.acl-short.10": {
    "title": "BQA: Body Language Question Answering Dataset for Video Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shintaro Ozaki",
      "Kazuki Hayashi",
      "Miyu Oba",
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-short.11": {
    "title": "Grounded, or a Good Guesser? A Per-Question Balanced Dataset to Separate Blind from Grounded Models for Embodied Question Answering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miles Shelton",
      "Nate Wingerd",
      "Kritim K Rijal",
      "Ayush Garg",
      "Adelina Gutic",
      "Brett Barnes",
      "Catherine Finegan-Dollak"
    ]
  },
  "https://aclanthology.org/2025.acl-short.12": {
    "title": "Learning Sparsity for Effective and Efficient Music Performance Question Answering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingjian Diao",
      "Tianzhen Yang",
      "Chunhui Zhang",
      "Weiyi Wu",
      "Ming Cheng",
      "Jiang Gui"
    ]
  },
  "https://aclanthology.org/2025.acl-short.13": {
    "title": "Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhang",
      "Zhiyuan Liao",
      "Yansong Feng"
    ]
  },
  "https://aclanthology.org/2025.acl-short.14": {
    "title": "Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suet-Ying Lam",
      "Qingcheng Zeng",
      "Jingyi Wu",
      "Rob Voigt"
    ]
  },
  "https://aclanthology.org/2025.acl-short.15": {
    "title": "Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution's Characteristics",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Jaime Yu Flores",
      "Ori Ernst",
      "Jackie CK Cheung"
    ]
  },
  "https://aclanthology.org/2025.acl-short.16": {
    "title": "KnowShiftQA: How Robust are RAG Systems when Textbook Knowledge Shifts in K-12 Education?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshi Zheng",
      "Weihan Li",
      "Jiaxin Bai",
      "Weiqi Wang",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.acl-short.17": {
    "title": "Improving Parallel Sentence Mining for Low-Resource and Endangered Languages",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shu Okabe",
      "Katharina Hämmerl",
      "Alexander Fraser"
    ]
  },
  "https://aclanthology.org/2025.acl-short.18": {
    "title": "Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayu Liu",
      "Qing Zong",
      "Weiqi Wang",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.acl-short.19": {
    "title": "Limited-Resource Adapters Are Regularizers, Not Linguists",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcell Fekete",
      "Nathaniel Romney Robinson",
      "Ernests Lavrinovics",
      "Djeride Jean-Baptiste",
      "Raj Dabre",
      "Johannes Bjerva",
      "Heather Lent"
    ]
  },
  "https://aclanthology.org/2025.acl-short.20": {
    "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Bavaresco",
      "Raffaella Bernardi",
      "Leonardo Bertolazzi",
      "Desmond Elliott",
      "Raquel Fernández",
      "Albert Gatt",
      "Esam Ghaleb",
      "Mario Giulianelli",
      "Michael Hanna",
      "Alexander Koller",
      "Andre Martins",
      "Philipp Mondorf",
      "Vera Neplenbroek",
      "Sandro Pezzelle",
      "Barbara Plank",
      "David Schlangen",
      "Alessandro Suglia",
      "Aditya K Surikuchi",
      "Ece Takmaz",
      "Alberto Testoni"
    ]
  },
  "https://aclanthology.org/2025.acl-short.21": {
    "title": "FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Liu",
      "Xiao Yu",
      "Wenxuan Zhou",
      "Jindong Gu",
      "Volker Tresp"
    ]
  },
  "https://aclanthology.org/2025.acl-short.22": {
    "title": "Combining Domain and Alignment Vectors Provides Better Knowledge-Safety Trade-offs in LLMs",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Megh Thakkar",
      "Quentin Fournier",
      "Matthew Riemer",
      "Pin-Yu Chen",
      "Amal Zouaq",
      "Payel Das",
      "Sarath Chandar"
    ]
  },
  "https://aclanthology.org/2025.acl-short.23": {
    "title": "Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shira Wein"
    ]
  },
  "https://aclanthology.org/2025.acl-short.24": {
    "title": "Subword models struggle with word learning, but surprisal hides it",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bastian Bunzeck",
      "Sina Zarrieß"
    ]
  },
  "https://aclanthology.org/2025.acl-short.25": {
    "title": "LLM as Entity Disambiguator for Biomedical Entity-Linking",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christophe Ye",
      "Cassie S. Mitchell"
    ]
  },
  "https://aclanthology.org/2025.acl-short.26": {
    "title": "Towards Geo-Culturally Grounded LLM Generations",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piyawat Lertvittayakumjorn",
      "David Kinney",
      "Vinodkumar Prabhakaran",
      "Donald Martin Jr.",
      "Sunipa Dev"
    ]
  },
  "https://aclanthology.org/2025.acl-short.27": {
    "title": "MUSTS: MUltilingual Semantic Textual Similarity Benchmark",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tharindu Ranasinghe",
      "Hansi Hettiarachchi",
      "Constantin Orasan",
      "Ruslan Mitkov"
    ]
  },
  "https://aclanthology.org/2025.acl-short.28": {
    "title": "Can Large Language Models Accurately Generate Answer Keys for Health-related Questions?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davis Bartels",
      "Deepak Gupta",
      "Dina Demner-Fushman"
    ]
  },
  "https://aclanthology.org/2025.acl-short.29": {
    "title": "Literary Evidence Retrieval via Long-Context Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katherine Thai",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2025.acl-short.30": {
    "title": "A Little Human Data Goes A Long Way",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dhananjay Ashok",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2025.acl-short.31": {
    "title": "Seeking Rational Demonstrations for Large Language Models: A Domain Generalization Approach to Unsupervised Cross-Domain Keyphrase Generation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangzhen Zhao",
      "Yu Yao",
      "Dechang Kong",
      "Zhenjiang Dong"
    ]
  },
  "https://aclanthology.org/2025.acl-short.32": {
    "title": "LexKeyPlan: Planning with Keyphrases and Retrieval Augmentation for Legal Text Generation: A Case Study on European Court of Human Rights Cases",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Santosh T.y.s.s",
      "Elvin Quero Hernandez"
    ]
  },
  "https://aclanthology.org/2025.acl-short.33": {
    "title": "SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runnan Fang",
      "Xiaobin Wang",
      "Yuan Liang",
      "Shuofei Qiao",
      "Jialong Wu",
      "Zekun Xi",
      "Ningyu Zhang",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-short.34": {
    "title": "Enhancing Retrieval Systems with Inference-Time Logical Reasoning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Faltings",
      "Wei Wei",
      "Yujia Bao"
    ]
  },
  "https://aclanthology.org/2025.acl-short.35": {
    "title": "Using Subtext to Enhance Generative IDRR",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipang Wang",
      "Yu Hong",
      "Weihao Sun",
      "Guodong Zhou"
    ]
  },
  "https://aclanthology.org/2025.acl-short.36": {
    "title": "State-offset Tuning: State-based Parameter-Efficient Fine-Tuning for State Space Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonjun Kang",
      "Kevin Galim",
      "Yuchen Zeng",
      "Minjae Lee",
      "Hyung Il Koo",
      "Nam Ik Cho"
    ]
  },
  "https://aclanthology.org/2025.acl-short.37": {
    "title": "Internal and External Impacts of Natural Language Processing Papers",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-short.38": {
    "title": "An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuemei Tang",
      "Jun Wang",
      "Qi Su",
      "Chu-Ren Huang",
      "Jinghang Gu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.39": {
    "title": "Accelerating Dense LLMs via L0-regularized Mixture-of-Experts",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Zhang",
      "JiuDong Yang",
      "Taozhaowen Taozhaowen",
      "Meng Chen"
    ]
  },
  "https://aclanthology.org/2025.acl-short.40": {
    "title": "Do Multimodal Large Language Models Truly See What We Point At? Investigating Indexical, Iconic, and Symbolic Gesture Comprehension",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Noriki Nishida",
      "Koji Inoue",
      "Hideki Nakayama",
      "Mayumi Bono",
      "Katsuya Takanashi"
    ]
  },
  "https://aclanthology.org/2025.acl-short.41": {
    "title": "Fast or Slow? Integrating Fast Intuition and Deliberate Thinking for Enhancing Visual Question Answering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songtao Jiang",
      "Chenyi Zhou",
      "Yan Zhang",
      "Yeying Jin",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.42": {
    "title": "Can Community Notes Replace Professional Fact-Checkers?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nadav Borenstein",
      "Greta Warren",
      "Desmond Elliott",
      "Isabelle Augenstein"
    ]
  },
  "https://aclanthology.org/2025.acl-short.43": {
    "title": "Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihan Tan",
      "Taro Miyazaki",
      "Kazuhiro Nakadai"
    ]
  },
  "https://aclanthology.org/2025.acl-short.44": {
    "title": "Advancing Sequential Numerical Prediction in Autoregressive Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Fei",
      "Jinghui Lu",
      "Qi Sun",
      "Hao Feng",
      "Yanjie Wang",
      "Wei Shi",
      "An-Lan Wang",
      "Jingqun Tang",
      "Can Huang"
    ]
  },
  "https://aclanthology.org/2025.acl-short.45": {
    "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyein Seo",
      "Taewook Hwang",
      "Yohan Lee",
      "Sangkeun Jung"
    ]
  },
  "https://aclanthology.org/2025.acl-short.46": {
    "title": "ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duygu Sezen Islakoglu",
      "Jan-Christoph Kalo"
    ]
  },
  "https://aclanthology.org/2025.acl-short.47": {
    "title": "Human Alignment: How Much Do We Adapt to LLMs?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cazalets Tanguy",
      "Ruben Janssens",
      "Tony Belpaeme",
      "Joni Dambre"
    ]
  },
  "https://aclanthology.org/2025.acl-short.48": {
    "title": "Dynamic Order Template Prediction for Generative Aspect-Based Sentiment Analysis",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghyun Jun",
      "Hwanhee Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-short.49": {
    "title": "That doesn't sound right: Evaluating speech transcription quality in field linguistics corpora",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eric Le Ferrand",
      "Bo Jiang",
      "Joshua Hartshorne",
      "Emily Prud’hommeaux"
    ]
  },
  "https://aclanthology.org/2025.acl-short.50": {
    "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Jurayj",
      "Jeffrey Cheng",
      "Benjamin Van Durme"
    ]
  },
  "https://aclanthology.org/2025.acl-short.51": {
    "title": "Acoustic Individual Identification of White-Faced Capuchin Monkeys Using Joint Multi-Species Embeddings",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Álvaro Vega-Hidalgo",
      "Artem Abzaliev",
      "Thore Bergman",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2025.acl-short.52": {
    "title": "SELF-PERCEPT: Introspection Improves Large Language Models' Detection of Multi-Person Mental Manipulation in Conversations",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danush Khanna",
      "Pratinav Seth",
      "Sidhaarth Sredharan Murali",
      "Aditya Kumar Guru",
      "Siddharth Shukla",
      "Tanuj Tyagi",
      "Sandeep Chaurasia",
      "Kripabandhu Ghosh"
    ]
  },
  "https://aclanthology.org/2025.acl-short.53": {
    "title": "A Variational Approach for Mitigating Entity Bias in Relation Extraction",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Mensah",
      "Elena Kochkina",
      "Jabez Magomere",
      "Joy Prakash Sain",
      "Simerjot Kaur",
      "Charese Smiley"
    ]
  },
  "https://aclanthology.org/2025.acl-short.54": {
    "title": "GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammadtaha Bagherifard",
      "Sahar Rajabi",
      "Ali Edalat",
      "Yadollah Yaghoobzadeh"
    ]
  },
  "https://aclanthology.org/2025.acl-short.55": {
    "title": "The Role of Abstract Representations and Observed Preferences in the Ordering of Binomials in Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zachary Nicholas Houghton",
      "Kenji Sagae",
      "Emily Morgan"
    ]
  },
  "https://aclanthology.org/2025.acl-short.56": {
    "title": "Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Payal Mohapatra",
      "Akash Pandey",
      "Xiaoyuan Zhang",
      "Qi Zhu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.57": {
    "title": "Decoder-Only LLMs can be Masked Auto-Encoders",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dan Qiao",
      "Yuan Gao",
      "Zheming Yang",
      "Di Yang",
      "Ziheng Wu",
      "Pengcheng Lu",
      "Minghui Qiu",
      "Juntao Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.acl-short.58": {
    "title": "Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zikai Xiao",
      "Ziyang Wang",
      "Wen Ma",
      "Yan Zhang",
      "Wei Shen",
      "WangYan WangYan",
      "Luqi Gong",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.59": {
    "title": "Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Zhang",
      "Cunxiao Du",
      "Sicheng Yu",
      "Jiawei Wu",
      "Fengzhuo Zhang",
      "Wei Gao",
      "Qian Liu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.60": {
    "title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Santilli",
      "Adam Golinski",
      "Michael Kirchhof",
      "Federico Danieli",
      "Arno Blaas",
      "Miao Xiong",
      "Luca Zappella",
      "Sinead Williamson"
    ]
  },
  "https://aclanthology.org/2025.acl-short.61": {
    "title": "Memorization Inheritance in Sequence-Level Knowledge Distillation for Neural Machine Translation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Verna Dankers",
      "Vikas Raunak"
    ]
  },
  "https://aclanthology.org/2025.acl-short.62": {
    "title": "CoRet: Improved Retriever for Code Editing",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fabio James Fehr",
      "Prabhu Teja S",
      "Luca Franceschi",
      "Giovanni Zappella"
    ]
  },
  "https://aclanthology.org/2025.acl-short.63": {
    "title": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Proietti",
      "Stefano Perrella",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2025.acl-short.64": {
    "title": "Diffusion Directed Acyclic Transformer for Non-Autoregressive Machine Translation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Nguyen-Tri",
      "Cong Dao Tran",
      "Hoang Thanh-Tung"
    ]
  },
  "https://aclanthology.org/2025.acl-short.65": {
    "title": "Efficient Knowledge Editing via Minimal Precomputation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshat Gupta",
      "Maochuan Lu",
      "Thomas Hartvigsen",
      "Gopala Anumanchipalli"
    ]
  },
  "https://aclanthology.org/2025.acl-short.66": {
    "title": "Meaning Variation and Data Quality in the Corpus of Founding Era American English",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dallas Card"
    ]
  },
  "https://aclanthology.org/2025.acl-short.67": {
    "title": "MindRef: Mimicking Human Memory for Hierarchical Reference Retrieval with Fine-Grained Location Awareness",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye Wang",
      "Xinrun Xu",
      "Zhiming Ding"
    ]
  },
  "https://aclanthology.org/2025.acl-short.68": {
    "title": "LLMs syntactically adapt their language use to their conversational partner",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Kandra",
      "Vera Demberg",
      "Alexander Koller"
    ]
  },
  "https://aclanthology.org/2025.acl-short.69": {
    "title": "TigerLLM - A Family of Bangla Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nishat Raihan",
      "Marcos Zampieri"
    ]
  },
  "https://aclanthology.org/2025.acl-short.70": {
    "title": "From Citations to Criticality: Predicting Legal Decision Influence in the Multilingual Swiss Jurisprudence",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ronja Stern",
      "Ken Kawamura",
      "Matthias Stürmer",
      "Ilias Chalkidis",
      "Joel Niklaus"
    ]
  },
  "https://aclanthology.org/2025.acl-short.71": {
    "title": "Revisiting LLMs as Zero-Shot Time Series Forecasters: Small Noise Can Break Large Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwoo Park",
      "Hyuck Lee",
      "Dohyun Lee",
      "Daehoon Gwak",
      "Jaegul Choo"
    ]
  },
  "https://aclanthology.org/2025.acl-short.72": {
    "title": "Transferring Textual Preferences to Vision-Language Understanding through Model Merging",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen-An Li",
      "Tzu-Han Lin",
      "Yun-Nung Chen",
      "Hung-yi Lee"
    ]
  },
  "https://aclanthology.org/2025.acl-short.73": {
    "title": "ProgCo: Program Helps Self-Correction of Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoshuai Song",
      "Yanan Wu",
      "Weixun Wang",
      "Jiaheng Liu",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  "https://aclanthology.org/2025.acl-short.74": {
    "title": "Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ananth Muppidi",
      "Abhilash Nandy",
      "Sambaran Bandyopadhyay"
    ]
  },
  "https://aclanthology.org/2025.acl-short.75": {
    "title": "Inconsistent Tokenizations Cause Language Models to be Perplexed by Japanese Grammar",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew Gambardella",
      "Takeshi Kojima",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ]
  },
  "https://aclanthology.org/2025.acl-short.76": {
    "title": "Unique Hard Attention: A Tale of Two Sides",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Selim Jerad",
      "Anej Svete",
      "Jiaoda Li",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2025.acl-short.77": {
    "title": "Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keqin Peng",
      "Liang Ding",
      "Yuanxin Ouyang",
      "Meng Fang",
      "Yancheng Yuan",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2025.acl-short.78": {
    "title": "Different Speech Translation Models Encode and Translate Speaker Gender Differently",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dennis Fucci",
      "Marco Gaido",
      "Matteo Negri",
      "Luisa Bentivogli",
      "Andre Martins",
      "Giuseppe Attanasio"
    ]
  },
  "https://aclanthology.org/2025.acl-short.79": {
    "title": "Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaikai An",
      "Shuzheng Si",
      "Helan Hu",
      "Haozhe Zhao",
      "Yuchi Wang",
      "Qingyan Guo",
      "Baobao Chang"
    ]
  },
  "https://aclanthology.org/2025.acl-short.80": {
    "title": "Quantifying Misattribution Unfairness in Authorship Attribution",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pegah Alipoormolabashi",
      "Ajay Patel",
      "Niranjan Balasubramanian"
    ]
  },
  "https://aclanthology.org/2025.acl-short.81": {
    "title": "Zero-Shot Text-to-Speech for Vietnamese",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thi Vu",
      "Linh The Nguyen",
      "Dat Quoc Nguyen"
    ]
  },
  "https://aclanthology.org/2025.acl-short.82": {
    "title": "Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheyuan Yang",
      "Zexi Kuang",
      "Xue Xia",
      "Yilun Zhao"
    ]
  },
  "https://aclanthology.org/2025.acl-short.83": {
    "title": "Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juan Wisznia",
      "Cecilia Bolaños",
      "Juan Tollo",
      "Giovanni Franco Gabriel Marraffini",
      "Agustín Andrés Gianolini",
      "Noe Fabian Hsueh",
      "Luciano Del Corro"
    ]
  },
  "https://aclanthology.org/2025.acl-short.84": {
    "title": "TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialin Ouyang"
    ]
  },
  "https://aclanthology.org/2025.acl-short.85": {
    "title": "WinSpot: GUI Grounding Benchmark with Multimodal Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Hui",
      "Yinheng Li",
      "Dan Zhao",
      "Colby Banbury",
      "Tianyi Chen",
      "Kazuhito Koishida"
    ]
  },
  "https://aclanthology.org/2025.acl-short.86": {
    "title": "Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fardin Ahsan Sakib",
      "Ziwei Zhu",
      "Karen Trister Grace",
      "Meliha Yetisgen",
      "Ozlem Uzuner"
    ]
  },
  "https://aclanthology.org/2025.acl-short.87": {
    "title": "Enhancing NER by Harnessing Multiple Datasets with Conditional Variational Autoencoders",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taku Oi",
      "Makoto Miwa"
    ]
  },
  "https://aclanthology.org/2025.acl-short.88": {
    "title": "CHEER-Ekman: Fine-grained Embodied Emotion Classification",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phan Anh Duong",
      "Cat Luong",
      "Divyesh Bommana",
      "Tianyu Jiang"
    ]
  },
  "https://aclanthology.org/2025.acl-short.89": {
    "title": "ScanEZ: Integrating Cognitive Models with Self-Supervised Learning for Spatiotemporal Scanpath Prediction",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ekta Sood",
      "Prajit Dhar",
      "Enrica Troiano",
      "Rosy Southwell",
      "Sidney K. DMello"
    ]
  },
  "https://aclanthology.org/2025.acl-short.90": {
    "title": "Improving Fairness of Large Language Models in Multi-document Summarization",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyuan Li",
      "Rui Zhang",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2025.acl-short.91": {
    "title": "Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Wu",
      "Yangmin Huang",
      "Qianyun Du",
      "Lixian Lai",
      "Zhiyang He",
      "Jiaxue Hu",
      "Xiaodong Tao"
    ]
  },
  "https://aclanthology.org/2025.acl-short.92": {
    "title": "Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takumi Goto",
      "Yusuke Sakai",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.acl-short.93": {
    "title": "Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengwei Qin",
      "Wenxuan Zhou",
      "Karthik Abinav Sankararaman",
      "Nanshu Wang",
      "Tengyu Xu",
      "Alexander Radovic",
      "Eryk Helenowski",
      "Arya Talebzadeh",
      "Aditya Tayade",
      "Sinong Wang",
      "Shafiq Joty",
      "Han Fang",
      "Hao Ma"
    ]
  },
  "https://aclanthology.org/2025.acl-short.94": {
    "title": "WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Elhady",
      "Eneko Agirre",
      "Mikel Artetxe"
    ]
  },
  "https://aclanthology.org/2025.acl-short.95": {
    "title": "Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathaniel Krasner",
      "Nicholas Lanuzo",
      "Antonios Anastasopoulos"
    ]
  },
  "https://aclanthology.org/2025.acl-short.96": {
    "title": "LAMB: A Training-Free Method to Enhance the Long-Context Understanding of SSMs via Attention-Guided Token Filtering",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhifan Ye",
      "Zheng Wang",
      "Kejing Xia",
      "Jihoon Hong",
      "Leshu Li",
      "Lexington Whalen",
      "Cheng Wan",
      "Yonggan Fu",
      "Yingyan Celine Lin",
      "Souvik Kundu"
    ]
  },
  "https://aclanthology.org/2025.acl-short.97": {
    "title": "Counterfactual-Consistency Prompting for Relative Temporal Understanding in Large Language Models",
    "volume": "short",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongho Kim",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1": {
    "title": "Explicit vs. Implicit: Investigating Social Bias in Large Language Models through Self-Reflection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yachao Zhao",
      "Bo Wang",
      "Yan Wang",
      "Dongming Zhao",
      "Ruifang He",
      "Yuexian Hou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.2": {
    "title": "Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanbei Jiang",
      "Yihao Ding",
      "Chao Lei",
      "Jiayang Ao",
      "Jey Han Lau",
      "Krista A. Ehinger"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.3": {
    "title": "How Numerical Precision Affects Arithmetical Reasoning Capabilities of LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guhao Feng",
      "Kai Yang",
      "Yuntian Gu",
      "Xinyue Ai",
      "Shengjie Luo",
      "Jiacheng Sun",
      "Di He",
      "Zhenguo Li",
      "Liwei Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.4": {
    "title": "Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeliang Zhang",
      "Xiaodong Liu",
      "Hao Cheng",
      "Chenliang Xu",
      "Jianfeng Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.5": {
    "title": "A Persona-Aware LLM-Enhanced Framework for Multi-Session Personalized Dialogue Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongshuo Liu",
      "Zhijing Wu",
      "Dandan Song",
      "Heyan Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.6": {
    "title": "Exploring In-Image Machine Translation with Real-World Background",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanzhi Tian",
      "Zeming Liu",
      "Zhengyang Liu",
      "Yuhang Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.7": {
    "title": "BayesKD: Bayesian Knowledge Distillation for Compact LLMs in Constrained Fine-tuning Scenarios",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Li",
      "Lujun Li",
      "Mark G. Lee",
      "Shengjie Sun",
      "Lei Zhang",
      "Wei Xue",
      "Yike Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.8": {
    "title": "GOLFer: Smaller LMs-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingyuan Liu",
      "Mengxiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.9": {
    "title": "Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingyuan Liu",
      "Mengxiang Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.10": {
    "title": "Emo Pillars: Knowledge Distillation to Support Fine-Grained Context-Aware and Context-Less Emotion Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Shvets"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.11": {
    "title": "Multi-Prompting Decoder Helps Better Language Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zifeng Cheng",
      "Zhaoling Chen",
      "Zhiwei Jiang",
      "Yafeng Yin",
      "Cong Wang",
      "Shiping Ge",
      "Qing Gu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.12": {
    "title": "Visual Cues Enhance Predictive Turn-Taking for Two-Party Human Interaction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sam O’Connor Russell",
      "Naomi Harte"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.13": {
    "title": "The Right Time Matters: Data Arrangement Affects Zero-Shot Generalization in Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingxiang He",
      "Ning Ding",
      "Cheng Qian",
      "Jia Deng",
      "Ganqu Cui",
      "Lifan Yuan",
      "Haiwen Hong",
      "Huan-ang Gao",
      "Longtao Huang",
      "Hui Xue",
      "Huimin Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.14": {
    "title": "MFinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Zhu",
      "Junhui Li",
      "Yalong Wen",
      "Xiandong Li",
      "Lifan Guo",
      "Feng Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.15": {
    "title": "ODDA: An OODA-Driven Diverse Data Augmentation Framework for Low-Resource Relation Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijie Zhong",
      "Yunfan Gao",
      "Xiaolian Zhang",
      "Haofen Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.16": {
    "title": "Detecting and Mitigating Challenges in Zero-Shot Video Summarization with Video LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Cagliero",
      "Lorenzo Vaiani",
      "Eliana Pastor",
      "Alkis Koudounas",
      "Elena Baralis",
      "Vittorio Mazzia",
      "Sandro Pollastrini",
      "Thomas Gueudre",
      "Manuel Giollo",
      "Daniele Amberti",
      "Yue Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.17": {
    "title": "Entity Framing and Role Portrayal in the News",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarek Mahmoud",
      "Zhuohan Xie",
      "Dimitar Iliyanov Dimitrov",
      "Nikolaos Nikolaidis",
      "Purificação Silvano",
      "Roman Yangarber",
      "Shivam Sharma",
      "Elisa Sartori",
      "Nicolas Stefanovitch",
      "Giovanni Da San Martino",
      "Jakub Piskorski",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.18": {
    "title": "Derailer-Rerailer: Adaptive Verification for Efficient and Reliable Language Model Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangya Wan",
      "Yuqi Wu",
      "Hao Wang",
      "Shengming Zhao",
      "Jie Chen",
      "Sheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.19": {
    "title": "Leveraging Large Language Models for Conversational Multi-Doc Question Answering: The First Place of WSDM Cup 2024",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Li",
      "Zhao Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.20": {
    "title": "TreeRAG: Unleashing the Power of Hierarchical Storage for Enhanced Knowledge Retrieval in Long Documents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyu Tao",
      "Xiaofen Xing",
      "Yirong Chen",
      "Linyi Huang",
      "Xiangmin Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.21": {
    "title": "Attention with Dependency Parsing Augmentation for Fine-Grained Attribution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiang Ding",
      "Lvzhou Luo",
      "Yixuan Cao",
      "Ping Luo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.22": {
    "title": "ASTRO: Automatic Strategy Optimization For Non-Cooperative Dialogues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yikuan Hu",
      "Chen Huang",
      "Wenqiang Lei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.23": {
    "title": "Defensive Prompt Patch: A Robust and Generalizable Defense of Large Language Models against Jailbreak Attacks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Xiong",
      "Xiangyu Qi",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.24": {
    "title": "GUM-SAGE: A Novel Dataset and Approach for Graded Entity Salience Prediction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jessica Lin",
      "Amir Zeldes"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.25": {
    "title": "Verifying the Steps of Deductive Reasoning Chains",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zacchary Sadeddine",
      "Fabian M. Suchanek"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.26": {
    "title": "Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in Large Language Model Translations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pardis Sadat Zahraei",
      "Ali Emami"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.27": {
    "title": "Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin C Warner",
      "Ziqi Xu",
      "Simon Haroutounian",
      "Thomas Kannampallil",
      "Chenyan Lu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.28": {
    "title": "Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runchu Tian",
      "Yanghao Li",
      "Yuepeng Fu",
      "Siyang Deng",
      "Qinyu Luo",
      "Cheng Qian",
      "Shuo Wang",
      "Xin Cong",
      "Zhong Zhang",
      "Yesai Wu",
      "Yankai Lin",
      "Huadong Wang",
      "Xiaojiang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.29": {
    "title": "Variable Layerwise Quantization: A Simple and Effective Approach to Quantize LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Razvan-Gabriel Dumitru",
      "Vikas Yadav",
      "Rishabh Maheshwary",
      "Paul Ioan Clotan",
      "Sathwik Tejaswi Madhusudhan",
      "Mihai Surdeanu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.30": {
    "title": "Why Are Positional Encodings Nonessential for Deep Autoregressive Transformers? A Petroglyph Revisited",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kazuki Irie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.31": {
    "title": "CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guofeng Cui",
      "Pichao Wang",
      "Yang Liu",
      "Zemian Ke",
      "Zhu Liu",
      "Vimal Bhat"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.32": {
    "title": "Talking Point based Ideological Discourse Analysis in News Events",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nishanth Sridhar Nakshatri",
      "Nikhil Mehta",
      "Siyi Liu",
      "Sihao Chen",
      "Daniel Hopkins",
      "Dan Roth",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.33": {
    "title": "FlashBack: Efficient Retrieval-Augmented Language Modeling for Fast Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runheng Liu",
      "Xingchen Xiao",
      "Heyan Huang",
      "Zewen Chi",
      "Zhijing Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.34": {
    "title": "CMQCIC-Bench: A Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangya Yu",
      "Yanhao Li",
      "Zongying Jiang",
      "Yuxiong Jin",
      "Li Dai",
      "Yupian Lin",
      "Ruihui Hou",
      "Weiyan Zhang",
      "Yongqi Fan",
      "Qi Ye",
      "Jingping Liu",
      "Tong Ruan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.35": {
    "title": "ConKE: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liyu Zhang",
      "Weiqi Wang",
      "Tianqing Fang",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.36": {
    "title": "Exploring Multi-Modal Data with Tool-Augmented LLM Agents for Precise Causal Discovery",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "ChengAo Shen",
      "Zhengzhang Chen",
      "Dongsheng Luo",
      "Dongkuan Xu",
      "Haifeng Chen",
      "Jingchao Ni"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.37": {
    "title": "PARSQL: Enhancing Text-to-SQL through SQL Parsing and Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxun Dai",
      "Haiqin Yang",
      "Mou Hao",
      "Pingfu Chao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.38": {
    "title": "Probing the Geometry of Truth: Consistency and Generalization of Truth Directions in LLMs Across Logical Transformations and Question Answering Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuntai Bao",
      "Xuhong Zhang",
      "Tianyu Du",
      "Xinkui Zhao",
      "Zhengwen Feng",
      "Hao Peng",
      "Jianwei Yin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.39": {
    "title": "Comparing Bad Apples to Good Oranges Aligning Large Language Models via Joint Preference Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hritik Bansal",
      "Ashima Suvarna",
      "Gantavya Bhatt",
      "Nanyun Peng",
      "Kai-Wei Chang",
      "Aditya Grover"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.40": {
    "title": "TestAgent: An Adaptive and Intelligent Expert for Human Assessment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Yu",
      "Yan Zhuang",
      "Yuxuan Sun",
      "Weibo Gao",
      "Qi Liu",
      "Mingyue Cheng",
      "Zhenya Huang",
      "Enhong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.41": {
    "title": "SPICA: Retrieving Scenarios for Pluralistic In-Context Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Ze Chen",
      "Kevin Feng",
      "Chan Young Park",
      "Amy X Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.42": {
    "title": "First-Step Advantage: Importance of Starting Right in Multi-Step Math Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kushal Jain",
      "Moritz Miller",
      "Niket Tandon",
      "Kumar Shridhar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.43": {
    "title": "Evaluating Instructively Generated Statement by Large Language Models for Directional Event Causality Identification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Xiang",
      "Chuanhong Zhan",
      "Qing Zhang",
      "Bang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.44": {
    "title": "CoinMath: Harnessing the Power of Coding Instruction for Math LLM",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengwei Wei",
      "Bin Wang",
      "Jung-jae Kim",
      "Guimei Liu",
      "Nancy F. Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.45": {
    "title": "Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zain Muhammad Mujahid",
      "Dilshod Azizov",
      "Maha Tufail Agro",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.46": {
    "title": "Structured Discourse Representation for Factual Consistency Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Zhang",
      "Oana Balalau",
      "Ioana Manolescu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.47": {
    "title": "SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuyi Kong",
      "Ziyang Luo",
      "Hongzhan Lin",
      "Zhiyuan Fan",
      "Yaxin Fan",
      "Yuxi Sun",
      "Jing Ma"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.48": {
    "title": "Understanding the Gap: an Analysis of Research Collaborations in NLP and Language Documentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luke Gessler",
      "Alexis Palmer",
      "Katharina Von Der Wense"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.49": {
    "title": "PersonaBench: Evaluating AI Models on Understanding Personal Information through Accessing (Synthetic) Private User Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juntao Tan",
      "Liangwei Yang",
      "Zuxin Liu",
      "Zhiwei Liu",
      "Rithesh R N",
      "Tulika Manoj Awalgaonkar",
      "Jianguo Zhang",
      "Weiran Yao",
      "Ming Zhu",
      "Shirley Kokane",
      "Silvio Savarese",
      "Huan Wang",
      "Caiming Xiong",
      "Shelby Heinecke"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.50": {
    "title": "Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simret A Gebreegziabher",
      "Kuangshi Ai",
      "Zheng Zhang",
      "Elena Glassman",
      "Toby Jia-Jun Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.51": {
    "title": "ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eric Modesitt",
      "Ke Yang",
      "Spencer Hulsey",
      "Xin Liu",
      "ChengXiang Zhai",
      "Volodymyr Kindratenko"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.52": {
    "title": "Serial Position Effects of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobo Guo",
      "Soroush Vosoughi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.53": {
    "title": "scRAG: Hybrid Retrieval-Augmented Generation for LLM-based Cross-Tissue Single-Cell Annotation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyin Yu",
      "Chao Zheng",
      "Chong Chen",
      "Xian-Sheng Hua",
      "Xiao Luo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.54": {
    "title": "Can Large Language Models Address Open-Target Stance Detection?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abu Ubaida Akash",
      "Ahmed Fahmy",
      "Amine Trabelsi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.55": {
    "title": "Improve Language Model and Brain Alignment via Associative Memory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Congchi Yin",
      "Yongpeng Zhang",
      "Xuyun Wen",
      "Piji Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.56": {
    "title": "Towards Reliable Large Audio Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Ma",
      "Xiquan Li",
      "Yakun Song",
      "Wenxi Chen",
      "Chenpeng Du",
      "Jian Wu",
      "Yuanzhe Chen",
      "Zhuo Chen",
      "Yuping Wang",
      "Yuxuan Wang",
      "Xie Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.57": {
    "title": "Large Vocabulary Size Improves Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sho Takase",
      "Ryokan Ri",
      "Shun Kiyono",
      "Takuya Kato"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.58": {
    "title": "MUSE: A Multimodal Conversational Recommendation Dataset with Scenario-Grounded User Profiles",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Wang",
      "Xiaocui Yang",
      "YongKang Liu",
      "Shi Feng",
      "Daling Wang",
      "Yifei Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.59": {
    "title": "Machine Translation Models are Zero-Shot Detectors of Translation Direction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michelle Wastl",
      "Jannis Vamvas",
      "Rico Sennrich"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.60": {
    "title": "Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jerry Huang",
      "Prasanna Parthasarathi",
      "Mehdi Rezagholizadeh",
      "Boxing Chen",
      "Sarath Chandar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.61": {
    "title": "GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie He",
      "Jennifer Neville",
      "Mengting Wan",
      "Longqi Yang",
      "Hui Liu",
      "Xiaofeng Xu",
      "Xia Song",
      "Jeff Z. Pan",
      "Pei Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.62": {
    "title": "SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengxing Xie",
      "Bowen Li",
      "Chang Gao",
      "He Du",
      "Wai Lam",
      "Difan Zou",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.63": {
    "title": "GlyphPattern: An Abstract Pattern Recognition for Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Wu",
      "Yoolim Kim",
      "Carolyn Jane Anderson"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.64": {
    "title": "FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianli Wang",
      "Nils Feldhus",
      "Simon Ostermann",
      "Luis Felipe Villa-Arenas",
      "Sebastian Möller",
      "Vera Schmitt"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.65": {
    "title": "From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning Method for LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guocong Li",
      "Weize Liu",
      "Yihang Wu",
      "Ping Wang",
      "Shuaihan Huang",
      "Hongxia Xu",
      "Jian Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.66": {
    "title": "Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Wu",
      "Xin Lu",
      "Yanyan Zhao",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.67": {
    "title": "Nuclear Deployed!: Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongwu Xu",
      "Xiaojian Li",
      "Shuo Chen",
      "Wei Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.68": {
    "title": "MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dacao Zhang",
      "Kun Zhang",
      "Shimao Chu",
      "Le Wu",
      "Xin Li",
      "Si Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.69": {
    "title": "Lunar Twins: We Choose to Go to the Moon with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin-Yu Xiao",
      "Yalei Liu",
      "Xiangyu Liu",
      "Zengrui Li",
      "Erwei Yin",
      "Qianchen Xia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.70": {
    "title": "SPHERE: An Evaluation Card for Human-AI Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dora Zhao",
      "Qianou Ma",
      "Xinran Zhao",
      "Chenglei Si",
      "Chenyang Yang",
      "Ryan Louie",
      "Ehud Reiter",
      "Diyi Yang",
      "Tongshuang Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.71": {
    "title": "Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximillian Chen",
      "Ruoxi Sun",
      "Sercan O Arik"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.72": {
    "title": "Question-Aware Knowledge Graph Prompting for Enhancing Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochen Liu",
      "Song Wang",
      "Chen Chen",
      "Jundong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.73": {
    "title": "UQ-Merge: Uncertainty Guided Multimodal Large Language Model Merging",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huaizhi Qu",
      "Xinyu Zhao",
      "Jie Peng",
      "Kwonjoon Lee",
      "Behzad Dariush",
      "Tianlong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.74": {
    "title": "AQuAECHR: Attributed Question Answering for European Court of Human Rights",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Korbinian Q. Weidinger",
      "Santosh T.y.s.s",
      "Oana Ichim",
      "Matthias Grabmair"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.75": {
    "title": "Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Zhang",
      "Xiangnan Ma",
      "Kaiqi Kou",
      "Peizhuo Liu",
      "Weiqiao Shan",
      "Benyou Wang",
      "Tong Xiao",
      "Yuxin Huang",
      "Zhengtao Yu",
      "JingBo Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.76": {
    "title": "Ponder & Press: Advancing Visual GUI Agent towards General Computer Control",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqin Wang",
      "Haoji Zhang",
      "Jingqi Tian",
      "Yansong Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.77": {
    "title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Gui",
      "Yiming Liu",
      "Jiale Cheng",
      "Xiaotao Gu",
      "Xiao Liu",
      "Hongning Wang",
      "Yuxiao Dong",
      "Jie Tang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.78": {
    "title": "LLM-Based Multi-Agent Systems are Scalable Graph Generative Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiarui Ji",
      "Runlin Lei",
      "Jialing Bi",
      "Zhewei Wei",
      "Xu Chen",
      "Yankai Lin",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.79": {
    "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiankai Yang",
      "Yi Nian",
      "Li Li",
      "Ruiyao Xu",
      "Yuangang Li",
      "Jiaqi Li",
      "Zhuo Xiao",
      "Xiyang Hu",
      "Ryan A. Rossi",
      "Kaize Ding",
      "Xia Hu",
      "Yue Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.80": {
    "title": "RTADev: Intention Aligned Multi-Agent Framework for Software Development",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Liu",
      "Guohua Wang",
      "Ronghui Yang",
      "Jiajie Zeng",
      "Mengchen Zhao",
      "Yi Cai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.81": {
    "title": "TACO-RL: Task Aware Prompt Compression Optimization with Reinforcement Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivam Shandilya",
      "Menglin Xia",
      "Supriyo Ghosh",
      "Huiqiang Jiang",
      "Jue Zhang",
      "Qianhui Wu",
      "Victor Rühle",
      "Saravan Rajmohan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.82": {
    "title": "A Character-Centric Creative Story Generation via Imagination",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyeongman Park",
      "Minbeom Kim",
      "Kyomin Jung"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.83": {
    "title": "Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghan Wang",
      "Viet Thanh Pham",
      "Farhad Moghimifar",
      "Thuy-Trang Vu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.84": {
    "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhang",
      "Shixin Yang",
      "Chenjia Bai",
      "Fei Wu",
      "Xiu Li",
      "Zhen Wang",
      "Xuelong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.85": {
    "title": "UAQFact: Evaluating Factual Knowledge Utilization of LLMs on Unanswerable Questions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanyuan Tan",
      "Wenbiao Shao",
      "Hao Xiong",
      "Tong Zhu",
      "Zhenhua Liu",
      "Kai Shi",
      "Wenliang Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.86": {
    "title": "Exploring Knowledge Filtering for Retrieval-Augmented Discriminative Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minjie Qiang",
      "Zhongqing Wang",
      "Xiaoyi Bao",
      "HaoYuan Ma",
      "Shoushan Li",
      "Guodong Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.87": {
    "title": "Group then Scale: Dynamic Mixture-of-Experts Multilingual Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Li",
      "Yingzhuo Deng",
      "Jiajun Zhang",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.88": {
    "title": "Beyond Verbal Cues: Emotional Contagion Graph Network for Causal Emotion Entailment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangxu Yu",
      "Junjie Guo",
      "Zhen Wu",
      "Xinyu Dai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.89": {
    "title": "Critic-CoT: Boosting the Reasoning Abilities of Large Language Model via Chain-of-Thought Critic",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zheng",
      "Jie Lou",
      "Boxi Cao",
      "Xueru Wen",
      "Yuqiu Ji",
      "Hongyu Lin",
      "Yaojie Lu",
      "Xianpei Han",
      "Debing Zhang",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.90": {
    "title": "Systematic Generalization in Language Models Scales with Information Entropy",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sondre Wold",
      "Lucas Georges Gabriel Charpentier",
      "Étienne Simon"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.91": {
    "title": "The Inverse Scaling Effect of Pre-Trained Language Model Surprisal Is Not Due to Data Leakage",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Byung-Doh Oh",
      "Hongao Zhu",
      "William Schuler"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.92": {
    "title": "Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ganlin Xu",
      "Zhoujia Zhang",
      "Wangyi Mei",
      "Jiaqing Liang",
      "Weijia Lu",
      "Xiaodong Zhang",
      "Zhifei Yang",
      "Xiaofeng Ma",
      "Yanghua Xiao",
      "Deqing Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.93": {
    "title": "‘No' Matters: Out-of-Distribution Detection in Multimodality Multi-Turn Interactive Dialogue Download PDF",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rena Wei Gao",
      "Xuetong Wu",
      "Siwen Luo",
      "Caren Han",
      "Feng Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.94": {
    "title": "Event Pattern-Instance Graph: A Multi-Round Role Representation Learning Strategy for Document-Level Event Argument Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qizhi Wan",
      "LiuTao LiuTao",
      "Changxuan Wan",
      "Rong Hu",
      "Keli Xiao",
      "Yuxin Shuai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.95": {
    "title": "EXECUTE: A Multilingual Benchmark for LLM Token Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Edman",
      "Helmut Schmid",
      "Alexander Fraser"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.96": {
    "title": "Explainable Hallucination through Natural Language Inference Mapping",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Fan Chen",
      "Zhixue Zhao",
      "Akbar Karimi",
      "Lucie Flek"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.97": {
    "title": "HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Liu",
      "Zhengren Wang",
      "Xi Chen",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Qinhan Yu",
      "Wentao Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.98": {
    "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Markus Frohmann",
      "Gabriel Meseguer-Brocal",
      "Markus Schedl",
      "Elena V. Epure"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.99": {
    "title": "Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangmin Woo",
      "Donguk Kim",
      "Jaehyuk Jang",
      "Yubin Choi",
      "Changick Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.100": {
    "title": "SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoning Dong",
      "Wenbo Hu",
      "Wei Xu",
      "Tianxing He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.101": {
    "title": "Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Hu",
      "Rui Liu",
      "Yi Ren",
      "Xiang Yin",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.102": {
    "title": "Parameter-Efficient Fine-Tuning via Circular Convolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aochuan Chen",
      "Jiashun Cheng",
      "Zijing Liu",
      "Ziqi Gao",
      "Fugee Tsung",
      "Yu Li",
      "Jia Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.103": {
    "title": "Alleviating Hallucinations in Large Language Models via Truthfulness-driven Rank-adaptive LoRA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Li",
      "Zhendong Mao",
      "Quan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.104": {
    "title": "ScEdit: Script-based Assessment of Knowledge Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinye Li",
      "Zunwen Zheng",
      "Qian Zhang",
      "Dekai Zhuang",
      "Jiabao Kang",
      "Liyan Xu",
      "Qingbin Liu",
      "Xi Chen",
      "Zhiying Tu",
      "Dianhui Chu",
      "Dianbo Sui"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.105": {
    "title": "SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seanie Lee",
      "Dong Bok Lee",
      "Dominik Wagner",
      "Minki Kang",
      "Haebin Seong",
      "Tobias Bocklet",
      "Juho Lee",
      "Sung Ju Hwang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.106": {
    "title": "Moderation Matters: Measuring Conversational Moderation Impact in English as a Second Language Group Discussion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rena Wei Gao",
      "Ming-Bin Chen",
      "Lea Frermann",
      "Jey Han Lau"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.107": {
    "title": "Measuring Bias and Agreement in Large Language Model Presupposition Judgments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katherine Atwell",
      "Mandy Simons",
      "Malihe Alikhani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.108": {
    "title": "Harnessing PDF Data for Improving Japanese Large Multimodal Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeonghun Baek",
      "Akiko Aizawa",
      "Kiyoharu Aizawa"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.109": {
    "title": "EnerGIZAr: Leveraging GIZA++ for Effective Tokenizer Initialization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pranaydeep Singh",
      "Eneko Agirre",
      "Gorka Azkune",
      "Orphee De Clercq",
      "Els Lefever"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.110": {
    "title": "AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Chai",
      "Siyuan Huang",
      "Yazhe Niu",
      "Han Xiao",
      "Liang Liu",
      "Guozhi Wang",
      "Dingyu Zhang",
      "Shuai Ren",
      "Hongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.111": {
    "title": "Drop Dropout on Single Epoch Language Model Pretraining",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houjun Liu",
      "John Bauer",
      "Christopher D Manning"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.112": {
    "title": "Robust and Minimally Invasive Watermarking for EaaS",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongqi Wang",
      "Baoyuan Wu",
      "Jingyuan Deng",
      "Yujiu Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.113": {
    "title": "Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jarca Andrei",
      "Florinel Alin Croitoru",
      "Radu Tudor Ionescu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.114": {
    "title": "CARMO: Dynamic Criteria Generation for Context Aware Reward Modelling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taneesh Gupta",
      "Shivam Shandilya",
      "Xuchao Zhang",
      "Rahul Madhavan",
      "Supriyo Ghosh",
      "Chetan Bansal",
      "Huaxiu Yao",
      "Saravan Rajmohan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.115": {
    "title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxi Chen",
      "Ziyang Ma",
      "Ruiqi Yan",
      "Yuzhe Liang",
      "Xiquan Li",
      "Ruiyang Xu",
      "Zhikang Niu",
      "Yanqiao Zhu",
      "Yifan Yang",
      "Zhanxun Liu",
      "Kai Yu",
      "Yuxuan Hu",
      "Jinyu Li",
      "Yan Lu",
      "Shujie Liu",
      "Xie Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.116": {
    "title": "C2LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanyang Li",
      "Wong Tin Long",
      "Cheung To Hung",
      "Jianqiao Zhao",
      "Duo Zheng",
      "Liu Ka Wai",
      "Michael R. Lyu",
      "Liwei Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.117": {
    "title": "Texts or Images? A Fine-grained Analysis on the Effectiveness of Input Representations and Models for Table Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhou",
      "Mohsen Mesgar",
      "Heike Adel",
      "Annemarie Friedrich"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.118": {
    "title": "Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees' Dialogue to Facilitate Nurse Communication Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyeun Lee",
      "Seolhee Lee",
      "Esther Hehsun Kim",
      "Yena Ko",
      "Jinsu Eun",
      "Dahee Kim",
      "Hyewon Cho",
      "Haiyi Zhu",
      "Robert E. Kraut",
      "Eunyoung E. Suh",
      "Eun-mee Kim",
      "Hajin Lim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.119": {
    "title": "Enhancing Multimodal Unified Representations for Cross Modal Generalization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Huang",
      "Yan Xia",
      "Shengpeng Ji",
      "Shulei Wang",
      "Hanting Wang",
      "Minghui Fang",
      "Jieming Zhu",
      "Zhenhua Dong",
      "Sashuai Zhou",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.120": {
    "title": "Domain Regeneration: How well do LLMs match syntactic properties of text domains?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Da Ju",
      "Hagen Blix",
      "Adina Williams"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.121": {
    "title": "Structural Deep Encoding for Table Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphaël Mouravieff",
      "Benjamin Piwowarski",
      "Sylvain Lamprier"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.122": {
    "title": "MPL: Multiple Programming Languages with Large Language Models for Information Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Li",
      "Gexiang Fang",
      "Wei Ye",
      "Zhenghua Xu",
      "Jinglei Zhang",
      "Hao Cheng",
      "Shikun Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.123": {
    "title": "Self-Critique Guided Iterative Reasoning for Multi-hop Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Chu",
      "Huiming Fan",
      "Jingchang Chen",
      "Qianyu Wang",
      "Mingda Yang",
      "Jiafeng Liang",
      "Zhongjie Wang",
      "Hao Li",
      "Guo Tang",
      "Ming Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.124": {
    "title": "Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruizhe Li",
      "Yanjun Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.125": {
    "title": "Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sreyan Ghosh",
      "Mohammad Sadegh Rasooli",
      "Michael Levit",
      "Peidong Wang",
      "Jian Xue",
      "Dinesh Manocha",
      "Jinyu Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.126": {
    "title": "LTRAG: Enhancing Autoformalization and Self-refinement for Logical Reasoning with Thought-Guided RAG",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruikang Hu",
      "Shaoyu Lin",
      "Yeliang Xiu",
      "Yongmei Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.127": {
    "title": "Eta-WavLM: Efficient Speaker Identity Removal in Self-Supervised Speech Representations Using a Simple Linear Equation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe Ruggiero",
      "Matteo Testa",
      "Jurgen Van De Walle",
      "Luigi Di Caro"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.128": {
    "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Wang",
      "Junting Pan",
      "Linda Wei",
      "Aojun Zhou",
      "Weikang Shi",
      "Zimu Lu",
      "Han Xiao",
      "Yunqiao Yang",
      "Houxing Ren",
      "Mingjie Zhan",
      "Hongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.129": {
    "title": "MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyang Xue",
      "Hongru Wang",
      "Rui Wang",
      "Sheng Wang",
      "Zezhong Wang",
      "Yiming Du",
      "Bin Liang",
      "Wenxuan Zhang",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.130": {
    "title": "COMPKE: Complex Question Answering under Knowledge Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyuan Cheng",
      "Zijian Kan",
      "Zhuoran Zhang",
      "Muhammad Asif Ali",
      "Lijie Hu",
      "Di Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.131": {
    "title": "RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Hu",
      "Wenrui Huang",
      "Weidong Wang",
      "Zhenwen Li",
      "Tiancheng Hu",
      "Zhixia Liu",
      "Xusheng Chen",
      "Tao Xie",
      "Yizhou Shan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.132": {
    "title": "One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongguang Ye",
      "Ming Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.133": {
    "title": "CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangda Wu",
      "Guo Zhancheng",
      "Ruibin Yuan",
      "Junyan Jiang",
      "SeungHeon Doh",
      "Gus Xia",
      "Juhan Nam",
      "Xiaobing Li",
      "Feng Yu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.134": {
    "title": "PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Zhang",
      "Yuhui Wang",
      "Yujiong Shen",
      "Tingyi Yang",
      "Changhao Jiang",
      "Yilong Wu",
      "Shihan Dou",
      "Qinhao Chen",
      "Zhiheng Xi",
      "Zhihao Zhang",
      "Yi Dong",
      "Zhen Wang",
      "Zhihui Fei",
      "Mingyang Wan",
      "Tao Liang",
      "Guojun Ma",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.135": {
    "title": "Listening to Patients: Detecting and Mitigating Patient Misreport in Medical Dialogue System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lang Qin",
      "Yao Zhang",
      "Hongru Liang",
      "Adam Jatowt",
      "Zhenglu Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.136": {
    "title": "Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Hu",
      "Richard Lewis"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.137": {
    "title": "Graph-guided Cross-composition Feature Disentanglement for Compositional Zero-shot Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxia Geng",
      "Runkai Zhu",
      "Jiaoyan Chen",
      "Jintai Chen",
      "Xiang Chen",
      "Zhuo Chen",
      "Shuofei Qiao",
      "Yuxiang Wang",
      "Xiaoliang Xu",
      "Sheng-Jun Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.138": {
    "title": "Training Long-Context LLMs Efficiently via Chunk-wise Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Li",
      "Yuxin Zhang",
      "Gen Luo",
      "Daohai Yu",
      "Rongrong Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.139": {
    "title": "Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiashun Cheng",
      "Aochuan Chen",
      "Nuo Chen",
      "Ziqi Gao",
      "Yuhan Li",
      "Jia Li",
      "Fugee Tsung"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.140": {
    "title": "CODEMENV: Benchmarking Large Language Models on Code Migration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyuan Cheng",
      "Xudong Shen",
      "Yihao Yang",
      "TengyueWang TengyueWang",
      "Yang Cao",
      "Muhammad Asif Ali",
      "Hanbin Wang",
      "Lijie Hu",
      "Di Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.141": {
    "title": "A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "V.S.D.S.Mahesh Akavarapu",
      "Hrishikesh Terdalkar",
      "Pramit Bhattacharyya",
      "Shubhangi Agarwal",
      "Dr. Vishakha Deulgaonkar",
      "Chaitali Dangarikar",
      "Pralay Manna",
      "Arnab Bhattacharya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.142": {
    "title": "BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jilong Li",
      "Zhenxi Song",
      "Jiaqi Wang",
      "Meishan Zhang",
      "Honghai Liu",
      "Min Zhang",
      "Zhiguo Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.143": {
    "title": "Progressive LoRA for Multimodal Continual Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yahan Yu",
      "Duzhen Zhang",
      "Yong Ren",
      "Xuanle Zhao",
      "Xiuyi Chen",
      "Chenhui Chu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.144": {
    "title": "ARC ‘Challenge' Is Not That Challenging",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Łukasz Borchmann"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.145": {
    "title": "Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vera Neplenbroek",
      "Arianna Bisazza",
      "Raquel Fernández"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.146": {
    "title": "Tracr-Injection: Distilling Algorithms into Pre-trained Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomás Vergara Browne",
      "Alvaro Soto"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.147": {
    "title": "Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ximing Dong",
      "Shaowei Wang",
      "Dayi Lin",
      "Ahmed Hassan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.148": {
    "title": "Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Yao",
      "Wenkai Yang",
      "Ziqiao Wang",
      "Yankai Lin",
      "Yong Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.149": {
    "title": "Stories that (are) Move(d by) Markets: A Causal Exploration of Market Shocks and Semantic Shifts across Different Partisan Groups",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Drinkall",
      "Stefan Zohren",
      "Michael McMahon",
      "Janet B. Pierrehumbert"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.150": {
    "title": "NetSafe: Exploring the Topological Safety of Multi-agent System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Yu",
      "Shilong Wang",
      "Guibin Zhang",
      "Junyuan Mao",
      "Chenlong Yin",
      "Qijiong Liu",
      "Kun Wang",
      "Qingsong Wen",
      "Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.151": {
    "title": "Reasoning is All You Need for Video Generalization: A Counterfactual Benchmark with Sub-question Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiji Zhou",
      "YiFan Gong",
      "Guangsheng Bao",
      "Hongjie Qiu",
      "Jinqiang Li",
      "Xiangrong Zhu",
      "Huajian Zhang",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.152": {
    "title": "Initializing and Retrofitting Key-Value Adaptors for Traceable Model Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanlun Zhu",
      "Yunshi Lan",
      "Xiang Li",
      "Weining Qian"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.153": {
    "title": "Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Li",
      "Yixuan Tang",
      "Yi Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.154": {
    "title": "Position-Aware Depth Decay Decoding (D3): Boosting Large Language Model Inference Efficiency",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Fan",
      "Xuezhi Fang",
      "Xingrun Xing",
      "Peng Han",
      "Shuo Shang",
      "Yequan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.155": {
    "title": "Explaining Puzzle Solutions in Natural Language: An Exploratory Study on 6x6 Sudoku",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anirudh Maiya",
      "Razan Alghamdi",
      "Maria Leonor Pacheco",
      "Ashutosh Trivedi",
      "Fabio Somenzi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.156": {
    "title": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Pedrotti",
      "Michele Papucci",
      "Cristiano Ciaccio",
      "Alessio Miaschi",
      "Giovanni Puccetti",
      "Felice Dell’Orletta",
      "Andrea Esuli"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.157": {
    "title": "InfiniSST: Simultaneous Translation of Unbounded Speech with Large Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Ouyang",
      "Xi Xu",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.158": {
    "title": "VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Geng",
      "Qing Li",
      "Zongxiong Chen",
      "Yuxia Wang",
      "Derui Zhu",
      "Zhuohan Xie",
      "Chenyang Lyu",
      "Xiuying Chen",
      "Preslav Nakov",
      "Fakhri Karray"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.159": {
    "title": "To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhe Wang",
      "Long Li",
      "Chao Qu",
      "Weidi Xu",
      "Fengming Zhu",
      "Wei Chu",
      "Fangzhen Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.160": {
    "title": "GOODLIAR: A Reinforcement Learning-Based Deceptive Agent for Disrupting LLM Beliefs on Foundational Principles",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soo Kyung Kim",
      "Hyunsoo Cho"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.161": {
    "title": "How Does Response Length Affect Long-Form Factuality",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Xu Zhao",
      "Jimmy Z.j. Liu",
      "Bryan Hooi",
      "See-Kiong Ng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.162": {
    "title": "Scaling LLMs' Social Reasoning: Sprinkle Cognitive \"Aha Moment\" into Fundamental Long-thought Logical Capabilities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guiyang Hou",
      "Wenqi Zhang",
      "Zhe Zheng",
      "Yongliang Shen",
      "Weiming Lu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.163": {
    "title": "SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzheng Cai",
      "Zhenyue Guo",
      "YiWen Pei",
      "WanRui Bian",
      "Weiguo Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.164": {
    "title": "RuleEdit: Towards Rule-Level Knowledge Generalization to Mitigate Over-Editing in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bihan Zhou",
      "HaoPeng Ren",
      "Li Yuan",
      "Yi Cai",
      "Liuwen Cao",
      "Zikun Deng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.165": {
    "title": "Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Qiu",
      "Varun R. Embar",
      "Yizhe Zhang",
      "Navdeep Jaitly",
      "Shay B Cohen",
      "Benjamin Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.166": {
    "title": "GeAR: Generation Augmented Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Liu",
      "Shaohan Huang",
      "Jianfeng Liu",
      "Yuefeng Zhan",
      "Hao Sun",
      "Weiwei Deng",
      "Feng Sun",
      "Furu Wei",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.167": {
    "title": "A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanzhen Shen",
      "Yu Zhang",
      "Yunyi Zhang",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.168": {
    "title": "Zero-Shot Conversational Stance Detection: Dataset and Approaches",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhe Ding",
      "Kang He",
      "Bobo Li",
      "Li Zheng",
      "Haijun He",
      "Fei Li",
      "Chong Teng",
      "Donghong Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.169": {
    "title": "LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful Synthetic Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cehao Yang",
      "Xueyuan Lin",
      "Chengjin Xu",
      "Xuhui Jiang",
      "Shengjie Ma",
      "Aofan Liu",
      "Hui Xiong",
      "Jian Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.170": {
    "title": "SYNTHVERIFY: Enhancing Zero-Shot Claim Verification through Step-by-Step Synthetic Data Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongwen Zhao",
      "Jeffrey Flanigan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.171": {
    "title": "Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Chu",
      "Zhijie Tan",
      "Hanlin Xue",
      "Guanyu Wang",
      "Tong Mo",
      "Weiping Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.172": {
    "title": "Dynamic Prefix as Instructor for Incremental Named Entity Recognition: A Unified Seq2Seq Generation Framework",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Wu",
      "YongXiang Hua",
      "Yongxin Zhu",
      "Fang Zhang",
      "Linli Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.173": {
    "title": "Who Taught You That? Tracing Teachers in Model Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Somin Wadhwa",
      "Chantal Shaib",
      "Silvio Amir",
      "Byron C Wallace"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.174": {
    "title": "D-GEN: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Grace Byun",
      "Jinho D. Choi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.175": {
    "title": "HammerBench: Fine-Grained Function-Calling Evaluation in Real Mobile Assistant Scenarios",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Wang",
      "Jiamu Zhou",
      "Xihuai Wang",
      "Xiaoyun Mo",
      "Haoyu Zhang",
      "Qiqiang Lin",
      "Jincheng Jincheng",
      "Muning Wen",
      "Weinan Zhang",
      "Qiuying Peng",
      "Jun Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.176": {
    "title": "Beyond In-Context Learning: Aligning Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Do Xuan Long",
      "Duong Ngoc Yen",
      "Do Xuan Trong",
      "Anh Tuan Luu",
      "Kenji Kawaguchi",
      "Shafiq Joty",
      "Min-Yen Kan",
      "Nancy F. Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.177": {
    "title": "GRAMMAR-LLM: Grammar-Constrained Natural Language Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriele Tuccio",
      "Luana Bulla",
      "Maria Madonia",
      "Aldo Gangemi",
      "Misael Mongiovì"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.178": {
    "title": "MANBench: Is Your Multimodal Model Smarter than Human?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Zhou",
      "Qitong Xu",
      "Yiheng Dong",
      "Xin Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.179": {
    "title": "BanStereoSet: A Dataset to Measure Stereotypical Social Biases in LLMs for Bangla",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mahammed Kamruzzaman",
      "Abdullah Al Monsur",
      "Shrabon Kumar Das",
      "Enamul Hassan",
      "Gene Louis Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.180": {
    "title": "mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthieu Futeral",
      "Armel Randy Zebaze",
      "Pedro Ortiz Suarez",
      "Julien Abadji",
      "Rémi Lacroix",
      "Cordelia Schmid",
      "Rachel Bawden",
      "Benoît Sagot"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.181": {
    "title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vladislav Mikhailov",
      "Tita Enstad",
      "David Samuel",
      "Hans Christian Farsethås",
      "Andrey Kutuzov",
      "Erik Velldal",
      "Lilja Øvrelid"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.182": {
    "title": "Massively Multilingual Instruction-Following Information Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thang Le",
      "Huy Huu Nguyen",
      "Anh Tuan Luu",
      "Thien Huu Nguyen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.183": {
    "title": "DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kang He",
      "Yuzhe Ding",
      "Haining Wang",
      "Fei Li",
      "Chong Teng",
      "Donghong Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.184": {
    "title": "Large Language Models in Bioinformatics: A Survey",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Wang",
      "Zikang Wang",
      "Jiyue Jiang",
      "Pengan Chen",
      "Xiangyu Shi",
      "Yu Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.185": {
    "title": "ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs' Capability via Chart Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanle Zhao",
      "Xuexin Liu",
      "Yang Haoyue",
      "Xianzhen Luo",
      "Fanhu Zeng",
      "Jianling Li",
      "Qi Shi",
      "Chi Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.186": {
    "title": "Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Liu",
      "Chao Shang",
      "Ling Liu",
      "Nikolaos Pappas",
      "Jie Ma",
      "Neha Anna John",
      "Srikanth Doss",
      "Lluis Marquez",
      "Miguel Ballesteros",
      "Yassine Benajiba"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.187": {
    "title": "Turbocharging Web Automation: The Impact of Compressed History States",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiyue Zhu",
      "Peng Tang",
      "Haofu Liao",
      "Srikar Appalaraju"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.188": {
    "title": "Making RALM Robust to Irrelevant Contexts via Layer Knowledge Guided Attention",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijie Shi",
      "Hao Chen",
      "Jiaming Li",
      "Yao Zhao",
      "Yazhong Zhang",
      "Qijin Chen",
      "Jipeng Zhang",
      "Ruiyuan Zhang",
      "Jia Zhu",
      "Jiajie Xu",
      "Xiaofang Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.189": {
    "title": "Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuting Huang",
      "Chengyuan Liu",
      "Yifeng Feng",
      "Yiquan Wu",
      "Chao Wu",
      "Fei Wu",
      "Kun Kuang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.190": {
    "title": "SignAlignLM: Integrating Multimodal Sign Language Processing into Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mert Inan",
      "Anthony Sicilia",
      "Malihe Alikhani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.191": {
    "title": "NegVQA: Can Vision Language Models Understand Negation?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhui Zhang",
      "Yuchang Su",
      "Yiming Liu",
      "Serena Yeung-Levy"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.192": {
    "title": "Natural Language Reasoning in Large Language Models: Analysis and Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debela Gemechu",
      "Ramon Ruiz-Dolz",
      "Henrike Beyer",
      "Chris Reed"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.193": {
    "title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Wang",
      "Zhenyu Hou",
      "Yao Wei",
      "Jie Tang",
      "Yuxiao Dong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.194": {
    "title": "The Two Paradigms of LLM Detection: Authorship Attribution vs Authorship Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Janek Bevendorff",
      "Matti Wiegmann",
      "Emmelie Richter",
      "Martin Potthast",
      "Benno Stein"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.195": {
    "title": "Unveiling Confirmation Bias in Chain-of-Thought Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Wan",
      "Xiaowei Jia",
      "Xiang Lorraine Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.196": {
    "title": "GRNFormer: A Biologically-Guided Framework for Integrating Gene Regulatory Networks into RNA Foundation Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mufan Qiu",
      "Xinyu Hu",
      "Fengwei Zhan",
      "Sukwon Yun",
      "Jie Peng",
      "Ruichen Zhang",
      "Bhavya Kailkhura",
      "Jiekun Yang",
      "Tianlong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.197": {
    "title": "RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihang Cheng",
      "Lan Zhang",
      "Junyang Wang",
      "Mu Yuan",
      "Yunhao Yao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.198": {
    "title": "My life is miserable, have to sign 500 autographs everyday\": Exposing Humblebragging, the Brags in Disguise",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sharath Naganna",
      "Saprativa Bhattacharjee",
      "Biplab Banerjee",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.199": {
    "title": "SCITAT: A Question Answering Benchmark for Scientific Tables and Text Covering Diverse Reasoning Types",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanliang Zhang",
      "Dingzirui Wang",
      "Baoxin Wang",
      "Longxu Dou",
      "Xinyuan Lu",
      "Keyan Xu",
      "Dayong Wu",
      "Qingfu Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.200": {
    "title": "TokenShapley: Token Level Context Attribution with Shapley Value",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingtai Xiao",
      "Yuqing Zhu",
      "Sirat Samyoun",
      "Wanrong Zhang",
      "Jiachen T. Wang",
      "Jian Du"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.201": {
    "title": "Entropy-based Exploration Conduction for Multi-step Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinghan Zhang",
      "Xiting Wang",
      "Fengran Mo",
      "Yeyang Zhou",
      "Wanfu Gao",
      "Kunpeng Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.202": {
    "title": "Taxonomizing Representational Harms using Speech Act Theory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emily Corvi",
      "Hannah Washington",
      "Stefanie Reed",
      "Chad Atalla",
      "Alexandra Chouldechova",
      "P. Alex Dow",
      "Jean Garcia-Gathright",
      "Nicholas J Pangakis",
      "Emily Sheng",
      "Dan Vann",
      "Matthew Vogel",
      "Hanna Wallach"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.203": {
    "title": "Turning Conversations into Workflows: A Framework to Extract and Evaluate Dialog Workflows for Service AI Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prafulla Kumar Choubey",
      "Xiangyu Peng",
      "Shilpa Bhagavath",
      "Caiming Xiong",
      "Shiva Kumar Pentyala",
      "Chien-Sheng Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.204": {
    "title": "Statistical inference on black-box generative models in the data kernel perspective space",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hayden Helm",
      "Aranyak Acharyya",
      "Youngser Park",
      "Brandon Duderstadt",
      "Carey Priebe"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.205": {
    "title": "Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sohee Yang",
      "Nora Kassner",
      "Elena Gribovskaya",
      "Sebastian Riedel",
      "Mor Geva"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.206": {
    "title": "AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Liu",
      "Yang Chen",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Wei Ping"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.207": {
    "title": "WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for Evaluating Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongan Yu",
      "Qingchen Hu",
      "Xianda Du",
      "Jiayin Wang",
      "Fengran Mo",
      "Renée Sieber"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.208": {
    "title": "MeMoTune: A Measure and Moment-Driven Fine-Tuning Framework for Quantized Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Zhang",
      "Xue Geng",
      "Lizi Liao",
      "Jintong Sun",
      "Minghe Yu",
      "Ge Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.209": {
    "title": "MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sagi Shaier",
      "George Arthur Baker",
      "Chiranthan Sridhar",
      "Lawrence Hunter",
      "Katharina Von Der Wense"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.210": {
    "title": "Sentimental Image Generation for Aspect-based Sentiment Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyi Bao",
      "Jinghang Gu",
      "Zhongqing Wang",
      "Chu-Ren Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.211": {
    "title": "Long-form Hallucination Detection with Self-elicitation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihang Liu",
      "Jiawei Guo",
      "Hao Zhang",
      "Hongyang Chen",
      "Jiajun Bu",
      "Haishuai Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.212": {
    "title": "ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qing Zong",
      "Zhaowei Wang",
      "Tianshi Zheng",
      "Xiyu Ren",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.213": {
    "title": "One-Dimensional Object Detection for Streaming Text Segmentation of Meeting Dialogue",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui He",
      "Zhongqing Wang",
      "Minjie Qiang",
      "Hongling Wang",
      "Yifan.zhang Yifan.zhang",
      "Hua Xu",
      "Shuai Fan",
      "Guodong Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.214": {
    "title": "CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code Language Prompts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingkai Zeng",
      "Yuyang Bai",
      "Zhaoxuan Tan",
      "Zhenyu Wu",
      "Shangbin Feng",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.215": {
    "title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqicheng Zhu",
      "Daniel Hernández",
      "Yuan He",
      "Zifeng Ding",
      "Bo Xiong",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.216": {
    "title": "Autonomous Data Selection with Zero-shot Generative Classifiers for Mathematical Texts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Zhang",
      "Yifan Luo",
      "Yang Yuan",
      "Andrew C Yao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.217": {
    "title": "Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuochun Li",
      "Yuelyu Ji",
      "Rui Meng",
      "Daqing He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.218": {
    "title": "Investigating Prosodic Signatures via Speech Pre-Trained Models for Audio Deepfake Source Attribution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Orchid Chetia Phukan",
      "Drishti Singh",
      "Swarup Ranjan Behera",
      "Arun Balaji Buduru",
      "Rajesh Sharma"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.219": {
    "title": "Multilingual Retrieval Augmented Generation for Culturally-Sensitive Tasks: A Benchmark for Cross-lingual Robustness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bryan Li",
      "Fiona Luo",
      "Samar Haider",
      "Adwait Agashe",
      "Siyu Li",
      "Runqi Liu",
      "Miranda Muqing Miao",
      "Shriya Ramakrishnan",
      "Yuan Yuan",
      "Chris Callison-Burch"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.220": {
    "title": "Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengyue Jia",
      "Derong Xu",
      "Xiaopeng Li",
      "Zhaocheng Du",
      "Xiangyang Li",
      "Yichao Wang",
      "Yuhao Wang",
      "Qidong Liu",
      "Maolin Wang",
      "Huifeng Guo",
      "Ruiming Tang",
      "Xiangyu Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.221": {
    "title": "Scaling Laws for Multilingual Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei He",
      "Alon Benhaim",
      "Barun Patra",
      "Praneetha Vaddamanu",
      "Sanchit Ahuja",
      "Parul Chopra",
      "Vishrav Chaudhary",
      "Han Zhao",
      "Xia Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.222": {
    "title": "Corpus Poisoning via Approximate Greedy Gradient Descent",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyan Su",
      "Preslav Nakov",
      "Claire Cardie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.223": {
    "title": "Taxonomy-Driven Knowledge Graph Construction for Domain-Specific Scientific Applications",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huitong Pan",
      "Qi Zhang",
      "Mustapha Adamu",
      "Eduard Dragut",
      "Longin Jan Latecki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.224": {
    "title": "Wanda++: Pruning Large Language Models via Regional Gradients",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Yang",
      "Kai Zhen",
      "Bhavana Ganesh",
      "Aram Galstyan",
      "Goeric Huybrechts",
      "Markus Müller",
      "Jonas M. Kübler",
      "Rupak Vignesh Swaminathan",
      "Athanasios Mouchtaris",
      "Sravan Babu Bodapati",
      "Nathan Susanj",
      "Zheng Zhang",
      "Jack FitzGerald",
      "Abhishek Kumar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.225": {
    "title": "MATCHED: Multimodal Authorship-Attribution To Combat Human Trafficking in Escort-Advertisement Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vageesh Kumar Saxena",
      "Benjamin Ashpole",
      "Gijs Van Dijck",
      "Gerasimos Spanakis"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.226": {
    "title": "Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shu Yang",
      "Shenzhe Zhu",
      "Zeyu Wu",
      "Keyu Wang",
      "Junchi Yao",
      "Junchao Wu",
      "Lijie Hu",
      "Mengdi Li",
      "Derek F. Wong",
      "Di Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.227": {
    "title": "Mitigating Paraphrase Attacks on Machine-Text Detection via Paraphrase Inversion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rafael Alberto Rivera Soto",
      "Barry Y. Chen",
      "Nicholas Andrews"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.228": {
    "title": "SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arijit Maji",
      "Raghvendra Kumar",
      "Akash Ghosh",
      "Anushka Anushka",
      "Sriparna Saha"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.229": {
    "title": "System Prompt Hijacking via Permutation Triggers in LLM Supply Chains",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lu Yan",
      "Siyuan Cheng",
      "Xuan Chen",
      "Kaiyuan Zhang",
      "Guangyu Shen",
      "Xiangyu Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.230": {
    "title": "Frequency matters: Modeling irregular morphological patterns in Spanish with Transformers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akhilesh Kakolu Ramarao",
      "Kevin Tang",
      "Dinah Baer-Henney"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.231": {
    "title": "From Heart to Words: Generating Empathetic Responses via Integrated Figurative Language and Semantic Context Signals",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gyeongeun Lee",
      "Zhu Wang",
      "Sathya N. Ravi",
      "Natalie Parde"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.232": {
    "title": "There's No Such Thing as Simple Reasoning for LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nurul Fajrin Ariyani",
      "Zied Bouraoui",
      "Richard Booth",
      "Steven Schockaert"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.233": {
    "title": "CLIX: Cross-Lingual Explanations of Idiomatic Expressions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aaron Gluck",
      "Katharina Von Der Wense",
      "Maria Leonor Pacheco"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.234": {
    "title": "Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dang Nguyen",
      "Ali Payani",
      "Baharan Mirzasoleiman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.235": {
    "title": "R3Mem: Bridging Memory Retention and Retrieval via Reversible Compression",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqiang Wang",
      "Suyuchen Wang",
      "Yun Zhu",
      "Bang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.236": {
    "title": "Vision Language Model Helps Private Information De-Identification in Vision Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiejin Chen",
      "Pingzhi Li",
      "Kaixiong Zhou",
      "Tianlong Chen",
      "Hua Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.237": {
    "title": "Unveiling Privacy Risks in Multi-modal Large Language Models: Task-specific Vulnerabilities and Mitigation Challenges",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiejin Chen",
      "Pingzhi Li",
      "Kaixiong Zhou",
      "Tianlong Chen",
      "Hua Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.238": {
    "title": "DeFine: Decision-Making with Analogical Reasoning over Factor Profiles",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yebowen Hu",
      "Xiaoyang Wang",
      "Wenlin Yao",
      "Yiming Lu",
      "Daoan Zhang",
      "Hassan Foroosh",
      "Dong Yu",
      "Fei Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.239": {
    "title": "SMART: Self-Aware Agent for Tool Overuse Mitigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Qian",
      "Emre Can Acikgoz",
      "Hongru Wang",
      "Xiusi Chen",
      "Avirup Sil",
      "Dilek Hakkani-Tür",
      "Gokhan Tur",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.240": {
    "title": "Continued Pretraining and Interpretability-Based Evaluation for Low-Resource Languages: A Galician Case Study",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pablo Rodríguez",
      "Silvia Paniagua Suárez",
      "Pablo Gamallo",
      "Susana Sotelo Docio"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.241": {
    "title": "TC-Bench: Benchmarking Temporal Compositionality in Conditional Video Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weixi Feng",
      "Jiachen Li",
      "Michael Saxon",
      "Tsu-Jui Fu",
      "Wenhu Chen",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.242": {
    "title": "DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanzhi Zhang",
      "Heng Fan",
      "Kewei Sha",
      "Yan Huang",
      "Yunhe Feng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.243": {
    "title": "Arbiters of Ambivalence: Challenges of using LLMs in No-Consensus tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bhaktipriya Radharapu",
      "Manon Revel",
      "Megan Ung",
      "Sebastian Ruder",
      "Adina Williams"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.244": {
    "title": "Beyond Text: Characterizing Domain Expert Needs in Document Research",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sireesh Gururaja",
      "Nupoor Gandhi",
      "Jeremiah Milbauer",
      "Emma Strubell"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.245": {
    "title": "Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Murong Yue",
      "Ziyu Yao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.246": {
    "title": "MM-R3: On (In-)Consistency of Vision-Language Models (VLMs)",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shih-Han Chou",
      "Shivam Chandhok",
      "Jim Little",
      "Leonid Sigal"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.247": {
    "title": "Investigating Context Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuepei Li",
      "Kang Zhou",
      "Qiao Qiao",
      "Bach Nguyen",
      "Qing Wang",
      "Qi Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.248": {
    "title": "Shadow-Activated Backdoor Attacks on Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Yin",
      "Muchao Ye",
      "Yuanpu Cao",
      "Jiaqi Wang",
      "Aofei Chang",
      "Han Liu",
      "Jinghui Chen",
      "Ting Wang",
      "Fenglong Ma"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.249": {
    "title": "Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kung-Hsiang Huang",
      "Can Qin",
      "Haoyi Qiu",
      "Philippe Laban",
      "Shafiq Joty",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.250": {
    "title": "K-order Ranking Preference Optimization for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shihao Cai",
      "Chongming Gao",
      "Yang Zhang",
      "Wentao Shi",
      "Jizhi Zhang",
      "Keqin Bao",
      "Qifan Wang",
      "Fuli Feng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.251": {
    "title": "Spectral Insights into Data-Oblivious Critical Layers in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuyuan Liu",
      "Lei Hsiung",
      "Yaoqing Yang",
      "Yujun Yan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.252": {
    "title": "SynFix: Dependency-Aware Program Repair via RelationGraph Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunzhu Tang",
      "Jiechao Gao",
      "Jin Xu",
      "Tiezhu Sun",
      "Yewei Song",
      "Saad Ezzini",
      "Wendkûuni C. Ouédraogo",
      "Jacques Klein",
      "Tegawendé F. Bissyandé"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.253": {
    "title": "EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeho Hwang",
      "Sukmin Cho",
      "Soyeong Jeong",
      "Hoyun Song",
      "SeungYoon Han",
      "Jong C. Park"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.254": {
    "title": "Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihu Wang",
      "Shiwan Zhao",
      "Yu Wang",
      "Heyuan Huang",
      "Sitao Xie",
      "Yubo Zhang",
      "Jiaxin Shi",
      "Zhixing Wang",
      "Hongyan Li",
      "Junchi Yan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.255": {
    "title": "Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Zhao",
      "Xiaobao Wu",
      "Cong-Duy T Nguyen",
      "Yanhao Jia",
      "Meihuizi Jia",
      "Feng Yichao",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.256": {
    "title": "Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuhe Wang",
      "Guoyin Wang",
      "Yizhong Wang",
      "Jiwei Li",
      "Eduard Hovy",
      "Chen Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.257": {
    "title": "Better Red Teaming via Searching with Large Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongkang Chen",
      "Chongyang Zhao",
      "Jianwentian Jianwentian",
      "Guiling Cao",
      "Hu Li",
      "Xiaohui Kuang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.258": {
    "title": "AdaV: Adaptive Text-visual Redirection for Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Han",
      "Liang Du",
      "Yiwen Wu",
      "Guanming Liang",
      "Xiangguo Zhou",
      "Weibo Zheng",
      "Donghong Han",
      "Zixun Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.259": {
    "title": "MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without Predefined SOPs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Wang",
      "Tianyu Wang",
      "Zhenheng Tang",
      "Qinbin Li",
      "Nuo Chen",
      "Jingsheng Liang",
      "Bingsheng He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.260": {
    "title": "Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotian Zhang",
      "Ruizhe Chen",
      "Yang Feng",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.261": {
    "title": "A Self-Distillation Recipe for Neural Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongfei Xu",
      "Zhuofei Liang",
      "Qiuhui Liu",
      "Lingling Mu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.262": {
    "title": "BlockPruner: Fine-grained Pruning for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longguang Zhong",
      "Fanqi Wan",
      "Ruijun Chen",
      "Xiaojun Quan",
      "Liangzhi Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.263": {
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Wen",
      "Keping Bi",
      "Wei Chen",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.264": {
    "title": "LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-Context QA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiajie Zhang",
      "Yushi Bai",
      "Xin Lv",
      "Wanjun Gu",
      "Danqing Liu",
      "Minhao Zou",
      "Shulin Cao",
      "Lei Hou",
      "Yuxiao Dong",
      "Ling Feng",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.265": {
    "title": "An Empirical Study of Group Conformity in Multi-Agent Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Choi",
      "Keonwoo Kim",
      "Sungwon Chae",
      "Sangyeop Baek"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.266": {
    "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanglin Wu",
      "Daimeng Wei",
      "Xiaoyu Chen",
      "Hengchao Shang",
      "Jiaxin Guo",
      "Zongyao Li",
      "Yuanchang Luo",
      "Jinlong Yang",
      "Zhiqiang Rao",
      "Hao Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.267": {
    "title": "ASPO: Adaptive Sentence-Level Preference Optimization for Fine-Grained Multimodal Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeyuan Wang",
      "Dehong Gao",
      "Rujiao Long",
      "Lei Yi",
      "Linbo Jin",
      "Libin Yang",
      "Xiaoyan Cai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.268": {
    "title": "NovelCR: A Large-Scale Bilingual Dataset Tailored for Long-Span Coreference Resolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "MeiHan Tong",
      "Shuai Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.269": {
    "title": "Dynamic Attention-Guided Context Decoding for Mitigating Context Faithfulness Hallucinations in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huangyw Huangyw",
      "Yong Zhang",
      "Ning Cheng",
      "Zhitao Li",
      "Shaojun Wang",
      "Jing Xiao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.270": {
    "title": "Exploring the Choice Behavior of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weidong Wu",
      "Qinlin Zhao",
      "Hao Chen",
      "Lexin Zhou",
      "Defu Lian",
      "Hong Xie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.271": {
    "title": "On-Policy Self-Alignment with Fine-grained Knowledge Feedback for Hallucination Mitigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueru Wen",
      "Jie Lou",
      "Xinyu Lu",
      "Yuqiu Ji",
      "Xinyan Guan",
      "Yaojie Lu",
      "Hongyu Lin",
      "Ben He",
      "Xianpei Han",
      "Debing Zhang",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.272": {
    "title": "From Phrases to Subgraphs: Fine-Grained Semantic Parsing for Knowledge Graph Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yurun Song",
      "Xiangqing Shen",
      "Rui Xia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.273": {
    "title": "StableToolBench-MirrorAPI: Modeling Tool Environments as Mirrors of 7,000+ Real-World APIs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Guo",
      "Sijie Cheng",
      "Yuchen Niu",
      "Hao Wang",
      "Sicheng Zhou",
      "Wenbing Huang",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.274": {
    "title": "ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoang Pham",
      "Thanh-Do Nguyen",
      "Khac-Hoai Nam Bui"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.275": {
    "title": "TriEmbed: Bridge the Gap between Text and Token Indices with Embedding Reparameterization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baizhou Huang",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.276": {
    "title": "Chain of Methodologies: Scaling Test Time Computation without Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Liu",
      "Jie Wu",
      "Weigang Wu",
      "Xu Chen",
      "Liang Lin",
      "Wei-Shi Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.277": {
    "title": "A Survey on Personalized Alignment—The Missing Piece for Large Language Models in Real-World Applications",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Guan",
      "Junfei Wu",
      "Jia-Nan Li",
      "Chuanqi Cheng",
      "Wei Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.278": {
    "title": "SuLoRA: Subspace Low-Rank Adaptation for Parameter-Efficient Fine-Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenhao Ding",
      "Jiangyang Li",
      "SongLin Dong",
      "Xinyuan Gao",
      "Yuhang He",
      "Yihong Gong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.279": {
    "title": "MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeong-Joon Ju",
      "Ho-Joong Kim",
      "Seong-Whan Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.280": {
    "title": "Correcting on Graph: Faithful Semantic Parsing over Knowledge Graphs with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruilin Zhao",
      "Feng Zhao",
      "Hong Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.281": {
    "title": "COPR: Continual Human Preference Learning via Optimal Policy Regularization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Zhang",
      "Lin Gui",
      "Yu Lei",
      "Yuanzhao Zhai",
      "Yehong Zhang",
      "Zhuo Zhang",
      "Yulan He",
      "Hui Wang",
      "Yue Yu",
      "Kam-Fai Wong",
      "Bin Liang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.282": {
    "title": "Robust Preference Optimization via Dynamic Target Margins",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Sun",
      "Junkang Wu",
      "Jiancan Wu",
      "Zhibo Zhu",
      "Xingyu Lu",
      "Jun Zhou",
      "Lintao Ma",
      "Xiang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.283": {
    "title": "AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for Video-language Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Wang",
      "Qingyi Si",
      "Shiyu Zhu",
      "Jianlong Wu",
      "Li Cao",
      "Liqiang Nie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.284": {
    "title": "Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongru Wang",
      "Wenyu Huang",
      "Yufei Wang",
      "Yuanhao Xi",
      "Jianqiao Lu",
      "Huan Zhang",
      "Nan Hu",
      "Zeming Liu",
      "Jeff Z. Pan",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.285": {
    "title": "Open-Set Living Need Prediction with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaochong Lan",
      "Jie Feng",
      "Yizhou Sun",
      "Chen Gao",
      "Jiahuan Lei",
      "Xinleishi Xinleishi",
      "Hengliang Luo",
      "Yong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.286": {
    "title": "Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Huang",
      "Wangtao Sun",
      "Jun Zhao",
      "Kang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.287": {
    "title": "Beyond Words: Integrating Theory of Mind into Conversational Agents for Human-Like Belief, Desire, and Intention Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehdi Jafari",
      "Yuncheng Hua",
      "Hao Xue",
      "Flora D. Salim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.288": {
    "title": "Multimodal Causal Reasoning Benchmark: Challenging Multimodal Large Language Models to Discern Causal Links Across Modalities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Li",
      "Heng Wang",
      "Dongnan Liu",
      "Chaoyi Zhang",
      "Ao Ma",
      "Jieting Long",
      "Weidong Cai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.289": {
    "title": "Context-Aware Hierarchical Merging for Long Document Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Litu Ou",
      "Mirella Lapata"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.290": {
    "title": "VCD: A Dataset for Visual Commonsense Discovery in Images",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangqing Shen",
      "Fanfan Wang",
      "Siwei Wu",
      "Rui Xia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.291": {
    "title": "Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongru Wang",
      "Deng Cai",
      "Wanjun Zhong",
      "Shijue Huang",
      "Jeff Z. Pan",
      "Zeming Liu",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.292": {
    "title": "HyperCRS: Hypergraph-Aware Multi-Grained Preference Learning to Burst Filter Bubbles in Conversational Recommendation System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongsen Zheng",
      "Mingjie Qian",
      "Guohua Wang",
      "Yang Liu",
      "Ziliang Chen",
      "Mingzhi Mao",
      "Liang Lin",
      "Kwok-Yan Lam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.293": {
    "title": "Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyu Lu",
      "Kai Ma",
      "Kaichun Wang",
      "Kelaiti Xiao",
      "Roy Ka-Wei Lee",
      "Bo Xu",
      "Liang Yang",
      "Hongfei Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.294": {
    "title": "Language Repository for Long Video Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kumara Kahatapitiya",
      "Kanchana Ranasinghe",
      "Jongwoo Park",
      "Michael S Ryoo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.295": {
    "title": "Investigating Language Preference of Multilingual RAG Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeonghyun Park",
      "Hwanhee Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.296": {
    "title": "FGDGNN: Fine-Grained Dynamic Graph Neural Network for Rumor Detection on Social Media",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mei Guo",
      "Chen Chen",
      "Chunyan Hou",
      "Yike Wu",
      "Xiaojie Yuan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.297": {
    "title": "Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoying Zhang",
      "Baolin Peng",
      "Ye Tian",
      "Jingyan Zhou",
      "Yipeng Zhang",
      "Haitao Mi",
      "Helen M. Meng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.298": {
    "title": "QueryAttack: Jailbreaking Aligned Large Language Models Using Structured Non-natural Query Language",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingsong Zou",
      "Jingyu Xiao",
      "Qing Li",
      "Zhi Yan",
      "Yuhang Wang",
      "Li Xu",
      "Wenxuan Wang",
      "Kuofeng Gao",
      "Ruoyu Li",
      "Yong Jiang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.299": {
    "title": "Memory or Reasoning? Explore How LLMs Compute Mixed Arithmetic Expressions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengzhi Li",
      "Heyan Huang",
      "Ping Jian",
      "Zhen Yang",
      "Chenxu Wang",
      "Yifan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.300": {
    "title": "PersonaX: A Recommendation Agent-Oriented User Modeling Framework for Long Behavior Sequence",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunxiao Shi",
      "Wujiang Xu",
      "Zhang Zeqi",
      "Xing Zi",
      "Qiang Wu",
      "Min Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.301": {
    "title": "Judge as A Judge: Improving the Evaluation of Retrieval-Augmented Generation through the Judge-Consistency of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuliang Liu",
      "Xinze Li",
      "Zhenghao Liu",
      "Yukun Yan",
      "Cheng Yang",
      "Zheni Zeng",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Ge Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.302": {
    "title": "Rationales Are Not Silver Bullets: Measuring the Impact of Rationales on Model Performance and Reliability",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chiwei Zhu",
      "Benfeng Xu",
      "An Yang",
      "Junyang Lin",
      "Quan Wang",
      "Chang Zhou",
      "Zhendong Mao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.303": {
    "title": "CA-GAR: Context-Aware Alignment of LLM Generation for Document Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng Yu",
      "Junfeng Kang",
      "Rui Li",
      "Qi Liu",
      "Liyang He",
      "Zhenya Huang",
      "Shuanghong Shen",
      "Junyu Lu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.304": {
    "title": "AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guhong Chen",
      "Liyang Fan",
      "Zihan Gong",
      "Nan Xie",
      "Zixuan Li",
      "Ziqiang Liu",
      "Chengming Li",
      "Qiang Qu",
      "Hamid Alinejad-Rokny",
      "Shiwen Ni",
      "Min Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.305": {
    "title": "MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "JinYang Huang",
      "Xiachong Feng",
      "Qiguang Chen",
      "Hanjie Zhao",
      "Zihui Cheng",
      "Jiesong Bai",
      "Jingxuan Zhou",
      "Min Li",
      "Libo Qin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.306": {
    "title": "An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Huang",
      "Xingyuan Bu",
      "Hongli Zhou",
      "Yingqi Qu",
      "Jing Liu",
      "Muyun Yang",
      "Bing Xu",
      "Tiejun Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.307": {
    "title": "Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueyang Feng",
      "Jingsen Zhang",
      "Jiakai Tang",
      "Wei Li",
      "Guohao Cai",
      "Xu Chen",
      "Quanyu Dai",
      "Yue Zhu",
      "Zhenhua Dong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.308": {
    "title": "ProMedTS: A Self-Supervised, Prompt-Guided Multimodal Approach for Integrating Medical Text and Time Series",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Niu",
      "Jing Ma",
      "Hongzhan Lin",
      "Liang Bai",
      "Zhihua Wang",
      "V. W.",
      "Richard Yi Da Xu",
      "Guo Li",
      "Xian Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.309": {
    "title": "CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Li",
      "Qizhi Pei",
      "Mengyuan Sun",
      "Honglin Lin",
      "Chenlin Ming",
      "Xin Gao",
      "Jiang Wu",
      "Conghui He",
      "Lijun Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.310": {
    "title": "Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hwan Chang",
      "Hwanhee Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.311": {
    "title": "Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Liu",
      "Siyu An",
      "Junru Lu",
      "Muling Wu",
      "Tianlong Li",
      "Xiaohua Wang",
      "Changze Lv",
      "Xiaoqing Zheng",
      "Di Yin",
      "Xing Sun",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.312": {
    "title": "LR²Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianghao Chen",
      "Zhenlin Wei",
      "Zhenjiang Ren",
      "Ziyong Li",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.313": {
    "title": "McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tian Lan",
      "Xiangdong Su",
      "Xu Liu",
      "Ruirui Wang",
      "Ke Chang",
      "Jiang Li",
      "Guanglai Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.314": {
    "title": "MARK: Multi-agent Collaboration with Ranking Guidance for Text-attributed Graph Clustering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Fu",
      "Yuxing Zhang",
      "Chunchun Chen",
      "JianwenMa JianwenMa",
      "Quan Yuan",
      "Rong-Cheng Tu",
      "Xinli Huang",
      "Wei Ye",
      "Xiao Luo",
      "Minghua Deng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.315": {
    "title": "Can Language Models Capture Human Writing Preferences for Domain-Specific Text Summarization?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingbao Luo",
      "Ming Liu",
      "Ran Liu",
      "Yongpan Sheng",
      "Xin Hu",
      "Gang Li",
      "WupengNjust WupengNjust"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.316": {
    "title": "Mitigate Position Bias in LLMs via Scaling a Single Hidden States Channel",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijiong Yu",
      "Huiqiang Jiang",
      "Xufang Luo",
      "Qianhui Wu",
      "Chin-Yew Lin",
      "Dongsheng Li",
      "Yuqing Yang",
      "Yongfeng Huang",
      "Lili Qiu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.317": {
    "title": "Self-attention-based Graph-of-Thought for Math Problem Solving",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqiao Bai",
      "Xue Han",
      "Shuo Lei",
      "Junlan Feng",
      "Yanyan Luo",
      "Chao Deng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.318": {
    "title": "BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihong Du",
      "Wenrui Liao",
      "Binyu Yan",
      "Hongru Liang",
      "Anthony G Cohn",
      "Wenqiang Lei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.319": {
    "title": "KAPA: A Deliberative Agent Framework with Tree-Structured Knowledge Base for Multi-Domain User Intent Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiakai Tang",
      "Shiqi Shen",
      "ZhipengWang ZhipengWang",
      "Gong Zhi",
      "Xueyang Feng",
      "Zexu Sun",
      "Haoran Tan",
      "Xu Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.320": {
    "title": "RASD: Retrieval-Augmented Speculative Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guofeng Quan",
      "Wenfeng Feng",
      "Chuzhan Hao",
      "Guochao Jiang",
      "Yuewei Zhang",
      "Hao Henry Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.321": {
    "title": "FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zengyi Gao",
      "Yukun Cao",
      "Hairu Wang",
      "Ao Ke",
      "Yuan Feng",
      "S Kevin Zhou",
      "Xike Xie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.322": {
    "title": "Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kening Zheng",
      "Junkai Chen",
      "Yibo Yan",
      "Xin Zou",
      "Huiyu Zhou",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.323": {
    "title": "Blessing of Multilinguality: A Systematic Analysis of Multilingual In-Context Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilei Tu",
      "Andrew Xue",
      "Freda Shi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.324": {
    "title": "SEK: Self-Explained Keywords Empower Large Language Models for Code Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lishui Fan",
      "Mouxiang Chen",
      "Zhongxin Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.325": {
    "title": "Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Ding",
      "Jun Kuang",
      "ZongYu Wang",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Jiajun Chen",
      "Shujian Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.326": {
    "title": "Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vardaan Pahuja",
      "Yadong Lu",
      "Corby Rosset",
      "Boyu Gou",
      "Arindam Mitra",
      "Spencer Whitehead",
      "Yu Su",
      "Ahmed Hassan Awadallah"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.327": {
    "title": "Advancing General Multimodal Capability of Vision-language Models with Pyramid-descent Visual Position Encoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanpeng Chen",
      "Mingxiao Li",
      "Ziyang Chen",
      "Nan Du",
      "Xiaolong Li",
      "Yuexian Zou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.328": {
    "title": "P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Dan",
      "Jie Zhou",
      "Qin Chen",
      "Junfeng Tian",
      "Liang He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.329": {
    "title": "EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiamin Su",
      "Yibo Yan",
      "Fangteng Fu",
      "Zhang Han",
      "Jingheng Ye",
      "Xiang Liu",
      "Jiahao Huo",
      "Huiyu Zhou",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.330": {
    "title": "Streamlining the Collaborative Chain of Models into A Single Forward Pass in Generation-Based Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanjie Lyu",
      "Chao Zhang",
      "Yuhao Chen",
      "Yong Chen",
      "Tong Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.331": {
    "title": "Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi He",
      "Hehai Lin",
      "Qingyun Wang",
      "Yi R. Fung",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.332": {
    "title": "Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenkai Sun",
      "Denghui Zhang",
      "ChengXiang Zhai",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.333": {
    "title": "Probability-Consistent Preference Optimization for Enhanced LLM Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunqiao Yang",
      "Houxing Ren",
      "Zimu Lu",
      "Ke Wang",
      "Weikang Shi",
      "Aojun Zhou",
      "Junting Pan",
      "Mingjie Zhan",
      "Hongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.334": {
    "title": "IW-Bench: Evaluating Large Multimodal Models for Converting Image-to-Web",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongcheng Guo",
      "Wei Zhang",
      "Junhao Chen",
      "Yaonan Gu",
      "Jian Yang",
      "Junjia Du",
      "Shaosheng Cao",
      "Binyuan Hui",
      "Tianyu Liu",
      "Jianxin Ma",
      "Chang Zhou",
      "Zhoujun Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.335": {
    "title": "TDCSA: LLM-Guided Top-Down Approach for Robust Citation Sentiment Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Gao",
      "Jieyang Peng",
      "Xiaoming Tao",
      "Wang Youzheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.336": {
    "title": "DeepRTL2: A Versatile Model for RTL-Related Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Liu",
      "Hongji Zhang",
      "Yunhao Zhou",
      "Zhengyuan Shi",
      "Changran Xu",
      "Qiang Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.337": {
    "title": "The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Sun",
      "Mingshuai Chen",
      "Tiancheng Zhao",
      "Ruochen Xu",
      "Zilun Zhang",
      "Jianwei Yin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.338": {
    "title": "Cross-lingual Multimodal Sentiment Analysis for Low-Resource Languages via Language Family Disentanglement and Rethinking Transfer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long Chen",
      "Shuoyu Guan",
      "Xiaohua Huang",
      "Wen-Jing Wang",
      "Cai Xu",
      "Ziyu Guan",
      "Wei Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.339": {
    "title": "Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengda Lu",
      "Xiaoyu Fan",
      "Yu Huang",
      "Rongwu Xu",
      "Jijie Li",
      "Wei Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.340": {
    "title": "InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Zang",
      "Xiaoyi Dong",
      "Pan Zhang",
      "Yuhang Cao",
      "Ziyu Liu",
      "Shengyuan Ding",
      "Shenxi Wu",
      "Yubo Ma",
      "Haodong Duan",
      "Wenwei Zhang",
      "Kai Chen",
      "Dahua Lin",
      "Jiaqi Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.341": {
    "title": "RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Li",
      "Nan Zhang",
      "Xiaoyang Qu",
      "Kai Lu",
      "Guokuan Li",
      "Jiguang Wan",
      "Jianzong Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.342": {
    "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhentao Xie",
      "Chengcheng Han",
      "Jinxin Shi",
      "Wenjun Cui",
      "Xin Zhao",
      "Xingjiao Wu",
      "Jiabao Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.343": {
    "title": "Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Jiang",
      "Yufei Wang",
      "Chuhan Wu",
      "Xinyi Dai",
      "Yan Xu",
      "Weinan Gan",
      "Yasheng Wang",
      "Xin Jiang",
      "Lifeng Shang",
      "Ruiming Tang",
      "Wei Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.344": {
    "title": "RLKGF: Reinforcement Learning from Knowledge Graph Feedback Without Human Annotations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lian Yan",
      "Chen Tang",
      "Yi Guan",
      "Haotian Wang",
      "Songyuan Wang",
      "Haifeng Liu",
      "Yang Yang",
      "Jingchi Jiang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.345": {
    "title": "Learning Task Representations from In-Context Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baturay Saglam",
      "Xinyang Hu",
      "Zhuoran Yang",
      "Dionysis Kalogerias",
      "Amin Karbasi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.346": {
    "title": "CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohu Li",
      "Yunfeng Ning",
      "Zepeng Bao",
      "Mayi Xu",
      "Jianhao Chen",
      "Tieyun Qian"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.347": {
    "title": "Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubo Li",
      "Yidi Miao",
      "Xueying Ding",
      "Ramayya Krishnan",
      "Rema Padman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.348": {
    "title": "OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengzhou Cheng",
      "Zheng Wu",
      "Zongru Wu",
      "Tianjie Ju",
      "Aston Zhang",
      "Zhuosheng Zhang",
      "Gongshen Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.349": {
    "title": "Red-Teaming LLM Multi-Agent Systems via Communication Attacks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei He",
      "Yuping Lin",
      "Shen Dong",
      "Han Xu",
      "Yue Xing",
      "Hui Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.350": {
    "title": "Can We Trust AI Doctors? A Survey of Medical Hallucination in Large Language and Large Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihong Zhu",
      "Yunyan Zhang",
      "Xianwei Zhuang",
      "Fan Zhang",
      "Zhongwei Wan",
      "Yuyan Chen",
      "QingqingLong QingqingLong",
      "Yefeng Zheng",
      "Xian Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.351": {
    "title": "DRT: Deep Reasoning Translation via Long Chain-of-Thought",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Yunlong Liang",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.352": {
    "title": "CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fuying Wang",
      "Feng Wu",
      "Yihan Tang",
      "Lequan Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.353": {
    "title": "Vision-aided Unsupervised Constituency Parsing with Multi-MLLM Debating",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Zhang",
      "Haiyan Tian",
      "Qingying Sun",
      "Shoushan Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.354": {
    "title": "Inter-Passage Verification for Multi-evidence Multi-answer QA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingsen Chen",
      "Shenji Wan",
      "Xi Ye",
      "Chen Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.355": {
    "title": "PROMTEC: Fast LLM Inference Decoding using Prompt Multi-Lookup with Template Database and Common Sequences",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alan Chi-Man Lee",
      "Wing-Sun Cheng",
      "Calvin Chun-Kit Chan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.356": {
    "title": "Logical DA: Enhancing Data Augmentation for Logical Reasoning via a Multi-Agent System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoqi Zheng",
      "DongWang DongWang",
      "Silin Yang",
      "Yunpeng Qi",
      "Ruochun Jin",
      "Liyang Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.357": {
    "title": "Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubai Wei",
      "Jiale Han",
      "Yi Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.358": {
    "title": "SQL Injection Jailbreak: A Structural Disaster of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Zhao",
      "Kejiang Chen",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.359": {
    "title": "TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewoo Lee",
      "Keyang Xuan",
      "Chanakya Ekbote",
      "Sandeep Polisetty",
      "Yi R. Fung",
      "Paul Pu Liang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.360": {
    "title": "Generative Music Models' Alignment with Professional and Amateur Users' Expectations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Wang",
      "Jiaxing Yu",
      "Haoxuan Liu",
      "Zehui Zheng",
      "Yuhang Jin",
      "Shuyu Li",
      "Shulei Ji",
      "Kejun Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.361": {
    "title": "LLM-Forest: Ensemble Learning of LLMs with Graph-Augmented Prompts for Data Imputation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinrui He",
      "Yikun Ban",
      "Jiaru Zou",
      "Tianxin Wei",
      "Curtiss Cook",
      "Jingrui He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.362": {
    "title": "Task Calibration: Calibrating Large Language Models on Inference Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingjie Li",
      "Yun Luo",
      "Xiaotian Xie",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.363": {
    "title": "MiniELM: A Lightweight and Adaptive Query Rewriting Framework for E-Commerce Search Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duy A. Nguyen",
      "Rishi Kesav Mohan",
      "Shimeng Yang",
      "Pritom Saha Akash",
      "Kevin Chen-Chuan Chang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.364": {
    "title": "Visibility as Survival: Generalizing NLP for Native Alaskan Language Identification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivory Yang",
      "Chunhui Zhang",
      "Yuxin Wang",
      "Zhongyu Ouyang",
      "Soroush Vosoughi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.365": {
    "title": "KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangchen Xu",
      "Yang Liu",
      "Yueqin Yin",
      "Mingyuan Zhou",
      "Radha Poovendran"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.366": {
    "title": "Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaochuan Liu",
      "Ruihua Song",
      "Xiting Wang",
      "Xu Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.367": {
    "title": "Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic languages",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratik Rakesh Singh",
      "Kritarth Prasad",
      "Mohammadi Zaki",
      "Pankaj Wasnik"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.368": {
    "title": "Question Answering in Climate Adaptation for Agriculture: Model Development and Evaluation with Expert Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Nguyen",
      "Sarvnaz Karimi",
      "Willow Hallgren",
      "Mahesh Prakash"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.369": {
    "title": "AGRec: Adapting Autoregressive Decoders with Graph Reasoning for LLM-based Sequential Recommendation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinfeng Wang",
      "Jin Cui",
      "Fumiyo Fukumoto",
      "Yoshimi Suzuki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.370": {
    "title": "Causal Denoising Prototypical Network for Few-Shot Multi-label Aspect Category Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Cui",
      "Xinfeng Wang",
      "Yoshimi Suzuki",
      "Fumiyo Fukumoto"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.371": {
    "title": "RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengzuo Wu",
      "Yuhang Yang",
      "Guangcheng Zhu",
      "Chao Ye",
      "Hong Gu",
      "Xu Lu",
      "Ruixuan Xiao",
      "Bowen Bao",
      "Yijing He",
      "Liangyu Zha",
      "Wentao Ye",
      "Junbo Zhao",
      "Haobo Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.372": {
    "title": "A Query-Response Framework for Whole-Page Complex-Layout Document Image Translation with Relevant Regional Concentration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyang Zhang",
      "Yaping Zhang",
      "Yupu Liang",
      "Zhiyuan Chen",
      "Lu Xiang",
      "Yang Zhao",
      "Yu Zhou",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.373": {
    "title": "DependEval: Benchmarking LLMs for Repository Dependency Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjia Du",
      "Yadi Liu",
      "Hongcheng Guo",
      "Jiawei Wang",
      "Haojian Huang",
      "Yunyi Ni",
      "Zhoujun Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.374": {
    "title": "A General Knowledge Injection Framework for ICD Coding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Zhang",
      "Kun Zhang",
      "Wenxin Ma",
      "Rongsheng Wang",
      "Chenxu Wu",
      "Yingtai Li",
      "S Kevin Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.375": {
    "title": "MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Huo",
      "Yibo Yan",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Xin Zou",
      "Zhihua Wei",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.376": {
    "title": "Generating Questions, Answers, and Distractors for Videos: Exploring Semantic Uncertainty of Object Motions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjian Ding",
      "Yao Zhang",
      "Jun Wang",
      "Adam Jatowt",
      "Zhenglu Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.377": {
    "title": "DiffSkip: Differential Layer Skipping in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Luo",
      "Weizhi Wang",
      "Xifeng Yan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.378": {
    "title": "Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Jiang",
      "Ben Liu",
      "Miao Peng",
      "Wenjie Xu",
      "Yao Xiao",
      "Zhenyan Shan",
      "Min Peng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.379": {
    "title": "A Bounding Box is Worth One Token - Interleaving Layout and Text in a Large Language Model for Document Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinghui Lu",
      "Haiyang Yu",
      "Yanjie Wang",
      "Yongjie Ye",
      "Jingqun Tang",
      "Ziwei Yang",
      "Binghong Wu",
      "Qi Liu",
      "Hao Feng",
      "Han Wang",
      "Hao Liu",
      "Can Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.380": {
    "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingzhe Li",
      "Xin Lu",
      "Yanyan Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.381": {
    "title": "TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Zheng",
      "Zhifan Feng",
      "Jia Wang",
      "Lanrui Wang",
      "Zheng Lin",
      "Hao Yang",
      "Weiping Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.382": {
    "title": "Konooz: Multi-domain Multi-dialect Corpus for Named Entity Recognition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nagham Hamad",
      "Mohammed Khalilia",
      "Mustafa Jarrar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.383": {
    "title": "Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongji Yang",
      "Yucheng Zhou",
      "Wencheng Han",
      "Jianbing Shen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.384": {
    "title": "CodeV: Issue Resolving with Visual Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linhao Zhang",
      "Daoguang Zan",
      "Quanshun Yang",
      "Zhirong Huang",
      "Dong Chen",
      "Bo Shen",
      "Tianyu Liu",
      "Yongshun Gong",
      "Huang Pengjie",
      "Xudong Lu",
      "Guangtai Liang",
      "Lizhen Cui",
      "Qianxiang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.385": {
    "title": "A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongbin Na",
      "Yining Hua",
      "Zimu Wang",
      "Tao Shen",
      "Beibei Yu",
      "Lilin Wang",
      "Wei Wang",
      "John Torous",
      "Ling Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.386": {
    "title": "Breaking the Reasoning Barrier A Survey on LLM Complex Reasoning through the Lens of Self-Evolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao He",
      "Hao Li",
      "Jingchang Chen",
      "Runxuan Liu",
      "Yixin Cao",
      "Lizi Liao",
      "Zihao Zheng",
      "Zheng Chu",
      "Jiafeng Liang",
      "Ming Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.387": {
    "title": "SEE: Continual Fine-tuning with Sequential Ensemble of Experts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhilin Wang",
      "Yafu Li",
      "Xiaoye Qu",
      "Yu Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.388": {
    "title": "Boosting Policy and Process Reward Models with Monte Carlo Tree Search in Open-Domain QA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi-Min Chan",
      "Chunpu Xu",
      "Junqi Zhu",
      "Jiaming Ji",
      "Donghai Hong",
      "Pengcheng Wen",
      "Chunyang Jiang",
      "Zhen Ye",
      "Yaodong Yang",
      "Wei Xue",
      "Sirui Han",
      "Yike Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.389": {
    "title": "Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Hu",
      "Delai Qiu",
      "Shuyu Wei",
      "Jiaming Zhang",
      "Yining Wang",
      "Shengping Liu",
      "Jitao Sang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.390": {
    "title": "OpenHuEval: Evaluating Large Language Model on Hungarian Specifics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haote Yang",
      "Xingjian Wei",
      "Jiang Wu",
      "Noémi Ligeti-Nagy",
      "Jiaxing Sun",
      "Yinfan Wang",
      "Győző Zijian Yang",
      "Junyuan Gao",
      "Jingchao Wang",
      "Bowen Jiang",
      "Shasha Wang",
      "Nanjun Yu",
      "Zihao Zhang",
      "Shixin Hong",
      "Hongwei Liu",
      "Wei Li",
      "Songyang Zhang",
      "Dahua Lin",
      "Lijun Wu",
      "Gábor Prószéky",
      "Conghui He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.391": {
    "title": "StructFact: Reasoning Factual Knowledge from Structured Data with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sirui Huang",
      "Yanggan Gu",
      "Zhonghao Li",
      "Xuming Hu",
      "Li Qing",
      "Guandong Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.392": {
    "title": "From Imitation to Introspection: Probing Self-Consciousness in Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sirui Chen",
      "Shu Yu",
      "Shengjie Zhao",
      "Chaochao Lu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.393": {
    "title": "DocFusion: A Unified Framework for Document Parsing Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxu Chai",
      "Ziyu Shen",
      "Chong Zhang",
      "Yue Zhang",
      "Xiao Wang",
      "Shihan Dou",
      "Jihua Kang",
      "Jiazheng Zhang",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.394": {
    "title": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Li",
      "Xin Yi",
      "Dongsheng Shi",
      "Gerard De Melo",
      "Xiaoling Wang",
      "Linlin Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.395": {
    "title": "LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Ping",
      "Jiali Zeng",
      "Fandong Meng",
      "Shuo Wang",
      "Jie Zhou",
      "Shanghang Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.396": {
    "title": "Reinforcing Compositional Retrieval: Retrieving Step-by-Step for Composing Informative Contexts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quanyu Long",
      "Jianda Chen",
      "Zhengyuan Liu",
      "Nancy F. Chen",
      "Wenya Wang",
      "Sinno Jialin Pan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.397": {
    "title": "Towards A Better Initial Policy Model For Scalable Long-CoT Reinforcement Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bofei Gao",
      "Yejie Wang",
      "Yibo Miao",
      "Ruoyu Wu",
      "Feifan Song",
      "Longhui Yu",
      "Tianyu Liu",
      "Baobao Chang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.398": {
    "title": "Topic Modeling for Short Texts via Optimal Transport-Based Clustering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tu Vu",
      "Manh Do",
      "Tung Nguyen",
      "Linh Ngo Van",
      "Sang Dinh",
      "Thien Huu Nguyen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.399": {
    "title": "Lemmatisation & Morphological Analysis of Unedited Greek: Do Simple Tasks Need Complex Solutions?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Colin Swaelens",
      "Ilse De Vos",
      "Els Lefever"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.400": {
    "title": "FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengzhang Yu",
      "Yiming Zhang",
      "Zhixin Liu",
      "Zenghui Ding",
      "Yining Sun",
      "Zhanpeng Jin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.401": {
    "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Li",
      "Ruofan Mao",
      "Yusen Zhang",
      "Renze Lou",
      "Chen Wu",
      "Jiaqi Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.402": {
    "title": "Relevance Scores Calibration for Ranked List Truncation via TMP Adapter",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavel Posokhov",
      "Sergei Masliukhin",
      "Skrylnikov Stepan",
      "Danil Tirskikh",
      "Olesia Makhnytkina"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.403": {
    "title": "Neuron Activation Modulation for Text Style Transfer: Guiding Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaona Kong",
      "Jianyi Liu",
      "Yifan Tang",
      "Ru Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.404": {
    "title": "MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingqun Tang",
      "Qi Liu",
      "Yongjie Ye",
      "Jinghui Lu",
      "Shu Wei",
      "An-Lan Wang",
      "Chunhui Lin",
      "Hao Feng",
      "Zhen Zhao",
      "Yanjie Wang",
      "Yuliang Liu",
      "Hao Liu",
      "Xiang Bai",
      "Can Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.405": {
    "title": "HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyan Jiang",
      "Hang Ye",
      "Yongxin Zhu",
      "Xiaoying Zheng",
      "Zikang Chen",
      "Jun Gong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.406": {
    "title": "Understanding the Repeat Curse in Large Language Models from a Feature Perspective",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junchi Yao",
      "Shu Yang",
      "Jianhua Xu",
      "Lijie Hu",
      "Mengdi Li",
      "Di Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.407": {
    "title": "Code-Switching Curriculum Learning for Multilingual Transfer in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haneul Yoo",
      "Cheonbok Park",
      "Sangdoo Yun",
      "Alice Oh",
      "Hwaran Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.408": {
    "title": "A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Yao",
      "Xuan Tong",
      "Ruofan Wang",
      "Yixu Wang",
      "Lujundong Li",
      "Liang Liu",
      "Yan Teng",
      "Yingchun Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.409": {
    "title": "Tag-Evol: Achieving Efficient Instruction Evolving via Tag Injection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Wang",
      "Shiqi Zhou",
      "Chuanzhe Guo",
      "Qingfu Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.410": {
    "title": "Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Huang",
      "Yitong Sun",
      "Shouwei Ruan",
      "Yichi Zhang",
      "Yinpeng Dong",
      "Xingxing Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.411": {
    "title": "GeNRe: A French Gender-Neutral Rewriting System Using Collective Nouns",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enzo Doyen",
      "Amalia Todirascu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.412": {
    "title": "LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Jaumann",
      "Andreas Wiedholz",
      "Annemarie Friedrich"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.413": {
    "title": "LCHAIM - Investigating Long Context Reasoning in Hebrew",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ehud Malul",
      "Oriel Perets",
      "Ziv Mor",
      "Yigal Kassel",
      "Elior Sulem"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.414": {
    "title": "CLeVeR: Multi-modal Contrastive Learning for Vulnerability Code Representation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayuan Li",
      "Lei Cui",
      "Sen Zhao",
      "Yun Yang",
      "Lun Li",
      "Hongsong Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.415": {
    "title": "MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zilu Dong",
      "Xiangqing Shen",
      "Rui Xia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.416": {
    "title": "Large Language Models for Predictive Analysis: How Far Are They?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Chen",
      "Yuanyi Ren",
      "Xiaojun Ma",
      "Yuyang Shi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.417": {
    "title": "Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxue Cheng",
      "Junyi Li",
      "Xin Zhao",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.418": {
    "title": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qitao Qin",
      "Yucong Luo",
      "Yihang Lu",
      "Zhibo Chu",
      "Xiaoman Liu",
      "Xianwei Meng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.419": {
    "title": "Enhancing Cross-Tokenizer Knowledge Distillation with Contextual Dynamical Mapping",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijie Chen",
      "Yijin Liu",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.420": {
    "title": "A Semantic-Aware Layer-Freezing Approach to Computation-Efficient Fine-Tuning of Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Gu",
      "Aldeida Aleti",
      "Chunyang Chen",
      "Hongyu Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.421": {
    "title": "CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingxiao Wei",
      "He Yan",
      "Lu Xiangju",
      "Junmin Zhu",
      "Jun Wang",
      "Wei Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.422": {
    "title": "Document Segmentation Matters for Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhitong Wang",
      "Cheng Gao",
      "Chaojun Xiao",
      "Yufei Huang",
      "Shuzheng Si",
      "Kangyang Luo",
      "Yuzhuo Bai",
      "Wenhao Li",
      "Tangjian Duan",
      "Chuancheng Lv",
      "Guoshan Lu",
      "Gang Chen",
      "Fanchao Qi",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.423": {
    "title": "UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunzhi Wang",
      "Zhuowei Zhang",
      "Gaonan Chen",
      "Qiongyu Li",
      "Bitong Luo",
      "Zhixin Han",
      "Haotian Wang",
      "Zhiyu Li",
      "Hang Gao",
      "Mengting Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.424": {
    "title": "Embracing Large Language Models in Traffic Flow Forecasting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusheng Zhao",
      "Xiao Luo",
      "Haomin Wen",
      "Zhiping Xiao",
      "Wei Ju",
      "Ming Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.425": {
    "title": "Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengliang He",
      "Jiayi Zeng",
      "Yankai Jiang",
      "Wei Zhang",
      "Zeming Liu",
      "Xiaoming Shi",
      "Aimin Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.426": {
    "title": "Smarter, Not Harder: Training-Free Adaptive Computation for Transformers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Romain Storaï",
      "Jaeseong Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.427": {
    "title": "UCS-SQL: Uniting Content and Structure for Enhanced Semantic Bridging In Text-to-SQL",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenhe Wu",
      "Zhongqiu Li",
      "JieZhangChinaTele JieZhangChinaTele",
      "Zhongjiang He",
      "Jian Yang",
      "Yu Zhao",
      "Ruiyu Fang",
      "Bing Wang",
      "Hongyan Xie",
      "Shuangyong Song",
      "Zhoujun Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.428": {
    "title": "CodePRM: Execution Feedback-enhanced Process Reward Model for Code Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyao Li",
      "Xinyi Dai",
      "Xiangyang Li",
      "Weinan Zhang",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.429": {
    "title": "STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaru Zou",
      "Qing Wang",
      "Pratyush Thakur",
      "Nickvash Kani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.430": {
    "title": "Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihoon Lee",
      "Min Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.431": {
    "title": "Leveraging LLMs for Bangla Grammar Error Correction: Error Categorization, Synthetic Data, and Model Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pramit Bhattacharyya",
      "Arnab Bhattacharya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.432": {
    "title": "Think Both Ways: Teacher-Student Bidirectional Reasoning Enhances MCQ Generation and Distractor Quality",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yimiao Qiu",
      "Yang Deng",
      "Quanming Yao",
      "Zhimeng Zhang",
      "Zhiang Dong",
      "Chang Yao",
      "Jingyuan Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.433": {
    "title": "mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haonan Chen",
      "Liang Wang",
      "Nan Yang",
      "Yutao Zhu",
      "Ziliang Zhao",
      "Furu Wei",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.434": {
    "title": "Word2Passage: Word-level Importance Re-weighting for Query Expansion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeonghwan Choi",
      "Minjeong Ban",
      "Minseok Kim",
      "Hwanjun Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.435": {
    "title": "MECoT: Markov Emotional Chain-of-Thought for Personality-Consistent Role-Playing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangbo Wei",
      "Zhen Huang",
      "Fangzhou Zhao",
      "Qi Feng",
      "Wei W. Xing"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.436": {
    "title": "FiDeLiS: Faithful Reasoning in Large Language Models for Knowledge Graph Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Sui",
      "Yufei He",
      "Nian Liu",
      "Xiaoxin He",
      "Kun Wang",
      "Bryan Hooi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.437": {
    "title": "REALM: A Dataset of Real-World LLM Use Cases",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwen Cheng",
      "Kshitish Ghate",
      "Wenyue Hua",
      "William Yang Wang",
      "Hong Shen",
      "Fei Fang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.438": {
    "title": "BABELEDITS: A Benchmark and a Modular Approach for Robust Cross-lingual Knowledge Editing of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tommaso Green",
      "Félix Gaschi",
      "Fabian David Schmidt",
      "Simone Paolo Ponzetto",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.439": {
    "title": "CDS: Data Synthesis Method Guided by Cognitive Diagnosis Theory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haokun Zhao",
      "Jinyi Han",
      "Jiaqing Liang",
      "Yanghua Xiao",
      "Xiaojun Meng",
      "Jiansheng Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.440": {
    "title": "Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuetao Ma",
      "Wenbin Jiang",
      "Hua Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.441": {
    "title": "BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dipankar Srirag",
      "Aditya Joshi",
      "Jordan Painter",
      "Diptesh Kanojia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.442": {
    "title": "NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Wang",
      "Yaohui Zhu",
      "Gim Hee Lee",
      "Yachun Fan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.443": {
    "title": "SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Guo",
      "Dong Jin",
      "Shenghao Ye",
      "Shuangwu Chen",
      "Jianyang Jianyang",
      "Xiaobin Tan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.444": {
    "title": "Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen Zhu",
      "Congmin Zheng",
      "Jianghao Lin",
      "Kounianhua Du",
      "Ying Wen",
      "Yong Yu",
      "Jun Wang",
      "Weinan Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.445": {
    "title": "Contrastive Learning for Task-Independent SpeechLLM-Pretraining",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maike Züfle",
      "Jan Niehues"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.446": {
    "title": "QiMeng-Attention: SOTA Attention Operator is generated by SOTA Attention Algorithm",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qirui Zhou",
      "Shaohui Peng",
      "Weiqiang Xiong",
      "Haixin Chen",
      "Yuanbo Wen",
      "Haochen Li",
      "Ling Li",
      "Qi Guo",
      "Yongwei Zhao",
      "Ke Gao",
      "Ruizhi Chen",
      "Yanjun Wu",
      "Zhao Chen",
      "Yunji Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.447": {
    "title": "ALW: Adaptive Layer-Wise contrastive decoding enhancing reasoning ability in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuechi Zhou",
      "Chuyue Zhou",
      "Jianxin Zhang",
      "Juntao Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.448": {
    "title": "Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinlong Chen",
      "Yuanxing Zhang",
      "Qiang Liu",
      "Junfei Wu",
      "Fuzheng Zhang",
      "Tieniu Tan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.449": {
    "title": "VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinlong Chen",
      "Yuanxing Zhang",
      "Chongling Rao",
      "Yushuo Guan",
      "Jiaheng Liu",
      "Fuzheng Zhang",
      "Chengru Song",
      "Qiang Liu",
      "Di Zhang",
      "Tieniu Tan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.450": {
    "title": "Mitigating Demonstration Bias through Global Coevolutionary Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuan Gou",
      "Bangwei Li",
      "Jianhua Dai",
      "Xiaoyang Han",
      "Ming Cai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.451": {
    "title": "A Representation Level Analysis of NMT Model Robustness to Grammatical Errors",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abderrahmane Issam",
      "Yusuf Can Semerci",
      "Jan Scholtes",
      "Gerasimos Spanakis"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.452": {
    "title": "T2DR: A Two-Tier Deficiency-Resistant Framework for Incomplete Multimodal Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Lin",
      "Xiu Tang",
      "Huan Li",
      "Wenxue Cao",
      "Sai Wu",
      "Chang Yao",
      "Lidan Shou",
      "Gang Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.453": {
    "title": "From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shixin Jiang",
      "Jiafeng Liang",
      "Jiyuan Wang",
      "Xuan Dong",
      "Heng Chang",
      "Weijiang Yu",
      "Jinhua Du",
      "Ming Liu",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.454": {
    "title": "Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Verena Blaschke",
      "Masha Fedzechkina",
      "Maartje Ter Hoeve"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.455": {
    "title": "Agents generalize to novel levels of abstraction by using adaptive linguistic strategies",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kristina Kobrock",
      "Xenia Ohmer",
      "Elia Bruni",
      "Nicole Gotzner"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.456": {
    "title": "The Linguistic Connectivities Within Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dan Wang",
      "Boxi Cao",
      "Ning Bian",
      "Xuanang Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Jia Zheng",
      "Le Sun",
      "Shanshan Jiang",
      "Bin Dong",
      "Xianpei Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.457": {
    "title": "XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihan Zhang",
      "Yixin Cao",
      "Lizi Liao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.458": {
    "title": "Align2LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongzhe Huang",
      "Jiang Liu",
      "Zhewen Yu",
      "Li Cai",
      "Dian Jiao",
      "Wenqiao Zhang",
      "Siliang Tang",
      "Juncheng Li",
      "Hao Jiang",
      "Haoyuan Li",
      "Yueting Zhuang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.459": {
    "title": "Achieving binary weight and activation for LLMs using Post-Training Quantization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqing Song",
      "Chuang Wang",
      "Rui-Qi Wang",
      "Yi Yang",
      "Xu-Yao Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.460": {
    "title": "Mitigating Negative Interference in Multilingual Knowledge Editing through Null-Space Constraints",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Sun",
      "Tingyu Qu",
      "Mingxiao Li",
      "Jesse Davis",
      "Marie-Francine Moens"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.461": {
    "title": "From Awareness to Adaptability: Enhancing Tool Utilization for Scientific Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjing Xie",
      "Xiaobo Liang",
      "Juntao Li",
      "Wanfu Wang",
      "Kehai Chen",
      "Qiaoming Zhu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.462": {
    "title": "AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Liu",
      "Jingqing Ruan",
      "Hao Li",
      "Haodong Zhao",
      "Desheng Wang",
      "Jiansong Chen",
      "Wan Guanglu",
      "Xunliang Cai",
      "Zhi Zheng",
      "Tong Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.463": {
    "title": "Supervised Optimism Correction: Be Confident When LLMs Are Sure",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Zhang",
      "Rushuai Yang",
      "Shunyu Liu",
      "Ting-En Lin",
      "Fei Huang",
      "Yi Chen",
      "Yongbin Li",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.464": {
    "title": "Offline Reinforcement Learning for LLM Multi-step Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huaijie Wang",
      "Shibo Hao",
      "Hanze Dong",
      "Shenao Zhang",
      "Yilin Bao",
      "Ziran Yang",
      "Yi Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.465": {
    "title": "Sampling-based Pseudo-Likelihood for Membership Inference Attacks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masahiro Kaneko",
      "Youmi Ma",
      "Yuki Wata",
      "Naoaki Okazaki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.466": {
    "title": "AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyou Jia",
      "Minnan Luo",
      "Zhuohang Dang",
      "Qiushi Sun",
      "Fangzhi Xu",
      "Junlin Hu",
      "Tianbao Xie",
      "Zhiyong Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.467": {
    "title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin-Cheng Wen",
      "Yijun Yang",
      "Cuiyun Gao",
      "Yang Xiao",
      "Deheng Ye"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.468": {
    "title": "GA-S3: Comprehensive Social Network Simulation with Group Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunyao Zhang",
      "Zikai Song",
      "Hang Zhou",
      "Wenfeng Ren",
      "Yi-Ping Phoebe Chen",
      "Junqing Yu",
      "Wei Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.469": {
    "title": "M-RangeDetector: Enhancing Generalization in Machine-Generated Text Detection through Multi-Range Attention Masks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaijie Jiao",
      "Quan Wang",
      "Licheng Zhang",
      "Zikang Guo",
      "Zhendong Mao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.470": {
    "title": "Does Your Voice Assistant Remember? Analyzing Conversational Context Recall and Utilization in Voice Interaction Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heeseung Kim",
      "Che Hyun Lee",
      "Sangkwon Park",
      "Jiheum Yeom",
      "Nohil Park",
      "Sangwon Yu",
      "Sungroh Yoon"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.471": {
    "title": "NeuronMerge: Merging Models via Functional Neuron Groups",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wangyun Gu",
      "Qianghua Gao",
      "Zhang Li-Xin",
      "Xu Shen",
      "Jieping Ye"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.472": {
    "title": "HellaSwag-Pro: A Large-Scale Bilingual Benchmark for Evaluating the Robustness of LLMs in Commonsense Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyuan Li",
      "Moxin Li",
      "Rui Men",
      "Yichang Zhang",
      "Keqin Bao",
      "Wenjie Wang",
      "Fuli Feng",
      "Dayiheng Liu",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.473": {
    "title": "Self-Steering Optimization: Autonomous Preference Optimization for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Xiang",
      "Bowen Yu",
      "Hongyu Lin",
      "Keming Lu",
      "Yaojie Lu",
      "Xianpei Han",
      "Ben He",
      "Le Sun",
      "Jingren Zhou",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.474": {
    "title": "LIME: Less Is More for MLLM Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "King Zhu",
      "Qianbo Zang",
      "Shian Jia",
      "Siwei Wu",
      "Feiteng Fang",
      "Yizhi Li",
      "Shuyue Guo",
      "Tianyu Zheng",
      "Jiawei Guo",
      "Bo Li",
      "Haoning Wu",
      "Xingwei Qu",
      "Jian Yang",
      "Ruibo Liu",
      "Xiang Yue",
      "Jiaheng Liu",
      "Chenghua Lin",
      "Hamid Alinejad-Rokny",
      "Min Yang",
      "Shiwen Ni",
      "Wenhao Huang",
      "Ge Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.475": {
    "title": "Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofeng Zhou",
      "Heyan Huang",
      "Lizi Liao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.476": {
    "title": "CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Yi Lin",
      "Chunhua Liu",
      "Haoyu Gao",
      "Patanamon Thongtanunam",
      "Christoph Treude"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.477": {
    "title": "Narrative Media Framing in Political Discourse",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulia Otmakhova",
      "Lea Frermann"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.478": {
    "title": "MHALO: Evaluating MLLMs as Fine-grained Hallucination Detectors",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yishuo Cai",
      "Renjie Gu",
      "Jiaxu Li",
      "Xuancheng Huang",
      "Junzhe Chen",
      "Xiaotao Gu",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.479": {
    "title": "Semantic Topology: a New Perspective for Communication Style Characterization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barbara Scalvini",
      "Alireza Mashaghi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.480": {
    "title": "Decoding LLM Personality Measurement: Forced-Choice vs. Likert",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Li",
      "Haoran Shi",
      "Zengyi Yu",
      "Yukun Tu",
      "Chanjin Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.481": {
    "title": "MultiMSD: A Corpus for Multilingual Medical Text Simplification from Online Medical References",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Koki Horiguchi",
      "Tomoyuki Kajiwara",
      "Takashi Ninomiya",
      "Shoko Wakamiya",
      "Eiji Aramaki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.482": {
    "title": "BadWindtunnel: Defending Backdoor in High-noise Simulated Training with Confidence Variance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruyi Zhang",
      "Songlei Jian",
      "Yusong Tan",
      "Heng Gao",
      "Haifang Zhou",
      "Kai Lu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.483": {
    "title": "Multimodal Machine Translation with Text-Image In-depth Questioning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Gao",
      "Jing Zhao",
      "Shiliang Sun",
      "Xiaosong Qiao",
      "Tengfei Song",
      "Hao Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.484": {
    "title": "ReKG-MCTS: Reinforcing LLM Reasoning on Knowledge Graphs via Training-Free Monte Carlo Tree Search",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaozhuang Song",
      "Shufei Zhang",
      "Tianshu Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.485": {
    "title": "HTML: Hierarchical Topology Multi-task Learning for Semantic Parsing in Knowledge Base Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aziguli Wulamu",
      "Lyu Zhengyu",
      "Kaiyuan Gong",
      "Yu Han",
      "Zewen Wang",
      "Zhihong Zhu",
      "Bowen Xing"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.486": {
    "title": "StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinnan Li",
      "Jinzhe Li",
      "Yue Wang",
      "Yi Chang",
      "Yuan Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.487": {
    "title": "CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanxiao Li",
      "Jiaying Wu",
      "Canyuan He",
      "Wei Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.488": {
    "title": "EtiCor++: Towards Understanding Etiquettical Bias in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashutosh Dwivedi",
      "Siddhant Shivdutt Singh",
      "Ashutosh Modi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.489": {
    "title": "FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanjian Xu",
      "Jianing Hao",
      "Kunsheng Tang",
      "Jingnan Chen",
      "Anxian Liu",
      "Peng Liu",
      "Guang Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.490": {
    "title": "Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingfeng Luo",
      "Tong Zheng",
      "Yongyu Mu",
      "Bei Li",
      "Qinghong Zhang",
      "Yongqi Gao",
      "Ziqiang Xu",
      "Peinan Feng",
      "Xiaoqian Liu",
      "Tong Xiao",
      "JingBo Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.491": {
    "title": "EC-RAFT: Automated Generation of Clinical Trial Eligibility Criteria through Retrieval-Augmented Fine-Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nopporn Lekuthai",
      "Nattawit Pewngam",
      "Supitcha Sokrai",
      "Titipat Achakulvisut"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.492": {
    "title": "Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elena Stringli",
      "Maria Lymperaiou",
      "Giorgos Filandrianos",
      "Athanasios Voulodimos",
      "Giorgos Stamou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.493": {
    "title": "Implicit Reasoning in Transformers is Reasoning through Shortcuts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhe Lin",
      "Jian Xie",
      "Siyu Yuan",
      "Deqing Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.494": {
    "title": "Learning to Align Multi-Faceted Evaluation: A Unified and Robust Framework",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaishuai Xu",
      "Tiezheng Yu",
      "Yi Cheng",
      "Wenjun Hou",
      "Liangyou Li",
      "Xin Jiang",
      "Lifeng Shang",
      "Qun Liu",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.495": {
    "title": "CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiliu Sun",
      "Zicheng Zhao",
      "Sheng Wan",
      "Chen Gong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.496": {
    "title": "PAP2PAT: Benchmarking Outline-Guided Long-Text Patent Generation with Patent-Paper Pairs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Valentin Knappich",
      "Anna Hätty",
      "Simon Razniewski",
      "Annemarie Friedrich"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.497": {
    "title": "Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofeng Wang",
      "Zhixin Zhang",
      "Jin Guang Zheng",
      "Yiming Ai",
      "Rui Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.498": {
    "title": "Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kechi Zhang",
      "Ge Li",
      "Jia Li",
      "Yihong Dong",
      "Jia Li",
      "Zhi Jin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.499": {
    "title": "Supervised and Unsupervised Probing of Shortcut Learning: Case Study on the Emergence and Evolution of Syntactic Heuristics in BERT",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elke Vandermeerschen",
      "Miryam De Lhoneux"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.500": {
    "title": "GIMMICK: Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Schneider",
      "Carolin Holtermann",
      "Chris Biemann",
      "Anne Lauscher"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.501": {
    "title": "R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonhyung Park",
      "Peng Tang",
      "Sagnik Das",
      "Srikar Appalaraju",
      "Kunwar Yashraj Singh",
      "R. Manmatha",
      "Shabnam Ghadar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.502": {
    "title": "Perspective Transition of Large Language Models for Solving Subjective Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolong Wang",
      "Yuanchi Zhang",
      "Ziyue Wang",
      "Yuzhuang Xu",
      "Fuwen Luo",
      "Yile Wang",
      "Peng Li",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.503": {
    "title": "TripTailor: A Real-World Benchmark for Personalized Travel Planning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaimin Wang",
      "Yuanzhe Shen",
      "Changze Lv",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.504": {
    "title": "Random Splitting Negatively Impacts NER Evaluation: Quantifying and Eliminating the Overestimation of NER Performance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Babl",
      "Moritz Hennen",
      "Jakob Murauer",
      "Michaela Geierhos"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.505": {
    "title": "Structure-adaptive Adversarial Contrastive Learning for Multi-Domain Fake News Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingwei Wei",
      "Dou Hu",
      "Wei Zhou",
      "Philip S. Yu",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.506": {
    "title": "BiasGuard: A Reasoning-Enhanced Bias Detection Tool for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiting Fan",
      "Ruizhe Chen",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.507": {
    "title": "Qorǵau: Evaluating Safety in Kazakh-Russian Bilingual Contexts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maiya Goloburda",
      "Nurkhan Laiyk",
      "Diana Turmakhan",
      "Yuxia Wang",
      "Mukhammed Togmanov",
      "Jonibek Mansurov",
      "Askhat Sametov",
      "Nurdaulet Mukhituly",
      "Minghan Wang",
      "Daniil Orel",
      "Zain Muhammad Mujahid",
      "Fajri Koto",
      "Timothy Baldwin",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.508": {
    "title": "MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linjie Mu",
      "Zhongzhen Huang",
      "Shengqian Qin",
      "Yakun Zhu",
      "Shaoting Zhang",
      "Xiaofan Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.509": {
    "title": "Tree-of-Code: A Self-Growing Tree Framework for End-to-End Code Generation and Execution in Complex Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Ni",
      "Yifan Li",
      "Ning Yang",
      "Dou Shen",
      "Pin Lyu",
      "Daxiang Dong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.510": {
    "title": "Akan Cinematic Emotions (ACE): A Multimodal Multi-party Dataset for Emotion Recognition in Movie Dialogues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Sasu",
      "Zehui Wu",
      "Ziwei Gong",
      "Run Chen",
      "Pengyuan Shi",
      "Lin Ai",
      "Julia Hirschberg",
      "Natalie Schluter"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.511": {
    "title": "A Cognitive Writing Perspective for Constrained Long-Form Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyang Wan",
      "Honglin Mu",
      "Rui Hao",
      "Haoran Luo",
      "Tianle Gu",
      "Xiuying Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.512": {
    "title": "Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "You Li",
      "Heyu Huang",
      "Chi Chen",
      "Kaiyu Huang",
      "Chao Huang",
      "Zonghao Guo",
      "Zhiyuan Liu",
      "Jinan Xu",
      "Yuhua Li",
      "Ruixuan Li",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.513": {
    "title": "SIKeD: Self-guided Iterative Knowledge Distillation for Mathematical Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivam Adarsh",
      "Kumar Shridhar",
      "Caglar Gulcehre",
      "Nicholas Monath",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.514": {
    "title": "Chain of Attack: Hide Your Intention through Multi-Turn Interrogation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xikang Yang",
      "Biyu Zhou",
      "Xuehai Tang",
      "Jizhong Han",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.515": {
    "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Chen",
      "Yining Li",
      "Kai Hu",
      "Ma Zerun",
      "HaochenYe HaochenYe",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.516": {
    "title": "Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongchan Chun",
      "Minhyuk Kim",
      "Dongjun Kim",
      "Chanjun Park",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.517": {
    "title": "Explainable Depression Detection in Clinical Interviews with Personalized Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linhai Zhang",
      "Ziyang Gao",
      "Deyu Zhou",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.518": {
    "title": "EMPEC: A Comprehensive Benchmark for Evaluating Large Language Models Across Diverse Healthcare Professions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheheng Luo",
      "Chenhan Yuan",
      "Qianqian Xie",
      "Sophia Ananiadou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.519": {
    "title": "Beyond Numeric Rewards: In-Context Dueling Bandits with LLM Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanzeng Xia",
      "Hao Liu",
      "Yisong Yue",
      "Tongxin Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.520": {
    "title": "Well, Keep Thinking\": Enhancing LLM Reasoning with Adaptive Injection Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunbin Jin",
      "Je Won Yeom",
      "Seunghyun Bae",
      "Taesup Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.521": {
    "title": "SpeechT-RAG: Reliable Depression Detection in LLMs with Retrieval-Augmented Generation Using Speech Timing Information",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Zhang",
      "Hexin Liu",
      "Qiquan Zhang",
      "Beena Ahmed",
      "Julien Epps"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.522": {
    "title": "Fine-grained Knowledge Enhancement for Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingxuan Han",
      "Zhendong Mao",
      "Yi Liu",
      "Yexuan Che",
      "Zheren Fu",
      "Quan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.523": {
    "title": "Bayesian Optimization for Controlled Image Editing via LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengkun Cai",
      "Haoliang Liu",
      "Xu Zhao",
      "Zhongyu Jiang",
      "Tianfang Zhang",
      "Zongkai Wu",
      "John Lee",
      "Jenq-Neng Hwang",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.524": {
    "title": "SPOT: Zero-Shot Semantic Parsing Over Property Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Cazzaro",
      "Justin Kleindienst",
      "Sofia Márquez Gomez",
      "Ariadna Quattoni"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.525": {
    "title": "Reasoning Circuits in Language Models: A Mechanistic Interpretation of Syllogistic Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geonhee Kim",
      "Marco Valentino",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.526": {
    "title": "Multi-Hop Question Generation via Dual-Perspective Keyword Guidance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maodong Li",
      "Longyin Zhang",
      "Fang Kong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.527": {
    "title": "LoRMA: Low-Rank Multiplicative Adaptation for LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harsh Bihany",
      "Shubham Patel",
      "Ashutosh Modi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.528": {
    "title": "DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linghao Zhang",
      "Junhao Wang",
      "Shilin He",
      "Chaoyun Zhang",
      "Yu Kang",
      "Bowen Li",
      "Jiaheng Wen",
      "Chengxing Xie",
      "Maoquan Wang",
      "Yufan Huang",
      "Elsie Nallipogu",
      "Qingwei Lin",
      "Yingnong Dang",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.529": {
    "title": "Weak-to-Strong Honesty Alignment via Learning-to-Rank Supervision",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YunfanXie YunfanXie",
      "Lixin Zou",
      "Dan Luo",
      "Min Tang",
      "Chenliang Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.530": {
    "title": "MultiHoax: A Dataset of Multi-hop False-premise questions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammadamin Shafiei",
      "Hamidreza Saffari",
      "Nafise Sadat Moosavi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.531": {
    "title": "Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinming Zhang",
      "Yunfei Long"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.532": {
    "title": "STATE ToxiCN: A Benchmark for Span-level Target-Aware Toxicity Extraction in Chinese Hate Speech Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zewen Bai",
      "Liang Yang",
      "Shengdi Yin",
      "Junyu Lu",
      "Jingjie Zeng",
      "Haohao Zhu",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.533": {
    "title": "RelEdit: Evaluating Conceptual Knowledge Editing in Language Models via Relational Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Niu",
      "Miao Peng",
      "Nuo Chen",
      "Yatao Bian",
      "Tingyang Xu",
      "Jia Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.534": {
    "title": "Unlocking Speech Instruction Data Potential with Query Rewriting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghua Hei",
      "Yibo Yan",
      "Shuliang Liu",
      "Huiyu Zhou",
      "Linfeng Zhang",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.535": {
    "title": "From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianle Gu",
      "Kexin Huang",
      "Ruilin Luo",
      "Yuanqi Yao",
      "Xiuying Chen",
      "Yujiu Yang",
      "Yan Teng",
      "Yingchun Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.536": {
    "title": "Context-DPO: Aligning Language Models for Context-Faithfulness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baolong Bi",
      "Shaohan Huang",
      "Yiwei Wang",
      "Tianchi Yang",
      "Zihan Zhang",
      "Haizhen Huang",
      "Lingrui Mei",
      "Junfeng Fang",
      "Zehao Li",
      "Furu Wei",
      "Weiwei Deng",
      "Feng Sun",
      "Qi Zhang",
      "Shenghua Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.537": {
    "title": "Reasoning Does Not Necessarily Improve Role-Playing Ability",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiachong Feng",
      "Longxu Dou",
      "Lingpeng Kong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.538": {
    "title": "TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaokang Zhang",
      "Sijia Luo",
      "Bohan Zhang",
      "Zeyao Ma",
      "Jing Zhang",
      "Yang Li",
      "Guanlin Li",
      "Zijun Yao",
      "Kangli Xu",
      "Jinchang Zhou",
      "Daniel Zhang-Li",
      "Jifan Yu",
      "Shu Zhao",
      "Juanzi Li",
      "Jie Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.539": {
    "title": "A Survey of LLM-based Agents in Medicine: How far are we from Baymax?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Zizhan Ma",
      "Zheng Wang",
      "Chenghan Wu",
      "Jiaming Ji",
      "Wenting Chen",
      "Xiang Li",
      "Yixuan Yuan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.540": {
    "title": "Context-Robust Knowledge Editing for Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haewon Park",
      "Gyubin Choi",
      "Minjun Kim",
      "Yohan Jo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.541": {
    "title": "Multi-Agent Collaboration via Cross-Team Orchestration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoyun Du",
      "Chen Qian",
      "Wei Liu",
      "Zihao Xie",
      "YiFei Wang",
      "Rennai Qiu",
      "Yufan Dang",
      "Weize Chen",
      "Cheng Yang",
      "Ye Tian",
      "Xuantang Xiong",
      "Lei Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.542": {
    "title": "Semantic Evaluation of Multilingual Data-to-Text Generation via NLI Fine-Tuning: Precision, Recall and F1 scores",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Soto Martinez",
      "Yannick Parmentier",
      "Claire Gardent"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.543": {
    "title": "Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kidist Amde Mekonnen",
      "Yosef Worku Alemneh",
      "Maarten de Rijke"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.544": {
    "title": "Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Fang",
      "Zhi Jin",
      "Jie An",
      "Hongshen Chen",
      "Xiaohong Chen",
      "Naijun Zhan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.545": {
    "title": "DAGS: A Dependency-Based Dual-Attention and Global Semantic Improvement Framework for Metaphor Recognition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Puli Chen",
      "Cheng Yang",
      "Xingmao Zhang",
      "Qingbao Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.546": {
    "title": "ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofan Bai",
      "Pingyi Hu",
      "Xiaojing Ma",
      "Linchen Yu",
      "Dongmei Zhang",
      "Qi Zhang",
      "Bin Benjamin Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.547": {
    "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenru Zhang",
      "Chujie Zheng",
      "Yangzhen Wu",
      "Beichen Zhang",
      "Runji Lin",
      "Bowen Yu",
      "Dayiheng Liu",
      "Jingren Zhou",
      "Junyang Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.548": {
    "title": "MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi Fan",
      "Yating Wang",
      "Guandong Wang",
      "Zhai Jie",
      "Jingping Liu",
      "Qi Ye",
      "Tong Ruan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.549": {
    "title": "Towards Conditioning Clinical Text Generation for User Control",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Osman Alperen Koraş",
      "Rabi Bahnan",
      "Jens Kleesiek",
      "Amin Dada"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.550": {
    "title": "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniil Orel",
      "Dilshod Azizov",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.551": {
    "title": "Q-Mamba: Towards more efficient Mamba models via post-training quantization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Tianqi",
      "Yuanteng Chen",
      "Peisong Wang",
      "Weixiang Xu",
      "Zeyu Zhu",
      "Jian Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.552": {
    "title": "P²Net: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiwen Wei",
      "Jie Yao",
      "Jiang Zhong",
      "Yangyang Kang",
      "Jingyuan Zhang",
      "Changlong Sun",
      "Xin Zhang",
      "Fengmao Lv",
      "Li Jin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.553": {
    "title": "Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liyang He",
      "Chenglong Liu",
      "Rui Li",
      "Zhenya Huang",
      "Shulan Ruan",
      "Jun Zhou",
      "Enhong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.554": {
    "title": "RQT: Hierarchical Residual Quantization for Multi-Model Compression",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Tianqi",
      "Peisong Wang",
      "Weixiang Xu",
      "Zeyu Zhu",
      "Jian Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.555": {
    "title": "taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stefanie Urchs",
      "Veronika Thurner",
      "Matthias Aßenmacher",
      "Christian Heumann",
      "Stephanie Thiemichen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.556": {
    "title": "LCFO: Long Context and Long Form Output Dataset and Benchmarking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marta R. Costa-jussà",
      "Pierre Andrews",
      "Mariano Coria Meglioli",
      "Joy Chen",
      "Joe Chuang",
      "David Dale",
      "Christophe Ropers",
      "Alexandre Mourachko",
      "Eduardo Sánchez",
      "Holger Schwenk",
      "Tuan A. Tran",
      "Arina Turkatenko",
      "Carleigh Wood"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.557": {
    "title": "Span-based Semantic Role Labeling as Lexicalized Constituency Tree Parsing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Hou",
      "Zhenghua Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.558": {
    "title": "Learning from Negative Samples in Biomedical Generative Entity Linking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chanhwi Kim",
      "Hyunjae Kim",
      "Sihyeon Park",
      "Jiwoo Lee",
      "Mujeen Sung",
      "Jaewoo Kang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.559": {
    "title": "Self-play through Computational Runtimes improves Chart Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tautvydas Misiūnas",
      "Hassan Mansoor",
      "Jasper Uijlings",
      "Oriana Riva",
      "Victor Carbune"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.560": {
    "title": "Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachun Li",
      "Pengfei Cao",
      "Yubo Chen",
      "Jiexin Xu",
      "Huaijun Li",
      "Xiaojian Jiang",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.561": {
    "title": "A Couch Potato is not a Potato on a Couch: Prompting Strategies, Image Generation, and Compositionality Prediction for Noun Compounds",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sinan Kurtyigit",
      "Diego Frassinelli",
      "Carina Silberer",
      "Sabine Schulte Im Walde"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.562": {
    "title": "A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beiduo Chen",
      "Siyao Peng",
      "Anna Korhonen",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.563": {
    "title": "Measuring What Matters: Evaluating Ensemble LLMs with Label Refinement in Inductive Coding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angelina Parfenova",
      "Jürgen Pfeffer"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.564": {
    "title": "Dynamic Evil Score-Guided Decoding: An Efficient Decoding Framework For Red-Team Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Gao",
      "Bo Zhang",
      "Linkang Yang",
      "Minghao Hu",
      "Zhunchen Luo",
      "Xiaoying Bai",
      "Guotong Geng",
      "Jun Zhang",
      "Yunhua Xue"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.565": {
    "title": "CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divyaksh Shukla",
      "Ritesh Baviskar",
      "Dwijesh Gohil",
      "Aniket Tiwari",
      "Atul Shree",
      "Ashutosh Modi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.566": {
    "title": "Multi-word Measures: Modeling Semantic Change in Compound Nouns",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris Jenkins",
      "Filip Miletić",
      "Sabine Schulte Im Walde"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.567": {
    "title": "Bridge-Coder: Transferring Model Capabilities from High-Resource to Low-Resource Programming Language",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jipeng Zhang",
      "Jianshu Zhang",
      "Yuanzhe Li",
      "Renjie Pi",
      "Rui Pan",
      "Runtao Liu",
      "Zheng Ziqiang",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.568": {
    "title": "ProBench: Judging Multimodal Foundation Models on Open-ended Multi-domain Expert Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Yang",
      "Dongxu Li",
      "Haoning Wu",
      "Bei Chen",
      "Liu Liu",
      "Liyuan Pan",
      "Junnan Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.569": {
    "title": "2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset Download PDF",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marta R. Costa-jussà",
      "Bokai Yu",
      "Pierre Andrews",
      "Belen Alastruey",
      "Necati Cihan Camgoz",
      "Joe Chuang",
      "Jean Maillard",
      "Christophe Ropers",
      "Arina Turkatenko",
      "Carleigh Wood"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.570": {
    "title": "LSC-Eval: A General Framework to Evaluate Methods for Assessing Dimensions of Lexical Semantic Change Using LLM-Generated Synthetic Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naomi Baes",
      "Raphael Merx",
      "Nick Haslam",
      "Ekaterina Vylomova",
      "Haim Dubossarsky"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.571": {
    "title": "Chain-of-Jailbreak Attack for Image Generation Models via Step by Step Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Kuiyi Gao",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Qiuzhi Liu",
      "Shuai Wang",
      "Wenxiang Jiao",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.572": {
    "title": "Tokenization is Sensitive to Language Variation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Wegmann",
      "Dong Nguyen",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.573": {
    "title": "WirelessMathBench: A Mathematical Modeling Benchmark for LLMs in Wireless Communications",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Li",
      "Mengbing Liu",
      "Li Wei",
      "Jiancheng An",
      "Merouane Abdelkader Debbah",
      "Chau Yuen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.574": {
    "title": "Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moxin Li",
      "Yuantao Zhang",
      "Wenjie Wang",
      "Wentao Shi",
      "Zhuo Liu",
      "Fuli Feng",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.575": {
    "title": "Investigating and Scaling up Code-Switching for Multilingual Language Model Pre-Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhijun Wang",
      "Jiahuan Li",
      "Hao Zhou",
      "Rongxiang Weng",
      "Jingang Wang",
      "Xin Huang",
      "Xue Han",
      "Junlan Feng",
      "Chao Deng",
      "Shujian Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.576": {
    "title": "User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sougata Saha",
      "Monojit Choudhury"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.577": {
    "title": "Beyond Browsing: API-Based Web Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yueqi Song",
      "Frank F. Xu",
      "Shuyan Zhou",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.578": {
    "title": "MiLiC-Eval: Benchmarking Multilingual LLMs for China's Minority Languages",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhang",
      "Mingxu Tao",
      "Zhiyuan Liao",
      "Yansong Feng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.579": {
    "title": "ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maja Stahl",
      "Timon Ziegenbein",
      "Joonsuk Park",
      "Henning Wachsmuth"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.580": {
    "title": "Crabs: Consuming Resource via Auto-generation for LLM-DoS Attack under Black-box Settings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanhe Zhang",
      "Zhenhong Zhou",
      "Wei Zhang",
      "Xinyue Wang",
      "Xiaojun Jia",
      "Yang Liu",
      "Sen Su"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.581": {
    "title": "Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenchen Yuan",
      "Zheyu Zhang",
      "Shuo Yang",
      "Bardh Prenkaj",
      "Gjergji Kasneci"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.582": {
    "title": "Unlocking Recursive Thinking of LLMs: Alignment via Refinement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoke Zhang",
      "Xiaobo Liang",
      "Cunxiang Wang",
      "Juntao Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.583": {
    "title": "CitaLaw: Enhancing LLM with Citations in Legal Domain",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kepu Zhang",
      "Weijie Yu",
      "Sunhao Dai",
      "Jun Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.584": {
    "title": "MEGen: Generative Backdoor into Large Language Models via Model Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiyang Qiu",
      "Xinbei Ma",
      "Zhuosheng Zhang",
      "Hai Zhao",
      "Yun Li",
      "Qianren Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.585": {
    "title": "Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiho Jin",
      "Woosung Kang",
      "Junho Myung",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.586": {
    "title": "Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junling Wang",
      "Anna Rutkiewicz",
      "April Wang",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.587": {
    "title": "RASPberry: Retrieval-Augmented Monte Carlo Tree Self-Play with Reasoning Consistency for Multi-Hop Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baixuan Li",
      "Yunlong Fan",
      "Tianyi Ma",
      "Miao Gao",
      "Chuanqi Shi",
      "Zhiqiang Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.588": {
    "title": "All That Glitters is Not Gold: Improving Robust Retrieval-Augmented Language Models with Fact-Centric Preference Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia Hao",
      "Chunhong Zhang",
      "Jiarun Liu",
      "Haiyu Zhao",
      "Zhiqiang Zhan",
      "Zheng Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.589": {
    "title": "FairSteer: Inference Time Debiasing for LLMs with Dynamic Activation Steering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Li",
      "Zhiting Fan",
      "Ruizhe Chen",
      "Xiaotang Gai",
      "Luqi Gong",
      "Yan Zhang",
      "Zuozhu Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.590": {
    "title": "Listen, Watch, and Learn to Feel: Retrieval-Augmented Emotion Reasoning for Compound Emotion Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuofan Wen",
      "Zheng Lian",
      "Shun Chen",
      "Hailiang Yao",
      "Longjiang Yang",
      "Bin Liu",
      "Jianhua Tao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.591": {
    "title": "GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangyang Luo",
      "Yuzhuo Bai",
      "Cheng Gao",
      "Shuzheng Si",
      "Zhu Liu",
      "Yingli Shen",
      "Zhitong Wang",
      "Cunliang Kong",
      "Wenhao Li",
      "Yufei Huang",
      "Ye Tian",
      "Xuantang Xiong",
      "Lei Han",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.592": {
    "title": "Learning to Select In-Context Demonstration Preferred by Large Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Zhang",
      "Shaocheng Lan",
      "Lei Song",
      "Jiang Bian",
      "Yexin Li",
      "Kan Ren"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.593": {
    "title": "Beyond the Spelling Miracle: Investigating Substring Awareness in Character-Blind Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cristiano Ciaccio",
      "Marta Sartor",
      "Alessio Miaschi",
      "Felice Dell’Orletta"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.594": {
    "title": "DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minzheng Wang",
      "Xinghua Zhang",
      "Kun Chen",
      "Nan Xu",
      "Haiyang Yu",
      "Fei Huang",
      "Wenji Mao",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.595": {
    "title": "InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Cao",
      "Deng Cai",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.596": {
    "title": "M3HG: Multimodal, Multi-scale, and Multi-type Node Heterogeneous Graph for Emotion Cause Triplet Extraction in Conversations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiao Liang",
      "Ying Shen",
      "Tiantian Chen",
      "Lin Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.597": {
    "title": "Large Language Models Are Natural Video Popularity Predictors",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratik Kayal",
      "Pascal Mettes",
      "Nima Dehmamy",
      "Minsu Park"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.598": {
    "title": "DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Wang",
      "Fenghua Weng",
      "Sibei Yang",
      "Zhan Qin",
      "Minlie Huang",
      "Wenjie Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.599": {
    "title": "You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with Multi-Agent Conversations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Frederic Kirstein",
      "Muneeb Khan",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.600": {
    "title": "Code-Switching and Syntax: A Large-Scale Experiment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Igor Sterner",
      "Simone Teufel"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.601": {
    "title": "Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weize Chen",
      "Jiarui Yuan",
      "Chen Qian",
      "Cheng Yang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.602": {
    "title": "Generating Domain-Specific Knowledge Graphs from Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marinela Parović",
      "Ze Li",
      "Jinhua Du"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.603": {
    "title": "Large Language Models are Miscalibrated In-Context Learners",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengzu Li",
      "Han Zhou",
      "Goran Glavaš",
      "Anna Korhonen",
      "Ivan Vulić"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.604": {
    "title": "STeCa: Step-level Trajectory Calibration for LLM Agent Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanlin Wang",
      "Jian Wang",
      "Chak Tou Leong",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.605": {
    "title": "LEMMA: Learning from Errors for MatheMatical Advancement in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoshi Pan",
      "Yu Li",
      "Honglin Lin",
      "Qizhi Pei",
      "Zinan Tang",
      "Wei Wu",
      "Chenlin Ming",
      "H. Vicky Zhao",
      "Conghui He",
      "Lijun Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.606": {
    "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lars Benedikt Kaesberg",
      "Jonas Becker",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.607": {
    "title": "Rhetorical Device-Aware Sarcasm Detection with Counterfactual Data Augmentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingqing Hong",
      "Dongyu Zhang",
      "Jiayi Lin",
      "Dapeng Yin",
      "Shuyue Zhu",
      "Junli Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.608": {
    "title": "Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianfei Zhang",
      "Bei Li",
      "Jun Bai",
      "Rumei Li",
      "Yanmeng Wang",
      "Chenghua Lin",
      "Wenge Rong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.609": {
    "title": "Cheap Character Noise for OCR-Robust Multilingual Embeddings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrianos Michail",
      "Juri Opitz",
      "Yining Wang",
      "Robin Meister",
      "Rico Sennrich",
      "Simon Clematide"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.610": {
    "title": "Physics: Benchmarking Foundation Models on University-Level Physics Problem Solving",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyue Feng",
      "Yilun Zhao",
      "Yixin Liu",
      "Tianyu Yang",
      "Chen Zhao",
      "John Sous",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.611": {
    "title": "DOVE: A Large-Scale Multi-Dimensional Predictions Dataset Towards Meaningful LLM Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eliya Habba",
      "Ofir Arviv",
      "Itay Itzhak",
      "Yotam Perlitz",
      "Elron Bandel",
      "Leshem Choshen",
      "Michal Shmueli-Scheuer",
      "Gabriel Stanovsky"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.612": {
    "title": "ALPS: Attention Localization and Pruning Strategy for Efficient Adaptation of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Chen",
      "Haoze Li",
      "Zhiqing Xiao",
      "Lirong Gao",
      "Qi Zhang",
      "Xiaomeng Hu",
      "Ningtao Wang",
      "Xing Fu",
      "Junbo Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.613": {
    "title": "DeTAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Li",
      "Han Jiang",
      "Zhihua Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.614": {
    "title": "A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Yan",
      "Jiamin Su",
      "Jianxiang He",
      "Fangteng Fu",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Kun Wang",
      "Shen Wang",
      "Qingsong Wen",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.615": {
    "title": "Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrei Catalin Coman",
      "Christos Theodoropoulos",
      "Marie-Francine Moens",
      "James Henderson"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.616": {
    "title": "NeoQA: Evidence-based Question Answering with Generated News Events",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Max Glockner",
      "Xiang Jiang",
      "Leonardo F. R. Ribeiro",
      "Iryna Gurevych",
      "Markus Dreyer"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.617": {
    "title": "ChatMap: Mining Human Thought Processes for Customer Service Chatbots via Multi-Agent Collaboration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyi Jiang",
      "Tianyi Hu",
      "Yuheng Qin",
      "Guoming Wang",
      "Zhou Huan",
      "Kehan Chen",
      "Gang Huang",
      "Rongxing Lu",
      "Siliang Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.618": {
    "title": "P3: Prompts Promote Prompting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhang",
      "Yuanquan Hu",
      "Fangchao Liu",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.619": {
    "title": "VAQUUM: Are Vague Quantifiers Grounded in Visual Data?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hugh Mee Wong",
      "Rick Nouwen",
      "Albert Gatt"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.620": {
    "title": "Forgotten Polygons: Multimodal Large Language Models are Shape-Blind",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Rudman",
      "Michal Golovanevsky",
      "Amir Bar",
      "Vedant Palit",
      "Yann LeCun",
      "Carsten Eickhoff",
      "Ritambhara Singh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.621": {
    "title": "MindBridge: Scalable and Cross-Model Knowledge Editing via Memory-Augmented Modality",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuaike Li",
      "Kai Zhang",
      "Qi Liu",
      "Enhong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.622": {
    "title": "FIHA: Automated Fine-grained Hallucinations Evaluations in Large Vision Language Models with Davidson Scene Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Yan",
      "Zhengsong Zhang",
      "Liqiang Jing",
      "Eftekhar Hossain",
      "Xinya Du"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.623": {
    "title": "On the Role of Semantic Proto-roles in Semantic Analysis: What do LLMs know about agency?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elizabeth Spaulding",
      "Shafiuddin Rehan Ahmed",
      "James Martin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.624": {
    "title": "GeAR: Graph-enhanced Agent for Retrieval-augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhili Shen",
      "Chenxin Diao",
      "Pavlos Vougiouklis",
      "Pascual Merita",
      "Shriram Piramanayagam",
      "Enting Chen",
      "Damien Graux",
      "Andre Melo",
      "Ruofei Lai",
      "Zeren Jiang",
      "Zhongyang Li",
      "Ye Qi",
      "Yang Ren",
      "Dandan Tu",
      "Jeff Z. Pan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.625": {
    "title": "WebNLG-IT: Construction of an aligned RDF-Italian corpus through Machine Translation techniques",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Oliverio",
      "Pier Felice Balestrucci",
      "Alessandro Mazzei",
      "Valerio Basile"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.626": {
    "title": "Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanyin Wang",
      "Chufan Gao",
      "Bolun Liu",
      "Qiping Xu",
      "Guleid Hussein",
      "Mohamad El Labban",
      "Kingsley Iheasirim",
      "Hariprasad Reddy Korsapati",
      "Chuck Outcalt",
      "Jimeng Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.627": {
    "title": "Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Bouri",
      "Adnane Saoud"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.628": {
    "title": "Neuro-Symbolic Query Compiler",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyao Zhang",
      "Zhicheng Dou",
      "Xiaoxi Li",
      "Jiajie Jin",
      "Yongkang Wu",
      "Zhonghua Li",
      "Ye Qi",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.629": {
    "title": "Revealing and Mitigating the Local Pattern Shortcuts of Mamba",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "WangJie You",
      "Zecheng Tang",
      "Juntao Li",
      "Lili Yao",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.630": {
    "title": "Forget the Token and Pixel: Rethinking Gradient Ascent for Concept Unlearning in Multimodal Generative Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Li",
      "Chuanyi Zhang",
      "Miaozeng Du",
      "Hui Zhang",
      "Yongrui Chen",
      "Qianshan Wei",
      "Junfeng Fang",
      "Ruipeng Wang",
      "Sheng Bi",
      "Guilin Qi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.631": {
    "title": "Slamming: Training a Speech Language Model on One GPU in a Day",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gallil Maimon",
      "Avishai Elmakies",
      "Yossi Adi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.632": {
    "title": "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhong Wu",
      "Yang Zhao",
      "Yangyifan Xu",
      "Bing Liu",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.633": {
    "title": "Clarifying Underspecified Discourse Relations in Instructional Texts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Berfin Aktas",
      "Michael Roth"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.634": {
    "title": "WMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Deutsch",
      "Eleftheria Briakou",
      "Isaac Rayburn Caswell",
      "Mara Finkelstein",
      "Rebecca Galor",
      "Juraj Juraska",
      "Geza Kovacs",
      "Alison Lui",
      "Ricardo Rei",
      "Jason Riesa",
      "Shruti Rijhwani",
      "Parker Riley",
      "Elizabeth Salesky",
      "Firas Trabelsi",
      "Stephanie Winkler",
      "Biao Zhang",
      "Markus Freitag"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.635": {
    "title": "Exploring Graph Representations of Logical Forms for Language Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Sullivan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.636": {
    "title": "SEA-HELM: Southeast Asian Holistic Evaluation of Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yosephine Susanto",
      "Adithya Venkatadri Hulagadri",
      "Jann Railey Montalan",
      "Jian Gang Ngui",
      "Xianbin Yong",
      "Wei Qi Leong",
      "Hamsawardhini Rengarajan",
      "Peerat Limkonchotiwat",
      "Yifan Mai",
      "William Chandra Tjhi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.637": {
    "title": "TRANS-ZERO: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zou",
      "Sen Yang",
      "Yu Bao",
      "Shujian Huang",
      "Jiajun Chen",
      "Shanbo Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.638": {
    "title": "A Conformal Risk Control Framework for Granular Word Assessment and Uncertainty Calibration of CLIPScore Quality Estimates",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Goncalo Emanuel Cavaco Gomes",
      "Bruno Martins",
      "Chrysoula Zerva"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.639": {
    "title": "SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqiao Zhu",
      "Ji Liu",
      "Lulu Wang",
      "Jun Wu",
      "Yulun Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.640": {
    "title": "Socratic Style Chain-of-Thoughts Help LLMs to be a Better Reasoner",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangbo Pei",
      "Peiyu Liu",
      "Xin Zhao",
      "Aidong Men",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.641": {
    "title": "Quantile Regression with Large Language Models for Price Prediction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikhita Vedula",
      "Dushyanta Dhyani",
      "Laleh Jalali",
      "Boris N. Oreshkin",
      "Mohsen Bayati",
      "Shervin Malmasi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.642": {
    "title": "Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Wang",
      "Yinpei Dai",
      "Yichi Zhang",
      "Ziqiao Ma",
      "Wenjie Li",
      "Joyce Chai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.643": {
    "title": "AIGuard: A Benchmark and Lightweight Detection for E-commerce AIGC Risks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhua Zhang",
      "Weicheng Li",
      "Xuanrong Rao",
      "Lixin Zou",
      "Xiangyang Luo",
      "Chubin Zhuang",
      "Yongjie Hong",
      "Zhen Qin",
      "Hengyu Chang",
      "Chenliang Li",
      "Bo Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.644": {
    "title": "A2ATS: Retrieval-Based KV Cache Reduction via Windowed Rotary Position Embedding and Query-Aware Vector Quantization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhui He",
      "Junna Xing",
      "Nan Wang",
      "Rui Xu",
      "Shangyu Wu",
      "Peng Zhou",
      "Qiang Liu",
      "Chun Jason Xue",
      "Qingan Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.645": {
    "title": "TransBench: Breaking Barriers for Transferable Graphical User Interface Agents in Dynamic Digital Environments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuheng Lu",
      "Qian Yu",
      "Hongru Wang",
      "Zeming Liu",
      "Wei Su",
      "Yanping Liu",
      "Yuhang Guo",
      "Maocheng Liang",
      "Yunhong Wang",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.646": {
    "title": "Order Matters: Investigate the Position Bias in Multi-constraint Instruction Following",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Zeng",
      "Qianyu He",
      "Qingyu Ren",
      "Jiaqing Liang",
      "Weikang Zhou",
      "Zeye Sun",
      "Fei Yu",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.647": {
    "title": "CoT-VTM: Visual-to-Music Generation with Chain-of-Thought Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xikang Guan",
      "Zheng Gu",
      "Jing Huo",
      "Tianyu Ding",
      "Yang Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.648": {
    "title": "A Tale of Evaluating Factual Consistency: Case Study on Long Document Summarization Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhong",
      "Diane Litman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.649": {
    "title": "Evaluating Pretrained Causal Language Models for Synonymy",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ioana Ivan",
      "Carlos Ramisch",
      "Alexis Nasr"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.650": {
    "title": "MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohan Jin",
      "Shuhan Qi",
      "Kehai Chen",
      "Xinyi Guo",
      "Xuan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.651": {
    "title": "CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochen Zhang",
      "Tianyi Zhang",
      "Junze Yin",
      "Oren Gal",
      "Anshumali Shrivastava",
      "Vladimir Braverman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.652": {
    "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liu Huanshuo",
      "Hao Zhang",
      "Zhijiang Guo",
      "Jing Wang",
      "Kuicai Dong",
      "Xiangyang Li",
      "Yi Quan Lee",
      "Cong Zhang",
      "Yong Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.653": {
    "title": "Maximum Score Routing For Mixture-of-Experts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Dong",
      "Yilong Fan",
      "Yutao Sun",
      "Zhenyu Li",
      "Tengyu Pan",
      "Zhou Xun",
      "Jianyong Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.654": {
    "title": "Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Dawar Hakimi",
      "Ali Modarressi",
      "Philipp Wicke",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.655": {
    "title": "Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feifan Song",
      "Shaohang Wei",
      "Wen Luo",
      "Yuxuan Fan",
      "Tianyu Liu",
      "Guoyin Wang",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.656": {
    "title": "Disentangling Text and Math in Word Problems: Evidence for the Bidimensional Structure of Large Language Models' Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pedro Calais",
      "Gabriel Franco",
      "Zilu Tang",
      "Themistoklis Nikas",
      "Wagner Meira Jr.",
      "Evimaria Terzi",
      "Mark Crovella"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.657": {
    "title": "Human-LLM Coevolution: Evidence from Academic Writing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingmeng Geng",
      "Roberto Trotta"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.658": {
    "title": "Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Dong",
      "Ziyue Qiao",
      "Zhiyuan Ning",
      "Qi Hao",
      "Yi Du",
      "Pengyang Wang",
      "Yuanchun Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.659": {
    "title": "GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cristian-George Craciun",
      "Răzvan-Alexandru Smădu",
      "Dumitru-Clementin Cercel",
      "Mihaela-Claudia Cercel"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.660": {
    "title": "Express What You See: Can Multimodal LLMs Decode Visual Ciphers with Intuitive Semiosis Comprehension?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Kuang",
      "Yinghui Li",
      "Chen Wang",
      "Haohao Luo",
      "Ying Shen",
      "Wenhao Jiang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.661": {
    "title": "ConFit v2: Improving Resume-Job Matching using Hypothetical Resume Embedding and Runner-Up Hard-Negative Mining",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Yu",
      "Ruize Xu",
      "Chengyuan Xue",
      "Jinzhong Zhang",
      "Xu Ma",
      "Zhou Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.662": {
    "title": "Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anum Afzal",
      "Florian Matthes",
      "Gal Chechik",
      "Yftah Ziser"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.663": {
    "title": "Grounding Task Assistance with Multimodal Cues from a Single Demonstration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriel Herbert Sarch",
      "Balasaravanan Thoravi Kumaravel",
      "Sahithya Ravi",
      "Vibhav Vineet",
      "Andrew D Wilson"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.664": {
    "title": "Awes, Laws, and Flaws From Today's LLM Research",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrian de Wynter"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.665": {
    "title": "Dual Debiasing for Noisy In-Context Learning for Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Liang",
      "Sumyeong Ahn",
      "Paramveer Dhillon",
      "Jiayu Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.666": {
    "title": "DRS: Deep Question Reformulation With Structured Output",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhecheng Li",
      "Yiwei Wang",
      "Bryan Hooi",
      "Yujun Cai",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.667": {
    "title": "Towards Explainable Hate Speech Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Happy Khairunnisa Sariyanto",
      "Diclehan Ulucan",
      "Oguzhan Ulucan",
      "Marc Ebner"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.668": {
    "title": "BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunsoo Kim",
      "Yusuf Abdulle",
      "Honghan Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.669": {
    "title": "PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bradley McDanel",
      "Sai Qian Zhang",
      "Yunhai Hu",
      "Zining Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.670": {
    "title": "LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thai Quoc Hoang",
      "Kung-Hsiang Huang",
      "Shirley Kokane",
      "Jianguo Zhang",
      "Zuxin Liu",
      "Ming Zhu",
      "Jake Grigsby",
      "Tian Lan",
      "Michael S Ryoo",
      "Chien-Sheng Wu",
      "Shelby Heinecke",
      "Huan Wang",
      "Silvio Savarese",
      "Caiming Xiong",
      "Juan Carlos Niebles"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.671": {
    "title": "Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sahil Mishra",
      "Kumar Arjun",
      "Tanmoy Chakraborty"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.672": {
    "title": "Probing Subphonemes in Morphology Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gal Astrach",
      "Yuval Pinter"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.673": {
    "title": "Exploiting Instruction-Following Retrievers for Malicious Information Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parishad BehnamGhader",
      "Nicholas Meade",
      "Siva Reddy"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.674": {
    "title": "Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alicja Dobrzeniecka",
      "Antske Fokkens",
      "Pia Sommerauer"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.675": {
    "title": "The Threat of PROMPTS in Large Language Models: A System and User Prompt Perspective",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Xia",
      "Haifeng Sun",
      "Jingyu Wang",
      "Qi Qi",
      "Huazheng Wang",
      "Xiaoyuan Fu",
      "Jianxin Liao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.676": {
    "title": "RoseRAG: Robust Retrieval-augmented Generation with Small-scale LLMs via Margin-aware Preference Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianci Liu",
      "Haoxiang Jiang",
      "Tianze Wang",
      "Ran Xu",
      "Yue Yu",
      "Linjun Zhang",
      "Tuo Zhao",
      "Haoyu Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.677": {
    "title": "Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saurabh Srivastava",
      "Sweta Pati",
      "Ziyu Yao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.678": {
    "title": "mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hellina Hailu Nigatu",
      "Min Li",
      "Maartje Ter Hoeve",
      "Saloni Potdar",
      "Sarah Chasins"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.679": {
    "title": "Mechanistic Interpretability of Emotion Inference in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ala N. Tak",
      "Amin Banayeeanzade",
      "Anahita Bolourani",
      "Mina Kian",
      "Robin Jia",
      "Jonathan Gratch"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.680": {
    "title": "RL-Guider: Leveraging Historical Decisions and Feedback for Drug Editing with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xufeng Liu",
      "Yixuan Ding",
      "Jingxiang Qu",
      "Yichi Zhang",
      "Wenhan Gao",
      "Yi Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.681": {
    "title": "BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jesse Woo",
      "Fateme Hashemi Chaleshtori",
      "Ana Marasovic",
      "Kenneth Marino"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.682": {
    "title": "I see what you mean: Co-Speech Gestures for Reference Resolution in Multimodal Dialogue",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Esam Ghaleb",
      "Bulat Khaertdinov",
      "Asli Ozyurek",
      "Raquel Fernández"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.683": {
    "title": "World Knowledge Resolves Some Aspectual Ambiguity",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katarzyna Pruś",
      "Mark Steedman",
      "Adam Lopez"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.684": {
    "title": "ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dren Fazlija",
      "Arkadij Orlov",
      "Sandipan Sikdar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.685": {
    "title": "Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi-Jane Chen",
      "Yuhang Chen",
      "Sukwon Yun",
      "Natalie Stanley",
      "Tianlong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.686": {
    "title": "HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation Task",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaojian Yu",
      "Yilun Zhao",
      "Arman Cohan",
      "Xiao-Ping Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.687": {
    "title": "TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhang",
      "Wenxiang Guo",
      "Changhao Pan",
      "Dongyu Yao",
      "Zhiyuan Zhu",
      "Ziyue Jiang",
      "Yuhan Wang",
      "Tao Jin",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.688": {
    "title": "Compute Optimal Scaling of Skills: Knowledge vs Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicholas Roberts",
      "Niladri S. Chatterji",
      "Sharan Narang",
      "Mike Lewis",
      "Dieuwke Hupkes"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.689": {
    "title": "PECAN: LLM-Guided Dynamic Progress Control with Attention-Guided Hierarchical Weighted Graph for Long-Document QA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Wang",
      "Yanzheng Xiang",
      "Lin Gui",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.690": {
    "title": "Lifelong Model Editing with Graph-Based External Memory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash Kumar Atri",
      "Ahmed Alaa",
      "Thomas Hartvigsen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.691": {
    "title": "Multi-Sense Embeddings for Language Models and Knowledge Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qitong Wang",
      "Mohammed J Zaki",
      "Georgios Kollias",
      "Vasileios Kalantzis"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.692": {
    "title": "CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Jansen",
      "Oyvind Tafjord",
      "Marissa Radensky",
      "Pao Siangliulue",
      "Tom Hope",
      "Bhavana Dalvi Mishra",
      "Bodhisattwa Prasad Majumder",
      "Daniel S Weld",
      "Peter Clark"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.693": {
    "title": "Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris Samarinas",
      "Alexander Krubner",
      "Alireza Salemi",
      "Youngwoo Kim",
      "Hamed Zamani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.694": {
    "title": "Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob Nielsen",
      "Peter Schneider-Kamp",
      "Lukas Galke"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.695": {
    "title": "When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hillary Dawkins",
      "Kathleen C. Fraser",
      "Svetlana Kiritchenko"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.696": {
    "title": "Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James A. Michaelov",
      "Reeka Estacio",
      "Zhien Zhang",
      "Ben Bergen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.697": {
    "title": "The Rotary Position Embedding May Cause Dimension Inefficiency in Attention Heads for Long-Distance Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting-Rui Chiang",
      "Dani Yogatama"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.698": {
    "title": "IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent through Induction, Deduction, and Abduction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyu He",
      "Mian Zhang",
      "Shuo Yan",
      "Peilin Wu",
      "Zhiyu Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.699": {
    "title": "EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with Neural Knowledge Base of Entity States",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hainiu Xu",
      "Siya Qi",
      "Jiazheng Li",
      "Yuxiang Zhou",
      "Jinhua Du",
      "Caroline Catmur",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.700": {
    "title": "ReasonerRank: Redefining Language Model Evaluation with Ground-Truth-Free Ranking Frameworks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiamu Zhang",
      "Jiayi Yuan",
      "Andrew Wen",
      "Hoang Anh Duy Le",
      "Yu-Neng Chuang",
      "Soo-Hyun Choi",
      "Rui Chen",
      "Xia Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.701": {
    "title": "HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weizhi Tang",
      "Yixuan Li",
      "Chris Sypherd",
      "Elizabeth Polgreen",
      "Vaishak Belle"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.702": {
    "title": "Can Large Language Models Understand Argument Schemes?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elfia Bezou-Vrakatseli",
      "Oana Cocarascu",
      "Sanjay Modgil"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.703": {
    "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shulin Tian",
      "Ziniu Zhang",
      "Liangyu Chen",
      "Ziwei Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.704": {
    "title": "ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofei Wen",
      "Wenxuan Zhou",
      "Wenjie Jacky Mo",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.705": {
    "title": "Neutralizing Bias in LLM Reasoning using Entailment Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Cheng",
      "Tianyi Li",
      "Zhaowei Wang",
      "Tianyang Liu",
      "Mark Steedman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.706": {
    "title": "Dynamic Steering With Episodic Memory For Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Van Dai Do",
      "Quan Hung Tran",
      "Svetha Venkatesh",
      "Hung Le"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.707": {
    "title": "Eeyore: Realistic Depression Simulation via Expert-in-the-Loop Supervised and Preference Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyang Liu",
      "Bianca Brie",
      "Wenda Li",
      "Laura Biester",
      "Andrew Lee",
      "James Pennebaker",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.708": {
    "title": "Lost in Translation: Benchmarking Commercial Machine Translation Models for Dyslexic-Style Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gregory Price",
      "Shaomei Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.709": {
    "title": "Divide-Verify-Refine: Can LLMs Self-align with Complex Instructions?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianren Zhang",
      "Xianfeng Tang",
      "Hui Liu",
      "Zongyu Wu",
      "Qi He",
      "Dongwon Lee",
      "Suhang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.710": {
    "title": "LlamaPIE: Proactive In-Ear Conversation Assistants",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuochao Chen",
      "Nicholas Scott Batchelder",
      "Alisa Liu",
      "Noah A. Smith",
      "Shyamnath Gollakota"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.711": {
    "title": "Task-Oriented Automatic Fact-Checking with Frame-Semantics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob Devasier",
      "Akshith Reddy Putta",
      "Rishabh Mediratta",
      "Chengkai Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.712": {
    "title": "Craw4LLM: Efficient Web Crawling for LLM Pretraining",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shi Yu",
      "Zhiyuan Liu",
      "Chenyan Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.713": {
    "title": "Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guo Zhenyuan",
      "Yi Shi",
      "Wenlong Meng",
      "Chen Gong",
      "Chengkun Wei",
      "Wenzhi Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.714": {
    "title": "Understand User Opinions of Large Language Models via LLM-Powered In-the-Moment User Experience Interviews",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengqiao Liu",
      "Tevin Wang",
      "Cassandra A. Cohen",
      "Sarah Li",
      "Chenyan Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.715": {
    "title": "HiCOT: Improving Neural Topic Models via Optimal Transport and Contrastive Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoang Tran Vuong",
      "Tue Le",
      "Tu Vu",
      "Tung Nguyen",
      "Linh Ngo Van",
      "Sang Dinh",
      "Thien Huu Nguyen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.716": {
    "title": "FLAG-TRADER: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guojun Xiong",
      "Zhiyang Deng",
      "Keyi Wang",
      "Yupeng Cao",
      "Haohang Li",
      "Yangyang Yu",
      "Xueqing Peng",
      "Mingquan Lin",
      "Kaleb E Smith",
      "Xiao-Yang Liu",
      "Jimin Huang",
      "Sophia Ananiadou",
      "Qianqian Xie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.717": {
    "title": "The Silent Saboteur: Imperceptible Adversarial Attacks against Black-Box Retrieval-Augmented Generation Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongru Song",
      "Yu-An Liu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Jianming Lv",
      "Maarten de Rijke",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.718": {
    "title": "CROSSAGENTIE: Cross-Type and Cross-Task Multi-Agent LLM Collaboration for Zero-Shot Information Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Lu",
      "Yuzhang Xie",
      "Zhenyu Bi",
      "Shuxiang Cao",
      "Xuan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.719": {
    "title": "Decoupling Memories, Muting Neurons: Towards Practical Machine Unlearning for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lishuai Hou",
      "Zixiong Wang",
      "Gaoyang Liu",
      "Chen Wang",
      "Wei Liu",
      "Kai Peng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.720": {
    "title": "Assimilation and Accommodation: Task-Adaptive Hierarchical Abstraction for Solving Web Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Pang",
      "Ruixin Hong",
      "Hongming Zhang",
      "Changshui Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.721": {
    "title": "SafeLawBench: Towards Safe Alignment of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuxue Cao",
      "Han Zhu",
      "Jiaming Ji",
      "Qichao Sun",
      "Zhenghao Zhu",
      "Wu Yinyu",
      "Josef Dai",
      "Yaodong Yang",
      "Sirui Han",
      "Yike Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.722": {
    "title": "3DM: Distill, Dynamic Drop, and Merge for Debiasing Multi-modal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoxi Zhang",
      "Sanwoo Lee",
      "Zhixiang Wang",
      "Yunfang Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.723": {
    "title": "CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxi Sun",
      "Aoqi Zuo",
      "Wei Gao",
      "Jing Ma"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.724": {
    "title": "CapArena: Benchmarking and Analyzing Detailed Image Captioning in the LLM Era",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kanzhi Cheng",
      "Wenpo Song",
      "Jiaxin Fan",
      "Zheng Ma",
      "Qiushi Sun",
      "Fangzhi Xu",
      "Chenyang Yan",
      "Nuo Chen",
      "Jianbing Zhang",
      "Jiajun Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.725": {
    "title": "LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Ma",
      "Yiyue Qian",
      "Zehong Wang",
      "Zheyuan Zhang",
      "Chuxu Zhang",
      "Yanfang Ye"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.726": {
    "title": "CoLA: Collaborative Low-Rank Adaptation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyun Zhou",
      "Chang Yao",
      "Jingyuan Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.727": {
    "title": "GLiM: Integrating Graph Transformer and LLM for Document-Level Biomedical Relation Extraction with Incomplete Labeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Fang",
      "Yuejie Zhang",
      "Rui Feng",
      "Yingwen Wang",
      "Qing Wang",
      "Wen He",
      "Xiaobo Zhang",
      "Tao Zhang",
      "Shang Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.728": {
    "title": "AnalyticKWS: Towards Exemplar-Free Analytic Class Incremental Learning for Small-footprint Keyword Spotting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Xiao",
      "Peng Tianyi",
      "Rohan Kumar Das",
      "Yuchen Hu",
      "Huiping Zhuang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.729": {
    "title": "Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taedong Yun",
      "Eric Yang",
      "Mustafa Safdari",
      "Jong Ha Lee",
      "Vaishnavi Vinod Kumar",
      "S. Sara Mahdavi",
      "Jonathan Amar",
      "Derek Peyton",
      "Reut Aharony",
      "Andreas Michaelides PhD",
      "Logan Douglas Schneider",
      "Isaac Galatzer-Levy",
      "Yugang Jia",
      "John Canny",
      "Arthur Gretton",
      "Maja Mataric"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.730": {
    "title": "Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suho Yoo",
      "Hyunjong Ok",
      "Jaeho Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.731": {
    "title": "SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkai Chen",
      "Zhijie Deng",
      "Kening Zheng",
      "Yibo Yan",
      "Shuliang Liu",
      "PeiJun Wu",
      "Peijie Jiang",
      "Jia Liu",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.732": {
    "title": "Prediction-Augmented Generation for Automatic Diagnosis Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chan-Yang Ju",
      "Dong-Ho Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.733": {
    "title": "FedLEKE: Federated Locate-then-Edit Knowledge Editing for Multi-Client Collaboration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongkai Zhao",
      "Guozeng Xu",
      "Xiuhua Li",
      "Kaiwen Wei",
      "Jiang Zhong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.734": {
    "title": "DiSCo: Device-Server Collaborative LLM-based Text Streaming Services",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting Sun",
      "Penghan Wang",
      "Fan Lai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.735": {
    "title": "Customizing In-context Learning for Dynamic Interest Adaption in LLM-based Recommendation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keqin Bao",
      "Ming Yan",
      "Yang Zhang",
      "Jizhi Zhang",
      "Wenjie Wang",
      "Fuli Feng",
      "Xiangnan He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.736": {
    "title": "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyue Cui",
      "Johnny Wei",
      "Swabha Swayamdipta",
      "Robin Jia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.737": {
    "title": "LLM-Enhanced Query Generation and Retrieval Preservation for Task-Oriented Dialogue",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiale Chen",
      "Xuelian Dong",
      "Wenxiu Xie",
      "Ru Peng",
      "Kun Zeng",
      "Tianyong Hao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.738": {
    "title": "ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quang Hieu Pham",
      "Thuy Duong Nguyen",
      "Tung Pham",
      "Anh Tuan Luu",
      "Dat Quoc Nguyen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.739": {
    "title": "Low-Entropy Watermark Detection via Bayes' Rule Derived Detector",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beining Huang",
      "Du Su",
      "Fei Sun",
      "Qi Cao",
      "Huawei Shen",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.740": {
    "title": "CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junying Chen",
      "Chi Gui",
      "Anningzhe Gao",
      "Ke Ji",
      "Xidong Wang",
      "Xiang Wan",
      "Benyou Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.741": {
    "title": "DaNet: Dual-Aware Enhanced Alignment Network for Multimodal Aspect-Based Sentiment Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aoqiang Zhu",
      "Min Hu",
      "Xiaohua Wang",
      "Jiaoyun Yang",
      "Yiming Tang",
      "Ning An"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.742": {
    "title": "Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shujian Yang",
      "Shiyao Cui",
      "Chuanrui Hu",
      "Haicheng Wang",
      "Tianwei Zhang",
      "Minlie Huang",
      "Jialiang Lu",
      "Han Qiu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.743": {
    "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yile Wang",
      "Zhanyu Shen",
      "Hui Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.744": {
    "title": "Ranked Voting based Self-Consistency of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiqin Wang",
      "Yile Wang",
      "Hui Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.745": {
    "title": "SemanticCamo: Jailbreaking Large Language Models through Semantic Camouflage",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihui Yan",
      "Xiaocui Yang",
      "Daling Wang",
      "Shi Feng",
      "Yifei Zhang",
      "Yinzhi Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.746": {
    "title": "Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yoonjun Cho",
      "Soeun Kim",
      "Dongjae Jeon",
      "Kyelim Lee",
      "Beomsoo Lee",
      "Albert No"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.747": {
    "title": "Better Process Supervision with Bi-directional Rewarding Signals",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxiang Chen",
      "Wei He",
      "Zhiheng Xi",
      "Honglin Guo",
      "Boyang Hong",
      "Jiazheng Zhang",
      "Nijun Li",
      "Tao Gui",
      "Yun Li",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.748": {
    "title": "KnowCoder-X: Boosting Multilingual Information Extraction via Code",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Zuo",
      "Wenxuan Jiang",
      "Wenxuan Liu",
      "Zixuan Li",
      "Long Bai",
      "Hanbin Wang",
      "Yutao Zeng",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.749": {
    "title": "MEIT: Multimodal Electrocardiogram Instruction Tuning on Large Language Models for Report Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongwei Wan",
      "Che Liu",
      "Xin Wang",
      "Chaofan Tao",
      "Hui Shen",
      "Jing Xiong",
      "Rossella Arcucci",
      "Huaxiu Yao",
      "Mi Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.750": {
    "title": "Harnessing Large Language Models for Disaster Management: A Survey",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Lei",
      "Yushun Dong",
      "Weiyu Li",
      "Rong Ding",
      "Qi R. Wang",
      "Jundong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.751": {
    "title": "Towards Medical Complex Reasoning with LLMs through Medical Verifiable Problems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junying Chen",
      "Zhenyang Cai",
      "Ke Ji",
      "Xidong Wang",
      "Wanlong Liu",
      "Rongsheng Wang",
      "Benyou Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.752": {
    "title": "Monitoring Decoding: Mitigating Hallucination via Evaluating the Factuality of Partial Response during Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yurui Chang",
      "Bochuan Cao",
      "Lu Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.753": {
    "title": "LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bofei Gao",
      "Zefan Cai",
      "Runxin Xu",
      "Peiyi Wang",
      "Ce Zheng",
      "Runji Lin",
      "Keming Lu",
      "Dayiheng Liu",
      "Chang Zhou",
      "Wen Xiao",
      "Tianyu Liu",
      "Baobao Chang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.754": {
    "title": "EvoBench: Towards Real-world LLM-Generated Text Detection Benchmarking for Evolving Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Yu",
      "Yi Yu",
      "Dongrui Liu",
      "Kejiang Chen",
      "Weiming Zhang",
      "Nenghai Yu",
      "Jing Shao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.755": {
    "title": "MMSciBench: Benchmarking Language Models on Chinese Multimodal Scientific Problems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwu Ye",
      "Chengfan Li",
      "Siming Chen",
      "Wei Wei",
      "Robert Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.756": {
    "title": "Lightweight Query Checkpoint: Classifying Faulty User Queries to Mitigate Hallucinations in Large Language Model Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minjoo Son",
      "Jonghak Jang",
      "Misuk Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.757": {
    "title": "Exploring LLM Annotation for Adaptation of Clinical Information Extraction Models under Data-sharing Restrictions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seiji Shimizu",
      "Hisada Shohei",
      "Yutaka Uno",
      "Shuntaro Yada",
      "Shoko Wakamiya",
      "Eiji Aramaki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.758": {
    "title": "Enhancing the Comprehensibility of Text Explanations via Unsupervised Concept Discovery",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Sun",
      "Danding Wang",
      "Qiang Sheng",
      "Juan Cao",
      "Jintao Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.759": {
    "title": "RecordTwin: Towards Creating Safe Synthetic Clinical Corpora",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seiji Shimizu",
      "Ibrahim Baroud",
      "Lisa Raithel",
      "Shuntaro Yada",
      "Shoko Wakamiya",
      "Eiji Aramaki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.760": {
    "title": "Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Xiang",
      "Ansen Zhang",
      "Yanfei Cao",
      "Fan Yang",
      "Ronghao Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.761": {
    "title": "Multimodal Invariant Sentiment Representation Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aoqiang Zhu",
      "Min Hu",
      "Xiaohua Wang",
      "Jiaoyun Yang",
      "Yiming Tang",
      "Ning An"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.762": {
    "title": "ChuLo: Chunk-Level Key Information Representation for Long Document Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Li",
      "Caren Han",
      "Yue Dai",
      "Feiqi Cao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.763": {
    "title": "REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomer Ashuach",
      "Martin Tutek",
      "Yonatan Belinkov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.764": {
    "title": "Is External Information Useful for Stance Detection with LLMs?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quang Minh Nguyen",
      "Taegyoon Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.765": {
    "title": "Benchmarking Query-Conditioned Natural Language Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marc E. Canby",
      "Xinchi Chen",
      "Xing Niu",
      "Jifan Chen",
      "Bonan Min",
      "Sergul Aydore",
      "Vittorio Castelli"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.766": {
    "title": "Flowchart-Based Decision Making with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuuki Yamanaka",
      "Hiroshi Takahashi",
      "Tomoya Yamashita"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.767": {
    "title": "NarGINA: Towards Accurate and Interpretable Children's Narrative Ability Assessment via Narrative Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Zhong",
      "Longwei Xu",
      "Li Kong",
      "Xianzhuo Li",
      "Dandan Liang",
      "Junsheng Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.768": {
    "title": "Improving Efficiency in Large Language Models via Extendable Block Floating Point Representation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyang Li",
      "Zeyang Li",
      "Bosheng Liu",
      "Jigang Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.769": {
    "title": "EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxu Tao",
      "Jie Hu",
      "Mingchuan Yang",
      "Yunhuai Liu",
      "Dongyan Zhao",
      "Yansong Feng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.770": {
    "title": "NativQA: Multilingual Culturally-Aligned Natural Query for LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md. Arid Hasan",
      "Maram Hasanain",
      "Fatema Ahmad",
      "Sahinur Rahman Laskar",
      "Sunaya Upadhyay",
      "Vrunda N Sukhadia",
      "Mucahid Kutlu",
      "Shammur Absar Chowdhury",
      "Firoj Alam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.771": {
    "title": "DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinglin Lyu",
      "Wei Tang",
      "Yuang Li",
      "Xiaofeng Zhao",
      "Ming Zhu",
      "Junhui Li",
      "Yunfei Lu",
      "Min Zhang",
      "Daimeng Wei",
      "Hao Yang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.772": {
    "title": "RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bolei He",
      "Xinran He",
      "Mengke Chen",
      "Xianwei Xue",
      "Ying Zhu",
      "Zhen-Hua Ling"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.773": {
    "title": "VADE: Visual Attention Guided Hallucination Detection and Elimination",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishnu Prabhakaran",
      "Purav Aggarwal",
      "Vinay Kumar Verma",
      "Gokul Swamy",
      "Anoop Saladi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.774": {
    "title": "PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zouying Cao",
      "Runze Wang",
      "Yifei Yang",
      "Xinbei Ma",
      "Xiaoyong Zhu",
      "Bo Zheng",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.775": {
    "title": "The Effectiveness of Uncased Tokeniziaion for Clinical Notes",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cory Paik",
      "Katharina Von Der Wense"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.776": {
    "title": "AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Janghwan Lee",
      "Jiwoong Park",
      "Jinseok Kim",
      "Yongjik Kim",
      "Jungju Oh",
      "Jinwook Oh",
      "Jungwook Choi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.777": {
    "title": "Improving Continual Pre-training Through Seamless Data Packing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruicheng Yin",
      "Xuan Gao",
      "Changze Lv",
      "Xiaohua Wang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.778": {
    "title": "The Impact of Name Age Perception on Job Recommendations in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mahammed Kamruzzaman",
      "Gene Louis Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.779": {
    "title": "DAPI: Domain Adaptive Toxicity Probe Vector Intervention, for Fine-Grained Detoxification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cho Hyeonsu",
      "Dooyoung Kim",
      "Youngjoong Ko"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.780": {
    "title": "Task Knowledge Injection via Interpolations and Reinstatement for Large Language Model Generalization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukun Zhao",
      "Lingyong Yan",
      "Zhenyang Li",
      "Shuaiqiang Wang",
      "Zhumin Chen",
      "Zhaochun Ren",
      "Dawei Yin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.781": {
    "title": "STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxiang Guo",
      "Yu Zhang",
      "Changhao Pan",
      "Zhiyuan Zhu",
      "Ruiqi Li",
      "ZheTao Chen",
      "Wenhao Xu",
      "Fei Wu",
      "Zhou Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.782": {
    "title": "Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinghao Chen",
      "Zhijing Sun",
      "Guo Wenjin",
      "Miaoran Zhang",
      "Yanjun Chen",
      "Yirong Sun",
      "Hui Su",
      "Yijie Pan",
      "Dietrich Klakow",
      "Wenjie Li",
      "Xiaoyu Shen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.783": {
    "title": "INT: Establishing Information Transfer for Multilingual Intent Detection and Slot Filling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Wu",
      "Liting Jiang",
      "Bohui Mao",
      "Hongyan Xie",
      "Haoxiang Su",
      "Zhongjiang He",
      "Ruiyu Fang",
      "Shuangyong Song",
      "Hao Huang",
      "Xuelong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.784": {
    "title": "Enhancing LLM Agent Safety via Causal Influence Prompting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyoon Hahm",
      "Woogyeol Jin",
      "June Suk Choi",
      "Sungsoo Ahn",
      "Kimin Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.785": {
    "title": "Position Paper: MeMo: Towards Language Models with Associative Memory Mechanisms",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fabio Massimo Zanzotto",
      "Elena Sofia Ruzzetti",
      "Giancarlo A. Xompero",
      "Leonardo Ranaldi",
      "Davide Venditti",
      "Federico Ranaldi",
      "Cristina Giannone",
      "Andrea Favalli",
      "Raniero Romagnoli"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.786": {
    "title": "DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Solee Im",
      "Wonjun Lee",
      "JinMyeong An",
      "Yunsu Kim",
      "Jungseul Ok",
      "Gary Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.787": {
    "title": "Rehearse With User: Personalized Opinion Summarization via Role-Playing based on Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanyue Zhang",
      "Yulan He",
      "Deyu Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.788": {
    "title": "AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soichiro Murakami",
      "Peinan Zhang",
      "Hidetaka Kamigaito",
      "Hiroya Takamura",
      "Manabu Okumura"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.789": {
    "title": "Beyond the Average Reader: the Reader Embedding Approach",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Calogero Jerik Scozzaro",
      "Matteo Delsanto",
      "Daniele P. Radicioni"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.790": {
    "title": "PredictaBoard: Benchmarking LLM Score Predictability",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Pacchiardi",
      "Konstantinos Voudouris",
      "Ben Slater",
      "Fernando Martínez-Plumed",
      "Jose Hernandez-Orallo",
      "Lexin Zhou",
      "Wout Schellaert"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.791": {
    "title": "FedDQC: Data Quality Control in Federated Instruction-tuning of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxin Du",
      "Rui Ye",
      "Fengting Yuchi",
      "Wanru Zhao",
      "Jingjing Qu",
      "Yanfeng Wang",
      "Siheng Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.792": {
    "title": "Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Yuan",
      "Yulin Chen",
      "Yin Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.793": {
    "title": "I understand your perspective\": LLM Persuasion through the Lens of Communicative Action Theory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Esra Dönmez",
      "Agnieszka Falenska"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.794": {
    "title": "Nunchi-Bench: Benchmarking Language Models on Cultural Reasoning with a Focus on Korean Superstition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyuhee Kim",
      "Sangah Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.795": {
    "title": "Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangyang Luo",
      "Zichen Ding",
      "Zhenmin Weng",
      "Lingfeng Qiao",
      "Meng Zhao",
      "Xiang Li",
      "Di Yin",
      "Jinlong Shu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.796": {
    "title": "daDPO: Distribution-Aware DPO for Distilling Conversational Abilities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengze Zhang",
      "Shiqi Wang",
      "Yiqun Shen",
      "Simin Guo",
      "Dahua Lin",
      "Xiaoliang Wang",
      "Nguyen Cam-Tu",
      "Fei Tan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.797": {
    "title": "Consultant Decoding: Yet Another Synergistic Mechanism",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanghao Ding",
      "Jiaping Wang",
      "Ziqing Yang",
      "Xiaoliang Wang",
      "Dahua Lin",
      "Nguyen Cam-Tu",
      "Fei Tan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.798": {
    "title": "IntelliCockpitBench: A Comprehensive Benchmark to Evaluate VLMs for Intelligent Cockpit",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Lin",
      "Siyuan Chai",
      "Jiahao Wu",
      "Hongbing Hu",
      "Xiaotao Gu",
      "Hao Hu",
      "Fan Zhang",
      "Wei Wang",
      "Dan Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.799": {
    "title": "Analyzing Political Bias in LLMs via Target-Oriented Sentiment Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akram Elbouanani",
      "Evan Dufraisse",
      "Adrian Popescu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.800": {
    "title": "PISCO: Pretty Simple Compression for Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxime Louis",
      "Hervé Déjean",
      "Stéphane Clinchant"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.801": {
    "title": "AnchorCoT: Anchors Pave the Way for Multi-hop Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshi Ming",
      "Xian Wu",
      "Yingying Zhang",
      "Zichuan Fu",
      "Dawei Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.802": {
    "title": "Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichen Wen",
      "Yifeng Gao",
      "Weijia Li",
      "Conghui He",
      "Linfeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.803": {
    "title": "Federated Data-Efficient Instruction Tuning for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Qin",
      "Zhaomin Wu",
      "Bingsheng He",
      "Shuiguang Deng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.804": {
    "title": "They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walter Paci",
      "Alessandro Panunzi",
      "Sandro Pezzelle"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.805": {
    "title": "ZeroNER: Fueling Zero-Shot Named Entity Recognition via Entity Type Descriptions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessio Cocchieri",
      "Marcos Martínez Galindo",
      "Giacomo Frisoni",
      "Gianluca Moro",
      "Claudio Sartori",
      "Giuseppe Tagliavini"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.806": {
    "title": "Do Large Language Models Have \"Emotion Neurons\"? Investigating the Existence and Role",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewook Lee",
      "Woojin Lee",
      "Oh-Woog Kwon",
      "Harksoo Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.807": {
    "title": "Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyuan Liang",
      "Zhao Zhang",
      "Zeyu Sun",
      "Zheng Lin",
      "Qi Luo",
      "Xiao Yueyi",
      "Yizhou Chen",
      "Yuqun Zhang",
      "Haotian Zhang",
      "Lu Zhang",
      "Chenbin Chenbin",
      "Yingfei Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.808": {
    "title": "Investigating Inference-time Scaling for Chain of Multi-modal Thought: A Preliminary Study",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Lin",
      "Ante Wang",
      "Moye Chen",
      "Jingyao Liu",
      "Hao Liu",
      "Jinsong Su",
      "Xinyan Xiao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.809": {
    "title": "UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyi Liu",
      "Xiaoyi Zhang",
      "Ziyun Zhang",
      "Yan Lu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.810": {
    "title": "A Study into Investigating Temporal Robustness of LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Wallat",
      "Abdelrahman Abdallah",
      "Adam Jatowt",
      "Avishek Anand"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.811": {
    "title": "ToolExpNet: Optimizing Multi-Tool Selection in LLMs with Similarity and Dependency-Aware Experience Networks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijing Zhang",
      "Zhanpeng Chen",
      "He Zhu",
      "Ziyang Chen",
      "Nan Du",
      "Xiaolong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.812": {
    "title": "SPILL: Domain-Adaptive Intent Clustering based on Selection and Pooling with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "I-Fan Lin",
      "Faegheh Hasibi",
      "Suzan Verberne"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.813": {
    "title": "How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Li",
      "Heming Xia",
      "Xinfeng Yuan",
      "Qingxiu Dong",
      "Lei Sha",
      "Wenjie Li",
      "Zhifang Sui"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.814": {
    "title": "GRI-QA: a Comprehensive Benchmark for Table Question Answering over Environmental Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michele Luca Contalbo",
      "Sara Pederzoli",
      "Francesco Del Buono",
      "Venturelli Valeria",
      "Francesco Guerra",
      "Matteo Paganelli"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.815": {
    "title": "WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyu Lin",
      "Zhengda Zhou",
      "Zhiyuan Zhao",
      "Tianrui Wan",
      "Yilun Ma",
      "Junyu Gao",
      "Xuelong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.816": {
    "title": "Optimizing Multi-Hop Document Retrieval Through Intermediate Representations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linjiaen Linjiaen",
      "Jingyu Liu",
      "Yingbo Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.817": {
    "title": "Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patomporn Payoungkhamdee",
      "Pume Tuchinda",
      "Jinheon Baek",
      "Samuel Cahyawijaya",
      "Can Udomcharoenchaikit",
      "Potsawee Manakul",
      "Peerat Limkonchotiwat",
      "Ekapol Chuangsuwanich",
      "Sarana Nutanong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.818": {
    "title": "A Fully Automated Pipeline for Conversational Discourse Annotation: Tree Scheme Generation and Labeling with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kseniia Petukhova",
      "Ekaterina Kochmar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.819": {
    "title": "Can Language Models Serve as Analogy Annotators?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaojing Zhang",
      "Bochen Lyu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.820": {
    "title": "Reward Generalization in RLHF: A Topological Perspective",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Alex Qiu",
      "Fanzhi Zeng",
      "Jiaming Ji",
      "Dong Yan",
      "Kaile Wang",
      "Jiayi Zhou",
      "Yang Han",
      "Josef Dai",
      "Xuehai Pan",
      "Yaodong Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.821": {
    "title": "Enhanced Data Synthesis for LLM through Reasoning Structures Generated by Hierarchical GFlowNet",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianpeng Bu",
      "Minying Zhang",
      "Hongtao Duan",
      "Shurui Li",
      "Lulu Hu",
      "Yu Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.822": {
    "title": "Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanggan Gu",
      "Junzhuo Li",
      "Sirui Huang",
      "Xin Zou",
      "Zhenghua Li",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.823": {
    "title": "Token-level Preference Self-Alignment Optimization for Multi-style Outline Controllable Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Li",
      "Xuekong Xu",
      "Ziyao Chen",
      "Lixin Zou",
      "Ethanhjwu Ethanhjwu",
      "Qiang Chen",
      "Chenliang Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.824": {
    "title": "HatePRISM: Policies, Platforms, and Research Integration. Advancing NLP for Hate Speech Proactive Mitigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naquee Rizwan",
      "Seid Muhie Yimam",
      "Daryna Dementieva",
      "Dr. Florian Skupin",
      "Tim Fischer",
      "Daniil Moskovskiy",
      "Aarushi Ajay Borkar",
      "Robert Geislinger",
      "Punyajoy Saha",
      "Sarthak Roy",
      "Martin Semmann",
      "Alexander Panchenko",
      "Chris Biemann",
      "Animesh Mukherjee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.825": {
    "title": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sara Rajaee",
      "Kumar Pratik",
      "Gabriele Cesa",
      "Arash Behboodi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.826": {
    "title": "Generalizable Cross-Lingual Cognitive Distortion Detection with Standardized Annotations and Multi-Task Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongzhi Qi",
      "Nan Bai",
      "Jianqiang Li",
      "Wei Zhai",
      "Qing Zhao",
      "Qi Gao",
      "Bing Xiang Yang",
      "Guanghui Fu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.827": {
    "title": "How Do Multilingual Language Models Remember Facts?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Constanza Fierro",
      "Negar Foroutan",
      "Desmond Elliott",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.828": {
    "title": "SeqPO-SiMT: Sequential Policy Optimization for Simultaneous Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting Xu",
      "Zhichao Huang",
      "Jiankai Sun",
      "Shanbo Cheng",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.829": {
    "title": "Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayuto Tsutsumi",
      "Yuu Jinnai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.830": {
    "title": "BOSE: A Systematic Evaluation Method Optimized for Base Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongzhi Luan",
      "Changxin Tian",
      "Zhaoxin Huan",
      "Xiaolu Zhang",
      "Kunlong Chen",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.831": {
    "title": "DPGA-TextSyn: Differentially Private Genetic Algorithm for Synthetic Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhonghao Sun",
      "Zhiliang Tian",
      "Yiping Song",
      "Yuyi Si",
      "Juhua Zhang",
      "Minlie Huang",
      "Kai Lu",
      "Zeyu Xiong",
      "Xinwang Liu",
      "Dongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.832": {
    "title": "Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungyoon Lee",
      "Seongtae Hong",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.833": {
    "title": "Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kounianhua Du",
      "Hanjing Wang",
      "Jianxing Liu",
      "Jizheng Chen",
      "Xinyi Dai",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Yu",
      "Jun Wang",
      "Weinan Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.834": {
    "title": "On the Consistency of Commonsense in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guozheng Li",
      "Peng Wang",
      "Wenjun Ke",
      "Zijie Xu",
      "Jiajun Liu",
      "Ziyu Shang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.835": {
    "title": "Statement-Tuning Enables Efficient Cross-lingual Generalization in Encoder-only Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Elshabrawy",
      "Thanh-Nhi Nguyen",
      "Yeeun Kang",
      "Lihan Feng",
      "Annant Jain",
      "Faadil Abdullah Shaikh",
      "Jonibek Mansurov",
      "Mohamed Fazli Mohamed Imam",
      "Jesus-German Ortiz-Barajas",
      "Rendi Chevi",
      "Alham Fikri Aji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.836": {
    "title": "Evaluating Large Language Models for Confidence-based Check Set Selection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jane Arleth Dela Cruz",
      "Iris Hendrickx",
      "Martha Larson"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.837": {
    "title": "Training Multi-Modal LLMs through Dialogue Planning for HRI",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Claudiu Daniel Hromei",
      "Federico Borazio",
      "Andrea Sensi",
      "Elisa Passone",
      "Danilo Croce",
      "Roberto Basili"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.838": {
    "title": "MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fabian David Schmidt",
      "Florian Schneider",
      "Chris Biemann",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.839": {
    "title": "The Rise of Darkness: Safety-Utility Trade-Offs in Role-Playing Dialogue Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihong Tang",
      "Kehai Chen",
      "Xuefeng Bai",
      "Zheng-Yu Niu",
      "Bo Wang",
      "Jie Liu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.840": {
    "title": "SynGraph: A Dynamic Graph-LLM Synthesis Framework for Sparse Streaming User Sentiment Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zhang",
      "Qiyu Wei",
      "Yingjie Zhu",
      "Linhai Zhang",
      "Deyu Zhou",
      "Sophia Ananiadou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.841": {
    "title": "Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Cui",
      "Liuyi Yao",
      "Shuchang Tao",
      "Weijie Shi",
      "Yaliang Li",
      "Bolin Ding",
      "Xiaofang Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.842": {
    "title": "A Large and Balanced Corpus for Fine-grained Arabic Readability Assessment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khalid Elmadani",
      "Nizar Habash",
      "Hanada Taha"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.843": {
    "title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Che Liu",
      "Zhongwei Wan",
      "Haozhe Wang",
      "Yinda Chen",
      "Talha Qaiser",
      "Chen Jin",
      "Nikolay Burlutskiy",
      "Fariba Yousefi",
      "Rossella Arcucci"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.844": {
    "title": "See the World, Discover Knowledge: A Chinese Factuality Evaluation for Large Vision Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihao Gu",
      "Yingyao Wang",
      "Pi Bu",
      "Chen Wang",
      "Ziming Wang",
      "Tengtao Song",
      "Donglai Wei",
      "Jiale Yuan",
      "Yingxiu Zhao",
      "Yancheng He",
      "Shilong Li",
      "Jiaheng Liu",
      "Meng Cao",
      "Jun Song",
      "Yingshui Tan",
      "Xiang Li",
      "Wenbo Su",
      "Xiaoyong Zhu",
      "Bo Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.845": {
    "title": "Argus: Benchmarking and Enhancing Vision-Language Models for 3D Radiology Report Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Che Liu",
      "Zhongwei Wan",
      "Yuqi Wang",
      "Hui Shen",
      "Haozhe Wang",
      "Kangyu Zheng",
      "Mi Zhang",
      "Rossella Arcucci"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.846": {
    "title": "Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binquan Ji",
      "Haibo Luo",
      "YifeiLu YifeiLu",
      "Lei Hei",
      "Jiaqi Wang",
      "Tingjing Liao",
      "Wang Lingyu",
      "Shichao Wang",
      "Feiliang Ren"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.847": {
    "title": "Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the Lens of Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siya Qi",
      "Rui Cao",
      "Yulan He",
      "Zheng Yuan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.848": {
    "title": "TUBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanli He",
      "Jun Wang",
      "Qiongkai Xu",
      "Pasquale Minervini",
      "Pontus Stenetorp",
      "Benjamin I. P. Rubinstein",
      "Trevor Cohn"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.849": {
    "title": "Eliciting Textual Descriptions from Representations of Continuous Prompts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniela Gottesman",
      "Mor Geva",
      "Dana Ramati"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.850": {
    "title": "Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Fu",
      "Ruobing Xie",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Xirong Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.851": {
    "title": "Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangxu Wu",
      "Cong Wang",
      "Tianhuang Su",
      "Lin Haozhi",
      "JunYang JunYang",
      "Zhangchao Zhangchao",
      "Binqiang Pan",
      "SongpanYang SongpanYang",
      "Mingpeng Mingpeng",
      "Kai Shi",
      "Zixian Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.852": {
    "title": "Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heydar Soudani",
      "Evangelos Kanoulas",
      "Faegheh Hasibi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.853": {
    "title": "EuroVerdict: A Multilingual Dataset for Verdict Generation Against Misinformation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Russo",
      "Fariba Sadeghi",
      "Stefano Menini",
      "Marco Guerini"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.854": {
    "title": "LoFTI: Localization and Factuality Transfer to Indian Locales",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sona Elza Simon",
      "Soumen Kumar Mondal",
      "Abhishek Singhania",
      "Sayambhu Sen",
      "Preethi Jyothi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.855": {
    "title": "Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeyoung Choe",
      "Jihoon Kim",
      "Woohwan Jung"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.856": {
    "title": "GNN-RAG: Graph Neural Retrieval for Efficient Large Language Model Reasoning on Knowledge Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Costas Mavromatis",
      "George Karypis"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.857": {
    "title": "ASTRID - An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yajie Vera He",
      "Mohita Chowdhury",
      "Jared Joselowitz",
      "Aisling Higham",
      "Ernest Lim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.858": {
    "title": "On Entity Identification in Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masaki Sakata",
      "Benjamin Heinzerling",
      "Sho Yokoi",
      "Takumi Ito",
      "Kentaro Inui"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.859": {
    "title": "RAPID: Efficient Retrieval-Augmented Long Text Generation with Writing Planning and Information Discovery",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongchao Gu",
      "Dexun Li",
      "Kuicai Dong",
      "Hao Zhang",
      "Hang Lv",
      "Hao Wang",
      "Defu Lian",
      "Yong Liu",
      "Enhong Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.860": {
    "title": "CHARPEVAL: Benchmarking Large Language Models' Contextual Reasoning in Knowledge-Grounded Dialogue",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abbas Ghaddar",
      "David Alfonso-Hermelo",
      "Philippe Langlais",
      "Boxing Chen",
      "Prasanna Parthasarathi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.861": {
    "title": "Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Mahdi Abootorabi",
      "Amirhosein Zobeiri",
      "Mahdi Dehghani",
      "Mohammadali Mohammadkhani",
      "Bardia Mohammadi",
      "Omid Ghahroodi",
      "Mahdieh Soleymani Baghshah",
      "Ehsaneddin Asgari"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.862": {
    "title": "Debate4MATH: Multi-Agent Debate for Fine-Grained Reasoning in Math",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaowei Zhang",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.863": {
    "title": "Disambiguate First, Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Irina Saparina",
      "Mirella Lapata"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.864": {
    "title": "The Anatomy of Evidence: An Investigation Into Explainable ICD Coding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katharina Beckh",
      "Elisa Studeny",
      "Sujan Sai Gannamaneni",
      "Dario Antweiler",
      "Stefan Rueping"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.865": {
    "title": "AVG-LLaVA: An Efficient Large Multimodal Model with Adaptive Visual Granularity",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhibin Lan",
      "Liqiang Niu",
      "Fandong Meng",
      "Wenbo Li",
      "Jie Zhou",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.866": {
    "title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxi Wang",
      "Tianle Gu",
      "Zhongyu Wei",
      "Lang Gao",
      "Zirui Song",
      "Xiuying Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.867": {
    "title": "LLM-based Translation Inference with Iterative Bilingual Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andong Chen",
      "Kehai Chen",
      "Yang Xiang",
      "Xuefeng Bai",
      "Muyun Yang",
      "Yang Feng",
      "Tiejun Zhao",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.868": {
    "title": "Vulnerability of Text-to-Image Models to Prompt Template Stealing: A Differential Evolution Approach",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yurong Wu",
      "Fangwen Mu",
      "Qiuhong Zhang",
      "Jinjing Zhao",
      "Xinrun Xu",
      "Lingrui Mei",
      "Yang Wu",
      "Lin Shi",
      "Junjie Wang",
      "Zhiming Ding",
      "Yiwei Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.869": {
    "title": "mStyleDistance: Multilingual Style Embeddings and their Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin Qiu",
      "Jiacheng Zhu",
      "Ajay Patel",
      "Marianna Apidianaki",
      "Chris Callison-Burch"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.870": {
    "title": "SeqMMR: Sequential Model Merging and LLM Routing for Enhanced Batched Sequential Knowledge Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanbao Qiao",
      "Xuebing Liu",
      "Akshat Gupta",
      "Seung-Hoon Na"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.871": {
    "title": "ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Li",
      "Xinyi Dong",
      "Yang Liu",
      "Zhizhuo Yang",
      "Quansen Wang",
      "Xiaobo Wang",
      "Song-Chun Zhu",
      "Zixia Jia",
      "Zilong Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.872": {
    "title": "MAGIC-VQA: Multimodal And Grounded Inference with Commonsense Knowledge for Visual Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Yang",
      "Caren Han",
      "Siwen Luo",
      "Eduard Hovy"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.873": {
    "title": "Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Injae Na",
      "Keonwoong Noh",
      "Woohwan Jung"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.874": {
    "title": "Low-Rank Interconnected Adaptation across Layers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Zhong",
      "Jinman Zhao",
      "Yao Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.875": {
    "title": "GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ionut Teodor Sorodoc",
      "Leonardo F. R. Ribeiro",
      "Rexhina Blloshmi",
      "Christopher Davis",
      "Adrià de Gispert"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.876": {
    "title": "Change Entity-guided Heterogeneous Representation Disentangling for Change Captioning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Li",
      "Yunbin Tu",
      "Liang Li",
      "Li Su",
      "Qingming Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.877": {
    "title": "RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoran Jin",
      "Hongbang Yuan",
      "Tianyi Men",
      "Pengfei Cao",
      "Yubo Chen",
      "Jiexin Xu",
      "Huaijun Li",
      "Xiaojian Jiang",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.878": {
    "title": "Generate, Discriminate, Evolve: Enhancing Context Faithfulness via Fine-Grained Sentence-Level Self-Evolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Li",
      "Tianhua Zhang",
      "Yunxiang Li",
      "Hongyin Luo",
      "Abdalla Mohamed Salama Sayed Moustafa",
      "Xixin Wu",
      "James R. Glass",
      "Helen M. Meng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.879": {
    "title": "PAM: Paraphrase AMR-Centric Evaluation Metric",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Afonso Sousa",
      "Henrique Lopes Cardoso"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.880": {
    "title": "VP-MEL: Visual Prompts Guided Multimodal Entity Linking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongze Mi",
      "Jinyuan Li",
      "Zhangxuying Zhangxuying",
      "Haoran Cheng",
      "Jiahao Wang",
      "Di Sun",
      "Gang Pan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.881": {
    "title": "FADE: Why Bad Descriptions Happen to Good Features",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bruno Puri",
      "Aakriti Jain",
      "Elena Golimblevskaia",
      "Patrick Kahardipraja",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.882": {
    "title": "In the LLM era, Word Sense Induction remains unsolved",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Mosolova",
      "Marie Candito",
      "Carlos Ramisch"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.883": {
    "title": "Navigating the Political Compass: Evaluating Multilingual LLMs across Languages and Nationalities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chadi Helwe",
      "Oana Balalau",
      "Davide Ceolin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.884": {
    "title": "Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Audio-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanqi Yang",
      "Yanda Li",
      "Meng Fang",
      "Yunchao Wei",
      "Ling Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.885": {
    "title": "Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sibo Yi",
      "Tianshuo Cong",
      "Xinlei He",
      "Qi Li",
      "Jiaxing Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.886": {
    "title": "EMRs2CSP : Mining Clinical Status Pathway from Electronic Medical Records",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Chen",
      "Ruihui Hou",
      "Jingping Liu",
      "Tong Ruan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.887": {
    "title": "A Law Reasoning Benchmark for LLM with Tree-Organized Structures including Factum Probandum, Evidence and Experiences",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Shen",
      "Jinan Xu",
      "Huiqi Hu",
      "Luyi Lin",
      "Guoyang Ma",
      "Fei Zheng",
      "Fandong Meng",
      "Jie Zhou",
      "Wenjuan Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.888": {
    "title": "Libra: Leveraging Temporal Images for Biomedical Radiology Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Zhang",
      "Zaiqiao Meng",
      "Jake Lever",
      "Edmond S. L. Ho"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.889": {
    "title": "Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aditya Tomar",
      "Rudra Murthy",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.890": {
    "title": "Filling the Temporal Void: Recovering Missing Publication Years in the Project Gutenberg Corpus Using LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omar Momen",
      "Manuel Schaaf",
      "Alexander Mehler"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.891": {
    "title": "ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martina Miliani",
      "Serena Auriemma",
      "Alessandro Bondielli",
      "Emmanuele Chersoni",
      "Lucia Passaro",
      "Irene Sucameli",
      "Alessandro Lenci"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.892": {
    "title": "Are Dialects Better Prompters? A Case Study on Arabic Subjective Text Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leila Moudjari",
      "Farah Benamara"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.893": {
    "title": "Natural Logic at the Core: Dynamic Rewards for Entailment Tree Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihao Shi",
      "Xiao Ding",
      "Kai Xiong",
      "Hengwei Zhao",
      "Bing Qin",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.894": {
    "title": "R.R.: Unveiling LLM Training Privacy through Recollection and Ranking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenlong Meng",
      "Guo Zhenyuan",
      "Lenan Wu",
      "Chen Gong",
      "Wenyan Liu",
      "Weixian Li",
      "Chengkun Wei",
      "Wenzhi Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.895": {
    "title": "Nested-Refinement Metamorphosis: Reflective Evolution for Efficient Optimization of Networking Problems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuhan Guo",
      "Nan Yin",
      "James Kwok",
      "Quanming Yao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.896": {
    "title": "MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junzhe Zhang",
      "Huixuan Zhang",
      "Xunjian Yin",
      "Baizhou Huang",
      "Xu Zhang",
      "Xinyu Hu",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.897": {
    "title": "Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference Optimisation of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessio Galatolo",
      "Zhenbang Dai",
      "Katie Winkle",
      "Meriem Beloucif"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.898": {
    "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elisa Sanchez-Bayona",
      "Rodrigo Agerri"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.899": {
    "title": "AskQE: Question Answering as Automatic Evaluation for Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayeon Ki",
      "Kevin Duh",
      "Marine Carpuat"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.900": {
    "title": "ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alireza Salemi",
      "Julian Killingback",
      "Hamed Zamani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.901": {
    "title": "Bridging Intuitive Associations and Deliberate Recall: Empowering LLM Personal Assistant with Graph-Structured Long-term Memory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Zhang",
      "Weikang Yuan",
      "Zhuoren Jiang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.902": {
    "title": "Each graph is a new language: Graph Learning with LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huachi Zhou",
      "Jiahe Du",
      "Chuang Zhou",
      "Chang Yang",
      "Yilin Xiao",
      "Yuxuan Xie",
      "Xiao Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.903": {
    "title": "100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Van Yang",
      "Hongye Jin",
      "Shaochen Zhong",
      "Song Jiang",
      "Qifan Wang",
      "Vipin Chaudhary",
      "Xiaotian Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.904": {
    "title": "Multimodal Fusion and Coherence Modeling for Video Topic Segmentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Yu",
      "Chong Deng",
      "Qinglin Zhang",
      "Jiaqing Liu",
      "Qian Chen",
      "Wen Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.905": {
    "title": "Are Your LLMs Capable of Stable Reasoning?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junnan Liu",
      "Hongwei Liu",
      "Linchen Xiao",
      "Ziyi Wang",
      "Kuikun Liu",
      "Songyang Gao",
      "Wenwei Zhang",
      "Songyang Zhang",
      "Kai Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.906": {
    "title": "FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Zhu",
      "Yifan Ding",
      "Yicheng Tao",
      "Zhiwen Ruan",
      "Yixia Li",
      "Wenjia Zhang",
      "Yun Chen",
      "Guanhua Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.907": {
    "title": "JEBS: A Fine-grained Biomedical Lexical Simplification Task",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Xia",
      "Ishita Unde",
      "Brian David Ondov",
      "Dina Demner-Fushman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.908": {
    "title": "Multi-Hop Reasoning for Question Answering with Hyperbolic Representations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Welz",
      "Lucie Flek",
      "Akbar Karimi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.909": {
    "title": "Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunsoo Kim",
      "Jinge Wu",
      "Su Hwan Kim",
      "Pardeep Vasudev",
      "Jiashu Shen",
      "Honghan Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.910": {
    "title": "Hatevolution: What Static Benchmarks Don't Tell Us",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chiara Di Bonaventura",
      "Barbara McGillivray",
      "Yulan He",
      "Albert Meroño-Peñuela"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.911": {
    "title": "Tag-Instruct: Controlled Instruction Complexity Enhancement through Structure-based Augmentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Zhu",
      "Zhiwen Ruan",
      "Junyou Su",
      "Xingwei He",
      "Yun Chen",
      "Wenjia Zhang",
      "Guanhua Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.912": {
    "title": "Code-SPA: Style Preference Alignment to Large Language Models for Effective and Robust Code Debugging",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tengfei Wen",
      "Xuanang Chen",
      "Ben He",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.913": {
    "title": "Open-World Authorship Attribution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhao Tan",
      "Songhua Liu",
      "Xia Cong",
      "Kunjun Li",
      "Xinchao Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.914": {
    "title": "What is in a name? Mitigating Name Bias in Text Embedding Similarity via Anonymization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sahil Manchanda",
      "Pannaga Shivaswamy"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.915": {
    "title": "BenNumEval: A Benchmark to Assess LLMs' Numerical Reasoning Capabilities in Bengali",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kawsar Ahmed",
      "Md Osama",
      "Omar Sharif",
      "Eftekhar Hossain",
      "Mohammed Moshiul Hoque"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.916": {
    "title": "LLM Agents for Coordinating Multi-User Information Gathering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harsh Jhamtani",
      "Jacob Andreas",
      "Benjamin Van Durme"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.917": {
    "title": "C2KD: Cross-layer and Cross-head Knowledge Distillation for Small Language Model-based Recommendation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Chen",
      "Changyi Ma",
      "Wenqi Fan",
      "Zhaoxiang Zhang",
      "Li Qing"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.918": {
    "title": "Sign2Vis: Automated Data Visualization from Sign Language",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Wan",
      "Yang Wu",
      "Zhen Li",
      "Guobiao Zhang",
      "Hongyu Zhang",
      "Zhou Zhao",
      "Hai Jin",
      "April Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.919": {
    "title": "Transparentize the Internal and External Knowledge Utilization in LLMs with Trustworthy Citation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiajun Shen",
      "Tong Zhou",
      "Yubo Chen",
      "Delai Qiu",
      "Shengping Liu",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.920": {
    "title": "JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muyao Li",
      "Zihao Wang",
      "Kaichen He",
      "Xiaojian Ma",
      "Yitao Liang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.921": {
    "title": "Generative Frame Sampler for Long Video Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linli Yao",
      "Haoning Wu",
      "Kun Ouyang",
      "Yuanxing Zhang",
      "Caiming Xiong",
      "Bei Chen",
      "Xu Sun",
      "Junnan Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.922": {
    "title": "Annotating the Annotators: Analysis, Insights and Modelling from an Annotation Campaign on Persuasion Techniques Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davide Bassi",
      "Dimitar Iliyanov Dimitrov",
      "Bernardo D’Auria",
      "Firoj Alam",
      "Maram Hasanain",
      "Christian Moro",
      "Luisa Orrù",
      "Gian Piero Turchi",
      "Preslav Nakov",
      "Giovanni Da San Martino"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.923": {
    "title": "On the Generalization vs Fidelity Paradox in Knowledge Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suhas Kamasetty Ramesh",
      "Ayan Sengupta",
      "Tanmoy Chakraborty"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.924": {
    "title": "BEDAA: Bayesian Enhanced DeBERTa for Uncertainty-Aware Authorship Attribution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iqra Zahid",
      "Youcheng Sun",
      "Riza Batista-Navarro"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.925": {
    "title": "Benchmarking the Benchmarks: Reproducing Climate-Related NLP Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Calamai",
      "Oana Balalau",
      "Fabian M. Suchanek"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.926": {
    "title": "Exploring Supervised Approaches to the Detection of Anthropomorphic Language in the Reporting of NLP Venues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Shardlow",
      "Ashley Williams",
      "Charlie Roadhouse",
      "Filippos Ventirozos",
      "Piotr Przybyła"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.927": {
    "title": "PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Zhao",
      "Clara Vania",
      "Subhradeep Kayal",
      "Naila Khan",
      "Shay B Cohen",
      "Emine Yilmaz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.928": {
    "title": "iAgent: LLM Agent as a Shield between User and Recommender Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wujiang Xu",
      "Yunxiao Shi",
      "Zujie Liang",
      "Xuying Ning",
      "Kai Mei",
      "Kun Wang",
      "Xi Zhu",
      "Min Xu",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.929": {
    "title": "FactLens: Benchmarking Fine-Grained Fact Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kushan Mitra",
      "Dan Zhang",
      "Sajjadur Rahman",
      "Estevam Hruschka"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.930": {
    "title": "Process-based Self-Rewarding Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shimao Zhang",
      "Xiao Liu",
      "Xin Zhang",
      "Junxiao Liu",
      "Zheheng Luo",
      "Shujian Huang",
      "Yeyun Gong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.931": {
    "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benedikt Ebing",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.932": {
    "title": "ShieldHead: Decoding-time Safeguard for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zitao Xuan",
      "Xiaofeng Mao",
      "Da Chen",
      "Xin Zhang",
      "Yuhan Dong",
      "Jun Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.933": {
    "title": "A Survey on Proactive Defense Strategies Against Misinformation in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuliang Liu",
      "Hongyi Liu",
      "Aiwei Liu",
      "Duan Bingchen",
      "Zheng Qi",
      "Yibo Yan",
      "He Geng",
      "Peijie Jiang",
      "Jia Liu",
      "Xuming Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.934": {
    "title": "Smotrom tvoja på ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexey Tikhonov",
      "Sergei Shteiner",
      "Anna Bykova",
      "Ivan P. Yamshchikov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.935": {
    "title": "PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueliang Zhao",
      "Wei Wu",
      "Jian Guan",
      "Lingpeng Kong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.936": {
    "title": "Speculative Sampling via Exponential Races",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Szymon Kobus",
      "Deniz Gunduz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.937": {
    "title": "Going Beyond Your Expectations in Latency Metrics for Simultaneous Speech Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jorge Iranzo-Sánchez",
      "Javier Iranzo-Sánchez",
      "Adrià Giménez",
      "Jorge Civera"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.938": {
    "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoran Chen",
      "Bingsheng Yao",
      "Ruishi Zou",
      "Wenyue Hua",
      "Weimin Lyu",
      "Toby Jia-Jun Li",
      "Dakuo Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.939": {
    "title": "Recursive Question Understanding for Complex Question Answering over Heterogeneous Personal Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp Christmann",
      "Gerhard Weikum"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.940": {
    "title": "PreSumm: Predicting Summarization Performance Without Summarizing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Steven Koniaev",
      "Ori Ernst",
      "Jackie CK Cheung"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.941": {
    "title": "Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongjia Lei",
      "Haoyu Han",
      "Ryan A. Rossi",
      "Franck Dernoncourt",
      "Nedim Lipka",
      "Mahantesh M Halappanavar",
      "Jiliang Tang",
      "Yu Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.942": {
    "title": "Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Denitsa Saynova",
      "Lovisa Hagström",
      "Moa Johansson",
      "Richard Johansson",
      "Marco Kuhlmann"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.943": {
    "title": "FPE2M2: Approaching Lossless and Efficient Quantization with Native Floating Point",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Yi",
      "Jianwei Zhang",
      "Zhiying Xu",
      "Xinlong Yang",
      "Yang Zhou",
      "Minmin Sun",
      "Zengke Liu",
      "Tong Zhang",
      "Junyang Lin",
      "Jingren Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.944": {
    "title": "Asymmetric Conflict and Synergy in Post-training for LLM-based Multilingual Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Zheng",
      "Yan Wen",
      "Huiwen Bao",
      "Junfeng Guo",
      "Heng Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.945": {
    "title": "VISIAR: Empower MLLM for Visual Story Ideation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Xia",
      "Somdeb Sarkhel",
      "Mehrab Tanjim",
      "Stefano Petrangeli",
      "Ishita Dasgupta",
      "Yuxiao Chen",
      "Jinxuan Xu",
      "Di Liu",
      "Saayan Mitra",
      "Dimitris N. Metaxas"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.946": {
    "title": "Same Company, Same Signal: The Role of Identity in Earnings Call Transcripts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ding Yu",
      "Zhuo Liu",
      "Hangfeng He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.947": {
    "title": "Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emma Harvey",
      "Emily Sheng",
      "Su Lin Blodgett",
      "Alexandra Chouldechova",
      "Jean Garcia-Gathright",
      "Alexandra Olteanu",
      "Hanna Wallach"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.948": {
    "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angana Borah",
      "Marwa Houalla",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.949": {
    "title": "A General Framework to Enhance Fine-tuning-based LLM Unlearning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ren",
      "Zhenwei Dai",
      "Xianfeng Tang",
      "Hui Liu",
      "Jingying Zeng",
      "Zhen Li",
      "Rahul Goutam",
      "Suhang Wang",
      "Yue Xing",
      "Qi He",
      "Hui Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.950": {
    "title": "Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Maria Molfese",
      "Luca Moroni",
      "Luca Gioffré",
      "Alessandro Scirè",
      "Simone Conia",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.951": {
    "title": "Machine Theory of Mind Needs Machine Validation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adil Soubki",
      "Owen Rambow"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.952": {
    "title": "MiniKV: Pushing the Limits of 2-Bit KV Cache via Compression and System Co-Design for Efficient Long Context Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshat Sharma",
      "Hangliang Ding",
      "Jianping Li",
      "Neel Dani",
      "Minjia Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.953": {
    "title": "Sci-LoRA: Mixture of Scientific LoRAs for Cross-Domain Lay Paraphrasing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Cheng",
      "Jiaying Gong",
      "Hoda Eldardiry"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.954": {
    "title": "Trick or Neat: Adversarial Ambiguity and Language Model Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antonia Karamolegkou",
      "Oliver Eberle",
      "Phillip Rust",
      "Carina Kauf",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.955": {
    "title": "Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kshitish Ghate",
      "Tessa Charlesworth",
      "Mona T. Diab",
      "Aylin Caliskan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.956": {
    "title": "Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingqian Cui",
      "Pengfei He",
      "Jingying Zeng",
      "Hui Liu",
      "Xianfeng Tang",
      "Zhenwei Dai",
      "Yan Han",
      "Chen Luo",
      "Jing Huang",
      "Zhen Li",
      "Suhang Wang",
      "Yue Xing",
      "Jiliang Tang",
      "Qi He"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.957": {
    "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilun Zhao",
      "Chengye Wang",
      "Chuhan Li",
      "Arman Cohan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.958": {
    "title": "MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaustubh Deshpande",
      "Ved Sirdeshmukh",
      "Johannes Baptist Mols",
      "Lifeng Jin",
      "Ed-Yeremai Hernandez-Cardona",
      "Dean Lee",
      "Jeremy Kritz",
      "Willow E. Primack",
      "Summer Yue",
      "Chen Xing"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.959": {
    "title": "Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaydeep Borkar",
      "Matthew Jagielski",
      "Katherine Lee",
      "Niloofar Mireshghallah",
      "David A. Smith",
      "Christopher A. Choquette-Choo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.960": {
    "title": "Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyou Zhang",
      "Miao Li",
      "William Han",
      "Yihang Yao",
      "Zhepeng Cen",
      "Ding Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.961": {
    "title": "Is a cute puyfred cute? Context-dependent form-meaning systematicity in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaïr A. Waal",
      "Giovanni Cassani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.962": {
    "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haris Riaz",
      "Sourav Sanjukta Bhabesh",
      "Vinayak Arannil",
      "Miguel Ballesteros",
      "Graham Horwood"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.963": {
    "title": "MVTamperBench: Evaluating Robustness of Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amit Agarwal",
      "Srikant Panda",
      "Angeline Charles",
      "Hitesh Laxmichand Patel",
      "Bhargava Kumar",
      "Priyaranjan Pattnayak",
      "Taki Hasan Rafi",
      "Tejaswini Kumar",
      "Hansa Meghwani",
      "Karan Gupta",
      "Dong-Kyu Chae"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.964": {
    "title": "Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianqi Yan",
      "Yue Fan",
      "Hongquan Li",
      "Shan Jiang",
      "Yang Zhao",
      "Xinze Guan",
      "Ching-Chen Kuo",
      "Xin Eric Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.965": {
    "title": "Vision-Language Models Struggle to Align Entities across Modalities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iñigo Alonso",
      "Gorka Azkune",
      "Ander Salaberria",
      "Jeremy Barnes",
      "Oier Lopez De Lacalle"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.966": {
    "title": "A Multi-Labeled Dataset for Indonesian Discourse: Examining Toxicity, Polarization, and Demographics Information",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucky Susanto",
      "Musa Izzanardi Wijanarko",
      "Prasetia Anugrah Pratama",
      "Zilu Tang",
      "Fariz Akyas",
      "Traci Hong",
      "Ika Karlina Idris",
      "Alham Fikri Aji",
      "Derry Tanti Wijaya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.967": {
    "title": "MedCite: Can Language Models Generate Verifiable Text for Medicine?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Wang",
      "Mengjue Tan",
      "Qiao Jin",
      "Guangzhi Xiong",
      "Yu Hu",
      "Aidong Zhang",
      "Zhiyong Lu",
      "Minjia Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.968": {
    "title": "Let The Jury Decide: Fair Demonstration Selection for In-Context Learning through Incremental Greedy Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sadaf Md Halim",
      "Chen Zhao",
      "Xintao Wu",
      "Latifur Khan",
      "Christan Grant",
      "Fariha Ishrat Rahman",
      "Feng Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.969": {
    "title": "The Lies Characters Tell: Utilizing Large Language Models to Normalize Adversarial Unicode Perturbations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Portia Cooper",
      "Eduardo Blanco",
      "Mihai Surdeanu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.970": {
    "title": "Speech Act Patterns for Improving Generalizability of Explainable Politeness Detection Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Aljanaideh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.971": {
    "title": "Systematic Evaluation of Auto-Encoding and Large Language Model Representations for Capturing Author States and Traits",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khushboo Singh",
      "Vasudha Varadarajan",
      "Adithya V Ganesan",
      "August Håkan Nilsson",
      "Nikita Soni",
      "Syeda Mahwish",
      "Pranav Chitale",
      "Ryan L. Boyd",
      "Lyle Ungar",
      "Richard N Rosenthal",
      "H. Schwartz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.972": {
    "title": "TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubin Ge",
      "Salvatore Romeo",
      "Jason Cai",
      "Raphael Shu",
      "Yassine Benajiba",
      "Monica Sunkara",
      "Yi Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.973": {
    "title": "Conservative Bias in Large Language Models: Measuring Relation Predictions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Toyin Aguda",
      "Erik Wilson",
      "Allan Anzagira",
      "Simerjot Kaur",
      "Charese Smiley"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.974": {
    "title": "Mitigating Bias in RAG: Controlling the Embedder",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeyoun Kim",
      "Jacob Mitchell Springer",
      "Aditi Raghunathan",
      "Maarten Sap"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.975": {
    "title": "V-ALPHASOCIAL: Benchmark and Self-Reflective Chain-of-Thought Generation for Visual Social Commonsense Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongyu Lin",
      "Zhikun Xu",
      "Xiaohan Song",
      "Yixin Wan",
      "Xingcheng Yao",
      "Tsung-Han Lin",
      "Selina Song",
      "Pranav Subbaraman",
      "Ben Zhou",
      "Kai-Wei Chang",
      "Yizhou Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.976": {
    "title": "AfroBench: How Good are Large Language Models on African Languages?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jessica Ojo",
      "Odunayo Ogundepo",
      "Akintunde Oladipo",
      "Kelechi Ogueji",
      "Jimmy Lin",
      "Pontus Stenetorp",
      "David Ifeoluwa Adelani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.977": {
    "title": "Training Bilingual LMs with Data Constraints in the Targeted Language",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Skyler Seto",
      "Maartje Ter Hoeve",
      "Richard He Bai",
      "Natalie Schluter",
      "David Grangier"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.978": {
    "title": "ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Masry",
      "Mohammed Saidul Islam",
      "Mahir Ahmed",
      "Aayush Bajaj",
      "Firoz Kabir",
      "Aaryaman Kartha",
      "Md Tahmid Rahman Laskar",
      "Mizanur Rahman",
      "Shadikur Rahman",
      "Mehrad Shahmohammadi",
      "Megh Thakkar",
      "Md Rizwan Parvez",
      "Enamul Hoque",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.979": {
    "title": "From Observation to Understanding: Front-Door Adjustments with Uncertainty Calibration for Enhancing Egocentric Reasoning in LVLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenshen Li",
      "Wenxin Meng",
      "Lei Wang",
      "Hao Yang",
      "Chong Peng",
      "Peng Yan",
      "Fumin Shen",
      "Jingkuan Song",
      "Heng Tao Shen",
      "Xing Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.980": {
    "title": "Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query Expansion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yejun Yoon",
      "Jaeyoon Jung",
      "Seunghyun Yoon",
      "Kunwoo Park"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.981": {
    "title": "Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianqi Yan",
      "Xuehai He",
      "Xiang Yue",
      "Xin Eric Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.982": {
    "title": "Optimizing Reasoning for Text-to-SQL with Execution Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohan Zhai",
      "Canwen Xu",
      "Yuxiong He",
      "Zhewei Yao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.983": {
    "title": "Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyue Hua",
      "Kaijie Zhu",
      "Lingyao Li",
      "Lizhou Fan",
      "Mingyu Jin",
      "Shuhang Lin",
      "Haochen Xue",
      "Zelong Li",
      "Jindong Wang",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.984": {
    "title": "Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuqi Liu",
      "Han Wu",
      "Bowei He",
      "Xiongwei Han",
      "Mingxuan Yuan",
      "Linqi Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.985": {
    "title": "EgoNormia: Benchmarking Physical-Social Norm Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "MohammadHossein Rezaei",
      "Yicheng Fu",
      "Phil Cuvin",
      "Caleb Ziems",
      "Yanzhe Zhang",
      "Hao Zhu",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.986": {
    "title": "Large Language Models as Neurolinguistic Subjects: Discrepancy between Performance and Competence",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linyang He",
      "Ercong Nie",
      "Helmut Schmid",
      "Hinrich Schuetze",
      "Nima Mesgarani",
      "Jonathan Brennan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.987": {
    "title": "The Impact of Large Language Models in Academia: from Writing to Speaking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingmeng Geng",
      "Caixi Chen",
      "Yanru Wu",
      "Yao Wan",
      "Pan Zhou",
      "Dongping Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.988": {
    "title": "X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Wang",
      "Ruihan Tao",
      "Qiguang Chen",
      "Mengkang Hu",
      "Libo Qin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.989": {
    "title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Tan",
      "Zeyu Zhang",
      "Chen Ma",
      "Xu Chen",
      "Quanyu Dai",
      "Zhenhua Dong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.990": {
    "title": "Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryota Miyano",
      "Yuki Arase"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.991": {
    "title": "LongAttn: Selecting Long-context Training Data via Token-level Attention",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longyun Wu",
      "Dawei Zhu",
      "Guangxiang Zhao",
      "Zhuocheng Yu",
      "Junfeng Ran",
      "Xiangyu Wong",
      "Lin Sun",
      "Sujian Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.992": {
    "title": "CoRE: Condition-based Reasoning for Identifying Outcome Variance in Complex Events",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai P Vallurupalli",
      "Francis Ferraro"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.993": {
    "title": "FaVe: Factored and Verified Search Rationale for Long-form Answer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyuk Kim",
      "Sungjin Lee",
      "Seung-won Hwang",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.994": {
    "title": "UnrealLLM: Towards Highly Controllable and Interactable 3D Scene Generation by LLM-powered Procedural Content Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "SongTang SongTang",
      "Kaiyong Zhao",
      "Lei Wang",
      "Yuliang Li",
      "Xuebo Liu",
      "Junyi Zou",
      "Qiang Wang",
      "Xiaowen Chu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.995": {
    "title": "Tree-of-Prompts: Abstracting Control-Flow for Prompt Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyuk Kim",
      "Shubham Garg",
      "Lahari Poddar",
      "Seung-won Hwang",
      "Chris Hench"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.996": {
    "title": "Outlier-weighed Layerwise Sampling for LLM Fine-tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengxiang Li",
      "Lu Yin",
      "Xiaowei Gao",
      "Shiwei Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.997": {
    "title": "KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyi Jiang",
      "Lei Gao",
      "Hossein Entezari Zarch",
      "Murali Annavaram"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.998": {
    "title": "Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongming Yang",
      "Shi Lin",
      "Jun Shao",
      "Changting Lin",
      "Donghai Zhu",
      "Meng Han",
      "Qinglei Kong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.999": {
    "title": "Whether LLMs Know If They Know: Identifying Knowledge Boundaries via Debiased Historical In-Context Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Lv",
      "Nayu Liu",
      "Yang Shen",
      "Xin Liu",
      "Ping Luo",
      "Yue Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1000": {
    "title": "How do LLMs' Preferences Affect Event Argument Extraction? CAT: Addressing Preference Traps in Unsupervised EAE",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhao Wei",
      "Kai Shuang",
      "Zhiyi Li",
      "Chenrui Mao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1001": {
    "title": "Out-of-Distribution Detection via LLM-Guided Outlier Generation for Text-attributed Graph",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangwei Lv",
      "Mengze Li",
      "Jingyuan Chen",
      "Zhiang Dong",
      "Sirui Han",
      "Beishui Liao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1002": {
    "title": "Document-Level Relation Extraction with Global Relations and Entity Pair Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fu Zhang",
      "Yi Yan",
      "Jingwei Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1003": {
    "title": "Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubo Ma",
      "Jinsong Li",
      "Yuhang Zang",
      "Xiaobao Wu",
      "Xiaoyi Dong",
      "Pan Zhang",
      "Yuhang Cao",
      "Haodong Duan",
      "Jiaqi Wang",
      "Yixin Cao",
      "Aixin Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1004": {
    "title": "Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyu Ren",
      "Jie Zeng",
      "Qianyu He",
      "Jiaqing Liang",
      "Yanghua Xiao",
      "Weikang Zhou",
      "Zeye Sun",
      "Fei Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1005": {
    "title": "ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hwiyeol Jo",
      "Hyunwoo Lee",
      "Kang Min Yoo",
      "Taiwoo Park"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1006": {
    "title": "Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunyang Li",
      "Weiqi Wang",
      "Tianshi Zheng",
      "Yangqiu Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1007": {
    "title": "LLMTaxo: Leveraging Large Language Models for Constructing Taxonomy of Factual Claims from Social Media",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiqi Zhang",
      "Zhengyuan Zhu",
      "Zeyu Zhang",
      "Chengkai Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1008": {
    "title": "AnCast++: Document-Level Evaluation of Graph-based Meaning Representations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haibo Sun",
      "Jayeol Chun",
      "Nianwen Xue"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1009": {
    "title": "MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Run Luo",
      "Haonan Zhang",
      "Longze Chen",
      "Ting-En Lin",
      "Xiong Liu",
      "Yuchuan Wu",
      "Min Yang",
      "Yongbin Li",
      "Minzheng Wang",
      "Pengpeng Zeng",
      "Lianli Gao",
      "Heng Tao Shen",
      "Yunshui Li",
      "Hamid Alinejad-Rokny",
      "Xiaobo Xia",
      "Jingkuan Song",
      "Fei Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1010": {
    "title": "SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Guo",
      "Renrui Zhang",
      "Hao Chen",
      "Jialin Gao",
      "Dongzhi Jiang",
      "Jiaze Wang",
      "Pheng-Ann Heng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1011": {
    "title": "Exploring Layer-wise Representations of English and Chinese Homonymy in Pre-trained Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew King-Hang Ma",
      "Xie Chenwei",
      "Wenbo Wang",
      "William Shiyuan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1012": {
    "title": "DocMEdit: Towards Document-Level Model Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Zeng",
      "Zeming Liu",
      "Chong Feng",
      "Heyan Huang",
      "Yuhang Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1013": {
    "title": "Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Lu",
      "Jing Li",
      "Yigeng Zhou",
      "Yihui Zhang",
      "Wenya Wang",
      "Xiucheng Li",
      "Meishan Zhang",
      "Fangming Liu",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1014": {
    "title": "Evaluating the Long-Term Memory of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixi Jia",
      "Qinghua Liu",
      "Hexiao Li",
      "Yuyan Chen",
      "Jiqiang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1015": {
    "title": "Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Russell Scheinberg",
      "Ameeta Agrawal",
      "Amber Shore",
      "So Young Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1016": {
    "title": "Data Interpreter: An LLM Agent for Data Science",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sirui Hong",
      "Yizhang Lin",
      "Bang Liu",
      "Bangbang Liu",
      "Binhao Wu",
      "Ceyao Zhang",
      "Danyang Li",
      "Jiaqi Chen",
      "Jiayi Zhang",
      "Jinlin Wang",
      "Li Zhang",
      "Lingyao Zhang",
      "Min Yang",
      "Mingchen Zhuge",
      "Taicheng Guo",
      "Tuo Zhou",
      "Wei Tao",
      "Robert Tang",
      "Xiangtao Lu",
      "Xiawu Zheng",
      "Xinbing Liang",
      "Yaying Fei",
      "Yuheng Cheng",
      "Yongxin Ni",
      "Zhibin Gou",
      "Zongze Xu",
      "Yuyu Luo",
      "Chenglin Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1017": {
    "title": "DReSD: Dense Retrieval for Speculative Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Milan Gritta",
      "Huiyin Xue",
      "Gerasimos Lampouras"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1018": {
    "title": "Core: Robust Factual Precision with Informative Sub-Claim Identification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengping Jiang",
      "Jingyu Zhang",
      "Nathaniel Weir",
      "Seth Ebner",
      "Miriam Wanner",
      "Kate Sanders",
      "Daniel Khashabi",
      "Anqi Liu",
      "Benjamin Van Durme"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1019": {
    "title": "Rethinking Diverse Human Preference Learning through Principal Component Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Luo",
      "Rui Yang",
      "Hao Sun",
      "Chunyuan Deng",
      "Jiarui Yao",
      "Jingyan Shen",
      "Huan Zhang",
      "Hanjie Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1020": {
    "title": "Improving Word Alignment Using Semi-Supervised Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongtao Miao",
      "Qiyu Wu",
      "Masaaki Nagata",
      "Yoshimasa Tsuruoka"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1021": {
    "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Ou",
      "Yunzhi Yao",
      "Ningyu Zhang",
      "Hui Jin",
      "Jiacheng Sun",
      "Shumin Deng",
      "Zhenguo Li",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1022": {
    "title": "LLM-Symbolic Integration for Robust Temporal Tabular Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atharv Kulkarni",
      "Kushagra Dixit",
      "Vivek Srikumar",
      "Dan Roth",
      "Vivek Gupta"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1023": {
    "title": "Multimodal Large Language Models for Text-rich Image Understanding: A Comprehensive Review",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pei Fu",
      "Tongkun Guan",
      "Zining Wang",
      "Zhentao Guo",
      "Chen Duan",
      "Hao Sun",
      "Boming Chen",
      "Qianyi Jiang",
      "Jiayao Ma",
      "Kai Zhou",
      "Junfeng Luo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1024": {
    "title": "PruneVid: Visual Token Pruning for Efficient Video Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohu Huang",
      "Hao Zhou",
      "Kai Han"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1025": {
    "title": "PromptWizard: Optimizing Prompts via Task-Aware, Feedback-Driven Self-Evolution",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eshaan Agarwal",
      "Raghav Magazine",
      "Joykirat Singh",
      "Vivek Dani",
      "Tanuja Ganu",
      "Akshay Nambi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1026": {
    "title": "Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Li",
      "Xuejia Chen",
      "Zhanchao Xu",
      "Darian Li",
      "Nicole Hu",
      "Fei Teng",
      "Yiming Li",
      "Luyu Qiu",
      "Chen Jason Zhang",
      "Li Qing",
      "Lei Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1027": {
    "title": "TABGEN-ICL: Residual-Aware In-Context Example Selection for Tabular Data Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liancheng Fang",
      "Aiwei Liu",
      "Hengrui Zhang",
      "Henry Peng Zou",
      "Weizhi Zhang",
      "Philip S. Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1028": {
    "title": "Benchmarking Multi-National Value Alignment for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyi Ju",
      "Weijie Shi",
      "Chengzhong Liu",
      "Jiaming Ji",
      "Jipeng Zhang",
      "Ruiyuan Zhang",
      "Jiajie Xu",
      "Yaodong Yang",
      "Sirui Han",
      "Yike Guo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1029": {
    "title": "MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xixian Yong",
      "Jianxun Lian",
      "Xiaoyuan Yi",
      "Xiao Zhou",
      "Xing Xie"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1030": {
    "title": "Confidence Improves Self-Consistency in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Taubenfeld",
      "Tom Sheffer",
      "Eran Ofek",
      "Amir Feder",
      "Ariel Goldstein",
      "Zorik Gekhman",
      "Gal Yona"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1031": {
    "title": "None of the Above, Less of the Right Parallel Patterns in Human and LLM Performance on Multi-Choice Questions Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Rui Tam",
      "Cheng-Kuang Wu",
      "Chieh-Yen Lin",
      "Yun-Nung Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1032": {
    "title": "In Search of the Lost Arch in Dialogue: A Dependency Dialogue Acts Corpus for Multi-Party Dialogues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jon Cai",
      "Brendan King",
      "Peyton Cameron",
      "Susan Windisch Brown",
      "Miriam Eckert",
      "Dananjay Srinivas",
      "George Arthur Baker",
      "V Kate Everson",
      "Martha Palmer",
      "James Martin",
      "Jeffrey Flanigan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1033": {
    "title": "ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinzhe Zheng",
      "Sijie Ji",
      "Jiawei Sun",
      "Renqi Chen",
      "Wei Gao",
      "Mani Srivastava"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1034": {
    "title": "Debiasing Online Preference Learning via Preference Feature Preservation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyoung Kim",
      "Jinsung Yoon",
      "Jinwoo Shin",
      "Jaehyung Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1035": {
    "title": "ShortGPT: Layers in Large Language Models are More Redundant Than You Expect",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Men",
      "Mingyu Xu",
      "Qingyu Zhang",
      "Qianhao Yuan",
      "Bingning Wang",
      "Hongyu Lin",
      "Yaojie Lu",
      "Xianpei Han",
      "Weipeng Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1036": {
    "title": "ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyuan Liu",
      "Youcheng Pan",
      "Yang Xiang",
      "Daojing He",
      "Jing Li",
      "Yexing Du",
      "Tianrun Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1037": {
    "title": "Unveiling the Lack of LVLM Robustness to Fundamental Visual Variations: Why and Path Forward",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Fan",
      "Yumeng Wang",
      "Sandeep Polisetty",
      "Yi R. Fung"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1038": {
    "title": "DYNTEXT: Semantic-Aware Dynamic Text Sanitization for Privacy-Preserving LLM Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juhua Zhang",
      "Zhiliang Tian",
      "Minghang Zhu",
      "Yiping Song",
      "Taishu Sheng",
      "Siyi Yang",
      "Qiunan Du",
      "Xinwang Liu",
      "Minlie Huang",
      "Dongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1039": {
    "title": "InImageTrans: Multimodal LLM-based Text Image Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Zuo",
      "Kehai Chen",
      "Yu Zhang",
      "Zhengshan Xue",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1040": {
    "title": "FRAME: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuemiao Zhang",
      "Feiyu Duan",
      "Xu Liangyu",
      "Yongwei Zhou",
      "Sirui Wang",
      "Rongxiang Weng",
      "Jingang Wang",
      "Xunliang Cai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1041": {
    "title": "When Large Language Models Meet Speech: A Survey on Integration Approaches",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengdong Yang",
      "Shuichiro Shimizu",
      "Yahan Yu",
      "Chenhui Chu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1042": {
    "title": "KE-MHISTO: Towards a Multilingual Historical Knowledge Extraction Benchmark for Addressing the Long-Tail Problem",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arianna Graciotti",
      "Leonardo Piano",
      "Nicolas Lazzari",
      "Enrico Daga",
      "Rocco Tripodi",
      "Valentina Presutti",
      "Livio Pompianu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1043": {
    "title": "TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dingyu Yao",
      "Bowen Shen",
      "Zheng Lin",
      "Wei Liu",
      "Jian Luan",
      "Bin Wang",
      "Weiping Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1044": {
    "title": "The Elephant in the Room: Exploring the Role of Neutral Words in Language Model Group-Agnostic Debiasing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwei Guo",
      "Jiashi Gao",
      "Junlei Zhou",
      "Jiaxin Zhang",
      "Guanhua Chen",
      "Xiangyu Zhao",
      "Quanying Liu",
      "Haiyan Wu",
      "Xin Yao",
      "Xuetao Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1045": {
    "title": "LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Biao Fu",
      "Minpeng Liao",
      "Kai Fan",
      "Chengxi Li",
      "Liang Zhang",
      "Yidong Chen",
      "Xiaodong Shi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1046": {
    "title": "Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yin Hua",
      "Zhiqiang Liu",
      "Mingyang Chen",
      "Zheng Fang",
      "Chi Man Wong",
      "Lingxiao Li",
      "Chi Man Vong",
      "Huajun Chen",
      "Wen Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1047": {
    "title": "Generative Error Correction for Emotion-aware Speech-to-text Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengdong Yang",
      "Sheng Li",
      "Chenhui Chu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1048": {
    "title": "SynapticRAG: Enhancing Temporal Memory Retrieval in Large Language Models through Synaptic Mechanisms",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuki Hou",
      "Haruki Tamoto",
      "Qinghua Zhao",
      "Homei Miyashita"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1049": {
    "title": "Localizing and Mitigating Errors in Long-form Question Answering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rachneet Singh Sachdeva",
      "Yixiao Song",
      "Mohit Iyyer",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1050": {
    "title": "EMGLLM: Data-to-Text Alignment for Electromyogram Diagnosis Generation with Medical Numerical Data Encoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zefei Long",
      "Zhenbiao Cao",
      "Wei Chen",
      "Zhongyu Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1051": {
    "title": "LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sambal Shikhar",
      "Mohammed Irfan Kurpath",
      "Sahal Shaji Mullappilly",
      "Jean Lahoud",
      "Fahad Shahbaz Khan",
      "Rao Muhammad Anwer",
      "Salman Khan",
      "Hisham Cholakkal"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1052": {
    "title": "Act2P: LLM-Driven Online Dialogue Act Classification for Power Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangwenbo Zhangwenbo",
      "Wang Yuhan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1053": {
    "title": "MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kurt Micallef",
      "Claudia Borg"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1054": {
    "title": "TRATES: Trait-Specific Rubric-Assisted Cross-Prompt Essay Scoring",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sohaila Eltanbouly",
      "Salam Albatarni",
      "Tamer Elsayed"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1055": {
    "title": "DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft Tokens",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaoshen Chen",
      "Yangning Li",
      "Zishan Xu",
      "Yongqin Zeng",
      "Shunlong Wu",
      "Xinshuo Hu",
      "Zifei Shan",
      "Xin Su",
      "Jiwei Tang",
      "Yinghui Li",
      "Hai-Tao Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1056": {
    "title": "A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yimin Deng",
      "Yuxia Wu",
      "Yejing Wang",
      "Guoshuai Zhao",
      "Li Zhu",
      "Qidong Liu",
      "Derong Xu",
      "Zichuan Fu",
      "Xian Wu",
      "Yefeng Zheng",
      "Xiangyu Zhao",
      "Xueming Qian"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1057": {
    "title": "MWPO: Enhancing LLMs Performance through Multi-Weight Preference Strength and Length Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyue Xu",
      "Fu Zhang",
      "Jingwei Cheng",
      "Linfeng Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1058": {
    "title": "CLEAR: Character Unlearning in Textual and Visual Modalities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexey Dontsov",
      "Dmitrii Korzh",
      "Alexey Zhavoronkin",
      "Boris Mikheev",
      "Denis Bobkov",
      "Aibek Alanov",
      "Oleg Rogov",
      "Ivan Oseledets",
      "Elena Tutubalina"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1059": {
    "title": "Assessing the Reasoning Capabilities of LLMs in the context of Evidence-based Claim Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "John Dougrez-Lewis",
      "Mahmud Elahi Akhter",
      "Federico Ruggeri",
      "Sebastian Löbbers",
      "Yulan He",
      "Maria Liakata"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1060": {
    "title": "Language Models Lack Temporal Generalization and Bigger is Not Better",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stella Verkijk",
      "Piek Vossen",
      "Pia Sommerauer"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1061": {
    "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying Zhou",
      "Xinyao Wang",
      "Yulei Niu",
      "Yaojie Shen",
      "Lexin Tang",
      "Fan Chen",
      "Ben He",
      "Le Sun",
      "Longyin Wen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1062": {
    "title": "Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Wang",
      "Yu Sheng",
      "Linjing Li",
      "Daniel Dajun Zeng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1063": {
    "title": "ToolSpectrum: Towards Personalized Tool Utilization for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Cheng",
      "Hongru Wang",
      "Zeming Liu",
      "Yuhang Guo",
      "Yuanfang Guo",
      "Yunhong Wang",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1064": {
    "title": "Reverse Preference Optimization for Complex Instruction Following",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Huang",
      "Ting-En Lin",
      "Feiteng Fang",
      "Yuchuan Wu",
      "Hangyu Li",
      "Yuzhong Qu",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1065": {
    "title": "MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeong Hun Yeo",
      "Hyeongseop Rha",
      "Se Jin Park",
      "Yong Man Ro"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1066": {
    "title": "Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungmin Lee",
      "Yongsang Yoo",
      "Minhwa Jung",
      "Min Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1067": {
    "title": "Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiehan Cui",
      "Yanxu Mao",
      "Peipei Liu",
      "Congying Liu",
      "Datao You"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1068": {
    "title": "Verbosity-Aware Rationale Reduction: Sentence-Level Rationale Reduction for Efficient and Effective Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonwon Jang",
      "Jaehee Kim",
      "Wonbin Kweon",
      "Seonghyeon Lee",
      "Hwanjo Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1069": {
    "title": "Exploring the Role of Mental Health Conversational Agents in Training Medical Students and Professionals: A Systematic Literature Review",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thushari Atapattu",
      "Menasha Thilakaratne",
      "Duc Nhan Do",
      "Mahen Herath",
      "Katrina E. Falkner"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1070": {
    "title": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rin Ashizawa",
      "Yoichi Hirose",
      "Nozomu Yoshinari",
      "Kento Uchida",
      "Shinichi Shirakawa"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1071": {
    "title": "STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Li",
      "Yukun Chen",
      "Ziqiang Liu",
      "Minghuan Tan",
      "Lei Zhang",
      "Yunshui Li",
      "Run Luo",
      "Longze Chen",
      "Jing Luo",
      "Ahmadreza Argha",
      "Hamid Alinejad-Rokny",
      "Wei Zhou",
      "Min Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1072": {
    "title": "SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaushal Kumar Maurya",
      "Kv Aditya Srivatsa",
      "Ekaterina Kochmar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1073": {
    "title": "SkyLLM: Cross-LLM-APIs Federation for Cost-effective Query Processing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng Zhao",
      "Yifei Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1074": {
    "title": "Matina: A Culturally-Aligned Persian Language Model Using Multiple LoRA Experts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sara Bourbour Hosseinbeigi",
      "MohammadAli SeifKashani",
      "Javad Seraj",
      "Fatemeh Taherinezhad",
      "Ali Nafisi",
      "Fatemeh Nadi",
      "Iman Barati",
      "Hosein Hasani",
      "Mostafa Amiri",
      "Mostafa Masoudi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1075": {
    "title": "PM3-KIE: A Probabilistic Multi-Task Meta-Model for Document Key Information Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Birgit Kirsch",
      "Héctor Allende-Cid",
      "Stefan Rueping"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1076": {
    "title": "TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Lekssays",
      "Utsav Shukla",
      "Husrev Taha Sencar",
      "Md Rizwan Parvez"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1077": {
    "title": "G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long Bai",
      "Zixuan Li",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1078": {
    "title": "Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziang Ye",
      "Zhenru Zhang",
      "Yang Zhang",
      "Jianxin Ma",
      "Junyang Lin",
      "Fuli Feng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1079": {
    "title": "APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Rao",
      "Zepeng Lin",
      "Xuebo Liu",
      "Xiaopeng Ke",
      "Lian Lian",
      "Dong Jin",
      "Shengjun Cheng",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1080": {
    "title": "EasyEA: Large Language Model is All You Need in Entity Alignment Between Knowledge Graphs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwei Cheng",
      "Chenglong Lu",
      "Linyan Yang",
      "Guoqing Chen",
      "Fu Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1081": {
    "title": "An Adaptive Multi-Threshold Loss and a General Framework for Collaborating Losses in Document-Level Relation Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huangming Xu",
      "Fu Zhang",
      "Jingwei Cheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1082": {
    "title": "RoleMRC: A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junru Lu",
      "Jiazheng Li",
      "Guodong Shen",
      "Lin Gui",
      "Siyu An",
      "Yulan He",
      "Di Yin",
      "Xing Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1083": {
    "title": "C²RBench: A Chinese Complex Reasoning Benchmark for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junru Wu",
      "Tianhao Shen",
      "Linxi Su",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1084": {
    "title": "Unlocking LLMs' Self-Improvement Capacity with Autonomous Learning for Domain Adaptation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Ji",
      "Junying Chen",
      "Anningzhe Gao",
      "Wenya Xie",
      "Xiang Wan",
      "Benyou Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1085": {
    "title": "How Personality Traits Shape LLM Risk-Taking Behaviour",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "John Hartley",
      "Conor Brian Hamill",
      "Dale Seddon",
      "Devesh Batra",
      "Ramin Okhrati",
      "Raad Khraishi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1086": {
    "title": "Word-Level Detection of Code-Mixed Hate Speech with Multilingual Domain Transfer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karin Niederreiter",
      "Dagmar Gromann"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1087": {
    "title": "Evaluation of Attribution Bias in Generator-Aware Retrieval-Augmented Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amin Abolghasemi",
      "Leif Azzopardi",
      "Seyyed Hadi Hashemi",
      "Maarten de Rijke",
      "Suzan Verberne"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1088": {
    "title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Yang",
      "Junhong Wu",
      "Chen Wang",
      "Chengqing Zong",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1089": {
    "title": "Diagnosing Failures in Large Language Models' Answers: Integrating Error Attribution into Evaluation Framework",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zishan Xu",
      "Shuyi Xie",
      "Qingsong Lv",
      "Shupei Xiao",
      "Linlin Song",
      "Sui Wenjuan",
      "Fan Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1090": {
    "title": "Encode Errors: Representational Retrieval of In-Context Demonstrations for Multilingual Grammatical Error Correction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyue Peng",
      "Wei Li",
      "Wen Luo",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1091": {
    "title": "Preference Curriculum: LLMs Should Always Be Pretrained on Their Preferred Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuemiao Zhang",
      "Xu Liangyu",
      "Feiyu Duan",
      "Yongwei Zhou",
      "Sirui Wang",
      "Rongxiang Weng",
      "Jingang Wang",
      "Xunliang Cai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1092": {
    "title": "Can Input Attributions Explain Inductive Reasoning in In-Context Learning?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengyu Ye",
      "Tatsuki Kuribayashi",
      "Goro Kobayashi",
      "Jun Suzuki"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1093": {
    "title": "Modal Dependency Parsing via Biaffine Attention with Self-Loop",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jayeol Chun",
      "Nianwen Xue"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1094": {
    "title": "Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiao Wang",
      "Duzhen Zhang",
      "Ishita Agarwal",
      "Shen Gao",
      "Le Song",
      "Xiuying Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1095": {
    "title": "Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilun Qiu",
      "Xiaoyan Zhao",
      "Yang Zhang",
      "Yimeng Bai",
      "Wenjie Wang",
      "Hong Cheng",
      "Fuli Feng",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1096": {
    "title": "VideoRAG: Retrieval-Augmented Generation over Video Corpus",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soyeong Jeong",
      "Kangsan Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1097": {
    "title": "Synergistic Augmentation: Enhancing Cross-Domain Zero-Shot Slot Filling with Small Model-Assisted Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weizhen Li",
      "Junbao Huang",
      "Peijie Huang",
      "Yuhong Xu",
      "Jiekun Fan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1098": {
    "title": "A Classifier of Word-Level Variants in Witnesses of Biblical Hebrew Manuscripts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iglika Nikolova-Stoupak",
      "Maxime Amblard",
      "Sophie Robert-Hayek",
      "Frédérique Rey"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1099": {
    "title": "NOVA: An Iterative Planning Framework for Enhancing Scientific Innovation with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Hu",
      "Hongyu Fu",
      "Jinge Wang",
      "Yifeng Wang",
      "Zhikun Li",
      "Renjun Xu",
      "Yu Lu",
      "Yaochu Jin",
      "Lili Pan",
      "Zhenzhong Lan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1100": {
    "title": "Query-Driven Multimodal GraphRAG: Dynamic Local Knowledge Graph Construction for Online Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Bu",
      "Guojie Chang",
      "Zihao Chen",
      "CunYuan Dang",
      "Zhize Wu",
      "Yi He",
      "Xindong Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1101": {
    "title": "A Survey of Uncertainty Estimation Methods on Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiqiu Xia",
      "Jinxuan Xu",
      "Yuqian Zhang",
      "Hang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1102": {
    "title": "Beyond Single-Value Metrics: Evaluating and Enhancing LLM Unlearning with Cognitive Diagnosis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Lang",
      "Kehan Guo",
      "Yue Huang",
      "Yujun Zhou",
      "Haomin Zhuang",
      "Tianyu Yang",
      "Yao Su",
      "Xiangliang Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1103": {
    "title": "Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Xu",
      "Haotian Ma",
      "Yihao Ding",
      "Gongbo Zhang",
      "Chunhua Weng",
      "Yifan Peng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1104": {
    "title": "How do Transformer Embeddings Represent Compositions? A Functional Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aishik Nagar",
      "Ishaan Singh Rawal",
      "Mansi Dhanania",
      "Cheston Tan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1105": {
    "title": "Entriever: Energy-based Retriever for Knowledge-Grounded Dialog Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Cai",
      "Ke Li",
      "Yi Huang",
      "Junlan Feng",
      "Zhijian Ou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1106": {
    "title": "MONTROSE: LLM-driven Monte Carlo Tree Search Self-Refinement for Cross-Domain Rumor Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanshan Liu",
      "Menglong Lu",
      "Zhen Huang",
      "Zejiang He",
      "Liu Liu",
      "Zhigang Sun",
      "Dongsheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1107": {
    "title": "PEToolLLM: Towards Personalized Tool Learning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiancheng Xu",
      "Yongqi Li",
      "Heming Xia",
      "Fan Liu",
      "Min Yang",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1108": {
    "title": "A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quanwei Tang",
      "Sophia Yat Mei Lee",
      "Junshuang Wu",
      "Dong Zhang",
      "Shoushan Li",
      "Erik Cambria",
      "Guodong Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1109": {
    "title": "A MISMATCHED Benchmark for Scientific Natural Language Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Firoz Shaik",
      "Mobashir Sadat",
      "Nikita Gautam",
      "Doina Caragea",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1110": {
    "title": "TagRouter: Learning Route to LLMs through Tags for Open-Domain Text Generation Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhou Chen",
      "Zhiqiang Wei",
      "Yuqi Bai",
      "Xue Xiong",
      "Jianmin Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1111": {
    "title": "The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihuai Hong",
      "Meng Cao",
      "Dian Zhou",
      "Lei Yu",
      "Zhijing Jin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1112": {
    "title": "MPBench: A Comprehensive Multimodal Reasoning Benchmark for Process Errors Identification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "xu Zhao Pan",
      "Pengfei Zhou",
      "Jiaxin Ai",
      "Wangbo Zhao",
      "Kai Wang",
      "Xiaojiang Peng",
      "Wenqi Shao",
      "Hongxun Yao",
      "Kaipeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1113": {
    "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqi Xu",
      "Linyao Chen",
      "Dai-Jie Wu",
      "Yanjun Chen",
      "Zecheng Zhang",
      "Xiang Yao",
      "Zhiqiang Xie",
      "Yongchao Chen",
      "Shilong Liu",
      "Bochen Qian",
      "Anjie Yang",
      "Zhaoxuan Jin",
      "Jianbo Deng",
      "Philip Torr",
      "Bernard Ghanem",
      "Guohao Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1114": {
    "title": "Towards A \"Novel\" Benchmark: Evaluating Literary Fiction with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqing Wang",
      "Mingqi Gao",
      "Xinyu Hu",
      "Xiaojun Wan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1115": {
    "title": "A Reinforcement Learning Framework for Cross-Lingual Stance Detection Using Chain-of-Thought Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binghui Li",
      "Minghui Zou",
      "Xiaowang Zhang",
      "Shizhan Chen",
      "Zhiyong Feng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1116": {
    "title": "CARE-STaR: Constraint-aware Self-taught Reasoner",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiliang Li",
      "Bo Tang",
      "Yijun Niu",
      "Beihong Jin",
      "Qiwen Shi",
      "Yuchen Feng",
      "Zhiyu Li",
      "Jie Hu",
      "Mingchuan Yang",
      "Feiyu Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1117": {
    "title": "Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Berkeley Sheffield",
      "Kanishka Misra",
      "Valentina Pyatkin",
      "Ashwini Deo",
      "Kyle Mahowald",
      "Junyi Jessy Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1118": {
    "title": "War of Thoughts: Competition Stimulates Stronger Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibin Chen",
      "Jinyi Liu",
      "Yan Zheng",
      "Yifu Yuan",
      "Jianye Hao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1119": {
    "title": "Does Rationale Quality Matter? Enhancing Mental Disorder Detection via Selective Reasoning Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoyun Song",
      "Huije Lee",
      "Jisu Shin",
      "Sukmin Cho",
      "Changgeon Ko",
      "Jong C. Park"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1120": {
    "title": "Rethinking Table Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naihao Deng",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1121": {
    "title": "CliniDial: A Naturally Occurring Multimodal Dialogue Dataset for Team Reflection in Action During Clinical Operation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naihao Deng",
      "Kapotaksha Das",
      "Rada Mihalcea",
      "Vitaliy Popov",
      "Mohamed Abouelenien"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1122": {
    "title": "Chumor 2.0: Towards Better Benchmarking Chinese Humor Understanding from (Ruo Zhi Ba)",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqi He",
      "Yushu He",
      "Longju Bai",
      "Jiarui Liu",
      "Zhenjie Sun",
      "Zenghao Tang",
      "He Wang",
      "Hanchen Xia",
      "Rada Mihalcea",
      "Naihao Deng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1123": {
    "title": "Explicit Bayesian Inference to Uncover the Latent Themes of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raymond Li",
      "Chuyuan Li",
      "Gabriel Murray",
      "Giuseppe Carenini"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1124": {
    "title": "Improving Occupational ISCO Classification of Multilingual Swiss Job Postings with LLM-Refined Training Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ann-Sophie Gnehm",
      "Simon Clematide"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1125": {
    "title": "Brevity is the soul of sustainability: Characterizing LLM response lengths",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soham Poddar",
      "Paramita Koley",
      "Janardan Misra",
      "Niloy Ganguly",
      "Saptarshi Ghosh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1126": {
    "title": "Adversarial Preference Learning for Robust LLM Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanfu Wang",
      "Pengyu Wang",
      "Chenyang Xi",
      "Bo Tang",
      "Junyi Zhu",
      "Wenqiang Wei",
      "Chen Chen",
      "Chao Yang",
      "Jingfeng Zhang",
      "Chaochao Lu",
      "Yijun Niu",
      "Keming Mao",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Jie Hu",
      "Mingchuan Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1127": {
    "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youjeong Roh",
      "Joon-Young Paik",
      "Jingun Kwon",
      "Eun-Sun Cho"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1128": {
    "title": "READoc: A Unified Benchmark for Realistic Document Structured Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichao Li",
      "Aizier Abulaiti",
      "Yaojie Lu",
      "Xuanang Chen",
      "Jia Zheng",
      "Hongyu Lin",
      "Xianpei Han",
      "Shanshan Jiang",
      "Bin Dong",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1129": {
    "title": "TicTac: Time-aware Supervised Fine-tuning for Automatic Text Dating",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Ren",
      "Minna Peng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1130": {
    "title": "Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Feng",
      "Shu Wei",
      "Xiang Fei",
      "Wei Shi",
      "Yingdong Han",
      "Lei Liao",
      "Jinghui Lu",
      "Binghong Wu",
      "Qi Liu",
      "Chunhui Lin",
      "Jingqun Tang",
      "Hao Liu",
      "Can Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1131": {
    "title": "FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilun Zheng",
      "Sha Li",
      "Fangkun Wu",
      "Yang Ziyi",
      "Lin Hongchao",
      "Zhichao Hu",
      "Cai Xinjun",
      "Ziming Wang",
      "Jinxuan Chen",
      "Sitao Luan",
      "Jiahao Xu",
      "Lihui Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1132": {
    "title": "P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongjun Jang",
      "Youngchae Ahn",
      "Hyopil Shin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1133": {
    "title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Hu",
      "Jinhao Duan",
      "Chunchen Wei",
      "Li Zhang",
      "Yue Zhang",
      "Kaidi Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1134": {
    "title": "Small Encoders Can Rival Large Decoders in Detecting Groundedness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Istabrak Abbes",
      "Gabriele Prato",
      "Quentin Fournier",
      "Fernando Rodriguez",
      "Alaa Boukhary",
      "Adam Elwood",
      "Sarath Chandar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1135": {
    "title": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Heakl",
      "Muhammad Abdullah Sohail",
      "Mukul Ranjan",
      "Rania Elbadry",
      "Ghazi Shazan Ahmad",
      "Mohamed El-Geish",
      "Omar Maher",
      "Zhiqiang Shen",
      "Fahad Shahbaz Khan",
      "Salman Khan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1136": {
    "title": "Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shayan Alipour",
      "Indira Sen",
      "Mattia Samory",
      "Tanu Mitra"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1137": {
    "title": "AL-QASIDA: Analyzing LLM Quality and Accuracy Systematically in Dialectal Arabic",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathaniel Romney Robinson",
      "Shahd Abdelmoneim",
      "Kelly Marchisio",
      "Sebastian Ruder"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1138": {
    "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seok Hwan Song",
      "Mohna Chakraborty",
      "Qi Li",
      "Wallapak Tavanapong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1139": {
    "title": "MutantPrompt: Prompt Optimization via Mutation Under a Budget on Modest-sized LMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arijit Nag",
      "Animesh Mukherjee",
      "Niloy Ganguly",
      "Soumen Chakrabarti"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1140": {
    "title": "Heuristic-based Search Algorithm in Automatic Instruction-focused Prompt Optimization: A Survey",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wendi Cui",
      "Jiaxin Zhang",
      "Zhuohang Li",
      "Hao Sun",
      "Damien Lopez",
      "Kamalika Das",
      "Bradley A. Malin",
      "Sricharan Kumar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1141": {
    "title": "CONSENSAGENT: Towards Efficient and Effective Consensus in Multi-Agent LLM Interactions Through Sycophancy Mitigation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priya Pitre",
      "Naren Ramakrishnan",
      "Xuan Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1142": {
    "title": "The Structural Safety Generalization Problem",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julius Broomfield",
      "Tom Gibbs",
      "George Ingebretsen",
      "Ethan Kosak-Hine",
      "Tia Nasir",
      "Jason Zhang",
      "Reihaneh Iranmanesh",
      "Sara Pieri",
      "Reihaneh Rabbany",
      "Kellin Pelrine"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1143": {
    "title": "DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amitava Das",
      "Suranjana Trivedy",
      "Danush Khanna",
      "Yaswanth Narsupalli",
      "Basab Ghosh",
      "Rajarshi Roy",
      "Gurpreet Singh",
      "Vinija Jain",
      "Vasu Sharma",
      "Aishwarya Naresh Reganti",
      "Aman Chadha"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1144": {
    "title": "Model-Dependent Moderation: Inconsistencies in Hate Speech Detection Across LLM-based Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neil Fasching",
      "Yphtach Lelkes"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1145": {
    "title": "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhendu Khatuya",
      "Shashwat Naidu",
      "Saptarshi Ghosh",
      "Pawan Goyal",
      "Niloy Ganguly"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1146": {
    "title": "Unsupervised Morphological Tree Tokenizer",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyang Zhu",
      "Xiang Hu",
      "Pengyu Ji",
      "Wei Wu",
      "Kewei Tu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1147": {
    "title": "CausalLink: An Interactive Evaluation Framework for Causal Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyue Feng",
      "Frank Rudzicz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1148": {
    "title": "Toward Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiarui Liu",
      "Iman Ouzzani",
      "Wenkai Li",
      "Lechen Zhang",
      "Tianyue Ou",
      "Houda Bouamor",
      "Zhijing Jin",
      "Mona T. Diab"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1149": {
    "title": "A Joint Optimization Framework for Enhancing Efficiency of Tool Utilization in LLM Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Wu",
      "Edgar Meij",
      "Emine Yilmaz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1150": {
    "title": "When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jabez Magomere",
      "Emanuele La Malfa",
      "Manuel Tonneau",
      "Ashkan Kazemi",
      "Scott A. Hale"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1151": {
    "title": "Splintering Nonconcatenative Languages for Better Tokenization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bar Gazit",
      "Shaltiel Shmidman",
      "Avi Shmidman",
      "Yuval Pinter"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1152": {
    "title": "Aria-UI: Visual Grounding for GUI Instructions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Yang",
      "Yue Wang",
      "Dongxu Li",
      "Ziyang Luo",
      "Bei Chen",
      "Chao Huang",
      "Junnan Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1153": {
    "title": "Revealing Hidden Mechanisms of Cross-Country Content Moderation with Natural Language Processing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neemesh Yadav",
      "Jiarui Liu",
      "Francesco Ortu",
      "Roya Ensafi",
      "Zhijing Jin",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1154": {
    "title": "Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stefan Vasilev",
      "Christian Herold",
      "Baohao Liao",
      "Seyyed Hadi Hashemi",
      "Shahram Khadivi",
      "Christof Monz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1155": {
    "title": "Creating a Lens of Chinese Culture: A Multimodal Dataset for Chinese Pun Rebus Art Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuo Zhang",
      "Tiantian Feng",
      "Yibin Ni",
      "Mengqin Cao",
      "Ruying Liu",
      "Kiana Avestimehr",
      "Katharine Butler",
      "Yanjun Weng",
      "Mi Zhang",
      "Shrikanth Narayanan",
      "Salman Avestimehr"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1156": {
    "title": "FastDraft: How to Train Your Draft",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ofir Zafrir",
      "Igor Margulis",
      "Dorin Shteyman",
      "Shira Guskin",
      "Guy Boudoukh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1157": {
    "title": "SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shester Gueuwou",
      "Xiaodan Du",
      "Greg Shakhnarovich",
      "Karen Livescu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1158": {
    "title": "GUI Agents: A Survey",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dang Nguyen",
      "Jian Chen",
      "Yu Wang",
      "Gang Wu",
      "Namyong Park",
      "Zhengmian Hu",
      "Hanjia Lyu",
      "Junda Wu",
      "Ryan Aponte",
      "Yu Xia",
      "Xintong Li",
      "Jing Shi",
      "Hongjie Chen",
      "Viet Dac Lai",
      "Zhouhang Xie",
      "Sungchul Kim",
      "Ruiyi Zhang",
      "Tong Yu",
      "Mehrab Tanjim",
      "Nesreen K. Ahmed",
      "Puneet Mathur",
      "Seunghyun Yoon",
      "Lina Yao",
      "Branislav Kveton",
      "Jihyung Kil",
      "Thien Huu Nguyen",
      "Trung Bui",
      "Tianyi Zhou",
      "Ryan A. Rossi",
      "Franck Dernoncourt"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1159": {
    "title": "MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asma Ben Abacha",
      "Wen-wai Yim",
      "Yujuan Fu",
      "Zhaoyi Sun",
      "Meliha Yetisgen",
      "Fei Xia",
      "Thomas Lin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1160": {
    "title": "Understanding the Influence of Synthetic Data for Text Embedders",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob Mitchell Springer",
      "Vaibhav Adlakha",
      "Siva Reddy",
      "Aditi Raghunathan",
      "Marius Mosbach"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1161": {
    "title": "Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anar Yeginbergen",
      "Maite Oronoz",
      "Rodrigo Agerri"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1162": {
    "title": "Tell, Don't Show: Leveraging Language Models' Abstractive Retellings to Model Literary Themes",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Lucy",
      "Camilla Griffiths",
      "Sarah Levine",
      "Jennifer L Eberhardt",
      "Dorottya Demszky",
      "David Bamman"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1163": {
    "title": "BottleHumor: Self-Informed Humor Explanation using the Information Bottleneck Principle",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "EunJeong Hwang",
      "Peter West",
      "Vered Shwartz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1164": {
    "title": "Financial Language Model Evaluation (FLaME)",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Glenn Matlin",
      "Mika Okamoto",
      "Huzaifa Pardawala",
      "Yang Yang",
      "Sudheer Chava"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1165": {
    "title": "CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nengbo Wang",
      "Xiaotian Han",
      "Jagdip Singh",
      "Jing Ma",
      "Vipin Chaudhary"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1166": {
    "title": "Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tharindu Kumarage",
      "Ninareh Mehrabi",
      "Anil Ramakrishna",
      "Xinyan Zhao",
      "Richard Zemel",
      "Kai-Wei Chang",
      "Aram Galstyan",
      "Rahul Gupta",
      "Charith Peris"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1167": {
    "title": "Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Puxuan Yu",
      "Daniel Cohen",
      "Hemank Lamba",
      "Joel R. Tetreault",
      "Alejandro Jaimes"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1168": {
    "title": "Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Romero Calvo",
      "Shuoyang Ding",
      "Corey D Barrett",
      "Georgiana Dinu",
      "George Karypis"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1169": {
    "title": "Metagent-P: A Neuro-Symbolic Planning Agent with Metacognition for Open Worlds",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YanfangZhou YanfangZhou",
      "Yuntao Liu",
      "Xiaodong Li",
      "Yongqiang Zhao",
      "Xintong Wang",
      "Jinlong Tian",
      "Zhenyu Li",
      "Xinhai Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1170": {
    "title": "Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George-Kirollos Saad",
      "Scott Sanner"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1171": {
    "title": "Inductive Linguistic Reasoning with Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raghav Ramji",
      "Keshav Ramji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1172": {
    "title": "Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Hong",
      "Navonil Majumder",
      "Deepanway Ghosal",
      "Somak Aditya",
      "Rada Mihalcea",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1173": {
    "title": "Exploiting Phonetics and Glyph Representation at Radical-level for Classical Chinese Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Xiang",
      "Maofu Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1174": {
    "title": "Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Toan Tran",
      "Ruixuan Liu",
      "Li Xiong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1175": {
    "title": "Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ameya Godbole",
      "Robin Jia"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1176": {
    "title": "TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vihang Pancholi",
      "Jainit Sushil Bafna",
      "Tejas Anvekar",
      "Manish Shrivastava",
      "Vivek Gupta"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1177": {
    "title": "LADDER: Language-Driven Slice Discovery and Error Rectification in Vision Classifiers",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shantanu Ghosh",
      "Rayan Syed",
      "Chenyu Wang",
      "Vaibhav Choudhary",
      "Binxu Li",
      "Clare B Poynton",
      "Shyam Visweswaran",
      "Kayhan Batmanghelich"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1178": {
    "title": "GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sifan Zhou",
      "Shuo Wang",
      "Zhihang Yuan",
      "Mingjia Shi",
      "Yuzhang Shang",
      "Dawei Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1179": {
    "title": "Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gunjan Balde",
      "Soumyadeep Roy",
      "Mainack Mondal",
      "Niloy Ganguly"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1180": {
    "title": "UniT: One Document, Many Revisions, Too Many Edit Intention Taxonomies",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangping Lan",
      "Abdullah Aljebreen",
      "Eduard Dragut"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1181": {
    "title": "Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianbing Zhao",
      "Yiqing Lyu",
      "Di Wang",
      "Buzhou Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1182": {
    "title": "Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihang Yao",
      "Zhepeng Cen",
      "Miao Li",
      "William Han",
      "Yuyou Zhang",
      "Emerson Liu",
      "Zuxin Liu",
      "Chuang Gan",
      "Ding Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1183": {
    "title": "TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianling Li",
      "ShangZhan Li",
      "Zhenye Gao",
      "Qi Shi",
      "Yuxuan Li",
      "Zefan Wang",
      "Jiacheng Huang",
      "WangHaojie WangHaojie",
      "Jianrong Wang",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1184": {
    "title": "Just KIDDIN' : Knowledge Infusion and Distillation for Detection of INdecent Memes",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rahul Garg",
      "Trilok Padhi",
      "Hemang Jain",
      "Ugur Kursuncu",
      "Ponnurangam Kumaraguru"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1185": {
    "title": "Dynamic Personality in LLM Agents: A Framework for Evolutionary Modeling and Behavioral Analysis in the Prisoner's Dilemma",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiqi Zeng",
      "Bo Wang",
      "Dongming Zhao",
      "Zongfeng Qu",
      "Ruifang He",
      "Yuexian Hou",
      "Qinghua Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1186": {
    "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarcity",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dylan Zhang",
      "Justin Wang",
      "Tianran Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1187": {
    "title": "On the Robust Approximation of ASR Metrics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdul Waheed",
      "Hanin Atwany",
      "Rita Singh",
      "Bhiksha Raj"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1188": {
    "title": "Are the Values of LLMs Structurally Aligned with Humans? A Causal Perspective",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yipeng Kang",
      "Junqi Wang",
      "Yexin Li",
      "Mengmeng Wang",
      "Wenming Tu",
      "Quansen Wang",
      "Hengli Li",
      "Tingjun Wu",
      "Xue Feng",
      "Fangwei Zhong",
      "Zilong Zheng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1189": {
    "title": "LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinxin Li",
      "Huiyao Chen",
      "Chengjun Liu",
      "Jing Li",
      "Meishan Zhang",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1190": {
    "title": "Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanin Atwany",
      "Abdul Waheed",
      "Rita Singh",
      "Monojit Choudhury",
      "Bhiksha Raj"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1191": {
    "title": "M2PA: A Multi-Memory Planning Agent for Open Worlds Inspired by Cognitive Theory",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YanfangZhou YanfangZhou",
      "Xiaodong Li",
      "Yuntao Liu",
      "Yongqiang Zhao",
      "Xintong Wang",
      "Zhenyu Li",
      "Jinlong Tian",
      "Xinhai Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1192": {
    "title": "AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Wang",
      "Peidong Wang",
      "Lin Wu",
      "Xiaocui Yang",
      "Daling Wang",
      "Shi Feng",
      "Yuxin Chen",
      "Bixuan Wang",
      "Yifei Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1193": {
    "title": "Diversification Catalyzes Language Models' Instruction Generalization To Unseen Semantics",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dylan Zhang",
      "Justin Wang",
      "Francois Charton"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1194": {
    "title": "DecompileBench: A Comprehensive Benchmark for Evaluating Decompilers in Real-World Scenarios",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyu Gao",
      "Yuxin Cui",
      "Hao Wang",
      "Siliang Qin",
      "Yuanda Wang",
      "Zhang Bolun",
      "Chao Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1195": {
    "title": "Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqing Zhang",
      "Yuhan Liu",
      "Flood Sung",
      "Xiuying Chen",
      "Shuo Shang",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1196": {
    "title": "Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Wu",
      "Liang Ding",
      "Li Shen",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1197": {
    "title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengqing Jiang",
      "Zhangchen Xu",
      "Yuetai Li",
      "Luyao Niu",
      "Zhen Xiang",
      "Bo Li",
      "Bill Yuchen Lin",
      "Radha Poovendran"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1198": {
    "title": "ETRQA: A Comprehensive Benchmark for Evaluating Event Temporal Reasoning Abilities of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sigang Luo",
      "Yinan Liu",
      "Dongying Lin",
      "Yingying Zhai",
      "Bin Wang",
      "Xiaochun Yang",
      "Junpeng Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1199": {
    "title": "The Law of Knowledge Overshadowing: Towards Understanding, Predicting and Preventing LLM Hallucination",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuji Zhang",
      "Sha Li",
      "Cheng Qian",
      "Jiateng Liu",
      "Pengfei Yu",
      "Chi Han",
      "Yi R. Fung",
      "Kathleen McKeown",
      "ChengXiang Zhai",
      "Manling Li",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1200": {
    "title": "LegoMT2: Selective Asynchronous Sharded Data Parallel Training for Massive Neural Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Yuan",
      "Yinquan Lu",
      "Lei Li",
      "Jingjing Xu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1201": {
    "title": "Pruning General Large Language Models into Customized Expert Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiran Zhao",
      "Guizhen Chen",
      "Kenji Kawaguchi",
      "Lidong Bing",
      "Wenxuan Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1202": {
    "title": "Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxin Lu",
      "Ranran Haoran Zhang",
      "Yusen Zhang",
      "Rui Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1203": {
    "title": "Un-considering Contextual Information: Assessing LLMs' Understanding of Indexical Elements",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Metehan Oğuz",
      "Yavuz Faruk Bakman",
      "Duygu Nur Yaldiz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1204": {
    "title": "Behavioral Analysis of Information Salience in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Trienes",
      "Jörg Schlötterer",
      "Junyi Jessy Li",
      "Christin Seifert"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1205": {
    "title": "The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avinash Baidya",
      "Kamalika Das",
      "Xiang Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1206": {
    "title": "Task Facet Learning: A Structured Approach To Prompt Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gurusha Juneja",
      "Gautam Jajoo",
      "Hua Li",
      "Jian Jiao",
      "Nagarajan Natarajan",
      "Amit Sharma"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1207": {
    "title": "LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junlong Tong",
      "Jinlan Fu",
      "Zixuan Lin",
      "Yingqi Fan",
      "Anhao Zhao",
      "Hui Su",
      "Xiaoyu Shen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1208": {
    "title": "YinYang-Align: A new Benchmark for Competing Objectives and Introducing Multi-Objective Preference based Text-to-Image Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amitava Das",
      "Yaswanth Narsupalli",
      "Gurpreet Singh",
      "Vinija Jain",
      "Vasu Sharma",
      "Suranjana Trivedy",
      "Aman Chadha",
      "Amit Sheth"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1209": {
    "title": "FREE: Fast and Robust Vision Language Models with Early Exits",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divya Jyoti Bajpai",
      "Manjesh Kumar Hanawal"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1210": {
    "title": "REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuxuan Hu",
      "Liyun Zhang",
      "Yeji Lim",
      "Aum Wadhwani",
      "Austin Peters",
      "Daniel Kang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1211": {
    "title": "Time Travel: A Comprehensive Benchmark to Evaluate LMMs on Historical and Cultural Artifacts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sara Ghaboura",
      "Ketan Pravin More",
      "Ritesh Thawkar",
      "Wafa Al Ghallabi",
      "Omkar Thawakar",
      "Fahad Shahbaz Khan",
      "Hisham Cholakkal",
      "Salman Khan",
      "Rao Muhammad Anwer"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1212": {
    "title": "Unveiling and Addressing Pseudo Forgetting in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huashan Sun",
      "Yizhe Yang",
      "Yinghao Li",
      "Jiawei Li",
      "Yang Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1213": {
    "title": "Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yupu Liang",
      "Yaping Zhang",
      "Zhiyang Zhang",
      "Zhiyuan Chen",
      "Yang Zhao",
      "Lu Xiang",
      "Chengqing Zong",
      "Yu Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1214": {
    "title": "HG-InsightLog: Context Prioritization and Reduction for Question Answering with Non-Natural Language Construct Log Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Supriya Bajpai",
      "Athira Gopal",
      "Chandrakant Harjpal",
      "Niraj Kumar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1215": {
    "title": "Dialect Normalization using Large Language Models and Morphological Rules",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antonios Dimakis",
      "John Pavlopoulos",
      "Antonios Anastasopoulos"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1216": {
    "title": "USDC: A Dataset of ̲User ̲Stance and ̲Dogmatism in Long ̲Conversations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mounika Marreddy",
      "Subba Reddy Oota",
      "Venkata Charan Chinni",
      "Manish Gupta",
      "Lucie Flek"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1217": {
    "title": "Learning to Insert [PAUSE] Tokens for Better Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunki Kim",
      "Sangryul Kim",
      "James Thorne"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1218": {
    "title": "Understand the Implication: Learning to Think for Pragmatic Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Settaluri Lakshmi Sravanthi",
      "Kishan Maharaj",
      "Sravani Gunnu",
      "Abhijit Mishra",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1219": {
    "title": "WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyang Lu",
      "Jingtan Wang",
      "Zitong Zhao",
      "Zhongxiang Dai",
      "Chuan-Sheng Foo",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1220": {
    "title": "Dense Retrieval with Quantity Comparison Intent",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prayas Agrawal",
      "Nandeesh Kumar K M",
      "Muthusamy Chelliah",
      "Surender Kumar",
      "Soumen Chakrabarti"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1221": {
    "title": "Reflection on Knowledge Graph for Large Language Models Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yigeng Zhou",
      "Wu Li",
      "Yifan Lu",
      "Jing Li",
      "Fangming Liu",
      "Meishan Zhang",
      "Yequan Wang",
      "Daojing He",
      "Honghai Liu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1222": {
    "title": "Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahe Jin",
      "Yanheng He",
      "Mingyan Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1223": {
    "title": "DIESEL: A Lightweight Inference-Time Safety Enhancement for Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Ganon",
      "Alon Zolfi",
      "Omer Hofman",
      "Inderjeet Singh",
      "Hisashi Kojima",
      "Yuval Elovici",
      "Asaf Shabtai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1224": {
    "title": "Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Gu",
      "Ziting Xian",
      "Yuanzhen Xie",
      "Ye Liu",
      "Enjie Liu",
      "Ruichao Zhong",
      "Mochi Gao",
      "Yunzhi Tan",
      "Bo Hu",
      "Zang Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1225": {
    "title": "Structured Pruning for Diverse Best-of-N Reasoning Optimization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hieu Trung Nguyen",
      "Bao Nguyen",
      "Viet Anh Nguyen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1226": {
    "title": "PodAgent: A Comprehensive Framework for Podcast Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujia Xiao",
      "Lei He",
      "Haohan Guo",
      "Feng-Long Xie",
      "Tan Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1227": {
    "title": "STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Liu",
      "Zhenyi Lu",
      "Xinyu Hu",
      "Jerry Zhang",
      "Dailin Li",
      "Jiacheng Cen",
      "Huilin Cao",
      "Haiteng Wang",
      "Yuhan Li",
      "Xie Kun",
      "Dandan Li",
      "Pei Zhang",
      "Chengbo Zhang",
      "Yuxiang Ren",
      "Xiaohong Huang",
      "Yan Ma"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1228": {
    "title": "iMOVE : Instance-Motion-Aware Video Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaze Li",
      "Yaya Shi",
      "Zongyang Ma",
      "Haoran Xu",
      "Yandong.bai Yandong.bai",
      "Huihui Xiao",
      "Ruiwen Kang",
      "Fan Yang",
      "Tingting Gao",
      "Di Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1229": {
    "title": "SceneGram: Conceptualizing and Describing Tangrams in Scene Context",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simeon Junker",
      "Sina Zarrieß"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1230": {
    "title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengwei Qin",
      "Wenhan Xia",
      "Tan Wang",
      "Fangkai Jiao",
      "Yuchen Hu",
      "Bosheng Ding",
      "Ruirui Chen",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1231": {
    "title": "MERIT: Multi-Agent Collaboration for Unsupervised Time Series Representation Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shu Zhou",
      "Yunyang Xuan",
      "Yuxuan Ao",
      "Xin Wang",
      "Tao Fan",
      "Hao Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1232": {
    "title": "JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chang Gao",
      "Wenxuan Zhang",
      "Guizhen Chen",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1233": {
    "title": "RedundancyLens: Revealing and Exploiting Visual Token Processing Redundancy for Efficient Decoder-Only MLLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongliang Li",
      "Jiaxin Zhang",
      "Wenhui Liao",
      "Dezhi Peng",
      "Kai Ding",
      "Lianwen Jin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1234": {
    "title": "Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mufan Xu",
      "Gewen Liang",
      "Kehai Chen",
      "Wei Wang",
      "Xun Zhou",
      "Muyun Yang",
      "Tiejun Zhao",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1235": {
    "title": "KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Xiantao Cai",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1236": {
    "title": "Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simeon Junker",
      "Manar Ali",
      "Larissa Koch",
      "Sina Zarrieß",
      "Hendrik Buschmeier"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1237": {
    "title": "Removing Prompt-template Bias in Reinforcement Learning from Human Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaojie Wang",
      "Haonan Shi",
      "Long Tian",
      "Bo An",
      "Shuicheng Yan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1238": {
    "title": "Latent Distribution Decouple for Uncertain-Aware Multimodal Multi-label Emotion Recognition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwang Huang",
      "Jiang Zhong",
      "Qin Lei",
      "Gaojinpeng Gaojinpeng",
      "Ymyang Ymyang",
      "Sirui Wang",
      "PeiguangLi PeiguangLi",
      "Kaiwen Wei"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1239": {
    "title": "Are LLMs Rational Investors? A Study on the Financial Bias in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Zhou",
      "Yuchen Ni",
      "Zhiheng Xi",
      "Zhangyue Yin",
      "Yu He",
      "Gan Yunhui",
      "Xiang Liu",
      "Zhang Jian",
      "Sen Liu",
      "Xipeng Qiu",
      "Yixin Cao",
      "Guangnan Ye",
      "Hongfeng Chai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1240": {
    "title": "Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dan Oneata",
      "Desmond Elliott",
      "Stella Frank"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1241": {
    "title": "Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sajjad Ghiasvand",
      "Yifan Yang",
      "Zhiyu Xue",
      "Mahnoosh Alizadeh",
      "Zheng Zhang",
      "Ramtin Pedarsani"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1242": {
    "title": "A rebuttal of two common deflationary stances against LLM cognition",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zak Hussain",
      "Rui Mata",
      "Dirk U. Wulff"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1243": {
    "title": "COVER: Context-Driven Over-Refusal Verification in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giovanni Sullutrone",
      "Riccardo A. Vigliermo",
      "Sonia Bergamaschi",
      "Luca Sala"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1244": {
    "title": "MOSAIC: Multiple Observers Spotting AI Content",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthieu Dubois",
      "François Yvon",
      "Pablo Piantanida"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1245": {
    "title": "GUIDEX: Guided Synthetic Data Generation for Zero-Shot Information Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neil De La Fuente",
      "Oscar Sainz",
      "Iker García-Ferrero",
      "Eneko Agirre"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1246": {
    "title": "Missing the Margins: A Systematic Literature Review on the Demographic Representativeness of LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Indira Sen",
      "Marlene Lutz",
      "Elisa Rogers",
      "David Garcia",
      "Markus Strohmaier"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1247": {
    "title": "LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omkar Thawakar",
      "Dinura Dissanayake",
      "Ketan Pravin More",
      "Ritesh Thawkar",
      "Ahmed Heakl",
      "Noor Ahsan",
      "Yuhao Li",
      "Ilmuz Zaman Mohammed Zumri",
      "Jean Lahoud",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal",
      "Ivan Laptev",
      "Mubarak Shah",
      "Fahad Shahbaz Khan",
      "Salman Khan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1248": {
    "title": "Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingjin Song",
      "Yupei Du",
      "Denis Paperno",
      "Albert Gatt"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1249": {
    "title": "Full-Step-DPO: Self-Supervised Preference Optimization with Step-wise Rewards for Mathematical Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huimin Xu",
      "Xin Mao",
      "Feng-Lin Li",
      "Xiaobao Wu",
      "Wang Chen",
      "Wei Zhang",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1250": {
    "title": "Do Emotions Really Affect Argument Convincingness? A Dynamic Approach with LLM-based Manipulation Checks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanran Chen",
      "Steffen Eger"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1251": {
    "title": "SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huimin Xu",
      "Xin Mao",
      "Feng-Lin Li",
      "Xiaobao Wu",
      "Wang Chen",
      "Wei Zhang",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1252": {
    "title": "Compositional Syntactico-SemBanking for English as a Second or Foreign Language",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxi Li",
      "Xihao Wang",
      "Weiwei Sun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1253": {
    "title": "Semantics-aware prompting for translating NOtices To AirMen",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minal Nitin Dani",
      "Aishwarya Maheswaran",
      "Maunendra Sankar Desarkar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1254": {
    "title": "Stereotype or Personalization? User Identity Biases Chatbot Recommendations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anjali Kantharuban",
      "Jeremiah Milbauer",
      "Maarten Sap",
      "Emma Strubell",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1255": {
    "title": "Automated main concept generation for narrative discourse assessment in aphasia",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ankita Gupta",
      "Marisa Hudspeth",
      "Polly Stokes",
      "Jacquie Kurland",
      "Brendan O’Connor"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1256": {
    "title": "Can VLMs Actually See and Read? A Survey on Modality Collapse in Vision-Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mong Yuan Sim",
      "Wei Emma Zhang",
      "Xiang Dai",
      "Biaoyan Fang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1257": {
    "title": "You are Beautiful, Body Image Stereotypes are Ugly!\" BIStereo: A Benchmark to Measure Body Image Stereotypes in Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Narjis Asad",
      "Nihar Ranjan Sahoo",
      "Rudra Murthy",
      "Swaprava Nath",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1258": {
    "title": "Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengliang Shi",
      "Yuhan Wang",
      "Lingyong Yan",
      "Pengjie Ren",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Zhaochun Ren"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1259": {
    "title": "FineCite: A Novel Approach For Fine-Grained Citation Context Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lasse M. Jantsch",
      "Dong-Jae Koh",
      "Seonghwan Yoon",
      "Jisu Lee",
      "Anne Lauscher",
      "Young-Kyoon Suh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1260": {
    "title": "Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changyue Wang",
      "Weihang Su",
      "Qingyao Ai",
      "Yujia Zhou",
      "Yiqun Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1261": {
    "title": "Entrospect: Information-Theoretic Self-Reflection Elicits Better Response Refinement of Small Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqiang Yan",
      "Ziqiao Lin",
      "Lin Zhang",
      "Zhenglong Sun",
      "Yuan Gao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1262": {
    "title": "Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Riya Sawhney",
      "Samrat Yadav",
      "Indrajit Bhattacharya",
      "Mausam Mausam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1263": {
    "title": "Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "San Kim",
      "Jonghwi Kim",
      "Yejin Jeon",
      "Gary Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1264": {
    "title": "EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heejae Suh",
      "Yejin Jeon",
      "Deokhyung Kang",
      "Taehee Park",
      "Yejin Min",
      "Gary Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1265": {
    "title": "MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiqian Qin",
      "Yuanfeng Song",
      "Jinwei Lu",
      "Yuanwei Song",
      "Shuaimin Li",
      "Chen Jason Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1266": {
    "title": "Tool learning via Inference-time Scaling and Cycle Verifier",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobo Liang",
      "Wenjin Xie",
      "Juntao Li",
      "Wanfu Wang",
      "Yibin Chen",
      "Kehai Chen",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1267": {
    "title": "When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jane Pan",
      "Ryan Shar",
      "Jacob Pfau",
      "Ameet Talwalkar",
      "He He",
      "Valerie Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1268": {
    "title": "Reranking-based Generation for Unbiased Perspective Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Narutatsu Ri",
      "Nicholas Deas",
      "Kathleen McKeown"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1269": {
    "title": "KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Fang",
      "Kaijing Ma",
      "Tianyu Zheng",
      "Xeron Du",
      "Ningxuan Lu",
      "Ge Zhang",
      "Qingkun Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1270": {
    "title": "Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Zhao",
      "Jiapeng Zhu",
      "Can Xu",
      "Yao Liu",
      "Xiang Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1271": {
    "title": "Mixture-of-Personas Language Models for Population Simulation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ngoc Bui",
      "Hieu Trung Nguyen",
      "Shantanu Kumar",
      "Julian Theodore",
      "Weikang Qiu",
      "Viet Anh Nguyen",
      "Rex Ying"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1272": {
    "title": "ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baohao Liao",
      "Christian Herold",
      "Seyyed Hadi Hashemi",
      "Stefan Vasilev",
      "Shahram Khadivi",
      "Christof Monz"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1273": {
    "title": "Decomposed Opinion Summarization with Verified Aspect-Aware Modules",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Li",
      "Jey Han Lau",
      "Eduard Hovy",
      "Mirella Lapata"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1274": {
    "title": "Token-Budget-Aware LLM Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingxu Han",
      "Zhenting Wang",
      "Chunrong Fang",
      "Shiyu Zhao",
      "Shiqing Ma",
      "Zhenyu Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1275": {
    "title": "HATA: Trainable and Hardware-Efficient Hash-Aware Top-k Attention for Scalable Large Model Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ping Gong",
      "Jiawei Yi",
      "Shengnan Wang",
      "Juncheng Zhang",
      "Zewen Jin",
      "Ouxiang Zhou",
      "Ruibo Liu",
      "Guanbin Xu",
      "Youhui Bai",
      "Bowen Ye",
      "Kun Yuan",
      "Tong Yang",
      "Gong Zhang",
      "Renhai Chen",
      "Feng Wu",
      "Cheng Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1276": {
    "title": "Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shota Takashiro",
      "Takeshi Kojima",
      "Andrew Gambardella",
      "Qi Cao",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1277": {
    "title": "LIST: Linearly Incremental SQL Translator for Single-Hop Reasoning, Generation and Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyuan Guan",
      "Ruoxin Li",
      "Xudong Guo",
      "Zhenning Huang",
      "Xudong Weng",
      "Hehuan Liu",
      "Zheng Wei",
      "Zang Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1278": {
    "title": "MAGI: Multi-Agent Guided Interview for Psychiatric Assessment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanqun Bi",
      "Zhuang Chen",
      "Zhoufu Liu",
      "Hongkai Wang",
      "Xiyao Xiao",
      "Yuqiang Xie",
      "Wen Zhang",
      "Yongkang Huang",
      "Yuxuan Chen",
      "Libiao Peng",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1279": {
    "title": "TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shahriar Kabir Nahin",
      "Rabindra Nath Nandi",
      "Sagor Sarker",
      "Quazi Sarwar Muhtaseem",
      "Md Kowsher",
      "Apu Chandraw Shill",
      "Md Ibrahim",
      "Mehadi Hasan Menon",
      "Tareq Al Muntasir",
      "Firoj Alam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1280": {
    "title": "WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Negar Foroutan",
      "Angelika Romanou",
      "Matin Ansaripour",
      "Julian Martin Eisenschlos",
      "Karl Aberer",
      "Rémi Lebret"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1281": {
    "title": "Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Robust and Instruction-Aware ASR and OCR",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chan-Jan Hsu",
      "Yi-Chang Chen",
      "Feng-Ting Liao",
      "Pei-Chen Ho",
      "Yu-Hsiang Wang",
      "Po-Chun Hsu",
      "Da-shan Shiu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1282": {
    "title": "HPSS: Heuristic Prompting Strategy Search for LLM Evaluators",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bosi Wen",
      "Pei Ke",
      "Yufei Sun",
      "Cunxiang Wang",
      "Xiaotao Gu",
      "Jinfeng Zhou",
      "Jie Tang",
      "Hongning Wang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1283": {
    "title": "A Fully Generative Motivational Interviewing Counsellor Chatbot for Moving Smokers Towards the Decision to Quit",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zafarullah Mahmood",
      "Soliman Ali",
      "Jiading Zhu",
      "Mohamed Abdelwahab",
      "Michelle Yu Collins",
      "Sihan Chen",
      "Yi Cheng Zhao",
      "Jodi Wolff",
      "Osnat C. Melamed",
      "Nadia Minian",
      "Marta Maslej",
      "Carolynne Cooper",
      "Matt Ratto",
      "Peter Selby",
      "Jonathan Rose"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1284": {
    "title": "LegalCore: A Dataset for Event Coreference Resolution in Legal Documents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangda Wei",
      "Xi Shi",
      "Jonathan Tong",
      "Sai Ramana Reddy",
      "Anandhavelu Natarajan",
      "Rajiv Jain",
      "Aparna Garimella",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1285": {
    "title": "Rectifying Belief Space via Unlearning to Harness LLMs' Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayana Niwa",
      "Masahiro Kaneko",
      "Kentaro Inui"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1286": {
    "title": "MemeDetoxNet: Balancing Toxicity Reduction and Context Preservation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gitanjali Kumari",
      "Jitendra Solanki",
      "Asif Ekbal"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1287": {
    "title": "Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wichayaporn Wongkamjan",
      "Yanze Wang",
      "Feng Gu",
      "Denis Peskoff",
      "Jonathan K. Kummerfeld",
      "Jonathan May",
      "Jordan Lee Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1288": {
    "title": "Multi-matrix Factorization Attention",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingcheng Hu",
      "Houyi Li",
      "Yinmin Zhang",
      "Zili Wang",
      "Shuigeng Zhou",
      "Xiangyu Zhang",
      "Heung-Yeung Shum"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1289": {
    "title": "Self-Training Elicits Concise Reasoning in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tergel Munkhbat",
      "Namgyu Ho",
      "Seo Hyun Kim",
      "Yongjin Yang",
      "Yujin Kim",
      "Se-Young Yun"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1290": {
    "title": "Reason from Future: Reverse Thought Chain Enhances LLM Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinlong Xu",
      "Yanzhao Zheng",
      "Shuoshuo Sun",
      "Shuaihan Huang",
      "Baohua Dong",
      "Zhu Hangcheng",
      "Ruohui Huang",
      "Gang Yu",
      "Hongxia Xu",
      "Jian Wu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1291": {
    "title": "LLMs as Planning Formalizers: A Survey for Leveraging Large Language Models to Construct Automated Planning Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcus Tantakoun",
      "Christian Muise",
      "Xiaodan Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1292": {
    "title": "From Conversation to Automation: Leveraging LLMs for Problem-Solving Therapy Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elham Aghakhani",
      "Lu Wang",
      "Karla T. Washington",
      "George Demiris",
      "Jina Huh-Yoo",
      "Rezvaneh Rezapour"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1293": {
    "title": "Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Li",
      "Ji Zhang",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Xinglin Wang",
      "Jiayi Shi",
      "Yueqi Zhang",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1294": {
    "title": "Don't Say No: Jailbreaking LLM by Suppressing Refusal",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukai Zhou",
      "Jian Lou",
      "Zhijie Huang",
      "Zhan Qin",
      "Sibei Yang",
      "Wenjie Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1295": {
    "title": "From Perception to Reasoning: Enhancing Vision-Language Models for Mobile UI Understanding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Settaluri Lakshmi Sravanthi",
      "Ankit Mishra",
      "Debjyoti Mondal",
      "Subhadarshi Panda",
      "Rituraj Singh",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1296": {
    "title": "Lemmas Matter, But Not Like That: Predictors of Lemma-Based Generalization in Morphological Inflection",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarah Ruth Brogden Payne",
      "Jordan Kodner"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1297": {
    "title": "Mosaic-IT: Cost-Free Compositional Data Synthesis for Instruction Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Li",
      "Pei Chen",
      "Chenguang Wang",
      "Hongyu Zhao",
      "Yijun Liang",
      "YuPeng Hou",
      "Fuxiao Liu",
      "Tianyi Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1298": {
    "title": "MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Zhou",
      "Lingran Song",
      "Jianbing Shen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1299": {
    "title": "ATLAS: Agent Tuning via Learning Critical Steps",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixun Chen",
      "Ming Li",
      "Yuxuan Huang",
      "Yali Du",
      "Meng Fang",
      "Tianyi Zhou"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1300": {
    "title": "Syntactic Control of Language Models by Posterior Inference",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vicky Xefteri",
      "Tim Vieira",
      "Ryan Cotterell",
      "Afra Amini"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1301": {
    "title": "Small Models Struggle to Learn from Strong Reasoners",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuetai Li",
      "Xiang Yue",
      "Zhangchen Xu",
      "Fengqing Jiang",
      "Luyao Niu",
      "Bill Yuchen Lin",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1302": {
    "title": "Sparse Rewards Can Self-Train Dialogue Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barrett Martin Lattimer",
      "Varun Prashant Gangal",
      "Ryan McDonald",
      "Yi Yang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1303": {
    "title": "Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shoumik Saha",
      "Soheil Feizi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1304": {
    "title": "The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillermo Marco",
      "Julio Gonzalo",
      "Víctor Fresno"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1305": {
    "title": "Summary Factual Inconsistency Detection Based on LLMs Enhanced by Universal Information Extraction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anguo Li",
      "Lei Yu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1306": {
    "title": "ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brihi Joshi",
      "Keyu He",
      "Sahana Ramnath",
      "Sadra Sabouri",
      "Kaitlyn Zhou",
      "Souti Chattopadhyay",
      "Swabha Swayamdipta",
      "Xiang Ren"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1307": {
    "title": "Beyond Generation: Leveraging LLM Creativity to Overcome Label Bias in Classification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyue Wang",
      "Xin Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1308": {
    "title": "CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xintong Wang",
      "Jingheng Pan",
      "Liang Ding",
      "Longyue Wang",
      "Longqin Jiang",
      "Xingshan Li",
      "Chris Biemann"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1309": {
    "title": "PASTEL : Polarity-Aware Sentiment Triplet Extraction with LLM-as-a-Judge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aaditya Bodke",
      "Avinoor Singh Kohli",
      "Hemant Subhash Pardeshi",
      "Prathamesh Bhosale"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1310": {
    "title": "COSMIC: Generalized Refusal Direction Identification in LLM Activations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Siu",
      "Nicholas Crispino",
      "Zihao Yu",
      "Sam Pan",
      "Zhun Wang",
      "Yang Liu",
      "Dawn Song",
      "Chenguang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1311": {
    "title": "Red Queen: Exposing Latent Multi-Turn Risks in Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Jiang",
      "Kriti Aggarwal",
      "Tanmay Laud",
      "Kashif Munir",
      "Jay Pujara",
      "Subhabrata Mukherjee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1312": {
    "title": "MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph J Peper",
      "Wenzhao Qiu",
      "Ali Payani",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1313": {
    "title": "DiaLLMs: EHR-Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijieying Ren",
      "Tianxiang Zhao",
      "Lei Wang",
      "Tianchun Wang",
      "Vasant G Honavar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1314": {
    "title": "Can Hallucination Correction Improve Video-Language Alignment?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingjun Zhao",
      "Mingyang Xie",
      "Paola Cascante-Bonilla",
      "Hal Daumé Iii",
      "Kwonjoon Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1315": {
    "title": "IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuke Sakai",
      "Takumi Goto",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1316": {
    "title": "Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenjun Xu",
      "Bingbing Wen",
      "Bin Han",
      "Robert Wolfe",
      "Lucy Lu Wang",
      "Bill Howe"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1317": {
    "title": "Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongsen Zheng",
      "Zongxuan Xie",
      "Guohua Wang",
      "Ziyao Liu",
      "Liang Lin",
      "Kwok-Yan Lam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1318": {
    "title": "Cautious Next Token Prediction",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhou Wang",
      "Lingzhi Zhang",
      "Yue Bai",
      "Mang Tik Chiu",
      "Zhengmian Hu",
      "Mingyuan Zhang",
      "Qihua Dong",
      "Yu Yin",
      "Sohrab Amirghodsi",
      "Yun Fu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1319": {
    "title": "Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Han",
      "Yaochen Xie",
      "Hui Liu",
      "Xianfeng Tang",
      "Sreyashi Nag",
      "William Headden",
      "Yang Li",
      "Chen Luo",
      "Shuiwang Ji",
      "Qi He",
      "Jiliang Tang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1320": {
    "title": "Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongda Sun",
      "Jiaren Peng",
      "Wenzhong Yang",
      "Liang He",
      "Bo Du",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1321": {
    "title": "Feature-Level Insights into Artificial Text Detection with Sparse Autoencoders",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kristian Kuznetsov",
      "Laida Kushnareva",
      "Anton Razzhigaev",
      "Polina Druzhinina",
      "Anastasia Voznyuk",
      "Irina Piontkovskaya",
      "Evgeny Burnaev",
      "Serguei Barannikov"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1322": {
    "title": "Low-Resource Grammatical Error Correction: Selective Data Augmentation with Round-Trip Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Frank Palma Gomez",
      "Alla Rozovskaya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1323": {
    "title": "Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hope Schroeder",
      "Deb Roy",
      "Jad Kabbara"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1324": {
    "title": "Research Community Perspectives on \"Intelligence\" and Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bertram Højer",
      "Terne Sasha Thorn Jakobsen",
      "Anna Rogers",
      "Stefan Heinrich"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1325": {
    "title": "LEMONADE: A Large Multilingual Expert-Annotated Abstractive Event Dataset for the Real World",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sina Semnani",
      "Pingyue Zhang",
      "Wanyue Zhai",
      "Haozhuo Li",
      "Ryan Beauchamp",
      "Trey Billing",
      "Katayoun Kishi",
      "Manling Li",
      "Monica Lam"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1326": {
    "title": "Memorization vs. Reasoning: Updating LLMs with New Knowledge",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aochong Oliver Li",
      "Tanya Goyal"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1327": {
    "title": "CourtEval: A Courtroom-Based Multi-Agent Evaluation Framework",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sandeep Kumar",
      "Abhijit A Nargund",
      "Vivek Sridhar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1328": {
    "title": "Multilingual Definition Modeling",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Edison Marrese-Taylor",
      "Erica K. Shimomoto",
      "A. Solano",
      "Enrique Reid"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1329": {
    "title": "Human Bias in the Face of AI: Examining Human Judgment Against Text Labeled as AI Generated",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiffany Zhu",
      "Iain Weissburg",
      "Kexun Zhang",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1330": {
    "title": "Redundancy, Isotropy, and Intrinsic Dimensionality of Prompt-based Text Embeddings",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hayato Tsukagoshi",
      "Ryohei Sasano"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1331": {
    "title": "Harnessing Whisper for Prosodic Stress Analysis",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel S. Sohn",
      "Sten Knutsen",
      "Karin Stromswold"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1332": {
    "title": "Can You Share Your Story? Modeling Clients' Metacognition and Openness for LLM Therapist Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minju Kim",
      "Dongje Yoo",
      "Yeonjun Hwang",
      "Minseok Kang",
      "Namyoung Kim",
      "Minju Gwak",
      "Beong-woo Kwak",
      "Hyungjoo Chae",
      "Harim Kim",
      "Yunjoong Lee",
      "Min Hee Kim",
      "Dayi Jung",
      "Kyong-Mee Chung",
      "Jinyoung Yeo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1333": {
    "title": "Dictionaries to the Rescue: Cross-Lingual Vocabulary Transfer for Low-Resource Languages Using Bilingual Dictionaries",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haruki Sakajo",
      "Yusuke Ide",
      "Justin Vasselli",
      "Yusuke Sakai",
      "Yingtao Tian",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1334": {
    "title": "When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting Out-of-Distribution Corpora Using GradNormIR",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayoon Ko",
      "Jinyoung Kim",
      "Sohyeon Kim",
      "Jinhyuk Kim",
      "Jaehoon Lee",
      "Seonghak Song",
      "Minyoung Lee",
      "Gunhee Kim"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1335": {
    "title": "The Million Authors Corpus: A Cross-Lingual and Cross-Domain Wikipedia Dataset for Authorship Verification",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abraham Israeli",
      "Shuai Liu",
      "Jonathan May",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1336": {
    "title": "BridG MT: Enhancing LLMs' Machine Translation Capabilities with Sentence Bridging and Gradual MT",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungwoo Choi",
      "Gahyun Yoo",
      "Jay-Yoon Lee"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1337": {
    "title": "Text2World: Benchmarking Large Language Models for Symbolic World Model Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengkang Hu",
      "Tianxing Chen",
      "Yude Zou",
      "Yuheng Lei",
      "Qiguang Chen",
      "Ming Li",
      "Yao Mu",
      "Hongyuan Zhang",
      "Wenqi Shao",
      "Ping Luo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1338": {
    "title": "Blinded by Context: Unveiling the Halo Effect of MLLM in AI Hiring",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyusik Kim",
      "Jeongwoo Ryu",
      "Hyeonseok Jeon",
      "Bongwon Suh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1339": {
    "title": "CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boxuan Zhang",
      "Ruqi Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1340": {
    "title": "ADO: Automatic Data Optimization for Inputs in LLM Prompts",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sam Lin",
      "Wenyue Hua",
      "Lingyao Li",
      "Zhenting Wang",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1341": {
    "title": "Large Language Models Still Exhibit Bias in Long Text",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonje Jeung",
      "Dongjae Jeon",
      "Ashkan Yousefpour",
      "Jonghyun Choi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1342": {
    "title": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiyue Gao",
      "Xinyu Pi",
      "Kevin Liu",
      "Junrong Chen",
      "Ruolan Yang",
      "Xinqi Huang",
      "Xinyu Fang",
      "Lu Sun",
      "Gautham Kishore",
      "Bo Ai",
      "Stone Tao",
      "Mengyang Liu",
      "Jiaxi Yang",
      "Chao-Jung Lai",
      "Chuanyang Jin",
      "Jiannan Xiang",
      "Benhao Huang",
      "Zeming Chen",
      "David Danks",
      "Hao Su",
      "Tianmin Shu",
      "Ziqiao Ma",
      "Lianhui Qin",
      "Zhiting Hu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1343": {
    "title": "Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivoline C. Ngong",
      "Swanand Ravindra Kadhe",
      "Hao Wang",
      "Keerthiram Murugesan",
      "Justin D. Weisz",
      "Amit Dhurandhar",
      "Karthikeyan Natesan Ramamurthy"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1344": {
    "title": "Enhancing Persona Consistency for LLMs' Role-Playing using Persona-Aware Contrastive Learning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Ji",
      "Yixin Lian",
      "Linxu Li",
      "Jingsheng Gao",
      "Weiyuan Li",
      "Bin Dai"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1345": {
    "title": "M2-TabFact: Multi-Document Multi-Modal Fact Verification with Visual and Textual Representations of Tabular Data",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyang Zhou",
      "Lingyu Zhang",
      "Sophia Horng",
      "Maximillian Chen",
      "Kung-Hsiang Huang",
      "Shih-Fu Chang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1346": {
    "title": "Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Holsman",
      "Yukun Huang",
      "Bhuwan Dhingra"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1347": {
    "title": "PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Fang",
      "Yang Zhang",
      "Kaizhi Qian",
      "James R. Glass",
      "Yada Zhu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1348": {
    "title": "Towards the Pedagogical Steering of Large Language Models for Tutoring: A Case Study with Modeling Productive Failure",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Romain Puech",
      "Jakub Macina",
      "Julia Chatain",
      "Mrinmaya Sachan",
      "Manu Kapur"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1349": {
    "title": "Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jisu Shin",
      "Juhyun Oh",
      "Eunsu Kim",
      "Hoyun Song",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1350": {
    "title": "What Language Do Non-English-Centric Large Language Models Think in?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengzhi Zhong",
      "Qianying Liu",
      "Fei Cheng",
      "Junfeng Jiang",
      "Zhen Wan",
      "Chenhui Chu",
      "Yugo Murawaki",
      "Sadao Kurohashi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1351": {
    "title": "T5Score: A Methodology for Automatically Assessing the Quality of LLM Generated Multi-Document Topic Sets",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Itamar Trainin",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1352": {
    "title": "Uncertainty-Aware Contrastive Decoding",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hakyung Lee",
      "Subeen Park",
      "Joowang Kim",
      "Sungjun Lim",
      "Kyungwoo Song"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1353": {
    "title": "GEMS: Generation-Based Event Argument Extraction via Multi-perspective Prompts and Ontology Steering",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Run Lin",
      "Yao Liu",
      "Yanglei Gan",
      "Yuxiang Cai",
      "Tian Lan",
      "Qiao Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1354": {
    "title": "RomanLens: The Role Of Latent Romanization In Multilinguality In LLMs",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alan Saji",
      "Jaavid Aktar Husain",
      "Thanmay Jayakumar",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Ratish Puduppully"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1355": {
    "title": "7 Points to Tsinghua but 10 Points to ? Assessing Large Language Models in Agentic Multilingual National Bias",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianying Liu",
      "Katrina Qiyao Wang",
      "Fei Cheng",
      "Sadao Kurohashi"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1356": {
    "title": "Search-in-Context: Efficient Multi-Hop QA over Long Contexts via Monte Carlo Tree Search with Dynamic KV Retrieval",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiabei Chen",
      "Guang Liu",
      "Shizhu He",
      "Kun Luo",
      "Yao Xu",
      "Jun Zhao",
      "Kang Liu"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1357": {
    "title": "LLM-as-an-Interviewer: Beyond Static Testing Through Dynamic LLM Evaluation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunsu Kim",
      "Juyoung Suk",
      "Seungone Kim",
      "Niklas Muennighoff",
      "Dongkwan Kim",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1358": {
    "title": "IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinjie Zhang",
      "Wenxuan Wang",
      "Qin Jin"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1359": {
    "title": "Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gerard Christopher Yeo",
      "Kokil Jaidka"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1360": {
    "title": "CSTRL: Context-Driven Sequential Transfer Learning for Abstractive Radiology Report Summarization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mst. Fahmida Sultana Naznin",
      "Adnan Ibney Faruq",
      "Mostafa Rifat Tazwar",
      "Md Jobayer",
      "Md. Mehedi Hasan Shawon",
      "Md Rakibul Hasan"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1361": {
    "title": "Rethinking Prompt-based Debiasing in Large Language Model",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyi Yang",
      "Runzhe Zhan",
      "Shu Yang",
      "Junchao Wu",
      "Lidia S. Chao",
      "Derek F. Wong"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1362": {
    "title": "Exploring In-context Example Generation for Machine Translation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dohyun Lee",
      "Seungil Chad Lee",
      "Chanwoo Yang",
      "Yujin Baek",
      "Jaegul Choo"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1363": {
    "title": "Knowledge Base Construction for Knowledge-Augmented Text-to-SQL",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinheon Baek",
      "Horst Samulowitz",
      "Oktie Hassanzadeh",
      "Dharmashankar Subramanian",
      "Sola Shirai",
      "Alfio Gliozzo",
      "Debarun Bhattacharjya"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1364": {
    "title": "NBDESCRIB: A Dataset for Text Description Generation from Tables and Code in Jupyter Notebooks with Guidelines",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuye Liu",
      "Tengfei Ma",
      "Yimu Wang",
      "Fengjie Wang",
      "Jian Zhao"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1365": {
    "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeonseok Jeong",
      "Jinsu Kim",
      "Dohyeon Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1366": {
    "title": "From Complexity to Clarity: AI/NLP's Role in Regulatory Compliance",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jivitesh Jain",
      "Nivedhitha Dhanasekaran",
      "Mona T. Diab"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1367": {
    "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunjong Kim",
      "Sangyeop Kim",
      "Jongheon Jeong",
      "Yeongjae Cho",
      "Sungzoon Cho"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1368": {
    "title": "Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eitan Wagner",
      "Nitay Alon",
      "Joseph M Barnby",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1369": {
    "title": "LLMs are Biased Evaluators But Not Biased for Fact-Centric Retrieval Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yen-Shan Chen",
      "Jing Jin",
      "Peng-Ting Kuo",
      "Chao-Wei Huang",
      "Yun-Nung Chen"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1370": {
    "title": "Standard Quality Criteria Derived from Current NLP Evaluations for Guiding Evaluation Design and Grounding Comparability and AI Compliance Assessments",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anya Belz",
      "Simon Mille",
      "Craig Thomson"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1371": {
    "title": "skLEP: A Slovak General Language Understanding Benchmark",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marek Suppa",
      "Andrej Ridzik",
      "Daniel Hládek",
      "Tomáš Javůrek",
      "Viktória Ondrejová",
      "Kristína Sásiková",
      "Martin Tamajka",
      "Marian Simko"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1372": {
    "title": "Can Vision Language Models Understand Mimed Actions?",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyundong Justin Cho",
      "Spencer Lin",
      "Tejas Srinivasan",
      "Michael Saxon",
      "Deuksin Kwon",
      "Natali T. Chavez",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1373": {
    "title": "Training Language Model to Critique for Better Refinement",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshu Yu",
      "Chao Xiang",
      "Mingchuan Yang",
      "Pei Ke",
      "Bosi Wen",
      "Cunxiang Wang",
      "Jiale Cheng",
      "Li Zhang",
      "Xinyu Mu",
      "Chuxiong Sun",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1374": {
    "title": "Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peiyi Zhang",
      "Richong Zhang",
      "Zhijie Nie",
      "Ziqiao Wang"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1375": {
    "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyochul Jang",
      "Donghyeon Lee",
      "Kyusik Kim",
      "Dongseok Heo",
      "Taewhoo Lee",
      "Woojeong Kim",
      "Bongwon Suh"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1376": {
    "title": "HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyu Guo",
      "Xunlei Chen",
      "Qiyang Xia",
      "Zhaokun Wang",
      "Jie Ou",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1377": {
    "title": "A Constrained Text Revision Agent via Iterative Planning and Searching",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hannan Cao",
      "Hwee Tou Ng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1378": {
    "title": "MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gio Paik",
      "Geewook Kim",
      "Jinbae Im"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1379": {
    "title": "How Programming Concepts and Neurons Are Shared in Code Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Hossein Kargaran",
      "Yihong Liu",
      "François Yvon",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1380": {
    "title": "DynaQuest: A Dynamic Question Answering Dataset Reflecting Real-World Knowledge Updates",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Lin",
      "Junyi Li",
      "Hwee Tou Ng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1381": {
    "title": "ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ekaterina Grishina",
      "Mikhail Gorbunov",
      "Maxim Rakhuba"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1382": {
    "title": "Revisiting In-Context Learning with Long Context Language Models",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinheon Baek",
      "Sun Jae Lee",
      "Prakhar Gupta",
      "Geunseob Oh",
      "Siddharth Dalmia",
      "Prateek Kolhar"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1383": {
    "title": "Rationalize and Align: Enhancing Writing Assistance with Rationale via Self-Training for Improved Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hannan Cao",
      "Hai Ye",
      "Hwee Tou Ng"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1384": {
    "title": "Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ou",
      "Jinyu Guo",
      "Shuaihong Jiang",
      "Zhaokun Wang",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1385": {
    "title": "MEXA: Multilingual Evaluation of English-Centric LLMs via Cross-Lingual Alignment",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Hossein Kargaran",
      "Ali Modarressi",
      "Nafiseh Nikeghbal",
      "Jana Diesner",
      "François Yvon",
      "Hinrich Schuetze"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1386": {
    "title": "Automated Fine-Grained Mixture-of-Experts Quantization",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanhao Xie",
      "Yuexiao Ma",
      "Xiawu Zheng",
      "Fei Chao",
      "Wanchen Sui",
      "Yong Li",
      "Shen Li",
      "Rongrong Ji"
    ]
  },
  "https://aclanthology.org/2025.findings-acl.1387": {
    "title": "Enhancing Complex Reasoning in Knowledge Graph Question Answering through Query Graph Approximation",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjun Jeong",
      "Minji Kim",
      "Heesoo Jung",
      "Ko Keun Kim",
      "Hogun Park"
    ]
  }
}