{
  "https://openreview.net/forum?id=NnMEadcdyD": {
    "title": "Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation",
    "volume": "oral",
    "abstract": "To achieve the highest perceptual quality, state-of-the-art diffusion models are optimized with objectives that typically look very different from the maximum likelihood and the Evidence Lower Bound (ELBO) objectives. In this work, we reveal that diffusion model objectives are actually closely related to the ELBO. Specifically, we show that all commonly used diffusion model objectives equate to a weighted integral of ELBOs over different noise levels, where the weighting depends on the specific objective used. Under the condition of monotonic weighting, the connection is even closer: the diffusion objective then equals the ELBO, combined with simple data augmentation, namely Gaussian noise perturbation. We show that this condition holds for a number of state-of-the-art diffusion models. In experiments, we explore new monotonic weightings and demonstrate their effectiveness, achieving state-of-the-art FID scores on the high-resolution ImageNet benchmark",
    "checked": true,
    "id": "11c8911f787eed34e6f058d5d36287d45c54c961",
    "semantic_title": "understanding diffusion objectives as the elbo with simple data augmentation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=TXoZiUZywf": {
    "title": "Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures",
    "volume": "oral",
    "abstract": "We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used \"optimism in the face of uncertainty\" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confidence sequences give improved performance in several hyperparameter tuning tasks",
    "checked": true,
    "id": "12489f8e157ef9e5b28a202f6b7444f232a3dd89",
    "semantic_title": "improved algorithms for stochastic linear bandits using tail bounds for martingale mixtures",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KvPwXVcslY": {
    "title": "Spatial-frequency channels, shape bias, and adversarial robustness",
    "volume": "oral",
    "abstract": "What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or \"channel\") that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. Unlike humans, the neural network channel is very broad, 2-4 times wider than the human channel. This means that the network channel extends to frequencies higher and lower than those that humans are sensitive to. Thus, noise at those frequencies will impair network performance and spare human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (51% variance explained) and robustness of adversarially-trained networks (66% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further beyond the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only makes it worse. Networks with narrower channels might be more robust",
    "checked": true,
    "id": "83991e8da386c581396aed9134fe8a470cec3f8a",
    "semantic_title": "spatial-frequency channels, shape bias, and adversarial robustness",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=AOKU4nRw1W": {
    "title": "Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment",
    "volume": "oral",
    "abstract": "Text-conditioned image generation models often generate incorrect associations between entities and their visual attributes. This reflects an impaired mapping between linguistic binding of entities and modifiers in the prompt and visual binding of the corresponding elements in the generated image. As one example, a query like ``a pink sunflower and a yellow flamingo'' may incorrectly produce an image of a yellow sunflower and a pink flamingo. To remedy this issue, we propose SynGen, an approach which first syntactically analyses the prompt to identify entities and their modifiers, and then uses a novel loss function that encourages the cross-attention maps to agree with the linguistic binding reflected by the syntax. Specifically, we encourage large overlap between attention maps of entities and their modifiers, and small overlap with other entities and modifier words. The loss is optimized during inference, without retraining or fine-tuning the model. Human evaluation on three datasets, including one new and challenging set, demonstrate significant improvements of SynGen compared with current state of the art methods. This work highlights how making use of sentence structure during inference can efficiently and substantially improve the faithfulness of text-to-image generation",
    "checked": true,
    "id": "9e8648550fbec45dc712eb084251807b6c44e1e4",
    "semantic_title": "linguistic binding in diffusion models: enhancing attribute correspondence through attention map alignment",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=jDIlzSU8wJ": {
    "title": "The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation",
    "volume": "oral",
    "abstract": "Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity. We show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. Compared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth. With self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. Extensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26\\% on the KITTI optical flow benchmark, about 25\\% better than the best published method",
    "checked": true,
    "id": "842182174ebd9e070101c85aa16c0818e5363c42",
    "semantic_title": "the surprising effectiveness of diffusion models for optical flow and monocular depth estimation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=HPuSIXJaa9": {
    "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model",
    "volume": "oral",
    "abstract": "While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train",
    "checked": true,
    "id": "0d1c76d45afa012ded7ab741194baf142117c495",
    "semantic_title": "direct preference optimization: your language model is secretly a reward model",
    "citation_count": 127,
    "authors": []
  },
  "https://openreview.net/forum?id=sW8yGZ4uVJ": {
    "title": "Ordering-based Conditions for Global Convergence of Policy Gradient Methods",
    "volume": "oral",
    "abstract": "We prove that, for finite-arm bandits with linear function approximation, the global convergence of policy gradient (PG) methods depends on inter-related properties between the policy update and the representation. textcolor{blue}{First}, we establish a few key observations that frame the study: \\textbf{(i)} Global convergence can be achieved under linear function approximation without policy or reward realizability, both for the standard Softmax PG and natural policy gradient (NPG). \\textbf{(ii)} Approximation error is not a key quantity for characterizing global convergence in either algorithm. \\textbf{(iii)} The conditions on the representation that imply global convergence are different between these two algorithms. Overall, these observations call into question approximation error as an appropriate quantity for characterizing the global convergence of PG methods under linear function approximation. \\textcolor{blue}{Second}, motivated by these observations, we establish new general results: \\textbf{(i)} NPG with linear function approximation achieves global convergence \\emph{if and only if} the projection of the reward onto the representable space preserves the optimal action's rank, a quantity that is not strongly related to approximation error. \\textbf{(ii)} The global convergence of Softmax PG occurs if the representation satisfies a non-domination condition and can preserve the ranking of rewards, which goes well beyond policy or reward realizability. We provide experimental results to support these theoretical findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Kv8GJkV19S": {
    "title": "Tester-Learners for Halfspaces: Universal Algorithms",
    "volume": "oral",
    "abstract": "We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\\mathrm{opt}) + \\epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincare inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincare distributions includes all strongly log-concave distributions, and, assuming the Kannan--Lovasz--Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\\mathrm{opt} + \\epsilon$ while accepting all log-concave distributions unconditionally (without assuming KLS). Our tests rely on checking hypercontractivity of the unknown distribution using a sum-of-squares (SOS) program, and crucially make use of the fact that Poincare distributions are certifiably hypercontractive in the SOS framework",
    "checked": true,
    "id": "6e86f984b0f17e1902f766ccc9f65047b50575a8",
    "semantic_title": "tester-learners for halfspaces: universal algorithms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IwnINorSZ5": {
    "title": "Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "volume": "oral",
    "abstract": "We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based \"meta-learners\" that can provide point estimates of the conditional average treatment effect (CATE)—these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo-outcome) conformity scores stochastically dominate \"oracle\" conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners",
    "checked": true,
    "id": "98f8818bf1bdbfa59863550c691f3edcd42abb0e",
    "semantic_title": "conformal meta-learners for predictive inference of individual treatment effects",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mmTy1iyU5G": {
    "title": "Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Method",
    "volume": "oral",
    "abstract": "Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions. In this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. As a byproduct of our analysis we introduce a novel regularization process over vanilla gradient descent and provide theoretical and experimental evidence that it helps address vanishing-gradient issues and escape bad stationary points",
    "checked": false,
    "id": "c5fe40da42a4df3b58ab2a4204922dcf76368053",
    "semantic_title": "optimizing solution-samplers for combinatorial problems: the landscape of policy-gradient methods",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pe9WxkN8Ff": {
    "title": "Learning Transformer Programs",
    "volume": "oral",
    "abstract": "Recent research in mechanistic interpretability has attempted to reverse-engineer Transformer models by carefully inspecting network weights and activations. However, these approaches require considerable manual effort and still fall short of providing complete, faithful descriptions of the underlying algorithms. In this work, we introduce a procedure for training Transformers that are mechanistically interpretable by design. We build on RASP [Weiss et al., 2021], a programming language that can be compiled into Transformer weights. Instead of compiling human-written programs into Transformers, we design a modified Transformer that can be trained using gradient-based optimization and then automatically converted into a discrete, human-readable program. We refer to these models as Transformer Programs. To validate our approach, we learn Transformer Programs for a variety of problems, including an in-context learning task, a suite of algorithmic problems (e.g. sorting, recognizing Dyck languages), and NLP tasks including named entity recognition and text classification. The Transformer Programs can automatically find reasonable solutions, performing on par with standard Transformers of comparable size; and, more importantly, they are easy to interpret. To demonstrate these advantages, we convert Transformers into Python programs and use off-the-shelf code analysis tools to debug model errors and identify the \"circuits\" used to solve different sub-problems. We hope that Transformer Programs open a new path toward the goal of intrinsically interpretable machine learning",
    "checked": true,
    "id": "6cb8bc7398ffcd27c500fb743cf72c84cfe4df8d",
    "semantic_title": "learning transformer programs",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=n84bzMrGUD": {
    "title": "Clifford Group Equivariant Neural Networks",
    "volume": "oral",
    "abstract": "We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing $\\mathrm{O}(n)$- and $\\mathrm{E}(n)$-equivariant models. We identify and study the *Clifford group*: a subgroup inside the Clifford algebra tailored to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, including their grade projections, constitutes an equivariant map with respect to the Clifford group, allowing us to parameterize equivariant neural network layers. An advantage worth mentioning is that we obtain expressive layers that can elegantly generalize to inner-product spaces of any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional $n$-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment",
    "checked": true,
    "id": "56c679a0d5fce962e1c09db6d762e4024e277450",
    "semantic_title": "clifford group equivariant neural networks",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=q131tA7HCT": {
    "title": "Learning Linear Causal Representations from Interventions under General Nonlinear Mixing",
    "volume": "oral",
    "abstract": "We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of identifiability from non-paired interventions for deep neural network embeddings and general causal structures. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks",
    "checked": true,
    "id": "5a7a0dd32646fe41db24d8e973adb920c911bd1b",
    "semantic_title": "learning linear causal representations from interventions under general nonlinear mixing",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=RSGNGiB1q4": {
    "title": "How to Turn Your Knowledge Graph Embeddings into Generative Models",
    "volume": "oral",
    "abstract": "Some of the most successful knowledge graph embedding (KGE) models for link prediction – CP, RESCAL, TuckER, ComplEx – can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits – constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities",
    "checked": false,
    "id": "4145d0fd4e8c8ed87786c34ee8d363887994607b",
    "semantic_title": "how to turn your knowledge graph embeddings into generative models via probabilistic circuits",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=fg7iyNK81W": {
    "title": "Rotating Features for Object Discovery",
    "volume": "oral",
    "abstract": "The binding problem in human cognition, concerning how the brain represents and connects objects within a fixed network of neural connections, remains a subject of intense debate. Most machine learning efforts addressing this issue in an unsupervised setting have focused on slot-based methods, which may be limiting due to their discrete nature and difficulty to express uncertainty. Recently, the Complex AutoEncoder was proposed as an alternative that learns continuous and distributed object-centric representations. However, it is only applicable to simple toy data. In this paper, we present Rotating Features, a generalization of complex-valued features to higher dimensions, and a new evaluation procedure for extracting objects from distributed representations. Additionally, we show the applicability of our approach to pre-trained features. Together, these advancements enable us to scale distributed object-centric representations from simple toy to real-world data. We believe this work advances a new paradigm for addressing the binding problem in machine learning and has the potential to inspire further innovation in the field",
    "checked": true,
    "id": "71ab2cb732d7664b831c2d55df2777d9fc3ffeed",
    "semantic_title": "rotating features for object discovery",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QzcZb3fWmW": {
    "title": "Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity",
    "volume": "oral",
    "abstract": "Current deep-learning models for object recognition are known to be heavily biased toward texture. In contrast, human visual systems are known to be biased toward shape and structure. What could be the design principles in human visual systems that led to this difference? How could we introduce more shape bias into the deep learning models? In this paper, we report that sparse coding, a ubiquitous principle in the brain, can in itself introduce shape bias into the network. We found that enforcing the sparse coding constraint using a non-differential Top-K operation can lead to the emergence of structural encoding in neurons in convolutional neural networks, resulting in a smooth decomposition of objects into parts and subparts and endowing the networks with shape bias. We demonstrated this emergence of shape bias and its functional benefits for different network structures with various datasets. For object recognition convolutional neural networks, the shape bias leads to greater robustness against style and pattern change distraction. For the image synthesis generative adversary networks, the emerged shape bias leads to more coherent and decomposable structures in the synthesized images. Ablation studies suggest that sparse codes tend to encode structures, whereas the more distributed codes tend to favor texture. Our code is host at the github repository: \\url{https://github.com/Crazy-Jack/nips2023_shape_vs_texture}",
    "checked": true,
    "id": "19ced7981353499ff113b88d04d2e0bbdbe6962b",
    "semantic_title": "emergence of shape bias in convolutional neural networks through activation sparsity",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=1zo4iioUEs": {
    "title": "DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative Diffusion Models",
    "volume": "oral",
    "abstract": "Nature evolves creatures with a high complexity of morphological and behavioral intelligence, meanwhile computational methods lag in approaching that diversity and efficacy. Co-optimization of artificial creatures' morphology and control in silico shows promise for applications in physical soft robotics and virtual character creation; such approaches, however, require developing new learning algorithms that can reason about function atop pure structure. In this paper, we present DiffuseBot, a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks. \\name bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and (ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation. We showcase a range of simulated and fabricated robots along with their capabilities. Check our website: https://diffusebot.github.io/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cB0BImqSS9": {
    "title": "Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture",
    "volume": "oral",
    "abstract": "Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance. However, existing architectures such as Transformers scale quadratically along both these axes. We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension? We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension: Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically. As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling. For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters. Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck. To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic. Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE—showing for the first time that it may be possible to match Transformer quality without attention or MLPs",
    "checked": true,
    "id": "c85268696fe1435605ae66a18653cfdcf8153753",
    "semantic_title": "monarch mixer: a simple sub-quadratic gemm-based architecture",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=OUIFPHEgJU": {
    "title": "QLoRA: Efficient Finetuning of Quantized LLMs",
    "volume": "oral",
    "abstract": "We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information-theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small, high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations, showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training",
    "checked": true,
    "id": "32ac52069e562d4f900afee70bdca63f53461481",
    "semantic_title": "qlora: efficient finetuning of quantized llms",
    "citation_count": 238,
    "authors": []
  },
  "https://openreview.net/forum?id=PITeSdYQkv": {
    "title": "User-Level Differential Privacy With Few Examples Per User",
    "volume": "oral",
    "abstract": "Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the *example-rich* regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the *example-scarce* regime, where each user has only a few examples, and obtain the following results: * For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\\varepsilon,\\delta}(\\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning. * For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry & Talwar, FOCS 2007] to the user-level setting. This gives new bounds for a variety of tasks, such as private PAC learning, hypothesis selection, and distribution learning. For some of these problems, we show that our bounds are near-optimal",
    "checked": true,
    "id": "e126f66778f5a790378d693bf4138ee0714d92f6",
    "semantic_title": "user-level differential privacy with few examples per user",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=rcXXNFVlEn": {
    "title": "Why think step by step? Reasoning emerges from the locality of experience",
    "volume": "oral",
    "abstract": "Humans have a powerful and mysterious capacity to reason. Working through a set of mental steps enables us to make inferences we would not be capable of making directly even though we get no additional data from the world. Similarly, when large language models generate intermediate steps (a chain of thought) before answering a question, they often produce better answers than they would directly. We investigate why and how chain-of-thought reasoning is useful in language models, testing the hypothesis that reasoning is effective when training data consists of overlapping local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences to estimate relationships between variables that were not seen together in training. We prove that there will exist a \"reasoning gap\", where reasoning through intermediate variables reduces bias, for the simple case of an autoregressive density estimator trained on local samples from a chain-structured probabilistic model. We then test our hypothesis experimentally in more complex models, training an autoregressive language model on samples from Bayes nets but only including a subset of variables in each sample. We test language models' ability to match conditional probabilities with and without intermediate reasoning steps, finding that intermediate steps are only helpful when the training data is locally structured with respect to dependencies between variables. The combination of locally structured observations and reasoning is much more data-efficient than training on all variables. Our results illustrate how the effectiveness of reasoning step by step is rooted in the local statistical structure of the training data",
    "checked": false,
    "id": "9a3edb5c6b0e8c84c94ea99a9ab647b1209f650f",
    "semantic_title": "why think step-by-step? reasoning emerges from the locality of experience",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=9VqMaSjf7U": {
    "title": "Brain Diffusion for Visual Exploration: Cortical Discovery using Large Scale Generative Models",
    "volume": "oral",
    "abstract": "A long standing goal in neuroscience has been to elucidate the functional organization of the brain. Within higher visual cortex, functional accounts have remained relatively coarse, focusing on regions of interest (ROIs) and taking the form of selectivity for broad categories such as faces, places, bodies, food, or words. Because the identification of such ROIs has typically relied on manually assembled stimulus sets consisting of isolated objects in non-ecological contexts, exploring functional organization without robust a priori hypotheses has been challenging. To overcome these limitations, we introduce a data-driven approach in which we synthesize images predicted to activate a given brain region using paired natural images and fMRI recordings, bypassing the need for category-specific stimuli. Our approach -- Brain Diffusion for Visual Exploration (\"BrainDiVE\") -- builds on recent generative methods by combining large-scale diffusion models with brain-guided image synthesis. Validating our method, we demonstrate the ability to synthesize preferred images with appropriate semantic specificity for well-characterized category-selective ROIs. We then show that BrainDiVE can characterize differences between ROIs selective for the same high-level category. Finally we identify novel functional subdivisions within these ROIs, validated with behavioral data. These results advance our understanding of the fine-grained functional organization of human visual cortex, and provide well-specified constraints for further examination of cortical organization using hypothesis-driven methods",
    "checked": true,
    "id": "a0fdf9b4823a1105fa9e15862e01d262a84337ce",
    "semantic_title": "brain diffusion for visual exploration: cortical discovery using large scale generative models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ITw9edRDlD": {
    "title": "Are Emergent Abilities of Large Language Models a Mirage?",
    "volume": "oral",
    "abstract": "Recent work claims that large language models display \\textit{emergent abilities}, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their \\textit{sharpness}, transitioning seemingly instantaneously from not present to present, and their \\textit{unpredictability}, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due the researcher's choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models",
    "checked": true,
    "id": "29c7f009df21d0112c48dec254ff80cc45fac3af",
    "semantic_title": "are emergent abilities of large language models a mirage?",
    "citation_count": 76,
    "authors": []
  },
  "https://openreview.net/forum?id=R6KJN1AUAR": {
    "title": "Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation",
    "volume": "oral",
    "abstract": "We tackle the problems of latent variables identification and \"out-of-support'' image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can generate novel images by recombining observed factors of variations in novel ways, an ability we refer to as Cartesian-product extrapolation. We show empirically that additivity is crucial for both identifiability and extrapolation on simulated data",
    "checked": true,
    "id": "dfe6e29e0b441ab417e847f6a09a7db5b559f9a7",
    "semantic_title": "additive decoders for latent variables identification and cartesian-product extrapolation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Vota6rFhBQ": {
    "title": "Fine-Tuning Language Models with Just Forward Passes",
    "volume": "oral",
    "abstract": "Fine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12× memory reduction and up to 2× GPU-hour reduction in our implementation; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise",
    "checked": true,
    "id": "ad4b365630f1c13d74d78f0f5d8cee87ef356d41",
    "semantic_title": "fine-tuning language models with just forward passes",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=27TdrEvqLD": {
    "title": "Going beyond persistent homology using persistent homology",
    "volume": "oral",
    "abstract": "Representational limits of message-passing graph neural networks (MP-GNNs), e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well understood. Augmenting these graph models with topological features via persistent homology (PH) has gained prominence, but identifying the class of attributed graphs that PH can recognize remains open. We introduce a novel concept of color-separating sets to provide a complete resolution to this important problem. Specifically, we establish the necessary and sufficient conditions for distinguishing graphs based on the persistence of their connected components, obtained from filter functions on vertex and edge colors. Our constructions expose the limits of vertex- and edge-level PH, proving that neither category subsumes the other. Leveraging these theoretical insights, we propose RePHINE for learning topological features on graphs. RePHINE efficiently combines vertex- and edge-level PH, achieving a scheme that is provably more powerful than both. Integrating RePHINE into MP-GNNs boosts their expressive power, resulting in gains over standard PH on several benchmarks for graph classification",
    "checked": true,
    "id": "3a28fee7ca840c8711bbf785309c4f90445ecf6e",
    "semantic_title": "going beyond persistent homology using persistent homology",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w116w62fxH": {
    "title": "Optimal Learners for Realizable Regression: PAC Learning and Online Learning",
    "volume": "oral",
    "abstract": "In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting. Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context. Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22",
    "checked": true,
    "id": "69b212f2a411450cf522eb100027c13e5b179f18",
    "semantic_title": "optimal learners for realizable regression: pac learning and online learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=oML3v2cFg2": {
    "title": "When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning",
    "volume": "oral",
    "abstract": "Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncertainty of the estimated model of the world. We propose a new algorithmic framework to solve the bi-level optimization problem formulation and provide statistical and computational guarantees of performance for the associated optimal reward estimator. Finally, we demonstrate that the proposed algorithm outperforms the state-of-the-art offline IRL and imitation learning benchmarks by a large margin, over the continuous control tasks in MuJoCo and different datasets in the D4RL benchmark",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Lr2swAfwff": {
    "title": "Bridging RL Theory and Practice with the Effective Horizon",
    "volume": "oral",
    "abstract": "Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the *random* policy also have the highest Q-values under the *optimal* policy—i.e., when it is optimal to act greedily with respect to the random's policy Q function—deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the *effective horizon*, which roughly corresponds to how many steps of lookahead search would be needed in that MDP in order to identify the next optimal action, when leaf nodes are evaluated with random rollouts. Using BRIDGE, we show that the effective horizon-based bounds are more closely reflective of the empirical performance of PPO and DQN than prior sample complexity bounds across four metrics. We also show that, unlike existing bounds, the effective horizon can predict the effects of using reward shaping or a pre-trained exploration policy. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon",
    "checked": true,
    "id": "a7159fed957889d7d7b7762e29cd7d14c88ddbb0",
    "semantic_title": "bridging rl theory and practice with the effective horizon",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=a2Yg9Za6Rb": {
    "title": "Students Parrot Their Teachers: Membership Inference on Model Distillation",
    "volume": "oral",
    "abstract": "Model distillation is frequently proposed as a technique to reduce the privacy leakage of machine learning. These empirical privacy defenses rely on the intuition that distilled ``student'' models protect the privacy of training data, as they only interact with this data indirectly through a ``teacher'' model. In this work, we design membership inference attacks to systematically study the privacy provided by knowledge distillation to both the teacher and student training sets. Our new attacks show that distillation alone provides only limited privacy across a number of domains. We explain the success of our attacks on distillation by showing that membership inference attacks on a private dataset can succeed even if the target model is never queried on any actual training points, but only on inputs whose predictions are highly influenced by training data. Finally, we show that our attacks are strongest when student and teacher sets are similar, or when the attacker can poison the teacher set",
    "checked": true,
    "id": "1aa9c50a52537bdac9b1edf9f9399155ec16eee0",
    "semantic_title": "students parrot their teachers: membership inference on model distillation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=dVnhdm9MIg": {
    "title": "Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language",
    "volume": "oral",
    "abstract": "A core tension in models of concept learning is that the model must carefully balance the tractability of inference against the expressivity of the hypothesis class. Humans, however, can efficiently learn a broad range of concepts. We introduce a model of inductive learning that seeks to be human-like in that sense. It implements a Bayesian reasoning process where a language model first proposes candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood. By estimating the prior from human data, we can predict human judgments on learning problems involving numbers and sets, spanning concepts that are generative, discriminative, propositional, and higher-order",
    "checked": true,
    "id": "1a3ba6662ef1c5aebd3b343d3d9f77a8543e474d",
    "semantic_title": "human-like few-shot learning via bayesian reasoning over natural language",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=yC3q7vInux": {
    "title": "Siamese Masked Autoencoders",
    "volume": "oral",
    "abstract": "Establishing correspondence between images or scenes is a significant challenge in computer vision, especially given occlusions, viewpoint changes, and varying object appearances. In this paper, we present Siamese Masked Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for learning visual correspondence from videos. SiamMAE operates on pairs of randomly sampled video frames and asymmetrically masks them. These frames are processed independently by an encoder network, and a decoder composed of a sequence of cross-attention layers is tasked with predicting the missing patches in the future frame. By masking a large fraction (95%) of patches in the future frame while leaving the past frame unchanged, SiamMAE encourages the network to focus on object motion and learn object-centric representations. Despite its conceptual simplicity, features learned via SiamMAE outperform state-of-the-art self-supervised methods on video object segmentation, pose keypoint propagation, and semantic part propagation tasks. SiamMAE achieves competitive results without relying on data augmentation, handcrafted tracking-based pretext tasks, or other techniques to prevent representational collapse",
    "checked": true,
    "id": "f04a8d11f8752a230d58ff792d529fe342f75104",
    "semantic_title": "siamese masked autoencoders",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Sf9goJtTCE": {
    "title": "Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent",
    "volume": "oral",
    "abstract": "Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves state-of-the-art performance on sufficiently large-scale or ill-conditioned regression tasks. Its uncertainty estimates match the performance of significantly more expensive baselines on a large-scale Bayesian~optimization~task",
    "checked": true,
    "id": "c720a3de1ae4293b16ca295f01e7a944feb49dc2",
    "semantic_title": "sampling from gaussian process posteriors using stochastic gradient descent",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Dkmpa6wCIx": {
    "title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization",
    "volume": "oral",
    "abstract": "Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize poorly, and (3) perhaps most strikingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve better generalization. This calls for the search for other explanations for the generalization of over-parameterized neural networks",
    "checked": true,
    "id": "0c311d188f2708e2f3a90ac03cfdd68c5523009b",
    "semantic_title": "sharpness minimization algorithms do not only minimize sharpness to achieve better generalization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=rybsHQ4DXy": {
    "title": "EgoEnv: Human-centric environment representations from egocentric video",
    "volume": "oral",
    "abstract": "First-person video highlights a camera-wearer's activities in the context of their persistent environment. However, current video understanding approaches reason over visual features from short video clips that are detached from the underlying physical space and capture only what is immediately visible. To facilitate human-centric environment understanding, we present an approach that links egocentric video and the environment by learning representations that are predictive of the camera-wearer's (potentially unseen) local surroundings. We train such models using videos from agents in simulated 3D environments where the environment is fully observable, and test them on human-captured real-world videos from unseen environments. On two human-centric video tasks, we show that models equipped with our environment-aware features consistently outperform their counterparts with traditional clip features. Moreover, despite being trained exclusively on simulated videos, our approach successfully handles real-world videos from HouseTours and Ego4D, and achieves state-of-the-art results on the Ego4D NLQ challenge",
    "checked": true,
    "id": "f23bcaaedd2e882e012c9d9f7075b62d1345ecdf",
    "semantic_title": "egoenv: human-centric environment representations from egocentric video",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=O0Lz8XZT2b": {
    "title": "A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning",
    "volume": "oral",
    "abstract": "Conventional statistical wisdom established a well-understood relationship between model complexity and prediction error, typically presented as a _U-shaped curve_ reflecting a transition between under- and overfitting regimes. However, motivated by the success of overparametrized neural networks, recent influential work has suggested this theory to be generally incomplete, introducing an additional regime that exhibits a second descent in test error as the parameter count $p$ grows past sample size $n$ -- a phenomenon dubbed _double descent_. While most attention has naturally been given to the deep-learning setting, double descent was shown to emerge more generally across non-neural models: known cases include _linear regression, trees, and boosting_. In this work, we take a closer look at the evidence surrounding these more classical statistical machine learning methods and challenge the claim that observed cases of double descent truly extend the limits of a traditional U-shaped complexity-generalization curve therein. We show that once careful consideration is given to _what is being plotted_ on the x-axes of their double descent plots, it becomes apparent that there are implicitly multiple, distinct complexity axes along which the parameter count grows. We demonstrate that the second descent appears exactly (and _only_) when and where the transition between these underlying axes occurs, and that its location is thus _not_ inherently tied to the interpolation threshold $p=n$. We then gain further insight by adopting a classical nonparametric statistics perspective. We interpret the investigated methods as _smoothers_ and propose a generalized measure for the _effective_ number of parameters they use _on unseen examples_, using which we find that their apparent double descent curves do indeed fold back into more traditional convex shapes -- providing a resolution to the ostensible tension between double descent and traditional statistical intuition",
    "checked": true,
    "id": "f059bbc0aad626da80e1d8abd91c907ff6a36997",
    "semantic_title": "a u-turn on double descent: rethinking parameter counting in statistical learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S5wmbQc1We": {
    "title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
    "volume": "oral",
    "abstract": "Do neural networks, trained on well-understood algorithmic tasks, reliably rediscover known algorithms? Several recent studies, on tasks ranging from group operations to in-context linear regression, have suggested that the answer is yes. Using modular addition as a prototypical problem, we show that algorithm discovery in neural networks is sometimes more complex: small changes to model hyperparameters and initializations can induce discovery of qualitatively different algorithms from a fixed training set, and even learning of multiple different solutions in parallel. In modular addition, we specifically show that models learn a known *Clock* algorithm, a previously undescribed, less intuitive, but comprehensible procedure we term the *Pizza* algorithm, and a variety of even more complex procedures. Our results show that even simple learning problems can admit a surprising diversity of solutions, motivating the development of new tools for mechanistically characterizing the behavior of neural networks across the algorithmic phase space",
    "checked": true,
    "id": "a72ba8dc49a6a842f69c312ac9a037a0f33b74f5",
    "semantic_title": "the clock and the pizza: two stories in mechanistic explanation of neural networks",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=HV85SiyrsV": {
    "title": "Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore",
    "volume": "oral",
    "abstract": "We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\\pi$-realizability assumption, where it is assumed that the action-values of all policies can be expressed as linear functions of state-action features. This class is known to be more general than linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\\pi$-realizable MDPs where for any policy, all the actions have approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorithm on the linear MDP hidden in the problem. The method returns an $\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions with the MDP, where $H$ is the time horizon and $d$ is the dimension of the feature vectors, giving the first polynomial-sample-complexity online RL algorithm for this setting. The results are proved for the misspecified case, where the sample complexity is shown to degrade gracefully with the misspecification error",
    "checked": true,
    "id": "b026ad6d3536767c410d8523868a6d5e36393928",
    "semantic_title": "online rl in linearly $q^\\pi$-realizable mdps is as easy as in linear mdps if you learn what to ignore",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5Xc1ecxO1h": {
    "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
    "volume": "oral",
    "abstract": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\\% of tasks, our method achieved a success rate of 74\\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm",
    "checked": true,
    "id": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820",
    "semantic_title": "tree of thoughts: deliberate problem solving with large language models",
    "citation_count": 274,
    "authors": []
  },
  "https://openreview.net/forum?id=A7feCufBhL": {
    "title": "Image Captioners Are Scalable Vision Learners Too",
    "volume": "oral",
    "abstract": "Contrastive pretraining on image-text pairs from the web is one of the most popular large-scale pretraining strategies for vision backbones, especially in the context of large multimodal models. At the same time, image captioning on this type of data is commonly considered an inferior pretraining strategy. In this paper, we perform a fair comparison of these two pretraining strategies, carefully matching training data, compute, and model capacity. Using a standard encoder-decoder transformer, we find that captioning alone is surprisingly effective: on classification tasks, captioning produces vision encoders competitive with contrastively pretrained encoders, while surpassing them on vision & language tasks. We further analyze the effect of the model architecture and scale, as well as the pretraining data on the representation quality, and find that captioning exhibits the same or better scaling behavior along these axes. Overall our results show that plain image captioning is a more powerful pretraining strategy than was previously believed",
    "checked": true,
    "id": "29cd4e8504df8c762b0b6eef8299584118feeb88",
    "semantic_title": "image captioners are scalable vision learners too",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=j5BuTrEj35": {
    "title": "Scaling Data-Constrained Language Models",
    "volume": "oral",
    "abstract": "The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations",
    "checked": true,
    "id": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c",
    "semantic_title": "scaling data-constrained language models",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=0A9f2jZDGW": {
    "title": "Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models",
    "volume": "oral",
    "abstract": "Task arithmetic has recently emerged as a cost-effective and scalable approach to edit pre-trained models directly in weight space: By adding the fine-tuned weights of different tasks, the model's performance can be improved on these tasks, while negating them leads to task forgetting. Yet, our understanding of the effectiveness of task arithmetic and its underlying principles remains limited. We present a comprehensive study of task arithmetic in vision-language models and show that weight disentanglement is the crucial factor that makes it effective. This property arises during pre-training and manifests when distinct directions in weight space govern separate, localized regions in function space associated with the tasks. Notably, we show that fine-tuning models in their tangent space by linearizing them amplifies weight disentanglement. This leads to substantial performance improvements across multiple task arithmetic benchmarks and diverse models. Building on these findings, we provide theoretical and empirical analyses of the neural tangent kernel (NTK) of these models and establish a compelling link between task arithmetic and the spatial localization of the NTK eigenfunctions. Overall, our work uncovers novel insights into the fundamental mechanisms of task arithmetic and offers a more reliable and effective approach to edit pre-trained models through the NTK linearization",
    "checked": true,
    "id": "5e0d3c25d375d83f0d88bfc17614dde5943c10c3",
    "semantic_title": "task arithmetic in the tangent space: improved editing of pre-trained models",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=QIFoCI7ca1": {
    "title": "Causal normalizing flows: from theory to practice",
    "volume": "oral",
    "abstract": "In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for *causal normalizing flows* to capture the underlying causal data-generating process. Third, we describe how to implement the *do-operator* in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems—where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be found at https://github.com/psanch21/causal-flows",
    "checked": true,
    "id": "0b32c17f92e36af1f7d7b64dd352674ca4883f45",
    "semantic_title": "causal normalizing flows: from theory to practice",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=QDByreuQyk": {
    "title": "Nearly Tight Bounds For Differentially Private Multiway Cut",
    "volume": "oral",
    "abstract": "Finding min $s$-$t$ cuts in graphs is a basic algorithmic tool, with applications in image segmentation, community detection, reinforcement learning, and data clustering. In this problem, we are given two nodes as terminals and the goal is to remove the smallest number of edges from the graph so that these two terminals are disconnected. We study the complexity of differential privacy for the min $s$-$t$ cut problem and show nearly tight lower and upper bounds where we achieve privacy at no cost for running time efficiency. We also develop a differentially private algorithm for the multiway $k$-cut problem, in which we are given $k$ nodes as terminals that we would like to disconnect. As a function of $k$, we obtain privacy guarantees that are exponentially more efficient than applying the advanced composition theorem to known algorithms for multiway $k$-cut. Finally, we empirically evaluate the approximation of our differentially private min $s$-$t$ cut algorithm and show that it almost matches the quality of the output of non-private ones",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=73XPopmbXH": {
    "title": "Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample Complexity for Learning Single Index Models",
    "volume": "oral",
    "abstract": "We focus on the task of learning a single index model $\\sigma(w^\\star \\cdot x)$ with respect to the isotropic Gaussian distribution in $d$ dimensions. Prior work has shown that the sample complexity of learning $w^\\star$ is governed by the information exponent $k^\\star$ of the link function $\\sigma$, which is defined as the index of the first nonzero Hermite coefficient of $\\sigma$. Ben Arous et al. (2021) showed that $n \\gtrsim d^{k^\\star-1}$ samples suffice for learning $w^\\star$ and that this is tight for online SGD. However, the CSQ lower bound for gradient based methods only shows that $n \\gtrsim d^{k^\\star/2}$ samples are necessary. In this work, we close the gap between the upper and lower bounds by showing that online SGD on a smoothed loss learns $w^\\star$ with $n \\gtrsim d^{k^\\star/2}$ samples. We also draw connections to statistical analyses of tensor PCA and to the implicit regularization effects of minibatch SGD on empirical losses",
    "checked": true,
    "id": "df29153629c3f00bdbbe1ea28f32ce379e35a144",
    "semantic_title": "smoothing the landscape boosts the signal for sgd: optimal sample complexity for learning single index models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=Yacmpz84TH": {
    "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
    "volume": "oral",
    "abstract": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller specialized models excel. In this paper, we show that LMs can teach themselves to *use external tools* via simple APIs and achieve the best of both worlds. We introduce *Toolformer*, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities",
    "checked": true,
    "id": "53d128ea815bcc0526856eb5a9c42cc977cb36a7",
    "semantic_title": "toolformer: language models can teach themselves to use tools",
    "citation_count": 424,
    "authors": []
  },
  "https://openreview.net/forum?id=i913TUOvTK": {
    "title": "Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity",
    "volume": "oral",
    "abstract": "Reconstructing human vision from brain activities has been an appealing task that helps to understand our cognitive process. Even though recent research has seen great success in reconstructing static images from non-invasive brain recordings, work on recovering continuous visual experiences in the form of videos is limited. In this work, we propose Mind-Video that learns spatiotemporal information from continuous fMRI data of the cerebral cortex progressively through masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model that incorporates network temporal inflation. We show that high-quality videos of arbitrary frame rates can be reconstructed with Mind-Video using adversarial guidance. The recovered videos were evaluated with various semantic and pixel-level metrics. We achieved an average accuracy of 85% in semantic classification tasks and 0.19 in structural similarity index (SSIM), outperforming the previous state-of-the-art by 45%. We also show that our model is biologically plausible and interpretable, reflecting established physiological processes",
    "checked": true,
    "id": "12cbf907d40a5406ca855f51af54cc16d0b28cd6",
    "semantic_title": "cinematic mindscapes: high-quality video reconstruction from brain activity",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=y8UAQQHVTX": {
    "title": "Private Everlasting Prediction",
    "volume": "oral",
    "abstract": "A private learner is trained on a sample of labeled points and generatesa hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set [Kasiviswannathan et al., FOCS 2008]. Research uncovered that private learners may need to exhibit significantly higher sample complexity than non-private learners as is the case with, e.g., learning of one-dimensional threshold functions [Bun et al., FOCS 2015, Alon et al., STOC 2019]. We explore prediction as an alternative to learning. Instead of putting forward a hypothesis, a predictor answers a stream of classification queries. Earlier work has considered a private prediction model with just a single classification query [Dwork and Feldman, COLT 2018]. We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and, furthermore, that it must use the queries for this modification, hence introducing potential privacy risks with respect to the queries themselves. We introduce private everlasting prediction taking into account the privacy of both the training set and the (adaptively chosen) queries made to the predictor. We then present a generic construction of private everlasting predictors in the PAC model. The sample complexity of the initial training sample in our construction is quadratic (up to polylog factors) in the VC dimension of the concept class. Our construction allows prediction for all concept classes with finite VC dimension, and in particular threshold functions with constant size initial training sample, even when considered over infinite domains, whereas it is known that the sample complexity of privately learning threshold functions must grow as a function of the domain size and hence is impossible for infinite domains",
    "checked": true,
    "id": "c6c3242cb0cc9fd832b306591b8dad26fef1fe60",
    "semantic_title": "private everlasting prediction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BHXsb69bSx": {
    "title": "ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings",
    "volume": "oral",
    "abstract": "Integrating large language models (LLMs) with various tools has led to increased attention in the field. Existing approaches either involve fine-tuning the LLM, which is both computationally costly and limited to a fixed set of tools, or prompting LLMs by in-context tool demonstrations. Although the latter method offers adaptability to new tools, it struggles with the inherent context length constraint of LLMs when many new tools are presented, and mastering a new set of tools with few-shot examples remains challenging, resulting in suboptimal performance. To address these limitations, we propose a novel solution, named **ToolkenGPT**, wherein LLMs effectively learn to master tools as predicting tokens through **tool embeddings** for solving complex tasks. In this framework, each tool is transformed into vector embeddings and plugged into the language model head. Once the function is triggered during text generation, the LLM enters a special function mode to execute the tool calls. Our experiments show that function embeddings effectively help LLMs understand tool use and improve on several tasks, including numerical reasoning, knowledge-based question answering and embodied decision-making",
    "checked": true,
    "id": "c7a3f9cc61cfafdc307f8ae24430b6b1121f9b2c",
    "semantic_title": "toolkengpt: augmenting frozen language models with massive tools via tool embeddings",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=w0H2xGHlkw": {
    "title": "Visual Instruction Tuning",
    "volume": "oral",
    "abstract": "Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for general-purpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available",
    "checked": true,
    "id": "1a8eb2cae1833df3bf12fe3b41b03d60b4a4a98d",
    "semantic_title": "visual instruction tuning",
    "citation_count": 362,
    "authors": []
  },
  "https://openreview.net/forum?id=wIlmx4bHrO": {
    "title": "A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization",
    "volume": "oral",
    "abstract": "In this paper, we propose a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave (NC-NC) minimax problems. In particular, we design a new extra-gradient difference step to obtain an important quasi-cocoercivity property, which plays a key role to significantly improve the convergence rate in the constrained NC-NC setting without additional structural assumption. Then momentum acceleration is also introduced into our dual accelerating update step. Moreover, we prove that, to find an $\\epsilon$-stationary point of the function $f$, our algorithm attains the complexity $\\mathcal{O}(\\epsilon^{-2})$ in the constrained NC-NC setting, while the best-known complexity bound is $\\widetilde{\\mathcal{O}}(\\epsilon^{-4})$, where $\\widetilde{\\mathcal{O}}(\\cdot)$ hides logarithmic factors compared to $\\mathcal{O}(\\cdot)$. As the special cases of the constrained NC-NC setting, our algorithm can also obtain the same complexity $\\mathcal{O}(\\epsilon^{-2})$ for both the nonconvex-concave (NC-C) and convex-nonconcave (C-NC) cases, while the best-known complexity bounds are $\\widetilde{\\mathcal{O}}(\\epsilon^{-2.5})$ for the NC-C case and $\\widetilde{\\mathcal{O}}(\\epsilon^{-4})$ for the C-NC case. For fair comparison with existing algorithms, we also analyze the complexity bound to find $\\epsilon$-stationary point of the primal function $\\phi$ for the constrained NC-C problem, which shows that our algorithm can improve the complexity bound from $\\widetilde{\\mathcal{O}}(\\epsilon^{-3})$ to $\\mathcal{O}(\\epsilon^{-2})$. To the best of our knowledge, this is the first time that the proposed algorithm improves the best-known complexity bounds from $\\mathcal{O}(\\epsilon^{-4})$ and $\\widetilde{\\mathcal{O}}(\\epsilon^{-3})$ to $\\mathcal{O}(\\epsilon^{-2})$ in both the NC-NC and NC-C settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eD534mPhAg": {
    "title": "Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis",
    "volume": "oral",
    "abstract": "This work studies the evaluation of explaining graph neural networks (GNNs), which is crucial to the credibility of post-hoc explainability in practical usage. Conventional evaluation metrics, and even explanation methods -- which mainly follow the paradigm of feeding the explanatory subgraph and measuring output difference -- always suffer from the notorious out-of-distribution (OOD) issue. In this work, we endeavor to confront the issue by introducing a novel evaluation metric, termed **O**OD-resistant **A**dversarial **R**obustness (OAR). Specifically, we draw inspiration from the notion of adversarial robustness and evaluate post-hoc explanation subgraphs by calculating their robustness under attack. On top of that, an elaborate OOD reweighting block is inserted into the pipeline to confine the evaluation process to the original data distribution. For applications involving large datasets, we further devise a **Sim**plified version of **OAR** (SimOAR), which achieves a significant improvement in computational efficiency at the cost of a small amount of performance. Extensive empirical studies validate the effectiveness of our OAR and SimOAR",
    "checked": false,
    "id": "cc92ae2ce3caf2142a92bed5957a8d5519215eb7",
    "semantic_title": "towards robust fidelity for evaluating explainability of graph neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qHrADgAdYu": {
    "title": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective",
    "volume": "oral",
    "abstract": "Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the \\emph{expressivity} of LLMs with CoT in solving fundamental mathematical and decision-making problems. By using circuit complexity theory, we first give impossibility results showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows \\emph{super-polynomially} with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of \\emph{constant size} suffice to solve both tasks by generating CoT derivations using a commonly used math language format. Moreover, we show LLMs with CoT can handle a general class of decision-making problems known as Dynamic Programming, thus justifying its power in tackling complex real-world tasks. Finally, an extensive set of experiments show that, while Transformers always fail to directly predict the answers, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations",
    "checked": true,
    "id": "c2260403fd5cb2de73491323433e48b6ec36872c",
    "semantic_title": "towards revealing the mystery behind chain of thought: a theoretical perspective",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=FtNruwFEs3": {
    "title": "Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach",
    "volume": "oral",
    "abstract": "We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to a large class of discrete inference problems, even with infinite support and continuous priors. To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on discrete events. Our key tool is *probability generating functions*: they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments. Our inference method is provably correct and fully automated in a tool called *Genfer*, which uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra. Our experiments show that Genfer is often faster than the existing exact inference tools PSI, Dice, and Prodigy. On a range of real-world inference problems that none of these exact tools can solve, Genfer's performance is competitive with approximate Monte Carlo methods, while avoiding approximation errors",
    "checked": true,
    "id": "659d2997af18f6f40802de2d146a4488692ee1b0",
    "semantic_title": "exact bayesian inference on discrete models via probability generating functions: a probabilistic programming approach",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=mayAyPrhJI": {
    "title": "Bridging Discrete and Backpropagation: Straight-Through and Beyond",
    "volume": "oral",
    "abstract": "Backpropagation, the cornerstone of deep learning, is limited to computing gradients for continuous variables. This limitation poses challenges for problems involving discrete latent variables. To address this issue, we propose a novel approach to approximate the gradient of parameters involved in generating discrete latent variables. First, we examine the widely used Straight-Through (ST) heuristic and demonstrate that it works as a first-order approximation of the gradient. Guided by our findings, we propose ReinMax, which achieves second-order accuracy by integrating Heun's method, a second-order numerical method for solving ODEs. ReinMax does not require Hessian or other second-order derivatives, thus having negligible computation overheads. Extensive experimental results on various tasks demonstrate the superiority of ReinMax over the state of the art",
    "checked": true,
    "id": "103ee4ea6dd56890c517dadc07c6bd8f4d29a359",
    "semantic_title": "bridging discrete and backpropagation: straight-through and beyond",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=eTHawKFT4h": {
    "title": "A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods",
    "volume": "oral",
    "abstract": "We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning---including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle systems in thermodynamics, and use our theory to prove the convergence of these algorithms to a well-defined global minimiser on the space of probability measures",
    "checked": true,
    "id": "2715c5ef2b5f10255c7403e9435dd92f3ab012e0",
    "semantic_title": "a rigorous link between deep ensembles and (variational) bayesian methods",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=MFWgLCWgUB": {
    "title": "Random Cuts are Optimal for Explainable k-Medians",
    "volume": "oral",
    "abstract": "We show that the RandomCoordinateCut algorithm gives the optimal competitive ratio for explainable $k$-medians in $\\ell_1$. The problem of explainable $k$-medians was introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian in 2020. Several groups of authors independently proposed a simple polynomial-time randomized algorithm for the problem and showed that this algorithm is $O(\\log k \\log\\log k)$ competitive. We provide a tight analysis of the algorithm and prove that its competitive ratio is upper bounded by $2\\ln k+2$. This bound matches the $\\Omega(\\log k)$ lower bound by Dasgupta et al (2020)",
    "checked": true,
    "id": "1ef6143d2151862062899a8805bc3b72fb2099e3",
    "semantic_title": "random cuts are optimal for explainable k-medians",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=fHyLsfMDIs": {
    "title": "Entropic Neural Optimal Transport via Diffusion Processes",
    "volume": "oral",
    "abstract": "We propose a novel neural algorithm for the fundamental problem of computing the entropic optimal transport (EOT) plan between probability distributions which are accessible by samples. Our algorithm is based on the saddle point reformulation of the dynamic version of EOT which is known as the Schrödinger Bridge problem. In contrast to the prior methods for large-scale EOT, our algorithm is end-to-end and consists of a single learning step, has fast inference procedure, and allows handling small values of the entropy regularization coefficient which is of particular importance in some applied problems. Empirically, we show the performance of the method on several large-scale EOT tasks. The code for the ENOT solver can be found at https://github.com/ngushchin/EntropicNeuralOptimalTransport",
    "checked": true,
    "id": "53b9ddadf86d97553eefa8ed501d40d5761625e1",
    "semantic_title": "entropic neural optimal transport via diffusion processes",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=liMSqUuVg9": {
    "title": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection",
    "volume": "oral",
    "abstract": "Neural sequence models based on the transformer architecture have demonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences. Building on these ``base'' ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving \\emph{in-context algorithm selection}, akin to what a statistician can do in real life---A \\emph{single} transformer can adaptively select different base ICL algorithms---or even perform qualitatively different tasks---on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a transformer that can perform nearly Bayes-optimal ICL on a challenging task---noisy linear models with mixed noise levels. Experimentally, we demonstrate the strong in-context algorithm selection capabilities of standard transformer architectures",
    "checked": true,
    "id": "70c3d5ab03a54281be91709b19e3f50a2e4be0e3",
    "semantic_title": "transformers as statisticians: provable in-context learning with in-context algorithm selection",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=sPLTQSf6GI": {
    "title": "A Measure-Theoretic Axiomatisation of Causality",
    "volume": "oral",
    "abstract": "Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of what happens when one intervenes on a system, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a causal space, consisting of a probability space along with a collection of transition probability kernels, called causal kernels, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes",
    "checked": true,
    "id": "c5665e783aacea59b387cb9267fe98ac16b56920",
    "semantic_title": "a measure-theoretic axiomatisation of causality",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kMueEV8Eyy": {
    "title": "Abide by the law and follow the flow: conservation laws for gradient flows",
    "volume": "oral",
    "abstract": "Understanding the geometric properties of gradient descent dynamics is a key ingredient in deciphering the recent success of very large machine learning models. A striking observation is that trained over-parameterized models retain some properties of the optimization initialization. This \"implicit bias\" is believed to be responsible for some favorable properties of the trained models and could explain their good generalization properties. The purpose of this article is threefold. First, we rigorously expose the definition and basic properties of \"conservation laws\", that define quantities conserved during gradient flows of a given model (e.g. of a ReLU network with a given architecture) with any training data and any loss. Then we explain how to find the maximal number of independent conservation laws by performing finite-dimensional algebraic manipulations on the Lie algebra generated by the Jacobian of the model. Finally, we provide algorithms to: a) compute a family of polynomial laws; b) compute the maximal number of (not necessarily polynomial) independent conservation laws. We provide showcase examples that we fully work out theoretically. Besides, applying the two algorithms confirms for a number of ReLU network architectures that all known laws are recovered by the algorithm, and that there are no other independent laws. Such computational tools pave the way to understanding desirable properties of optimization initialization in large machine learning models",
    "checked": true,
    "id": "a55b3f89de0370b34751d9a7820d7a0b3d698654",
    "semantic_title": "abide by the law and follow the flow: conservation laws for gradient flows",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=jA235JGM09": {
    "title": "Jailbroken: How Does LLM Safety Training Fail?",
    "volume": "oral",
    "abstract": "Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of \"jailbreak\" attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models' red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity—that safety mechanisms should be as sophisticated as the underlying model—and argues against the idea that scaling alone can resolve these safety failure modes",
    "checked": true,
    "id": "929305892d4ddae575a0fc23227a8139f7681632",
    "semantic_title": "jailbroken: how does llm safety training fail?",
    "citation_count": 80,
    "authors": []
  },
  "https://openreview.net/forum?id=5W7cXno10k": {
    "title": "Characteristic Circuits",
    "volume": "oral",
    "abstract": "In many real-world scenarios it is crucial to be able to reliably and efficiently reason under uncertainty while capturing complex relationships in data. Probabilistic circuits (PCs), a prominent family of tractable probabilistic models, offer a remedy to this challenge by composing simple, tractable distributions into a high-dimensional probability distribution. However, learning PCs on heterogeneous data is challenging and densities of some parametric distributions are not available in closed form, limiting their potential use. We introduce characteristic circuits (CCs), a family of tractable probabilistic models providing a unified formalization of distributions over heterogeneous data in the spectral domain. The one-to-one relationship between characteristic functions and probability measures enables us to learn high-dimensional distributions on heterogeneous data domains and facilitates efficient probabilistic inference even when no closed-form density function is available. We show that the structure and parameters of CCs can be learned efficiently from the data and find that CCs outperform state-of-the-art density estimators for heterogeneous data domains on common benchmark data sets",
    "checked": false,
    "id": "049840a3595af125dc590e0cfcf50fb3231fc559",
    "semantic_title": "adaptive event-triggered smc for stochastic switching systems with semi-markov process and application to boost converter circuit model",
    "citation_count": 194,
    "authors": []
  },
  "https://openreview.net/forum?id=gI1SOgW3kw": {
    "title": "Generalizing Nonlinear ICA Beyond Structural Sparsity",
    "volume": "oral",
    "abstract": "Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets",
    "checked": true,
    "id": "f57749e893c9d532e5b65845cea7adacedc0a4aa",
    "semantic_title": "generalizing nonlinear ica beyond structural sparsity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=APGXBNkt6h": {
    "title": "When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment",
    "volume": "oral",
    "abstract": "Reinforcement learning (RL) algorithms face two distinct challenges: learning effective representations of past and present observations, and determining how actions influence future returns. Both challenges involve modeling long-term dependencies. The Transformer architecture has been very successful to solve problems that involve long-term dependencies, including in the RL domain. However, the underlying reason for the strong performance of Transformer-based RL methods remains unclear: is it because they learn effective memory, or because they perform effective credit assignment? After introducing formal definitions of memory length and credit assignment length, we design simple configurable tasks to measure these distinct quantities. Our empirical results reveal that Transformers can enhance the memory capability of RL algorithms, scaling up to tasks that require memorizing observations $1500$ steps ago. However, Transformers do not improve long-term credit assignment. In summary, our results provide an explanation for the success of Transformers in RL, while also highlighting an important area for future research and benchmark design. Our code is open-sourced at https://github.com/twni2016/Memory-RL",
    "checked": true,
    "id": "7177fcb8e0311eeebd4070b62312a4bec1432ea3",
    "semantic_title": "when do transformers shine in rl? decoupling memory from credit assignment",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=1vzF4zWQ1E": {
    "title": "Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition",
    "volume": "oral",
    "abstract": "Face recognition systems are widely deployed in safety-critical applications, including law enforcement, yet they exhibit bias across a range of socio-demographic dimensions, such as gender and race. Conventional wisdom dictates that model biases arise from biased training data. As a consequence, previous works on bias mitigation largely focused on pre-processing the training data, adding penalties to prevent bias from effecting the model during training, or post-processing predictions to debias them, yet these approaches have shown limited success on hard problems such as face recognition. In our work, we discover that biases are actually inherent to neural network architectures themselves. Following this reframing, we conduct the first neural architecture search for fairness, jointly with a search for hyperparameters. Our search outputs a suite of models which Pareto-dominate all other high-performance architectures and existing bias mitigation methods in terms of accuracy and fairness, often by large margins, on the two most widely used datasets for face identification, CelebA and VGGFace2. Furthermore, these models generalize to other datasets and sensitive attributes. We release our code, models and raw data files at https://github.com/dooleys/FR-NAS",
    "checked": true,
    "id": "0bc414d4682076e6f22e143c829b6b13feb37323",
    "semantic_title": "rethinking bias mitigation: fairer architectures make for fairer face recognition",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=f38EY21lBw": {
    "title": "Privacy Auditing with One (1) Training Run",
    "volume": "oral",
    "abstract": "We propose a scheme for auditing differentially private machine learning systems with a single training run. This exploits the parallelism of being able to add or remove multiple training examples independently. We analyze this using the connection between differential privacy and statistical generalization, which avoids the cost of group privacy. Our auditing scheme requires minimal assumptions about the algorithm and can be applied in the black-box or white-box setting. We demonstrate the effectiveness of our framework by applying it to DP-SGD, where we can achieve meaningful empirical privacy lower bounds by training only one model. In contrast, standard methods would require training hundreds of models",
    "checked": true,
    "id": "b45c477e9d736e10b68d564509be262f6ff4d6ad",
    "semantic_title": "privacy auditing with one (1) training run",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=CAF4CnUblx": {
    "title": "Information Maximization Perspective of Orthogonal Matching Pursuit with Applications to Explainable AI",
    "volume": "spotlight",
    "abstract": "Information Pursuit (IP) is a classical active testing algorithm for predicting an output by sequentially and greedily querying the input in order of information gain. However, IP is computationally intensive since it involves estimating mutual information in high-dimensional spaces. This paper explores Orthogonal Matching Pursuit (OMP) as an alternative to IP for greedily selecting the queries. OMP is a classical signal processing algorithm for sequentially encoding a signal in terms of dictionary atoms chosen in order of correlation gain. In each iteration, OMP selects the atom that is most correlated with the signal residual (the signal minus its reconstruction thus far). Our first contribution is to establish a fundamental connection between IP and OMP, where we prove that IP with random projections of dictionary atoms as queries ``almost'' reduces to OMP, with the difference being that IP selects atoms in order of normalized correlation gain. We call this version IP-OMP and present simulations indicating that this difference does not have any appreciable effect on the sparse code recovery rate of IP-OMP compared to that of OMP for random Gaussian dictionaries. Inspired by this connection, our second contribution is to explore the utility of IP-OMP for generating explainable predictions, an area in which IP has recently gained traction. More specifically, we propose a simple explainable AI algorithm which encodes an image as a sparse combination of semantically meaningful dictionary atoms that are defined as text embeddings of interpretable concepts. The final prediction is made using the weights of this sparse combination, which serve as an explanation. Empirically, our proposed algorithm is not only competitive with existing explainability methods but also computationally less expensive",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YkBDJWerKg": {
    "title": "STEVE-1: A Generative Model for Text-to-Behavior in Minecraft",
    "volume": "spotlight",
    "abstract": "Constructing AI models that respond to text instructions is challenging, especially for sequential decision-making tasks. This work introduces an instruction-tuned Video Pretraining (VPT) model for Minecraft called STEVE-1, demonstrating that the unCLIP approach, utilized in DALL•E 2, is also effective for creating instruction-following sequential decision-making agents. STEVE-1 is trained in two steps: adapting the pretrained VPT model to follow commands in MineCLIP's latent space, then training a prior to predict latent codes from text. This allows us to finetune VPT through self-supervised behavioral cloning and hindsight relabeling, bypassing the need for costly human text annotations. By leveraging pretrained models like VPT and MineCLIP and employing best practices from text-conditioned image generation, STEVE-1 costs just $60 to train and can follow short-horizon open-ended text and visual instructions in Minecraft. STEVE-1 sets a new bar for open-ended instruction following in Minecraft with low-level controls (mouse and keyboard) and raw pixel inputs, far outperforming previous baselines and robustly completing 12 of 13 tasks in our early-game evaluation suite. We provide experimental evidence highlighting key factors for downstream performance, including pretraining, classifier-free guidance, and data scaling. All resources, including our model weights, training scripts, and evaluation tools are made available for further research",
    "checked": true,
    "id": "844b22bb025f485d85d00f1f61555a8ff0131658",
    "semantic_title": "steve-1: a generative model for text-to-behavior in minecraft",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=4KV2xLeqPN": {
    "title": "On the Variance, Admissibility, and Stability of Empirical Risk Minimization",
    "volume": "spotlight",
    "abstract": "It is well known that Empirical Risk Minimization (ERM) may attain minimax suboptimal rates in terms of the mean squared error (Birgé and Massart, 1993). In this paper, we prove that, under relatively mild assumptions, the suboptimality of ERM must be due to its bias. Namely, the variance error term of ERM (in terms of the bias and variance decomposition) enjoys the minimax rate. In the fixed design setting, we provide an elementary proof of this result using the probabilistic method. Then, we extend our proof to the random design setting for various models. In addition, we provide a simple proof of Chatterjee's admissibility theorem (Chatterjee, 2014, Theorem 1.4), which states that in the fixed design setting, ERM cannot be ruled out as an optimal method, and then we extend this result to the random design setting. We also show that our estimates imply stability of ERM, complementing the main result of Caponnetto and Rakhlin (2006) for non-Donsker classes. Finally, we highlight the somewhat irregular nature of the loss landscape of ERM in the non-Donsker regime, by showing that functions can be close to ERM, in terms of $L_2$ distance, while still being far from almost-minimizers of the empirical loss",
    "checked": true,
    "id": "32e76b692338cc9309f306a6eb311dd26abe7101",
    "semantic_title": "on the variance, admissibility, and stability of empirical risk minimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3PjCt4kmRx": {
    "title": "From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces",
    "volume": "spotlight",
    "abstract": "Much of the previous work towards digital agents for graphical user interfaces (GUIs) has relied on text-based representations (derived from HTML or other structured data sources), which are not always readily available. These input representations have been often coupled with custom, task-specific action spaces. This paper focuses on creating agents that interact with the digital world using the same conceptual interface that humans commonly use — via pixel-based screenshots and a generic action space corresponding to keyboard and mouse actions. Building upon recent progress in pixel-based pretraining, we show, for the first time, that it is possible for such agents to outperform human crowdworkers on the MiniWob++ benchmark of GUI-based instruction following tasks",
    "checked": true,
    "id": "ee7020fc413590878dca60dcf41896bbe6a6c628",
    "semantic_title": "from pixels to ui actions: learning to follow instructions via graphical user interfaces",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=CSbGXyCswu": {
    "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training",
    "volume": "spotlight",
    "abstract": "Language models (LMs) often exhibit undesirable text generation behaviors, including generating false, toxic, or irrelevant outputs. Reinforcement learning from human feedback (RLHF)---where human preference judgments on LM outputs are transformed into a learning signal---has recently shown promise in addressing these issues. However, such holistic feedback conveys limited information on long text outputs; it does not indicate which aspects of the outputs influenced user preference; e.g., which parts contain what type(s) of errors. In this paper, we use fine-grained human feedback (e.g., which sentence is false, which sub-sentence is irrelevant) as an explicit training signal. We introduce Fine-Grained RLHF, a framework that enables training and learning from reward functions that are fine-grained in two respects: (1) density, providing a reward after every segment (e.g., a sentence) is generated; and (2) incorporating multiple reward models associated with different feedback types (e.g., factual incorrectness, irrelevance, and information incompleteness). We conduct experiments on detoxification and long-form question answering to illustrate how learning with this reward function leads to improved performance, supported by both automatic and human evaluation. Additionally, we show that LM behaviors can be customized using different combinations of fine-grained reward models. We release all data, collected human feedback, and codes at https://FineGrainedRLHF.github.io",
    "checked": true,
    "id": "e2e52461194bc81351da7caa978ac42e9e9549cc",
    "semantic_title": "fine-grained human feedback gives better rewards for language model training",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=OZ7aImD4uQ": {
    "title": "Scale Alone Does not Improve Mechanistic Interpretability in Vision Models",
    "volume": "spotlight",
    "abstract": "In light of the recent widespread adoption of AI systems, understanding the internal information processing of neural networks has become increasingly critical. Most recently, machine vision has seen remarkable progress by scaling neural networks to unprecedented levels in dataset and model size. We here ask whether this extraordinary increase in scale also positively impacts the field of mechanistic interpretability. In other words, has our understanding of the inner workings of scaled neural networks improved as well? We use a psychophysical paradigm to quantify one form of mechanistic interpretability for a diverse suite of nine models and find no scaling effect for interpretability - neither for model nor dataset size. Specifically, none of the investigated state-of-the-art models are easier to interpret than the GoogLeNet model from almost a decade ago. Latest-generation vision models appear even less interpretable than older architectures, hinting at a regression rather than improvement, with modern models sacrificing interpretability for accuracy. These results highlight the need for models explicitly designed to be mechanistically interpretable and the need for more helpful interpretability methods to increase our understanding of networks at an atomic level. We release a dataset containing more than 130'000 human responses from our psychophysical evaluation of 767 units across nine models. This dataset facilitates research on automated instead of human-based interpretability evaluations, which can ultimately be leveraged to directly optimize the mechanistic interpretability of models",
    "checked": true,
    "id": "2e4ad5efadaaa317d7f8f148e8c7d10fce97ba59",
    "semantic_title": "scale alone does not improve mechanistic interpretability in vision models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cRGINXQWem": {
    "title": "Precise asymptotic generalization for multiclass classification with overparameterized linear models",
    "volume": "spotlight",
    "abstract": "We study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al. (NeurIPS'22), where the number of data points, features, and classes all grow together. We fully resolve the conjecture posed in Subramanian et al. '22, matching the predicted regimes for which the model does and does not generalize. Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically. One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal. The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels. As an application, we show that the same type of analysis can be used to analyze the related multi-label classification problem under the same bi-level ensemble",
    "checked": true,
    "id": "1b104c36fe10751d79e64dd02d470372a3075dd6",
    "semantic_title": "precise asymptotic generalization for multiclass classification with overparameterized linear models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u39QQh5L8Q": {
    "title": "Uncovering motifs of concurrent signaling across multiple neuronal populations",
    "volume": "spotlight",
    "abstract": "Modern recording techniques now allow us to record from distinct neuronal populations in different brain networks. However, especially as we consider multiple (more than two) populations, new conceptual and statistical frameworks are needed to characterize the multi-dimensional, concurrent flow of signals among these populations. Here, we develop a dimensionality reduction framework that determines (1) the subset of populations described by each latent dimension, (2) the direction of signal flow among those populations, and (3) how those signals evolve over time within and across experimental trials. We illustrate these features in simulation, and further validate the method by applying it to previously studied recordings from neuronal populations in macaque visual areas V1 and V2. Then we study interactions across select laminar compartments of areas V1, V2, and V3d, recorded simultaneously with multiple Neuropixels probes. Our approach uncovered signatures of selective communication across these three areas that related to their retinotopic alignment. This work advances the study of concurrent signaling across multiple neuronal populations",
    "checked": false,
    "id": "96be0e34f1b6e2142a287a12acb0c101f73dcd0e",
    "semantic_title": "dual-polarity voltage imaging of the concurrent dynamics of multiple neuron types",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=DkeeXVdQyu": {
    "title": "How to Scale Your EMA",
    "volume": "spotlight",
    "abstract": "Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important machine learning tool is the model EMA, a functional copy of a target model, whose parameters move towards those of its target model according to an Exponential Moving Average (EMA) at a rate parameterized by a momentum hyperparameter. This model EMA can improve the robustness and generalization of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have not considered the optimization of the model EMA when performing scaling, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of a model EMA and demonstrate the rule's validity across a range of architectures, optimizers, and data modalities. We also show the rule's validity where the model EMA contributes to the optimization of the target model, enabling us to train EMA-based pseudo-labeling and SSL methods at small and large batch sizes. For SSL, we enable training of BYOL up to batch size 24,576 without sacrificing performance, a 6$\\times$ wall-clock time reduction under idealized hardware settings",
    "checked": true,
    "id": "3d04f5bb0599ce02d8fa47420f72f500758c4660",
    "semantic_title": "how to scale your ema",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=89ia77nZ8u": {
    "title": "Towards Automated Circuit Discovery for Mechanistic Interpretability",
    "volume": "spotlight",
    "abstract": "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: finding the connections between the abstract neural network units that form a circuit. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery",
    "checked": true,
    "id": "eefbd8b384a58f464827b19e30a6920ba976def9",
    "semantic_title": "towards automated circuit discovery for mechanistic interpretability",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=qjnl1QUnFA": {
    "title": "High-Fidelity Audio Compression with Improved RVQGAN",
    "volume": "spotlight",
    "abstract": "Language models have been successfully used to model natural signals, such as images, speech, and music. A key component of these models is a high quality neural compression model that can compress high-dimensional natural signals into lower dimensional discrete tokens. To that end, we introduce a high-fidelity universal neural audio compression algorithm that achieves ~90x compression of 44.1 KHz audio into tokens at just 8kbps bandwidth. We achieve this by combining advances in high-fidelity audio generation with better vector quantization techniques from the image domain, along with improved adversarial and reconstruction losses. We compress all domains (speech, environment, music, etc.) with a single universal model, making it widely applicable to generative modeling of all audio. We compare with competing audio compression algorithms, and find our method outperforms them significantly. We provide thorough ablations for every design choice, as well as open-source code and trained model weights. We hope our work can lay the foundation for the next generation of high-fidelity audio modeling",
    "checked": true,
    "id": "cf8fced1f446c554ca0c5608ae0a1131184212f6",
    "semantic_title": "high-fidelity audio compression with improved rvqgan",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=zaQ7wV9NOg": {
    "title": "Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework for Online RL",
    "volume": "spotlight",
    "abstract": "While policy optimization algorithms have played an important role in recent empirical success of Reinforcement Learning (RL), the existing theoretical understanding of policy optimization remains rather limited---they are either restricted to tabular MDPs or suffer from highly suboptimal sample complexity, especial in online RL where exploration is necessary. This paper proposes a simple efficient policy optimization framework---Optimistic NPG for online RL. Optimistic NPG can be viewed as simply combining of the classic natural policy gradient (NPG) algorithm [Kakade, 2001] with optimistic policy evaluation subroutines to encourage exploration. For $d$-dimensional linear MDPs, Optimistic NPG is computationally efficient, and learns an $\\epsilon$-optimal policy within $\\tilde{\\mathcal{O}}(d^2/\\epsilon^3)$ samples, which is the first computationally efficient algorithm whose sample complexity has the optimal dimension dependence $\\tilde{\\Theta}(d^2)$. It also improves over state-of-the-art results of policy optimization algorithms [Zanette et al., 2021] by a factor of $d$. For general function approximation that subsumes linear MDPs, Optimistic NPG, to our best knowledge, is also the first policy optimization algorithm that achieves the polynomial sample complexity for learning near-optimal policies",
    "checked": true,
    "id": "ce3d89938d9b1f5a6426debdda3a63960a1a0812",
    "semantic_title": "optimistic natural policy gradient: a simple efficient policy optimization framework for online rl",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=917crxqJdA": {
    "title": "Distribution-Free Statistical Dispersion Control for Societal Applications",
    "volume": "spotlight",
    "abstract": "Explicit finite-sample statistical guarantees on model performance are an important ingredient in responsible machine learning. Previous work has focused mainly on bounding either the expected loss of a predictor or the probability that an individual prediction will incur a loss value in a specified range. However, for many high-stakes applications it is crucial to understand and control the \\textit{dispersion} of a loss distribution, or the extent to which different members of a population experience unequal effects of algorithmic decisions. We initiate the study of distribution-free control of statistical dispersion measures with societal implications and propose a simple yet flexible framework that allows us to handle a much richer class of statistical functionals beyond previous work. Our methods are verified through experiments in toxic comment detection, medical imaging, and film recommendation",
    "checked": true,
    "id": "8e988c776b3e90c469f09434c52bf017cac789a4",
    "semantic_title": "distribution-free statistical dispersion control for societal applications",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d0IEd3VgBh": {
    "title": "On the Role of Randomization in Adversarially Robust Classification",
    "volume": "spotlight",
    "abstract": "Deep neural networks are known to be vulnerable to small adversarial perturbations in test data. To defend against adversarial attacks, probabilistic classifiers have been proposed as an alternative to deterministic ones. However, literature has conflicting findings on the effectiveness of probabilistic classifiers in comparison to deterministic ones. In this paper, we clarify the role of randomization in building adversarially robust classifiers. Given a base hypothesis set of deterministic classifiers, we show the conditions under which a randomized ensemble outperforms the hypothesis set in adversarial risk, extending previous results. Additionally, we show that for any probabilistic binary classifier (including randomized ensembles), there exists a deterministic classifier that outperforms it. Finally, we give an explicit description of the deterministic hypothesis set that contains such a deterministic classifier for many types of commonly used probabilistic classifiers, *i.e.* randomized ensembles and parametric/input noise injection",
    "checked": true,
    "id": "106b2d9185c91c45f86560fb9bd89aba8a7c5874",
    "semantic_title": "on the role of randomization in adversarially robust classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uJ3qNIsDGF": {
    "title": "Exploring Geometry of Blind Spots in Vision models",
    "volume": "spotlight",
    "abstract": "Despite the remarkable success of deep neural networks in a myriad of settings, several works have demonstrated their overwhelming sensitivity to near-imperceptible perturbations, known as adversarial attacks. On the other hand, prior works have also observed that deep networks can be under-sensitive, wherein large-magnitude perturbations in input space do not induce appreciable changes to network activations. In this work, we study in detail the phenomenon of under-sensitivity in vision models such as CNNs and Transformers, and present techniques to study the geometry and extent of \"equi-confidence\" level sets of such networks. We propose a Level Set Traversal algorithm that iteratively explores regions of high confidence with respect to the input space using orthogonal components of the local gradients. Given a source image, we use this algorithm to identify inputs that lie in the same equi-confidence level set as the source image despite being perceptually similar to arbitrary images from other classes. We further observe that the source image is linearly connected by a high-confidence path to these inputs, uncovering a star-like structure for level sets of deep networks. Furthermore, we attempt to identify and estimate the extent of these connected higher-dimensional regions over which the model maintains a high degree of confidence",
    "checked": true,
    "id": "c2e76c4804d887197896966a430b8968593e3e68",
    "semantic_title": "exploring geometry of blind spots in vision models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RInTOCEL3l": {
    "title": "Relax, it doesn't matter how you get there: A new self-supervised approach for multi-timescale behavior analysis",
    "volume": "spotlight",
    "abstract": "Unconstrained and natural behavior consists of dynamics that are complex and unpredictable, especially when trying to predict what will happen multiple steps into the future. While some success has been found in building representations of animal behavior under constrained or simplified task-based conditions, many of these models cannot be applied to free and naturalistic settings where behavior becomes increasingly hard to model. In this work, we develop a multi-task representation learning model for animal behavior that combines two novel components: (i) an action-prediction objective that aims to predict the distribution of actions over future timesteps, and (ii) a multi-scale architecture that builds separate latent spaces to accommodate short- and long-term dynamics. After demonstrating the ability of the method to build representations of both local and global dynamics in robots in varying environments and terrains, we apply our method to the MABe 2022 Multi-Agent Behavior challenge, where our model ranks first overall on both mice and fly benchmarks. In all of these cases, we show that our model can build representations that capture the many different factors that drive behavior and solve a wide range of downstream tasks",
    "checked": true,
    "id": "ad0b83f7806bb242af7daccb8fe63d4d807d7298",
    "semantic_title": "relax, it doesn't matter how you get there: a new self-supervised approach for multi-timescale behavior analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8aunGrXdkl": {
    "title": "Convex and Non-convex Optimization Under Generalized Smoothness",
    "volume": "spotlight",
    "abstract": "Classical analysis of convex and non-convex optimization methods often requires the Lipschitz continuity of the gradient, which limits the analysis to functions bounded by quadratics. Recent work relaxed this requirement to a non-uniform smoothness condition with the Hessian norm bounded by an affine function of the gradient norm, and proved convergence in the non-convex setting via gradient clipping, assuming bounded noise. In this paper, we further generalize this non-uniform smoothness condition and develop a simple, yet powerful analysis technique that bounds the gradients along the trajectory, thereby leading to stronger results for both convex and non-convex optimization problems. In particular, we obtain the classical convergence rates for (stochastic) gradient descent and Nesterov's accelerated gradient method in the convex and/or non-convex setting under this general smoothness condition. The new analysis approach does not require gradient clipping and allows heavy-tailed noise with bounded variance in the stochastic setting",
    "checked": true,
    "id": "7c4d6da876c79d5f6b620148163bc3f35410e527",
    "semantic_title": "convex and non-convex optimization under generalized smoothness",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=yEewbkBNzi": {
    "title": "Convergence of Adam Under Relaxed Assumptions",
    "volume": "spotlight",
    "abstract": "In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\\epsilon$-stationary points with $\\mathcal{O}(\\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory of Adam, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradient complexity of $\\mathcal{O}(\\epsilon^{-3})$",
    "checked": true,
    "id": "b7dfa8acfa5776e22e7c8f6cc0c05b060515e6d6",
    "semantic_title": "convergence of adam under relaxed assumptions",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=Sxu7xlUJGx": {
    "title": "Implicit Variational Inference for High-Dimensional Posteriors",
    "volume": "spotlight",
    "abstract": "In variational inference, the benefits of Bayesian models rely on accurately capturing the true posterior distribution. We propose using neural samplers that specify implicit distributions, which are well-suited for approximating complex multimodal and correlated posteriors in high-dimensional spaces. Our approach introduces novel bounds for approximate inference using implicit distributions by locally linearising the neural sampler. This is distinct from existing methods that rely on additional discriminator networks and unstable adversarial objectives. Furthermore, we present a new sampler architecture that, for the first time, enables implicit distributions over tens of millions of latent variables, addressing computational concerns by using differentiable numerical approximations. We empirically show that our method is capable of recovering correlations across layers in large Bayesian neural networks, a property that is crucial for a network's performance but notoriously challenging to achieve. To the best of our knowledge, no other method has been shown to accomplish this task for such large models. Through experiments in downstream tasks, we demonstrate that our expressive posteriors outperform state-of-the-art uncertainty quantification methods, validating the effectiveness of our training algorithm and the quality of the learned implicit approximation",
    "checked": true,
    "id": "4494ade4fdf1165f828b632230726f62d0b13eb2",
    "semantic_title": "implicit variational inference for high-dimensional posteriors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AA1xrgAP5z": {
    "title": "Universal Online Learning with Gradient Variations: A Multi-layer Online Ensemble Approach",
    "volume": "spotlight",
    "abstract": "In this paper, we propose an online convex optimization approach with two different levels of adaptivity. On a higher level, our approach is agnostic to the unknown types and curvatures of the online functions, while at a lower level, it can exploit the unknown niceness of the environments and attain problem-dependent guarantees. Specifically, we obtain $\\mathcal{O}(\\log V_T)$, $\\mathcal{O}(d \\log V_T)$ and $\\hat{\\mathcal{O}}(\\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and the $\\hat{\\mathcal{O}}(\\cdot)$-notation omits $\\log V_T$ factors. Our result not only safeguards the worst-case guarantees but also directly implies the small-loss bounds in analysis. Moreover, when applied to adversarial/stochastic convex optimization and game theory problems, our result enhances the existing universal guarantees. Our approach is based on a multi-layer online ensemble framework incorporating novel ingredients, including a carefully designed optimism for unifying diverse function types and cascaded corrections for algorithmic stability. Notably, despite its multi-layer structure, our algorithm necessitates only one gradient query per round, making it favorable when the gradient evaluation is time-consuming. This is facilitated by a novel regret decomposition equipped with carefully designed surrogate losses",
    "checked": false,
    "id": "b8fa13c921bb9b1405bdd2741ecf5cb3204d9e77",
    "semantic_title": "universal online learning with gradual variations: a multi-layer online ensemble approach",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z37ki6nqAY": {
    "title": "Online List Labeling with Predictions",
    "volume": "spotlight",
    "abstract": "A growing line of work shows how learned predictions can be used to break through worst-case barriers to improve the running time of an algorithm. However, incorporating predictions into data structures with strong theoretical guarantees remains underdeveloped. This paper takes a step in this direction by showing that predictions can be leveraged in the fundamental online list labeling problem. In the problem, $n$ items arrive over time and must be stored in sorted order in an array of size $\\Theta(n)$. The array slot of an element is its label and the goal is to maintain sorted order while minimizing the total number of elements moved (i.e., relabeled). We design a new list labeling data structure and bound its performance in two models. In the worst-case learning-augmented model, we give guarantees in terms of the error in the predictions. Our data structure provides strong guarantees: it is optimal for any prediction error and guarantees the best-known worst-case bound even when the predictions are entirely erroneous. We also consider a stochastic error model and bound the performance in terms of the expectation and variance of the error. Finally, the theoretical results are demonstrated empirically. In particular, we show that our data structure has strong performance on real temporal data sets where predictions are constructed from elements that arrived in the past, as is typically done in a practical use case",
    "checked": true,
    "id": "609e73a42cbc583bb5b41e31f2228c7e6c6cc58e",
    "semantic_title": "online list labeling with predictions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CbsJ53LdKc": {
    "title": "In-Context Impersonation Reveals Large Language Models' Strengths and Biases",
    "volume": "spotlight",
    "abstract": "In everyday conversations, humans can take on different roles and adapt their vocabulary to their chosen roles. We explore whether LLMs can take on, that is impersonate, different roles when they generate text in-context. We ask LLMs to assume different personas before solving vision and language tasks. We do this by prefixing the prompt with a persona that is associated either with a social identity or domain expertise. In a multi-armed bandit task, we find that LLMs pretending to be children of different ages recover human-like developmental stages of exploration. In a language-based reasoning task, we find that LLMs impersonating domain experts perform better than LLMs impersonating non-domain experts. Finally, we test whether LLMs' impersonations are complementary to visual information when describing different categories. We find that impersonation can improve performance: an LLM prompted to be a bird expert describes birds better than one prompted to be a car expert. However, impersonation can also uncover LLMs' biases: an LLM prompted to be a man describes cars better than one prompted to be a woman. These findings demonstrate that LLMs are capable of taking on diverse roles and that this in-context impersonation can be used to uncover their strengths and hidden biases. Our code is available at https://github.com/ExplainableML/in-context-impersonation",
    "checked": true,
    "id": "19c63eade265d8a47d160098d97194b3b83d3770",
    "semantic_title": "in-context impersonation reveals large language models' strengths and biases",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=pjSzKhSrfs": {
    "title": "Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schrödinger Equation",
    "volume": "spotlight",
    "abstract": "Solving the quantum many-body Schrödinger equation is a fundamental and challenging problem in the fields of quantum physics, quantum chemistry, and material sciences. One of the common computational approaches to this problem is Quantum Variational Monte Carlo (QVMC), in which ground-state solutions are obtained by minimizing the energy of the system within a restricted family of parameterized wave functions. Deep learning methods partially address the limitations of traditional QVMC by representing a rich family of wave functions in terms of neural networks. However, the optimization objective in QVMC remains notoriously hard to minimize and requires second-order optimization methods such as natural gradient. In this paper, we first reformulate energy functional minimization in the space of Born distributions corresponding to particle-permutation (anti-)symmetric wave functions, rather than the space of wave functions. We then interpret QVMC as the Fisher--Rao gradient flow in this distributional space, followed by a projection step onto the variational manifold. This perspective provides us with a principled framework to derive new QMC algorithms, by endowing the distributional space with better metrics, and following the projected gradient flow induced by those metrics. More specifically, we propose ``Wasserstein Quantum Monte Carlo'' (WQMC), which uses the gradient flow induced by the Wasserstein metrics, rather than Fisher--Rao metric, and corresponds to *transporting* the probability mass, rather than *teleporting* it. We demonstrate empirically that the dynamics of WQMC results in faster convergence to the ground state of molecular systems",
    "checked": true,
    "id": "0b1b08ddde3093c4b26d4d0ef0599754f2602fd4",
    "semantic_title": "wasserstein quantum monte carlo: a novel approach for solving the quantum many-body schrödinger equation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=utreNaM1VY": {
    "title": "Can semi-supervised learning use all the data effectively? A lower bound perspective",
    "volume": "spotlight",
    "abstract": "Prior theoretical and empirical works have established that semi-supervised learning algorithms can leverage the unlabeled data to improve over the labeled sample complexity of supervised learning (SL) algorithms. However, existing theoretical work focuses on regimes where the unlabeled data is sufficient to learn a good decision boundary using unsupervised learning (UL) alone. This begs the question: Can SSL algorithms simultaneously improve upon both UL and SL? To this end, we derive a tight lower bound for 2-Gaussian mixture models that explicitly depends on the labeled and the unlabeled dataset size as well as the signal-to-noise ratio of the mixture distribution. Surprisingly, our result implies that no SSL algorithm improves upon the minimax-optimal statistical error rates of SL or UL algorithms for these distributions. Nevertheless, in our real-world experiments, SSL algorithms can often outperform UL and SL algorithms. In summary, our work suggests that while it is possible to prove the performance gains of SSL algorithms, this would require careful tracking of constants in the theoretical analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FasIQqsJhe": {
    "title": "Towards In-context Scene Understanding",
    "volume": "spotlight",
    "abstract": "In-context learning––the ability to configure a model's behavior with different prompts––has revolutionized the field of natural language processing, alleviating the need for task-specific models and paving the way for generalist models capable of assisting with any query. Computer vision, in contrast, has largely stayed in the former regime: specialized decoders and finetuning protocols are generally required to perform dense tasks such as semantic segmentation and depth estimation. In this work we explore a simple mechanism for in-context learning of such scene understanding tasks: nearest neighbor retrieval from a prompt of annotated features. We propose a new pretraining protocol––leveraging attention within and across images––which yields representations particularly useful in this regime. The resulting Hummingbird model, suitably prompted, performs various scene understanding tasks without modification while approaching the performance of specialists that have been finetuned for each task. Moreover, Hummingbird can be configured to perform new tasks much more efficiently than finetuned models, raising the possibility of scene understanding in the interactive assistant regime",
    "checked": true,
    "id": "d9f9d3450d6a3a8c1f79b9d289313c3e27972b10",
    "semantic_title": "towards in-context scene understanding",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=nN8TnHB5nw": {
    "title": "Memory Efficient Optimizers with 4-bit States",
    "volume": "spotlight",
    "abstract": "Optimizer states are a major source of memory consumption for training neural networks, limiting the maximum trainable model within given memory budget. Compressing the optimizer states from 32-bit floating points to lower bitwidth is promising to reduce the training memory footprint, while the current lowest achievable bitwidth is 8-bit. In this work, we push optimizer states bitwidth down to 4-bit through a detailed empirical analysis of first and second moments. Specifically, we find that moments have complicated outlier patterns, that current block-wise quantization cannot accurately approximate. We use a smaller block size and propose to utilize both row-wise and column-wise information for better quantization. We further identify a zero point problem of quantizing the second moment, and solve this problem with a linear quantizer that excludes the zero point. Our 4-bit optimizers are evaluated on a wide variety of benchmarks including natural language understanding, machine translation, image classification, and instruction tuning. On all the tasks our optimizers can achieve comparable accuracy with their full-precision counterparts, while enjoying better memory efficiency",
    "checked": true,
    "id": "5639f5467655581fd780440d88e43af40711d9a6",
    "semantic_title": "memory efficient optimizers with 4-bit states",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=b6FeLpKKjl": {
    "title": "Convergence of Alternating Gradient Descent for Matrix Factorization",
    "volume": "spotlight",
    "abstract": "We consider alternating gradient descent (AGD) with fixed step size applied to the asymmetric matrix factorization objective. We show that, for a rank-$r$ matrix $A \\in \\mathbb{R}^{m \\times n}$, $T = C ( \\frac{\\sigma_1(A)}{\\sigma_r(A)} )^2 \\log(1/\\epsilon)$ iterations of alternating gradient descent suffice to reach an $\\epsilon$-optimal factorization $\\| A - X_{T} Y_{T}' \\|^2 \\leq \\epsilon \\| A \\|^2$ with high probability starting from an atypical random initialization. The factors have rank $d \\geq r$ so that $X_{T}\\in \\mathbb{R}^{m \\times d}$ and $Y_{T} \\in\\mathbb{R}^{n \\times d}$, and mild overparameterization suffices for the constant $C$ in the iteration complexity $T$ to be an absolute constant. Experiments suggest that our proposed initialization is not merely of theoretical benefit, but rather significantly improves the convergence rate of gradient descent in practice. Our proof is conceptually simple: a uniform Polyak-Lojasiewicz (PL) inequality and uniform Lipschitz smoothness constant are guaranteed for a sufficient number of iterations, starting from our random initialization. Our proof method should be useful for extending and simplifying convergence analyses for a broader class of nonconvex low-rank factorization problems",
    "checked": true,
    "id": "ab4184ba6f0e7bfb2eccc5f2e489b12df29c2982",
    "semantic_title": "convergence of alternating gradient descent for matrix factorization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3FJaFElIVN": {
    "title": "GLIME: General, Stable and Local LIME Explanation",
    "volume": "spotlight",
    "abstract": "As black-box machine learning models become more complex and are applied in high-stakes settings, the need for providing explanations for their predictions becomes crucial. Although Local Interpretable Model-agnostic Explanations (LIME) \\cite{ribeiro2016should} is a widely adopted method for understanding model behavior, it suffers from instability with respect to random seeds \\cite{zafar2019dlime, shankaranarayana2019alime, bansal2020sam} and exhibits low local fidelity (i.e., how the explanation explains model's local behaviors) \\cite{rahnama2019study, laugel2018defining}. Our study demonstrates that this instability is caused by small sample weights, resulting in the dominance of regularization and slow convergence. Additionally, LIME's sampling approach is non-local and biased towards the reference, leading to diminished local fidelity and instability to references. To address these challenges, we propose \\textsc{Glime}, an enhanced framework that extends LIME and unifies several previous methods. Within the \\textsc{Glime} framework, we derive an equivalent formulation of LIME that achieves significantly faster convergence and improved stability. By employing a local and unbiased sampling distribution, \\textsc{Glime} generates explanations with higher local fidelity compared to LIME, while being independent of the reference choice. Moreover, \\textsc{Glime} offers users the flexibility to choose sampling distribution based on their specific scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TczT2jiPT5": {
    "title": "The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance",
    "volume": "spotlight",
    "abstract": "Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We demonstrate through experiments that our framework recovers variable importance rankings for complex simulation setups where other methods fail. Further, we show that our framework accurately estimates the _true importance_ of a variable for the underlying data distribution. We provide theoretical guarantees on the consistency and finite sample error rates for our estimator. Finally, we demonstrate its utility with a real-world case study exploring which genes are important for predicting HIV load in persons with HIV, highlighting an important gene that has not previously been studied in connection with HIV",
    "checked": true,
    "id": "a0ab2a87324bd3df4c7dd89d8b372b90e232934b",
    "semantic_title": "the rashomon importance distribution: getting rid of unstable, single model-based variable importance",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UdaTyy0BNB": {
    "title": "Double Gumbel Q-Learning",
    "volume": "spotlight",
    "abstract": "We show that Deep Neural Networks introduce two heteroscedastic Gumbel noise sources into Q-Learning. To account for these noise sources, we propose Double Gumbel Q-Learning, a Deep Q-Learning algorithm applicable for both discrete and continuous control. In discrete control, we derive a closed-form expression for the loss function of our algorithm. In continuous control, this loss function is intractable and we therefore derive an approximation with a hyperparameter whose value regulates pessimism in Q-Learning. We present a default value for our pessimism hyperparameter that enables DoubleGum to outperform DDPG, TD3, SAC, XQL, quantile regression, and Mixture-of-Gaussian Critics in aggregate over 33 tasks from DeepMind Control, MuJoCo, MetaWorld, and Box2D and show that tuning this hyperparameter may further improve sample efficiency",
    "checked": false,
    "id": "9ed54de8f43499c4d719fbcc31a4f65f337d95f5",
    "semantic_title": "double deep q-learning in opponent modeling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FAZ3i0hvm0": {
    "title": "A Privacy-Friendly Approach to Data Valuation",
    "volume": "spotlight",
    "abstract": "Data valuation, a growing field that aims at quantifying the usefulness of individual data sources for training machine learning (ML) models, faces notable yet often overlooked privacy challenges. This paper studies these challenges with a focus on KNN-Shapley, one of the most practical data valuation methods nowadays. We first emphasize the inherent privacy risks of KNN-Shapley, and demonstrate the significant technical challenges in adapting KNN-Shapley to accommodate differential privacy (DP). To overcome these challenges, we introduce TKNN-Shapley, a refined variant of KNN-Shapley that is privacy-friendly, allowing for straightforward modifications to incorporate DP guarantee (DP-TKNN-Shapley). We show that DP-TKNN-Shapley has several advantages and offers a superior privacy-utility tradeoff compared to naively privatized KNN-Shapley. Moreover, even non-private TKNN-Shapley matches KNN-Shapley's performance in discerning data quality. Overall, our findings suggest that TKNN-Shapley is a promising alternative to KNN-Shapley, particularly for real-world applications involving sensitive data",
    "checked": false,
    "id": "96c827eea1a35a407616ee564d8c657b16399602",
    "semantic_title": "threshold knn-shapley: a linear-time and privacy-friendly approach to data valuation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5AMa9fiyJq": {
    "title": "Common Ground in Cooperative Communication",
    "volume": "spotlight",
    "abstract": "Cooperative communication plays a fundamental role in theories of human-human interaction--cognition, culture, development, language, etc.--as well as human-robot interaction. The core challenge in cooperative communication is the problem of common ground: having enough shared knowledge and understanding to successfully communicate. Prior models of cooperative communication, however, uniformly assume the strongest form of common ground, perfect and complete knowledge sharing, and, therefore, fail to capture the core challenge of cooperative communication. We propose a general theory of cooperative communication that is mathematically principled and explicitly defines a spectrum of common ground possibilities, going well beyond that of perfect and complete knowledge sharing, on spaces that permit arbitrary representations of data and hypotheses. Our framework is a strict generalization of prior models of cooperative communication. After considering a parametric form of common ground and viewing the data selection and hypothesis inference processes of communication as encoding and decoding, we establish a connection to variational autoencoding, a powerful model in modern machine learning. Finally, we carry out a series of empirical simulations to support and elaborate on our theoretical results",
    "checked": false,
    "id": "600ece9cf568fe5739cc2468d8febf008a07bc35",
    "semantic_title": "circular formation control for the cooperative ground target tracking of unmanned aerial vehicle",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Ki6DqBXss4": {
    "title": "Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms",
    "volume": "spotlight",
    "abstract": "This paper focuses on supervised and unsupervised online label shift, where the class marginals $Q(y)$ varies but the class-conditionals $Q(x|y)$ remain invariant. In the unsupervised setting, our goal is to adapt a learner, trained on some offline labeled data, to changing label distributions given unlabeled online data. In the supervised setting, we must both learn a classifier and adapt to the dynamically evolving class marginals given only labeled online data. We develop novel algorithms that reduce the adaptation problem to online regression and guarantee optimal dynamic regret without any prior knowledge of the extent of drift in the label distribution. Our solution is based on bootstrapping the estimates of *online regression oracles* that track the drifting proportions. Experiments across numerous simulated and real-world online label shift scenarios demonstrate the superior performance of our proposed approaches, often achieving 1-3% improvement in accuracy while being sample and computationally efficient. Code is publicly available at https://github.com/Anon-djiwh/OnlineLabelShift",
    "checked": true,
    "id": "62f952c330d7e535b350a2e6f73a67b4e04bcd96",
    "semantic_title": "online label shift: optimal dynamic regret meets practical algorithms",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=rUf0GV5CuU": {
    "title": "Locality Sensitive Hashing in Fourier Frequency Domain For Soft Set Containment Search",
    "volume": "spotlight",
    "abstract": "In many search applications related to passage retrieval, text entailment, and subgraph search, the query and each 'document' is a set of elements, with a document being relevant if it contains the query. These elements are not represented by atomic IDs, but by embedded representations, thereby extending set containment to *soft* set containment. Recent applications address soft set containment by encoding sets into fixed-size vectors and checking for elementwise *vector* *dominance*. This 0/1 property can be relaxed to an asymmetric *hinge* *distance* for scoring and ranking candidate documents. Here we focus on data-sensitive, trainable indices for fast retrieval of relevant documents. Existing LSH methods are designed for mostly symmetric or few simple asymmetric distance functions, which are not suitable for hinge distance. Instead, we transform hinge distance into a proposed *dominance* *similarity* measure, to which we then apply a Fourier transform, thereby expressing dominance similarity as an expectation of inner products of functions in the frequency domain. Next, we approximate the expectation with an importance-sampled estimate. The overall consequence is that now we can use a traditional LSH, but in the frequency domain. To ensure that the LSH uses hash bits efficiently, we learn hash functions that are sensitive to both corpus and query distributions, mapped to the frequency domain. Our experiments show that the proposed asymmetric dominance similarity is critical to the targeted applications, and that our LSH, which we call FourierHashNet, provides a better query time vs. retrieval quality trade-off, compared to several baselines. Both the Fourier transform and the trainable hash codes contribute to performance gains",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EldbUlZtbd": {
    "title": "Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models",
    "volume": "spotlight",
    "abstract": "Language models learn a great quantity of factual information during pretraining, and recent work localizes this information to specific model weights like mid-layer MLP weights. In this paper, we find that we can change how a fact is stored in a model by editing weights that are in a different location than where existing methods suggest that the fact is stored. This is surprising because we would expect that localizing facts to specific model parameters would tell us where to manipulate knowledge in models, and this assumption has motivated past work on model editing methods. Specifically, we show that localization conclusions from representation denoising (also known as Causal Tracing) do not provide any insight into which model MLP layer would be best to edit in order to override an existing stored fact with a new one. This finding raises questions about how past work relies on Causal Tracing to select which model layers to edit. Next, we consider several variants of the editing problem, including erasing and amplifying facts. For one of our editing problems, editing performance does relate to localization results from representation denoising, but we find that which layer we edit is a far better predictor of performance. Our results suggest, counterintuitively, that better mechanistic understanding of how pretrained language models work may not always translate to insights about how to best change their behavior",
    "checked": true,
    "id": "9c0a434b240299cec0029a1be93ab263d7ec9963",
    "semantic_title": "does localization inform editing? surprising differences in causality-based localization vs. knowledge editing in language models",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=cpUuSV8kRw": {
    "title": "Group Fairness in Peer Review",
    "volume": "spotlight",
    "abstract": "Large conferences such as NeurIPS and AAAI serve as crossroads of various AI fields, since they attract submissions from a vast number of communities. However, in some cases, this has resulted in a poor reviewing experience for some communities, whose submissions get assigned to less qualified reviewers outside of their communities. An often-advocated solution is to break up any such large conference into smaller conferences, but this can lead to isolation of communities and harm interdisciplinary research. We tackle this challenge by introducing a notion of group fairness, called the core, which requires that every possible community (subset of researchers) to be treated in a way that prevents them from unilaterally benefiting by withdrawing from a large conference. We study a simple peer review model, prove that it always admits a reviewing assignment in the core, and design an efficient algorithm to find one such assignment. We use real data from CVPR and ICLR conferences to compare our algorithm to existing reviewing assignment algorithms on a number of metrics",
    "checked": true,
    "id": "1a33e251c08524213854c1c3b2d5b8bb17e36869",
    "semantic_title": "group fairness in peer review",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=0VcvYQ3uPh": {
    "title": "Improved Frequency Estimation Algorithms with and without Predictions",
    "volume": "spotlight",
    "abstract": "Estimating frequencies of elements appearing in a data stream is a key task in large-scale data analysis. Popular sketching approaches to this problem (e.g., CountMin and CountSketch) come with worst-case guarantees that probabilistically bound the error of the estimated frequencies for any possible input. The work of Hsu et al.~(2019) introduced the idea of using machine learning to tailor sketching algorithms to the specific data distribution they are being run on. In particular, their learning-augmented frequency estimation algorithm uses a learned heavy-hitter oracle which predicts which elements will appear many times in the stream. We give a novel algorithm, which in some parameter regimes, already theoretically outperforms the learning based algorithm of Hsu et al. *without* the use of any predictions. Augmenting our algorithm with heavy-hitter predictions further reduces the error and improves upon the state of the art. Empirically, our algorithms achieve superior performance in all experiments compared to prior approaches",
    "checked": false,
    "id": "ad152854be1497826c5b7929ea2d137aa1b0d5e4",
    "semantic_title": "pollutant flux estimation of the lijiang river based on an improved prediction-correction method",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=75v88kyyko": {
    "title": "Hierarchical clustering with dot products recovers hidden tree structure",
    "volume": "spotlight",
    "abstract": "In this paper we offer a new perspective on the well established agglomerative clustering algorithm, focusing on recovery of hierarchical structure. We recommend a simple variant of the standard algorithm, in which clusters are merged by maximum average dot product and not, for example, by minimum distance or within-cluster variance. We demonstrate that the tree output by this algorithm provides a bona fide estimate of generative hierarchical structure in data, under a generic probabilistic graphical model. The key technical innovations are to understand how hierarchical information in this model translates into tree geometry which can be recovered from data, and to characterise the benefits of simultaneously growing sample size and data dimension. We demonstrate superior tree recovery performance with real data over existing approaches such as UPGMA, Ward's method, and HDBSCAN",
    "checked": true,
    "id": "e7a5ee90c6c79710d517a187f20f776b769081c6",
    "semantic_title": "hierarchical clustering with dot products recovers hidden tree structure",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5bWW9Eop7l": {
    "title": "The Goldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs",
    "volume": "spotlight",
    "abstract": "Despite widespread use of LLMs as conversational agents, evaluations of performance fail to capture a crucial aspect of communication: interpreting language in context---incorporating its pragmatics. Humans interpret language using beliefs and prior knowledge about the world. For example, we intuitively understand the response \"I wore gloves\" to the question \"Did you leave fingerprints?\" as meaning \"No\". To investigate whether LLMs have the ability to make this type of inference, known as an implicature, we design a simple task and evaluate four categories of widely used state-of-the-art models. We find that, despite only evaluating on utterances that require a binary inference (yes or no), models in three of these categories perform close to random. However, LLMs instruction-tuned at the example-level perform significantly better. These results suggest that certain fine-tuning strategies are far better at inducing pragmatic understanding in models. We present our findings as the starting point for further research into evaluating how LLMs interpret language in context and to drive the development of more pragmatic and useful models of human discourse",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P1TCHxJwLB": {
    "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling",
    "volume": "spotlight",
    "abstract": "Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling. Recently, there has been a renewed interest in using linear RNNs for efficient sequence modeling. These linear RNNs often employ gating mechanisms in the output of the linear recurrence layer while ignoring the significance of using forget gates within the recurrence. In this paper, we propose a gated linear RNN model dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes forget gates that are lower bounded by a learnable value. The lower bound increases monotonically when moving up layers. This allows the upper layers to model long-term dependencies and the lower layers to model more local, short-term dependencies. Experiments on language modeling, image classification, and long-range arena benchmarks showcase the efficiency and effectiveness of our proposed model. The source code is available at https://github.com/OpenNLPLab/HGRN",
    "checked": true,
    "id": "434d751d355d7a7c20efa570e785c76286245e77",
    "semantic_title": "hierarchically gated recurrent neural network for sequence modeling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=phnN1eu5AX": {
    "title": "Learning Probabilistic Symmetrization for Architecture Agnostic Equivariance",
    "volume": "spotlight",
    "abstract": "We present a novel framework to overcome the limitations of equivariant architectures in learning functions with group symmetries. In contrary to equivariant architectures, the framework uses an arbitrary backbone (such as an MLP or a transformer) and symmetrizes it to be equivariant to given group by employing a small equivariant network that parameterizes the probabilistic distribution underlying the symmetrization. The distribution is end-to-end trained with the backbone which can maximize performance while reducing sample complexity of symmetrization. We show that this approach ensures not only equivariance to the given group but also universal approximation ability in expectation. We implement our method on a simple patch-based transformer backbone initialized from pretrained vision transformer, and test it for a wide range of symmetry groups including permutation and Euclidean groups and their combinations. Empirical tests show competitive results against tailored equivariant architectures, suggesting the potential for learning equivariant functions for diverse groups using a non-equivariant universal backbone. We further show evidence of enhanced learning in symmetric modalities, like graphs, when pretrained from non-symmetric modalities, like vision",
    "checked": true,
    "id": "ae7ae7b7e123b8d5ec86cc1c53548943e88f386f",
    "semantic_title": "learning probabilistic symmetrization for architecture agnostic equivariance",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ZQMlfNijY5": {
    "title": "Normalizing flow neural networks by JKO scheme",
    "volume": "spotlight",
    "abstract": "Normalizing flow is a class of deep generative models for efficient sampling and likelihood estimation, which achieves attractive performance, particularly in high dimensions. The flow is often implemented using a sequence of invertible residual blocks. Existing works adopt special network architectures and regularization of flow trajectories. In this paper, we develop a neural ODE flow network called JKO-iFlow, inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which unfolds the discrete-time dynamic of the Wasserstein gradient flow. The proposed method stacks residual blocks one after another, allowing efficient block-wise training of the residual blocks, avoiding sampling SDE trajectories and score matching or variational learning, thus reducing the memory load and difficulty in end-to-end training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the induced trajectory in probability space to improve the model accuracy further. Experiments with synthetic and real data show that the proposed JKO-iFlow network achieves competitive performance compared with existing flow and diffusion models at a significantly reduced computational and memory cost",
    "checked": true,
    "id": "56f98c6b773825c3062e3b061f6c8844e8e577bb",
    "semantic_title": "normalizing flow neural networks by jko scheme",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=LTbIUkN95h": {
    "title": "Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applications to Queueing Networks",
    "volume": "spotlight",
    "abstract": "This paper considers a class of reinforcement learning problems, which involve systems with two types of states: stochastic and pseudo-stochastic. In such systems, stochastic states follow a stochastic transition kernel while the transitions of pseudo-stochastic states are deterministic {\\em given} the stochastic states/transitions. We refer to such systems as mixed systems, which are widely used in various applications, including Manufacturing systems, communication networks, and queueing networks. We propose a sample-efficient RL method that accelerates learning by generating augmented data samples. The proposed algorithm is data-driven (model-free), but it learns the policy from data samples from both real and augmented samples. This method significantly improves learning by reducing the sample complexity such that the dataset only needs to have sufficient coverage of the stochastic states. We analyze the sample complexity of the proposed method under Fitted Q Iteration (FQI) and demonstrate that the optimality gap decreases as $O\\left(\\sqrt{\\frac{1}{n}}+\\sqrt{\\frac{1}{m}}\\right),$ where $n$ represents the number of real samples, and $m$ is the number of augmented samples per real sample. It is important to note that without augmented samples, the optimality gap is $O(1)$ due to the insufficient data coverage of the pseudo-stochastic states. Our experimental results on multiple queueing network applications confirm that the proposed method indeed significantly accelerates both deep Q-learning and deep policy gradient",
    "checked": true,
    "id": "cc563dcbacdb5474de52535b1de384aebb30b597",
    "semantic_title": "sample efficient reinforcement learning in mixed systems through augmented samples and its applications to queueing networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=uvdJgFFzby": {
    "title": "Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers",
    "volume": "spotlight",
    "abstract": "Autoregressive Transformers adopted in Large Language Models (LLMs) are hard to scale to long sequences. Despite several works trying to reduce their computational cost, most of LLMs still adopt attention layers between all pairs of tokens in the sequence, thus incurring a quadratic cost. In this study, we present a novel approach that dynamically prunes contextual information while preserving the model's expressiveness, resulting in reduced memory and computational requirements during inference. Our method employs a learnable mechanism that determines which uninformative tokens can be dropped from the context at any point across the generation process. By doing so, our approach not only addresses performance concerns but also enhances interpretability, providing valuable insight into the model's decision-making process. Our technique can be applied to existing pre-trained models through a straightforward fine-tuning process, and the pruning strength can be specified by a sparsity parameter. Notably, our empirical findings demonstrate that we can effectively prune up to 80\\% of the context without significant performance degradation on downstream tasks, offering a valuable tool for mitigating inference costs. Our reference implementation achieves up to $2\\times$ increase in inference throughput and even greater memory savings",
    "checked": true,
    "id": "c193eb176985a81ae64f63c5e50b2f11cfb7c4e6",
    "semantic_title": "dynamic context pruning for efficient and interpretable autoregressive transformers",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Ex3oJEKS53": {
    "title": "Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures",
    "volume": "spotlight",
    "abstract": "The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with *weight-sharing*. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- *expand* and *reduce*. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in $50$-$75$\\% of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures",
    "checked": true,
    "id": "35bfd3eaa9760f04af07199faab4972f42b0fde4",
    "semantic_title": "kronecker-factored approximate curvature for modern neural network architectures",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eVrmcOvJV4": {
    "title": "Inferring the Future by Imagining the Past",
    "volume": "spotlight",
    "abstract": "A single panel of a comic book can say a lot: it can depict not only where the characters currently are, but also their motions, their motivations, their emotions, and what they might do next. More generally, humans routinely infer complex sequences of past and future events from a *static snapshot* of a *dynamic scene*, even in situations they have never seen before. In this paper, we model how humans make such rapid and flexible inferences. Building on a long line of work in cognitive science, we offer a Monte Carlo algorithm whose inferences correlate well with human intuitions in a wide variety of domains, while only using a small, cognitively-plausible number of samples. Our key technical insight is a surprising connection between our inference problem and Monte Carlo path tracing, which allows us to apply decades of ideas from the computer graphics community to this seemingly-unrelated theory of mind task",
    "checked": true,
    "id": "d75ba73f2471f1c163bffdd94a731c5335733d84",
    "semantic_title": "inferring the future by imagining the past",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nCLdsEzZBV": {
    "title": "The Equivalence of Dynamic and Strategic Stability under Regularized Learning in Games",
    "volume": "spotlight",
    "abstract": "In this paper, we examine the long-run behavior of regularized, no-regret learning in finite N-player games. A well-known result in the field states that the empirical frequencies of play under no-regret learning converge to the game's set of coarse correlated equilibria; however, our understanding of how the players' _actual strategies_ evolve over time is much more limited – and, in many cases, non-existent. This issue is exacerbated further by a series of recent results showing that _only_ strict Nash equilibria are stable and attracting under regularized learning, thus making the relation between learning and _pointwise_ solution concepts particularly elusive. In lieu of this, we take a more general approach and instead seek to characterize the _setwise_ rationality properties of the players' day-to-day trajectory of play. To do so, we focus on one of the most stringent criteria of setwise strategic stability, namely that any unilateral deviation from the set in question incurs a cost to the deviator – a property known as _closedness under better replies_ (club). In so doing, we obtain a remarkable equivalence between strategic and dynamic stability: _a product of pure strategies is closed under better replies if and only if its span is stable and attracting under regularized learning._ In addition, we estimate the rate of convergence to such sets, and we show that methods based on entropic regularization (like the exponential weights algorithm) converge at a geometric rate, while projection-based methods converge within a finite number of iterations, even with bandit, payoff-based feedback",
    "checked": true,
    "id": "e64b94039a83bceca573fa00b1805e8820bbce72",
    "semantic_title": "the equivalence of dynamic and strategic stability under regularized learning in games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HwhRehMr4a": {
    "title": "Future-Dependent Value-Based Off-Policy Evaluation in POMDPs",
    "volume": "spotlight",
    "abstract": "We study off-policy evaluation (OPE) for partially observable MDPs (POMDPs) with general function approximation. Existing methods such as sequential importance sampling estimators and fitted-Q evaluation suffer from the curse of horizon in POMDPs. To circumvent this problem, we develop a novel model-free OPE method by introducing future-dependent value functions that take future proxies as inputs. Future-dependent value functions play similar roles as classical value functions in fully-observable MDPs. We derive a new off-policy Bellman equation for future-dependent value functions as conditional moment equations that use history proxies as instrumental variables. We further propose a minimax learning method to learn future-dependent value functions using the new Bellman equation. We obtain the PAC result, which implies our OPE estimator is close to the true policy value as long as futures and histories contain sufficient information about latent states, and the Bellman completeness. Our code is available at https://github.com/aiueola/neurips2023-future-dependent-ope",
    "checked": true,
    "id": "d2a22a46fa4b4e7c917d434576b6b7ae0a0d09b5",
    "semantic_title": "future-dependent value-based off-policy evaluation in pomdps",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=y08bkEtNBK": {
    "title": "WITRAN: Water-wave Information Transmission and Recurrent Acceleration Network for Long-range Time Series Forecasting",
    "volume": "spotlight",
    "abstract": "Capturing semantic information is crucial for accurate long-range time series forecasting, which involves modeling global and local correlations, as well as discovering long- and short-term repetitive patterns. Previous works have partially addressed these issues separately, but have not been able to address all of them simultaneously. Meanwhile, their time and memory complexities are still not sufficiently low for long-range forecasting. To address the challenge of capturing different types of semantic information, we propose a novel Water-wave Information Transmission (WIT) framework. This framework captures both long- and short-term repetitive patterns through bi-granular information transmission. It also models global and local correlations by recursively fusing and selecting information using Horizontal Vertical Gated Selective Unit (HVGSU). In addition, to improve the computing efficiency, we propose a generic Recurrent Acceleration Network (RAN) which reduces the time complexity to $\\mathcal{O}(\\sqrt{L})$ while maintaining the memory complexity at $\\mathcal{O}(L)$. Our proposed method, called Water-wave Information Transmission and Recurrent Acceleration Network (WITRAN), outperforms the state-of-the-art methods by 5.80% and 14.28% on long-range and ultra-long-range time series forecasting tasks respectively, as demonstrated by experiments on four benchmark datasets. The code is available at: https://github.com/Water2sea/WITRAN",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=htM8yp2EwX": {
    "title": "AMDP: An Adaptive Detection Procedure for False Discovery Rate Control in High-Dimensional Mediation Analysis",
    "volume": "spotlight",
    "abstract": "High-dimensional mediation analysis is often associated with a multiple testing problem for detecting significant mediators. Assessing the uncertainty of this detecting process via false discovery rate (FDR) has garnered great interest. To control the FDR in multiple testing, two essential steps are involved: ranking and selection. Existing approaches either construct p-values without calibration or disregard the joint information across tests, leading to conservation in FDR control or non-optimal ranking rules for multiple hypotheses. In this paper, we develop an adaptive mediation detection procedure (referred to as \"AMDP\") to identify relevant mediators while asymptotically controlling the FDR in high-dimensional mediation analysis. AMDP produces the optimal rule for ranking hypotheses and proposes a data-driven strategy to determine the threshold for mediator selection. This novel method captures information from the proportions of composite null hypotheses and the distribution of p-values, which turns the high dimensionality into an advantage instead of a limitation. The numerical studies on synthetic and real data sets illustrate the performances of AMDP compared with existing approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yEfmhgwslQ": {
    "title": "Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency",
    "volume": "spotlight",
    "abstract": "Interpreting time series models is uniquely challenging because it requires identifying both the location of time series signals that drive model predictions and their matching to an interpretable temporal pattern. While explainers from other modalities can be applied to time series, their inductive biases do not transfer well to the inherently challenging interpretation of time series. We present TimeX, a time series consistency model for training explainers. TimeX trains an interpretable surrogate to mimic the behavior of a pretrained time series model. It addresses the issue of model faithfulness by introducing model behavior consistency, a novel formulation that preserves relations in the latent space induced by the pretrained model with relations in the latent space induced by TimeX. TimeX provides discrete attribution maps and, unlike existing interpretability methods, it learns a latent space of explanations that can be used in various ways, such as to provide landmarks to visually aggregate similar explanations and easily recognize temporal patterns. We evaluate TimeX on eight synthetic and real-world datasets and compare its performance against state-of-the-art interpretability methods. We also conduct case studies using physiological time series. Quantitative evaluations demonstrate that TimeX achieves the highest or second-highest performance in every metric compared to baselines across all datasets. Through case studies, we show that the novel components of TimeX show potential for training faithful, interpretable models that capture the behavior of pretrained time series models",
    "checked": true,
    "id": "4337200e8063bddc97c508efeb1ef81f118abe30",
    "semantic_title": "encoding time-series explanations through self-supervised model behavior consistency",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=b1JPBGJhUi": {
    "title": "Stable Nonconvex-Nonconcave Training via Linear Interpolation",
    "volume": "spotlight",
    "abstract": "This paper presents a theoretical analysis of linear interpolation as a principled method for stabilizing (large-scale) neural network training. We argue that instabilities in the optimization process are often caused by the nonmonotonicity of the loss landscape and show how linear interpolation can help by leveraging the theory of nonexpansive operators. We construct a new optimization scheme called relaxed approximate proximal point (RAPP), which is the first explicit method to achieve last iterate convergence rates for the full range of cohypomonotone problems. The construction extends to constrained and regularized settings. By replacing the inner optimizer in RAPP we rediscover the family of Lookahead algorithms for which we establish convergence in cohypomonotone problems even when the base optimizer is taken to be gradient descent ascent. The range of cohypomonotone problems in which Lookahead converges is further expanded by exploiting that Lookahead inherits the properties of the base optimizer. We corroborate the results with experiments on generative adversarial networks which demonstrates the benefits of the linear interpolation present in both RAPP and Lookahead",
    "checked": true,
    "id": "4b5c7954f9e5dc58477c814b45c7d2ea10b3c4de",
    "semantic_title": "stable nonconvex-nonconcave training via linear interpolation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6EaLIw3W7c": {
    "title": "LinkerNet: Fragment Poses and Linker Co-Design with 3D Equivariant Diffusion",
    "volume": "spotlight",
    "abstract": "Targeted protein degradation techniques, such as PROteolysis TArgeting Chimeras (PROTACs), have emerged as powerful tools for selectively removing disease-causing proteins. One challenging problem in this field is designing a linker to connect different molecular fragments to form a stable drug-candidate molecule. Existing models for linker design assume that the relative positions of the fragments are known, which may not be the case in real scenarios. In this work, we address a more general problem where the poses of the fragments are *unknown* in 3D space. We develop a 3D equivariant diffusion model that jointly learns the generative process of both fragment poses and the 3D structure of the linker. By viewing fragments as rigid bodies, we design a fragment pose prediction module inspired by the Newton-Euler equations in rigid body mechanics. Empirical studies on ZINC and PROTAC-DB datasets demonstrate that our model can generate chemically valid, synthetically-accessible, and low-energy molecules under both unconstrained and constrained generation settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pya0kCEpDk": {
    "title": "Private estimation algorithms for stochastic block models and mixture models",
    "volume": "spotlight",
    "abstract": "We introduce general tools for designing efficient private estimation algorithms, in the high-dimensional settings, whose statistical guarantees almost match those of the best known non-private algorithms. To illustrate our techniques, we consider two problems: recovery of stochastic block models and learning mixtures of spherical Gaussians. For the former, we present the first efficient $(\\epsilon, \\delta)$-differentially private algorithm for both weak recovery and exact recovery. Previously known algorithms achieving comparable guarantees required quasi-polynomial time. For the latter, we design an $(\\epsilon, \\delta)$-differentially private algorithm that recovers the centers of the $k$-mixture when the minimum separation is at least $ O(k^{1/t}\\sqrt{t})$. For all choices of $t$, this algorithm requires sample complexity $n\\geq k^{O(1)}d^{O(t)}$ and time complexity $(nd)^{O(t)}$. Prior work required either an additional additive $\\Omega(\\sqrt{\\log n})$ term in the minimum separation or an explicit upper bound on the Euclidean norm of the centers",
    "checked": true,
    "id": "7c5f3e1868f59daec162c953f8ec2755fd12fbbe",
    "semantic_title": "private estimation algorithms for stochastic block models and mixture models",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=tbbId8u7nP": {
    "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability",
    "volume": "spotlight",
    "abstract": "We show how to \"compile\" human-readable programs into standard decoder-only transformer models. Our compiler, Tracr, generates models with known structure. This structure can be used to design experiments. For example, we use it to study \"superposition\" in transformers that execute multi-step algorithms. Additionally, the known structure of Tracr-compiled models can serve as _ground-truth_ for evaluating interpretability methods. Commonly, because the \"programs\" learned by transformers are unknown it is unclear whether an interpretation succeeded. We demonstrate our approach by implementing and examining programs including computing token frequencies, sorting, and parenthesis checking. We provide an open-source implementation of Tracr at https://github.com/google-deepmind/tracr",
    "checked": true,
    "id": "a5cc5edcabba4c9c62cfbc3379daa140084a2a24",
    "semantic_title": "tracr: compiled transformers as a laboratory for interpretability",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=nijJN0LHqM": {
    "title": "Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima",
    "volume": "spotlight",
    "abstract": "Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent step based on the gradient at a perturbation $y_t = x_t + \\rho \\frac{\\nabla f(x_t)}{\\lVert \\nabla f(x_t) \\rVert}$ of the current point $x_t$. Existing studies prove convergence of SAM for smooth functions, but they do so by assuming decaying perturbation size $\\rho$ and/or no gradient normalization in $y_t$, which is detached from practice. To address this gap, we study deterministic/stochastic versions of SAM with practical configurations (i.e., constant $\\rho$ and gradient normalization in $y_t$) and explore their convergence properties on smooth functions with (non)convexity assumptions. Perhaps surprisingly, in many scenarios, we find out that SAM has limited capability to converge to global minima or stationary points. For smooth strongly convex functions, we show that while deterministic SAM enjoys tight global convergence rates of $\\tilde \\Theta(\\frac{1}{T^2})$, the convergence bound of stochastic SAM suffers an inevitable additive term $\\mathcal O(\\rho^2)$, indicating convergence only up to neighborhoods of optima. In fact, such $\\mathcal O(\\rho^2)$ factors arise for stochastic SAM in all the settings we consider, and also for deterministic SAM in nonconvex cases; importantly, we prove by examples that such terms are unavoidable. Our results highlight vastly different characteristics of SAM with vs. without decaying perturbation size or gradient normalization, and suggest that the intuitions gained from one version may not apply to the other",
    "checked": true,
    "id": "c5ee9fc8bd862efc8afdf0866142ff572dd34c73",
    "semantic_title": "practical sharpness-aware minimization cannot converge all the way to optima",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FQGRkwmRzm": {
    "title": "Streaming PCA for Markovian Data",
    "volume": "spotlight",
    "abstract": "Since its inception in 1982, Oja's algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain starting in stationarity. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in scenarios where data can solely be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the objective is to perform inference on parameters of the stationary distribution. Most convergence guarantees for Oja's algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a \"nearly\" independent data stream. In this paper, we obtain the first near-optimal rate for Oja's algorithm on the entire data, where we remove the logarithmic dependence on the sample size, $n$, resulting from throwing data away in downsampling strategies",
    "checked": true,
    "id": "02d6855a9d8692bfa851043f6a4f263cdd6b52c3",
    "semantic_title": "streaming pca for markovian data",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Xasl21tSOf": {
    "title": "Provable Training for Graph Contrastive Learning",
    "volume": "spotlight",
    "abstract": "Graph Contrastive Learning (GCL) has emerged as a popular training approach for learning node embeddings from augmented graphs without labels. Despite the key principle that maximizing the similarity between positive node pairs while minimizing it between negative node pairs is well established, some fundamental problems are still unclear. Considering the complex graph structure, are some nodes consistently well-trained and following this principle even with different graph augmentations? Or are there some nodes more likely to be untrained across graph augmentations and violate the principle? How to distinguish these nodes and further guide the training of GCL? To answer these questions, we first present experimental evidence showing that the training of GCL is indeed imbalanced across all nodes. To address this problem, we propose the metric \"node compactness\", which is the lower bound of how a node follows the GCL principle related to the range of augmentations. We further derive the form of node compactness theoretically through bound propagation, which can be integrated into binary cross-entropy as a regularization. To this end, we propose the PrOvable Training (POT) for GCL, which regularizes the training of GCL to encode node embeddings that follows the GCL principle better. Through extensive experiments on various benchmarks, POT consistently improves the existing GCL approaches, serving as a friendly plugin",
    "checked": true,
    "id": "76d04818252ccb87f38c8ea8a02bc700b4519f5a",
    "semantic_title": "provable training for graph contrastive learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bNIHdyunFC": {
    "title": "Learning Layer-wise Equivariances Automatically using Gradients",
    "volume": "spotlight",
    "abstract": "Convolutions encode equivariance symmetries into neural networks leading to better generalisation performance. However, symmetries provide fixed hard constraints on the functions a network can represent, need to be specified in advance, and can not be adapted. Our goal is to allow flexible symmetry constraints that can automatically be learned from data using gradients. Learning symmetry and associated weight connectivity structures from scratch is difficult for two reasons. First, it requires efficient and flexible parameterisations of layer-wise equivariances. Secondly, symmetries act as constraints and are therefore not encouraged by training losses measuring data fit. To overcome these challenges, we improve parameterisations of soft equivariance and learn the amount of equivariance in layers by optimising the marginal likelihood, estimated using differentiable Laplace approximations. The objective balances data fit and model complexity enabling layer-wise symmetry discovery in deep networks. We demonstrate the ability to automatically learn layer-wise equivariances on image classification tasks, achieving equivalent or improved performance over baselines with hard-coded symmetry",
    "checked": true,
    "id": "a3ac0ef3a7687108e55903426b5d364ba65dc0c5",
    "semantic_title": "learning layer-wise equivariances automatically using gradients",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I50HbChk3U": {
    "title": "Provably Bounding Neural Network Preimages",
    "volume": "spotlight",
    "abstract": "Most work on the formal verification of neural networks has focused on bounding the set of outputs that correspond to a given set of inputs (for example, bounded perturbations of a nominal input). However, many use cases of neural network verification require solving the inverse problem, or over-approximating the set of inputs that lead to certain outputs. We present the INVPROP algorithm for verifying properties over the preimage of a linearly constrained output set, which can be combined with branch-and-bound to increase precision. Contrary to other approaches, our efficient algorithm is GPU-accelerated and does not require a linear programming solver. We demonstrate our algorithm for identifying safe control regions for a dynamical system via backward reachability analysis, verifying adversarial robustness, and detecting out-of-distribution inputs to a neural network. Our results show that in certain settings, we find over-approximations over $2500\\times$ tighter than prior work while being $2.5\\times$ faster. By strengthening robustness verification with output constraints, we consistently verify more properties than the previous state-of-the-art on multiple benchmarks, including a large model with 167k neurons in VNN-COMP 2023. Our algorithm has been incorporated into the $\\alpha,\\beta$-CROWN verifier, available at https://abcrown.org",
    "checked": true,
    "id": "0ad90df9d692dfb040a9aa6dab1e6065de0cae4a",
    "semantic_title": "provably bounding neural network preimages",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=JOkgEY9os2": {
    "title": "MMD-Fuse: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting",
    "volume": "spotlight",
    "abstract": "We propose novel statistics which maximise the power of a two-sample test based on the Maximum Mean Discrepancy (MMD), by adapting over the set of kernels used in defining it. For finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum. Exponential concentration bounds are proved for our proposed statistics under the null and alternative. We further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting. This technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders. We highlight the applicability of our MMD-Fuse tests on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests",
    "checked": true,
    "id": "2311d3b473a4d49a07337da1bbe948a03c21e22c",
    "semantic_title": "mmd-fuse: learning and combining kernels for two-sample testing without data splitting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9STYRIVx6u": {
    "title": "Mean-field Langevin dynamics: Time-space discretization, stochastic gradient, and variance reduction",
    "volume": "spotlight",
    "abstract": "The mean-field Langevin dynamics (MFLD) is a nonlinear generalization of the Langevin dynamics that incorporates a distribution-dependent drift, and it naturally arises from the optimization of two-layer neural networks via (noisy) gradient descent. Recent works have shown that MFLD globally minimizes an entropy-regularized convex functional in the space of measures. However, all prior analyses assumed the infinite-particle or continuous-time limit, and cannot handle stochastic gradient updates. We provide a general framework to prove a uniform-in-time propagation of chaos for MFLD that takes into account the errors due to finite-particle approximation, time-discretization, and stochastic gradient. To demonstrate the wide applicability of our framework, we establish quantitative convergence rate guarantees to the regularized global optimal solution for $(i)$ a wide range of learning problems such as mean-field neural network and MMD minimization, and $(ii)$ different gradient estimators including SGD and SVRG. Despite the generality of our results, we achieve an improved convergence rate in both the SGD and SVRG settings when specialized to the standard Langevin dynamics",
    "checked": false,
    "id": "898d1fffc0f2ec0a74c73b2802413dc270d6ac75",
    "semantic_title": "convergence of mean-field langevin dynamics: time and space discretization, stochastic gradient, and variance reduction",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=B4G87Bq5wA": {
    "title": "Fast Approximation of Similarity Graphs with Kernel Density Estimation",
    "volume": "spotlight",
    "abstract": "Constructing a similarity graph from a set $X$ of data points in $ \\mathbb{R}^d$ is the first step of many modern clustering algorithms. However, typical constructions of a similarity graph have high time complexity, and a quadratic space dependency with respect to $|X|$. We address this limitation and present a new algorithmic framework that constructs a sparse approximation of the fully connected similarity graph while preserving its cluster structure. Our presented algorithm is based on the kernel density estimation problem, and is applicable for arbitrary kernel functions. We compare our designed algorithm with the well-known implementations from the scikit-learn library and the FAISS library, and find that our method significantly outperforms the implementation from both libraries on a variety of datasets",
    "checked": true,
    "id": "df877eda049bb89c2ff1eebfa493fc9772e5e764",
    "semantic_title": "fast approximation of similarity graphs with kernel density estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iWGC0Nsq9i": {
    "title": "Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond",
    "volume": "spotlight",
    "abstract": "Recent research has developed several Monte Carlo methods for estimating the normalization constant (partition function) based on the idea of annealing. This means sampling successively from a path of distributions which interpolate between a tractable \"proposal\" distribution and the unnormalized \"target\" distribution. Prominent estimators in this family include annealed importance sampling and annealed noise-contrastive estimation (NCE). Such methods hinge on a number of design choices: which estimator to use, which path of distributions to use and whether to use a path at all; so far, there is no definitive theory on which choices are efficient. Here, we evaluate each design choice by the asymptotic estimation error it produces. First, we show that using NCE is more efficient than the importance sampling estimator, but in the limit of infinitesimal path steps, the difference vanishes. Second, we find that using the geometric path brings down the estimation error from an exponential to a polynomial function of the parameter distance between the target and proposal distributions. Third, we find that the arithmetic path, while rarely used, can offer optimality properties over the universally-used geometric path. In fact, in a particular limit, the optimal path is arithmetic. Based on this theory, we finally propose a two-step estimator to approximate the optimal path in an efficient way",
    "checked": true,
    "id": "38e2b7030b176f6a3c475ca729c88a951f9cb304",
    "semantic_title": "provable benefits of annealing for estimating normalizing constants: importance sampling, noise-contrastive estimation, and beyond",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gGl0n7Onug": {
    "title": "Theoretical and Practical Perspectives on what Influence Functions Do",
    "volume": "spotlight",
    "abstract": "Influence functions (IF) have been seen as a technique for explaining model predictions through the lens of the training data. Their utility is assumed to be in identifying training examples \"responsible\" for a prediction so that, for example, correcting a prediction is possible by intervening on those examples (removing or editing them) and retraining the model. However, recent empirical studies have shown that the existing methods of estimating IF predict the leave-one-out-and-retrain effect poorly. In order to understand the mismatch between the theoretical promise and the practical results, we analyse five assumptions made by IF methods which are problematic for modern-scale deep neural networks and which concern convexity, numeric stability, training trajectory and parameter divergence. This allows us to clarify what can be expected theoretically from IF. We show that while most assumptions can be addressed successfully, the parameter divergence poses a clear limitation on the predictive power of IF: influence fades over training time even with deterministic training. We illustrate this theoretical result with BERT and ResNet models. Another conclusion from the theoretical analysis is that IF are still useful for model debugging and correcting even though some of the assumptions made in prior work do not hold: using natural language processing and computer vision tasks, we verify that mis-predictions can be successfully corrected by taking only a few fine-tuning steps on influential examples",
    "checked": true,
    "id": "01a3ae8808dc61c9c1fffff370430c3a0059cba5",
    "semantic_title": "theoretical and practical perspectives on what influence functions do",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=4L9g1jUDtO": {
    "title": "Generalization in the Face of Adaptivity: A Bayesian Perspective",
    "volume": "spotlight",
    "abstract": "Repeated use of a data sample via adaptively chosen queries can rapidly lead to overfitting, wherein the empirical evaluation of queries on the sample significantly deviates from their mean with respect to the underlying data distribution. It turns out that simple noise addition algorithms suffice to prevent this issue, and differential privacy-based analysis of these algorithms shows that they can handle an asymptotically optimal number of queries. However, differential privacy's worst-case nature entails scaling such noise to the range of the queries even for highly-concentrated queries, or introducing more complex algorithms. In this paper, we prove that straightforward noise-addition algorithms already provide variance-dependent guarantees that also extend to unbounded queries. This improvement stems from a novel characterization that illuminates the core problem of adaptive data analysis. We show that the harm of adaptivity results from the covariance between the new query and a Bayes factor-based measure of how much information about the data sample was encoded in the responses given to past queries. We then leverage this characterization to introduce a new data-dependent stability notion that can bound this covariance",
    "checked": true,
    "id": "a8de171902b3d1ce0765cafa398973b5a693f54d",
    "semantic_title": "generalization in the face of adaptivity: a bayesian perspective",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=yvqqkOn9Pi": {
    "title": "Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis",
    "volume": "spotlight",
    "abstract": "To make reinforcement learning more sample efficient, we need better credit assignment methods that measure an action's influence on future rewards. Building upon Hindsight Credit Assignment (HCA), we introduce Counterfactual Contribution Analysis (COCOA), a new family of model-based credit assignment algorithms. Our algorithms achieve precise credit assignment by measuring the contribution of actions upon obtaining subsequent rewards, by quantifying a counterfactual query: ‘Would the agent still have reached this reward if it had taken another action?'. We show that measuring contributions w.r.t. rewarding _states_, as is done in HCA, results in spurious estimates of contributions, causing HCA to degrade towards the high-variance REINFORCE estimator in many relevant environments. Instead, we measure contributions w.r.t. rewards or learned representations of the rewarding objects, resulting in gradient estimates with lower variance. We run experiments on a suite of problems specifically designed to evaluate long-term credit assignment capabilities. By using dynamic programming, we measure ground-truth policy gradients and show that the improved performance of our new model-based credit assignment methods is due to lower bias and variance compared to HCA and common baselines. Our results demonstrate how modeling action contributions towards rewarding outcomes can be leveraged for credit assignment, opening a new path towards sample-efficient reinforcement learning",
    "checked": true,
    "id": "bd120c6c642022683b7148bb83113f734ba140bb",
    "semantic_title": "would i have gotten that reward? long-term credit assignment by counterfactual contribution analysis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XpmJNP8BVA": {
    "title": "Regularized Behavior Cloning for Blocking the Leakage of Past Action Information",
    "volume": "spotlight",
    "abstract": "For partially observable environments, imitation learning with observation histories (ILOH) assumes that control-relevant information is sufficiently captured in the observation histories for imitating the expert actions. In the offline setting wherethe agent is required to learn to imitate without interaction with the environment, behavior cloning (BC) has been shown to be a simple yet effective method for imitation learning. However, when the information about the actions executed in the past timesteps leaks into the observation histories, ILOH via BC often ends up imitating its own past actions. In this paper, we address this catastrophic failure by proposing a principled regularization for BC, which we name Past Action Leakage Regularization (PALR). The main idea behind our approach is to leverage the classical notion of conditional independence to mitigate the leakage. We compare different instances of our framework with natural choices of conditional independence metric and its estimator. The result of our comparison advocates the use of a particular kernel-based estimator for the conditional independence metric. We conduct an extensive set of experiments on benchmark datasets in order to assess the effectiveness of our regularization method. The experimental results show that our method significantly outperforms prior related approaches, highlighting its potential to successfully imitate expert actions when the past action information leaks into the observation histories",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fY7dShbtmo": {
    "title": "Multi Time Scale World Models",
    "volume": "spotlight",
    "abstract": "Intelligent agents use internal world models to reason and make predictions about different courses of their actions at many scales. Devising learning paradigms and architectures that allow machines to learn world models that operate at multiple levels of temporal abstractions while dealing with complex uncertainty predictions is a major technical hurdle. In this work, we propose a probabilistic formalism to learn multi-time scale world models which we call the Multi Time Scale State Space (MTS3) model. Our model uses a computationally efficient inference scheme on multiple time scales for highly accurate long-horizon predictions and uncertainty estimates over several seconds into the future. Our experiments, which focus on action conditional long horizon future predictions, show that MTS3 outperforms recent methods on several system identification benchmarks including complex simulated and real-world dynamical systems",
    "checked": true,
    "id": "f6dc0af5a7d38e8cb8adb944d8ecfbddc2ba77b1",
    "semantic_title": "multi time scale world models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1PnSOKQKvq": {
    "title": "Gaussian Partial Information Decomposition: Bias Correction and Application to High-dimensional Data",
    "volume": "spotlight",
    "abstract": "Recent advances in neuroscientific experimental techniques have enabled us to simultaneously record the activity of thousands of neurons across multiple brain regions. This has led to a growing need for computational tools capable of analyzing how task-relevant information is represented and communicated between several brain regions. Partial information decompositions (PIDs) have emerged as one such tool, quantifying how much unique, redundant and synergistic information two or more brain regions carry about a task-relevant message. However, computing PIDs is computationally challenging in practice, and statistical issues such as the bias and variance of estimates remain largely unexplored. In this paper, we propose a new method for efficiently computing and estimating a PID definition on multivariate Gaussian distributions. We show empirically that our method satisfies an intuitive additivity property, and recovers the ground truth in a battery of canonical examples, even at high dimensionality. We also propose and evaluate, for the first time, a method to correct the bias in PID estimates at finite sample sizes. Finally, we demonstrate that our Gaussian PID effectively characterizes inter-areal interactions in the mouse brain, revealing higher redundancy between visual areas when a stimulus is behaviorally relevant",
    "checked": true,
    "id": "fece099da70416cea4532d9fd9586a9b1c338c62",
    "semantic_title": "gaussian partial information decomposition: bias correction and application to high-dimensional data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Cs9ea2Gbgx": {
    "title": "List and Certificate Complexities in Replicable Learning",
    "volume": "spotlight",
    "abstract": "We investigate replicable learning algorithms. Informally a learning algorithm is replicable if the algorithm outputs the same canonical hypothesis over multiple runs with high probability, even when different runs observe a different set of samples from the unknown data distribution. In general, such a strong notion of replicability is not achievable. Thus we consider two feasible notions of replicability called {\\em list replicability} and {\\em certificate replicability}. Intuitively, these notions capture the degree of (non) replicability. The goal is to design learning algorithms with optimal list and certificate complexities while minimizing the sample complexity. Our contributions are the following. 1. We first study the learning task of estimating the biases of $d$ coins, up to an additive error of $\\varepsilon$, by observing samples. For this task, we design a $(d+1)$-list replicable algorithm. To complement this result, we establish that the list complexity is optimal, i.e there are no learning algorithms with a list size smaller than $d+1$ for this task. We also design learning algorithms with certificate complexity $\\tilde{O}(\\log d)$. The sample complexity of both these algorithms is $\\tilde{O}(\\frac{d^2}{\\varepsilon^2})$ where $\\varepsilon$ is the approximation error parameter (for a constant error probability). 2. In the PAC model, we show that any hypothesis class that is learnable with $d$-nonadaptive statistical queries can be learned via a $(d+1)$-list replicable algorithm and also via a $\\tilde{O}(\\log d)$-certificate replicable algorithm. The sample complexity of both these algorithms is $\\tilde{O}(\\frac{d^2}{\\nu^2})$ where $\\nu$ is the approximation error of the statistical query. We also show that for the concept class \\dtep, the list complexity is exactly $d+1$ with respect to the uniform distribution. To establish our upper bound results we use rounding schemes induced by geometric partitions with certain properties. We use Sperner/KKM Lemma to establish the lower bound results",
    "checked": true,
    "id": "49c60c7e69b70a44ed63f40ced4f8e5766ef2ace",
    "semantic_title": "list and certificate complexities in replicable learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=geLARFEK8O": {
    "title": "Combating Representation Learning Disparity with Geometric Harmonization",
    "volume": "spotlight",
    "abstract": "Self-supervised learning (SSL) as an effective paradigm of representation learning has achieved tremendous success on various curated datasets in diverse scenarios. Nevertheless, when facing the long-tailed distribution in real-world applications, it is still hard for existing methods to capture transferable and robust representation. The attribution is that the vanilla SSL methods that pursue the sample-level uniformity easily leads to representation learning disparity, where head classes with the huge sample number dominate the feature regime but tail classes with the small sample number passively collapse. To address this problem, we propose a novel Geometric Harmonization (GH) method to encourage the category-level uniformity in representation learning, which is more benign to the minority and almost does not hurt the majority under long-tailed distribution. Specially, GH measures the population statistics of the embedding space on top of self-supervised learning, and then infer an fine-grained instance-wise calibration to constrain the space expansion of head classes and avoid the passive collapse of tail classes. Our proposal does not alter the setting of SSL and can be easily integrated into existing methods in a low-cost manner. Extensive results on a range of benchmark datasets show the effectiveness of \\methodspace with high tolerance to the distribution skewness",
    "checked": true,
    "id": "d2c3dde5a5b6cade440c15c187bf82f62f3a1377",
    "semantic_title": "combating representation learning disparity with geometric harmonization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OIJ3VXDy6s": {
    "title": "RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability",
    "volume": "spotlight",
    "abstract": "Visual model-based RL methods typically encode image observations into low-dimensional representations in a manner that does not eliminate redundant information. This leaves them susceptible to spurious variations -- changes in task-irrelevant components such as background distractors or lighting conditions. In this paper, we propose a visual model-based RL method that learns a latent representation resilient to such spurious variations. Our training objective encourages the representation to be maximally predictive of dynamics and reward, while constraining the information flow from the observation to the latent representation. We demonstrate that this objective significantly bolsters the resilience of visual model-based RL methods to visual distractors, allowing them to operate in dynamic environments. We then show that while the learned encoder is able to operate in dynamic environments, it is not invariant under significant distribution shift. To address this, we propose a simple reward-free alignment procedure that enables test time adaptation of the encoder. This allows for quick adaptation to widely differing environments without having to relearn the dynamics and policy. Our effort is a step towards making model-based RL a practical and useful tool for dynamic, diverse domains and we show its effectiveness in simulation tasks with significant spurious variations",
    "checked": true,
    "id": "b3d213883226192fd2f59f0413ceb4610249362a",
    "semantic_title": "repo: resilient model-based reinforcement learning by regularizing posterior predictability",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=VGLXjbTSYa": {
    "title": "Delegated Classification",
    "volume": "spotlight",
    "abstract": "When machine learning is outsourced to a rational agent, conflicts of interest might arise and severely impact predictive performance. In this work, we propose a theoretical framework for incentive-aware delegation of machine learning tasks. We model delegation as a principal-agent game, in which accurate learning can be incentivized by the principal using performance-based contracts. Adapting the economic theory of contract design to this setting, we define budget-optimal contracts and prove they take a simple threshold form under reasonable assumptions. In the binary-action case, the optimality of such contracts is shown to be equivalent to the classic Neyman-Pearson lemma, establishing a formal connection between contract design and statistical hypothesis testing. Empirically, we demonstrate that budget-optimal contracts can be constructed using small-scale data, leveraging recent advances in the study of learning curves and scaling laws. Performance and economic outcomes are evaluated using synthetic and real-world classification tasks",
    "checked": true,
    "id": "1205d6406577389f583247b2eae4abae6215656d",
    "semantic_title": "delegated classification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QmPf29EHyI": {
    "title": "Bifurcations and loss jumps in RNN training",
    "volume": "spotlight",
    "abstract": "Recurrent neural networks (RNNs) are popular machine learning tools for modeling and forecasting sequential data and for inferring dynamical systems (DS) from observed time series. Concepts from DS theory (DST) have variously been used to further our understanding of both, how trained RNNs solve complex tasks, and the training process itself. Bifurcations are particularly important phenomena in DS, including RNNs, that refer to topological (qualitative) changes in a system's dynamical behavior as one or more of its parameters are varied. Knowing the bifurcation structure of an RNN will thus allow to deduce many of its computational and dynamical properties, like its sensitivity to parameter variations or its behavior during training. In particular, bifurcations may account for sudden loss jumps observed in RNN training that could severely impede the training process. Here we first mathematically prove for a particular class of ReLU-based RNNs that certain bifurcations are indeed associated with loss gradients tending toward infinity or zero. We then introduce a novel heuristic algorithm for detecting all fixed points and $k$-cycles in ReLU-based RNNs and their existence and stability regions, hence bifurcation manifolds in parameter space. In contrast to previous numerical algorithms for finding fixed points and common continuation methods, our algorithm provides $\\textit{exact}$ results and returns fixed points and cycles up to high orders with surprisingly good scaling behavior. We exemplify the algorithm on the analysis of the training process of RNNs, and find that the recently introduced technique of generalized teacher forcing completely avoids certain types of bifurcations in training. Thus, besides facilitating the DST analysis of trained RNNs, our algorithm provides a powerful instrument for analyzing the training process itself",
    "checked": true,
    "id": "ed5769161fdb2bdc15b933f590ef7c91e5ef8b32",
    "semantic_title": "bifurcations and loss jumps in rnn training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dzqKAM2sKa": {
    "title": "Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural Networks",
    "volume": "spotlight",
    "abstract": "In various engineering and applied science applications, repetitive numerical simulations of partial differential equations (PDEs) for varying input parameters are often required (e.g., aircraft shape optimization over many design parameters) and solvers are required to perform rapid execution. In this study, we suggest a path that potentially opens up a possibility for physics-informed neural networks (PINNs), emerging deep-learning-based solvers, to be considered as one such solver. Although PINNs have pioneered a proper integration of deep-learning and scientific computing, they require repetitive time-consuming training of neural networks, which is not suitable for many-query scenarios. To address this issue, we propose a lightweight low-rank PINNs containing only hundreds of model parameters and an associated hypernetwork-based meta-learning algorithm, which allows efficient approximation of solutions of PDEs for varying ranges of PDE input parameters. Moreover, we show that the proposed method is effective in overcoming a challenging issue, known as \"failure modes\" of PINNs",
    "checked": true,
    "id": "8f864b48afdabfd2f88dcc1c35be60136ec4f172",
    "semantic_title": "hypernetwork-based meta-learning for low-rank physics-informed neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3AreDQZ8eO": {
    "title": "Schema-learning and rebinding as mechanisms of in-context learning and emergence",
    "volume": "spotlight",
    "abstract": "In-context learning (ICL) is one of the most powerful and most unexpected capabilities to emerge in recent transformer-based large language models (LLMs). Yet the mechanisms that underlie it are poorly understood. In this paper, we demonstrate that comparable ICL capabilities can be acquired by an alternative sequence prediction learning method using clone-structured causal graphs (CSCGs). Moreover, a key property of CSCGs is that, unlike transformer-based LLMs, they are {\\em interpretable}, which considerably simplifies the task of explaining how ICL works. Specifically, we show that it uses a combination of (a) learning template (schema) circuits for pattern completion, (b) retrieving relevant templates in a context-sensitive manner, and (c) rebinding of novel tokens to appropriate slots in the templates. We go on to marshall evidence for the hypothesis that similar mechanisms underlie ICL in LLMs. For example, we find that, with CSCGs as with LLMs, different capabilities emerge at different levels of overparameterization, suggesting that overparameterization helps in learning more complex template (schema) circuits. By showing how ICL can be achieved with small models and datasets, we open up a path to novel architectures, and take a vital step towards a more general understanding of the mechanics behind this important capability",
    "checked": true,
    "id": "787f3c102342efb14e3691d310e77ab3c07b5343",
    "semantic_title": "schema-learning and rebinding as mechanisms of in-context learning and emergence",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=MvoMDD6emT": {
    "title": "State Sequences Prediction via Fourier Transform for Representation Learning",
    "volume": "spotlight",
    "abstract": "While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance. Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states. However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain. To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently. Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information. One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets. Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance",
    "checked": true,
    "id": "4839c9dfb29076ec78407fc8281e41cd3583a18b",
    "semantic_title": "state sequences prediction via fourier transform for representation learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rhIfzCZoXG": {
    "title": "Counterfactual Evaluation of Peer-Review Assignment Policies",
    "volume": "spotlight",
    "abstract": "Peer review assignment algorithms aim to match research papers to suitable expert reviewers, working to maximize the quality of the resulting reviews. A key challenge in designing effective assignment policies is evaluating how changes to the assignment algorithm map to changes in review quality. In this work, we leverage recently proposed policies that introduce randomness in peer-review assignment—in order to mitigate fraud—as a valuable opportunity to evaluate counterfactual assignment policies. Specifically, we exploit how such randomized assignments provide a positive probability of observing the reviews of many assignment policies of interest. To address challenges in applying standard off-policy evaluation methods, such as violations of positivity, we introduce novel methods for partial identification based on monotonicity and Lipschitz smoothness assumptions for the mapping between reviewer-paper covariates and outcomes. We apply our methods to peer-review data from two computer science venues: the TPDP'21 workshop (95 papers and 35 reviewers) and the AAAI'22 conference (8,450 papers and 3,145 reviewers). We consider estimates of (i) the effect on review quality when changing weights in the assignment algorithm, e.g., weighting reviewers' bids vs. textual similarity (between the review's past papers and the submission), and (ii) the \"cost of randomization\", capturing the difference in expected quality between the perturbed and unperturbed optimal match. We find that placing higher weight on text similarity results in higher review quality and that introducing randomization in the reviewer-paper assignment only marginally reduces the review quality. Our methods for partial identification may be of independent interest, while our off-policy approach can likely find use in evaluating a broad class of algorithmic matching systems",
    "checked": true,
    "id": "974c29be4b96f0da692575e78278c35ded60c2d1",
    "semantic_title": "counterfactual evaluation of peer-review assignment policies",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2SScUiWUbn": {
    "title": "On the Connection between Pre-training Data Diversity and Fine-tuning Robustness",
    "volume": "spotlight",
    "abstract": "Pre-training has been widely adopted in deep learning to improve model performance, especially when the training data for a target task is limited. In our work, we seek to understand the implications of this training strategy on the generalization properties of downstream models. More specifically, we ask the following question: how do properties of the pre-training distribution affect the robustness of a fine-tuned model? The properties we explore include the label space, label semantics, image diversity, data domains, and data quantity of the pre-training distribution. We find that the primary factor influencing downstream effective robustness (Taori et al., 2020) is data quantity, while other factors have limited significance. For example, reducing the number of ImageNet pre-training classes by 4x while increasing the number of images per class by 4x (that is, keeping total data quantity fixed) does not impact the robustness of fine-tuned models. We demonstrate our findings on pre-training distributions drawn from various natural and synthetic data sources, primarily using the iWildCam-WILDS distribution shift as a test for robustness",
    "checked": true,
    "id": "8e682c25e9eb8c471383151a8fed52aefb987696",
    "semantic_title": "on the connection between pre-training data diversity and fine-tuning robustness",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=KbqQMoqfLQ": {
    "title": "Blockwise Parallel Transformers for Large Context Models",
    "volume": "spotlight",
    "abstract": "Transformers have emerged as the cornerstone of state-of-the-art natural language processing models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands posed by the self-attention mechanism and the large feedforward network in Transformers limit their ability to handle long sequences, thereby creating challenges for tasks involving multiple long sequences or long-term dependencies. We present a distinct approach, Blockwise Parallel Transformer (BPT), that leverages blockwise computation of self-attention and feedforward network fusion to minimize memory costs. By processing longer input sequences while maintaining memory efficiency, BPT enables training sequences 32 times longer than vanilla Transformers and up to 4 times longer than previous memory-efficient methods. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of BPT in reducing memory requirements and improving performance",
    "checked": false,
    "id": "86b6e42e2ce957f6497d4aa578c9bb4d2b4e4ba3",
    "semantic_title": "blockwise parallel transformer for large context models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=LnZuxp3Tx7": {
    "title": "From Tempered to Benign Overfitting in ReLU Neural Networks",
    "volume": "spotlight",
    "abstract": "Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on \"benign overfitting\", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as \"tempered overfitting\", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the overfitting profile in this setting, which we also validate empirically for intermediate dimensions. Overall, our results shed light on the intricate connections between the dimension, sample size, architecture and training algorithm on the one hand, and the type of resulting overfitting on the other hand",
    "checked": true,
    "id": "c94d483dc2b28eb235a02937040411db06c0f060",
    "semantic_title": "from tempered to benign overfitting in relu neural networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ofa1U5BJVJ": {
    "title": "Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost",
    "volume": "spotlight",
    "abstract": "This paper investigates the logistic bandit problem, a variant of the generalized linear bandit model that utilizes a logistic model to depict the feedback from an action. While most existing research focuses on the binary logistic bandit problem, the multinomial case, which considers more than two possible feedback values, offers increased practical relevance and adaptability for use in complex decision-making problems such as reinforcement learning. In this paper, we provide an algorithm that enjoys both statistical and computational efficiency for the logistic bandit problem. In the binary case, our method improves the state-of-the-art binary logistic bandit method by reducing the per-round computation cost from $\\mathcal{O}(\\log T)$ to $\\mathcal{O}(1)$ with respect to the time horizon $T$, while still preserving the minimax optimal guarantee up to logarithmic factors. In the multinomial case, with $K+1$ potential feedback values, our algorithm achieves an $\\tilde{\\mathcal{O}}(K\\sqrt{T})$ regret bound with $\\mathcal{O}(1)$ computational cost per round. The result not only improves the $\\tilde{\\mathcal{O}}(K\\sqrt{\\kappa T})$ bound for the best-known tractable algorithm—where the large constant $\\kappa$ increases exponentially with the diameter of the parameter domain—but also reduces the $\\mathcal{O}(T)$ computational complexity demanded by the previous method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r8snfquzs3": {
    "title": "Grounding Neural Inference with Satisfiability Modulo Theories",
    "volume": "spotlight",
    "abstract": "Recent techniques that integrate solver layers into Deep Neural Networks (DNNs) have shown promise in bridging a long-standing gap between inductive learning and symbolic reasoning techniques. In this paper we present a set of techniques for integrating Satisfiability Modulo Theories (SMT) solvers into the forward and backward passes of a deep network layer, called SMTLayer. Using this approach, one can encode rich domain knowledge into the network in the form of mathematical formulas. In the forward pass, the solver uses symbols produced by prior layers, along with these formulas, to construct inferences; in the backward pass, the solver informs updates to the network, driving it towards representations that are compatible with the solver's theory. Notably, the solver need not be differentiable. We implement SMTLayer as a Pytorch module, and our empirical results show that it leads to models that 1) require fewer training samples than conventional models, 2) that are robust to certain types of covariate shift, and 3) that ultimately learn representations that are consistent with symbolic knowledge, and thus naturally interpretable",
    "checked": false,
    "id": "51510b3de4823ac647b78939be51e183e5b9b0d5",
    "semantic_title": "learning modulo theories",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cLQCCtVDuW": {
    "title": "HIQL: Offline Goal-Conditioned RL with Latent States as Actions",
    "volume": "spotlight",
    "abstract": "Unsupervised pre-training has recently become the bedrock for computer vision and natural language processing. In reinforcement learning (RL), goal-conditioned RL can potentially provide an analogous self-supervised approach for making use of large quantities of unlabeled (reward-free) data. However, building effective algorithms for goal-conditioned RL that can learn directly from diverse offline data is challenging, because it is hard to accurately estimate the exact value function for faraway goals. Nonetheless, goal-reaching problems exhibit structure, such that reaching distant goals entails first passing through closer subgoals. This structure can be very useful, as assessing the quality of actions for nearby goals is typically easier than for more distant goals. Based on this idea, we propose a hierarchical algorithm for goal-conditioned RL from offline data. Using one action-free value function, we learn two policies that allow us to exploit this structure: a high-level policy that treats states as actions and predicts (a latent representation of) a subgoal and a low-level policy that predicts the action for reaching this subgoal. Through analysis and didactic examples, we show how this hierarchical decomposition makes our method robust to noise in the estimated value function. We then apply our method to offline goal-reaching benchmarks, showing that our method can solve long-horizon tasks that stymie prior methods, can scale to high-dimensional image observations, and can readily make use of action-free data. Our code is available at https://seohong.me/projects/hiql/",
    "checked": true,
    "id": "f18587247e4769ad0efd96a0286b012d856ba214",
    "semantic_title": "hiql: offline goal-conditioned rl with latent states as actions",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=h1FhXVM0cB": {
    "title": "Improved Convergence in High Probability of Clipped Gradient Methods with Heavy Tailed Noise",
    "volume": "spotlight",
    "abstract": "In this work, we study the convergence in high probability of clipped gradient methods when the noise distribution has heavy tails, i.e., with bounded $p$th moments, for some $1<p\\le2$. Prior works in this setting follow the same recipe of using concentration inequalities and an inductive argument with union bound to bound the iterates across all iterations. This method results in an increase in the failure probability by a factor of $T$, where $T$ is the number of iterations. We instead propose a new analysis approach based on bounding the moment generating function of a well chosen supermartingale sequence. We improve the dependency on $T$ in the convergence guarantee for a wide range of algorithms with clipped gradients, including stochastic (accelerated) mirror descent for convex objectives and stochastic gradient descent for nonconvex objectives. Our high probability bounds achieve the optimal convergence rates and match the best currently known in-expectation bounds. Our approach naturally allows the algorithms to use time-varying step sizes and clipping parameters when the time horizon is unknown, which appears difficult or even impossible using the techniques from prior works. Furthermore, we show that in the case of clipped stochastic mirror descent, several problem constants, including the initial distance to the optimum, are not required when setting step sizes and clipping parameters",
    "checked": false,
    "id": "c89f5c58419f18a52d7d650254556b8437139aec",
    "semantic_title": "improved convergence in high probability of clipped gradient methods with heavy tails",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=8aDG51pxFc": {
    "title": "No Change, No Gain: Empowering Graph Neural Networks with Expected Model Change Maximization for Active Learning",
    "volume": "spotlight",
    "abstract": "Graph Neural Networks (GNNs) are crucial for machine learning applications with graph-structured data, but their success depends on sufficient labeled data. We present a novel active learning (AL) method for GNNs, extending the Expected Model Change Maximization (EMCM) principle to improve prediction performance on unlabeled data. By presenting a Bayesian interpretation for the node embeddings generated by GNNs under the semi-supervised setting, we efficiently compute the closed-form EMCM acquisition function as the selection criterion for AL without re-training. Our method establishes a direct connection with expected prediction error minimization, offering theoretical guarantees for AL performance. Experiments demonstrate our method's effectiveness compared to existing approaches, in terms of both accuracy and efficiency",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BfQJrIiOZC": {
    "title": "Zero-shot causal learning",
    "volume": "spotlight",
    "abstract": "Predicting how different interventions will causally affect a specific individual is important in a variety of domains such as personalized medicine, public policy, and online marketing. There are a large number of methods to predict the effect of an existing intervention based on historical data from individuals who received it. However, in many settings it is important to predict the effects of novel interventions (e.g., a newly invented drug), which these methods do not address. Here, we consider zero-shot causal learning: predicting the personalized effects of a novel intervention. We propose CaML, a causal meta-learning framework which formulates the personalized prediction of each intervention's effect as a task. CaML trains a single meta-model across thousands of tasks, each constructed by sampling an intervention, its recipients, and its nonrecipients. By leveraging both intervention information (e.g., a drug's attributes) and individual features (e.g., a patient's history), CaML is able to predict the personalized effects of novel interventions that do not exist at the time of training. Experimental results on real world datasets in large-scale medical claims and cell-line perturbations demonstrate the effectiveness of our approach. Most strikingly, CaML's zero-shot predictions outperform even strong baselines trained directly on data from the test interventions",
    "checked": true,
    "id": "64c1ba56a32ed9a42f2cac010de56002380c2408",
    "semantic_title": "zero-shot causal learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gbOukzirpK": {
    "title": "Object-Centric Slot Diffusion",
    "volume": "spotlight",
    "abstract": "The recent success of transformer-based image generative models in object-centric learning highlights the importance of powerful image generators for handling complex scenes. However, despite the high expressiveness of diffusion models in image generation, their integration into object-centric learning remains largely unexplored in this domain. In this paper, we explore the feasibility and potential of integrating diffusion models into object-centric learning and investigate the pros and cons of this approach. We introduce Latent Slot Diffusion (LSD), a novel model that serves dual purposes: it is the first object-centric learning model to replace conventional slot decoders with a latent diffusion model conditioned on object slots, and it is also the first unsupervised compositional conditional diffusion model that operates without the need for supervised annotations like text. Through experiments on various object-centric tasks, including the first application of the FFHQ dataset in this field, we demonstrate that LSD significantly outperforms state-of-the-art transformer-based decoders, particularly in more complex scenes, and exhibits superior unsupervised compositional generation quality. In addition, we conduct a preliminary investigation into the integration of pre-trained diffusion models in LSD and demonstrate its effectiveness in real-world image segmentation and generation. Project page is available at https://latentslotdiffusion.github.io",
    "checked": true,
    "id": "b298f65455dd4acbbc96e8aa43bd3673af480bcb",
    "semantic_title": "object-centric slot diffusion",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=zkfyOkBVpz": {
    "title": "Curriculum Learning With Infant Egocentric Videos",
    "volume": "spotlight",
    "abstract": "Infants possess a remarkable ability to rapidly learn and process visual inputs. As an infant's mobility increases, so does the variety and dynamics of their visual inputs. Is this change in the properties of the visual inputs beneficial or even critical for the proper development of the visual system? To address this question, we used video recordings from infants wearing head-mounted cameras to train a variety of self-supervised learning models. Critically, we separated the infant data by age group and evaluated the importance of training with a curriculum aligned with developmental order. We found that initiating learning with the data from the youngest age group provided the strongest learning signal and led to the best learning outcomes in terms of downstream task performance. We then showed that the benefits of the data from the youngest age group are due to the slowness and simplicity of the visual experience. The results provide strong empirical evidence for the importance of the properties of the early infant experience and developmental progression in training. More broadly, our approach and findings take a noteworthy step towards reverse engineering the learning mechanisms in newborn brains using image-computable models from artificial intelligence",
    "checked": true,
    "id": "f9ec53bace9ea36d7e53525e7eea23ca98b81276",
    "semantic_title": "curriculum learning with infant egocentric videos",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X6dEqXIsEW": {
    "title": "On the Planning Abilities of Large Language Models - A Critical Investigation",
    "volume": "spotlight",
    "abstract": "Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating plans autonomously in commonsense planning tasks and (2) the potential of LLMs as a source of heuristic guidance for other agents (AI planners) in their planning tasks. We conduct a systematic study by generating a suite of instances on domains similar to the ones employed in the International Planning Competition and evaluate LLMs in two distinct modes: autonomous and heuristic. Our findings reveal that LLMs' ability to generate executable plans autonomously is rather limited, with the best model (GPT-4) having an average success rate of ~12% across the domains. However, the results in the heuristic mode show more promise. In the heuristic mode, we demonstrate that LLM-generated plans can improve the search process for underlying sound planners and additionally show that external verifiers can help provide feedback on the generated plans and back-prompt the LLM for better plan generation",
    "checked": true,
    "id": "dedfe929d182cc3537a9ed765d589b4735ce062a",
    "semantic_title": "on the planning abilities of large language models - a critical investigation",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=STqaMqhtDi": {
    "title": "Plug-and-Play Stability for Intracortical Brain-Computer Interfaces: A One-Year Demonstration of Seamless Brain-to-Text Communication",
    "volume": "spotlight",
    "abstract": "Intracortical brain-computer interfaces (iBCIs) have shown promise for restoring rapid communication to people with neurological disorders such as amyotrophic lateral sclerosis (ALS). However, to maintain high performance over time, iBCIs typically need frequent recalibration to combat changes in the neural recordings that accrue over days. This requires iBCI users to stop using the iBCI and engage in supervised data collection, making the iBCI system hard to use. In this paper, we propose a method that enables self-recalibration of communication iBCIs without interrupting the user. Our method leverages large language models (LMs) to automatically correct errors in iBCI outputs. The self-recalibration process uses these corrected outputs (\"pseudo-labels\") to continually update the iBCI decoder online. Over a period of more than one year (403 days), we evaluated our Continual Online Recalibration with Pseudo-labels (CORP) framework with one clinical trial participant. CORP achieved a stable decoding accuracy of 93.84% in an online handwriting iBCI task, significantly outperforming other baseline methods. Notably, this is the longest-running iBCI stability demonstration involving a human participant. Our results provide the first evidence for long-term stabilization of a plug-and-play, high-performance communication iBCI, addressing a major barrier for the clinical translation of iBCIs",
    "checked": true,
    "id": "c6a88b7a368bb30df347b11edcdde2a8bdf129e2",
    "semantic_title": "plug-and-play stability for intracortical brain-computer interfaces: a one-year demonstration of seamless brain-to-text communication",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7h1YaSGaHS": {
    "title": "Physics-Driven ML-Based Modelling for Correcting Inverse Estimation",
    "volume": "spotlight",
    "abstract": "When deploying machine learning estimators in science and engineering (SAE) domains, it is critical to avoid failed estimations that can have disastrous consequences, e.g., in aero engine design. This work focuses on detecting and correcting failed state estimations before adopting them in SAE inverse problems, by utilizing simulations and performance metrics guided by physical laws. We suggest to flag a machine learning estimation when its physical model error exceeds a feasible threshold, and propose a novel approach, GEESE, to correct it through optimization, aiming at delivering both low error and high efficiency. The key designs of GEESE include (1) a hybrid surrogate error model to provide fast error estimations to reduce simulation cost and to enable gradient based backpropagation of error feedback, and (2) two generative models to approximate the probability distributions of the candidate states for simulating the exploitation and exploration behaviours. All three models are constructed as neural networks. GEESE is tested on three real-world SAE inverse problems and compared to a number of state-of-the-art optimization/search approaches. Results show that it fails the least number of times in terms of finding a feasible state correction, and requires physical evaluations less frequently in general",
    "checked": true,
    "id": "c78164daf8da5e36f098d7efbea17f7d748e77af",
    "semantic_title": "physics-driven ml-based modelling for correcting inverse estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5NxJuc0T1P": {
    "title": "Debias Coarsely, Sample Conditionally: Statistical Downscaling through Optimal Transport and Probabilistic Diffusion Models",
    "volume": "spotlight",
    "abstract": "We introduce a two-stage probabilistic framework for statistical downscaling using unpaired data. Statistical downscaling seeks a probabilistic map to transform low-resolution data from a biased coarse-grained numerical scheme to high-resolution data that is consistent with a high-fidelity scheme. Our framework tackles the problem by composing two transformations: (i) a debiasing step via an optimal transport map, and (ii) an upsampling step achieved by a probabilistic diffusion model with a posteriori conditional sampling. This approach characterizes a conditional distribution without needing paired data, and faithfully recovers relevant physical statistics from biased samples. We demonstrate the utility of the proposed approach on one- and two-dimensional fluid flow problems, which are representative of the core difficulties present in numerical simulations of weather and climate. Our method produces realistic high-resolution outputs from low-resolution inputs, by upsampling resolutions of $8\\times$ and $16\\times$. Moreover, our procedure correctly matches the statistics of physical quantities, even when the low-frequency content of the inputs and outputs do not match, a crucial but difficult-to-satisfy assumption needed by current state-of-the-art alternatives. Code for this work is available at: https://github.com/google-research/swirl-dynamics/tree/main/swirl_dynamics/projects/probabilistic_diffusion",
    "checked": true,
    "id": "a434f28fb4f2da407c11cf104e47f4c5a12bae13",
    "semantic_title": "debias coarsely, sample conditionally: statistical downscaling through optimal transport and probabilistic diffusion models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=LlERoXEKjh": {
    "title": "Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?",
    "volume": "spotlight",
    "abstract": "We study benign overfitting in two-layer ReLU networks trained using gradient descent and hinge loss on noisy data for binary classification. In particular, we consider linearly separable data for which a relatively small proportion of labels are corrupted or flipped. We identify conditions on the margin of the clean data that give rise to three distinct training outcomes: benign overfitting, in which zero loss is achieved and with high probability test data is classified correctly; overfitting, in which zero loss is achieved but test data is misclassified with probability lower bounded by a constant; and non-overfitting, in which clean points, but not corrupt points, achieve zero loss and again with high probability test data is classified correctly. Our analysis provides a fine-grained description of the dynamics of neurons throughout training and reveals two distinct phases: in the first phase clean points achieve close to zero loss, in the second phase clean points oscillate on the boundary of zero loss while corrupt points either converge towards zero loss or are eventually zeroed by the network. We prove these results using a combinatorial approach that involves bounding the number of clean versus corrupt updates during these phases of training",
    "checked": true,
    "id": "bf4418dfdf31f4f8d2eeab634699a7d8b4a3365a",
    "semantic_title": "training shallow relu networks on noisy data using hinge loss: when do we overfit and is it benign?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=sLr1sohnmo": {
    "title": "Error Bounds for Learning with Vector-Valued Random Features",
    "volume": "spotlight",
    "abstract": "This paper provides a comprehensive error analysis of learning with vector-valued random features (RF). The theory is developed for RF ridge regression in a fully general infinite-dimensional input-output setting, but nonetheless applies to and improves existing finite-dimensional analyses. In contrast to comparable work in the literature, the approach proposed here relies on a direct analysis of the underlying risk functional and completely avoids the explicit RF ridge regression solution formula in terms of random matrices. This removes the need for concentration results in random matrix theory or their generalizations to random operators. The main results established in this paper include strong consistency of vector-valued RF estimators under model misspecification and minimax optimal convergence rates in the well-specified setting. The parameter complexity (number of random features) and sample complexity (number of labeled data) required to achieve such rates are comparable with Monte Carlo intuition and free from logarithmic factors",
    "checked": true,
    "id": "960903429f5585020107b05082b8018cbd26b03e",
    "semantic_title": "error bounds for learning with vector-valued random features",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5Gw9YkJkFF": {
    "title": "PAC Learning Linear Thresholds from Label Proportions",
    "volume": "spotlight",
    "abstract": "Learning from label proportions (LLP) is a generalization of supervised learning in which the training data is available as sets or bags of feature-vectors (instances) along with the average instance-label of each bag. The goal is to train a good instance classifier. While most previous works on LLP have focused on training models on such training data, computational learnability of LLP was only recently explored by Saket (2021, 2022) who showed worst case intractability of properly learning linear threshold functions (LTFs) from label proportions. However, their work did not rule out efficient algorithms for this problem for natural distributions. In this work we show that it is indeed possible to efficiently learn LTFs using LTFs when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution $N(µ, Σ)$. Our work shows that a certain matrix – formed using covariances of the differences of feature-vectors sampled from the bags with and without replacement – necessarily has its principal component, after a transformation, in the direction of the normal vector of the LTF. Our algorithm estimates the means and covariance matrices using subgaussian concentration bounds which we show can be applied to efficiently sample bags for approximating the normal direction. Using this in conjunction with novel generalization error bounds in the bag setting, we show that a low error hypothesis LTF can be identified. For some special cases of the $N(0, I)$ distribution we provide a simpler mean estimation based algorithm. We include an experimental evaluation of our learning algorithms along with a comparison with those of Saket (2021, 2022) and random LTFs, demonstrating the effectiveness of our techniques",
    "checked": true,
    "id": "4f407715b7d3cf1beb0554ae6d6eb21769144371",
    "semantic_title": "pac learning linear thresholds from label proportions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UDqHhbqYJV": {
    "title": "Can Language Models Solve Graph Problems in Natural Language?",
    "volume": "spotlight",
    "abstract": "Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings. We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems. Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question",
    "checked": true,
    "id": "df2beaae63e4d68ef8e762bcd4704c9f11f856d9",
    "semantic_title": "can language models solve graph problems in natural language?",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=2Xqvk2KVAq": {
    "title": "CLIP-OGD: An Experimental Design for Adaptive Neyman Allocation in Sequential Experiments",
    "volume": "spotlight",
    "abstract": "From clinical development of cancer therapies to investigations into partisan bias, adaptive sequential designs have become increasingly popular method for causal inference, as they offer the possibility of improved precision over their non-adaptive counterparts. However, even in simple settings (e.g. two treatments) the extent to which adaptive designs can improve precision is not sufficiently well understood. In this work, we study the problem of Adaptive Neyman Allocation in a design-based potential outcomes framework, where the experimenter seeks to construct an adaptive design which is nearly as efficient as the optimal (but infeasible) non-adaptive Neyman design, which has access to all potential outcomes. Motivated by connections to online optimization, we propose Neyman Ratio and Neyman Regret as two (equivalent) performance measures of adaptive designs for this problem. We present Clip-OGD, an adaptive design which achieves $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ expected Neyman regret and thereby recovers the optimal Neyman variance in large samples. Finally, we construct a conservative variance estimator which facilitates the development of asymptotically valid confidence intervals. To complement our theoretical results, we conduct simulations using data from a microeconomic experiment",
    "checked": true,
    "id": "e16f00646b2bdfb8fbd1e95817e91798c74c103c",
    "semantic_title": "clip-ogd: an experimental design for adaptive neyman allocation in sequential experiments",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=dCYBAGQXLo": {
    "title": "Supervised Pretraining Can Learn In-Context Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "Large transformer models trained on diverse datasets have shown a remarkable ability to learn in-context, achieving high few-shot performance on tasks they were not explicitly trained to solve. In this paper, we study the in-context learning capabilities of transformers in decision-making problems, i.e., reinforcement learning (RL) for bandits and Markov decision processes. To do so, we introduce and study the Decision-Pretrained Transformer (DPT), a supervised pretraining method where a transformer predicts an optimal action given a query state and an in-context dataset of interactions from a diverse set of tasks. While simple, this procedure produces a model with several surprising capabilities. We find that the trained transformer can solve a range of RL problems in-context, exhibiting both exploration online and conservatism offline, despite not being explicitly trained to do so. The model also generalizes beyond the pretraining distribution to new tasks and automatically adapts its decision-making strategies to unknown structure. Theoretically, we show DPT can be viewed as an efficient implementation of Bayesian posterior sampling, a provably sample-efficient RL algorithm. We further leverage this connection to provide guarantees on the regret of the in-context algorithm yielded by DPT, and prove that it can learn faster than algorithms used to generate the pretraining data. These results suggest a promising yet simple path towards instilling strong in-context decision-making abilities in transformers",
    "checked": true,
    "id": "5bac7d00035bc1e246a34f9ee3152b290f97bb92",
    "semantic_title": "supervised pretraining can learn in-context reinforcement learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=Fkckkr3ya8": {
    "title": "Faith and Fate: Limits of Transformers on Compositionality",
    "volume": "spotlight",
    "abstract": "Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify transformer LLMs, we investigate the limits of these models across three representative compositional tasks---multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that transformer LLMs solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how autoregressive generations' performance can rapidly decay with increased task complexity",
    "checked": true,
    "id": "7d97c17a75beb89f938eaac1d3ca60ac2245fb2e",
    "semantic_title": "faith and fate: limits of transformers on compositionality",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=Kg65qieiuB": {
    "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks",
    "volume": "spotlight",
    "abstract": "Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models, including random walk GCNs, Graph Attention Networks (GATs) and (graph) transformers. In particular, our analysis accounts for asymmetric, state-dependent and time-varying aggregation operators and a wide range of common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU",
    "checked": true,
    "id": "8b9f01585a679dffe92261ecdec56425db9ef97f",
    "semantic_title": "demystifying oversmoothing in attention-based graph neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Bj1QSgiBPP": {
    "title": "Participatory Personalization in Classification",
    "volume": "spotlight",
    "abstract": "Machine learning models are often personalized based on information that is protected, sensitive, self-reported, or costly to acquire. These models use information about people, but do not facilitate nor inform their *consent*. Individuals cannot opt out of reporting information that a model needs to personalize their predictions nor tell if they benefit from personalization in the first place. We introduce a new family of prediction models, called participatory systems, that let individuals opt into personalization at prediction time. We present a model-agnostic algorithm to learn participatory systems for supervised learning tasks where models are personalized with categorical group attributes. We conduct a comprehensive empirical study of participatory systems in clinical prediction tasks, comparing them to common approaches for personalization and imputation. Our results show that participatory systems can facilitate and inform consent in a way that improves performance and privacy across all groups who report personal data",
    "checked": true,
    "id": "04a20a27a5b39749a0fbdb752f07109a55cf9ee2",
    "semantic_title": "participatory personalization in classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MWQjqtV1z4": {
    "title": "Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption",
    "volume": "spotlight",
    "abstract": "We study the infinite-horizon Restless Bandit problem with the average reward criterion, under both discrete-time and continuous-time settings. A fundamental goal is to design computationally efficient policies that achieve a diminishing optimality gap as the number of arms, $N$, grows large. Existing results on asymptotic optimality all rely on the uniform global attractor property (UGAP), a complex and challenging-to-verify assumption. In this paper, we propose a general, simulation-based framework, Follow-the-Virtual-Advice, that converts any single-armed policy into a policy for the original $N$-armed problem. This is done by simulating the single-armed policy on each arm and carefully steering the real state towards the simulated state. Our framework can be instantiated to produce a policy with an $O(1/\\sqrt{N})$ optimality gap. In the discrete-time setting, our result holds under a simpler synchronization assumption, which covers some problem instances that violate UGAP. More notably, in the continuous-time setting, we do not require \\emph{any} additional assumptions beyond the standard unichain condition. In both settings, our work is the first asymptotic optimality result that does not require UGAP",
    "checked": true,
    "id": "b12f976066a59e19faa4c0e4662ef4f8d4af0907",
    "semantic_title": "restless bandits with average reward: breaking the uniform global attractor assumption",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=wm5Ane9VRO": {
    "title": "Maximization of Average Precision for Deep Learning with Adversarial Ranking Robustness",
    "volume": "spotlight",
    "abstract": "This paper seeks to address a gap in optimizing Average Precision (AP) while ensuring adversarial robustness, an area that has not been extensively explored to the best of our knowledge. AP maximization for deep learning has widespread applications, particularly when there is a significant imbalance between positive and negative examples. Although numerous studies have been conducted on adversarial training, they primarily focus on robustness concerning accuracy, ensuring that the average accuracy on adversarially perturbed examples is well maintained. However, this type of adversarial robustness is insufficient for many applications, as minor perturbations on a single example can significantly impact AP while not greatly influencing the accuracy of the prediction system. To tackle this issue, we introduce a novel formulation that combines an AP surrogate loss with a regularization term representing adversarial ranking robustness, which maintains the consistency between ranking of clean data and that of perturbed data. We then devise an efficient stochastic optimization algorithm to optimize the resulting objective. Our empirical studies, which compare our method to current leading adversarial training baselines and other robust AP maximization strategies, demonstrate the effectiveness of the proposed approach. Notably, our methods outperform a state-of-the-art method (TRADES) by more than 4\\% in terms of robust AP against PGD attacks while achieving 7\\% higher AP on clean data simultaneously on CIFAR10 and CIFAR100",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V2yFumwo5B": {
    "title": "Effective Human-AI Teams via Learned Natural Language Rules and Onboarding",
    "volume": "spotlight",
    "abstract": "People are relying on AI agents to assist them with various tasks. The human must know when to rely on the agent, collaborate with the agent, or ignore its suggestions. In this work, we propose to learn rules grounded in data regions and described in natural language that illustrate how the human should collaborate with the AI. Our novel region discovery algorithm finds local regions in the data as neighborhoods in an embedding space that corrects the human prior. Each region is then described using an iterative and contrastive procedure where a large language model describes the region. We then teach these rules to the human via an onboarding stage. Through user studies on object detection and question-answering tasks, we show that our method can lead to more accurate human-AI teams. We also evaluate our region discovery and description algorithms separately",
    "checked": true,
    "id": "6389144ee8896409af54cf70c10b5cc4dd64f22f",
    "semantic_title": "effective human-ai teams via learned natural language rules and onboarding",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=waXoG35kbb": {
    "title": "Provable benefits of score matching",
    "volume": "spotlight",
    "abstract": "Score matching is an alternative to maximum likelihood (ML) for estimating a probability distribution parametrized up to a constant of proportionality. By fitting the ''score'' of the distribution, it sidesteps the need to compute this constant of proportionality (which is often intractable). While score matching and variants thereof are popular in practice, precise theoretical understanding of the benefits and tradeoffs with maximum likelihood---both computational and statistical---are not well understood. In this work, we give the first example of a natural exponential family of distributions such that the score matching loss is computationally efficient to optimize, and has a comparable statistical efficiency to ML, while the ML loss is intractable to optimize using a gradient-based method. The family consists of exponentials of polynomials of fixed degree, and our result can be viewed as a continuous analogue of recent developments in the discrete setting. Precisely, we show: (1) Designing a zeroth-order or first-order oracle for optimizing the maximum likelihood loss is NP-hard. (2) Maximum likelihood has a statistical efficiency polynomial in the ambient dimension and the radius of the parameters of the family. (3) Minimizing the score matching loss is both computationally and statistically efficient, with complexity polynomial in the ambient dimension",
    "checked": true,
    "id": "aa3e15b2b726f4186cd3298ee06728098b95fd18",
    "semantic_title": "provable benefits of score matching",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ubzNoJjOKj": {
    "title": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution",
    "volume": "spotlight",
    "abstract": "Genomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context (<0.001% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers or fixed k-mers to aggregate meaningful DNA units, losing single nucleotide resolution (i.e. DNA \"characters\") where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyena's new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level – an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single nucleotide tokens, and has full global context at each layer. We explore what longer context enables - including the first use of in-context learning in genomics for simple adaptation to novel tasks without updating pretrained model weights. On fine-tuned benchmarks from the Nucleotide Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 18 datasets using a model with orders of magnitude less parameters and pretraining data.1 On the GenomicBenchmarks, HyenaDNA surpasses SotA on 7 of 8 datasets on average by +10 accuracy points. Code at https://github.com/HazyResearch/hyena-dna",
    "checked": true,
    "id": "bfd2b76998a0521c12903ef5ced517adf70ad2ba",
    "semantic_title": "hyenadna: long-range genomic sequence modeling at single nucleotide resolution",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=2JtwuJtoa0": {
    "title": "Unifying Predictions of Deterministic and Stochastic Physics in Mesh-reduced Space with Sequential Flow Generative Model",
    "volume": "spotlight",
    "abstract": "Accurate prediction of dynamical systems in unstructured meshes has recently shown successes in scientific simulations. Many dynamical systems have a nonnegligible level of stochasticity introduced by various factors (e.g. chaoticity), so there is a need for a unified framework that captures both deterministic and stochastic components in the rollouts of these systems. Inspired by regeneration learning, we propose a new model that combines generative and sequential networks to model dynamical systems. Specifically, we use an autoencoder to learn compact representations of full-space physical variables in a low-dimensional space. We then integrate a transformer with a conditional normalizing flow model to model the temporal sequence of latent representations. We evaluate the new model in both deterministic and stochastic systems. The model outperforms several competitive baseline models and makes more accurate predictions of deterministic systems. Its own prediction error is also reflected in its uncertainty estimations. When predicting stochastic systems, the proposed model generates high-quality rollout samples. The mean and variance of these samples well match the statistics of samples computed from expensive numerical simulations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=blm1pqiOXe": {
    "title": "Paxion: Patching Action Knowledge in Video-Language Foundation Models",
    "volume": "spotlight",
    "abstract": "Action knowledge involves the understanding of textual, visual, and temporal aspects of actions. We introduce the **Action Dynamics Benchmark (ActionBench)** containing two carefully designed probing tasks: Action Antonym and Video Reversal, which targets multimodal alignment capabilities and temporal understanding skills of the model, respectively. Despite recent video-language models' (VidLM) impressive performance on various benchmark tasks, our diagnostic tasks reveal their surprising deficiency (near-random performance) in action knowledge, suggesting that current models rely on object recognition abilities as a shortcut for action understanding. To remedy this, we propose a novel framework, **Paxion**, along with a new **Discriminative Video Dynamics Modeling (DVDM)** objective. The Paxion framework utilizes a **Knowledge Patcher** network to encode new action knowledge and a **Knowledge Fuser** component to integrate the Patcher into frozen VidLMs without compromising their existing capabilities. Due to limitations of the widely-used Video-Text Contrastive (VTC) loss for learning action knowledge, we introduce the DVDM objective to train the Knowledge Patcher. DVDM forces the model to encode the correlation between the action text and the correct ordering of video frames. Our extensive analyses show that Paxion and DVDM together effectively fill the gap in action knowledge understanding (~50% → 80%), while maintaining or improving performance on a wide spectrum of both object- and action-centric downstream tasks",
    "checked": true,
    "id": "3130643a5d02f0e849d83bb1f85577a924081f36",
    "semantic_title": "paxion: patching action knowledge in video-language foundation models",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=iMfPFPMsZo": {
    "title": "Parallel Submodular Function Minimization",
    "volume": "spotlight",
    "abstract": "We consider the parallel complexity of submodular function minimization (SFM). We provide a pair of methods which obtain two new query versus depth trade-offs a submodular function defined on subsets of $n$ elements that has integer values between $-M$ and $M$. The first method has depth $2$ and query complexity $n^{O(M)}$ and the second method has depth $\\widetilde{O}(n^{1/3} M^{2/3})$ and query complexity $O(\\mathrm{poly}(n, M))$. Despite a line of work on improved parallel lower bounds for SFM, prior to our work the only known algorithms for parallel SFM either followed from more general methods for sequential SFM or highly-parallel minimization of convex $\\ell_2$-Lipschitz functions. Interestingly, to obtain our second result we provide the first highly-parallel algorithm for minimizing $\\ell_\\infty$-Lipschitz function over the hypercube which obtains near-optimal depth for obtaining constant accuracy",
    "checked": true,
    "id": "d6c36bbd5924fb19e2d8c14b5726996533b55ae5",
    "semantic_title": "parallel submodular function minimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=8kyIChWsAG": {
    "title": "When Does Optimizing a Proper Loss Yield Calibration?",
    "volume": "spotlight",
    "abstract": "Optimizing proper loss functions is popularly believed to yield predictors with good calibration properties; the intuition being that for such losses, the global optimum is to predict the ground-truth probabilities, which is indeed calibrated. However, typical machine learning models are trained to approximately minimize loss over restricted families of predictors, that are unlikely to contain the ground truth. Under what circumstances does optimizing proper loss over a restricted family yield calibrated models? What precise calibration guarantees does it give? In this work, we provide a rigorous answer to these questions. We replace the global optimality with a local optimality condition stipulating that the (proper) loss of the predictor cannot be reduced much by post-processing its predictions with a certain family of Lipschitz functions. We show that any predictor with this local optimality satisfies smooth calibration as defined in [Kakade and Foster, 2008, Błasiok et al., 2023]. Local optimality is plausibly satisfied by well-trained DNNs, which suggests an explanation for why they are calibrated from proper loss minimization alone. Finally, we show that the connection between local optimality and calibration error goes both ways: nearly calibrated predictors are also nearly locally optimal",
    "checked": true,
    "id": "e7f01505ac8b2a3d6b2c347ba1f23f79c2a5e8b0",
    "semantic_title": "when does optimizing a proper loss yield calibration?",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=PfpAQuyZCB": {
    "title": "Behavior Alignment via Reward Function Optimization",
    "volume": "spotlight",
    "abstract": "Designing reward functions for efficiently guiding reinforcement learning (RL) agents toward specific behaviors is a complex task. This is challenging since it requires the identification of reward structures that are not sparse and that avoid inadvertently inducing undesirable behaviors. Naively modifying the reward structure to offer denser and more frequent feedback can lead to unintended outcomes and promote behaviors that are not aligned with the designer's intended goal. Although potential-based reward shaping is often suggested as a remedy, we systematically investigate settings where deploying it often significantly impairs performance. To address these issues, we introduce a new framework that uses a bi-level objective to learn \\emph{behavior alignment reward functions}. These functions integrate auxiliary rewards reflecting a designer's heuristics and domain knowledge with the environment's primary rewards. Our approach automatically determines the most effective way to blend these types of feedback, thereby enhancing robustness against heuristic reward misspecification. Remarkably, it can also adapt an agent's policy optimization process to mitigate suboptimalities resulting from limitations and biases inherent in the underlying RL algorithms. We evaluate our method's efficacy on a diverse set of tasks, from small-scale experiments to high-dimensional control challenges. We investigate heuristic auxiliary rewards of varying quality---some of which are beneficial and others detrimental to the learning process. Our results show that our framework offers a robust and principled way to integrate designer-specified heuristics. It not only addresses key shortcomings of existing approaches but also consistently leads to high-performing solutions, even when given misaligned or poorly-specified auxiliary reward functions",
    "checked": true,
    "id": "b5798e23acedbb4cbcadee9feb28eaa9eb47b4ab",
    "semantic_title": "behavior alignment via reward function optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9dp35y5C0p": {
    "title": "Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions",
    "volume": "spotlight",
    "abstract": "Feature transformation aims to generate new pattern-discriminative feature space from original features to improve downstream machine learning (ML) task performances. However, the discrete search space for the optimal feature explosively grows on the basis of combinations of features and operations from low-order forms to high-order forms. Existing methods, such as exhaustive search, expansion reduction, evolutionary algorithms, reinforcement learning, and iterative greedy, suffer from large search space. Overly emphasizing efficiency in algorithm design usually sacrifice stability or robustness. To fundamentally fill this gap, we reformulate discrete feature transformation as a continuous space optimization task and develop an embedding-optimization-reconstruction framework. This framework includes four steps: 1) reinforcement-enhanced data preparation, aiming to prepare high-quality transformation-accuracy training data; 2) feature transformation operation sequence embedding, intending to encapsulate the knowledge of prepared training data within a continuous space; 3) gradient-steered optimal embedding search, dedicating to uncover potentially superior embeddings within the learned space; 4) transformation operation sequence reconstruction, striving to reproduce the feature transformation solution to pinpoint the optimal feature space. Finally, extensive experiments and case studies are performed to demonstrate the effectiveness and robustness of the proposed method. The code and data are publicly accessible https://www.dropbox.com/sh/imh8ckui7va3k5u/AACulQegVx0MuywYyoCqSdVPa?dl=0",
    "checked": true,
    "id": "3b28e053bd9d2aef2f289b5103ba62a1bf9b780f",
    "semantic_title": "reinforcement-enhanced autoregressive feature transformation: gradient-steered search in continuous space for postfix expressions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NpyZkaEEun": {
    "title": "Distributionally Robust Skeleton Learning of Discrete Bayesian Networks",
    "volume": "spotlight",
    "abstract": "We consider the problem of learning the exact skeleton of general discrete Bayesian networks from potentially corrupted data. Building on distributionally robust optimization and a regression approach, we propose to optimize the most adverse risk over a family of distributions within bounded Wasserstein distance or KL divergence to the empirical distribution. The worst-case risk accounts for the effect of outliers. The proposed approach applies for general categorical random variables without assuming faithfulness, an ordinal relationship or a specific form of conditional distribution. We present efficient algorithms and show the proposed methods are closely related to the standard regularized regression approach. Under mild assumptions, we derive non-asymptotic guarantees for successful structure learning with logarithmic sample complexities for bounded-degree graphs. Numerical study on synthetic and real datasets validates the effectiveness of our method",
    "checked": true,
    "id": "3c61af57635decec5996de2e33f07f0676c57f64",
    "semantic_title": "distributionally robust skeleton learning of discrete bayesian networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yKCLfOOIL7": {
    "title": "Mechanism Design for Collaborative Normal Mean Estimation",
    "volume": "spotlight",
    "abstract": "We study collaborative normal mean estimation, where $m$ strategic agents collect i.i.d samples from a normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$ at a cost. They all wish to estimate the mean $\\mu$. By sharing data with each other, agents can obtain better estimates while keeping the cost of data collection small. To facilitate this collaboration, we wish to design mechanisms that encourage agents to collect a sufficient amount of data and share it truthfully, so that they are all better off than working alone. In naive mechanisms, such as simply pooling and sharing all the data, an individual agent might find it beneficial to under-collect and/or fabricate data, which can lead to poor social outcomes. We design a novel mechanism that overcomes these challenges via two key techniques: first, when sharing the others' data with an agent, the mechanism corrupts this dataset proportional to how much the data reported by the agent differs from the others; second, we design minimax optimal estimators for the corrupted dataset. Our mechanism, which is Nash incentive compatible and individually rational, achieves a social penalty (sum of all agents' estimation errors and data collection costs) that is at most a factor 2 of the global minimum. When applied to high dimensional (non-Gaussian) distributions with bounded variance, this mechanism retains these three properties, but with slightly weaker results. Finally, in two special cases where we restrict the strategy space of the agents, we design mechanisms that essentially achieve the global minimum",
    "checked": true,
    "id": "fc13fa57b21fa9882b821cbb5fa910451f35be7e",
    "semantic_title": "mechanism design for collaborative normal mean estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bKqrWLCMrX": {
    "title": "Uncovering the Hidden Dynamics of Video Self-supervised Learning under Distribution Shifts",
    "volume": "spotlight",
    "abstract": "Video self-supervised learning (VSSL) has made significant progress in recent years. However, the exact behavior and dynamics of these models under different forms of distribution shift are not yet known. In this paper, we comprehensively study the behavior of six popular self-supervised methods (v-SimCLR, v-MoCo, v-BYOL, v-SimSiam, v-DINO, v-MAE) in response to various forms of natural distribution shift, i.e., (i) context shift, (ii) viewpoint shift, (iii) actor shift, (iv) source shift, (v) generalizability to unknown classes (zero-shot), and (vi) open-set recognition. To perform this extensive study, we carefully craft a test bed consisting of 17 in-distribution and out-of-distribution benchmark pairs using available public datasets and a series of evaluation protocols to stress-test the different methods under the intended shifts. Our study uncovers a series of intriguing findings and interesting behaviors of VSSL methods. For instance, we observe that while video models generally struggle with context shifts, v-MAE and supervised learning exhibit more robustness. Moreover, our study shows that v-MAE is a strong temporal learner, whereas contrastive methods, v-SimCLR and v-MoCo, exhibit strong performances against viewpoint shifts. When studying the notion of open-set recognition, we notice a trade-off between closed-set and open-set recognition performance if the pretrained VSSL encoders are used without finetuning. We hope that our work will contribute to the development of robust video representation learning frameworks for various real-world scenarios. The project page and code are available at: https://pritamqu.github.io/OOD-VSSL",
    "checked": true,
    "id": "b485ceffc468c499bf5acb0ca90176d0fc8f8a3a",
    "semantic_title": "uncovering the hidden dynamics of video self-supervised learning under distribution shifts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J66ptjMkAG": {
    "title": "Kernel Quadrature with Randomly Pivoted Cholesky",
    "volume": "spotlight",
    "abstract": "This paper presents new quadrature rules for functions in a reproducing kernel Hilbert space using nodes drawn by a sampling algorithm known as randomly pivoted Cholesky. The resulting computational procedure compares favorably to previous kernel quadrature methods, which either achieve low accuracy or require solving a computationally challenging sampling problem. Theoretical and numerical results show that randomly pivoted Cholesky is fast and achieves comparable quadrature error rates to more computationally expensive quadrature schemes based on continuous volume sampling, thinning, and recombination. Randomly pivoted Cholesky is easily adapted to complicated geometries with arbitrary kernels, unlocking new potential for kernel quadrature",
    "checked": true,
    "id": "a65c61be76cfede0d09c46df094c99e080cc2c40",
    "semantic_title": "kernel quadrature with randomly pivoted cholesky",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=TiFMYdQiqp": {
    "title": "Bayesian target optimisation for high-precision holographic optogenetics",
    "volume": "spotlight",
    "abstract": "Two-photon optogenetics has transformed our ability to probe the structure and function of neural circuits. However, achieving precise optogenetic control of neural ensemble activity has remained fundamentally constrained by the problem of off-target stimulation (OTS): the inadvertent activation of nearby non-target neurons due to imperfect confinement of light onto target neurons. Here we propose a novel computational approach to this problem called Bayesian target optimisation. Our approach uses nonparametric Bayesian inference to model neural responses to optogenetic stimulation, and then optimises the laser powers and optical target locations needed to achieve a desired activity pattern with minimal OTS. We validate our approach in simulations and using data from in vitro experiments, showing that Bayesian target optimisation considerably reduces OTS across all conditions we test. Together, these results establish our ability to overcome OTS, enabling optogenetic stimulation with substantially improved precision",
    "checked": true,
    "id": "9d1fdb72be2328293d106365d9f20374230ad1a3",
    "semantic_title": "bayesian target optimisation for high-precision holographic optogenetics",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=kKFDMtpeDW": {
    "title": "On Learning Necessary and Sufficient Causal Graphs",
    "volume": "spotlight",
    "abstract": "The causal revolution has stimulated interest in understanding complex relationships in various fields. Most of the existing methods aim to discover causal relationships among all variables within a complex large-scale graph. However, in practice, only a small subset of variables in the graph are relevant to the outcomes of interest. Consequently, causal estimation with the full causal graph---particularly given limited data---could lead to numerous *falsely discovered, spurious* variables that exhibit high correlation with, but exert no causal impact on, the target outcome. In this paper, we propose learning a class of *necessary and sufficient causal graphs (NSCG)* that exclusively comprises causally relevant variables for an outcome of interest, which we term *causal features*. The key idea is to employ *probabilities of causation* to systematically evaluate the importance of features in the causal graph, allowing us to identify a subgraph relevant to the outcome of interest. To learn NSCG from data, we develop a *necessary and sufficient causal structural learning (NSCSL)* algorithm, by establishing theoretical properties and relationships between probabilities of causation and natural causal effects of features. Across empirical studies of simulated and real data, we demonstrate that NSCSL outperforms existing algorithms and can reveal crucial yeast genes for target heritable traits of interest",
    "checked": true,
    "id": "c32f1a393ada7f276b0b7ca87196ffe60f0cdea4",
    "semantic_title": "on learning necessary and sufficient causal graphs",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=IoizwO1NLf": {
    "title": "Skill-it! A data-driven skills framework for understanding and training language models",
    "volume": "spotlight",
    "abstract": "The quality of training data impacts the performance of pre-trained large language models (LMs). Given a fixed budget of tokens, we study how to best select data that leads to good downstream model performance across tasks. We develop a new framework based on a simple hypothesis: just as humans acquire interdependent skills in a deliberate order, language models also follow a natural order when learning a set of skills from their training data. If such an order exists, it can be utilized for improved understanding of LMs and for data-efficient training. Using this intuition, our framework formalizes the notion of a skill and of an ordered set of skills in terms of the associated data. First, using both synthetic and real data, we demonstrate that these ordered skill sets exist, and that their existence enables more advanced skills to be learned with less data when we train on their prerequisite skills. Second, using our proposed framework, we introduce an online data sampling algorithm, Skill-It, over mixtures of skills for both continual pre-training and fine-tuning regimes, where the objective is to efficiently learn multiple skills in the former and an individual skill in the latter. On the LEGO synthetic in the continual pre-training setting, Skill-It obtains 37.5 points higher accuracy than random sampling. On the Natural Instructions dataset in the fine-tuning setting, Skill-It reduces the validation loss on the target skill by 13.6% versus training on data associated with the target skill itself. We apply our skills framework on the RedPajama dataset to continually pre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation Harness with 1B tokens than the baseline approach of sampling uniformly over data sources with 3B tokens",
    "checked": true,
    "id": "4b474c1f42eefbf14ca85c951f2a22ce031b6cb7",
    "semantic_title": "skill-it! a data-driven skills framework for understanding and training language models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=IKQOS8rqwr": {
    "title": "QuACK: Accelerating Gradient-Based Quantum Optimization with Koopman Operator Learning",
    "volume": "spotlight",
    "abstract": "Quantum optimization, a key application of quantum computing, has traditionally been stymied by the linearly increasing complexity of gradient calculations with an increasing number of parameters. This work bridges the gap between Koopman operator theory, which has found utility in applications because it allows for a linear representation of nonlinear dynamical systems, and natural gradient methods in quantum optimization, leading to a significant acceleration of gradient-based quantum optimization. We present Quantum-circuit Alternating Controlled Koopman learning (QuACK), a novel framework that leverages an alternating algorithm for efficient prediction of gradient dynamics on quantum computers. We demonstrate QuACK's remarkable ability to accelerate gradient-based optimization across a range of applications in quantum optimization and machine learning. In fact, our empirical studies, spanning quantum chemistry, quantum condensed matter, quantum machine learning, and noisy environments, have shown accelerations of more than 200x speedup in the overparameterized regime, 10x speedup in the smooth regime, and 3x speedup in the non-smooth regime. With QuACK, we offer a robust advancement that harnesses the advantage of gradient-based quantum optimization for practical benefits",
    "checked": true,
    "id": "09b85dd390b8e4e738ad884e7dc468ab0bdc9f5c",
    "semantic_title": "quack: accelerating gradient-based quantum optimization with koopman operator learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4ImZxqmT1K": {
    "title": "Learning to Receive Help: Intervention-Aware Concept Embedding Models",
    "volume": "spotlight",
    "abstract": "Concept Bottleneck Models (CBMs) tackle the opacity of neural architectures by constructing and explaining their predictions using a set of high-level concepts. A special property of these models is that they permit concept interventions, wherein users can correct mispredicted concepts and thus improve the model's performance. Recent work, however, has shown that intervention efficacy can be highly dependent on the order in which concepts are intervened on and on the model's architecture and training hyperparameters. We argue that this is rooted in a CBM's lack of train-time incentives for the model to be appropriately receptive to concept interventions. To address this, we propose Intervention-aware Concept Embedding models (IntCEMs), a novel CBM-based architecture and training paradigm that improves a model's receptiveness to test-time interventions. Our model learns a concept intervention policy in an end-to-end fashion from where it can sample meaningful intervention trajectories at train-time. This conditions IntCEMs to effectively select and receive concept interventions when deployed at test-time. Our experiments show that IntCEMs significantly outperform state-of-the-art concept-interpretable models when provided with test-time concept interventions, demonstrating the effectiveness of our approach",
    "checked": true,
    "id": "965c4b4142dd6d6c98d278e3dcf9f3c3ec1b5ed3",
    "semantic_title": "learning to receive help: intervention-aware concept embedding models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=BHxsP5fSHv": {
    "title": "OKRidge: Scalable Optimal k-Sparse Ridge Regression",
    "volume": "spotlight",
    "abstract": "We consider an important problem in scientific discovery, namely identifying sparse governing equations for nonlinear dynamical systems. This involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. We propose a fast algorithm, OKRidge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an ADMM-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. We also propose a method to warm-start our solver, which leverages a beam search. Experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing MIP formulations solved by the commercial solver Gurobi",
    "checked": false,
    "id": "33fce15291bea95ad6df1d60a89f75b1c2fe83aa",
    "semantic_title": "okridge: scalable optimal k-sparse ridge regression for learning dynamical systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hJzEoQHfCe": {
    "title": "Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems",
    "volume": "spotlight",
    "abstract": "Learning high-quality feature embeddings efficiently and effectively is critical for the performance of web-scale machine learning systems. A typical model ingests hundreds of features with vocabularies on the order of millions to billions of tokens. The standard approach is to represent each feature value as a $d$-dimensional embedding, which introduces hundreds of billions of parameters for extremely high-cardinality features. This bottleneck has led to substantial progress in alternative embedding algorithms. Many of these methods, however, make the assumption that each feature uses an independent embedding table. This work introduces a simple yet highly effective framework, Feature Multiplexing, where one single representation space is used for many different categorical features. Our theoretical and empirical analysis reveals that multiplexed embeddings can be decomposed into components from each constituent feature, allowing models to distinguish between features. We show that multiplexed representations give Pareto-optimal space-accuracy tradeoffs for three public benchmark datasets. Further, we propose a highly practical approach called Unified Embedding with three major benefits: simplified feature configuration, strong adaptation to dynamic data distributions, and compatibility with modern hardware. Unified embedding gives significant improvements in offline and online metrics compared to highly competitive baselines across five web-scale search, ads, and recommender systems, where it serves billions of users across the world in industry-leading products",
    "checked": true,
    "id": "874160247612834ef40e3e1302323173b5213f3a",
    "semantic_title": "unified embedding: battle-tested feature representations for web-scale ml systems",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=JTKd7zYROf": {
    "title": "Randomized Sparse Neural Galerkin Schemes for Solving Evolution Equations with Deep Networks",
    "volume": "spotlight",
    "abstract": "Training neural networks sequentially in time to approximate solution fields of time-dependent partial differential equations can be beneficial for preserving causality and other physics properties; however, the sequential-in-time training is numerically challenging because training errors quickly accumulate and amplify over time. This work introduces Neural Galerkin schemes that update randomized sparse subsets of network parameters at each time step. The randomization avoids overfitting locally in time and so helps prevent the error from accumulating quickly over the sequential-in-time training, which is motivated by dropout that addresses a similar issue of overfitting due to neuron co-adaptation. The sparsity of the update reduces the computational costs of training without losing expressiveness because many of the network parameters are redundant locally at each time step. In numerical experiments with a wide range of evolution equations, the proposed scheme with randomized sparse updates is up to two orders of magnitude more accurate at a fixed computational budget and up to two orders of magnitude faster at a fixed accuracy than schemes with dense updates",
    "checked": true,
    "id": "c05c72e0f180e7c13809138550205578eb084cfb",
    "semantic_title": "randomized sparse neural galerkin schemes for solving evolution equations with deep networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=tgQRMrsxht": {
    "title": "Bypassing spike sorting: Density-based decoding using spike localization from dense multielectrode probes",
    "volume": "spotlight",
    "abstract": "Neural decoding and its applications to brain computer interfaces (BCI) are essential for understanding the association between neural activity and behavior. A prerequisite for many decoding approaches is spike sorting, the assignment of action potentials (spikes) to individual neurons. Current spike sorting algorithms, however, can be inaccurate and do not properly model uncertainty of spike assignments, therefore discarding information that could potentially improve decoding performance. Recent advances in high-density probes (e.g., Neuropixels) and computational methods now allow for extracting a rich set of spike features from unsorted data; these features can in turn be used to directly decode behavioral correlates. To this end, we propose a spike sorting-free decoding method that directly models the distribution of extracted spike features using a mixture of Gaussians (MoG) encoding the uncertainty of spike assignments, without aiming to solve the spike clustering problem explicitly. We allow the mixing proportion of the MoG to change over time in response to the behavior and develop variational inference methods to fit the resulting model and to perform decoding. We benchmark our method with an extensive suite of recordings from different animals and probe geometries, demonstrating that our proposed decoder can consistently outperform current methods based on thresholding (i.e. multi-unit activity) and spike sorting. Open source code is available at https://github.com/yzhang511/density_decoding",
    "checked": true,
    "id": "ae273982bf49c0b956744f92351d5c3d96ee8eb2",
    "semantic_title": "bypassing spike sorting: density-based decoding using spike localization from dense multielectrode probes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bbbbbov4Xu": {
    "title": "Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion",
    "volume": "spotlight",
    "abstract": "Instance segmentation in 3D is a challenging task due to the lack of large-scale annotated datasets. In this paper, we show that this task can be addressed effectively by leveraging instead 2D pre-trained models for instance segmentation. We propose a novel approach to lift 2D segments to 3D and fuse them by means of a neural field representation, which encourages multi-view consistency across frames. The core of our approach is a slow-fast clustering objective function, which is scalable and well-suited for scenes with a large number of objects. Unlike previous approaches, our method does not require an upper bound on the number of objects or object tracking across frames. To demonstrate the scalability of the slow-fast clustering, we create a new semi-realistic dataset called the Messy Rooms dataset, which features scenes with up to 500 objects per scene. Our approach outperforms the state-of-the-art on challenging scenes from the ScanNet, Hypersim, and Replica datasets, as well as on our newly created Messy Rooms dataset, demonstrating the effectiveness and scalability of our slow-fast clustering method",
    "checked": true,
    "id": "fc2570c8307c2ac64f1d64b993dded39320b85bd",
    "semantic_title": "contrastive lift: 3d object instance segmentation by slow-fast contrastive fusion",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=CXPUg86A1D": {
    "title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs",
    "volume": "spotlight",
    "abstract": "In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the rich semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%",
    "checked": true,
    "id": "376f494126d1ea4f571ea0263c43ac2b6331800a",
    "semantic_title": "spae: semantic pyramid autoencoder for multimodal generation with frozen llms",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=O06z2G18me": {
    "title": "Evaluating the Moral Beliefs Encoded in LLMs",
    "volume": "spotlight",
    "abstract": "This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM \"making a choice\", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., \"Should I tell a white lie?\") and 687 low-ambiguity moral scenarios (e.g., \"Should I stop for a pedestrian on the road?\"). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., \"do not kill\"). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scenarios, most models ``choose\" actions that align with commonsense. In ambiguous cases, most models express uncertainty. (b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording. (c) Some models reflect clear preferences in ambiguous scenarios. Specifically, closed-source models tend to agree with each other",
    "checked": true,
    "id": "12acdfc7e32e9d603dc108008bb15e65439e7c79",
    "semantic_title": "evaluating the moral beliefs encoded in llms",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=ZvDmna23r3": {
    "title": "Thought Cloning: Learning to Think while Acting by Imitating Human Thinking",
    "volume": "spotlight",
    "abstract": "Language is often considered a key aspect of human thinking, providing us with exceptional abilities to generalize, explore, plan, replan, and adapt to new situations. However, Reinforcement Learning (RL) agents are far from human-level performance in any of these abilities. We hypothesize one reason for such cognitive deficiencies is that they lack the benefits of thinking in language and that we can improve AI agents by training them to $\\textit{think like humans do}$. We introduce a novel Imitation Learning framework, Thought Cloning, where the idea is to not just clone the behaviors of human demonstrators, $\\textit{but also the thoughts humans have as they perform these behaviors}$. While we expect Thought Cloning to truly shine at scale on internet-sized datasets (e.g. online videos with transcripts), here we conduct experiments in a domain where the thinking and action data are synthetically generated. Results reveal that Thought Cloning learns much faster than Behavioral Cloning and its performance advantage grows the further out of distribution test tasks are, highlighting its ability to better handle novel situations. Thought Cloning also provides important benefits for AI Safety and Interpretability, and makes it easier to debug and improve AI. Because we can observe the agent's thoughts, we can (1) more easily diagnose why things are going wrong, making it easier to fix the problem, (2) steer the agent by correcting its thinking, or (3) prevent it from doing unsafe things it plans to do. Overall, by training agents $\\textit{how to think}$ as well as behave, Thought Cloning creates safer, more powerful agents",
    "checked": true,
    "id": "29d9c516cee64ec4a5d8ea94129e6f8da2d60488",
    "semantic_title": "thought cloning: learning to think while acting by imitating human thinking",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=TegmlsD8oQ": {
    "title": "4M: Massively Multimodal Masked Modeling",
    "volume": "spotlight",
    "abstract": "Current machine learning models for vision are often highly specialized and limited to a single modality and task. In contrast, recent large language models exhibit a wide range of capabilities, hinting at a possibility for similarly versatile models in computer vision. In this paper, we take a step in this direction and propose a multimodal training scheme called 4M. It consists of training a single unified Transformer encoder-decoder using a masked modeling objective across a wide range of input/output modalities – including text, images, geometric, and semantic modalities, as well as neural network feature maps. 4M achieves scalability by unifying the representation space of all modalities through mapping them into discrete tokens and performing multimodal masked modeling on a small randomized subset of tokens. 4M leads to models that exhibit several key capabilities: (1) they can perform a diverse set of vision tasks out of the box, (2) they excel when fine-tuned for unseen downstream tasks or new input modalities, and (3) they can function as a generative model that can be conditioned on arbitrary modalities, enabling a wide variety of expressive multimodal editing capabilities with remarkable flexibility. Through experimental analyses, we demonstrate the potential of 4M for training versatile and scalable foundation models for vision tasks, setting the stage for further exploration in multimodal learning for vision and other domains",
    "checked": false,
    "id": "d0b59b3e34a79c8c79a31bf3944ded8ab7a803ae",
    "semantic_title": "rosita: enhancing vision-and-language semantic alignments via cross- and intra-modal knowledge integration",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=eJZ5vJEaaa": {
    "title": "What Planning Problems Can A Relational Neural Network Solve?",
    "volume": "spotlight",
    "abstract": "Goal-conditioned policies are generally understood to be \"feed-forward\" circuits, in the form of neural networks that map from the current state and the goal specification to the next action to take. However, under what circumstances such a policy can be learned and how efficient the policy will be are not well understood. In this paper, we present a circuit complexity analysis for relational neural networks (such as graph neural networks and transformers) representing policies for planning problems, by drawing connections with serialized goal regression search (S-GRS). We show that there are three general classes of planning problems, in terms of the growth of circuit width and depth as a function of the number of objects and planning horizon, providing constructive proofs. We also illustrate the utility of this analysis for designing neural networks for policy learning",
    "checked": false,
    "id": "f12b744d6b6d82a778144c61a3400b563d1ae8aa",
    "semantic_title": "deep convolutional neural network based approach for",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bo8q5MRcwy": {
    "title": "Learning Universal Policies via Text-Guided Video Generation",
    "volume": "spotlight",
    "abstract": "A goal of artificial intelligence is to construct an agent that can solve a wide variety of tasks. Recent progress in text-guided image synthesis has yielded models with an impressive ability to generate complex novel images, exhibiting combinatorial generalization across domains. Motivated by this success, we investigate whether such tools can be used to construct more general-purpose agents. Specifically, we cast the sequential decision making problem as a text-conditioned video generation problem, where, given a text-encoded specification of a desired goal, a planner synthesizes a set of future frames depicting its planned actions in the future, after which control actions are extracted from the generated video. By leveraging text as the underlying goal specification, we are able to naturally and combinatorially generalize to novel goals. The proposed policy-as-video formulation can further represent environments with different state and action spaces in a unified space of images, which, for example, enables learning and generalization across a variety of robot manipulation tasks. Finally, by leveraging pretrained language embeddings and widely available videos from the internet, the approach enables knowledge transfer through predicting highly realistic video plans for real robots",
    "checked": true,
    "id": "da2fe6cd385194b0274d04d04ee72e8caf3854d4",
    "semantic_title": "learning universal policies via text-guided video generation",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=pJQu0zpKCS": {
    "title": "Optimal Exploration for Model-Based RL in Nonlinear Systems",
    "volume": "spotlight",
    "abstract": "Learning to control unknown nonlinear dynamical systems is a fundamental problem in reinforcement learning and control theory. A commonly applied approach is to first explore the environment (exploration), learn an accurate model of it (system identification), and then compute an optimal controller with the minimum cost on this estimated system (policy optimization). While existing work has shown that it is possible to learn a uniformly good model of the system (Mania et al., 2020), in practice, if we aim to learn a good controller with a low cost on the actual system, certain system parameters may be significantly more critical than others, and we therefore ought to focus our exploration on learning such parameters. In this work, we consider the setting of nonlinear dynamical systems and seek to formally quantify, in such settings, (a) which parameters are most relevant to learning a good controller, and (b) how we can best explore so as to minimize uncertainty in such parameters. Inspired by recent work in linear systems (Wagenmaker et al., 2021), we show that minimizing the controller loss in nonlinear systems translates to estimating the system parameters in a particular, task-dependent metric. Motivated by this, we develop an algorithm able to efficiently explore the system to reduce uncertainty in this metric, and prove a lower bound showing that our approach learns a controller at a near-instance-optimal rate. Our algorithm relies on a general reduction from policy optimization to optimal experiment design in arbitrary systems, and may be of independent interest. We conclude with experiments demonstrating the effectiveness of our method in realistic nonlinear robotic systems",
    "checked": true,
    "id": "8037c0795aa73f7a5f4be1d452cccbbad70254a2",
    "semantic_title": "optimal exploration for model-based rl in nonlinear systems",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=nzkWhoXUpv": {
    "title": "Individual Arbitrariness and Group Fairness",
    "volume": "spotlight",
    "abstract": "Machine learning tasks may admit multiple competing models that achieve similar performance yet produce conflicting outputs for individual samples---a phenomenon known as predictive multiplicity. We demonstrate that fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. Consequently, state-of-the-art fairness interventions can mask high predictive multiplicity behind favorable group fairness and accuracy metrics. We argue that a third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact. To address this challenge, we propose an ensemble algorithm applicable to any fairness intervention that provably ensures more consistent predictions",
    "checked": false,
    "id": "703a4bec14310de4810ea55971ae1e5ad1e24fad",
    "semantic_title": "arbitrariness lies beyond the fairness-accuracy frontier",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CgJJvuLjec": {
    "title": "PAPR: Proximity Attention Point Rendering",
    "volume": "spotlight",
    "abstract": "Learning accurate and parsimonious point cloud representations of scene surfaces from scratch remains a challenge in 3D representation learning. Existing point-based methods often suffer from the vanishing gradient problem or require a large number of points to accurately model scene geometry and texture. To address these limitations, we propose Proximity Attention Point Rendering (PAPR), a novel method that consists of a point-based scene representation and a differentiable renderer. Our scene representation uses a point cloud where each point is characterized by its spatial position, foreground score, and view-independent feature vector. The renderer selects the relevant points for each ray and produces accurate colours using their associated features. PAPR effectively learns point cloud positions to represent the correct scene geometry, even when the initialization drastically differs from the target geometry. Notably, our method captures fine texture details while using only a parsimonious set of points. We also demonstrate four practical applications of our method: geometry editing, object manipulation, texture transfer, and exposure control. More results and code are available on our project website at https://zvict.github.io/papr/",
    "checked": true,
    "id": "50f7ccec6179ba708f304e256de54b64ac5d08d8",
    "semantic_title": "papr: proximity attention point rendering",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=KKxO6wwx8p": {
    "title": "SE(3) Equivariant Augmented Coupling Flows",
    "volume": "spotlight",
    "abstract": "Coupling normalizing flows allow for fast sampling and density evaluation, making them the tool of choice for probabilistic modeling of physical systems. However, the standard coupling architecture precludes endowing flows that operate on the Cartesian coordinates of atoms with the SE(3) and permutation invariances of physical systems. This work proposes a coupling flow that preserves SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions. At each layer, the flow maps atoms' positions into learned SE(3) invariant bases, where we apply standard flow transformations, such as monotonic rational-quadratic splines, before returning to the original basis. Crucially, our flow preserves fast sampling and density evaluation, and may be used to produce unbiased estimates of expectations with respect to the target distribution via importance sampling. When trained on the DW4, LJ13, and QM9-positional datasets, our flow is competitive with equivariant continuous normalizing flows, while allowing sampling more than an order of magnitude faster. Moreover, to the best of our knowledge, we are the first to learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms. Lastly, we demonstrate that our flow can be trained to approximately sample from the Boltzmann distribution of the DW4 and LJ13 particle systems using only their energy functions",
    "checked": true,
    "id": "dfb8cf117dc2ccf1f326bb17b489547007fce85d",
    "semantic_title": "se(3) equivariant augmented coupling flows",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bbL20Oupi4": {
    "title": "Anonymous and Copy-Robust Delegations for Liquid Democracy",
    "volume": "spotlight",
    "abstract": "Liquid democracy with ranked delegations is a novel voting scheme that unites the practicability of representative democracy with the idealistic appeal of direct democracy: Every voter decides between casting their vote on a question at hand or delegating their voting weight to some other, trusted agent. Delegations are transitive, and since voters may end up in a delegation cycle, they are encouraged to indicate not only a single delegate, but a set of potential delegates and a ranking among them. Based on the delegation preferences of all voters, a delegation rule selects one representative per voter. Previous work has revealed a trade-off between two properties of delegation rules called anonymity and copy-robustness. To overcome this issue we study two fractional delegation rules: Mixed Borda branching, which generalizes a rule satisfying copy-robustness, and the random walk rule, which satisfies anonymity. Using the Markov chain tree theorem, we show that the two rules are in fact equivalent, and simultaneously satisfy generalized versions of the two properties. Combining the same theorem with Fulkerson's algorithm, we develop a polynomial-time algorithm for computing the outcome of the studied delegation rule. This algorithm is of independent interest, having applications in semi-supervised learning and graph theory",
    "checked": true,
    "id": "8201746be327ae94a7a2bf5904b73318c6e4f73a",
    "semantic_title": "anonymous and copy-robust delegations for liquid democracy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZdxGmJGKOo": {
    "title": "SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning",
    "volume": "spotlight",
    "abstract": "Federated bilevel optimization (FBO) has shown great potential recently in machine learning and edge computing due to the emerging nested optimization structure in meta-learning, fine-tuning, hyperparameter tuning, etc. However, existing FBO algorithms often involve complicated computations and require multiple sub-loops per iteration, each of which contains a number of communication rounds. In this paper, we propose a simple and flexible FBO framework named SimFBO, which is easy to implement without sub-loops, and includes a generalized server-side aggregation and update for improving communication efficiency. We further propose System-level heterogeneity robust FBO (ShroFBO) as a variant of SimFBO with stronger resilience to heterogeneous local computation. We show that SimFBO and ShroFBO provably achieve a linear convergence speedup with partial client participation and client sampling without replacement, as well as improved sample and communication complexities. Experiments demonstrate the effectiveness of the proposed methods over existing FBO algorithms",
    "checked": true,
    "id": "e90ee5b4566c2c7012c6044039057535476248a8",
    "semantic_title": "simfbo: towards simple, flexible and communication-efficient federated bilevel learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0BfQT652sC": {
    "title": "Stochastic Multi-armed Bandits: Optimal Trade-off among Optimality, Consistency, and Tail Risk",
    "volume": "spotlight",
    "abstract": "We consider the stochastic multi-armed bandit problem and fully characterize the interplays among three desired properties for policy design: worst-case optimality, instance-dependent consistency, and light-tailed risk. We show how the order of expected regret exactly affects the decaying rate of the regret tail probability for both the worst-case and instance-dependent scenario. A novel policy is proposed to achieve the optimal regret tail risk for any regret threshold. Concretely, for any given $\\alpha\\in[1/2, 1)$ and $\\beta\\in[0, 1)$, our policy achieves a worst-case expected regret of $\\tilde O(T^\\alpha)$ and instance-dependent expected regret of $\\tilde O(T^\\beta)$, while enjoys a probability of incurring an $\\Omega(T^\\delta)$ regret that decays exponentially with a polynomial $T$ term. Such decaying rate is proved to be best achievable. We also generalize our analysis to the stochastic multi-armed bandit problem with non-stationary baseline rewards, where in each time period $t$, the decision maker pulls one of $K$ arms and collects a reward which is the sum of three terms: the mean of the pulled arm, an independent noise, and a non-stationary baseline reward as a function of $t$. Our results reveal insights on the trade-off between expected regret and tail risk for both worst-case and instance-dependent scenario, indicating that more sub-optimality and inconsistency leaves space for more light-tailed risk of incurring a large regret",
    "checked": false,
    "id": "0cc29ca9d95dda98535c1e979e661bc6654be57b",
    "semantic_title": "regret distribution in stochastic bandits: optimal trade-off between expectation and tail risk",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=i28zCSsQIc": {
    "title": "GloptiNets: Scalable Non-Convex Optimization with Certificates",
    "volume": "spotlight",
    "abstract": "We present a novel approach to non-convex optimization with certificates, which handles smooth functions on the hypercube or on the torus. Unlike traditional methods that rely on algebraic properties, our algorithm exploits the regularity of the target function intrinsic in the decay of its Fourier spectrum. By defining a tractable family of models, we allow {\\em at the same time} to obtain precise certificates and to leverage the advanced and powerful computational techniques developed to optimize neural networks. In this way the scalability of our approach is naturally enhanced by parallel computing with GPUs. Our approach, when applied to the case of polynomials of moderate dimensions but with thousands of coefficients, outperforms the state-of-the-art optimization methods with certificates, as the ones based on Lasserre's hierarchy, addressing problems intractable for the competitors",
    "checked": true,
    "id": "c7a506f319b8a3745b180a167a261bbc4ecad6ff",
    "semantic_title": "gloptinets: scalable non-convex optimization with certificates",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9KtX12YmA7": {
    "title": "The Behavior and Convergence of Local Bayesian Optimization",
    "volume": "spotlight",
    "abstract": "A recent development in Bayesian optimization is the use of local optimization strategies, which can deliver strong empirical performance on high-dimensional problems compared to traditional global strategies. The \"folk wisdom\" in the literature is that the focus on local optimization sidesteps the curse of dimensionality; however, little is known concretely about the expected behavior or convergence of Bayesian local optimization routines. We first study the behavior of the local approach, and find that the statistics of individual local solutions of Gaussian process sample paths are surprisingly good compared to what we would expect to recover from global methods. We then present the first rigorous analysis of such a Bayesian local optimization algorithm recently proposed by Müller et al. (2021), and derive convergence rates in both the noisy and noiseless settings",
    "checked": true,
    "id": "9738c961f1c858c6bfa90d0c3753f7ef8d3d4731",
    "semantic_title": "the behavior and convergence of local bayesian optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YMMlHBSQdC": {
    "title": "Which Models have Perceptually-Aligned Gradients? An Explanation via Off-Manifold Robustness",
    "volume": "spotlight",
    "abstract": "One of the remarkable properties of robust computer vision models is that their input-gradients are often aligned with human perception, referred to in the literature as perceptually-aligned gradients (PAGs). Despite only being trained for classification, PAGs cause robust models to have rudimentary generative capabilities, including image generation, denoising, and in-painting. However, the underlying mechanisms behind these phenomena remain unknown. In this work, we provide a first explanation of PAGs via \\emph{off-manifold robustness}, which states that models must be more robust off- the data manifold than they are on-manifold. We first demonstrate theoretically that off-manifold robustness leads input gradients to lie approximately on the data manifold, explaining their perceptual alignment. We then show that Bayes optimal models satisfy off-manifold robustness, and confirm the same empirically for robust models trained via gradient norm regularization, randomized smoothing, and adversarial training with projected gradient descent. Quantifying the perceptual alignment of model gradients via their similarity with the gradients of generative models, we show that off-manifold robustness correlates well with perceptual alignment. Finally, based on the levels of on- and off-manifold robustness, we identify three different regimes of robustness that affect both perceptual alignment and model accuracy: weak robustness, bayes-aligned robustness, and excessive robustness. Code is available at https://github.com/tml-tuebingen/pags",
    "checked": true,
    "id": "5c46a0bfb23a1df660ba41cb1de387ced85bcf0a",
    "semantic_title": "which models have perceptually-aligned gradients? an explanation via off-manifold robustness",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Y18r0xWkSh": {
    "title": "Posterior Contraction Rates for Matérn Gaussian Processes on Riemannian Manifolds",
    "volume": "spotlight",
    "abstract": "Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Matérn Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of examples, which, mirroring prior work, show that intrinsic processes can achieve better performance in practice. Therefore, our work shows that finer-grained analyses are needed to distinguish between different levels of data-efficiency of geometric Gaussian processes, particularly in settings which involve small data set sizes and non-asymptotic behavior",
    "checked": true,
    "id": "154e5cc26ae0dc82264d6ece09748fe3f76b0513",
    "semantic_title": "posterior contraction rates for matérn gaussian processes on riemannian manifolds",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=1xPsn2gCOe": {
    "title": "Computing a human-like reaction time metric from stable recurrent vision models",
    "volume": "spotlight",
    "abstract": "The meteoric rise in the adoption of deep neural networks as computational models of vision has inspired efforts to ``align\" these models with humans. One dimension of interest for alignment includes behavioral choices, but moving beyond characterizing choice patterns to capturing temporal aspects of visual decision-making has been challenging. Here, we sketch a general-purpose methodology to construct computational accounts of reaction times from a stimulus-computable, task-optimized model. Specifically, we introduce a novel metric leveraging insights from subjective logic theory summarizing evidence accumulation in recurrent vision models. We demonstrate that our metric aligns with patterns of human reaction times for stimulus manipulations across four disparate visual decision-making tasks spanning perceptual grouping, mental simulation, and scene categorization. This work paves the way for exploring the temporal alignment of model and human visual strategies in the context of various other cognitive tasks toward generating testable hypotheses for neuroscience. Links to the code and data can be found on the project page: https://serre-lab.github.io/rnn_rts_site/",
    "checked": true,
    "id": "383eb317cfb30e17d72aa87402fcf57ea6725bb4",
    "semantic_title": "computing a human-like reaction time metric from stable recurrent vision models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zt9RzHjSEy": {
    "title": "Differentially Private Approximate Near Neighbor Counting in High Dimensions",
    "volume": "spotlight",
    "abstract": "Range counting (e.g., counting the number of data points falling into a given query ball) under differential privacy has been studied extensively. However, the current algorithms for this problem are subject to the following dichotomy. One class of algorithms suffers from an additive error that is a fixed polynomial in the number of points. Another class of algorithms allows for polylogarithmic additive error, but the error grows exponentially in the dimension. To achieve the latter, the problem is relaxed to allow a \"fuzzy\" definition of the range boundary, e.g., a count of the points in a ball of radius $r$ might also include points in a ball of radius $cr$ for some $c>1$. In this paper we present an efficient algorithm that offers a sweet spot between these two classes. The algorithm has an additive error that is an arbitrary small power of the data set size, depending on how fuzzy the range boundary is, as well as a small ($1+o(1)$) multiplicative error. Crucially, the amount of noise added has no dependence on the dimension. Our algorithm introduces a variant of Locality-Sensitive Hashing, utilizing it in a novel manner",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0jZH883i34": {
    "title": "Model Sparsity Can Simplify Machine Unlearning",
    "volume": "spotlight",
    "abstract": "In response to recent data regulation requirements, machine unlearning (MU) has emerged as a critical process to remove the influence of specific examples from a given model. Although exact unlearning can be achieved through complete model retraining using the remaining dataset, the associated computational costs have driven the development of efficient, approximate unlearning techniques. Moving beyond data-centric MU approaches, our study introduces a novel model-based perspective: model sparsification via weight pruning, which is capable of reducing the gap between exact unlearning and approximate unlearning. We show in both theory and practice that model sparsity can boost the multi-criteria unlearning performance of an approximate unlearner, closing the approximation gap, while continuing to be efficient. This leads to a new MU paradigm, termed prune first, then unlearn, which infuses a sparse prior to the unlearning process. Building on this insight, we also develop a sparsity-aware unlearning method that utilizes sparsity regularization to enhance the training process of approximate unlearning. Extensive experiments show that our proposals consistently benefit MU in various unlearning scenarios. A notable highlight is the 77% unlearning efficacy gain of fine-tuning (one of the simplest approximate unlearning methods) when using our proposed sparsity-aware unlearning method. Furthermore, we showcase the practical impact of our proposed MU methods through two specific use cases: defending against backdoor attacks, and enhancing transfer learning through source class removal. These applications demonstrate the versatility and effectiveness of our approaches in addressing a variety of machine learning challenges beyond unlearning for data privacy. Codes are available at https://github.com/OPTML-Group/Unlearn-Sparse",
    "checked": true,
    "id": "c8323e6906483bf18bed267306a5081bb843beb4",
    "semantic_title": "model sparsity can simplify machine unlearning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ez6Cb0ZGzG": {
    "title": "Continual Learning for Instruction Following from Realtime Feedback",
    "volume": "spotlight",
    "abstract": "We propose and deploy an approach to continually train an instruction-following agent from feedback provided by users during collaborative interactions. During interaction, human users instruct an agent using natural language, and provide realtime binary feedback as they observe the agent following their instructions. We design a contextual bandit learning approach, converting user feedback to immediate reward. We evaluate through thousands of human-agent interactions, demonstrating 15.4% absolute improvement in instruction execution accuracy over time. We also show our approach is robust to several design variations, and that the feedback signal is roughly equivalent to the learning signal of supervised demonstration data",
    "checked": true,
    "id": "6ba3e4172e5c22c8c3ace05a31e9b119a2e3c33c",
    "semantic_title": "continual learning for instruction following from realtime feedback",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=rwbzMiuFQl": {
    "title": "Break It Down: Evidence for Structural Compositionality in Neural Networks",
    "volume": "spotlight",
    "abstract": "Though modern neural networks have achieved impressive performance in both vision and language tasks, we know little about the functions that they implement. One possibility is that neural networks implicitly break down complex tasks into subroutines, implement modular solutions to these subroutines, and compose them into an overall solution to a task --- a property we term structural compositionality. Another possibility is that they may simply learn to match new inputs to learned templates, eliding task decomposition entirely. Here, we leverage model pruning techniques to investigate this question in both vision and language across a variety of architectures, tasks, and pretraining regimens. Our results demonstrate that models oftentimes implement solutions to subroutines via modular subnetworks, which can be ablated while maintaining the functionality of other subnetworks. This suggests that neural networks may be able to learn compositionality, obviating the need for specialized symbolic mechanisms",
    "checked": true,
    "id": "d369fcd0d7652380e094425b98eae22a77cdcfdf",
    "semantic_title": "break it down: evidence for structural compositionality in neural networks",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=kvXcHfBghm": {
    "title": "Minimum-Risk Recalibration of Classifiers",
    "volume": "spotlight",
    "abstract": "Recalibrating probabilistic classifiers is vital for enhancing the reliability and accuracy of predictive models. Despite the development of numerous recalibration algorithms, there is still a lack of a comprehensive theory that integrates calibration and sharpness (which is essential for maintaining predictive power). In this paper, we introduce the concept of minimum-risk recalibration within the framework of mean-squared-error (MSE) decomposition, offering a principled approach for evaluating and recalibrating probabilistic classifiers. Using this framework, we analyze the uniform-mass binning (UMB) recalibration method and establish a finite-sample risk upper bound of order $\\tilde{O}(B/n + 1/B^2)$ where $B$ is the number of bins and $n$ is the sample size. By balancing calibration and sharpness, we further determine that the optimal number of bins for UMB scales with $n^{1/3}$, resulting in a risk bound of approximately $O(n^{-2/3})$. Additionally, we tackle the challenge of label shift by proposing a two-stage approach that adjusts the recalibration function using limited labeled data from the target domain. Our results show that transferring a calibrated classifier requires significantly fewer target samples compared to recalibrating from scratch. We validate our theoretical findings through numerical simulations, which confirm the tightness of the proposed bounds, the optimal number of bins, and the effectiveness of label shift adaptation",
    "checked": true,
    "id": "7063023f918fc0b434af356a57134aa5417ec405",
    "semantic_title": "minimum-risk recalibration of classifiers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jSuhnO9QJv": {
    "title": "Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases",
    "volume": "spotlight",
    "abstract": "We present a simple but effective method to measure and mitigate model biases caused by reliance on spurious cues. Instead of requiring costly changes to one's data or model training, our method better utilizes the data one already has by sorting them. Specifically, we rank images within their classes based on spuriosity (the degree to which common spurious cues are present), proxied via deep neural features of an interpretable network. With spuriosity rankings, it is easy to identify minority subpopulations (i.e. low spuriosity images) and assess model bias as the gap in accuracy between high and low spuriosity images. One can even efficiently remove a model's bias at little cost to accuracy by finetuning its classification head on low spuriosity images, resulting in fairer treatment of samples regardless of spuriosity. We demonstrate our method on ImageNet, annotating $5000$ class-feature dependencies ($630$ of which we find to be spurious) and generating a dataset of $325k$ soft segmentations for these features along the way. Having computed spuriosity rankings via the identified spurious neural features, we assess biases for $89$ diverse models and find that class-wise biases are highly correlated across models. Our results suggest that model bias due to spurious feature reliance is influenced far more by what the model is trained on than how it is trained",
    "checked": true,
    "id": "0e07da2c25359f6488bdd9b18bd62cf587a1797c",
    "semantic_title": "spuriosity rankings: sorting data to measure and mitigate biases",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Rzk3GP1HN7": {
    "title": "SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks",
    "volume": "spotlight",
    "abstract": "We introduce SwiftSage, a novel agent framework inspired by the dual-process theory of human cognition, designed to excel in action planning for complex interactive reasoning tasks. SwiftSage integrates the strengths of behavior cloning and prompting large language models (LLMs) to enhance task completion performance. The framework comprises two primary modules: the Swift module, representing fast and intuitive thinking, and the Sage module, emulating deliberate thought processes. The Swift module is a small encoder-decoder LM fine-tuned on the oracle agent's action trajectories, while the Sage module employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a heuristic method to harmoniously integrate the two modules, resulting in a more efficient and robust problem-solving process. In 30 tasks from the ScienceWorld benchmark, SwiftSage significantly outperforms other methods such as SayCan, ReAct, and Reflexion, demonstrating its effectiveness in solving complex interactive tasks",
    "checked": true,
    "id": "d671d62a1eb4d57343e4a0928297266dffc0c118",
    "semantic_title": "swiftsage: a generative agent with fast and slow thinking for complex interactive tasks",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=mQPNcBWjGc": {
    "title": "Scaling Open-Vocabulary Object Detection",
    "volume": "spotlight",
    "abstract": "Open-vocabulary object detection has benefited greatly from pretrained vision-language models, but is still limited by the amount of available detection training data. While detection training data can be expanded by using Web image-text pairs as weak supervision, this has not been done at scales comparable to image-level pretraining. Here, we scale up detection data with self-training, which uses an existing detector to generate pseudo-box annotations on image-text pairs. Major challenges in scaling self-training are the choice of label space, pseudo-annotation filtering, and training efficiency. We present the OWLv2 model and OWL-ST self-training recipe, which address these challenges. OWLv2 surpasses the performance of previous state-of-the-art open-vocabulary detectors already at comparable training scales (~10M examples). However, with OWL-ST, we can scale to over 1B examples, yielding further large improvement: With an L/14 architecture, OWL-ST improves AP on LVIS rare classes, for which the model has seen no human box annotations, from 31.2% to 44.6% (43% relative improvement). OWL-ST unlocks Web-scale training for open-world localization, similar to what has been seen for image classification and language modelling. Code and checkpoints are available on GitHub",
    "checked": true,
    "id": "2bf1b63d4222a14f78bfcb481378c3caf9c39528",
    "semantic_title": "scaling open-vocabulary object detection",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=VEpU9rFaQr": {
    "title": "Auditing for Human Expertise",
    "volume": "spotlight",
    "abstract": "High-stakes prediction tasks (e.g., patient diagnosis) are often handled by trained human experts. A common source of concern about automation in these settings is that experts may exercise intuition that is difficult to model and/or have access to information (e.g., conversations with a patient) that is simply unavailable to a would-be algorithm. This raises a natural question whether human experts add value which could not be captured by an algorithmic predictor. We develop a statistical framework under which we can pose this question as a natural hypothesis test. Indeed, as our framework highlights, detecting human expertise is more subtle than simply comparing the accuracy of expert predictions to those made by a particular learning algorithm. Instead, we propose a simple procedure which tests whether expert predictions are statistically independent from the outcomes of interest after conditioning on the available inputs (‘features'). A rejection of our test thus suggests that human experts may add value to any algorithm trained on the available data, and has direct implications for whether human-AI ‘complementarity' is achievable in a given prediction task. We highlight the utility of our procedure using admissions data collected from the emergency department of a large academic hospital system, where we show that physicians' admit/discharge decisions for patients with acute gastrointestinal bleeding (AGIB) appear to be incorporating information that is not available to a standard algorithmic screening tool. This is despite the fact that the screening tool is arguably more accurate than physicians' discretionary decisions, highlighting that – even absent normative concerns about accountability or interpretability – accuracy is insufficient to justify algorithmic automation",
    "checked": true,
    "id": "b97efeace4a0c7607d8256fd34dd8826b996c340",
    "semantic_title": "auditing for human expertise",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=aINqoP32cb": {
    "title": "CS4ML: A general framework for active learning with arbitrary data based on Christoffel functions",
    "volume": "spotlight",
    "abstract": "We introduce a general framework for active learning in regression problems. Our framework extends the standard setup by allowing for general types of data, rather than merely pointwise samples of the target function. This generalization covers many cases of practical interest, such as data acquired in transform domains (e.g., Fourier data), vector-valued data (e.g., gradient-augmented data), data acquired along continuous curves, and, multimodal data (i.e., combinations of different types of measurements). Our framework considers random sampling according to a finite number of sampling measures and arbitrary nonlinear approximation spaces (model classes). We introduce the concept of \\textit{generalized Christoffel functions} and show how these can be used to optimize the sampling measures. We prove that this leads to near-optimal sample complexity in various important cases. This paper focuses on applications in scientific computing, where active learning is often desirable, since it is usually expensive to generate data. We demonstrate the efficacy of our framework for gradient-augmented learning with polynomials, Magnetic Resonance Imaging (MRI) using generative models and adaptive sampling for solving PDEs using Physics-Informed Neural Networks (PINNs)",
    "checked": true,
    "id": "a8ad7babcf93fdcd9271cf80a085955fd2e83679",
    "semantic_title": "cs4ml: a general framework for active learning with arbitrary data based on christoffel functions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=YQA28p7qNz": {
    "title": "3D-LLM: Injecting the 3D World into Large Language Models",
    "volume": "spotlight",
    "abstract": "Large language models (LLMs) and Vision-Language Models (VLMs) have been proved to excel at multiple tasks, such as commonsense reasoning. Powerful as these models can be, they are not grounded in the 3D physical world, which involves richer concepts such as spatial relationships, affordances, physics, layout, and so on. In this work, we propose to inject the 3D world into large language models, and introduce a whole new family of 3D-LLMs. Specifically, 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on. Using three types of prompting mechanisms that we design, we are able to collect over 300k 3D-language data covering these tasks. To efficiently train 3D-LLMs, we first utilize a 3D feature extractor that obtains 3D features from rendered multi-view images. Then, we use 2D VLMs as our backbones to train our 3D-LLMs. By introducing a 3D localization mechanism, 3D-LLMs could better capture 3D spatial information. Experiments on ScanQA show that our model outperforms state-of-the-art baselines by a large margin (\\textit{e.g.}, the BLEU-1 score surpasses state-of-the-art score by 9\\%). Furthermore, experiments on our held-in datasets for 3D captioning, task composition, and 3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative examples also show that our model could perform more tasks beyond the scope of existing LLMs and VLMs. Our model and data will be publicly available",
    "checked": true,
    "id": "7637ed79d30d0139901175ae4abedd822c217ab4",
    "semantic_title": "3d-llm: injecting the 3d world into large language models",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=hE5RWzQyvf": {
    "title": "Distributionally Robust Linear Quadratic Control",
    "volume": "spotlight",
    "abstract": "Linear-Quadratic-Gaussian (LQG) control is a fundamental control paradigm that is studied in various fields such as engineering, computer science, economics, and neuroscience. It involves controlling a system with linear dynamics and imperfect observations, subject to additive noise, with the goal of minimizing a quadratic cost function for the state and control variables. In this work, we consider a generalization of the discrete-time, finite-horizon LQG problem, where the noise distributions are unknown and belong to Wasserstein ambiguity sets centered at nominal (Gaussian) distributions. The objective is to minimize a worst-case cost across all distributions in the ambiguity set, including non-Gaussian distributions. Despite the added complexity, we prove that a control policy that is linear in the observations is optimal for this problem, as in the classic LQG problem. We propose a numerical solution method that efficiently characterizes this optimal control policy. Our method uses the Frank-Wolfe algorithm to identify the least-favorable distributions within the Wasserstein ambiguity sets and computes the controller's optimal policy using Kalman filter estimation under these distributions",
    "checked": true,
    "id": "9cd2c80bd9279aeda6d9a252c3abefbfd73ab672",
    "semantic_title": "distributionally robust linear quadratic control",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=adq0oXb9KM": {
    "title": "Tree Variational Autoencoders",
    "volume": "spotlight",
    "abstract": "We propose Tree Variational Autoencoder (TreeVAE), a new generative hierarchical clustering model that learns a flexible tree-based posterior distribution over latent variables. TreeVAE hierarchically divides samples according to their intrinsic characteristics, shedding light on hidden structures in the data. It adapts its architecture to discover the optimal tree for encoding dependencies between latent variables. The proposed tree-based generative architecture enables lightweight conditional inference and improves generative performance by utilizing specialized leaf decoders. We show that TreeVAE uncovers underlying clusters in the data and finds meaningful hierarchical relations between the different groups on a variety of datasets, including real-world imaging data. We present empirically that TreeVAE provides a more competitive log-likelihood lower bound than the sequential counterparts. Finally, due to its generative nature, TreeVAE is able to generate new samples from the discovered clusters via conditional sampling",
    "checked": true,
    "id": "ea99152dfc8df70e81002a665536f96f1beb646c",
    "semantic_title": "tree variational autoencoders",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EmxpDiPgRu": {
    "title": "Honesty Is the Best Policy: Defining and Mitigating AI Deception",
    "volume": "spotlight",
    "abstract": "Deceptive agents are a challenge for the safety, trustworthiness, and cooperation of AI systems. We focus on the problem that agents might deceive in order to achieve their goals (for instance, in our experiments with language models, the goal of being evaluated as truthful). There are a number of existing definitions of deception in the literature on game theory and symbolic AI, but there is no overarching theory of deception for learning agents in games. We introduce a formal definition of deception in structural causal games, grounded in the philosophy literature, and applicable to real-world machine learning systems. Several examples and results illustrate that our formal definition aligns with the philosophical and commonsense meaning of deception. Our main technical result is to provide graphical criteria for deception. We show, experimentally, that these results can be used to mitigate deception in reinforcement learning agents and language models",
    "checked": true,
    "id": "569d6641ff9b67c2bd399ea0519940a171a48829",
    "semantic_title": "honesty is the best policy: defining and mitigating ai deception",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=EEVpt3dJQj": {
    "title": "Auditing Fairness by Betting",
    "volume": "spotlight",
    "abstract": "We provide practical, efficient, and nonparametric methods for auditing the fairness of deployed classification and regression models. Whereas previous work relies on a fixed-sample size, our methods are sequential and allow for the continuous monitoring of incoming data, making them highly amenable to tracking the fairness of real-world systems. We also allow the data to be collected by a probabilistic policy as opposed to sampled uniformly from the population. This enables auditing to be conducted on data gathered for another purpose. Moreover, this policy may change over time and different policies may be used on different subpopulations. Finally, our methods can handle distribution shift resulting from either changes to the model or changes in the underlying population. Our approach is based on recent progress in anytime-valid inference and game-theoretic statistics---the ``testing by betting'' framework in particular. These connections ensure that our methods are interpretable, fast, and easy to implement. We demonstrate the efficacy of our approach on three benchmark fairness datasets",
    "checked": true,
    "id": "40eabf1cc9a1216f941847b21c3c98244d77e703",
    "semantic_title": "auditing fairness by betting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q8SukwaEBy": {
    "title": "Learning from Active Human Involvement through Proxy Value Propagation",
    "volume": "spotlight",
    "abstract": "Learning from active human involvement enables the human subject to actively intervene and demonstrate to the AI agent during training. The interaction and corrective feedback from human brings safety and AI alignment to the learning process. In this work, we propose a new reward-free active human involvement method called Proxy Value Propagation for policy optimization. Our key insight is that a proxy value function can be designed to express human intents, wherein state- action pairs in the human demonstration are labeled with high values, while those agents' actions that are intervened receive low values. Through the TD-learning framework, labeled values of demonstrated state-action pairs are further propagated to other unlabeled data generated from agents' exploration. The proxy value function thus induces a policy that faithfully emulates human behaviors. Human- in-the-loop experiments show the generality and efficiency of our method. With minimal modification to existing reinforcement learning algorithms, our method can learn to solve continuous and discrete control tasks with various human control devices, including the challenging task of driving in Grand Theft Auto V. Demo video and code are available at: https://metadriverse.github.io/pvp",
    "checked": false,
    "id": "5d3f64a099883641aa92dfc7a061d2991becdfff",
    "semantic_title": "a deep learning approach for semantic segmentation in brain tumor images",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p40XRfBX96": {
    "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",
    "volume": "spotlight",
    "abstract": "Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including < 200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings",
    "checked": true,
    "id": "e01515c6138bc525f7aec30fc85f2adf028d4156",
    "semantic_title": "principle-driven self-alignment of language models from scratch with minimal human supervision",
    "citation_count": 68,
    "authors": []
  },
  "https://openreview.net/forum?id=gq4xkwQZ1l": {
    "title": "Diffusion with Forward Models: Solving Stochastic Inverse Problems Without Direct Supervision",
    "volume": "spotlight",
    "abstract": "Denoising diffusion models are a powerful type of generative models used to capture complex distributions of real-world signals. However, their applicability is limited to scenarios where training samples are readily available, which is not always the case in real-world applications. For example, in inverse graphics, the goal is to generate samples from a distribution of 3D scenes that align with a given image, but ground-truth 3D scenes are unavailable and only 2D images are accessible. To address this limitation, we propose a novel class of denoising diffusion probabilistic models that learn to sample from distributions of signals that are never directly observed. Instead, these signals are measured indirectly through a known differentiable forward model, which produces partial observations of the unknown signal. Our approach involves integrating the forward model directly into the denoising process. A key contribution of our work is the integration of a differentiable forward model into the denoising process. This integration effectively connects the generative modeling of observations with the generative modeling of the underlying signals, allowing for end-to-end training of a conditional generative model over signals. During inference, our approach enables sampling from the distribution of underlying signals that are consistent with a given partial observation. We demonstrate the effectiveness of our method on three challenging computer vision tasks. For instance, in the context of inverse graphics, our model enables direct sampling from the distribution of 3D scenes that align with a single 2D input image",
    "checked": true,
    "id": "489b35b66fab138ea28ade179f68135a1cd06ff9",
    "semantic_title": "diffusion with forward models: solving stochastic inverse problems without direct supervision",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=JV8Ff0lgVV": {
    "title": "DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization",
    "volume": "spotlight",
    "abstract": "Neural network-based Combinatorial Optimization (CO) methods have shown promising results in solving various NP-complete (NPC) problems without relying on hand-crafted domain knowledge. This paper broadens the current scope of neural solvers for NPC problems by introducing a new graph-based diffusion framework, namely DIFUSCO. It formulates NPC problems into a discrete {0, 1}-vector space and uses graph-based denoising diffusion models to generate high-quality solutions. Specifically, we explore diffusion models with Gaussian and Bernoulli noise, respectively, and also introduce an effective inference schedule to improve the generation quality. We evaluate our methods on two well-studied combinatorial optimization problems: Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS). Experimental results show that DIFUSCO strongly outperforms the previous state-of-the-art neural solvers, improving the performance gap between ground-truth and neural solvers from 1.76% to 0.46% on TSP-500, from 2.46% to 1.17% on TSP-1000, and from 3.19% to 2.58% on TSP-10000. For the MIS problem, DIFUSCO outperforms the previous state-of-the-art neural solver on the challenging SATLIB benchmark. Our code is available at [this url](https://github.com/Edward-Sun/DIFUSCO)",
    "checked": true,
    "id": "5f90d43e6ece5c6ee6e8186e4b57d46c85377713",
    "semantic_title": "difusco: graph-based diffusion solvers for combinatorial optimization",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=1p6teT6F73": {
    "title": "Alternating Updates for Efficient Transformers",
    "volume": "spotlight",
    "abstract": "It has been well established that increasing scale in deep transformer networks leads to improved quality and performance. However, this increase in scale often comes with prohibitive increases in compute cost and inference latency. We introduce Alternating Updates (AltUp), a simple-to-implement method to increase a model's capacity without the computational burden. AltUp enables the widening of the learned representation, i.e., the token embedding, while only incurring a negligible increase in latency. AltUp achieves this by working on a subblock of the widened representation at each layer and using a predict-and-correct mechanism to update the inactivated blocks. We present extensions of AltUp, such as its applicability to the sequence dimension, and demonstrate how AltUp can be synergistically combined with existing approaches, such as Sparse Mixture-of-Experts models, to obtain efficient models with even higher capacity. Our experiments on benchmark transformer models and language tasks demonstrate the consistent effectiveness of AltUp on a diverse set of scenarios. Notably, on SuperGLUE and SQuAD benchmarks, AltUp enables up to $87\\%$ speedup relative to the dense baselines at the same accuracy",
    "checked": true,
    "id": "c9d46cfcf0211d11356c295ecd9584c84c19c8f8",
    "semantic_title": "alternating updates for efficient transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bOQNd7tWAp": {
    "title": "Online Control for Meta-optimization",
    "volume": "spotlight",
    "abstract": "Choosing the optimal hyperparameters, including learning rate and momentum, for specific optimization instances is a significant yet non-convex challenge. This makes conventional iterative techniques such as hypergradient descent \\cite{baydin2017online} insufficient in obtaining global optimality guarantees. We consider the more general task of meta-optimization -- online learning of the best optimization algorithm given problem instances, and introduce a novel approach based on control theory. We show how meta-optimization can be formulated as an optimal control problem, departing from existing literature that use stability-based methods to study optimization. Our approach leverages convex relaxation techniques in the recently-proposed nonstochastic control framework to overcome the challenge of nonconvexity, and obtains regret guarantees vs. the best offline solution. This guarantees that in meta-optimization, we can learn a method that attains convergence comparable to that of the best optimization method in hindsight from a class of methods",
    "checked": false,
    "id": "86aab024f48baac8cdf5a2ae61041d16b322fe41",
    "semantic_title": "a nonstochastic control approach to optimization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=voG6nEW9BV": {
    "title": "Conditional score-based diffusion models for Bayesian inference in infinite dimensions",
    "volume": "spotlight",
    "abstract": "Since their initial introduction, score-based diffusion models (SDMs) have been successfully applied to solve a variety of linear inverse problems in finite-dimensional vector spaces due to their ability to efficiently approximate the posterior distribution. However, using SDMs for inverse problems in infinite-dimensional function spaces has only been addressed recently, primarily through methods that learn the unconditional score. While this approach is advantageous for some inverse problems, it is mostly heuristic and involves numerous computationally costly forward operator evaluations during posterior sampling. To address these limitations, we propose a theoretically grounded method for sampling from the posterior of infinite-dimensional Bayesian linear inverse problems based on amortized conditional SDMs. In particular, we prove that one of the most successful approaches for estimating the conditional score in finite dimensions—the conditional denoising estimator—can also be applied in infinite dimensions. A significant part of our analysis is dedicated to demonstrating that extending infinite-dimensional SDMs to the conditional setting requires careful consideration, as the conditional score typically blows up for small times, contrarily to the unconditional score. We conclude by presenting stylized and large-scale numerical examples that validate our approach, offer additional insights, and demonstrate that our method enables large-scale, discretization-invariant Bayesian inference",
    "checked": true,
    "id": "16a5c629a59d87a2616afc2b94cd37b9e2f5063f",
    "semantic_title": "conditional score-based diffusion models for bayesian inference in infinite dimensions",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=SthlUe5xDP": {
    "title": "Topological Parallax: A Geometric Specification for Deep Perception Models",
    "volume": "spotlight",
    "abstract": "For safety and robustness of AI systems, we introduce _topological parallax_ as a theoretical and computational tool that compares a trained model to a reference dataset to determine whether they have similar multiscale geometric structure. Our proofs and examples show that this geometric similarity between dataset and model is essential to trustworthy interpolation and perturbation, and we conjecture that this new concept will add value to the current debate regarding the unclear relationship between \"overfitting\"' and \"generalization'' in applications of deep-learning. In typical deep-learning applications, an explicit geometric description of the model is impossible, but parallax can estimate topological features (components, cycles, voids, etc.) in the model by examining the effect on the Rips complex of geodesic distortions using the reference dataset. Thus, parallax indicates whether the model shares similar multiscale geometric features with the dataset. Parallax presents theoretically via topological data analysis [TDA] as a bi-filtered persistence module, and the key properties of this module are stable under perturbation of the reference dataset",
    "checked": true,
    "id": "8ac76f8921c69fd673d56f99b91fc445b12575ca",
    "semantic_title": "topological parallax: a geometric specification for deep perception models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=94rKFkcm56": {
    "title": "Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power",
    "volume": "spotlight",
    "abstract": "The ability of graph neural networks (GNNs) to count certain graph substructures, especially cycles, is important for the success of GNNs on a wide range of tasks. It has been recently used as a popular metric for evaluating the expressive power of GNNs. Many of the proposed GNN models with provable cycle counting power are based on subgraph GNNs, i.e., extracting a bag of subgraphs from the input graph, generating representations for each subgraph, and using them to augment the representation of the input graph. However, those methods require heavy preprocessing, and suffer from high time and memory costs. In this paper, we overcome the aforementioned limitations of subgraph GNNs by proposing a novel class of GNNs---$d$-Distance-Restricted FWL(2) GNNs, or $d$-DRFWL(2) GNNs, based on the well-known FWL(2) algorithm. As a heuristic method for graph isomorphism testing, FWL(2) colors all node pairs in a graph and performs message passing among those node pairs. In order to balance the expressive power and complexity, $d$-DRFWL(2) GNNs simplify FWL(2) by restricting the range of message passing to node pairs whose mutual distances are at most $d$. This way, $d$-DRFWL(2) GNNs exploit graph sparsity while avoiding the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower. We theoretically investigate both the discriminative power and the cycle counting power of $d$-DRFWL(2) GNNs. Our most important finding is that $d$-DRFWL(2) GNNs have provably strong cycle counting power even with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene rings) are ubiquitous in organic molecules, being able to detect and count them is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify our theory. To the best of our knowledge, 2-DRFWL(2) GNN is the most efficient GNN model to date (both theoretically and empirically) that can count up to 6-cycles",
    "checked": true,
    "id": "8f7eb270c0e338d544af82e81769abaaf53d6c2d",
    "semantic_title": "distance-restricted folklore weisfeiler-leman gnns with provable cycle counting power",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=40L3viVWQN": {
    "title": "The Pick-to-Learn Algorithm: Empowering Compression for Tight Generalization Bounds and Improved Post-training Performance",
    "volume": "spotlight",
    "abstract": "Generalization bounds are valuable both for theory and applications. On the one hand, they shed light on the mechanisms that underpin the learning processes; on the other, they certify how well a learned model performs against unseen inputs. In this work we build upon a recent breakthrough in compression theory to develop a new framework yielding tight generalization bounds of wide practical applicability. The core idea is to embed any given learning algorithm into a suitably-constructed meta-algorithm (here called Pick-to-Learn, P2L) in order to instill desirable compression properties. When applied to the MNIST classification dataset and to a synthetic regression problem, P2L not only attains generalization bounds that compare favorably with the state of the art (test-set and PAC-Bayes bounds), but it also learns models with better post-training performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5B1ZK60jWn": {
    "title": "A Spectral Theory of Neural Prediction and Alignment",
    "volume": "spotlight",
    "abstract": "The representations of neural networks are often compared to those of biological systems by performing regression between the neural network responses and those measured from biological systems. Many different state-of-the-art deep neural networks yield similar neural predictions, but it remains unclear how to differentiate among models that perform equally well at predicting neural responses. To gain insight into this, we use a recent theoretical framework that relates the generalization error from regression to the spectral properties of the model and the target. We apply this theory to the case of regression between model activations and neural responses and decompose the neural prediction error in terms of the model eigenspectra, alignment of model eigenvectors and neural responses, and the training set size. Using this decomposition, we introduce geometrical measures to interpret the neural prediction error. We test a large number of deep neural networks that predict visual cortical activity and show that there are multiple types of geometries that result in low neural prediction error as measured via regression. The work demonstrates that carefully decomposing representational metrics can provide interpretability of how models are capturing neural activity and points the way towards improved models of neural activity",
    "checked": true,
    "id": "9d9150db40f205beb08ed4b8bf62011631d17b94",
    "semantic_title": "a spectral theory of neural prediction and alignment",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=fHsBNNDroC": {
    "title": "Calibrated Stackelberg Games: Learning Optimal Commitments Against Calibrated Agents",
    "volume": "spotlight",
    "abstract": "In this paper, we introduce a generalization of the standard Stackelberg Games (SGs) framework: _Calibrated Stackelberg Games_. In CSGs, a principal repeatedly interacts with an agent who (contrary to standard SGs) does not have direct access to the principal's action but instead best responds to _calibrated forecasts_ about it. CSG is a powerful modeling tool that goes beyond assuming that agents use ad hoc and highly specified algorithms for interacting in strategic settings to infer the principal's actions and thus more robustly addresses real-life applications that SGs were originally intended to capture. Along with CSGs, we also introduce a stronger notion of calibration, termed _adaptive calibration_, that provides fine-grained any-time calibration guarantees against adversarial sequences. We give a general approach for obtaining adaptive calibration algorithms and specialize them for finite CSGs. In our main technical result, we show that in CSGs, the principal can achieve utility that converges to the optimum Stackelberg value of the game both in _finite_ and _continuous_ settings and that no higher utility is achievable. Two prominent and immediate applications of our results are the settings of learning in Stackelberg Security Games and strategic classification, both against _calibrated_ agents",
    "checked": true,
    "id": "34035931f0eb5678545bfe0ace00251f5fc38a32",
    "semantic_title": "calibrated stackelberg games: learning optimal commitments against calibrated agents",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=haHIji0yFt": {
    "title": "$SE(3)$ Equivariant Convolution and Transformer in Ray Space",
    "volume": "spotlight",
    "abstract": "3D reconstruction and novel view rendering can greatly benefit from geometric priors when the input views are not sufficient in terms of coverage and inter-view baselines. Deep learning of geometric priors from 2D images requires each image to be represented in a $2D$ canonical frame and the prior to be learned in a given or learned $3D$ canonical frame. In this paper, given only the relative poses of the cameras, we show how to learn priors from multiple views equivariant to coordinate frame transformations by proposing an $SE(3)$-equivariant convolution and transformer in the space of rays in 3D. We model the ray space as a homogeneous space of $SE(3)$ and introduce the $SE(3)$-equivariant convolution in ray space. Depending on the output domain of the convolution, we present convolution-based $SE(3)$-equivariant maps from ray space to ray space and to $\\mathbb{R}^3$. Our mathematical framework allows us to go beyond convolution to $SE(3)$-equivariant attention in the ray space. We showcase how to tailor and adapt the equivariant convolution and transformer in the tasks of equivariant $3D$ reconstruction and equivariant neural rendering from multiple views. We demonstrate $SE(3)$-equivariance by obtaining robust results in roto-translated datasets without performing transformation augmentation",
    "checked": false,
    "id": "763efe38d5a8ee011b98cbd326834104b8943bae",
    "semantic_title": "equivariant light field convolution and transformer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wiidCRA3at": {
    "title": "Stein $\\Pi$-Importance Sampling",
    "volume": "spotlight",
    "abstract": "Stein discrepancies have emerged as a powerful tool for retrospective improvement of Markov chain Monte Carlo output. However, the question of how to design Markov chains that are well-suited to such post-processing has yet to be addressed. This paper studies Stein importance sampling, in which weights are assigned to the states visited by a $\\Pi$-invariant Markov chain to obtain a consistent approximation of $P$, the intended target. Surprisingly, the optimal choice of $\\Pi$ is not identical to the target $P$; we therefore propose an explicit construction for $\\Pi$ based on a novel variational argument. Explicit conditions for convergence of Stein $\\Pi$-Importance Sampling are established. For $\\approx 70$% of tasks in the PosteriorDB benchmark, a significant improvement over the analogous post-processing of $P$-invariant Markov chains is reported",
    "checked": true,
    "id": "d6bf93d7bf91481b5049826bd99815dc1531481d",
    "semantic_title": "stein $\\pi$-importance sampling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1vyAG6j9PE": {
    "title": "Unexpected Improvements to Expected Improvement for Bayesian Optimization",
    "volume": "spotlight",
    "abstract": "Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in \"classic\" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies. Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature",
    "checked": true,
    "id": "0a1bf4740dc9f02c292d5489c5097cc8da7f4368",
    "semantic_title": "unexpected improvements to expected improvement for bayesian optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QKSejqE8Vp": {
    "title": "An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions",
    "volume": "spotlight",
    "abstract": "Noisy marginals are a common form of confidentiality-protecting data release and are useful for many downstream tasks such as contingency table analysis, construction of Bayesian networks, and even synthetic data generation. Privacy mechanisms that provide unbiased noisy answers to linear queries (such as marginals) are known as matrix mechanisms. We propose ResidualPlanner, a matrix mechanism for marginals with Gaussian noise that is both optimal and scalable. ResidualPlanner can optimize for many loss functions that can be written as a convex function of marginal variances (prior work was restricted to just one predefined objective function). ResidualPlanner can optimize the accuracy of marginals in large scale settings in seconds, even when the previous state of the art (HDMM) runs out of memory. It even runs on datasets with 100 attributes in a couple of minutes. Furthermore ResidualPlanner can efficiently compute variance/covariance values for each marginal (prior methods quickly run out of memory, even for relatively small datasets)",
    "checked": true,
    "id": "68aec831af77ba45886440a419ed77edda192e10",
    "semantic_title": "an optimal and scalable matrix mechanism for noisy marginals under convex loss functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qv6468llWS": {
    "title": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers",
    "volume": "spotlight",
    "abstract": "Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering. Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest. The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem. In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance. Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process. We validate PDE-Refiner on challenging benchmarks of complex fluid dynamics, demonstrating stable and accurate rollouts that consistently outperform state-of-the-art models, including neural, numerical, and hybrid neural-numerical architectures. We further demonstrate that PDE-Refiner greatly enhances data efficiency, since the denoising objective implicitly induces a novel form of spectral data augmentation. Finally, PDE-Refiner's connection to diffusion models enables an accurate and efficient assessment of the model's predictive uncertainty, allowing us to estimate when the surrogate becomes inaccurate",
    "checked": true,
    "id": "cee75e291d693e3ee4087f1aa74f0f7e223b3b6f",
    "semantic_title": "pde-refiner: achieving accurate long rollouts with neural pde solvers",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=UWd4ysACo4": {
    "title": "Expressive Sign Equivariant Networks for Spectral Geometric Learning",
    "volume": "spotlight",
    "abstract": "Recent work has shown the utility of developing machine learning models that respect the structure and symmetries of eigenvectors. These works promote sign invariance, since for any eigenvector v the negation -v is also an eigenvector. However, we show that sign invariance is theoretically limited for tasks such as building orthogonally equivariant models and learning node positional encodings for link prediction in graphs. In this work, we demonstrate the benefits of sign equivariance for these tasks. To obtain these benefits, we develop novel sign equivariant neural network architectures. Our models are based on a new analytic characterization of sign equivariant polynomials and thus inherit provable expressiveness properties. Controlled synthetic experiments show that our networks can achieve the theoretically predicted benefits of sign equivariant models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3X2EbBLNsk": {
    "title": "Birth of a Transformer: A Memory Viewpoint",
    "volume": "spotlight",
    "abstract": "Large language models based on transformers have achieved great empirical successes. However, as they are deployed more widely, there is a growing need to better understand their internal mechanisms in order to make them more reliable. These models appear to store vast amounts of knowledge from their training data, and to adapt quickly to new information provided in their context or prompt. We study how transformers balance these two types of knowledge by considering a synthetic setup where tokens are generated from either global or context-specific bigram distributions. By a careful empirical analysis of the training process on a simplified two-layer transformer, we illustrate the fast learning of global bigrams and the slower development of an \"induction head\" mechanism for the in-context bigrams. We highlight the role of weight matrices as associative memories, provide theoretical insights on how gradients enable their learning during training, and study the role of data-distributional properties",
    "checked": true,
    "id": "11ae58636a5daf0ea1297f1c4ee94042fcebefa8",
    "semantic_title": "birth of a transformer: a memory viewpoint",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=AygwZzdCM0": {
    "title": "Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model",
    "volume": "spotlight",
    "abstract": "Counterfactual inference aims to answer retrospective \"what if\" questions and thus belongs to the most fine-grained type of inference in Pearl's causality ladder. Existing methods for counterfactual inference with continuous outcomes aim at point identification and thus make strong and unnatural assumptions about the underlying structural causal model. In this paper, we relax these assumptions and aim at partial counterfactual identification of continuous outcomes, i.e., when the counterfactual query resides in an ignorance interval with informative bounds. We prove that, in general, the ignorance interval of the counterfactual queries has non-informative bounds, already when functions of structural causal models are continuously differentiable. As a remedy, we propose a novel sensitivity model called Curvature Sensitivity Model. This allows us to obtain informative bounds by bounding the curvature of level sets of the functions. We further show that existing point counterfactual identification methods are special cases of our Curvature Sensitivity Model when the bound of the curvature is set to zero. We then propose an implementation of our Curvature Sensitivity Model in the form of a novel deep generative model, which we call Augmented Pseudo-Invertible Decoder. Our implementation employs (i) residual normalizing flows with (ii) variational augmentations. We empirically demonstrate the effectiveness of our Augmented Pseudo-Invertible Decoder. To the best of our knowledge, ours is the first partial identification model for Markovian structural causal models with continuous outcomes",
    "checked": true,
    "id": "6cc1f2f6a02ad5cd6822e99ed80bf469ba0fefef",
    "semantic_title": "partial counterfactual identification of continuous outcomes with a curvature sensitivity model",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hCdqDkA25J": {
    "title": "Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization",
    "volume": "spotlight",
    "abstract": "Algorithmic reproducibility measures the deviation in outputs of machine learning algorithms upon minor changes in the training process. Previous work suggests that first-order methods would need to trade-off convergence rate (gradient complexity) for better reproducibility. In this work, we challenge this perception and demonstrate that both optimal reproducibility and near-optimal convergence guarantees can be achieved for smooth convex minimization and smooth convex-concave minimax problems under various error-prone oracle settings. Particularly, given the inexact initialization oracle, our regularization-based algorithms achieve the best of both worlds -- optimal reproducibility and near-optimal gradient complexity -- for minimization and minimax optimization. With the inexact gradient oracle, the near-optimal guarantees also hold for minimax optimization. Additionally, with the stochastic gradient oracle, we show that stochastic gradient descent ascent is optimal in terms of both reproducibility and gradient complexity. We believe our results contribute to an enhanced understanding of the reproducibility-convergence trade-off in the context of convex optimization",
    "checked": true,
    "id": "5d141a9f0d3b1bb01c08ec3ef0aa0963dd473a8a",
    "semantic_title": "optimal guarantees for algorithmic reproducibility and gradient complexity in convex optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xtADRDRsM2": {
    "title": "Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach",
    "volume": "spotlight",
    "abstract": "Graph neural networks (GNNs) are vulnerable to adversarial perturbations, including those that affect both node features and graph topology. This paper investigates GNNs derived from diverse neural flows, concentrating on their connection to various stability notions such as BIBO stability, Lyapunov stability, structural stability, and conservative stability. We argue that Lyapunov stability, despite its common use, does not necessarily ensure adversarial robustness. Inspired by physics principles, we advocate for the use of conservative Hamiltonian neural flows to construct GNNs that are robust to adversarial attacks. The adversarial robustness of different neural flow GNNs is empirically compared on several benchmark datasets under a variety of adversarial attacks. Extensive numerical experiments demonstrate that GNNs leveraging conservative Hamiltonian flows with Lyapunov stability substantially improve robustness against adversarial perturbations. The implementation code of experiments is available at \\url{https://github.com/zknus/NeurIPS-2023-HANG-Robustness}",
    "checked": true,
    "id": "72ce1f2b6c2f66f548607faf53ffccf1f5a2acd5",
    "semantic_title": "adversarial robustness in graph neural networks: a hamiltonian approach",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=vO04AzsB49": {
    "title": "Imitation Learning from Imperfection: Theoretical Justifications and Algorithms",
    "volume": "spotlight",
    "abstract": "Imitation learning (IL) algorithms excel in acquiring high-quality policies from expert data for sequential decision-making tasks. But, their effectiveness is hampered when faced with limited expert data. To tackle this challenge, a novel framework called (offline) IL with supplementary data has emerged, which enhances learning by incorporating an additional yet imperfect dataset obtained inexpensively from sub-optimal policies. Nonetheless, learning becomes challenging due to the potential inclusion of out-of-expert-distribution samples. In this work, we pioneer the mathematical formalization of this framework, uncovering its limitations. Our theoretical analysis reveals that a naive approach—applying the behavioral cloning (BC) algorithm concept to the combined set of expert and supplementary data—may fall short of vanilla BC, which solely relies on expert data. This deficiency arises due to the distribution shift between the two data sources. To address this issue, we propose a new importance-sampling-based technique for selecting data within the expert distribution. We prove that the proposed method theoretically eliminates the gap of the naive approach, highlighting its efficacy when handling imperfect data. Empirical studies demonstrate that our method outperforms previous state-of-the-art methods in tasks including robotics locomotion control, Atari video games, and image classification. Overall, our work underscores the potential of improving IL by leveraging diverse data sources through effective data selection",
    "checked": false,
    "id": "fab87cc094c0aedf2a283371de8339f466fdf3f8",
    "semantic_title": "learning to weight imperfect demonstrations",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=5gz7npbQ6Z": {
    "title": "A Cross-Moment Approach for Causal Effect Estimation",
    "volume": "spotlight",
    "abstract": "We consider the problem of estimating the causal effect of a treatment on an outcome in linear structural causal models (SCM) with latent confounders when we have access to a single proxy variable. Several methods (such as difference-in-difference (DiD) estimator or negative outcome control) have been proposed in this setting in the literature. However, these approaches require either restrictive assumptions on the data generating model or having access to at least two proxy variables. We propose a method to estimate the causal effect using cross moments between the treatment, the outcome, and the proxy variable. In particular, we show that the causal effect can be identified with simple arithmetic operations on the cross moments if the latent confounder in linear SCM is non-Gaussian. In this setting, DiD estimator provides an unbiased estimate only in the special case where the latent confounder has exactly the same direct causal effects on the outcomes in the pre-treatment and post-treatment phases. This translates to the common trend assumption in DiD, which we effectively relax. Additionally, we provide an impossibility result that shows the causal effect cannot be identified if the observational distribution over the treatment, the outcome, and the proxy is jointly Gaussian. Our experiments on both synthetic and real-world datasets showcase the effectiveness of the proposed approach in estimating the causal effect",
    "checked": true,
    "id": "ac9727d5fe06472278404f9465c137ea63786eec",
    "semantic_title": "a cross-moment approach for causal effect estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v9yC7sSXf3": {
    "title": "Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained Features Model",
    "volume": "spotlight",
    "abstract": "Neural collapse (NC) refers to the surprising structure of the last layer of deep neural networks in the terminal phase of gradient descent training. Recently, an increasing amount of experimental evidence has pointed to the propagation of NC to earlier layers of neural networks. However, while the NC in the last layer is well studied theoretically, much less is known about its multi-layered counterpart - deep neural collapse (DNC). In particular, existing work focuses either on linear layers or only on the last two layers at the price of an extra assumption. Our work fills this gap by generalizing the established analytical framework for NC - the unconstrained features model - to multiple non-linear layers. Our key technical contribution is to show that, in a deep unconstrained features model, the unique global optimum for binary classification exhibits all the properties typical of DNC. This explains the existing experimental evidence of DNC. We also empirically show that (i) by optimizing deep unconstrained features models via gradient descent, the resulting solution agrees well with our theory, and (ii) trained networks recover the unconstrained features suitable for the occurrence of DNC, thus supporting the validity of this modeling principle",
    "checked": true,
    "id": "e88e7bf8f1755933244be53a16772cbced205fde",
    "semantic_title": "deep neural collapse is provably optimal for the deep unconstrained features model",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ca2QmdOlIh": {
    "title": "Bayesian Extensive-Rank Matrix Factorization with Rotational Invariant Priors",
    "volume": "spotlight",
    "abstract": "We consider a statistical model for matrix factorization in a regime where the rank of the two hidden matrix factors grows linearly with their dimension and their product is corrupted by additive noise. Despite various approaches, statistical and algorithmic limits of such problems have remained elusive. We study a Bayesian setting with the assumptions that (a) one of the matrix factors is symmetric, (b) both factors as well as the additive noise have rotational invariant priors, (c) the priors are known to the statistician. We derive analytical formulas for Rotation Invariant Estimators to reconstruct the two matrix factors, and conjecture that these are optimal in the large-dimension limit, in the sense that they minimize the average mean-square-error. We provide numerical checks which confirm the optimality conjecture when confronted to Oracle Estimators which are optimal by definition, but involve the ground-truth. Our derivation relies on a combination of tools, namely random matrix theory transforms, spherical integral formulas, and the replica method from statistical mechanics",
    "checked": true,
    "id": "143824ed281c2ec88950af149d2e8092c6b6d7f8",
    "semantic_title": "bayesian extensive-rank matrix factorization with rotational invariant priors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YsYKv95jy9": {
    "title": "Deep Fractional Fourier Transform",
    "volume": "spotlight",
    "abstract": "Existing deep learning-based computer vision methods usually operate in the spatial and frequency domains, which are two orthogonal \\textbf{individual} perspectives for image processing. In this paper, we introduce a new spatial-frequency analysis tool, Fractional Fourier Transform (FRFT), to provide comprehensive \\textbf{unified} spatial-frequency perspectives. The FRFT is a unified continuous spatial-frequency transform that simultaneously reflects an image's spatial and frequency representations, making it optimal for processing non-stationary image signals. We explore the properties of the FRFT for image processing and present a fast implementation of the 2D FRFT, which facilitates its widespread use. Based on these explorations, we introduce a simple yet effective operator, Multi-order FRactional Fourier Convolution (MFRFC), which exhibits the remarkable merits of processing images from more perspectives in the spatial-frequency plane. Our proposed MFRFC is a general and basic operator that can be easily integrated into various tasks for performance improvement. We experimentally evaluate the MFRFC on various computer vision tasks, including object detection, image classification, guided super-resolution, denoising, dehazing, deraining, and low-light enhancement. Our proposed MFRFC consistently outperforms baseline methods by significant margins across all tasks",
    "checked": false,
    "id": "433e5289d033a83aab6abda892e070982840cf11",
    "semantic_title": "fractional fourier transform meets transformer encoder",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=vTug54Uunq": {
    "title": "Faster Margin Maximization Rates for Generic Optimization Methods",
    "volume": "spotlight",
    "abstract": "First-order optimization methods tend to inherently favor certain solutions over others when minimizing a given training objective with multiple local optima. This phenomenon, known as \\emph{implicit bias}, plays a critical role in understanding the generalization capabilities of optimization algorithms. Recent research has revealed that gradient-descent-based methods exhibit an implicit bias for the $\\ell_2$-maximal margin classifier in the context of separable binary classification. In contrast, generic optimization methods, such as mirror descent and steepest descent, have been shown to converge to maximal margin classifiers defined by alternative geometries. However, while gradient-descent-based algorithms demonstrate fast implicit bias rates, the implicit bias rates of generic optimization methods have been relatively slow. To address this limitation, in this paper, we present a series of state-of-the-art implicit bias rates for mirror descent and steepest descent algorithms. Our primary technique involves transforming a generic optimization algorithm into an online learning dynamic that solves a regularized bilinear game, providing a unified framework for analyzing the implicit bias of various optimization methods. The accelerated rates are derived leveraging the regret bounds of online learning algorithms within this game framework",
    "checked": true,
    "id": "a8601108d2853c64bddafbe6f6562460093da243",
    "semantic_title": "faster margin maximization rates for generic optimization methods",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BKAFLUcpBS": {
    "title": "Outlier-Robust Gromov-Wasserstein for Graph Data",
    "volume": "spotlight",
    "abstract": "Gromov-Wasserstein (GW) distance is a powerful tool for comparing and aligning probability distributions supported on different metric spaces. Recently, GW has become the main modeling technique for aligning heterogeneous data for a wide range of graph learning tasks. However, the GW distance is known to be highly sensitive to outliers, which can result in large inaccuracies if the outliers are given the same weight as other samples in the objective function. To mitigate this issue, we introduce a new and robust version of the GW distance called RGW. RGW features optimistically perturbed marginal constraints within a Kullback-Leibler divergence-based ambiguity set. To make the benefits of RGW more accessible in practice, we develop a computationally efficient and theoretically provable procedure using Bregman proximal alternating linearized minimization algorithm. Through extensive experimentation, we validate our theoretical results and demonstrate the effectiveness of RGW on real-world graph learning tasks, such as subgraph matching and partial shape correspondence",
    "checked": false,
    "id": "85eb1ba3f4b557bdf8785fd70ec2b4f2f10b3689",
    "semantic_title": "outlier-robust gromov wasserstein for graph data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KFm2lZiI7n": {
    "title": "MeCo: Zero-Shot NAS with One Data and Single Forward Pass via Minimum Eigenvalue of Correlation",
    "volume": "spotlight",
    "abstract": "Neural Architecture Search (NAS) is a promising paradigm in automatic architecture engineering. Zero-shot NAS can evaluate the network without training via some specific metrics called zero-cost proxies. Though effective, the existing zero-cost proxies either invoke at least one backpropagation or depend highly on the data and labels. To alleviate the above issues, in this paper, we first reveal how the Pearson correlation matrix of the feature maps impacts the convergence rate and the generalization capacity of an over-parameterized neural network. Enlightened by the theoretical analysis, we propose a novel zero-cost proxy called $\\mathsf{MeCo}$, which requires only one random data for a single forward pass. We further propose an optimization approach $\\mathsf{MeCo_{opt}}$ to improve the performance of our method. We design comprehensive experiments and extensively evaluate $\\mathsf{MeCo}$ on multiple popular benchmarks. $\\mathsf{MeCo}$ achieves the highest correlation with the ground truth (e.g., 0.89 on NATS-Bench-TSS with CIFAR-10) among all the state-of-the-art proxies, which is also fully independent of the data and labels. Moreover, we integrate $\\mathsf{MeCo}$ with the existing generation method to comprise a complete NAS. The experimental results illustrate that $\\mathsf{MeCo}$-based NAS can select the architecture with the highest accuracy and a low search cost. For instance, the best network searched by $\\mathsf{MeCo}$-based NAS achieves 97.31% on CIFAR-10, which is 0.04% higher than the baselines under the same settings. Our code is available at https://github.com/HamsterMimi/MeCo",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IHR83ufYPy": {
    "title": "Leveraging sparse and shared feature activations for disentangled representation learning",
    "volume": "spotlight",
    "abstract": "Recovering the latent factors of variation of high dimensional data has so far focused on simple synthetic settings. Mostly building on unsupervised and weakly-supervised objectives, prior work missed out on the positive implications for representation learning on real world data. In this work, we propose to leverage knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation. Assuming each supervised task only depends on an unknown subset of the factors of variation, we disentangle the feature space of a supervised multi-task model, with features activating sparsely across different tasks and information being shared as appropriate. Importantly, we never directly observe the factors of variations but establish that access to multiple tasks is sufficient for identifiability under sufficiency and minimality assumptions. We validate our approach on six real world distribution shift benchmarks, and different data modalities (images, text), demonstrating how disentangled representations can be transferred to real settings",
    "checked": true,
    "id": "d32a0fdd974badf6bf5529e11c6776fe5ed88d00",
    "semantic_title": "leveraging sparse and shared feature activations for disentangled representation learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=tDAu3FPJn9": {
    "title": "A Robust and Opponent-Aware League Training Method for StarCraft II",
    "volume": "spotlight",
    "abstract": "It is extremely difficult to train a superhuman Artificial Intelligence (AI) for games of similar size to StarCraft II. AlphaStar is the first AI that beat human professionals in the full game of StarCraft II, using a league training framework that is inspired by a game-theoretic approach. In this paper, we improve AlphaStar's league training in two significant aspects. We train goal-conditioned exploiters, whose abilities of spotting weaknesses in the main agent and the entire league are greatly improved compared to the unconditioned exploiters in AlphaStar. In addition, we endow the agents in the league with the new ability of opponent modeling, which makes the agent more responsive to the opponent's real-time strategy. Based on these improvements, we train a better and superhuman AI with orders of magnitude less resources than AlphaStar (see Table 1 for a full comparison). Considering the iconic role of StarCraft II in game AI research, we believe our method and results on StarCraft II provide valuable design principles on how one would utilize the general league training framework for obtaining a least-exploitable strategy in various, large-scale, real-world games",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0Wp3VHX0Gm": {
    "title": "Score-based Generative Models with Lévy Processes",
    "volume": "spotlight",
    "abstract": "Investigating the optimal stochastic process beyond Gaussian for noise injection in a score-based generative model remains an open question. Brownian motion is a light-tailed process with continuous paths, which leads to a slow convergence rate for the Number of Function Evaluation (NFE). Recent studies have shown that diffusion models suffer from mode-collapse issues on imbalanced data. In order to overcome the limitations of Brownian motion, we introduce a novel score-based generative model referred to as Lévy-Itō Model (LIM). This model utilizes isotropic $\\alpha$-stable Lévy processes. We first derive an exact reverse-time stochastic differential equation driven by the Lévy process and develop the corresponding fractional denoising score matching. The proposed generative model takes advantage of the heavy-tailed properties of the Lévy process. Our experimental results show LIM allows for faster and more diverse sampling while maintaining high fidelity compared to existing diffusion models across various image datasets such as CIFAR10, CelebA, and imbalanced dataset CIFAR10LT. Comparing our results to those of DDPM with 3.21 Fréchet Inception Distance (FID) and 0.6437 Recall on the CelebA dataset, we achieve 1.58 FID and 0.7006 Recall using the same architecture. LIM shows the best performance in NFE 500 with $2\\times$ faster total wall-clock time than the baseline",
    "checked": true,
    "id": "1480824f96d2b4ffc97016f011e4c1f451819d54",
    "semantic_title": "score-based generative models with lévy processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kCCD8d2aEu": {
    "title": "Coherent Soft Imitation Learning",
    "volume": "spotlight",
    "abstract": "Imitation learning methods seek to learn from an expert either through behavioral cloning (BC) for the policy or inverse reinforcement learning (IRL) for the reward. Such methods enable agents to learn complex tasks from humans that are difficult to capture with hand-designed reward functions. Choosing between BC or IRL for imitation depends on the quality and state-action coverage of the demonstrations, as well as additional access to the Markov decision process. Hybrid strategies that combine BC and IRL are rare, as initial policy optimization against inaccurate rewards diminishes the benefit of pretraining the policy with BC. Our work derives an imitation method that captures the strengths of both BC and IRL. In the entropy-regularized (`soft') reinforcement learning setting, we show that the behavioral-cloned policy can be used as both a shaped reward and a critic hypothesis space by inverting the regularized policy update. This coherency facilitates fine-tuning cloned policies using the reward estimate and additional interactions with the environment. This approach conveniently achieves imitation learning through initial behavioral cloning and subsequent refinement via RL with online or offline data sources. The simplicity of the approach enables graceful scaling to high-dimensional and vision-based tasks, with stable learning and minimal hyperparameter tuning, in contrast to adversarial approaches. For the open-source implementation and simulation results, see https://joemwatson.github.io/csil/",
    "checked": true,
    "id": "5b5c03667055aae101ba6d57399457732a6fae99",
    "semantic_title": "coherent soft imitation learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nDIrJmKPd5": {
    "title": "Private Distribution Learning with Public Data: The View from Sample Compression",
    "volume": "spotlight",
    "abstract": "We study the problem of private distribution learning with access to public data. In this setup, which we refer to as *public-private learning*, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples. We show that the public-private learnability of a class $\\mathcal Q$ is connected to the existence of a sample compression scheme for $\\mathcal Q$, as well as to an intermediate notion we refer to as \\emph{list learning}. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability under taking mixtures and products of distributions. Finally, via the connection to list learning, we show that for Gaussians in $\\mathbb R^d$, at least $d$ public samples are necessary for private learnability, which is close to the known upper bound of $d+1$ public samples",
    "checked": true,
    "id": "f821b9a0557bfce8b5cab784e257ae003dee2f9e",
    "semantic_title": "private distribution learning with public data: the view from sample compression",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=3GpIeVYw8X": {
    "title": "The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning",
    "volume": "spotlight",
    "abstract": "We present HUME, a simple model-agnostic framework for inferring human labeling of a given dataset without any external supervision. The key insight behind our approach is that classes defined by many human labelings are linearly separable regardless of the representation space used to represent a dataset. HUME utilizes this insight to guide the search over all possible labelings of a dataset to discover an underlying human labeling. We show that the proposed optimization objective is strikingly well-correlated with the ground truth labeling of the dataset. In effect, we only train linear classifiers on top of pretrained representations that remain fixed during training, making our framework compatible with any large pretrained and self-supervised model. Despite its simplicity, HUME outperforms a supervised linear classifier on top of self-supervised representations on the STL-10 dataset by a large margin and achieves comparable performance on the CIFAR-10 dataset. Compared to the existing unsupervised baselines, HUME achieves state-of-the-art performance on four benchmark image classification datasets including the large-scale ImageNet-1000 dataset. Altogether, our work provides a fundamentally new view to tackle unsupervised learning by searching for consistent labelings between different representation spaces",
    "checked": true,
    "id": "e794b4c023020c4cb21d024d1115301812145f8d",
    "semantic_title": "the pursuit of human labeling: a new perspective on unsupervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HF6bnhfSqH": {
    "title": "On quantum backpropagation, information reuse, and cheating measurement collapse",
    "volume": "spotlight",
    "abstract": "The success of modern deep learning hinges on the ability to train neural networks at scale. Through clever reuse of intermediate information, backpropagation facilitates training through gradient computation at a total cost roughly proportional to running the function, rather than incurring an additional factor proportional to the number of parameters -- which can now be in the trillions. Naively, one expects that quantum measurement collapse entirely rules out the reuse of quantum information as in backpropagation. But recent developments in shadow tomography, which assumes access to multiple copies of a quantum state, have challenged that notion. Here, we investigate whether parameterized quantum models can train as efficiently as classical neural networks. We show that achieving backpropagation scaling is impossible without access to multiple copies of a state. With this added ability, we introduce an algorithm with foundations in shadow tomography that matches backpropagation scaling in quantum resources while reducing classical auxiliary computational costs to open problems in shadow tomography. These results highlight the nuance of reusing quantum information for practical purposes and clarify the unique difficulties in training large quantum models, which could alter the course of quantum machine learning",
    "checked": true,
    "id": "863bbbbb7d5c535dab03d6c552dc6a7e60960e26",
    "semantic_title": "on quantum backpropagation, information reuse, and cheating measurement collapse",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=00EKYYu3fD": {
    "title": "Complexity Matters: Rethinking the Latent Space for Generative Modeling",
    "volume": "spotlight",
    "abstract": "In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel \"distance\" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propose a two-stage training strategy called Decoupled Autoencoder (DAE), where the encoder is only updated in the first stage with an auxiliary decoder and then frozen in the second stage while the actual decoder is being trained. DAE can improve the latent distribution and as a result, improve the generative performance. Our theoretical analyses are corroborated by comprehensive experiments on various models such as VQGAN and Diffusion Transformer, where our modifications yield significant improvements in sample quality with decreased model complexity",
    "checked": true,
    "id": "655ce703ece0565139fccb1325f8ad30d8917c57",
    "semantic_title": "complexity matters: rethinking the latent space for generative modeling",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Lt3jqxsbVO": {
    "title": "Sharp Spectral Rates for Koopman Operator Learning",
    "volume": "spotlight",
    "abstract": "Non-linear dynamical systems can be handily described by the associated Koopman operator, whose action evolves every observable of the system forward in time. Learning the Koopman operator and its spectral decomposition from data is enabled by a number of algorithms. In this work we present for the first time non-asymptotic learning bounds for the Koopman eigenvalues and eigenfunctions. We focus on time-reversal-invariant stochastic dynamical systems, including the important example of Langevin dynamics. We analyze two popular estimators: Extended Dynamic Mode Decomposition (EDMD) and Reduced Rank Regression (RRR). Our results critically hinge on novel {minimax} estimation bounds for the operator norm error, that may be of independent interest. Our spectral learning bounds are driven by the simultaneous control of the operator norm error and a novel metric distortion functional of the estimated eigenfunctions. The bounds indicates that both EDMD and RRR have similar variance, but EDMD suffers from a larger bias which might be detrimental to its learning rate. Our results shed new light on the emergence of spurious eigenvalues, an issue which is well known empirically. Numerical experiments illustrate the implications of the bounds in practice",
    "checked": true,
    "id": "1bc9fd4f2f36fb1355d34c2ec8b15ed1be98b8ec",
    "semantic_title": "sharp spectral rates for koopman operator learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XfYpIaKDb6": {
    "title": "On the Minimax Regret for Online Learning with Feedback Graphs",
    "volume": "spotlight",
    "abstract": "In this work, we improve on the upper and lower bounds for the regret of online learning with strongly observable undirected feedback graphs. The best known upper bound for this problem is $\\mathcal{O}\\bigl(\\sqrt{\\alpha T\\ln K}\\bigr)$, where $K$ is the number of actions, $\\alpha$ is the independence number of the graph, and $T$ is the time horizon. The $\\sqrt{\\ln K}$ factor is known to be necessary when $\\alpha = 1$ (the experts case). On the other hand, when $\\alpha = K$ (the bandits case), the minimax rate is known to be $\\Theta\\bigl(\\sqrt{KT}\\bigr)$, and a lower bound $\\Omega\\bigl(\\sqrt{\\alpha T}\\bigr)$ is known to hold for any $\\alpha$. Our improved upper bound $\\mathcal{O}\\bigl(\\sqrt{\\alpha T(1+\\ln(K/\\alpha))}\\bigr)$ holds for any $\\alpha$ and matches the lower bounds for bandits and experts, while interpolating intermediate cases. To prove this result, we use FTRL with $q$-Tsallis entropy for a carefully chosen value of $q \\in [1/2, 1)$ that varies with $\\alpha$. The analysis of this algorithm requires a new bound on the variance term in the regret. We also show how to extend our techniques to time-varying graphs, without requiring prior knowledge of their independence numbers. Our upper bound is complemented by an improved $\\Omega\\bigl(\\sqrt{\\alpha T(\\ln K)/(\\ln\\alpha)}\\bigr)$ lower bound for all $\\alpha > 1$, whose analysis relies on a novel reduction to multitask learning. This shows that a logarithmic factor is necessary as soon as $\\alpha < K$",
    "checked": true,
    "id": "2ed6a56105a6e69d14d84aa5952c530c09dca11d",
    "semantic_title": "on the minimax regret for online learning with feedback graphs",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=BDno5qWEFh": {
    "title": "Multi-Object Representation Learning via Feature Connectivity and Object-Centric Regularization",
    "volume": "spotlight",
    "abstract": "Discovering object-centric representations from images has the potential to greatly improve the robustness, sample efficiency and interpretability of machine learning algorithms. Current works on multi-object images typically follow a generative approach that optimizes for input reconstruction and fail to scale to real-world datasets despite significant increases in model capacity. We address this limitation by proposing a novel method that leverages feature connectivity to cluster neighboring pixels likely to belong to the same object. We further design two object-centric regularization terms to refine object representations in the latent space, enabling our approach to scale to complex real-world images. Experimental results on simulated, real-world, complex texture and common object images demonstrate a substantial improvement in the quality of discovered objects compared to state-of-the-art methods, as well as the sample efficiency and generalizability of our approach. We also show that the discovered object-centric representations can accurately predict key object properties in downstream tasks, highlighting the potential of our method to advance the field of multi-object representation learning",
    "checked": false,
    "id": "99b9f43da35ef41b5d7cd6811fbf57c64ad4f86c",
    "semantic_title": "boosting weakly-supervised image segmentation via representation, transform, and compensator",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aRBa0lSxEB": {
    "title": "A Dynamical System View of Langevin-Based Non-Convex Sampling",
    "volume": "spotlight",
    "abstract": "Non-convex sampling is a key challenge in machine learning, central to non-convex optimization in deep learning as well as to approximate probabilistic inference. Despite its significance, theoretically there remain some important challenges: Existing guarantees suffer from the drawback of lacking guarantees for the last-iterates, and little is known beyond the elementary schemes of stochastic gradient Langevin dynamics. To address these issues, we develop a novel framework that lifts the above issues by harnessing several tools from the theory of dynamical systems. Our key result is that, for a large class of state-of-the-art sampling schemes, their last-iterate convergence in Wasserstein distances can be reduced to the study of their continuous-time counterparts, which is much better understood. Coupled with standard assumptions of MCMC sampling, our theory immediately yields the last-iterate Wasserstein convergence of many advanced sampling schemes such as mirror Langevin, proximal, randomized mid-point, and Runge-Kutta methods",
    "checked": true,
    "id": "641b67bbf2a5e76a61bf4a4b27ce5dd9c547ab61",
    "semantic_title": "a dynamical system view of langevin-based non-convex sampling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t7ozN4AXd0": {
    "title": "Rewiring Neurons in Non-Stationary Environments",
    "volume": "spotlight",
    "abstract": "The human brain rewires itself for neuroplasticity in the presence of new tasks. We are inspired to harness this key process in continual reinforcement learning, prioritizing adaptation to non-stationary environments. In distinction to existing rewiring approaches that rely on pruning or dynamic routing, which may limit network capacity and plasticity, this work presents a novel rewiring scheme by permuting hidden neurons. Specifically, the neuron permutation is parameterized to be end-to-end learnable and can rearrange all available synapses to explore a large span of weight space, thereby promoting adaptivity. In addition, we introduce two main designs to steer the rewiring process in continual reinforcement learning: first, a multi-mode rewiring strategy is proposed which diversifies the policy and encourages exploration when encountering new environments. Secondly, to ensure stability on history tasks, the network is devised to cache each learned wiring while subtly updating its weights, allowing for retrospective recovery of any previous state appropriate for the task. Meanwhile, an alignment mechanism is curated to achieve better plasticity-stability tradeoff by jointly optimizing cached wirings and weights. Our proposed method is comprehensively evaluated on 18 continual reinforcement learning scenarios ranging from locomotion to manipulation, demonstrating its advantages over state-of-the-art competitors in performance-efficiency tradeoffs. Code is available at https://github.com/feifeiobama/RewireNeuron",
    "checked": true,
    "id": "938975891e19b10b61de3aca3e23c3ac33be9356",
    "semantic_title": "rewiring neurons in non-stationary environments",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H2SuXHbFIn": {
    "title": "Tree-Based Diffusion Schrödinger Bridge with Applications to Wasserstein Barycenters",
    "volume": "spotlight",
    "abstract": "Multi-marginal Optimal Transport (mOT), a generalization of OT, aims at minimizing the integral of a cost function with respect to a distribution with some prescribed marginals. In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i.e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree. To address this problem, we develop Tree-based Diffusion Schr\\\"odinger Bridge (TreeDSB), an extension of the Diffusion Schr\\\"odinger Bridge (DSB) algorithm. TreeDSB corresponds to a dynamic and continuous state-space counterpart of the multimarginal Sinkhorn algorithm. A notable use case of our methodology is to compute Wasserstein barycenters which can be recast as the solution of a mOT problem on a star-shaped tree. We demonstrate that our methodology can be applied in high-dimensional settings such as image interpolation and Bayesian fusion",
    "checked": true,
    "id": "8dfcf6c33b32c561552fa5bb9f7c1047f020a7d2",
    "semantic_title": "tree-based diffusion schrödinger bridge with applications to wasserstein barycenters",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=LVHEcVgEGm": {
    "title": "Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels",
    "volume": "spotlight",
    "abstract": "In an effort to further advance semi-supervised generative and classification tasks, we propose a simple yet effective training strategy called *dual pseudo training* (DPT), built upon strong semi-supervised learners and diffusion models. DPT operates in three stages: training a classifier on partially labeled data to predict pseudo-labels; training a conditional generative model using these pseudo-labels to generate pseudo images; and retraining the classifier with a mix of real and pseudo images. Empirically, DPT consistently achieves SOTA performance of semi-supervised generation and classification across various settings. In particular, with one or two labels per class, DPT achieves a Fréchet Inception Distance (FID) score of 3.08 or 2.52 on ImageNet $256\\times256$. Besides, DPT outperforms competitive semi-supervised baselines substantially on ImageNet classification tasks, *achieving top-1 accuracies of 59.0 (+2.8), 69.5 (+3.0), and 74.4 (+2.0)* with one, two, or five labels per class, respectively. Notably, our results demonstrate that diffusion can generate realistic images with only a few labels (e.g., $<0.1$%) and generative augmentation remains viable for semi-supervised classification. Our code is available at *https://github.com/ML-GSAI/DPT*",
    "checked": true,
    "id": "f5324c908e840995f681ac677c40d5d6b1555622",
    "semantic_title": "diffusion models and semi-supervised learners benefit mutually with few labels",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=NBMIsOS6B7": {
    "title": "Alternation makes the adversary weaker in two-player games",
    "volume": "spotlight",
    "abstract": "Motivated by alternating game-play in two-player games, we study an altenating variant of the \\textit{Online Linear Optimization} (OLO). In alternating OLO, a \\textit{learner} at each round $t \\in [n]$ selects a vector $x^t$ and then an \\textit{adversary} selects a cost-vector $c^t \\in [-1,1]^n$. The learner then experiences cost $(c^t + c^{t-1})^\\top x^t$ instead of $(c^t)^\\top x^t$ as in standard OLO. We establish that under this small twist, the $\\Omega(\\sqrt{T})$ lower bound on the regret is no longer valid. More precisely, we present two online learning algorithms for alternating OLO that respectively admit $\\mathcal{O}((\\log n)^{4/3} T^{1/3})$ regret for the $n$-dimensional simplex and $\\mathcal{O}(\\rho \\log T)$ regret for the ball of radius $\\rho>0$. Our results imply that in alternating game-play, an agent can always guarantee $\\mathcal{\\tilde{O}}((\\log n)^{4/3} T^{1/3})$ regardless the strategies of the other agent while the regret bound improves to $\\mathcal{O}(\\log T)$ in case the agent admits only two actions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6iouUxI45W": {
    "title": "The Exact Sample Complexity Gain from Invariances for Kernel Regression",
    "volume": "spotlight",
    "abstract": "In practice, encoding invariances into models improves sample complexity. In this work, we study this phenomenon from a theoretical perspective. In particular, we provide minimax optimal rates for kernel ridge regression on compact manifolds, with a target function that is invariant to a group action on the manifold. Our results hold for any smooth compact Lie group action, even groups of positive dimension. For a finite group, the gain effectively multiplies the number of samples by the group size. For groups of positive dimension, the gain is observed by a reduction in the manifold's dimension, in addition to a factor proportional to the volume of the quotient space. Our proof takes the viewpoint of differential geometry, in contrast to the more common strategy of using invariant polynomials. This new geometric viewpoint on learning with invariances may be of independent interest",
    "checked": false,
    "id": "886bd870f1c28cc4d78ac0af1f58d9b4066f8a19",
    "semantic_title": "the exact sample complexity gain from invariances for kernel regression on manifolds",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=vIGNYQ4Alv": {
    "title": "Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth Convex Optimization",
    "volume": "spotlight",
    "abstract": "In this paper, we propose an accelerated quasi-Newton proximal extragradient method for solving unconstrained smooth convex optimization problems. With access only to the gradients of the objective, we prove that our method can achieve a convergence rate of $\\mathcal{O}\\bigl(\\min\\\\{\\frac{1}{k^2}, \\frac{\\sqrt{d\\log k}}{k^{2.5}}\\\\}\\bigr)$, where $d$ is the problem dimension and $k$ is the number of iterations. In particular, in the regime where $k = \\mathcal{O}(d)$, our method matches the _optimal rate_ of $\\mathcal{O}(\\frac{1}{k^2})$ by Nesterov's accelerated gradient (NAG). Moreover, in the the regime where $k = \\Omega(d \\log d)$, it outperforms NAG and converges at a _faster rate_ of $\\mathcal{O}\\bigl(\\frac{\\sqrt{d\\log k}}{k^{2.5}}\\bigr)$. To the best of our knowledge, this result is the first to demonstrate a provable gain for a quasi-Newton-type method over NAG in the convex setting. To achieve such results, we build our method on a recent variant of the Monteiro-Svaiter acceleration framework and adopt an online learning perspective to update the Hessian approximation matrices, in which we relate the convergence rate of our method to the dynamic regret of a specific online convex optimization problem in the space of matrices",
    "checked": true,
    "id": "2daaba077a441522b00b8431e0964c94b0d0636b",
    "semantic_title": "accelerated quasi-newton proximal extragradient: faster rate for smooth convex optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=SoLebIqHgZ": {
    "title": "ARTree: A Deep Autoregressive Model for Phylogenetic Inference",
    "volume": "spotlight",
    "abstract": "Designing flexible probabilistic models over tree topologies is important for developing efficient phylogenetic inference methods. To do that, previous works often leverage the similarity of tree topologies via hand-engineered heuristic features which would require domain expertise and may suffer from limited approximation capability. In this paper, we propose a deep autoregressive model for phylogenetic inference based on graph neural networks (GNNs), called ARTree. By decomposing a tree topology into a sequence of leaf node addition operations and modeling the involved conditional distributions based on learnable topological features via GNNs, ARTree can provide a rich family of distributions over tree topologies that have simple sampling algorithms, without using heuristic features. We demonstrate the effectiveness and efficiency of our method on a benchmark of challenging real data tree topology density estimation and variational Bayesian phylogenetic inference problems",
    "checked": true,
    "id": "3b07d884a5e1c68b98e731c18c769e4b16deed1e",
    "semantic_title": "artree: a deep autoregressive model for phylogenetic inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d47iuwOt3j": {
    "title": "On the Gini-impurity Preservation For Privacy Random Forests",
    "volume": "spotlight",
    "abstract": "Random forests have been one successful ensemble algorithms in machine learning. Various techniques have been utilized to preserve the privacy of random forests from anonymization, differential privacy, homomorphic encryption, etc., whereas it rarely takes into account some crucial ingredients of learning algorithm. This work presents a new encryption to preserve data's Gini impurity, which plays a crucial role during the construction of random forests. Our basic idea is to modify the structure of binary search tree to store several examples in each node, and encrypt data features by incorporating label and order information. Theoretically, we prove that our scheme preserves the minimum Gini impurity in ciphertexts without decrypting, and present the security guarantee for encryption. For random forests, we encrypt data features based on our Gini-impurity-preserving scheme, and take the homomorphic encryption scheme CKKS to encrypt data labels due to their importance and privacy. We conduct extensive experiments to show the effectiveness, efficiency and security of our proposed method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=konBXvt2iS": {
    "title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear Behaviors of ReLU Networks",
    "volume": "spotlight",
    "abstract": "The training process of ReLU neural networks often exhibits complicated nonlinear phenomena. The nonlinearity of models and non-convexity of loss pose significant challenges for theoretical analysis. Therefore, most previous theoretical works on the optimization dynamics of neural networks focus either on local analysis (like the end of training) or approximate linear models (like Neural Tangent Kernel). In this work, we conduct a complete theoretical characterization of the training process of a two-layer ReLU network trained by Gradient Flow on a linearly separable data. In this specific setting, our analysis captures the whole optimization process starting from random initialization to final convergence. Despite the relatively simple model and data that we studied, we reveal four different phases from the whole training process showing a general simplifying-to-complicating learning trend. Specific nonlinear behaviors can also be precisely identified and captured theoretically, such as initial condensation, saddle-to-plateau dynamics, plateau escape, changes of activation patterns, learning with increasing complexity, etc",
    "checked": true,
    "id": "2647393824b4ccd6218c74c0937394c4d3f36142",
    "semantic_title": "understanding multi-phase optimization dynamics and rich nonlinear behaviors of relu networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=oaCDiKoJ2w": {
    "title": "Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts",
    "volume": "spotlight",
    "abstract": "Standard contextual bandit problem assumes that all the relevant contexts are observed before the algorithm chooses an arm. This modeling paradigm, while useful, often falls short when dealing with problems in which additional valuable contexts can be observed after arm selection. For example, content recommendation platforms like Youtube, Instagram, Tiktok receive much additional features about a user's reward after the user clicks a content (e.g., how long the user stayed, what is the user's watch speed, etc.). To improve online learning efficiency in these applications, we study a novel contextual bandit problem with post-serving contexts and design a new algorithm, poLinUCB, that achieves tight regret under standard assumptions. Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate noise in data. Such robustification is necessary for tackling our problem, though we believe it could also be of general interest. Extensive empirical tests on both synthetic and real-world datasets demonstrate the significant benefit of utilitzing post-serving contexts as well as the superior performance of our algorithm over the state-of-the-art approaches",
    "checked": true,
    "id": "2eb88875085cddc5de428bcd0d71eb31aa2faef4",
    "semantic_title": "follow-ups also matter: improving contextual bandits via post-serving contexts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4hturzLcKX": {
    "title": "AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback",
    "volume": "spotlight",
    "abstract": "Large language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well. Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these bottlenecks with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM based simulator for human feedback that is 45x cheaper than crowdworkers and displays high agreement with humans. Second, we identify an evaluation dataset representative of real-world instructions and propose an automatic evaluation procedure. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, among others) that learn from pairwise feedback. Finally, as an end-to-end validation of AlpacaFarm, we train and evaluate eleven models on 10k pairs of human feedback and show that rankings of models trained in AlpacaFarm match rankings of models trained on human data. As a demonstration of the research possible in AlpacaFarm, we find that methods that use a reward model can substantially improve over supervised fine-tuning and that our reference PPO implementation leads to a +10% win-rate improvement against Davinci003",
    "checked": true,
    "id": "cb6cc7d28d06a0d7c0d3f0d7ee551bbc86dbc3aa",
    "semantic_title": "alpacafarm: a simulation framework for methods that learn from human feedback",
    "citation_count": 81,
    "authors": []
  },
  "https://openreview.net/forum?id=WHedsAeatp": {
    "title": "Rank-N-Contrast: Learning Continuous Representations for Regression",
    "volume": "spotlight",
    "abstract": "Deep regression models typically learn in an end-to-end fashion without explicitly emphasizing a regression-aware representation. Consequently, the learned representations exhibit fragmentation and fail to capture the continuous nature of sample orders, inducing suboptimal results across a wide range of regression tasks. To fill the gap, we propose Rank-N-Contrast (RNC), a framework that learns continuous representations for regression by contrasting samples against each other based on their rankings in the target space. We demonstrate, theoretically and empirically, that RNC guarantees the desired order of learned representations in accordance with the target orders, enjoying not only better performance but also significantly improved robustness, efficiency, and generalization. Extensive experiments using five real-world regression datasets that span computer vision, human-computer interaction, and healthcare verify that RNC achieves state-of-the-art performance, highlighting its intriguing properties including better data efficiency, robustness to spurious targets and data corruptions, and generalization to distribution shifts",
    "checked": true,
    "id": "94785337539d5a7bc4a8b74c2b651e51482fce92",
    "semantic_title": "rank-n-contrast: learning continuous representations for regression",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=EjiA3uWpnc": {
    "title": "Equivariant Neural Operator Learning with Graphon Convolution",
    "volume": "spotlight",
    "abstract": "We propose a general architecture that combines the coefficient learning scheme with a residual operator layer for learning mappings between continuous functions in the 3D Euclidean space. Our proposed model is guaranteed to achieve SE(3)-equivariance by design. From the graph spectrum view, our method can be interpreted as convolution on graphons (dense graphs with infinitely many nodes), which we term InfGCN. By leveraging both the continuous graphon structure and the discrete graph structure of the input data, our model can effectively capture the geometric information while preserving equivariance. Through extensive experiments on large-scale electron density datasets, we observed that our model significantly outperformed the current state-of-the-art architectures. Multiple ablation studies were also carried out to demonstrate the effectiveness of the proposed architecture",
    "checked": true,
    "id": "61401df9e48eecd698dfb2cea3af7b57fcef0ae9",
    "semantic_title": "equivariant neural operator learning with graphon convolution",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RUCFAKNDb2": {
    "title": "Promises and Pitfalls of Threshold-based Auto-labeling",
    "volume": "spotlight",
    "abstract": "Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially prohibitive validation data usage. Together, these insights describe the promise and pitfalls of using such systems. We validate our theoretical guarantees with extensive experiments on synthetic and real datasets",
    "checked": false,
    "id": "077ecce04b32d99b966512ad11025956c7546795",
    "semantic_title": "good data from bad models : foundations of threshold-based auto-labeling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6BZS2EAkns": {
    "title": "In-Context Learning Unlocked for Diffusion Models",
    "volume": "spotlight",
    "abstract": "We present Prompt Diffusion, a framework for enabling in-context learning in diffusion-based generative models. Given a pair of task-specific example images, such as depth from/to image and scribble from/to image, and a text guidance, our model automatically understands the underlying task and performs the same task on a new query image following the text guidance. To achieve this, we propose a vision-language prompt that can model a wide range of vision-language tasks and a diffusion model that takes it as input. The diffusion model is trained jointly on six different tasks using these prompts. The resulting Prompt Diffusion model becomes the first diffusion-based vision-language foundation model capable of in-context learning. It demonstrates high-quality in-context generation for the trained tasks and effectively generalizes to new, unseen vision tasks using their respective prompts. Our model also shows compelling text-guided image editing results. Our framework aims to facilitate research into in-context learning for computer vision. We share our code and pre-trained models at https://github.com/Zhendong-Wang/Prompt-Diffusion",
    "checked": true,
    "id": "57be0448d168e8d6d0b6e0d1a4405fb5fbaa1b56",
    "semantic_title": "in-context learning unlocked for diffusion models",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=D9CMRR5Lof": {
    "title": "MGDD: A Meta Generator for Fast Dataset Distillation",
    "volume": "spotlight",
    "abstract": "Existing dataset distillation (DD) techniques typically rely on iterative strategies to synthesize condensed datasets, where datasets before and after distillation are forward and backward through neural networks a massive number of times. Despite the promising results achieved, the time efficiency of prior approaches is still far from satisfactory. Moreover, when different sizes of synthetic datasets are required, they have to repeat the iterative training procedures, which is highly cumbersome and lacks flexibility. In this paper, different from the time-consuming forward-backward passes, we introduce a generative fashion for dataset distillation with significantly improved efficiency. Specifically, synthetic samples are produced by a generator network conditioned on the initialization of DD, while synthetic labels are obtained by solving a least-squares problem in a feature space. Our theoretical analysis reveals that the errors of synthetic datasets solved in the original space and then processed by any conditional generators are upper-bounded. To find a satisfactory generator efficiently, we propose a meta-learning algorithm, where a meta generator is trained on a large dataset so that only a few steps are required to adapt to a target dataset. The meta generator is termed as MGDD in our approach. Once adapted, it can handle arbitrary sizes of synthetic datasets, even for those unseen during adaptation. Experiments demonstrate that the generator adapted with only a limited number of steps performs on par with those state-of-the-art DD methods and yields $22\\times$ acceleration",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xOJUmwwlJc": {
    "title": "Proximity-Informed Calibration for Deep Neural Networks",
    "volume": "spotlight",
    "abstract": "Confidence calibration is central to providing accurate and interpretable uncertainty estimates, especially under safety-critical scenarios. However, we find that existing calibration algorithms often overlook the issue of proximity bias, a phenomenon where models tend to be more overconfident in low proximity data (i.e., data lying in the sparse region of the data distribution) compared to high proximity samples, and thus suffer from inconsistent miscalibration across different proximity samples. We examine the problem over $504$ pretrained ImageNet models and observe that: 1) Proximity bias exists across a wide variety of model architectures and sizes; 2) Transformer-based models are relatively more susceptible to proximity bias than CNN-based models; 3) Proximity bias persists even after performing popular calibration algorithms like temperature scaling; 4) Models tend to overfit more heavily on low proximity samples than on high proximity samples. Motivated by the empirical findings, we propose ProCal, a plug-and-play algorithm with a theoretical guarantee to adjust sample confidence based on proximity. To further quantify the effectiveness of calibration algorithms in mitigating proximity bias, we introduce proximity-informed expected calibration error (PIECE) with theoretical analysis. We show that ProCal is effective in addressing proximity bias and improving calibration on balanced, long-tail, and distribution-shift settings under four metrics over various model architectures. We believe our findings on proximity bias will guide the development of fairer and better-calibrated} models, contributing to the broader pursuit of trustworthy AI",
    "checked": true,
    "id": "19aa1002f704a8f08eb4a198ad71aad677869b28",
    "semantic_title": "proximity-informed calibration for deep neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=CnvZ7FIyAD": {
    "title": "Newton–Cotes Graph Neural Networks: On the Time Evolution of Dynamic Systems",
    "volume": "spotlight",
    "abstract": "Reasoning system dynamics is one of the most important analytical approaches for many scientific studies. With the initial state of a system as input, the recent graph neural networks (GNNs)-based methods are capable of predicting the future state distant in time with high accuracy. Although these methods have diverse designs in modeling the coordinates and interacting forces of the system, we show that they actually share a common paradigm that learns the integration of the velocity over the interval between the initial and terminal coordinates. However, their integrand is constant w.r.t. time. Inspired by this observation, we propose a new approach to predict the integration based on several velocity estimations with Newton–Cotes formulas and prove its effectiveness theoretically. Extensive experiments on several benchmarks empirically demonstrate consistent and significant improvement compared with the state-of-the-art methods",
    "checked": false,
    "id": "4ada6508596ccede68a5ac96b2c0c45cec39d979",
    "semantic_title": "newton-cotes graph neural networks: on the time evolution of dynamic systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aIUnoHuENG": {
    "title": "Feature Adaptation for Sparse Linear Regression",
    "volume": "spotlight",
    "abstract": "Sparse linear regression is a central problem in high-dimensional statistics. We study the correlated random design setting, where the covariates are drawn from a multivariate Gaussian $N(0,\\Sigma)$, and we seek an estimator with small excess risk. If the true signal is $t$-sparse, information-theoretically, it is possible to achieve strong recovery guarantees with only $O(t\\log n)$ samples. However, computationally efficient algorithms have sample complexity linear in (some variant of) the *condition number* of $\\Sigma$. Classical algorithms such as the Lasso can require significantly more samples than necessary even if there is only a single sparse approximate dependency among the covariates. We provide a polynomial-time algorithm that, given $\\Sigma$, automatically adapts the Lasso to tolerate a small number of approximate dependencies. In particular, we achieve near-optimal sample complexity for constant sparsity and if $\\Sigma$ has few ``outlier'' eigenvalues. Our algorithm fits into a broader framework of *feature adaptation* for sparse linear regression with ill-conditioned covariates. With this framework, we additionally provide the first polynomial-factor improvement over brute-force search for constant sparsity $t$ and arbitrary covariance $\\Sigma$",
    "checked": true,
    "id": "e469bf972efeb5c46f1ee0f9e6490a85d5315ad3",
    "semantic_title": "feature adaptation for sparse linear regression",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=wRJqZRxDEX": {
    "title": "Critical Initialization of Wide and Deep Neural Networks using Partial Jacobians: General Theory and Applications",
    "volume": "spotlight",
    "abstract": "Deep neural networks are notorious for defying theoretical treatment. However, when the number of parameters in each layer tends to infinity, the network function is a Gaussian process (GP) and quantitatively predictive description is possible. Gaussian approximation allows one to formulate criteria for selecting hyperparameters, such as variances of weights and biases, as well as the learning rate. These criteria rely on the notion of criticality defined for deep neural networks. In this work we describe a new practical way to diagnose criticality. We introduce *partial Jacobians* of a network, defined as derivatives of preactivations in layer $l$ with respect to preactivations in layer $l_0\\leq l$. We derive recurrence relations for the norms of partial Jacobians and utilize these relations to analyze criticality of deep fully connected neural networks with LayerNorm and/or residual connections. We derive and implement a simple and cheap numerical test that allows one to select optimal initialization for a broad class of deep neural networks; containing fully connected, convolutional and normalization layers. Using these tools we show quantitatively that proper stacking of the LayerNorm (applied to preactivations) and residual connections leads to an architecture that is critical for any initialization. Finally, we apply our methods to analyze ResNet and MLP-Mixer architectures; demonstrating the everywhere-critical regime",
    "checked": false,
    "id": "1135005b5a85ac471d5bf41396dc5fa48621402d",
    "semantic_title": "critical initialization of wide and deep neural networks through partial jacobians: general theory and applications",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=fShubymWrc": {
    "title": "Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks",
    "volume": "spotlight",
    "abstract": "One of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic features -- and show that in the latter setting three-layer networks obtain a sample complexity improvement over all existing guarantees for two-layer networks. Crucially, this sample complexity improvement relies on the ability of three-layer networks to efficiently learn *nonlinear* features. We then establish a concrete optimization-based depth separation by constructing a function which is efficiently learnable via gradient descent on a three-layer network, yet cannot be learned efficiently by a two-layer network. Our work makes progress towards understanding the provable benefit of three-layer neural networks over two-layer networks in the feature learning regime",
    "checked": true,
    "id": "3a41d05efb2835ef4b2995b708e4dd5f76a637de",
    "semantic_title": "provable guarantees for nonlinear feature learning in three-layer neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FujJO3dsNj": {
    "title": "Balancing memorization and generalization in RNNs for high performance brain-machine Interfaces",
    "volume": "spotlight",
    "abstract": "Brain-machine interfaces (BMIs) can restore motor function to people with paralysis but are currently limited by the accuracy of real-time decoding algorithms. Recurrent neural networks (RNNs) using modern training techniques have shown promise in accurately predicting movements from neural signals but have yet to be rigorously evaluated against other decoding algorithms in a closed-loop setting. Here we compared RNNs to other neural network architectures in real-time, continuous decoding of finger movements using intracortical signals from nonhuman primates. Across one and two finger online tasks, LSTMs (a type of RNN) outperformed convolutional and transformer-based neural networks, averaging 18% higher throughput than the convolution network. On simplified tasks with a reduced movement set, RNN decoders were allowed to memorize movement patterns and matched able-bodied control. Performance gradually dropped as the number of distinct movements increased but did not go below fully continuous decoder performance. Finally, in a two-finger task where one degree-of-freedom had poor input signals, we recovered functional control using RNNs trained to act both like a movement classifier and continuous decoder. Our results suggest that RNNs can enable functional real-time BMI control by learning and generating accurate movement patterns",
    "checked": true,
    "id": "5fcb56559dd55ec34583f08ab92c102e3d8e1637",
    "semantic_title": "balancing memorization and generalization in rnns for high performance brain-machine interfaces",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8Kch0ILfQH": {
    "title": "Bootstrapping Vision-Language Learning with Decoupled Language Pre-training",
    "volume": "spotlight",
    "abstract": "We present a novel methodology aimed at optimizing the application of frozen large language models (LLMs) for resource-intensive vision-language (VL) pre-training. The current paradigm uses visual features as prompts to guide language models, with a focus on determining the most relevant visual features for corresponding text. Our approach diverges by concentrating on the language component, specifically identifying the optimal prompts to align with visual features. We introduce the Prompt-Transformer (P-Former), a model that predicts these ideal prompts, which is trained exclusively on linguistic data, bypassing the need for image-text pairings. This strategy subtly bifurcates the end-to-end VL training process into an additional, separate stage. Our experiments reveal that our framework significantly enhances the performance of a robust image-to-text baseline (BLIP-2), and effectively narrows the performance gap between models trained with either 4M or 129M image-text pairs. Importantly, our framework is modality-agnostic and flexible in terms of architectural design, as validated by its successful application in a video learning task using varied base modules. The code will be made available at https://github.com/yiren-jian/BLIText",
    "checked": true,
    "id": "98f8793a18eaced0ce93f5202065496cc5a84943",
    "semantic_title": "bootstrapping vision-language learning with decoupled language pre-training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xrk9g5vcXR": {
    "title": "QuIP: 2-Bit Quantization of Large Language Models With Guarantees",
    "volume": "spotlight",
    "abstract": "This work studies post-training parameter quantization in large language models (LLMs). We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights being even in magnitude and the directions in which it is important to round them accurately being unaligned with the coordinate axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices. We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight. Our code can be found at https://github.com/jerry-chee/QuIP",
    "checked": true,
    "id": "56b828717f32251a5e0f0be9c0113077f23c8429",
    "semantic_title": "quip: 2-bit quantization of large language models with guarantees",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=bpzwUfX1UP": {
    "title": "Parallel Sampling of Diffusion Models",
    "volume": "spotlight",
    "abstract": "Diffusion models are powerful generative models but suffer from slow sampling, often taking 1000 sequential denoising steps for one sample. As a result, considerable efforts have been directed toward reducing the number of denoising steps, but these methods hurt sample quality. Instead of reducing the number of denoising steps (trading quality for speed), in this paper we explore an orthogonal approach: can we run the denoising steps in parallel (trading compute for speed)? In spite of the sequential nature of the denoising steps, we show that surprisingly it is possible to parallelize sampling via Picard iterations, by guessing the solution of future denoising steps and iteratively refining until convergence. With this insight, we present ParaDiGMS, a novel method to accelerate the sampling of pretrained diffusion models by denoising multiple steps in parallel. ParaDiGMS is the first diffusion sampling method that enables trading compute for speed and is even compatible with existing fast sampling techniques such as DDIM and DPMSolver. Using ParaDiGMS, we improve sampling speed by 2-4x across a range of robotics and image generation models, giving state-of-the-art sampling speeds of 0.2s on 100-step DiffusionPolicy and 14.6s on 1000-step StableDiffusion-v2 with no measurable degradation of task reward, FID score, or CLIP score",
    "checked": true,
    "id": "ba3e9e45f91257c9af6dfe74ed91a03c53086f07",
    "semantic_title": "parallel sampling of diffusion models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=XkcufOcgUc": {
    "title": "Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data",
    "volume": "spotlight",
    "abstract": "Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediate benefits for various graph learning tasks. However, existing graph condensation methods rely on the joint optimization of nodes and structures in the condensed graph, and overlook critical issues in effectiveness and generalization ability. In this paper, we advocate a new Structure-Free Graph Condensation paradigm, named SFGC, to distill a large-scale graph into a small-scale graph node set without explicit graph structures, i.e., graph-free data. Our idea is to implicitly encode topology structure information into the node attributes in the synthesized graph-free data, whose topology is reduced to an identity matrix. Specifically, SFGC contains two collaborative components: (1) a training trajectory meta-matching scheme for effectively synthesizing small-scale graph-free data; (2) a graph neural feature score metric for dynamically evaluating the quality of the condensed data. Through training trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors between the large-scale graph and the condensed small-scale graph-free data, ensuring comprehensive and compact transfer of informative knowledge to the graph-free data. Afterward, the underlying condensed graph-free data would be dynamically evaluated with the graph neural feature score, which is a closed-form metric for ensuring the excellent expressiveness of the condensed graph-free data. Extensive experiments verify the superiority of SFGC across different condensation ratios",
    "checked": true,
    "id": "7975b4a71236acb1e48714e8dd7a2a770bf3c0a3",
    "semantic_title": "structure-free graph condensation: from large-scale graphs to condensed graph-free data",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=e0pRF9tOtm": {
    "title": "Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks",
    "volume": "spotlight",
    "abstract": "We reconsider the challenge of non-convex optimization under differential privacy constraint. Building upon the previous variance-reduced algorithm SpiderBoost, we propose a novel framework that employs two types of gradient oracles: one that estimates the gradient at a single point and a more cost-effective option that calculates the gradient difference between two points. Our framework can ensure continuous accuracy of gradient estimations and subsequently enhances the rates of identifying second-order stationary points. Additionally, we consider a more challenging task by attempting to locate the global minima of a non-convex objective via the exponential mechanism without almost any assumptions. Our preliminary results suggest that the regularized exponential mechanism can effectively emulate previous empirical and population risk bounds, negating the need for smoothness assumptions for algorithms with polynomial running time. Furthermore, with running time factors excluded, the exponential mechanism demonstrates promising population risk bound performance, and we provide a nearly matching lower bound",
    "checked": true,
    "id": "cf60ed12f3409bcf2e55725ab3844e7b3d12feeb",
    "semantic_title": "private (stochastic) non-convex optimization revisited: second-order stationary points and excess risks",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=rwrblCYb2A": {
    "title": "Reconstructing the Mind's Eye: fMRI-to-Image with Contrastive Learning and Diffusion Priors",
    "volume": "spotlight",
    "abstract": "We present MindEye, a novel fMRI-to-image approach to retrieve and reconstruct viewed images from brain activity. Our model comprises two parallel submodules that are specialized for retrieval (using contrastive learning) and reconstruction (using a diffusion prior). MindEye can map fMRI brain activity to any high dimensional multimodal latent space, like CLIP image space, enabling image reconstruction using generative models that accept embeddings from this latent space. We comprehensively compare our approach with other existing methods, using both qualitative side-by-side comparisons and quantitative evaluations, and show that MindEye achieves state-of-the-art performance in both reconstruction and retrieval tasks. In particular, MindEye can retrieve the exact original image even among highly similar candidates indicating that its brain embeddings retain fine-grained image-specific information. This allows us to accurately retrieve images even from large-scale databases like LAION-5B. We demonstrate through ablations that MindEye's performance improvements over previous methods result from specialized submodules for retrieval and reconstruction, improved training techniques, and training models with orders of magnitude more parameters. Furthermore, we show that MindEye can better preserve low-level image features in the reconstructions by using img2img, with outputs from a separate autoencoder. All code is available on GitHub",
    "checked": true,
    "id": "5efcfc6476c5ddbd69fa1ec3ca598604ae376c1c",
    "semantic_title": "reconstructing the mind's eye: fmri-to-image with contrastive learning and diffusion priors",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=shePL2nbwl": {
    "title": "Survival Instinct in Offline Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "We present a novel observation about the behavior of offline reinforcement learning (RL) algorithms: on many benchmark datasets, offline RL can produce well-performing and safe policies even when trained with \"wrong\" reward labels, such as those that are zero everywhere or are negatives of the true rewards. This phenomenon cannot be easily explained by offline RL's return maximization objective. Moreover, it gives offline RL a degree of robustness that is uncharacteristic of its online RL counterparts, which are known to be sensitive to reward design. We demonstrate that this surprising robustness property is attributable to an interplay between the notion of *pessimism* in offline RL algorithms and certain implicit biases in common data collection practices. As we prove in this work, pessimism endows the agent with a *survival instinct*, i.e., an incentive to stay within the data support in the long term, while the limited and biased data coverage further constrains the set of survival policies. Formally, given a reward class -- which may not even contain the true reward -- we identify conditions on the training data distribution that enable offline RL to learn a near-optimal and safe policy from any reward within the class. We argue that the survival instinct should be taken into account when interpreting results from existing offline RL benchmarks and when creating future ones. Our empirical and theoretical results suggest a new paradigm for offline RL, whereby an agent is \"nudged\" to learn a desirable behavior with imperfect reward but purposely biased data coverage. Please visit our website [https://survival-instinct.github.io](https://survival-instinct.github.io) for accompanied code and videos",
    "checked": true,
    "id": "f5f5640b4f2b267c57c7c07254a9b90e62e97699",
    "semantic_title": "survival instinct in offline reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=67o9UQgTD0": {
    "title": "Counterfactual Memorization in Neural Language Models",
    "volume": "spotlight",
    "abstract": "Modern neural language models that are widely used in various NLP tasks risk memorizing sensitive information from their training data. Understanding this memorization is important in real world applications and also from a learning-theoretical perspective. An open question in previous studies of language model memorization is how to filter out ``common'' memorization. In fact, most memorization criteria strongly correlate with the number of occurrences in the training set, capturing memorized familiar phrases, public knowledge, templated texts, or other repeated data. We formulate a notion of counterfactual memorization which characterizes how a model's predictions change if a particular document is omitted during training. We identify and study counterfactually-memorized training examples in standard text datasets. We estimate the influence of each memorized training example on the validation set and on generated texts, showing how this can provide direct evidence of the source of memorization at test time",
    "checked": true,
    "id": "39c77e29a232a9fb62b3a3c89c50f487d73e27ce",
    "semantic_title": "counterfactual memorization in neural language models",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=1CpVHL10fh": {
    "title": "Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations",
    "volume": "spotlight",
    "abstract": "Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests",
    "checked": true,
    "id": "f734d43db6474d839f559d42970a7afbbe3453fc",
    "semantic_title": "should i stop or should i go: early stopping with heterogeneous populations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zCFfv49MjE": {
    "title": "Quasi-Monte Carlo Graph Random Features",
    "volume": "spotlight",
    "abstract": "We present a novel mechanism to improve the accuracy of the recently-introduced class of graph random features (GRFs). Our method induces negative correlations between the lengths of the algorithm's random walks by imposing antithetic termination: a procedure to sample more diverse random walks which may be of independent interest. It has a trivial drop-in implementation. We derive strong theoretical guarantees on the properties of these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance estimators of the $2$-regularised Laplacian kernel under mild conditions. Remarkably, our results hold for any graph topology. We demonstrate empirical accuracy improvements on a variety of tasks including a new practical application: time-efficient approximation of the graph diffusion process. To our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo scheme for kernels defined on combinatorial objects, inviting new research on correlations between graph random walks",
    "checked": true,
    "id": "257048f305436fc870ae08bb5fa871ff16799c1c",
    "semantic_title": "quasi-monte carlo graph random features",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=cwBeRBe9hq": {
    "title": "On the Learnability of Multilabel Ranking",
    "volume": "spotlight",
    "abstract": "Multilabel ranking is a central task in machine learning. However, the most fundamental question of learnability in a multilabel ranking setting with relevance-score feedback remains unanswered. In this work, we characterize the learnability of multilabel ranking problems in both batch and online settings for a large family of ranking losses. Along the way, we give two equivalence classes of ranking losses based on learnability that capture most losses used in practice",
    "checked": true,
    "id": "afeb4dc2bf54459e0001c253038456546d4c35db",
    "semantic_title": "on the learnability of multilabel ranking",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=GrElRvXnEj": {
    "title": "Score-based Generative Modeling through Stochastic Evolution Equations in Hilbert Spaces",
    "volume": "spotlight",
    "abstract": "Continuous-time score-based generative models consist of a pair of stochastic differential equations (SDEs)—a forward SDE that smoothly transitions data into a noise space and a reverse SDE that incrementally eliminates noise from a Gaussian prior distribution to generate data distribution samples—are intrinsically connected by the time-reversal theory on diffusion processes. In this paper, we investigate the use of stochastic evolution equations in Hilbert spaces, which expand the applicability of SDEs in two aspects: sample space and evolution operator, so they enable encompassing recent variations of diffusion models, such as generating functional data or replacing drift coefficients with image transformation. To this end, we derive a generalized time-reversal formula to build a bridge between probabilistic diffusion models and stochastic evolution equations and propose a score-based generative model called Hilbert Diffusion Model (HDM). Combining with Fourier neural operator, we verify the superiority of HDM for sampling functions from functional datasets with a power of kernel two-sample test of 4.2 on Quadratic, 0.2 on Melbourne, and 3.6 on Gridwatch, which outperforms existing diffusion models formulated in function spaces. Furthermore, the proposed method shows its strength in motion synthesis tasks by utilizing the Wiener process with values in Hilbert space. Finally, our empirical results on image datasets also validate a connection between HDM and diffusion models using heat dissipation, revealing the potential for exploring evolution operators and sample spaces",
    "checked": false,
    "id": "aeaacb08904397521fade138869a6c8582055e72",
    "semantic_title": "universal generative modeling in dual domains for dynamic mri",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ygjQCOyNfh": {
    "title": "Uncertainty Quantification over Graph with Conformalized Graph Neural Networks",
    "volume": "spotlight",
    "abstract": "Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Moreover, besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the prediction and produces more efficient prediction sets/intervals. Extensive experiments show that CF-GNN achieves any pre-defined target marginal coverage while significantly reducing the prediction set/interval size by up to 74% over the baselines. It also empirically achieves satisfactory conditional coverage over various raw and network features",
    "checked": true,
    "id": "569140ad11310f71c5fcc0ecaa6810d12bee3416",
    "semantic_title": "uncertainty quantification over graph with conformalized graph neural networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=jucDLW6G9l": {
    "title": "Deep Reinforcement Learning with Plasticity Injection",
    "volume": "spotlight",
    "abstract": "A growing body of evidence suggests that neural networks employed in deep reinforcement learning (RL) gradually lose their plasticity, the ability to learn from new data; however, the analysis and mitigation of this phenomenon is hampered by the complex relationship between plasticity, exploration, and performance in RL. This paper introduces plasticity injection, a minimalistic intervention that increases the network plasticity without changing the number of trainable parameters or biasing the predictions. The applications of this intervention are two-fold: first, as a diagnostic tool — if injection increases the performance, we may conclude that an agent's network was losing its plasticity. This tool allows us to identify a subset of Atari environments where the lack of plasticity causes performance plateaus, motivating future studies on understanding and combating plasticity loss. Second, plasticity injection can be used to improve the computational efficiency of RL training if the agent has to re-learn from scratch due to exhausted plasticity or by growing the agent's network dynamically without compromising performance. The results on Atari show that plasticity injection attains stronger performance compared to alternative methods while being computationally efficient",
    "checked": true,
    "id": "b9c9338e247570bbcea0d947b5fbe18a19116ceb",
    "semantic_title": "deep reinforcement learning with plasticity injection",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=zW1uVN6Mbv": {
    "title": "Unpaired Multi-Domain Causal Representation Learning",
    "volume": "spotlight",
    "abstract": "The goal of causal representation learning is to find a representation of data that consists of causally related latent variables. We consider a setup where one has access to data from multiple domains that potentially share a causal representation. Crucially, observations in different domains are assumed to be unpaired, that is, we only observe the marginal distribution in each domain but not their joint distribution. In this paper, we give sufficient conditions for identifiability of the joint distribution and the shared causal graph in a linear setup. Identifiability holds if we can uniquely recover the joint distribution and the shared causal representation from the marginal distributions in each domain. We transform our results into a practical method to recover the shared latent causal graph",
    "checked": true,
    "id": "bd9fd8c7a6cc8aa3e1f4333454858e49e731cf3c",
    "semantic_title": "unpaired multi-domain causal representation learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=pLwYhNNnoR": {
    "title": "PRODIGY: Enabling In-context Learning Over Graphs",
    "volume": "spotlight",
    "abstract": "In-context learning is the ability of a pretrained model to adapt to novel and diverse downstream tasks by conditioning on prompt examples, without optimizing any parameters. While large language models have demonstrated this ability, how in-context learning could be performed over graphs is unexplored. In this paper, we develop \\textbf{Pr}etraining \\textbf{O}ver \\textbf{D}iverse \\textbf{I}n-Context \\textbf{G}raph S\\textbf{y}stems (PRODIGY), the first pretraining framework that enables in-context learning over graphs. The key idea of our framework is to formulate in-context learning over graphs with a novel \\emph{prompt graph} representation, which connects prompt examples and queries. We then propose a graph neural network architecture over the prompt graph and a corresponding family of in-context pretraining objectives. With PRODIGY, the pretrained model can directly perform novel downstream classification tasks on unseen graphs via in-context learning. We provide empirical evidence of the effectiveness of our framework by showcasing its strong in-context learning performance on tasks involving citation networks and knowledge graphs. Our approach outperforms the in-context learning accuracy of contrastive pretraining baselines with hard-coded adaptation by 18\\% on average across all setups. Moreover, it also outperforms standard finetuning with limited data by 33\\% on average with in-context learning",
    "checked": true,
    "id": "0088c9f4d50706c7ab71efa13bcb4b42cf2058e2",
    "semantic_title": "prodigy: enabling in-context learning over graphs",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=EmYWJsyad4": {
    "title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "Reinforcement Learning (RL) environments can produce training data with spurious correlations between features due to the amount of training data or its limited feature coverage. This can lead to RL agents encoding these misleading correlations in their latent representation, preventing the agent from generalising if the correlation changes within the environment or when deployed in the real world. Disentangled representations can improve robustness, but existing disentanglement techniques that minimise mutual information between features require independent features, thus they cannot disentangle correlated features. We propose an auxiliary task for RL algorithms that learns a disentangled representation of high-dimensional observations with correlated features by minimising the conditional mutual information between features in the representation. We demonstrate experimentally, using continuous control tasks, that our approach improves generalisation under correlation shifts, as well as improving the training performance of RL algorithms in the presence of correlated features",
    "checked": true,
    "id": "9e9fa602005193d3c7b7924ef3c50987bd97a07e",
    "semantic_title": "conditional mutual information for disentangled representations in reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=5otj6QKUMI": {
    "title": "Compression with Bayesian Implicit Neural Representations",
    "volume": "spotlight",
    "abstract": "Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a progressive refinement process for the variational posterior that significantly enhances performance. Experiments show that our method achieves strong performance on image and audio compression while retaining simplicity",
    "checked": true,
    "id": "e772d88c3f20bf965872d108bd0bf262f26bf5f7",
    "semantic_title": "compression with bayesian implicit neural representations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ffOhY40Nrh": {
    "title": "Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes",
    "volume": "spotlight",
    "abstract": "Humans and animals have a rich and flexible understanding of the physical world, which enables them to infer the underlying dynamical trajectories of objects and events, plausible future states, and use that to plan and anticipate the consequences of actions. However, the neural mechanisms underlying these computations are unclear. We combine a goal-driven modeling approach with dense neurophysiological data and high-throughput human behavioral readouts that contain thousands of comparisons to directly impinge on this question. Specifically, we construct and evaluate several classes of sensory-cognitive networks to predict the future state of rich, ethologically-relevant environments, ranging from self-supervised end-to-end models with pixel-wise or object-slot objectives, to models that future predict in the latent space of purely static image-pretrained or dynamic video-pretrained foundation models. We find that ``scale is \\emph{not} all you need'', and that many state-of-the-art machine learning models fail to perform well on our neural and behavioral benchmarks for future prediction. In fact, only one class of models matches these data well overall. We find that neural responses are currently best predicted by models trained to predict the future state of their environment in the \\emph{latent} space of pretrained foundation models optimized for \\emph{dynamic} scenes in a self-supervised manner. These models also approach the neurons' ability to predict the environmental state variables that are visually hidden from view, despite not being explicitly trained to do so. Finally, we find that not all foundation model latents are equal. Notably, models that future predict in the latent space of video foundation models that are optimized to support a \\emph{diverse} range of egocentric sensorimotor tasks, reasonably match \\emph{both} human behavioral error patterns and neural dynamics across all environmental scenarios that we were able to test. Overall, these findings suggest that the neural mechanisms and behaviors of primate mental simulation have strong inductive biases associated with them, and are thus far most consistent with being optimized to future predict on \\emph{reusable} visual representations that are useful for Embodied AI more generally",
    "checked": true,
    "id": "3b6e936bbe038375782f0ff78e209595d805598f",
    "semantic_title": "neural foundations of mental simulation: future prediction of latent representations on dynamic scenes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=nYgs0qZJ97": {
    "title": "Regret Matching+: (In)Stability and Fast Convergence in Games",
    "volume": "spotlight",
    "abstract": "Regret Matching$^+$ (RM$^+$) and its variants are important algorithms for solving large-scale games. However, a theoretical understanding of their success in practice is still a mystery. Moreover, recent advances on fast convergence in games are limited to no-regret algorithms such as online mirror descent, which satisfy stability. In this paper, we first give counterexamples showing that RM+ and its predictive version can be unstable, which might cause other players to suffer large regret. We then provide two fixes: restarting and chopping off the positive orthant that RM$^+$ works in. We show that these fixes are sufficient to get $O(T^{1/4})$ individual regret and $O(1)$ social regret in normal-form games via RM$^+$ with predictions. We also apply our stabilizing techniques to clairvoyant updates in the uncoupled learning setting for RM$^+$ and prove desirable results akin to recent works for Clairvoyant online mirror descent. Our experiments show the advantages of our algorithms over vanilla RM$^+$-based algorithms in matrix and extensive-form games",
    "checked": true,
    "id": "f1ece703d023b3487a59ee7e40a4b1e7b52ab1bc",
    "semantic_title": "regret matching+: (in)stability and fast convergence in games",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=2CRaOpEKWh": {
    "title": "Characterizing the Optimal $0-1$ Loss for Multi-class Classification with a Test-time Attacker",
    "volume": "spotlight",
    "abstract": "Finding classifiers robust to adversarial examples is critical for their safe deployment. Determining the robustness of the best possible classifier under a given threat model for a fixed data distribution and comparing it to that achieved by state-of-the-art training methods is thus an important diagnostic tool. In this paper, we find achievable information-theoretic lower bounds on robust loss in the presence of a test-time attacker for *multi-class classifiers on any discrete dataset*. We provide a general framework for finding the optimal $0-1$ loss that revolves around the construction of a conflict hypergraph from the data and adversarial constraints. The prohibitive cost of this formulation in practice leads us to formulate other variants of the attacker-classifier game that more efficiently determine the range of the optimal loss. Our valuation shows, for the first time, an analysis of the gap to optimal robustness for classifiers in the multi-class setting on benchmark datasets",
    "checked": false,
    "id": "9205de58cb8c6e745f45715829498cad2eee090f",
    "semantic_title": "characterizing the optimal 0-1 loss for multi-class classification with a test-time attacker",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TQlpqmCeMe": {
    "title": "Neural Injective Functions for Multisets, Measures and Graphs via a Finite Witness Theorem",
    "volume": "spotlight",
    "abstract": "Injective multiset functions have a key role in the theoretical study of machine learning on multisets and graphs. Yet, there remains a gap between the provably injective multiset functions considered in theory, which typically rely on polynomial moments, and the multiset functions used in practice, which rely on $\\textit{neural moments}$ — whose injectivity on multisets has not been studied to date. In this paper, we bridge this gap by showing that moments of neural networks do define injective multiset functions, provided that an analytic non-polynomial activation is used. The number of moments required by our theory is optimal essentially up to a multiplicative factor of two. To prove this result, we state and prove a $\\textit{finite witness theorem}$, which is of independent interest. As a corollary to our main theorem, we derive new approximation results for functions on multisets and measures, and new separation results for graph neural networks. We also provide two negative results: (1) moments of piecewise-linear neural networks cannot be injective multiset functions; and (2) even when moment-based multiset functions are injective, they can never be bi-Lipschitz",
    "checked": true,
    "id": "5e7ec4dfc146410178695966c30ad23fb6866423",
    "semantic_title": "neural injective functions for multisets, measures and graphs via a finite witness theorem",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=n3XuYdvhNW": {
    "title": "Fast Optimal Transport through Sliced Generalized Wasserstein Geodesics",
    "volume": "spotlight",
    "abstract": "Wasserstein distance (WD) and the associated optimal transport plan have been proven useful in many applications where probability measures are at stake. In this paper, we propose a new proxy of the squared WD, coined $\\textnormal{min-SWGG}$, that is based on the transport map induced by an optimal one-dimensional projection of the two input distributions. We draw connections between $\\textnormal{min-SWGG}$, and Wasserstein generalized geodesics in which the pivot measure is supported on a line. We notably provide a new closed form for the exact Wasserstein distance in the particular case of one of the distributions supported on a line allowing us to derive a fast computational scheme that is amenable to gradient descent optimization. We show that $\\textnormal{min-SWGG}$, is an upper bound of WD and that it has a complexity similar to as Sliced-Wasserstein, with the additional feature of providing an associated transport plan. We also investigate some theoretical properties such as metricity, weak convergence, computational and topological properties. Empirical evidences support the benefits of $\\textnormal{min-SWGG}$, in various contexts, from gradient flows, shape matching and image colorization, among others",
    "checked": false,
    "id": "1df217771f2c52e9211bd6c95298196885812830",
    "semantic_title": "fast optimal transport through sliced wasserstein generalized geodesics",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=7vqlzODS28": {
    "title": "HyTrel: Hypergraph-enhanced Tabular Data Representation Learning",
    "volume": "spotlight",
    "abstract": "Language models pretrained on large collections of tabular data have demonstrated their effectiveness in several downstream tasks. However, many of these models do not take into account the row/column permutation invariances, hierarchical structure, etc. that exist in tabular data. To alleviate these limitations, we propose HyTrel, a tabular language model, that captures the permutation invariances and three more structural properties of tabular data by using hypergraphs--where the table cells make up the nodes and the cells occurring jointly together in each row, column, and the entire table are used to form three different types of hyperedges. We show that HyTrel is maximally invariant under certain conditions for tabular data, i.e., two tables obtain the same representations via HyTrel iff the two tables are identical up to permutation. Our empirical results demonstrate that HyTrel consistently outperforms other competitive baselines on four downstream tasks with minimal pretraining, illustrating the advantages of incorporating inductive biases associated with tabular data into the representations. Finally, our qualitative analyses showcase that HyTrel can assimilate the table structure to generate robust representations for the cells, rows, columns, and the entire table",
    "checked": true,
    "id": "a7e58dc03d029100fd437e229f7ee80e976fc842",
    "semantic_title": "hytrel: hypergraph-enhanced tabular data representation learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=BACQLWQW8u": {
    "title": "Subspace Identification for Multi-Source Domain Adaptation",
    "volume": "spotlight",
    "abstract": "Multi-source domain adaptation (MSDA) methods aim to transfer knowledge from multiple labeled source domains to an unlabeled target domain. Although current methods achieve target joint distribution identifiability by enforcing minimal changes across domains, they often necessitate stringent conditions, such as an adequate number of domains, monotonic transformation of latent variables, and invariant label distributions. These requirements are challenging to satisfy in real-world applications. To mitigate the need for these strict assumptions, we propose a subspace identification theory that guarantees the disentanglement of domain-invariant and domain-specific variables under less restrictive constraints regarding domain numbers and transformation properties and thereby facilitating domain adaptation by minimizing the impact of domain shifts on invariant variables. Based on this theory, we develop a Subspace Identification Guarantee (SIG) model that leverages variational inference. Furthermore, the SIG model incorporates class-aware conditional alignment to accommodate target shifts where label distributions change with the domain. Experimental results demonstrate that our SIG model outperforms existing MSDA techniques on various benchmark datasets, highlighting its effectiveness in real-world applications",
    "checked": true,
    "id": "7ab6c5a5f9d83d04a147ee152aff944a16eca6ce",
    "semantic_title": "subspace identification for multi-source domain adaptation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=UkPeUXML7s": {
    "title": "Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent",
    "volume": "spotlight",
    "abstract": "A recent line of empirical studies has demonstrated that SGD might exhibit a heavy-tailed behavior in practical settings, and the heaviness of the tails might correlate with the overall performance. In this paper, we investigate the emergence of such heavy tails. Previous works on this problem only considered, up to our knowledge, online (also called single-pass) SGD, in which the emergence of heavy tails in theoretical findings is contingent upon access to an infinite amount of data. Hence, the underlying mechanism generating the reported heavy-tailed behavior in practical settings, where the amount of training data is finite, is still not well-understood. Our contribution aims to fill this gap. In particular, we show that the stationary distribution of offline (also called multi-pass) SGD exhibits ‘approximate' power-law tails and the approximation error is controlled by how fast the empirical distribution of the training data converges to the true underlying data distribution in the Wasserstein metric. Our main takeaway is that, as the number of data points increases, offline SGD will behave increasingly ‘power-law-like'. To achieve this result, we first prove nonasymptotic Wasserstein convergence bounds for offline SGD to online SGD as the number of data points increases, which can be interesting on their own. Finally, we illustrate our theory on various experiments conducted on synthetic data and neural networks",
    "checked": true,
    "id": "3de7b17b3fca785cfcba234473c82e99d5408675",
    "semantic_title": "approximate heavy tails in offline (multi-pass) stochastic gradient descent",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tEKBU5XOTw": {
    "title": "Safety Verification of Decision-Tree Policies in Continuous Time",
    "volume": "spotlight",
    "abstract": "Decision trees have gained popularity as interpretable surrogate models for learning-based control policies. However, providing safety guarantees for systems controlled by decision trees is an open challenge. We show that the problem is undecidable even for systems with the simplest dynamics, and PSPACE-complete for finite-horizon properties. The latter can be verified for discrete-time systems via bounded model checking. However, for continuous-time systems, such an approach requires discretization, thereby weakening the guarantees for the original system. This paper presents the first algorithm to directly verify decision-tree controlled system in continuous time. The key aspect of our method is exploiting the decision-tree structure to propagate a set-based approximation through the decision nodes. We demonstrate the effectiveness of our approach by verifying safety of several decision trees distilled to imitate neural-network policies for nonlinear systems",
    "checked": false,
    "id": "4fcc703b3c63dddd91154f05f9fc473fb9cd6dd4",
    "semantic_title": "interpretable reinforcement learning for robotics and continuous control",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BsZNWXD3a1": {
    "title": "Optimizing Prompts for Text-to-Image Generation",
    "volume": "spotlight",
    "abstract": "Well-designed prompts can guide text-to-image models to generate amazing images. However, the performant prompts are often model-specific and misaligned with user input. Instead of laborious human engineering, we propose prompt adaptation, a general framework that automatically adapts original user input to model-preferred prompts. Specifically, we first perform supervised fine-tuning with a pretrained language model on a small collection of manually engineered prompts. Then we use reinforcement learning to explore better prompts. We define a reward function that encourages the policy to generate more aesthetically pleasing images while preserving the original user intentions. Experimental results on Stable Diffusion show that our method outperforms manual prompt engineering in terms of both automatic metrics and human preference ratings. Moreover, reinforcement learning further boosts performance, especially on out-of-domain prompts",
    "checked": true,
    "id": "4d81c33b295c092016ac236cfd32020a5bb70b97",
    "semantic_title": "optimizing prompts for text-to-image generation",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=ooXpTZYwXa": {
    "title": "Explore In-Context Learning for 3D Point Cloud Understanding",
    "volume": "spotlight",
    "abstract": "With the rise of large-scale models trained on broad data, in-context learning has become a new learning paradigm that has demonstrated significant potential in natural language processing and computer vision tasks. Meanwhile, in-context learning is still largely unexplored in the 3D point cloud domain. Although masked modeling has been successfully applied for in-context learning in 2D vision, directly extending it to 3D point clouds remains a formidable challenge. In the case of point clouds, the tokens themselves are the point cloud positions (coordinates) that are masked during inference. Moreover, position embedding in previous works may inadvertently introduce information leakage. To address these challenges, we introduce a novel framework, named Point-In-Context, designed especially for in-context learning in 3D point clouds, where both inputs and outputs are modeled as coordinates for each task. Additionally, we propose the Joint Sampling module, carefully designed to work in tandem with the general point sampling operator, effectively resolving the aforementioned technical issues. We conduct extensive experiments to validate the versatility and adaptability of our proposed methods in handling a wide range of tasks. Furthermore, with a more effective prompt selection strategy, our framework surpasses the results of individually trained models",
    "checked": true,
    "id": "50073733a6f8ddafd7ef9a8221cd940fa910b6e2",
    "semantic_title": "explore in-context learning for 3d point cloud understanding",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=qSS9izTOpo": {
    "title": "Alleviating the Semantic Gap for Generalized fMRI-to-Image Reconstruction",
    "volume": "spotlight",
    "abstract": "Although existing fMRI-to-image reconstruction methods could predict high-quality images, they do not explicitly consider the semantic gap between training and testing data, resulting in reconstruction with unstable and uncertain semantics. This paper addresses the problem of generalized fMRI-to-image reconstruction by explicitly alleviates the semantic gap. Specifically, we leverage the pre-trained CLIP model to map the training data to a compact feature representation, which essentially extends the sparse semantics of training data to dense ones, thus alleviating the semantic gap of the instances nearby known concepts (i.e., inside the training super-classes). Inspired by the robust low-level representation in fMRI data, which could help alleviate the semantic gap for instances that far from the known concepts (i.e., outside the training super-classes), we leverage structural information as a general cue to guide image reconstruction. Further, we quantify the semantic uncertainty based on probability density estimation and achieve Generalized fMRI-to-image reconstruction by adaptively integrating Expanded Semantics and Structural information (GESS) within a diffusion process. Experimental results demonstrate that the proposed GESS model outperforms state-of-the-art methods, and we propose a generalized scenario split strategy to evaluate the advantage of GESS in closing the semantic gap",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vz7SdRqWGM": {
    "title": "Adaptive whitening with fast gain modulation and slow synaptic plasticity",
    "volume": "spotlight",
    "abstract": "Neurons in early sensory areas rapidly adapt to changing sensory statistics, both by normalizing the variance of their individual responses and by reducing correlations between their responses. Together, these transformations may be viewed as an adaptive form of statistical whitening. Existing mechanistic models of adaptive whitening exclusively use either synaptic plasticity or gain modulation as the biological substrate for adaptation; however, on their own, each of these models has significant limitations. In this work, we unify these approaches in a normative multi-timescale mechanistic model that adaptively whitens its responses with complementary computational roles for synaptic plasticity and gain modulation. Gains are modified on a fast timescale to adapt to the current statistical context, whereas synapses are modified on a slow timescale to match structural properties of the input statistics that are invariant across contexts. Our model is derived from a novel multi-timescale whitening objective that factorizes the inverse whitening matrix into basis vectors, which correspond to synaptic weights, and a diagonal matrix, which corresponds to neuronal gains. We test our model on synthetic and natural datasets and find that the synapses learn optimal configurations over long timescales that enable adaptive whitening on short timescales using gain modulation",
    "checked": true,
    "id": "f7db07b05b0fa9977b1032ab672a04d1a8aec913",
    "semantic_title": "adaptive whitening with fast gain modulation and slow synaptic plasticity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BC1IJdsuYB": {
    "title": "Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models",
    "volume": "spotlight",
    "abstract": "The recent proliferation of large-scale text-to-image models has led to growing concerns that such models may be misused to generate harmful, misleading, and inappropriate content. Motivated by this issue, we derive a technique inspired by continual learning to selectively forget concepts in pretrained deep generative models. Our method, dubbed Selective Amnesia, enables controllable forgetting where a user can specify how a concept should be forgotten. Selective Amnesia can be applied to conditional variational likelihood models, which encompass a variety of popular deep generative frameworks, including variational autoencoders and large-scale text-to-image diffusion models. Experiments across different models demonstrate that our approach induces forgetting on a variety of concepts, from entire classes in standard datasets to celebrity and nudity prompts in text-to-image models",
    "checked": true,
    "id": "4e75ae56dc134abb076c3c6513d4d80751393df1",
    "semantic_title": "selective amnesia: a continual learning approach to forgetting in deep generative models",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=CxjmYRP9Ji": {
    "title": "Non-Asymptotic Analysis of a UCB-based Top Two Algorithm",
    "volume": "spotlight",
    "abstract": "A Top Two sampling rule for bandit identification is a method which selects the next arm to sample from among two candidate arms, a *leader* and a *challenger*. Due to their simplicity and good empirical performance, they have received increased attention in recent years. However, for fixed-confidence best arm identification, theoretical guarantees for Top Two methods have only been obtained in the asymptotic regime, when the error level vanishes. In this paper, we derive the first non-asymptotic upper bound on the expected sample complexity of a Top Two algorithm, which holds for any error level. Our analysis highlights sufficient properties for a regret minimization algorithm to be used as leader. These properties are satisfied by the UCB algorithm, and our proposed UCB-based Top Two algorithm simultaneously enjoys non-asymptotic guarantees and competitive empirical performance",
    "checked": true,
    "id": "acacc4068756c39175dbd26735f6f825e7ce6a4e",
    "semantic_title": "non-asymptotic analysis of a ucb-based top two algorithm",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=dEySGIcDnI": {
    "title": "Separable Physics-Informed Neural Networks",
    "volume": "spotlight",
    "abstract": "Physics-informed neural networks (PINNs) have recently emerged as promising data-driven PDE solvers showing encouraging results on various PDEs. However, there is a fundamental limitation of training PINNs to solve multi-dimensional PDEs and approximate very complex solution functions. The number of training points (collocation points) required on these challenging PDEs grows substantially, and it is severely limited due to the expensive computational costs and heavy memory overhead. To overcome this limit, we propose a network architecture and training algorithm for PINNs. The proposed method, separable PINN (SPINN), operates on a per-axis basis to decrease the number of network propagations in multi-dimensional PDEs instead of point-wise processing in conventional PINNs. We also propose using forward-mode automatic differentiation to reduce the computational cost of computing PDE residuals, enabling a large number of collocation points ($>10^7$) on a single commodity GPU. The experimental results show significantly reduced computational costs ($62\\times$ in wall-clock time, $1,394\\times$ in FLOPs given the same number of collocation points) in multi-dimensional PDEs while achieving better accuracy. Furthermore, we present that SPINN can solve a chaotic (2+1)-d Navier-Stokes equation much faster than the best-performing prior method (9 minutes vs. 10 hours in a single GPU), maintaining accuracy. Finally, we showcase that SPINN can accurately obtain the solution of a highly nonlinear and multi-dimensional PDE, a (3+1)-d Navier-Stokes equation. For visualized results and code, please see https://jwcho5576.github.io/spinn.github.io/",
    "checked": true,
    "id": "be3ecf03c30561b6be525398d85a1cd6aea12de8",
    "semantic_title": "separable physics-informed neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Ypbke6biDm": {
    "title": "Pareto Frontiers in Deep Feature Learning: Data, Compute, Width, and Luck",
    "volume": "spotlight",
    "abstract": "In modern deep learning, algorithmic choices (such as width, depth, and learning rate) are known to modulate nuanced resource tradeoffs. This work investigates how these complexities necessarily arise for feature learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a *multi-resource tradeoff frontier*: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding \"lottery ticket\" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests",
    "checked": false,
    "id": "3aba2e1d4532bab1ebc8caa616f21960e4afb2bc",
    "semantic_title": "pareto frontiers in neural feature learning: data, compute, width, and luck",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=VzmpXQAn6E": {
    "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
    "volume": "spotlight",
    "abstract": "Why do large language models sometimes output factual inaccuracies and exhibit erroneous reasoning? The brittleness of these models, particularly when executing long chains of reasoning, currently seems to be an inevitable price to pay for their advanced capabilities of coherently synthesizing knowledge, pragmatics, and abstract thought. Towards making sense of this fundamentally unsolved problem, this work identifies and analyzes the phenomenon of _attention glitches_, in which the Transformer architecture's inductive biases intermittently fail to capture robust reasoning. To isolate the issue, we introduce _flip-flop language modeling_ (FFLM), a parametric family of synthetic benchmarks designed to probe the extrapolative behavior of neural language models. This simple generative task requires a model to copy binary symbols over long-range dependencies, ignoring the tokens in between. We find that Transformer FFLMs suffer from a long tail of sporadic reasoning errors, some of which we can eliminate using various regularization techniques. Our preliminary mechanistic analyses show why the remaining errors may be very difficult to diagnose and resolve. We hypothesize that attention glitches account for (some of) the closed-domain hallucinations in natural LLMs",
    "checked": true,
    "id": "d40dbe668d5b68419e934dfa4c5851ffa1c24aa2",
    "semantic_title": "exposing attention glitches with flip-flop language modeling",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=P0Avuii9iI": {
    "title": "Differentially Private Image Classification by Learning Priors from Random Processes",
    "volume": "spotlight",
    "abstract": "In privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) performs worse than SGD due to per-sample gradient clipping and noise addition. A recent focus in private learning research is improving the performance of DP-SGD on private data by incorporating priors that are learned on real-world public data. In this work, we explore how we can improve the privacy-utility tradeoff of DP-SGD by learning priors from images generated by random processes and transferring these priors to private data. We propose DP-RandP, a three-phase approach. We attain new state-of-the-art accuracy when training from scratch on CIFAR10, CIFAR100, MedMNIST and ImageNet for a range of privacy budgets $\\\\varepsilon \\\\in [1, 8]$. In particular, we improve the previous best reported accuracy on CIFAR10 from $60.6 \\\\%$ to $72.3 \\\\%$ for $\\\\varepsilon=1$",
    "checked": true,
    "id": "b40b72ccfa4eb12ecf97ad9a65543dec02bceab2",
    "semantic_title": "differentially private image classification by learning priors from random processes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FXU4aR2uif": {
    "title": "Episodic Multi-Task Learning with Heterogeneous Neural Processes",
    "volume": "spotlight",
    "abstract": "This paper focuses on the data-insufficiency problem in multi-task learning within an episodic training setup. Specifically, we explore the potential of heterogeneous information across tasks and meta-knowledge among episodes to effectively tackle each task with limited data. Existing meta-learning methods often fail to take advantage of crucial heterogeneous information in a single episode, while multi-task learning models neglect reusing experience from earlier episodes. To address the problem of insufficient data, we develop Heterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within the framework of hierarchical Bayes, HNPs effectively capitalize on prior experiences as meta-knowledge and capture task-relatedness among heterogeneous tasks, mitigating data-insufficiency. Meanwhile, transformer-structured inference modules are designed to enable efficient inferences toward meta-knowledge and task-relatedness. In this way, HNPs can learn more powerful functional priors for adapting to novel heterogeneous tasks in each meta-test episode. Experimental results show the superior performance of the proposed HNPs over typical baselines, and ablation studies verify the effectiveness of the designed inference modules",
    "checked": true,
    "id": "b47a93fd5c49035819154f8ec81ddefb7b82edcd",
    "semantic_title": "episodic multi-task learning with heterogeneous neural processes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=AuXd54odxm": {
    "title": "Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Model",
    "volume": "spotlight",
    "abstract": "In the field of behavior-related brain computation, it is necessary to align raw neural signals against the drastic domain shift among them. A foundational framework within neuroscience research posits that trial-based neural population activities rely on low-dimensional latent dynamics, thus focusing on the latter greatly facilitates the alignment procedure. Despite this field's progress, existing methods ignore the intrinsic spatio-temporal structure during the alignment phase. Hence, their solutions usually lead to poor quality in latent dynamics structures and overall performance. To tackle this problem, we propose an alignment method ERDiff, which leverages the expressivity of the diffusion model to preserve the spatio-temporal structure of latent dynamics. Specifically, the latent dynamics structures of the source domain are first extracted by a diffusion model. Then, under the guidance of this diffusion model, such structures are well-recovered through a maximum likelihood alignment procedure in the target domain. We first demonstrate the effectiveness of our proposed method on a synthetic dataset. Then, when applied to neural recordings from the non-human primate motor cortex, under both cross-day and inter-subject settings, our method consistently manifests its capability of preserving the spatio-temporal structure of latent dynamics and outperforms existing approaches in alignment goodness-of-fit and neural decoding performance",
    "checked": true,
    "id": "13429c931cbd4307590a02d1be26a5df05760b9c",
    "semantic_title": "extraction and recovery of spatio-temporal structure in latent dynamics alignment with diffusion model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KmdlUP23qh": {
    "title": "Generalizing Importance Weighting to A Universal Solver for Distribution Shift Problems",
    "volume": "spotlight",
    "abstract": "Distribution shift (DS) may have two levels: the distribution itself changes, and the support (i.e., the set where the probability density is non-zero) also changes. When considering the support change between the training and test distributions, there can be four cases: (i) they exactly match; (ii) the training support is wider (and thus covers the test support); (iii) the test support is wider; (iv) they partially overlap. Existing methods are good at cases (i) and (ii), while cases (iii) and (iv) are more common nowadays but still under-explored. In this paper, we generalize importance weighting (IW), a golden solver for cases (i) and (ii), to a universal solver for all cases. Specifically, we first investigate why IW might fail in cases (iii) and (iv); based on the findings, we propose generalized IW (GIW) that could handle cases (iii) and (iv) and would reduce to IW in cases (i) and (ii). In GIW, the test support is split into an in-training (IT) part and an out-of-training (OOT) part, and the expected risk is decomposed into a weighted classification term over the IT part and a standard classification term over the OOT part, which guarantees the risk consistency of GIW. Then, the implementation of GIW consists of three components: (a) the split of validation data is carried out by the one-class support vector machine, (b) the first term of the empirical risk can be handled by any IW algorithm given training data and IT validation data, and (c) the second term just involves OOT validation data. Experiments demonstrate that GIW is a universal solver for DS problems, outperforming IW methods in cases (iii) and (iv)",
    "checked": true,
    "id": "992122be8818e63f396c1b032a30600ac582b66a",
    "semantic_title": "generalizing importance weighting to a universal solver for distribution shift problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jR2FkqW6GB": {
    "title": "Is Learning in Games Good for the Learners?",
    "volume": "spotlight",
    "abstract": "We consider a number of questions related to tradeoffs between reward and regret in repeated gameplay between two agents. To facilitate this, we introduce a notion of generalized equilibrium which allows for asymmetric regret constraints, and yields polytopes of feasible values for each agent and pair of regret constraints, where we show that any such equilibrium is reachable by a pair of algorithms which maintain their regret guarantees against arbitrary opponents. As a central example, we highlight the case one agent is no-swap and the other's regret is unconstrained. We show that this captures an extension of Stackelberg equilibria with a matching optimal value, and that there exists a wide class of games where a player can significantly increase their utility by deviating from a no-swap-regret algorithm against a no-swap learner (in fact, almost any game without pure Nash equilibria is of this form). Additionally, we make use of generalized equilibria to consider tradeoffs in terms of the opponent's algorithm choice. We give a tight characterization for the maximal reward obtainable against some no-regret learner, yet we also show a class of games in which this is bounded away from the value obtainable against the class of common \"mean-based\" no-regret algorithms. Finally, we consider the question of learning reward-optimal strategies via repeated play with a no-regret agent when the game is initially unknown. Again we show tradeoffs depending on the opponent's learning algorithm: the Stackelberg strategy is learnable in exponential time with any no-regret agent (and in polynomial time with any no-adaptive-regret agent) for any game where it is learnable via queries, and there are games where it is learnable in polynomial time against any no-swap-regret agent but requires exponential time against a mean-based no-regret agent",
    "checked": true,
    "id": "56fc6055968114bda15423afe96a21ac1ed526ca",
    "semantic_title": "is learning in games good for the learners?",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FDzQQTPqEJ": {
    "title": "Squared Neural Families: A New Class of Tractable Density Models",
    "volume": "spotlight",
    "abstract": "Flexible models for probability distributions are an essential ingredient in many machine learning tasks. We develop and investigate a new class of probability distributions, which we call a Squared Neural Family (SNEFY), formed by squaring the 2-norm of a neural network and normalising it with respect to a base measure. Following the reasoning similar to the well established connections between infinitely wide neural networks and Gaussian processes, we show that SNEFYs admit closed form normalising constants in many cases of interest, thereby resulting in flexible yet fully tractable density models. SNEFYs strictly generalise classical exponential families, are closed under conditioning, and have tractable marginal distributions. Their utility is illustrated on a variety of density estimation, conditional density estimation, and density estimation with missing data tasks",
    "checked": true,
    "id": "c09c8e531325f873ba9b07600160074a1cf2e45e",
    "semantic_title": "squared neural families: a new class of tractable density models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Jkc74vn1aZ": {
    "title": "Towards Symmetry-Aware Generation of Periodic Materials",
    "volume": "spotlight",
    "abstract": "We consider the problem of generating periodic materials with deep models. While symmetry-aware molecule generation has been studied extensively, periodic materials possess different symmetries, which have not been completely captured by existing methods. In this work, we propose SyMat, a novel material generation approach that can capture physical symmetries of periodic material structures. SyMat generates atom types and lattices of materials through generating atom type sets, lattice lengths and lattice angles with a variational auto-encoder model. In addition, SyMat employs a score-based diffusion model to generate atom coordinates of materials, in which a novel symmetry-aware probabilistic model is used in the coordinate diffusion process. We show that SyMat is theoretically invariant to all symmetry transformations on materials and demonstrate that SyMat achieves promising performance on random generation and property optimization tasks. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS)",
    "checked": true,
    "id": "cf6a040162a23d5322e1c624c435afc128dfe9e9",
    "semantic_title": "towards symmetry-aware generation of periodic materials",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZIyAHaLlsn": {
    "title": "ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting",
    "volume": "spotlight",
    "abstract": "Diffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps. Existing acceleration sampling techniques inevitably sacrifice performance to some extent, leading to over-blurry SR results. To address this issue, we propose a novel and efficient diffusion model for SR that significantly reduces the number of diffusion steps, thereby eliminating the need for post-acceleration during inference and its associated performance deterioration. Our method constructs a Markov chain that transfers between the high-resolution image and the low-resolution image by shifting the residual between them, substantially improving the transition efficiency. Additionally, an elaborate noise schedule is developed to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experiments demonstrate that the proposed method obtains superior or at least comparable performance to current state-of-the-art methods on both synthetic and real-world datasets, \\textit{\\textbf{even only with 20 sampling steps}}. Our code and model will be made publicly",
    "checked": true,
    "id": "d4a60ef37125fcde198781c2eb578a9c9dc78c1c",
    "semantic_title": "resshift: efficient diffusion model for image super-resolution by residual shifting",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=gmmXyAq8TI": {
    "title": "Coop: Memory is not a Commodity",
    "volume": "spotlight",
    "abstract": "Tensor rematerialization allows the training of deep neural networks (DNNs) under limited memory budgets by checkpointing the models and recomputing the evicted tensors as needed. However, the existing tensor rematerialization techniques overlook the memory system in deep learning frameworks and implicitly assume that free memory blocks at different addresses are identical. Under this flawed assumption, discontiguous tensors are evicted, among which some are not used to allocate the new tensor. This leads to severe memory fragmentation and increases the cost of potential rematerializations. To address this issue, we propose to evict tensors within a sliding window to ensure all evictions are contiguous and are immediately used. Furthermore, we proposed cheap tensor partitioning and recomputable in-place to further reduce the rematerialization cost by optimizing the tensor allocation. We named our method \\name/ as it is a co-optimization of tensor allocation and tensor rematerialization. We evaluated \\name/ on eight representative DNNs. The experimental results demonstrate that \\name/ achieves up to $2\\times$ memory saving and hugely reduces compute overhead, search latency, and memory fragmentation compared to the state-of-the-art baselines",
    "checked": true,
    "id": "57c655bec92a3df3ee2a9be0a209a7350fa8a25b",
    "semantic_title": "coop: memory is not a commodity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K5e5tFZuur": {
    "title": "Invariant Learning via Probability of Sufficient and Necessary Causes",
    "volume": "spotlight",
    "abstract": "Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. However, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of sufficiency and necessity conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. To capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. To associate PNS with OOD generalization, we propose PNS risk and formulate an algorithm to learn representation with a high PNS value. We theoretically analyze and prove the generalizability of the PNS risk. Experiments on both synthetic and real-world benchmarks demonstrate the effectiveness of the proposed method. The detailed implementation can be found at the GitHub repository: https://github.com/ymy4323460/CaSN",
    "checked": true,
    "id": "cbf660b9244de0189ea1c27b77114f9bde0c5b57",
    "semantic_title": "invariant learning via probability of sufficient and necessary causes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5R9bZlpZKj": {
    "title": "Smoothed Analysis of Sequential Probability Assignment",
    "volume": "spotlight",
    "abstract": "We initiate the study of smoothed analysis for the sequential probability assignment problem with contexts. We study information-theoretically optimal minmax rates as well as a framework for algorithmic reduction involving the maximum likelihood estimator oracle. Our approach establishes a general-purpose reduction from minimax rates for sequential probability assignment for smoothed adversaries to minimax rates for transductive learning. This leads to optimal (logarithmic) fast rates for parametric classes and classes with finite VC dimension. On the algorithmic front, we develop an algorithm that efficiently taps into the MLE oracle, for general classes of functions. We show that under general conditions this algorithmic approach yields sublinear regret",
    "checked": true,
    "id": "9f0c3aff8d659c1b71e076c0b8e1be995a271258",
    "semantic_title": "smoothed analysis of sequential probability assignment",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=DEiNSfh1k7": {
    "title": "DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data",
    "volume": "spotlight",
    "abstract": "Current perceptual similarity metrics operate at the level of pixels and patches. These metrics compare images in terms of their low-level colors and textures, but fail to capture mid-level similarities and differences in image layout, object pose, and semantic content. In this paper, we develop a perceptual metric that assesses images holistically. Our first step is to collect a new dataset of human similarity judgments over image pairs that are alike in diverse ways. Critical to this dataset is that judgments are nearly automatic and shared by all observers. To achieve this we use recent text-to-image models to create synthetic pairs that are perturbed along various dimensions. We observe that popular perceptual metrics fall short of explaining our new data, and we introduce a new metric, DreamSim, tuned to better align with human perception. We analyze how our metric is affected by different visual attributes, and find that it focuses heavily on foreground objects and semantic content while also being sensitive to color and layout. Notably, despite being trained on synthetic data, our metric generalizes to real images, giving strong results on retrieval and reconstruction tasks. Furthermore, our metric outperforms both prior learned metrics and recent large vision models on these tasks. Our project page: https://dreamsim-nights.github.io/",
    "checked": true,
    "id": "de374dc9bb0b443ef399fc36587aa1e192447466",
    "semantic_title": "dreamsim: learning new dimensions of human visual similarity using synthetic data",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=qJRlz3SucN": {
    "title": "VaRT: Variational Regression Trees",
    "volume": "spotlight",
    "abstract": "Decision trees are a well-established tool in machine learning for classification and regression tasks. In this paper, we introduce a novel non-parametric Bayesian model that uses variational inference to approximate a posterior distribution over the space of stochastic decision trees. We evaluate the model's performance on 18 datasets and demonstrate its competitiveness with other state-of-the-art methods in regression tasks. We also explore its application to causal inference problems. We provide a fully vectorized implementation of our algorithm in PyTorch",
    "checked": false,
    "id": "eb748bf56c62a403c80dcc75a8eea5ca7f69db1b",
    "semantic_title": "large scale prediction with decision trees",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=zQTi3pziFp": {
    "title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and Audio",
    "volume": "spotlight",
    "abstract": "While 3D human body modeling has received much attention in computer vision, modeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by body motion and speech, has fallen short in the community. To close this gap, we present a model that can generate accurate 3D spatial audio for full human bodies. The system consumes, as input, audio signals from headset microphones and body pose, and produces, as output, a 3D sound field surrounding the transmitter's body, from which spatial audio can be rendered at any arbitrary position in the 3D space. We collect a first-of-its-kind multimodal dataset of human bodies, recorded with multiple cameras and a spherical array of 345 microphones. In an empirical evaluation, we demonstrate that our model can produce accurate body-induced sound fields when trained with a suitable loss. Dataset and code are available online",
    "checked": true,
    "id": "6a0fa97b3e572b085e9b68aaa7832f27579cd8f8",
    "semantic_title": "sounding bodies: modeling 3d spatial sound of humans using body pose and audio",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m21rQusNgb": {
    "title": "Learning List-Level Domain-Invariant Representations for Ranking",
    "volume": "spotlight",
    "abstract": "Domain adaptation aims to transfer the knowledge learned on (data-rich) source domains to (low-resource) target domains, and a popular method is invariant representation learning, which matches and aligns the data distributions on the feature space. Although this method is studied extensively and applied on classification and regression problems, its adoption on ranking problems is sporadic, and the few existing implementations lack theoretical justifications. This paper revisits invariant representation learning for ranking. Upon reviewing prior work, we found that they implement what we call item-level alignment, which aligns the distributions of the items being ranked from all lists in aggregate but ignores their list structure. However, the list structure should be leveraged, because it is intrinsic to ranking problems where the data and the metrics are defined and computed on lists, not the items by themselves. To close this discrepancy, we propose list-level alignment—learning domain-invariant representations at the higher level of lists. The benefits are twofold: it leads to the first domain adaptation generalization bound for ranking, in turn providing theoretical support for the proposed method, and it achieves better empirical transfer performance for unsupervised domain adaptation on ranking tasks, including passage reranking",
    "checked": true,
    "id": "05c39a2f16dc959dddc0b650a5eac952a451b1ac",
    "semantic_title": "learning list-level domain-invariant representations for ranking",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Ifq8GMdqJK": {
    "title": "Conditional independence testing under misspecified inductive biases",
    "volume": "spotlight",
    "abstract": "Conditional independence (CI) testing is a fundamental and challenging task in modern statistics and machine learning. Many modern methods for CI testing rely on powerful supervised learning methods to learn regression functions or Bayes predictors as an intermediate step; we refer to this class of tests as regression-based tests. Although these methods are guaranteed to control Type-I error when the supervised learning methods accurately estimate the regression functions or Bayes predictors of interest, their behavior is less understood when they fail due to misspecified inductive biases; in other words, when the employed models are not flexible enough or when the training algorithm does not induce the desired predictors. Then, we study the performance of regression-based CI tests under misspecified inductive biases. Namely, we propose new approximations or upper bounds for the testing errors of three regression-based tests that depend on misspecification errors. Moreover, we introduce the Rao-Blackwellized Predictor Test (RBPT), a regression-based CI test robust against misspecified inductive biases. Finally, we conduct experiments with artificial and real data, showcasing the usefulness of our theory and methods",
    "checked": true,
    "id": "addcf746f3bffe1138a5e4565c4959c873d5a82c",
    "semantic_title": "conditional independence testing under misspecified inductive biases",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PpI7XvOXkF": {
    "title": "A Spectral Algorithm for List-Decodable Covariance Estimation in Relative Frobenius Norm",
    "volume": "spotlight",
    "abstract": "We study the problem of list-decodable Gaussian covariance estimation. Given a multiset $T$ of $n$ points in $\\mathbb{R}^d$ such that an unknown $\\alpha<1/2$ fraction of points in $T$ are i.i.d. samples from an unknown Gaussian $\\mathcal{N}(\\mu, \\Sigma)$, the goal is to output a list of $O(1/\\alpha)$ hypotheses at least one of which is close to $\\Sigma$ in relative Frobenius norm. Our main result is a $\\mathrm{poly}(d,1/\\alpha)$ sample and time algorithm for this task that guarantees relative Frobenius norm error of $\\mathrm{poly}(1/\\alpha)$. Importantly, our algorithm relies purely on spectral techniques. As a corollary, we obtain an efficient spectral algorithm for robust partial clustering of Gaussian mixture models (GMMs) --- a key ingredient in the recent work of [BakDJKKV22] on robustly learning arbitrary GMMs. Combined with the other components of [BakDJKKV22], our new method yields the first Sum-of-Squares-free algorithm for robustly learning GMMs, resolving an open problem proposed by Vempala and Kothari. At the technical level, we develop a novel multi-filtering method for list-decodable covariance estimation that may be useful in other settings",
    "checked": true,
    "id": "c3e1234615c3f0bb54399d80d4049eaced433a39",
    "semantic_title": "a spectral algorithm for list-decodable covariance estimation in relative frobenius norm",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IT9mWLYNpQ": {
    "title": "Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability",
    "volume": "spotlight",
    "abstract": "Recent research has observed that in machine learning optimization, gradient descent (GD) often operates at the edge of stability (EoS) [Cohen et al., 2021], where the stepsizes are set to be large, resulting in non-monotonic losses induced by the GD iterates. This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime. Despite the presence of local oscillations, we prove that the logistic loss can be minimized by GD with any constant stepsize over a long time scale. Furthermore, we prove that with any constant stepsize, the GD iterates tend to infinity when projected to a max-margin direction (the hard-margin SVM direction) and converge to a fixed vector that minimizes a strongly convex potential when projected to the orthogonal complement of the max-margin direction. In contrast, we also show that in the EoS regime, GD iterates may diverge catastrophically under the exponential loss, highlighting the superiority of the logistic loss. These theoretical findings are in line with numerical simulations and complement existing theories on the convergence and implicit bias of GD for logistic regression, which are only applicable when the stepsizes are sufficiently small",
    "checked": true,
    "id": "7156104cb692b609ce820f73b66afc5824bf0fb0",
    "semantic_title": "implicit bias of gradient descent for logistic regression at the edge of stability",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=HYGnmSLBCf": {
    "title": "Alignment with human representations supports robust few-shot learning",
    "volume": "spotlight",
    "abstract": "Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both natural adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well",
    "checked": true,
    "id": "7026fcb7e6df84a4c873f77be1e8d260a516cc62",
    "semantic_title": "alignment with human representations supports robust few-shot learning",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=dlDFakG6kJ": {
    "title": "Sample Complexity of Forecast Aggregation",
    "volume": "spotlight",
    "abstract": "We consider a Bayesian forecast aggregation model where $n$ experts, after observing private signals about an unknown binary event, report their posterior beliefs about the event to a principal, who then aggregates the reports into a single prediction for the event. The signals of the experts and the outcome of the event follow a joint distribution that is unknown to the principal, but the principal has access to i.i.d. \"samples\" from the distribution, where each sample is a tuple of the experts' reports (not signals) and the realization of the event. Using these samples, the principal aims to find an $\\varepsilon$-approximately optimal aggregator, where optimality is measured in terms of the expected squared distance between the aggregated prediction and the realization of the event. We show that the sample complexity of this problem is at least $\\tilde \\Omega(m^{n-2} / \\varepsilon)$ for arbitrary discrete distributions, where $m$ is the size of each expert's signal space. This sample complexity grows exponentially in the number of experts $n$. But, if the experts' signals are independent conditioned on the realization of the event, then the sample complexity is significantly reduced, to $\\tilde O(1 / \\varepsilon^2)$, which does not depend on $n$. Our results can be generalized to non-binary events. The proof of our results uses a reduction from the distribution learning problem and reveals the fact that forecast aggregation is almost as difficult as distribution learning",
    "checked": true,
    "id": "e238aa29e7fce808f60899363764937fe4c43606",
    "semantic_title": "sample complexity of forecast aggregation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2BFZ8cPIf6": {
    "title": "Learning Functional Transduction",
    "volume": "spotlight",
    "abstract": "Research in statistical learning has polarized into two general approaches to perform regression analysis: Transductive methods construct estimates directly based on exemplar data using generic relational principles which might suffer from the curse of dimensionality. Conversely, inductive methods can potentially fit highly complex functions at the cost of compute-intensive solution searches. In this work, we leverage the theory of vector-valued Reproducing Kernel Banach Spaces (RKBS) to propose a hybrid approach: We show that transductive regression systems can be meta-learned with gradient descent to form efficient _in-context_ neural approximators of function defined over both finite and infinite-dimensional spaces (operator regression). Once trained, our _Transducer_ can almost instantaneously capture new functional relationships and produce original image estimates, given a few pairs of input and output examples. We demonstrate the benefit of our meta-learned transductive approach to model physical systems influenced by varying external factors with little data at a fraction of the usual deep learning training costs for partial differential equations and climate modeling applications",
    "checked": true,
    "id": "d866e37b25b65b56ad816ada830588655f32e050",
    "semantic_title": "learning functional transduction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ce59j806df": {
    "title": "Semi-Supervised Domain Generalization with Known and Unknown Classes",
    "volume": "spotlight",
    "abstract": "Semi-Supervised Domain Generalization (SSDG) aims to learn a model that is generalizable to an unseen target domain with only a few labels, and most existing SSDG methods assume that unlabeled training and testing samples are all known classes. However, a more realistic scenario is that known classes may be mixed with some unknown classes in unlabeled training and testing data. To deal with such a scenario, we propose the Class-Wise Adaptive Exploration and Exploitation (CWAEE) method. In particular, we explore unlabeled training data by using one-vs-rest classifiers and class-wise adaptive thresholds to detect known and unknown classes, and exploit them by adopting consistency regularization on augmented samples based on Fourier Transformation to improve the unseen domain generalization. The experiments conducted on real-world datasets verify the effectiveness and superiority of our method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ppJuFSOAnM": {
    "title": "ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation",
    "volume": "spotlight",
    "abstract": "Score distillation sampling (SDS) has shown great promise in text-to-3D generation by distilling pretrained large-scale text-to-image diffusion models, but suffers from over-saturation, over-smoothing, and low-diversity problems. In this work, we propose to model the 3D parameter as a random variable instead of a constant as in SDS and present *variational score distillation* (VSD), a principled particle-based variational framework to explain and address the aforementioned issues in text-to-3D generation. We show that SDS is a special case of VSD and leads to poor samples with both small and large CFG weights. In comparison, VSD works well with various CFG weights as ancestral sampling from diffusion models and simultaneously improves the diversity and sample quality with a common CFG weight (i.e., 7.5). We further present various improvements in the design space for text-to-3D such as distillation time schedule and density initialization, which are orthogonal to the distillation algorithm yet not well explored. Our overall approach, dubbed *ProlificDreamer*, can generate high rendering resolution (i.e., 512$\\times$512) and high-fidelity NeRF with rich structure and complex effects (e.g., smoke and drops). Further, initialized from NeRF, meshes fine-tuned by VSD are meticulously detailed and photo-realistic",
    "checked": true,
    "id": "c5e9fd131cde68c218d0ea69cd617a67c7f35d42",
    "semantic_title": "prolificdreamer: high-fidelity and diverse text-to-3d generation with variational score distillation",
    "citation_count": 67,
    "authors": []
  },
  "https://openreview.net/forum?id=wbbTqsiKzl": {
    "title": "High-dimensional Asymptotics of Denoising Autoencoders",
    "volume": "spotlight",
    "abstract": "We address the problem of denoising data from a Gaussian mixture using a two-layer non-linear autoencoder with tied weights and a skip connection. We consider the high-dimensional limit where the number of training samples and the input dimension jointly tend to infinity while the number of hidden units remains bounded. We provide closed-form expressions for the denoising mean-squared test error. Building on this result, we quantitatively characterize the advantage of the considered architecture over the autoencoder without the skip connection that relates closely to principal component analysis. We further show that our results capture accurately the learning curves on a range of real datasets",
    "checked": true,
    "id": "6e09980963055bd98a9e0a27fb1e5a77213ca901",
    "semantic_title": "high-dimensional asymptotics of denoising autoencoders",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=HZQZli6amV": {
    "title": "ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets",
    "volume": "spotlight",
    "abstract": "Several studies have compared the in-distribution (ID) and out-of-distribution (OOD) performance of models in computer vision and NLP. They report a frequent positive correlation and some surprisingly never even observe an inverse correlation indicative of a necessary trade-off. The possibility of inverse patterns is important to determine whether ID performance can serve as a proxy for OOD generalization capabilities. This paper shows that inverse correlations between ID and OOD performance do happen with multiple real-world datasets, not only in artificial worst-case settings. We explain theoretically how these cases arise and how past studies missed them because of improper methodologies that examined a biased selection of models. Our observations lead to recommendations that contradict those found in much of the current literature. - High OOD performance sometimes requires trading off ID performance. - Focusing on ID performance alone may not lead to optimal OOD performance. It may produce diminishing (eventually negative) returns in OOD performance. - In these cases, studies on OOD generalization that use ID performance for model selection (a common recommended practice) will necessarily miss the best-performing models, making these studies blind to a whole range of phenomena",
    "checked": true,
    "id": "5f09037109dceda8803baa527e8d1ed4095bee8f",
    "semantic_title": "id and ood performance are sometimes inversely correlated on real-world datasets",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=QkLpGxUboF": {
    "title": "ProPILE: Probing Privacy Leakage in Large Language Models",
    "volume": "spotlight",
    "abstract": "The rapid advancement and widespread use of large language models (LLMs) have raised significant concerns regarding the potential leakage of personally identifiable information (PII). These models are often trained on vast quantities of web-collected data, which may inadvertently include sensitive personal data. This paper presents ProPILE, a novel probing tool designed to empower data subjects, or the owners of the PII, with awareness of potential PII leakage in LLM-based services. ProPILE lets data subjects formulate prompts based on their own PII to evaluate the level of privacy intrusion in LLMs. We demonstrate its application on the OPT-1.3B model trained on the publicly available Pile dataset. We show how hypothetical data subjects may assess the likelihood of their PII being included in the Pile dataset being revealed. ProPILE can also be leveraged by LLM service providers to effectively evaluate their own levels of PII leakage with more powerful prompts specifically tuned for their in-house models. This tool represents a pioneering step towards empowering the data subjects for their awareness and control over their own data on the web",
    "checked": true,
    "id": "b2c68b708a9f98996b18c8d21b53a815a2c46a8b",
    "semantic_title": "propile: probing privacy leakage in large language models",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=pLsPFxqn7J": {
    "title": "Kernelized Cumulants: Beyond Kernel Mean Embeddings",
    "volume": "spotlight",
    "abstract": "In $\\mathbb{R}^d$, it is well-known that cumulants provide an alternative to moments that can achieve the same goals with numerous benefits such as lower variance estimators. In this paper we extend cumulants to reproducing kernel Hilbert spaces (RKHS) using tools from tensor algebras and show that they are computationally tractable by a kernel trick. These kernelized cumulants provide a new set of all-purpose statistics; the classical maximum mean discrepancy and Hilbert-Schmidt independence criterion arise as the degree one objects in our general construction. We argue both theoretically and empirically (on synthetic, environmental, and traffic data analysis) that going beyond degree one has several advantages and can be achieved with the same computational complexity and minimal overhead in our experiments",
    "checked": true,
    "id": "d6c4c81a0bbb761485cd80f75aee266d9fc91081",
    "semantic_title": "kernelized cumulants: beyond kernel mean embeddings",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sTjW3JHs2V": {
    "title": "Let the Flows Tell: Solving Graph Combinatorial Problems with GFlowNets",
    "volume": "spotlight",
    "abstract": "Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space. On the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates. In this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. Efficient training techniques are also developed to benefit long-range credit assignment. Through extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quality solutions. Our implementation is open-sourced at https://github.com/zdhNarsil/GFlowNet-CombOpt",
    "checked": false,
    "id": "e3d0b3f6c085cdf254bf127adc039a0dc45977e6",
    "semantic_title": "let the flows tell: solving graph combinatorial optimization problems with gflownets",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=rheCTpRrxI": {
    "title": "DreamHuman: Animatable 3D Avatars from Text",
    "volume": "spotlight",
    "abstract": "We present \\emph{DreamHuman}, a method to generate realistic animatable 3D human avatar models entirely from textual descriptions. Recent text-to-3D methods have made considerable strides in generation, but are still lacking in important aspects. Control and often spatial resolution remain limited, existing methods produce fixed rather than 3D human models that can be placed in different poses (i.e. re-posable or animatable), and anthropometric consistency for complex structures like people remains a challenge. \\emph{DreamHuman} connects large text-to-image synthesis models, neural radiance fields, and statistical human body models in a novel optimization framework. This makes it possible to generate dynamic 3D human avatars with high-quality textures and learnt per-instance rigid and non rigid geometric deformations. We demonstrate that our method is capable to generate a wide variety of animatable, realistic 3D human models from text. These have diverse appearance, clothing, skin tones and body shapes, and outperform both generic text-to-3D approaches and previous text-based 3D avatar generators in visual fidelity",
    "checked": true,
    "id": "1799398201d38f527cd0edcd23024b053984c4ee",
    "semantic_title": "dreamhuman: animatable 3d avatars from text",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=iuqCXg1Gng": {
    "title": "Saddle-to-Saddle Dynamics in Diagonal Linear Networks",
    "volume": "spotlight",
    "abstract": "In this paper we fully describe the trajectory of gradient flow over $2$-layer diagonal linear networks for the regression setting in the limit of vanishing initialisation. We show that the limiting flow successively jumps from a saddle of the training loss to another until reaching the minimum $\\ell_1$-norm solution. We explicitly characterise the visited saddles as well as the jump times through a recursive algorithm reminiscent of the LARS algorithm used for computing the Lasso path. Starting from the zero vector, coordinates are successively activated until the minimum $\\ell_1$-norm solution is recovered, revealing an incremental learning. Our proof leverages a convenient arc-length time-reparametrisation which enables to keep track of the transitions between the jumps. Our analysis requires negligible assumptions on the data, applies to both under and overparametrised settings and covers complex cases where there is no monotonicity of the number of active coordinates. We provide numerical experiments to support our findings",
    "checked": true,
    "id": "b4729916f1249853a56e446d12500528b56f4e83",
    "semantic_title": "saddle-to-saddle dynamics in diagonal linear networks",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=MvCq52yt9Y": {
    "title": "Mitigating the Popularity Bias of Graph Collaborative Filtering: A Dimensional Collapse Perspective",
    "volume": "spotlight",
    "abstract": "Graph-based Collaborative Filtering (GCF) is widely used in personalized recommendation systems. However, GCF suffers from a fundamental problem where features tend to occupy the embedding space inefficiently (by spanning only a low-dimensional subspace). Such an effect is characterized in GCF by the embedding space being dominated by a few of popular items with the user embeddings highly concentrated around them. This enhances the so-called Matthew effect of the popularity bias where popular items are highly recommend whereas remaining items are ignored. In this paper, we analyze the above effect in GCF and reveal that the simplified graph convolution operation (typically used in GCF) shrinks the singular space of the feature matrix. As typical approaches (i.e., optimizing the uniformity term) fail to prevent the embedding space degradation, we propose a decorrelation-enhanced GCF objective that promotes feature diversity by leveraging the so-called principle of redundancy reduction in embeddings. However, unlike conventional methods that use the Euclidean geometry to relax hard constraints for decorrelation, we exploit non-Euclidean geometry. Such a choice helps maintain the range space of the matrix and obtain small condition number, which prevents the embedding space degradation. Our method outperforms contrastive-based GCF models on several benchmark datasets and improves the performance for unpopular items",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cNb5hkTfGC": {
    "title": "A Scalable Neural Network for DSIC Affine Maximizer Auction Design",
    "volume": "spotlight",
    "abstract": "Automated auction design aims to find empirically high-revenue mechanisms through machine learning. Existing works on multi item auction scenarios can be roughly divided into RegretNet-like and affine maximizer auctions (AMAs) approaches. However, the former cannot strictly ensure dominant strategy incentive compatibility (DSIC), while the latter faces scalability issue due to the large number of allocation candidates. To address these limitations, we propose AMenuNet, a scalable neural network that constructs the AMA parameters (even including the allocation menu) from bidder and item representations. AMenuNet is always DSIC and individually rational (IR) due to the properties of AMAs, and it enhances scalability by generating candidate allocations through a neural network. Additionally, AMenuNet is permutation equivariant, and its number of parameters is independent of auction scale. We conduct extensive experiments to demonstrate that AMenuNet outperforms strong baselines in both contextual and non-contextual multi-item auctions, scales well to larger auctions, generalizes well to different settings, and identifies useful deterministic allocations. Overall, our proposed approach offers an effective solution to automated DSIC auction design, with improved scalability and strong revenue performance in various settings",
    "checked": true,
    "id": "18a13f32f27de5805cfe50a8ec52e8b6b3e45793",
    "semantic_title": "a scalable neural network for dsic affine maximizer auction design",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=AiEipk1X0c": {
    "title": "A Deep Instance Generative Framework for MILP Solvers Under Limited Data Availability",
    "volume": "spotlight",
    "abstract": "In the past few years, there has been an explosive surge in the use of machine learning (ML) techniques to address combinatorial optimization (CO) problems, especially mixed-integer linear programs (MILPs). Despite the achievements, the limited availability of real-world instances often leads to sub-optimal decisions and biased solver assessments, which motivates a suite of synthetic MILP instance generation techniques. However, existing methods either rely heavily on expert-designed formulations or struggle to capture the rich features of real-world instances. To tackle this problem, we propose G2MILP, *the first* deep generative framework for MILP instances. Specifically, G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs to generate new ones. The appealing feature of G2MILP is that it can learn to generate novel and realistic MILP instances without prior expert-designed formulations, while preserving the structures and computational hardness of real-world datasets, simultaneously. Thus the generated instances can facilitate downstream tasks for enhancing MILP solvers under limited data availability. We design a suite of benchmarks to evaluate the quality of the generated MILP instances. Experiments demonstrate that our method can produce instances that closely resemble real-world datasets in terms of both structures and computational hardness. The deliverables are released at [https://miralab-ustc.github.io/L2O-G2MILP](https://miralab-ustc.github.io/L2O-G2MILP)",
    "checked": true,
    "id": "abb6e9dc000fbc094e1598ae5e81c545340656ea",
    "semantic_title": "a deep instance generative framework for milp solvers under limited data availability",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dSRyKIYRnP": {
    "title": "Slow and Weak Attractor Computation Embedded in Fast and Strong E-I Balanced Neural Dynamics",
    "volume": "spotlight",
    "abstract": "Attractor networks require neuronal connections to be highly structured in order to maintain attractor states that represent information, while excitation and inhibition balanced networks (E-INNs) require neuronal connections to be random and sparse to generate irregular neuronal firings. Despite being regarded as canonical models of neural circuits, both types of networks are usually studied in isolation, and it remains unclear how they coexist in the brain, given their very different structural demands. In this study, we investigate the compatibility of continuous attractor neural networks (CANNs) and E-INNs. In line with recent experimental data, we find that a neural circuit can exhibit both the traits of CANNs and E-INNs if the neuronal synapses consist of two sets: one set is strong and fast for irregular firing, and the other set is weak and slow for attractor dynamics. Our results from simulations and theoretical analysis reveal that the network also exhibits enhanced performance compared to the case of using only one set of synapses, with accelerated convergence of attractor states and retained E-I balanced condition for localized input. We also apply the network model to solve a real-world tracking problem and demonstrate that it can track fast-moving objects well. We hope that this study provides insight into how structured neural computations are realized by irregular firings of neurons",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DBz9E5aZey": {
    "title": "Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation",
    "volume": "spotlight",
    "abstract": "Stein Variational Gradient Descent (SVGD) is a popular particle-based variational inference algorithm with impressive empirical performance across various domains. Although the population (i.e, infinite-particle) limit dynamics of SVGD is well characterized, its behavior in the finite-particle regime is far less understood. To this end, our work introduces the notion of *virtual particles* to develop novel stochastic approximations of population-limit SVGD dynamics in the space of probability measures, that are exactly realizable using finite particles. As a result, we design two computationally efficient variants of SVGD, namely VP-SVGD and GB-SVGD, with provably fast finite-particle convergence rates. Our algorithms can be viewed as specific random-batch approximations of SVGD, which are computationally more efficient than ordinary SVGD. We show that the $n$ particles output by VP-SVGD and GB-SVGD, run for $T$ steps with batch-size $K$, are at-least as good as i.i.d samples from a distribution whose Kernel Stein Discrepancy to the target is at most $O(\\tfrac{d^{1/3}}{(KT)^{1/6}})$ under standard assumptions. Our results also hold under a mild growth condition on the potential function, which is much weaker than the isoperimetric (e.g. Poincare Inequality) or information-transport conditions (e.g. Talagrand's Inequality $\\mathsf{T}_1$) generally considered in prior works. As a corollary, we analyze the convergence of the empirical measure (of the particles output by VP-SVGD and GB-SVGD) to the target distribution and demonstrate a **double exponential improvement** over the best known finite-particle analysis of SVGD. Beyond this, our results present the **first known oracle complexities for this setting with polynomial dimension dependence**, thereby completely eliminating the curse of dimensionality exhibited by previously known finite-particle rates",
    "checked": true,
    "id": "edf64d9e8737e5a288060ffe9a81ee1800d623f0",
    "semantic_title": "provably fast finite particle variants of svgd via virtual particle stochastic approximation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qlnlamFQEa": {
    "title": "Aligning Synthetic Medical Images with Clinical Knowledge using Human Feedback",
    "volume": "spotlight",
    "abstract": "Generative models capable of precisely capturing nuanced clinical features in medical images hold great promise for facilitating clinical data sharing, enhancing rare disease datasets, and efficiently synthesizing (annotated) medical images at scale. Despite their potential, assessing the quality of synthetic medical images remains a challenge. While modern generative models can synthesize visually-realistic medical images, the clinical plausibility of these images may be called into question. Domain-agnostic scores, such as FID score, precision, and recall, cannot incorporate clinical knowledge and are, therefore, not suitable for assessing clinical sensibility. Additionally, there are numerous unpredictable ways in which generative models may fail to synthesize clinically plausible images, making it challenging to anticipate potential failures and design automated scores for their detection. To address these challenges, this paper introduces a pathologist-in-the-loop framework for generating clinically-plausible synthetic medical images. Our framework comprises three steps: (1) pretraining a conditional diffusion model to generate medical images conditioned on a clinical concept, (2) expert pathologist evaluation of the generated images to assess whether they satisfy clinical desiderata, and (3) training a reward model that predicts human feedback on new samples, which we use to incorporate expert knowledge into the finetuning objective of the diffusion model. Our results show that human feedback significantly improves the quality of synthetic images in terms of fidelity, diversity, utility in downstream applications, and plausibility as evaluated by experts. We also demonstrate that human feedback can teach the model new clinical concepts not annotated in the original training data. Our results demonstrate the value of incorporating human feedback in clinical applications where generative models may struggle to capture extensive domain knowledge from raw data alone",
    "checked": true,
    "id": "993f0eb1cf576a50cba4fbc667e10f15d63b07f4",
    "semantic_title": "aligning synthetic medical images with clinical knowledge using human feedback",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ginTcBUnL8": {
    "title": "SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling",
    "volume": "spotlight",
    "abstract": "Time series analysis is widely used in extensive areas. Recently, to reduce labeling expenses and benefit various tasks, self-supervised pre-training has attracted immense interest. One mainstream paradigm is masked modeling, which successfully pre-trains deep models by learning to reconstruct the masked content based on the unmasked part. However, since the semantic information of time series is mainly contained in temporal variations, the standard way of randomly masking a portion of time points will seriously ruin vital temporal variations of time series, making the reconstruction task too difficult to guide representation learning. We thus present SimMTM, a Simple pre-training framework for Masked Time-series Modeling. By relating masked modeling to manifold learning, SimMTM proposes to recover masked time points by the weighted aggregation of multiple neighbors outside the manifold, which eases the reconstruction task by assembling ruined but complementary temporal variations from multiple masked series. SimMTM further learns to uncover the local structure of the manifold, which is helpful for masked modeling. Experimentally, SimMTM achieves state-of-the-art fine-tuning performance compared to the most advanced time series pre-training methods in two canonical time series analysis tasks: forecasting and classification, covering both in- and cross-domain settings",
    "checked": true,
    "id": "581921989e50637b1f9930670e623fbd18e42c5d",
    "semantic_title": "simmtm: a simple pre-training framework for masked time-series modeling",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Pz8xvVCLNJ": {
    "title": "Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks",
    "volume": "spotlight",
    "abstract": "No-Reference Video Quality Assessment (NR-VQA) plays an essential role in improving the viewing experience of end-users. Driven by deep learning, recent NR-VQA models based on Convolutional Neural Networks (CNNs) and Transformers have achieved outstanding performance. To build a reliable and practical assessment system, it is of great necessity to evaluate their robustness. However, such issue has received little attention in the academic community. In this paper, we make the first attempt to evaluate the robustness of NR-VQA models against adversarial attacks, and propose a patch-based random search method for black-box attack. Specifically, considering both the attack effect on quality score and the visual quality of adversarial video, the attack problem is formulated as misleading the estimated quality score under the constraint of just-noticeable difference (JND). Built upon such formulation, a novel loss function called Score-Reversed Boundary Loss is designed to push the adversarial video's estimated quality score far away from its ground-truth score towards a specific boundary, and the JND constraint is modeled as a strict $L_2$ and $L_\\infty$ norm restriction. By this means, both white-box and black-box attacks can be launched in an effective and imperceptible manner. The source code is available at https://github.com/GZHU-DVL/AttackVQA",
    "checked": true,
    "id": "d413ddd4b33ec1d8546e2b8656c08fc1998bf181",
    "semantic_title": "vulnerabilities in video quality assessment models: the challenge of adversarial attacks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8rDbUoYc0p": {
    "title": "Constant Approximation for Individual Preference Stable Clustering",
    "volume": "spotlight",
    "abstract": "Individual preference (IP) stability, introduced by Ahmadi et al. (ICML 2022), is a natural clustering objective inspired by stability and fairness constraints. A clustering is $\\alpha$-IP stable if the average distance of every data point to its own cluster is at most $\\alpha$ times the average distance to any other cluster. Unfortunately, determining if a dataset admits a $1$-IP stable clustering is NP-Hard. Moreover, before this work, it was unknown if an $o(n)$-IP stable clustering always exists, as the prior state of the art only guaranteed an $O(n)$-IP stable clustering. We close this gap in understanding and show that an $O(1)$-IP stable clustering always exists for general metrics, and we give an efficient algorithm which outputs such a clustering. We also introduce generalizations of IP stability beyond average distance and give efficient near optimal algorithms in the cases where we consider the maximum and minimum distances within and between clusters",
    "checked": true,
    "id": "153b5bf5c14ded780ed1c6fb1ac2dfaac97573b2",
    "semantic_title": "constant approximation for individual preference stable clustering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WXc8O8ghLH": {
    "title": "Max-Margin Token Selection in Attention Mechanism",
    "volume": "spotlight",
    "abstract": "Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(X)=\\langle Xv, \\texttt{softmax}(XWp)\\rangle$, where $X$ is the token sequence and $(v,W,p)$ are trainable parameters. We prove that running gradient descent on $p$, or equivalently $W$, converges in direction to a max-margin solution that separates *locally-optimal* tokens from non-optimal ones. This clearly formalizes attention as an optimal token selection mechanism. Remarkably, our results are applicable to general data and precisely characterize *optimality* of tokens in terms of the value embeddings $Xv$ and problem geometry. We also provide a broader regularization path analysis that establishes the margin maximizing nature of attention even for nonlinear prediction heads. When optimizing $v$ and $p$ simultaneously with logistic loss, we identify conditions under which the regularization paths directionally converge to their respective hard-margin SVM solutions where $v$ separates the input features based on their labels. Interestingly, the SVM formulation of $p$ is influenced by the support vector geometry of $v$. Finally, we verify our theoretical findings via numerical experiments and provide insights",
    "checked": true,
    "id": "a87f40a49da377c0d00bebe711e417fc3b1d8969",
    "semantic_title": "max-margin token selection in attention mechanism",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ZITOHWeAy7": {
    "title": "A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised Learning",
    "volume": "spotlight",
    "abstract": "Open-world semi-supervised learning aims at inferring both known and novel classes in unlabeled data, by harnessing prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for this problem. This paper bridges the gap by formalizing a graph-theoretic framework tailored for the open-world setting, where the clustering can be theoretically characterized by graph factorization. Our graph-theoretic framework illuminates practical algorithms and provides guarantees. In particular, based on our graph formulation, we apply the algorithm called Spectral Open-world Representation Learning (SORL), and show that minimizing our loss is equivalent to performing spectral decomposition on the graph. Such equivalence allows us to derive a provable error bound on the clustering performance for both known and novel classes, and analyze rigorously when labeled data helps. Empirically, SORL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees",
    "checked": true,
    "id": "23784d956043af0c247d7e985f15be407a3edd68",
    "semantic_title": "a graph-theoretic framework for understanding open-world semi-supervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D94QKZA7UP": {
    "title": "A One-Size-Fits-All Approach to Improving Randomness in Paper Assignment",
    "volume": "spotlight",
    "abstract": "The assignment of papers to reviewers is a crucial part of the peer review processes of large publication venues, where organizers (e.g., conference program chairs) rely on algorithms to perform automated paper assignment. As such, a major challenge for the organizers of these processes is to specify paper assignment algorithms that find appropriate assignments with respect to various desiderata. Although the main objective when choosing a good paper assignment is to maximize the expertise of each reviewer for their assigned papers, several other considerations make introducing randomization into the paper assignment desirable: robustness to malicious behavior, the ability to evaluate alternative paper assignments, reviewer diversity, and reviewer anonymity. However, it is unclear in what way one should randomize the paper assignment in order to best satisfy all of these considerations simultaneously. In this work, we present a practical, one-size-fits-all method for randomized paper assignment intended to perform well across different motivations for randomness. We show theoretically and experimentally that our method outperforms currently-deployed methods for randomized paper assignment on several intuitive randomness metrics, demonstrating that the randomized assignments produced by our method are general-purpose",
    "checked": true,
    "id": "b002b9763941f839f24b2bee2344b00d5a9dfe22",
    "semantic_title": "a one-size-fits-all approach to improving randomness in paper assignment",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DQgTewaKzt": {
    "title": "ZoomTrack: Target-aware Non-uniform Resizing for Efficient Visual Tracking",
    "volume": "spotlight",
    "abstract": "Recently, the transformer has enabled the speed-oriented trackers to approach state-of-the-art (SOTA) performance with high-speed thanks to the smaller input size or the lighter feature extraction backbone, though they still substantially lag behind their corresponding performance-oriented versions. In this paper, we demonstrate that it is possible to narrow or even close this gap while achieving high tracking speed based on the smaller input size. To this end, we non-uniformly resize the cropped image to have a smaller input size while the resolution of the area where the target is more likely to appear is higher and vice versa. This enables us to solve the dilemma of attending to a larger visual field while retaining more raw information for the target despite a smaller input size. Our formulation for the non-uniform resizing can be efficiently solved through quadratic programming (QP) and naturally integrated into most of the crop-based local trackers. Comprehensive experiments on five challenging datasets based on two kinds of transformer trackers, \\ie, OSTrack and TransT, demonstrate consistent improvements over them. In particular, applying our method to the speed-oriented version of OSTrack even outperforms its performance-oriented counterpart by 0.6\\% AUC on TNL2K, while running 50\\% faster and saving over 55\\% MACs. Codes and models are available at https://github.com/Kou-99/ZoomTrack",
    "checked": true,
    "id": "3ac21448bfcb74b52ccdefd7cbf9cc33b38ef13d",
    "semantic_title": "zoomtrack: target-aware non-uniform resizing for efficient visual tracking",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rHAX0LRwk8": {
    "title": "Adversarial Counterfactual Environment Model Learning",
    "volume": "spotlight",
    "abstract": "An accurate environment dynamics model is crucial for various downstream tasks, such as counterfactual prediction, off-policy evaluation, and offline reinforcement learning. Currently, these models were learned through empirical risk minimization (ERM) by step-wise fitting of historical transition data. However, we first show that, particularly in the sequential decision-making setting, this approach may catastrophically fail to predict counterfactual action effects due to the selection bias of behavior policies during data collection. To tackle this problem, we introduce a novel model-learning objective called adversarial weighted empirical risk minimization (AWRM). AWRM incorporates an adversarial policy that exploits the model to generate a data distribution that weakens the model's prediction accuracy, and subsequently, the model is learned under this adversarial data distribution. We implement a practical algorithm, GALILEO, for AWRM and evaluate it on two synthetic tasks, three continuous-control tasks, and \\textit{a real-world application}. The experiments demonstrate that GALILEO can accurately predict counterfactual actions and improve various downstream tasks, including offline policy evaluation and improvement, as well as online decision-making",
    "checked": true,
    "id": "9ae56934704cc43573b94c6e72b829390681f883",
    "semantic_title": "adversarial counterfactual environment model learning",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=c2eedxSlPJ": {
    "title": "Tight Risk Bounds for Gradient Descent on Separable Data",
    "volume": "spotlight",
    "abstract": "We study the generalization properties of unregularized gradient methods applied to separable linear classification---a setting that has received considerable attention since the pioneering work of Soudry et al. (2018). We establish tight upper and lower (population) risk bounds for gradient descent in this setting, for any smooth loss function, expressed in terms of its tail decay rate. Our bounds take the form $\\Theta(r_{\\ell,T}^2 / \\gamma^2 T + r_{\\ell,T}^2 / \\gamma^2 n)$, where $T$ is the number of gradient steps, $n$ is size of the training set, $\\gamma$ is the data margin, and $r_{\\ell,T}$ is a complexity term that depends on the tail decay rate of the loss function (and on $T$). Our upper bound greatly improves the existing risk bounds due to Shamir (2021) and Schliserman and Koren (2022), that either applied to specific loss functions or imposed extraneous technical assumptions, and applies to virtually any convex and smooth loss function. Our risk lower bound is the first in this context and establish the tightness of our general upper bound for any given tail decay rate and in all parameter regimes. The proof technique used to show these results is also markedly simpler compared to previous work, and is straightforward to extend to other gradient methods; we illustrate this by providing analogous results for Stochastic Gradient Descent",
    "checked": true,
    "id": "5bfc7b7d5da24702907ad96bab4a7d24cc25aedb",
    "semantic_title": "tight risk bounds for gradient descent on separable data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=exg62lfHrB": {
    "title": "Model Spider: Learning to Rank Pre-Trained Models Efficiently",
    "volume": "spotlight",
    "abstract": "Figuring out which Pre-Trained Model (PTM) from a model zoo fits the target task is essential to take advantage of plentiful model resources. With the availability of numerous heterogeneous PTMs from diverse fields, efficiently selecting the most suitable one is challenging due to the time-consuming costs of carrying out forward or backward passes over all PTMs. In this paper, we propose Model Spider, which tokenizes both PTMs and tasks by summarizing their characteristics into vectors to enable efficient PTM selection. By leveraging the approximated performance of PTMs on a separate set of training tasks, Model Spider learns to construct representation and measure the fitness score between a model-task pair via their representation. The ability to rank relevant PTMs higher than others generalizes to new tasks. With the top-ranked PTM candidates, we further learn to enrich task repr. with their PTM-specific semantics to re-rank the PTMs for better selection. Model Spider balances efficiency and selection ability, making PTM selection like a spider preying on a web. Model Spider exhibits promising performance across diverse model zoos, including visual models and Large Language Models (LLMs). Code is available at https://github.com/zhangyikaii/Model-Spider",
    "checked": true,
    "id": "bb2806625aa469af034727c4df71c33c9746ec85",
    "semantic_title": "model spider: learning to rank pre-trained models efficiently",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tIzbNQko3c": {
    "title": "Pre-Training Protein Encoder via Siamese Sequence-Structure Diffusion Trajectory Prediction",
    "volume": "spotlight",
    "abstract": "Self-supervised pre-training methods on proteins have recently gained attention, with most approaches focusing on either protein sequences or structures, neglecting the exploration of their joint distribution, which is crucial for a comprehensive understanding of protein functions by integrating co-evolutionary information and structural characteristics. In this work, inspired by the success of denoising diffusion models in generative tasks, we propose the DiffPreT approach to pre-train a protein encoder by sequence-structure joint diffusion modeling. DiffPreT guides the encoder to recover the native protein sequences and structures from the perturbed ones along the joint diffusion trajectory, which acquires the joint distribution of sequences and structures. Considering the essential protein conformational variations, we enhance DiffPreT by a method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the correlation between different conformers of a protein. SiamDiff attains this goal by maximizing the mutual information between representations of diffusion trajectories of structurally-correlated conformers. We study the effectiveness of DiffPreT and SiamDiff on both atom- and residue-level structure-based protein understanding tasks. Experimental results show that the performance of DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new state-of-the-art performance, considering the mean ranks on all tasks. Code will be released upon acceptance",
    "checked": true,
    "id": "6c0303b54320944f950c9483051d00e57b5a8380",
    "semantic_title": "pre-training protein encoder via siamese sequence-structure diffusion trajectory prediction",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=t6nA7x3GAC": {
    "title": "Trans-Dimensional Generative Modeling via Jump Diffusion Models",
    "volume": "spotlight",
    "abstract": "We propose a new class of generative model that naturally handles data of varying dimensionality by jointly modeling the state and dimension of each datapoint. The generative process is formulated as a jump diffusion process that makes jumps between different dimensional spaces. We first define a dimension destroying forward noising process, before deriving the dimension creating time-reversed generative process along with a novel evidence lower bound training objective for learning to approximate it. Simulating our learned approximation to the time-reversed generative process then provides an effective way of sampling data of varying dimensionality by jointly generating state values and dimensions. We demonstrate our approach on molecular and video datasets of varying dimensionality, reporting better compatibility with test-time diffusion guidance imputation tasks and improved interpolation capabilities versus fixed dimensional models that generate state values and dimensions separately",
    "checked": true,
    "id": "447a0af01bc975276e2c67eabecd0b8df7bc0b20",
    "semantic_title": "trans-dimensional generative modeling via jump diffusion models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=oyV9FslE3j": {
    "title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training",
    "volume": "spotlight",
    "abstract": "Regularization in modern machine learning is crucial, and it can take various forms in algorithmic design: training set, model family, error function, regularization terms, and optimizations. In particular, the learning rate, which can be interpreted as a temperature-like parameter within the statistical mechanics of learning, plays a crucial role in neural network training. Indeed, many widely adopted training strategies basically just define the decay of the learning rate over time. This process can be interpreted as decreasing a temperature, using either a global learning rate (for the entire model) or a learning rate that varies for each parameter. This paper proposes TempBalance, a straightforward yet effective layer-wise learning rate method. TempBalance is based on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which characterizes the implicit self-regularization of different layers in trained models. We demonstrate the efficacy of using HT-SR-motivated metrics to guide the scheduling and balancing of temperature across all network layers during model training, resulting in improved performance during testing. We implement TempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using ResNets, VGGs and WideResNets with various depths and widths. Our results show that TempBalance significantly outperforms ordinary SGD and carefully-tuned spectral norm regularization. We also show that TempBalance outperforms a number of state-of-the-art optimizers and learning rate schedulers",
    "checked": true,
    "id": "2485a84a12c6b3ee4a5600b7313b8667f87a3af6",
    "semantic_title": "temperature balancing, layer-wise weight analysis, and neural network training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lXuByUeHhd": {
    "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining",
    "volume": "spotlight",
    "abstract": "The mixture proportions of pretraining data domains (e.g., Wikipedia, books, web text) greatly affect language model (LM) performance. In this paper, we propose Domain Reweighting with Minimax Optimization (DoReMi), which first trains a small proxy model using group distributionally robust optimization (Group DRO) over domains to produce domain weights (mixture proportions) without knowledge of downstream tasks. We then resample a dataset with these domain weights and train a larger, full-sized model. In our experiments, we use DoReMi on a 280M-parameter proxy model to find domain weights for training an 8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi improves perplexity across all domains, even when it downweights a domain. DoReMi improves average few-shot downstream accuracy by 6.5% points over a baseline model trained using The Pile's default domain weights and reaches the baseline accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi, which has no knowledge of downstream tasks, even matches the performance of using domain weights tuned on downstream tasks",
    "checked": true,
    "id": "9b4f7c97c0b83a80c32bc0b93595cbcfb4ecb16d",
    "semantic_title": "doremi: optimizing data mixtures speeds up language model pretraining",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=x2xQEszznV": {
    "title": "Online Constrained Meta-Learning: Provable Guarantees for Generalization",
    "volume": "spotlight",
    "abstract": "Meta-learning has attracted attention due to its strong ability to learn experiences from known tasks, which can speed up and enhance the learning process for new tasks. However, most existing meta-learning approaches only can learn from tasks without any constraint. This paper proposes an online constrained meta-learning framework, which continuously learns meta-knowledge from sequential learning tasks, and the learning tasks are subject to hard constraints. Beyond existing meta-learning analyses, we provide the upper bounds of optimality gaps and constraint violations produced by the proposed framework, which considers the dynamic regret of online learning, as well as the generalization ability of the task-specific models. Moreover, we provide a practical algorithm for the framework, and validate its superior effectiveness through experiments conducted on meta-imitation learning and few-shot image classification",
    "checked": false,
    "id": "536b9296f9f02048241645ec72bba8ad02d3cff9",
    "semantic_title": "meta-learning adversarial bandits",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=fxNQJVMwK2": {
    "title": "Text-to-Image Diffusion Models are Zero Shot Classifiers",
    "volume": "spotlight",
    "abstract": "The excellent generative capabilities of text-to-image diffusion models suggest they learn informative representations of image-text data. However, what knowledge their representations capture is not fully understood, and they have not been thoroughly explored on downstream tasks. We investigate diffusion models by proposing a method for evaluating them as zero-shot classifiers. The key idea is using a diffusion model's ability to denoise a noised image given a text description of a label as a proxy for that label's likelihood. We apply our method to Stable Diffusion and Imagen, using it to probe fine-grained aspects of the models' knowledge and comparing them with CLIP's zero-shot abilities. They perform competitively with CLIP on a wide range of zero-shot image classification datasets. Additionally, they achieve state-of-the-art results on shape/texture bias tests and can successfully perform attribute binding while CLIP cannot. Although generative pre-training is prevalent in NLP, visual foundation models often use other methods such as contrastive learning. Based on our findings, we argue that generative pre-training should be explored as a compelling alternative for vision and vision-language problems",
    "checked": false,
    "id": "1bba2a9c6db3b356b8ae6ef2efff5645e4d96c2b",
    "semantic_title": "text-to-image diffusion models are zero-shot classifiers",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=xRfTcZdQxq": {
    "title": "Robust Model Reasoning and Fitting via Dual Sparsity Pursuit",
    "volume": "spotlight",
    "abstract": "In this paper, we contribute to solving a threefold problem: outlier rejection, true model reasoning and parameter estimation with a unified optimization modeling. To this end, we first pose this task as a sparse subspace recovering problem, to search a maximum of independent bases under an over-embedded data space. Then we convert the objective into a continuous optimization paradigm that estimates sparse solutions for both bases and errors. Wherein a fast and robust solver is proposed to accurately estimate the sparse subspace parameters and error entries, which is implemented by a proximal approximation method under the alternating optimization framework with the ``optimal'' sub-gradient descent. Extensive experiments regarding known and unknown model fitting on synthetic and challenging real datasets have demonstrated the superiority of our method against the state-of-the-art. We also apply our method to multi-class multi-model fitting and loop closure detection, and achieve promising results both in accuracy and efficiency. Code is released at: https://github.com/StaRainJ/DSP",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lSLYXuLqRQ": {
    "title": "Masked Space-Time Hash Encoding for Efficient Dynamic Scene Reconstruction",
    "volume": "spotlight",
    "abstract": "In this paper, we propose the Masked Space-Time Hash encoding (MSTH), a novel method for efficiently reconstructing dynamic 3D scenes from multi-view or monocular videos. Based on the observation that dynamic scenes often contain substantial static areas that result in redundancy in storage and computations, MSTH represents a dynamic scene as a weighted combination of a 3D hash encoding and a 4D hash encoding. The weights for the two components are represented by a learnable mask which is guided by an uncertainty-based objective to reflect the spatial and temporal importance of each 3D position. With this design, our method can reduce the hash collision rate by avoiding redundant queries and modifications on static areas, making it feasible to represent a large number of space-time voxels by hash tables with small size.Besides, without the requirements to fit the large numbers of temporally redundant features independently, our method is easier to optimize and converge rapidly with only twenty minutes of training for a 300-frame dynamic scene. We evaluate our method on extensive dynamic scenes. As a result, MSTH obtains consistently better results than previous state-of-the-art methods with only 20 minutes of training time and 130 MB of memory storage",
    "checked": true,
    "id": "a2fca897257b6453a051d5e459f1e500e6ee368a",
    "semantic_title": "masked space-time hash encoding for efficient dynamic scene reconstruction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cto6jIIbMZ": {
    "title": "Demystifying Softmax Gating Function in Gaussian Mixture of Experts",
    "volume": "spotlight",
    "abstract": "Understanding the parameter estimation of softmax gating Gaussian mixture of experts has remained a long-standing open problem in the literature. It is mainly due to three fundamental theoretical challenges associated with the softmax gating function: (i) the identifiability only up to the translation of parameters; (ii) the intrinsic interaction via partial differential equations between the softmax gating and the expert functions in the Gaussian density; (iii) the complex dependence between the numerator and denominator of the conditional density of softmax gating Gaussian mixture of experts. We resolve these challenges by proposing novel Voronoi loss functions among parameters and establishing the convergence rates of maximum likelihood estimator (MLE) for solving parameter estimation in these models. When the true number of experts is unknown and over-specified, our findings show a connection between the convergence rate of the MLE and a solvability problem of a system of polynomial equations",
    "checked": true,
    "id": "f02d9cd70f3e6d53796a47c0b4efefd0a81f826f",
    "semantic_title": "demystifying softmax gating function in gaussian mixture of experts",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=gMS6FVZvmF": {
    "title": "One Fits All: Power General Time Series Analysis by Pretrained LM",
    "volume": "spotlight",
    "abstract": "Although we have witnessed great success of pre-trained models in natural language processing (NLP) and computer vision (CV), limited progress has been made for general time series analysis. Unlike NLP and CV where a unified model can be used to perform different tasks, specially designed approach still dominates in each time series analysis task such as classification, anomaly detection, forecasting, and few-shot learning. The main challenge that blocks the development of pre-trained model for time series analysis is the lack of a large amount of data for training. In this work, we address this challenge by leveraging language or CV models, pre-trained from billions of tokens, for time series analysis. Specifically, we refrain from altering the self-attention and feedforward layers of the residual blocks in the pre-trained language or image model. This model, known as the Frozen Pretrained Transformer (FPT), is evaluated through fine-tuning on all major types of tasks involving time series. Our results demonstrate that pre-trained models on natural language or images can lead to a comparable or state-of-the-art performance in all main time series analysis tasks, as illustrated in Figure1. We also found both theoretically and empirically that the self-attention module behaviors similarly to principle component analysis (PCA), an observation that helps explains how transformer bridges the domain gap and a crucial step towards understanding the universality of a pre-trained transformer. The code is publicly available at https://anonymous.4open.science/r/Pretrained-LM-for-TSForcasting-C561",
    "checked": false,
    "id": "5b7f5488c380cf5085a5dd93e993ad293b225eee",
    "semantic_title": "one fits all:power general time series analysis by pretrained lm",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=A57UMlUJdc": {
    "title": "Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration",
    "volume": "spotlight",
    "abstract": "In reinforcement learning (RL), balancing exploration and exploitation is crucial for achieving an optimal policy in a sample-efficient way. To this end, existing sample- efficient algorithms typically consist of three components: estimation, planning, and exploration. However, to cope with general function approximators, most of them involve impractical algorithmic components to incentivize exploration, such as data-dependent level-set constraints or complicated sampling procedures. To address this challenge, we propose an easy-to-implement RL framework called Maximize to Explore (MEX), which only needs to optimize unconstrainedly a single objective that integrates the estimation and planning components while balancing exploration and exploitation automatically. Theoretically, we prove that the MEX achieves a sublinear regret with general function approximators and is extendable to the zero-sum Markov game setting. Meanwhile, we adapt deep RL baselines to design practical versions of MEX in both the model-based and model-free settings, which outperform baselines in various MuJoCo environments with sparse reward by a stable margin. Compared with existing sample-efficient algorithms with general function approximators, MEX achieves similar sample efficiency while also enjoying a lower computational cost and is more compatible with modern deep RL methods",
    "checked": true,
    "id": "1311944e1ac408fd4a7829b254f25a6560b66e07",
    "semantic_title": "maximize to explore: one objective function fusing estimation, planning, and exploration",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9XieH21Tlf": {
    "title": "Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality",
    "volume": "spotlight",
    "abstract": "Prompt-based continual learning is an emerging direction in leveraging pre-trained knowledge for downstream continual learning, and has almost reached the performance pinnacle under supervised pre-training. However, our empirical research reveals that the current strategies fall short of their full potential under the more realistic self-supervised pre-training, which is essential for handling vast quantities of unlabeled data in practice. This is largely due to the difficulty of task-specific knowledge being incorporated into instructed representations via prompt parameters and predicted by uninstructed representations at test time. To overcome the exposed sub-optimality, we conduct a theoretical analysis of the continual learning objective in the context of pre-training, and decompose it into hierarchical components: within-task prediction, task-identity inference, and task-adaptive prediction. Following these empirical and theoretical insights, we propose Hierarchical Decomposition (HiDe-)Prompt, an innovative approach that explicitly optimizes the hierarchical components with an ensemble of task-specific prompts and statistics of both uninstructed and instructed representations, further with the coordination of a contrastive regularization strategy. Our extensive experiments demonstrate the superior performance of HiDe-Prompt and its robustness to pre-training paradigms in continual learning (e.g., up to 15.01% and 9.61% lead on Split CIFAR-100 and Split ImageNet-R, respectively)",
    "checked": true,
    "id": "17f75f98cb3c331c048fcbb1eaa59c094f65e696",
    "semantic_title": "hierarchical decomposition of prompt-based continual learning: rethinking obscured sub-optimality",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QatZNssk7T": {
    "title": "Adaptive Data Analysis in a Balanced Adversarial Model",
    "volume": "spotlight",
    "abstract": "In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an unknown distribution $\\cal{D}$, and is required to provide accurate estimations to a sequence of adaptively chosen statistical queries with respect to $\\cal{D}$. Hardt and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in general, it is computationally hard to answer more than $\\Theta(n^2)$ adaptive queries, assuming the existence of one-way functions. However, these negative results strongly rely on an adversarial model that significantly advantages the adversarial analyst over the mechanism, as the analyst, who chooses the adaptive queries, also chooses the underlying distribution $\\cal{D}$. This imbalance raises questions with respect to the applicability of the obtained hardness results -- an analyst who has complete knowledge of the underlying distribution $\\cal{D}$ would have little need, if at all, to issue statistical queries to a mechanism which only holds a finite number of samples from $\\cal{D}$. We consider more restricted adversaries, called \\emph{balanced}, where each such adversary consists of two separated algorithms: The \\emph{sampler} who is the entity that chooses the distribution and provides the samples to the mechanism, and the \\emph{analyst} who chooses the adaptive queries, but has no prior knowledge of the underlying distribution (and hence has no a priori advantage with respect to the mechanism). We improve the quality of previous lower bounds by revisiting them using an efficient \\emph{balanced} adversary, under standard public-key cryptography assumptions. We show that these stronger hardness assumptions are unavoidable in the sense that any computationally bounded \\emph{balanced} adversary that has the structure of all known attacks, implies the existence of public-key cryptography",
    "checked": true,
    "id": "7feee0515f59fc684c7bff17b6f0605d9c873c16",
    "semantic_title": "adaptive data analysis in a balanced adversarial model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5Fgdk3hZpb": {
    "title": "Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective",
    "volume": "spotlight",
    "abstract": "We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for efficient dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5\\% and 60.8\\% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5\\% and 32.9\\%, respectively. Our approach also surpasses MTT in terms of speed by approximately 52$\\times$ (ConvNet-4) and 16$\\times$ (ResNet-18) faster with less memory consumption of 11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://github.com/VILA-Lab/SRe2L",
    "checked": true,
    "id": "1262758538525835d918007d15726794e19a07b7",
    "semantic_title": "squeeze, recover and relabel: dataset condensation at imagenet scale from a new perspective",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=DqfdhM64LI": {
    "title": "Decentralized Randomly Distributed Multi-agent Multi-armed Bandit with Heterogeneous Rewards",
    "volume": "spotlight",
    "abstract": "We study a decentralized multi-agent multi-armed bandit problem in which multiple clients are connected by time dependent random graphs provided by an environment. The reward distributions of each arm vary across clients and rewards are generated independently over time by an environment based on distributions that include both sub-exponential and sub-gaussian distributions. Each client pulls an arm and communicates with neighbors based on the graph provided by the environment. The goal is to minimize the overall regret of the entire system through collaborations. To this end, we introduce a novel algorithmic framework, which first provides robust simulation methods for generating random graphs using rapidly mixing markov chains or the random graph model, and then combines an averaging-based consensus approach with a newly proposed weighting technique and the upper confidence bound to deliver a UCB-type solution. Our algorithms account for the randomness in the graphs, removing the conventional doubly stochasticity assumption, and only require the knowledge of the number of clients at initialization. We derive optimal instance-dependent regret upper bounds of order $\\log{T}$ in both sub-gaussian and sub-exponential environments, and a nearly optimal instance-free regret upper bound of order $\\sqrt{T}\\log T$ up to a $\\log T$ factor. Importantly, our regret bounds hold with high probability and capture graph randomness, whereas prior works consider expected regret under assumptions and require more stringent reward distributions",
    "checked": true,
    "id": "2765fe875a049d1691c4eb1e3173d52d15f82f83",
    "semantic_title": "decentralized randomly distributed multi-agent multi-armed bandit with heterogeneous rewards",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XRy4YQYLe0": {
    "title": "Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions",
    "volume": "spotlight",
    "abstract": "Machine learning (ML) models can underperform on certain population groups due to choices made during model development and bias inherent in the data. We categorize sources of discrimination in the ML pipeline into two classes: aleatoric discrimination, which is inherent in the data distribution, and epistemic discrimination, which is due to decisions made during model development. We quantify aleatoric discrimination by determining the performance limits of a model under fairness constraints, assuming perfect knowledge of the data distribution. We demonstrate how to characterize aleatoric discrimination by applying Blackwell's results on comparing statistical experiments. We then quantify epistemic discrimination as the gap between a model's accuracy when fairness constraints are applied and the limit posed by aleatoric discrimination. We apply this approach to benchmark existing fairness interventions and investigate fairness risks in data with missing values. Our results indicate that state-of-the-art fairness interventions are effective at removing epistemic discrimination on standard (overused) tabular datasets. However, when data has missing values, there is still significant room for improvement in handling aleatoric discrimination",
    "checked": true,
    "id": "2a3d82d3af02d8c893397c45d1bf14042dd9d679",
    "semantic_title": "aleatoric and epistemic discrimination: fundamental limits of fairness interventions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K8gLHZIgVW": {
    "title": "Regularization properties of adversarially-trained linear regression",
    "volume": "spotlight",
    "abstract": "State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated as a min-max problem, it searches for the best solution when the training data were corrupted by the worst-case attacks. Linear models are among the simple models where vulnerabilities can be observed and are the focus of our study. In this case, adversarial training leads to a convex optimization problem which can be formulated as the minimization of a finite sum. We provide a comparative analysis between the solution of adversarial training in linear regression and other regularization methods. Our main findings are that: (A) Adversarial training yields the minimum-norm interpolating solution in the overparameterized regime (more parameters than data), as long as the maximum disturbance radius is smaller than a threshold. And, conversely, the minimum-norm interpolator is the solution to adversarial training with a given radius. (B) Adversarial training can be equivalent to parameter shrinking methods (ridge regression and Lasso). This happens in the underparametrized region, for an appropriate choice of adversarial radius and zero-mean symmetrically distributed covariates. (C) For $\\ell_\\infty$-adversarial training---as in square-root Lasso---the choice of adversarial radius for optimal bounds does not depend on the additive noise variance. We confirm our theoretical findings with numerical examples",
    "checked": true,
    "id": "f874fd7a1961be99c39a0cb3d1c615f51d8276d2",
    "semantic_title": "regularization properties of adversarially-trained linear regression",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7GyYpomkEa": {
    "title": "AbDiffuser: full-atom generation of in-vitro functioning antibodies",
    "volume": "spotlight",
    "abstract": "We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude, enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of the selected designs were tight binders",
    "checked": true,
    "id": "021c4955947fe6f7836dba8e5d63bb35d0917059",
    "semantic_title": "abdiffuser: full-atom generation of in-vitro functioning antibodies",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=LAGxc2ybuH": {
    "title": "Explaining the Uncertain: Stochastic Shapley Values for Gaussian Process Models",
    "volume": "spotlight",
    "abstract": "We present a novel approach for explaining Gaussian processes (GPs) that can utilize the full analytical covariance structure present in GPs. Our method is based on the popular solution concept of Shapley values extended to stochastic cooperative games, resulting in explanations that are random variables. The GP explanations generated using our approach satisfy similar favorable axioms to standard Shapley values and possess a tractable covariance function across features and data observations. This covariance allows for quantifying explanation uncertainties and studying the statistical dependencies between explanations. We further extend our framework to the problem of predictive explanation, and propose a Shapley prior over the explanation function to predict Shapley values for new data based on previously computed ones. Our extensive illustrations demonstrate the effectiveness of the proposed approach",
    "checked": true,
    "id": "9b933a98347f111bd9afd67eb6a06ff09210ec3a",
    "semantic_title": "explaining the uncertain: stochastic shapley values for gaussian process models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JpU5YmMKx7": {
    "title": "Attentive Transfer Entropy to Exploit Transient Emergence of Coupling Effect",
    "volume": "spotlight",
    "abstract": "We consider the problem of reconstructing coupled networks (e.g., biological neural networks) connecting large numbers of variables (e.g.,nerve cells), of which state evolution is governed by dissipative dynamics consisting of strong self-drive (dominants the evolution) and weak coupling-drive. The core difficulty is sparseness of coupling effect that emerges (the coupling force is significant) only momentarily and otherwise remains quiescent in time series (e.g., neuronal activity sequence). Here we learn the idea from attention mechanism to guide the classifier to make inference focusing on the critical regions of time series data where coupling effect may manifest. Specifically, attention coefficients are assigned autonomously by artificial neural networks trained to maximise the Attentive Transfer Entropy (ATEn), which is a novel generalization of the iconic transfer entropy metric. Our results show that, without any prior knowledge of dynamics, ATEn explicitly identifies areas where the strength of coupling-drive is distinctly greater than zero. This innovation substantially improves reconstruction performance for both synthetic and real directed coupling networks using data generated by neuronal models widely used in neuroscience",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NWEbeI2HNQ": {
    "title": "Prefix-Tree Decoding for Predicting Mass Spectra from Molecules",
    "volume": "spotlight",
    "abstract": "Computational predictions of mass spectra from molecules have enabled the discovery of clinically relevant metabolites. However, such predictive tools are still limited as they occupy one of two extremes, either operating (a) by fragmenting molecules combinatorially with overly rigid constraints on potential rearrangements and poor time complexity or (b) by decoding lossy and nonphysical discretized spectra vectors. In this work, we use a new intermediate strategy for predicting mass spectra from molecules by treating mass spectra as sets of molecular formulae, which are themselves multisets of atoms. After first encoding an input molecular graph, we decode a set of molecular subformulae, each of which specify a predicted peak in the mass spectrum, the intensities of which are predicted by a second model. Our key insight is to overcome the combinatorial possibilities for molecular subformulae by decoding the formula set using a prefix tree structure, atom-type by atom-type, representing a general method for ordered multiset decoding. We show promising empirical results on mass spectra prediction tasks",
    "checked": true,
    "id": "f361a4feba42c595b3a40b6f20ae95d26589650e",
    "semantic_title": "prefix-tree decoding for predicting mass spectra from molecules",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=n3fPDW87is": {
    "title": "Robust Distributed Learning: Tight Error Bounds and Breakdown Point under Data Heterogeneity",
    "volume": "spotlight",
    "abstract": "The theory underlying robust distributed learning algorithms, designed to resist adversarial machines, matches empirical observations when data is homogeneous. Under data heterogeneity however, which is the norm in practical scenarios, established lower bounds on the learning error are essentially vacuous and greatly mismatch empirical observations. This is because the heterogeneity model considered is too restrictive and does not cover basic learning tasks such as least-squares regression. We consider in this paper a more realistic heterogeneity model, namely $(G,B)$-gradient dissimilarity, and show that it covers a larger class of learning problems than existing theory. Notably, we show that the breakdown point under heterogeneity is lower than the classical fraction $\\frac{1}{2}$. We also prove a new lower bound on the learning error of any distributed learning algorithm. We derive a matching upper bound for a robust variant of distributed gradient descent, and empirically show that our analysis reduces the gap between theory and practice",
    "checked": true,
    "id": "525c77783fbc1e91f45b8ce5f850f3898fba8302",
    "semantic_title": "robust distributed learning: tight error bounds and breakdown point under data heterogeneity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EjMLpTgvKH": {
    "title": "Timewarp: Transferable Acceleration of Molecular Dynamics by Learning Time-Coarsened Dynamics",
    "volume": "spotlight",
    "abstract": "*Molecular dynamics* (MD) simulation is a widely used technique to simulate molecular systems, most commonly at the all-atom resolution where equations of motion are integrated with timesteps on the order of femtoseconds ($1\\textrm{fs}=10^{-15}\\textrm{s}$). MD is often used to compute equilibrium properties, which requires sampling from an equilibrium distribution such as the Boltzmann distribution. However, many important processes, such as binding and folding, occur over timescales of milliseconds or beyond, and cannot be efficiently sampled with conventional MD. Furthermore, new MD simulations need to be performed for each molecular system studied. We present *Timewarp*, an enhanced sampling method which uses a normalising flow as a proposal distribution in a Markov chain Monte Carlo method targeting the Boltzmann distribution. The flow is trained offline on MD trajectories and learns to make large steps in time, simulating the molecular dynamics of $10^{5} - 10^{6} \\textrm{fs}$. Crucially, Timewarp is *transferable* between molecular systems: once trained, we show that it generalises to unseen small peptides (2-4 amino acids) at all-atom resolution, exploring their metastable states and providing wall-clock acceleration of sampling compared to standard MD. Our method constitutes an important step towards general, transferable algorithms for accelerating MD",
    "checked": true,
    "id": "827ca2f16ded73b2df1f760eebb2f1c5c9e5b44b",
    "semantic_title": "timewarp: transferable acceleration of molecular dynamics by learning time-coarsened dynamics",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=4aIpgq1nuI": {
    "title": "What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement",
    "volume": "spotlight",
    "abstract": "The question of what makes a data distribution suitable for deep learning is a fundamental open problem. Focusing on locally connected neural networks (a prevalent family of architectures that includes convolutional and recurrent neural networks as well as local self-attention models), we address this problem by adopting theoretical tools from quantum physics. Our main theoretical result states that a certain locally connected neural network is capable of accurate prediction over a data distribution if and only if the data distribution admits low quantum entanglement under certain canonical partitions of features. As a practical application of this result, we derive a preprocessing method for enhancing the suitability of a data distribution to locally connected neural networks. Experiments with widespread models over various datasets demonstrate our findings. We hope that our use of quantum entanglement will encourage further adoption of tools from physics for formally reasoning about the relation between deep learning and real-world data",
    "checked": true,
    "id": "bd5cacd8dbc8a1cefc1573501bb7cda8ea1a288a",
    "semantic_title": "what makes data suitable for a locally connected neural network? a necessary and sufficient condition based on quantum entanglement",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=81snFfE3vR": {
    "title": "One-step differentiation of iterative algorithms",
    "volume": "spotlight",
    "abstract": "In appropriate frameworks, automatic differentiation is transparent to the user, at the cost of being a significant computational burden when the number of operations is large. For iterative algorithms, implicit differentiation alleviates this issue but requires custom implementation of Jacobian evaluation. In this paper, we study one-step differentiation, also known as Jacobian-free backpropagation, a method as easy as automatic differentiation and as performant as implicit differentiation for fast algorithms (e.g. superlinear optimization methods). We provide a complete theoretical approximation analysis with specific examples (Newton's method, gradient descent) along with its consequences in bilevel optimization. Several numerical examples illustrate the well-foundness of the one-step estimator",
    "checked": true,
    "id": "c8e59a9d0acd91d0cf68b63d7c84127dd63d1cec",
    "semantic_title": "one-step differentiation of iterative algorithms",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=pb1OwZNgr2": {
    "title": "Learning Generalizable Agents via Saliency-guided Features Decorrelation",
    "volume": "spotlight",
    "abstract": "In visual-based Reinforcement Learning (RL), agents often struggle to generalize well to environmental variations in the state space that were not observed during training. The variations can arise in both task-irrelevant features, such as background noise, and task-relevant features, such as robot configurations, that are related to the optimal decisions. To achieve generalization in both situations, agents are required to accurately understand the impact of changed features on the decisions, i.e., establishing the true associations between changed features and decisions in the policy model. However, due to the inherent correlations among features in the state space, the associations between features and decisions become entangled, making it difficult for the policy to distinguish them. To this end, we propose Saliency-Guided Features Decorrelation (SGFD) to eliminate these correlations through sample reweighting. Concretely, SGFD consists of two core techniques: Random Fourier Functions (RFF) and the saliency map. RFF is utilized to estimate the complex non-linear correlations in high-dimensional images, while the saliency map is designed to identify the changed features. Under the guidance of the saliency map, SGFD employs sample reweighting to minimize the estimated correlations related to changed features, thereby achieving decorrelation in visual RL tasks. Our experimental results demonstrate that SGFD can generalize well on a wide range of test environments and significantly outperforms state-of-the-art methods in handling both task-irrelevant variations and task-relevant variations",
    "checked": true,
    "id": "42eb3dd61fcf90c5437b713838b1076ee95bc604",
    "semantic_title": "learning generalizable agents via saliency-guided features decorrelation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ikkdTD3hQJ": {
    "title": "AIMS: All-Inclusive Multi-Level Segmentation for Anything",
    "volume": "spotlight",
    "abstract": "Despite the progress of image segmentation for accurate visual entity segmentation, completing the diverse requirements of image editing applications for different-level region-of-interest selections remains unsolved. In this paper, we propose a new task, All-Inclusive Multi-Level Segmentation (AIMS), which segments visual regions into three levels: part, entity, and relation (two entities with some semantic relationships). We also build a unified AIMS model through multi-dataset multi-task training to address the two major challenges of annotation inconsistency and task correlation. Specifically, we propose task complementarity, association, and prompt mask encoder for three-level predictions. Extensive experiments demonstrate the effectiveness and generalization capacity of our method compared to other state-of-the-art methods on a single dataset or the concurrent work on segment anything. We will make our code and training model publicly available",
    "checked": false,
    "id": "e7de0864c2bef274471399782f5bd35498853895",
    "semantic_title": "aims: all-inclusive multi-level segmentation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=TcmjewOAd1": {
    "title": "L-CAD: Language-based Colorization with Any-level Descriptions using Diffusion Priors",
    "volume": "spotlight",
    "abstract": "Language-based colorization produces plausible and visually pleasing colors under the guidance of user-friendly natural language descriptions. Previous methods implicitly assume that users provide comprehensive color descriptions for most of the objects in the image, which leads to suboptimal performance. In this paper, we propose a unified model to perform language-based colorization with any-level descriptions. We leverage the pretrained cross-modality generative model for its robust language understanding and rich color priors to handle the inherent ambiguity of any-level descriptions. We further design modules to align with input conditions to preserve local spatial structures and prevent the ghosting effect. With the proposed novel sampling strategy, our model achieves instance-aware colorization in diverse and complex scenarios. Extensive experimental results demonstrate our advantages of effectively handling any-level descriptions and outperforming both language-based and automatic colorization methods. The code and pretrained models are available at: https://github.com/changzheng123/L-CAD",
    "checked": false,
    "id": "460bdd9ccb95ad788c913c6a4d93c400cc71c432",
    "semantic_title": "l-cad: language-based colorization with any-level descriptions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mmmd2vp0n0": {
    "title": "Transient Neural Radiance Fields for Lidar View Synthesis and 3D Reconstruction",
    "volume": "spotlight",
    "abstract": "Neural radiance fields (NeRFs) have become a ubiquitous tool for modeling scene appearance and geometry from multiview imagery. Recent work has also begun to explore how to use additional supervision from lidar or depth sensor measurements in the NeRF framework. However, previous lidar-supervised NeRFs focus on rendering conventional camera imagery and use lidar-derived point cloud data as auxiliary supervision; thus, they fail to incorporate the underlying image formation model of the lidar. Here, we propose a novel method for rendering transient NeRFs that take as input the raw, time-resolved photon count histograms measured by a single-photon lidar system, and we seek to render such histograms from novel views. Different from conventional NeRFs, the approach relies on a time-resolved version of the volume rendering equation to render the lidar measurements and capture transient light transport phenomena at picosecond timescales. We evaluate our method on a first-of-its-kind dataset of simulated and captured transient multiview scans from a prototype single-photon lidar. Overall, our work brings NeRFs to a new dimension of imaging at transient timescales, newly enabling rendering of transient imagery from novel views. Additionally, we show that our approach recovers improved geometry and conventional appearance compared to point cloud-based supervision when training on few input viewpoints. Transient NeRFs may be especially useful for applications which seek to simulate raw lidar measurements for downstream tasks in autonomous driving, robotics, and remote sensing",
    "checked": true,
    "id": "3fd9eecb47d769fda066423b71112e56dd85ca95",
    "semantic_title": "transient neural radiance fields for lidar view synthesis and 3d reconstruction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ETk6cfS3vk": {
    "title": "SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models",
    "volume": "spotlight",
    "abstract": "Object-centric learning aims to represent visual data with a set of object entities (a.k.a. slots), providing structured representations that enable systematic generalization. Leveraging advanced architectures like Transformers, recent approaches have made significant progress in unsupervised object discovery. In addition, slot-based representations hold great potential for generative modeling, such as controllable image generation and object manipulation in image editing. However, current slot-based methods often produce blurry images and distorted objects, exhibiting poor generative modeling capabilities. In this paper, we focus on improving slot-to-image decoding, a crucial aspect for high-quality visual generation. We introduce SlotDiffusion -- an object-centric Latent Diffusion Model (LDM) designed for both image and video data. Thanks to the powerful modeling capacity of LDMs, SlotDiffusion surpasses previous slot models in unsupervised object segmentation and visual generation across six datasets. Furthermore, our learned object features can be utilized by existing object-centric dynamics models, improving video prediction quality and downstream temporal reasoning tasks. Finally, we demonstrate the scalability of SlotDiffusion to unconstrained real-world datasets such as PASCAL VOC and COCO, when integrated with self-supervised pre-trained image encoders",
    "checked": true,
    "id": "df67a069d7425a2075f26681bc40c45901cfa67e",
    "semantic_title": "slotdiffusion: object-centric generative modeling with diffusion models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=z06npyCwDq": {
    "title": "Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers",
    "volume": "spotlight",
    "abstract": "Transformers have achieved great success in machine learning applications. Normalization techniques, such as Layer Normalization (LayerNorm, LN) and Root Mean Square Normalization (RMSNorm), play a critical role in accelerating and stabilizing the training of Transformers. While LayerNorm recenters and rescales input vectors, RMSNorm only rescales the vectors by their RMS value. Despite being more computationally efficient, RMSNorm may compromise the representation ability of Transformers. There is currently no consensus regarding the preferred normalization technique, as some models employ LayerNorm while others utilize RMSNorm, especially in recent large language models. It is challenging to convert Transformers with one normalization to the other type. While there is an ongoing disagreement between the two normalization types, we propose a solution to unify two mainstream Transformer architectures, Pre-LN and Pre-RMSNorm Transformers. By removing the inherent redundant mean information in the main branch of Pre-LN Transformers, we can reduce LayerNorm to RMSNorm, achieving higher efficiency. We further propose the Compressed RMSNorm (CRMSNorm) and Pre-CRMSNorm Transformer based on a lossless compression of the zero-mean vectors. We formally establish the equivalence of Pre-LN, Pre-RMSNorm, and Pre-CRMSNorm Transformer variants in both training and inference. It implies that Pre-LN Transformers can be substituted with Pre-(C)RMSNorm counterparts at almost no cost, offering the same arithmetic functionality along with free efficiency improvement. Experiments demonstrate that we can reduce the training and inference time of Pre-LN Transformers by 1% - 10%",
    "checked": true,
    "id": "e4f10c448aaea9cba800e8ed324c46f13725e952",
    "semantic_title": "pre-rmsnorm and pre-crmsnorm transformers: equivalent and efficient pre-ln transformers",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=2doqt9r0r0": {
    "title": "Efficient Online Clustering with Moving Costs",
    "volume": "spotlight",
    "abstract": "In this work we consider an online learning problem, called Online $k$-Clustering with Moving Costs, at which a learner maintains a set of $k$ facilities over $T$ rounds so as to minimize the connection cost of an adversarially selected sequence of clients. The learner is informed on the positions of the clients at each round $t$ only after its facility-selection and can use this information to update its decision in the next round. However, updating the facility positions comes with an additional moving cost based on the moving distance of the facilities. We present the first $\\mathcal{O}(\\log n)$-regret polynomial-time online learning algorithm guaranteeing that the overall cost (connection $+$ moving) is at most $\\mathcal{O}(\\log n)$ times the time-averaged connection cost of the best fixed solution. Our work improves on the recent result of (Fotakis et al., 2021) establishing $\\mathcal{O}(k)$-regret guarantees only on the connection cost",
    "checked": false,
    "id": "046fcc0c44333776a035f5a642c3315c9470c91e",
    "semantic_title": "cost-effective and adaptive clustering algorithm for stream processing on cloud system",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=I9xE1Jsjfx": {
    "title": "Evaluating and Inducing Personality in Pre-trained Language Models",
    "volume": "spotlight",
    "abstract": "Standardized and quantified evaluation of machine behaviors is a crux of understanding LLMs. In this study, we draw inspiration from psychometric studies by leveraging human personality theory as a tool for studying machine behaviors. Originating as a philosophical quest for human behaviors, the study of personality delves into how individuals differ in thinking, feeling, and behaving. Toward building and understanding human-like social machines, we are motivated to ask: Can we assess machine behaviors by leveraging human psychometric tests in a **principled** and **quantitative** manner? If so, can we induce a specific personality in LLMs? To answer these questions, we introduce the Machine Personality Inventory (MPI) tool for studying machine behaviors; MPI follows standardized personality tests, built upon the Big Five Personality Factors (Big Five) theory and personality assessment inventories. By systematically evaluating LLMs with MPI, we provide the first piece of evidence demonstrating the efficacy of MPI in studying LLMs behaviors. We further devise a Personality Prompting (P$^2$) method to induce LLMs with specific personalities in a **controllable** way, capable of producing diverse and verifiable behaviors. We hope this work sheds light on future studies by adopting personality as the essential indicator for various downstream tasks, and could further motivate research into equally intriguing human-like machine behaviors",
    "checked": true,
    "id": "e30a39570bf8a153bae86a6afde00983be9d7d73",
    "semantic_title": "evaluating and inducing personality in pre-trained language models",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=jkPDRHff3s": {
    "title": "Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory",
    "volume": "spotlight",
    "abstract": "Since their inception, Variational Autoencoders (VAEs) have become central in machine learning. Despite their widespread use, numerous questions regarding their theoretical properties remain open. Using PAC-Bayesian theory, this work develops statistical guarantees for VAEs. First, we derive the first PAC-Bayesian bound for posterior distributions conditioned on individual samples from the data-generating distribution. Then, we utilize this result to develop generalization guarantees for the VAE's reconstruction loss, as well as upper bounds on the distance between the input and the regenerated distributions. More importantly, we provide upper bounds on the Wasserstein distance between the input distribution and the distribution defined by the VAE's generative model",
    "checked": true,
    "id": "aed9fd4f7c29001baaa3030a0f8fd20bd8713c2f",
    "semantic_title": "statistical guarantees for variational autoencoders using pac-bayesian theory",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Izt7rDD7jN": {
    "title": "Smoothed Online Learning for Prediction in Piecewise Affine Systems",
    "volume": "spotlight",
    "abstract": "The problem of piecewise affine (PWA) regression and planning is of foundational importance to the study of online learning, control, and robotics, where it provides a theoretically and empirically tractable setting to study systems undergoing sharp changes in the dynamics. Unfortunately, due to the discontinuities that arise when crossing into different ``pieces,'' learning in general sequential settings is impossible and practical algorithms are forced to resort to heuristic approaches. This paper builds on the recently developed smoothed online learning framework and provides the first algorithms for prediction and simulation in PWA systems whose regret is polynomial in all relevant problem parameters under a weak smoothness assumption; moreover, our algorithms are efficient in the number of calls to an optimization oracle. We further apply our results to the problems of one-step prediction and multi-step simulation regret in piecewise affine dynamical systems, where the learner is tasked with simulating trajectories and regret is measured in terms of the Wasserstein distance between simulated and true data. Along the way, we develop several technical tools of more general interest",
    "checked": true,
    "id": "7f091914bd374751eba1a10223c9d5474817d3dc",
    "semantic_title": "smoothed online learning for prediction in piecewise affine systems",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=bfmSc1ETT9": {
    "title": "Kiki or Bouba? Sound Symbolism in Vision-and-Language Models",
    "volume": "spotlight",
    "abstract": "Although the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism. Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain. In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion. Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools. Our code will be made publicly available",
    "checked": true,
    "id": "84f53210891bfbdce3336c855b5bd0c0381270cb",
    "semantic_title": "kiki or bouba? sound symbolism in vision-and-language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ARrwf7Ev2T": {
    "title": "Dense and Aligned Captions (DAC) Promote Compositional Reasoning in VL Models",
    "volume": "spotlight",
    "abstract": "Vision and Language (VL) models offer an effective method for aligning representation spaces of images and text allowing for numerous applications such as cross-modal retrieval, visual and multi-hop question answering, captioning, and many more. However, the aligned image-text spaces learned by all the popular VL models are still suffering from the so-called 'object bias' - their representations behave as 'bags of nouns' mostly ignoring or downsizing the attributes, relations, and states of objects described/appearing in texts/images. Although some great attempts at fixing these `compositional reasoning' issues were proposed in the recent literature, the problem is still far from being solved. In this paper, we uncover two factors limiting the VL models' compositional reasoning performance. These two factors are properties of the paired VL dataset used for finetuning (or pre-training) the VL model: (i) the caption quality, or in other words 'image-alignment', of the texts; and (ii) the 'density' of the captions in the sense of mentioning all the details appearing on the image. We propose a fine-tuning approach for automatically treating these factors on a standard collection of paired VL data (CC3M). Applied to CLIP, we demonstrate its significant compositional reasoning performance increase of up to $\\sim27$\\% over the base model, up to $\\sim20$\\% over the strongest baseline, and by $6.7$\\% on average. Our code is provided in the Supplementary and would be released upon acceptance",
    "checked": true,
    "id": "5fb7afae5fcacae1d40f109a348b43e00aa5d486",
    "semantic_title": "dense and aligned captions (dac) promote compositional reasoning in vl models",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=vA0vj1mY77": {
    "title": "MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion",
    "volume": "spotlight",
    "abstract": "This paper introduces MVDiffusion, a simple yet effective multi-view image generation method for scenarios where pixel-to-pixel correspondences are available, such as perspective crops from panorama or multi-view images given geometry (depth maps and poses). Unlike prior methods that rely on iterative image warping and inpainting, MVDiffusion concurrently generates all images with a global awareness, encompassing high resolution and rich content, effectively addressing the error accumulation prevalent in preceding models. MVDiffusion specifically incorporates a correspondence-aware attention mechanism, enabling effective cross-view interaction. This mechanism underpins three pivotal modules: 1) a generation module that produces low-resolution images while maintaining global correspondence, 2) an interpolation module that densifies spatial coverage between images, and 3) a super-resolution module that upscales into high-resolution images. In terms of panoramic imagery, MVDiffusion generates high-resolution photorealistic images up to 1024*1024 pixels. For geometry-conditioned multi-view image generation, MVDiffusion demonstrates state-of-the-art performance on texture-map generation for a given scene mesh. We recommend referring to our Arxiv version at https://arxiv.org/pdf/2307.01097.pdf for the latest update. The project page is at https://mvdiffusion.github.io/",
    "checked": true,
    "id": "87a6fa722b2eacf7fc6470a493f49ce8809f4543",
    "semantic_title": "mvdiffusion: enabling holistic multi-view image generation with correspondence-aware diffusion",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=MziFFGjpkb": {
    "title": "A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation",
    "volume": "spotlight",
    "abstract": "In recent years, concept-based approaches have emerged as some of the most promising explainability methods to help us interpret the decisions of Artificial Neural Networks (ANNs). These methods seek to discover intelligible visual ``concepts'' buried within the complex patterns of ANN activations in two key steps: (1) concept extraction followed by (2) importance estimation. While these two steps are shared across methods, they all differ in their specific implementations. Here, we introduce a unifying theoretical framework that recast the first step -- concept extraction problem -- as a special case of **dictionary learning**, and we formalize the second step -- concept importance estimation -- as a more general form of **attribution method**. This framework offers several advantages as it allows us: (i) to propose new evaluation metrics for comparing different concept extraction approaches; (ii) to leverage modern attribution methods and evaluation metrics to extend and systematically evaluate state-of-the-art concept-based approaches and importance estimation techniques; (iii) to derive theoretical guarantees regarding the optimality of such methods. We further leverage our framework to try to tackle a crucial question in explainability: how to *efficiently* identify clusters of data points that are classified based on a similar shared strategy. To illustrate these findings and to highlight the main strategies of a model, we introduce a visual representation called the strategic cluster graph. Finally, we present Lens, a dedicated website that offers a complete compilation of these visualizations for all classes of the ImageNet dataset",
    "checked": true,
    "id": "d83a51ae59a7c47922cfa12c56e2a8c5a5f11172",
    "semantic_title": "a holistic approach to unifying automatic concept extraction and concept importance estimation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=i39yXaUKuF": {
    "title": "Segment Any Point Cloud Sequences by Distilling Vision Foundation Models",
    "volume": "spotlight",
    "abstract": "Recent advancements in vision foundation models (VFMs) have opened up new possibilities for versatile and efficient visual perception. In this work, we introduce Seal, a novel framework that harnesses VFMs for segmenting diverse automotive point cloud sequences. Seal exhibits three appealing properties: i) Scalability: VFMs are directly distilled into point clouds, obviating the need for annotations in either 2D or 3D during pretraining. ii) Consistency: Spatial and temporal relationships are enforced at both the camera-to-LiDAR and point-to-segment regularization stages, facilitating cross-modal representation learning. iii) Generalizability: Seal enables knowledge transfer in an off-the-shelf manner to downstream tasks involving diverse point clouds, including those from real/synthetic, low/high-resolution, large/small-scale, and clean/corrupted datasets. Extensive experiments conducted on eleven different point cloud datasets showcase the effectiveness and superiority of Seal. Notably, Seal achieves a remarkable 45.0% mIoU on nuScenes after linear probing, surpassing random initialization by 36.9% mIoU and outperforming prior arts by 6.1% mIoU. Moreover, Seal demonstrates significant performance gains over existing methods across 20 different few-shot fine-tuning tasks on all eleven tested point cloud datasets. The code is available at this link",
    "checked": true,
    "id": "c6639aa87101f76c11fcfb4f69193a55363050d3",
    "semantic_title": "segment any point cloud sequences by distilling vision foundation models",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=GEWzHeHpLr": {
    "title": "Transition-constant Normalization for Image Enhancement",
    "volume": "spotlight",
    "abstract": "Normalization techniques that capture image style by statistical representation have become a popular component in deep neural networks. Although image enhancement can be considered as a form of style transformation, there has been little exploration of how normalization affect the enhancement performance. To fully leverage the potential of normalization, we present a novel Transition-Constant Normalization (TCN) for various image enhancement tasks. Specifically, it consists of two streams of normalization operations arranged under an invertible constraint, along with a feature sub-sampling operation that satisfies the normalization constraint. TCN enjoys several merits, including being parameter-free, plug-and-play, and incurring no additional computational costs. We provide various formats to utilize TCN for image enhancement, including seamless integration with enhancement networks, incorporation into encoder-decoder architectures for downsampling, and implementation of efficient architectures. Through extensive experiments on multiple image enhancement tasks, like low-light enhancement, exposure correction, SDR2HDR translation, and image dehazing, our TCN consistently demonstrates performance improvements. Besides, it showcases extensive ability in other tasks including pan-sharpening and medical segmentation. The code is available at \\textit{\\textcolor{blue}{https://github.com/huangkevinj/TCNorm}}",
    "checked": false,
    "id": "36f58cc9966ee4b1487d7846753fa3ec1f39333a",
    "semantic_title": "maize disease recognition based on image enhancement and oscrnet",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tesBViWnbx": {
    "title": "Stable Diffusion is Unstable",
    "volume": "spotlight",
    "abstract": "Recently, text-to-image models have been thriving. Despite their powerful generative capacity, our research has uncovered a lack of robustness in this generation process. Specifically, the introduction of small perturbations to the text prompts can result in the blending of primary subjects with other categories or their complete disappearance in the generated images. In this paper, we propose **Auto-attack on Text-to-image Models (ATM)**, a gradient-based approach, to effectively and efficiently generate such perturbations. By learning a Gumbel Softmax distribution, we can make the discrete process of word replacement or extension continuous, thus ensuring the differentiability of the perturbation generation. Once the distribution is learned, ATM can sample multiple attack samples simultaneously. These attack samples can prevent the generative model from generating the desired subjects without tampering with the category keywords in the prompt. ATM has achieved a 91.1\\% success rate in short-text attacks and an 81.2\\% success rate in long-text attacks. Further empirical analysis revealed three attack patterns based on: 1) variability in generation speed, 2) similarity of coarse-grained characteristics, and 3) polysemy of words. The code is available at https://github.com/duchengbin8/Stable_Diffusion_is_Unstable",
    "checked": true,
    "id": "9523e62dc3a1195bb6e7bf9678664b48f0c84257",
    "semantic_title": "stable diffusion is unstable",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=LGqIAn2OaZ": {
    "title": "Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes",
    "volume": "spotlight",
    "abstract": "Tensor decomposition is an important tool for multiway data analysis. In practice, the data is often sparse yet associated with rich temporal information. Existing methods, however, often under-use the time information and ignore the structural knowledge within the sparsely observed tensor entries. To overcome these limitations and to better capture the underlying temporal structure, we propose Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE). We develop a neural diffusion-reaction process to estimate dynamic embeddings for the entities in each tensor mode. Specifically, based on the observed tensor entries, we build a multi-partite graph to encode the correlation between the entities. We construct a graph diffusion process to co-evolve the embedding trajectories of the correlated entities and use a neural network to construct a reaction process for each individual entity. In this way, our model can capture both the commonalities and personalities during the evolution of the embeddings for different entities. We then use a neural network to model the entry value as a nonlinear function of the embedding trajectories. For model estimation, we combine ODE solvers to develop a stochastic mini-batch learning algorithm. We propose a stratified sampling method to balance the cost of processing each mini-batch so as to improve the overall efficiency. We show the advantage of our approach in both simulation studies and real-world applications. The code is available at https://github.com/wzhut/Dynamic-Tensor-Decomposition-via-Neural-Diffusion-Reaction-Processes",
    "checked": true,
    "id": "271348cff183ce7475674f237917e1a79911582c",
    "semantic_title": "dynamic tensor decomposition via neural diffusion-reaction processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u6Ibs4hTJH": {
    "title": "Real-World Image Variation by Aligning Diffusion Inversion Chain",
    "volume": "spotlight",
    "abstract": "Recent diffusion model advancements have enabled high-fidelity images to be generated using text prompts. However, a domain gap exists between generated images and real-world images, which poses a challenge in generating high-quality variations of real-world images. Our investigation uncovers that this domain gap originates from a latents' distribution gap in different diffusion processes. To address this issue, we propose a novel inference pipeline called Real-world Image Variation by ALignment (RIVAL) that utilizes diffusion models to generate image variations from a single image exemplar. Our pipeline enhances the generation quality of image variations by aligning the image generation process to the source image's inversion chain. Specifically, we demonstrate that step-wise latent distribution alignment is essential for generating high-quality variations. To attain this, we design a cross-image self-attention injection for feature interaction and a step-wise distribution normalization to align the latent features. Incorporating these alignment processes into a diffusion model allows RIVAL to generate high-quality image variations without further parameter optimization. Our experimental results demonstrate that our proposed approach outperforms existing methods concerning semantic similarity and perceptual quality. This generalized inference pipeline can be easily applied to other diffusion-based generation tasks, such as image-conditioned text-to-image generation and stylization. Project page: https://rival-diff.github.io",
    "checked": true,
    "id": "83ce9f983bf0d3691cdea9bb5beffa7e4f970a4d",
    "semantic_title": "real-world image variation by aligning diffusion inversion chain",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=WPdGRRJaPb": {
    "title": "Full-Atom Protein Pocket Design via Iterative Refinement",
    "volume": "spotlight",
    "abstract": "The design of \\emph{de novo} functional proteins that bind with specific ligand molecules is crucial in various domains like therapeutics and bio-engineering. One vital yet challenging step is to design the protein pocket, the cavity region of protein where the ligand binds with. Existing methods suffer from inefficient generation, insufficient context modeling (ligand molecule), and incapability of generating sidechain atoms. To overcome the limitations, we propose a \\textbf{F}ull-\\textbf{A}tom \\textbf{I}terative \\textbf{R}efinement framework (\\textbf{FAIR}) for protein pocket sequence (i.e., residue types) and 3D structure co-design. Generally, FAIR consists of two steps that follow a coarse-to-fine pipeline (backbone atoms to full atoms including sidechain) for full-atom generation. For efficiency, all residue types and structures are updated together in each round (i.e., full-shot refinement). In the first step, the residue types and backbone coordinates are updated with a hierarchical context encoder and two structure refinement modules capturing inter-residue and pocket-ligand interactions. The second step further models the sidechain atoms of pockets and updates residue types to achieve sequence-structure consistency. The structure of the binding ligand is also updated along with the above refinement iterations accounting for its flexibility. Finally, extensive evaluations show that FAIR outperforms baselines in efficiently designing high-quality pocket sequences and structures. Specifically, the average improvements on AAR and RMSD are over 10$\\%$",
    "checked": true,
    "id": "7850333f1958889d73e262831d3c4587120abd91",
    "semantic_title": "full-atom protein pocket design via iterative refinement",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=iT9MOAZqsb": {
    "title": "Adversarial Training from Mean Field Perspective",
    "volume": "spotlight",
    "abstract": "Although adversarial training is known to be effective against adversarial examples, training dynamics are not well understood. In this study, we present the first theoretical analysis of adversarial training in random deep neural networks without any assumptions on data distributions. We introduce a new theoretical framework based on mean field theory, which addresses the limitations of existing mean field-based approaches. Based on the framework, we derive the (empirically tight) upper bounds of $\\ell_q$ norm-based adversarial loss with $\\ell_p$ norm-based adversarial examples for various values of $p$ and $q$. Moreover, we prove that networks without shortcuts are generally not adversarially trainable and that adversarial training reduces network capacity. We also show that the network width alleviates these issues. Furthermore, the various impacts of input and output dimensions on the upper bounds and time evolution of weight variance are presented",
    "checked": false,
    "id": "ffeaa70ae5e1280bafb29cc2d9fe80aae340eb70",
    "semantic_title": "domain adversarial training: a game perspective",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=dZqcC1qCmB": {
    "title": "Epistemic Neural Networks",
    "volume": "spotlight",
    "abstract": "Intelligence relies on an agent's knowledge of what it does not know. This capability can be assessed based on the quality of joint predictions of labels across multiple inputs. In principle, ensemble-based approaches can produce effective joint predictions, but the computational costs of large ensembles become prohibitive. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform very large ensembles, consisting of hundreds or more particles, with orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks. To accommodate development of approaches beyond BNNs, such as the epinet, we introduce the epistemic neural network (ENN) as a general interface for models that produce joint predictions",
    "checked": true,
    "id": "1106f88502c8681c774a63fd1553fb98525fe2fa",
    "semantic_title": "epistemic neural networks",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=aLLuYpn83y": {
    "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model",
    "volume": "spotlight",
    "abstract": "We introduce Inference-Time Intervention (ITI), a technique designed to enhance the \"truthfulness\" of large language models (LLMs). ITI operates by shifting model activations during inference, following a learned set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from $32.5\\%$ to $65.1\\%$. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface",
    "checked": true,
    "id": "405f8f5f1c6df1b3343c812832479aad5180b65f",
    "semantic_title": "inference-time intervention: eliciting truthful answers from a language model",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=vtLNwa6uX0": {
    "title": "The Geometry of Neural Nets' Parameter Spaces Under Reparametrization",
    "volume": "spotlight",
    "abstract": "Model reparametrization, which follows the change-of-variable rule of calculus, is a popular way to improve the training of neural nets. But it can also be problematic since it can induce inconsistencies in, e.g., Hessian-based flatness measures, optimization trajectories, and modes of probability densities. This complicates downstream analyses: e.g. one cannot definitively relate flatness with generalization since arbitrary reparametrization changes their relationship. In this work, we study the invariance of neural nets under reparametrization from the perspective of Riemannian geometry. From this point of view, invariance is an inherent property of any neural net _if_ one explicitly represents the metric and uses the correct associated transformation rules. This is important since although the metric is always present, it is often implicitly assumed as identity, and thus dropped from the notation, then lost under reparametrization. We discuss implications for measuring the flatness of minima, optimization, and for probability-density maximization. Finally, we explore some interesting directions where invariance is useful",
    "checked": true,
    "id": "77e999252bd2bbb6f59df32d317dec02f92c6302",
    "semantic_title": "the geometry of neural nets' parameter spaces under reparametrization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=XeMryhpniy": {
    "title": "Hierarchical Integration Diffusion Model for Realistic Image Deblurring",
    "volume": "spotlight",
    "abstract": "Diffusion models (DMs) have recently been introduced in image deblurring and exhibited promising performance, particularly in terms of details reconstruction. However, the diffusion model requires a large number of inference iterations to recover the clean image from pure Gaussian noise, which consumes massive computational resources. Moreover, the distribution synthesized by the diffusion model is often misaligned with the target results, leading to restrictions in distortion-based metrics. To address the above issues, we propose the Hierarchical Integration Diffusion Model (HI-Diff), for realistic image deblurring. Specifically, we perform the DM in a highly compacted latent space to generate the prior feature for the deblurring process. The deblurring process is implemented by a regression-based method to obtain better distortion accuracy. Meanwhile, the highly compact latent space ensures the efficiency of the DM. Furthermore, we design the hierarchical integration module to fuse the prior into the regression-based model from multiple scales, enabling better generalization in complex blurry scenarios. Comprehensive experiments on synthetic and real-world blur datasets demonstrate that our HI-Diff outperforms state-of-the-art methods. Code and trained models are available at https://github.com/zhengchen1999/HI-Diff",
    "checked": true,
    "id": "ea2feb30a758519672e876bd1ff6f05b859e308e",
    "semantic_title": "hierarchical integration diffusion model for realistic image deblurring",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=1IOU2329Za": {
    "title": "Banana: Banach Fixed-Point Network for Pointcloud Segmentation with Inter-Part Equivariance",
    "volume": "spotlight",
    "abstract": "Equivariance has gained strong interest as a desirable network property that inherently ensures robust generalization. However, when dealing with complex systems such as articulated objects or multi-object scenes, effectively capturing inter-part transformations poses a challenge, as it becomes entangled with the overall structure and local transformations. The interdependence of part assignment and per-part group action necessitates a novel equivariance formulation that allows for their co-evolution. In this paper, we present Banana, a Banach fixed-point network for equivariant segmentation with inter-part equivariance by construction. Our key insight is to iteratively solve a fixed-point problem, where point-part assignment labels and per-part SE(3)-equivariance co-evolve simultaneously. We provide theoretical derivations of both per-step equivariance and global convergence, which induces an equivariant final convergent state. Our formulation naturally provides a strict definition of inter-part equivariance that generalizes to unseen inter-part configurations. Through experiments conducted on both articulated objects and multi-object scans, we demonstrate the efficacy of our approach in achieving strong generalization under inter-part transformations, even when confronted with substantial changes in pointcloud geometry and topology",
    "checked": true,
    "id": "6c1064cbb45259732ef8032b105f5121a67d27ef",
    "semantic_title": "banana: banach fixed-point network for pointcloud segmentation with inter-part equivariance",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=WjWifKqmcG": {
    "title": "Differentiable Registration of Images and LiDAR Point Clouds with VoxelPoint-to-Pixel Matching",
    "volume": "spotlight",
    "abstract": "Cross-modality registration between 2D images captured by cameras and 3D point clouds from LiDARs is a crucial task in computer vision and robotic. Previous methods estimate 2D-3D correspondences by matching point and pixel patterns learned by neural networks, and use Perspective-n-Points (PnP) to estimate rigid transformation during post-processing. However, these methods struggle to map points and pixels to a shared latent space robustly since points and pixels have very different characteristics with patterns learned in different manners (MLP and CNN), and they also fail to construct supervision directly on the transformation since the PnP is non-differentiable, which leads to unstable registration results. To address these problems, we propose to learn a structured cross-modality latent space to represent pixel features and 3D features via a differentiable probabilistic PnP solver. Specifically, we design a triplet network to learn VoxelPoint-to-Pixel matching, where we represent 3D elements using both voxels and points to learn the cross-modality latent space with pixels. We design both the voxel and pixel branch based on CNNs to operate convolutions on voxels/pixels represented in grids, and integrate an additional point branch to regain the information lost during voxelization. We train our framework end-to-end by imposing supervisions directly on the predicted pose distribution with a probabilistic PnP solver. To explore distinctive patterns of cross-modality features, we design a novel loss with adaptive-weighted optimization for cross-modality feature description. The experimental results on KITTI and nuScenes datasets show significant improvements over the state-of-the-art methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fpzA8uRA95": {
    "title": "Efficient Adversarial Contrastive Learning via Robustness-Aware Coreset Selection",
    "volume": "spotlight",
    "abstract": "Adversarial contrastive learning (ACL) does not require expensive data annotations but outputs a robust representation that withstands adversarial attacks and also generalizes to a wide range of downstream tasks. However, ACL needs tremendous running time to generate the adversarial variants of all training data, which limits its scalability to large datasets. To speed up ACL, this paper proposes a robustness-aware coreset selection (RCS) method. RCS does not require label information and searches for an informative subset that minimizes a representational divergence, which is the distance of the representation between natural data and their virtual adversarial variants. The vanilla solution of RCS via traversing all possible subsets is computationally prohibitive. Therefore, we theoretically transform RCS into a surrogate problem of submodular maximization, of which the greedy search is an efficient solution with an optimality guarantee for the original problem. Empirically, our comprehensive results corroborate that RCS can speed up ACL by a large margin without significantly hurting the robustness transferability. Notably, to the best of our knowledge, we are the first to conduct ACL efficiently on the large-scale ImageNet-1K dataset to obtain an effective robust representation via RCS. Our source code is at https://github.com/GodXuxilie/Efficient_ACL_via_RCS",
    "checked": true,
    "id": "1615ae4f94299d97104ad8a295336ccb3fc275b9",
    "semantic_title": "efficient adversarial contrastive learning via robustness-aware coreset selection",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=QwvaqV48fB": {
    "title": "Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends",
    "volume": "spotlight",
    "abstract": "Learning binary classifiers from positive and unlabeled data (PUL) is vital in many real-world applications, especially when verifying negative examples is difficult. Despite the impressive empirical performance of recent PUL methods, challenges like accumulated errors and increased estimation bias persist due to the absence of negative labels. In this paper, we unveil an intriguing yet long-overlooked observation in PUL: \\textit{resampling the positive data in each training iteration to ensure a balanced distribution between positive and unlabeled examples results in strong early-stage performance. Furthermore, predictive trends for positive and negative classes display distinctly different patterns.} Specifically, the scores (output probability) of unlabeled negative examples consistently decrease, while those of unlabeled positive examples show largely chaotic trends. Instead of focusing on classification within individual time frames, we innovatively adopt a holistic approach, interpreting the scores of each example as a temporal point process (TPP). This reformulates the core problem of PUL as recognizing trends in these scores. We then propose a novel TPP-inspired measure for trend detection and prove its asymptotic unbiasedness in predicting changes. Notably, our method accomplishes PUL without requiring additional parameter tuning or prior assumptions, offering an alternative perspective for tackling this problem. Extensive experiments verify the superiority of our method, particularly in a highly imbalanced real-world setting, where it achieves improvements of up to $11.3\\%$ in key metrics",
    "checked": true,
    "id": "cda12226872833f5cabb7d5c16fc6252e157299a",
    "semantic_title": "beyond myopia: learning from positive and unlabeled data through holistic predictive trends",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cnpkzQZaLU": {
    "title": "Context-PIPs: Persistent Independent Particles Demands Context Features",
    "volume": "spotlight",
    "abstract": "We tackle the problem of Persistent Independent Particles (PIPs), also called Tracking Any Point (TAP), in videos, which specifically aims at estimating persistent long-term trajectories of query points in videos. Previous methods attempted to estimate these trajectories independently to incorporate longer image sequences, therefore, ignoring the potential benefits of incorporating spatial context features. We argue that independent video point tracking also demands spatial context features. To this end, we propose a novel framework Context-PIPs, which effectively improves point trajectory accuracy by aggregating spatial context features in videos. Context-PIPs contains two main modules: 1) a SOurse Feature Enhancement (SOFE) module, and 2) a TArget Feature Aggregation (TAFA) module. Context-PIPs significantly improves PIPs all-sided, reducing 11.4\\% Average Trajectory Error of Occluded Points (ATE-Occ) on CroHD and increasing 11.8\\% Average Percentage of Correct Keypoint (A-PCK) on TAP-Vid-Kinectics. Demos are available at \\url{https://wkbian.github.io/Projects/Context-PIPs/}",
    "checked": false,
    "id": "16dcb3a8498ee55f53eac5bef8683d7983554ad7",
    "semantic_title": "context-tap: tracking any point demands spatial context features",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Jw0KRTjsGA": {
    "title": "CODA: Generalizing to Open and Unseen Domains with Compaction and Disambiguation",
    "volume": "spotlight",
    "abstract": "The generalization capability of machine learning systems degenerates notably when the test distribution drifts from the training distribution. Recently, Domain Generalization (DG) has been gaining momentum in enabling machine learning models to generalize to unseen domains. However, most DG methods assume that training and test data share an identical label space, ignoring the potential unseen categories in many real-world applications. In this paper, we delve into a more general but difficult problem termed Open Test-Time DG (OTDG), where both domain shift and open class may occur on the unseen test data. We propose Compaction and Disambiguation (CODA), a novel two-stage framework for learning compact representations and adapting to open classes in the wild. To meaningfully regularize the model's decision boundary, CODA introduces virtual unknown classes and optimizes a new training objective to insert unknowns into the latent space by compacting the embedding space of source known classes. To adapt target samples to the source model, we then disambiguate the decision boundaries between known and unknown classes with a test-time training objective, mitigating the adaptivity gap and catastrophic forgetting challenges. Experiments reveal that CODA can significantly outperform the previous best method on standard DG datasets and harmonize the classification accuracy between known and unknown classes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vtoY8qJjTR": {
    "title": "Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "Offline-to-online reinforcement learning (RL) is a training paradigm that combines pre-training on a pre-collected dataset with fine-tuning in an online environment. However, the incorporation of online fine-tuning can intensify the well-known distributional shift problem. Existing solutions tackle this problem by imposing a policy constraint on the policy improvement objective in both offline and online learning. They typically advocate a single balance between policy improvement and constraints across diverse data collections. This one-size-fits-all manner may not optimally leverage each collected sample due to the significant variation in data quality across different states. To this end, we introduce Family Offline-to-Online RL (FamO2O), a simple yet effective framework that empowers existing algorithms to determine state-adaptive improvement-constraint balances. FamO2O utilizes a universal model to train a family of policies with different improvement/constraint intensities, and a balance model to select a suitable policy for each state. Theoretically, we prove that state-adaptive balances are necessary for achieving a higher policy performance upper bound. Empirically, extensive experiments show that FamO2O offers a statistically significant improvement over various existing methods, achieving state-of-the-art performance on the D4RL benchmark. Codes are available at https://github.com/LeapLabTHU/FamO2O",
    "checked": true,
    "id": "403f009aa5047e88df0b2c0d497ec12aad3547a9",
    "semantic_title": "train once, get a family: state-adaptive balances for offline-to-online reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UAow2kPsYP": {
    "title": "A Unified Generalization Analysis of Re-Weighting and Logit-Adjustment for Imbalanced Learning",
    "volume": "spotlight",
    "abstract": "Real-world datasets are typically imbalanced in the sense that only a few classes have numerous samples, while many classes are associated with only a few samples. As a result, a naive ERM learning process will be biased towards the majority classes, making it difficult to generalize to the minority classes. To address this issue, one simple but effective approach is to modify the loss function to emphasize the learning on minority classes, such as re-weighting the losses or adjusting the logits via class-dependent terms. However, existing generalization analysis of such losses is still coarse-grained and fragmented, failing to explain some empirical results. To bridge this gap between theory and practice, we propose a novel technique named data-dependent contraction to capture how these modified losses handle different classes. On top of this technique, a fine-grained generalization bound is established for imbalanced learning, which helps reveal the mystery of re-weighting and logit-adjustment in a unified manner. Furthermore, a principled learning algorithm is developed based on the theoretical insights. Finally, the empirical results on benchmark datasets not only validate the theoretical results but also demonstrate the effectiveness of the proposed method",
    "checked": true,
    "id": "82de4d6fa4368af755e8265ccd7d271ad3b93693",
    "semantic_title": "a unified generalization analysis of re-weighting and logit-adjustment for imbalanced learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8IvW2k5VeA": {
    "title": "Exploring Loss Functions for Time-based Training Strategy in Spiking Neural Networks",
    "volume": "spotlight",
    "abstract": "Spiking Neural Networks (SNNs) are considered promising brain-inspired energy-efficient models due to their event-driven computing paradigm. The spatiotemporal spike patterns used to convey information in SNNs consist of both rate coding and temporal coding, where the temporal coding is crucial to biological-plausible learning rules such as spike-timing-dependent-plasticity. The time-based training strategy is proposed to better utilize the temporal information in SNNs and learn in an asynchronous fashion. However, some recent works train SNNs by the time-based scheme with rate-coding-dominated loss functions. In this paper, we first map rate-based loss functions to time-based counterparts and explain why they are also applicable to the time-based training scheme. After that, we infer that loss functions providing adequate positive overall gradients help training by theoretical analysis. Based on this, we propose the enhanced counting loss to replace the commonly used mean square counting loss. In addition, we transfer the training of scale factor in weight standardization into thresholds. Experiments show that our approach outperforms previous time-based training methods in most datasets. Our work provides insights for training SNNs with time-based schemes and offers a fresh perspective on the correlation between rate coding and temporal coding. Our code is available at https://github.com/zhuyaoyu/SNN-temporal-training-losses",
    "checked": false,
    "id": "d7a33032b9cc1401c60ca856fa39c03b838836c1",
    "semantic_title": "exploring temporal information dynamics in spiking neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=NiQTy0NW1L": {
    "title": "Lexinvariant Language Models",
    "volume": "spotlight",
    "abstract": "Token embeddings, a mapping from discrete lexical symbols to continuous vectors, are at the heart of any language model (LM). However, lexical symbol meanings can also be determined and even redefined by their structural role in a long context. In this paper, we ask: is it possible for a language model to be performant without \\emph{any} fixed token embeddings? Such a language model would have to rely entirely on the co-occurence and repetition of tokens in the context rather than the \\textit{a priori} identity of any token. To answer this, we study \\textit{lexinvariant}language models that are invariant to lexical symbols and therefore do not need fixed token embeddings in practice. First, we prove that we can construct a lexinvariant LM to converge to the true language model at a uniform rate that is polynomial in terms of the context length, with a constant factor that is sublinear in the vocabulary size. Second, to build a lexinvariant LM, we simply encode tokens using random Gaussian vectors, such that each token maps to the same representation within each sequence but different representations across sequences. Empirically, we demonstrate that it can indeed attain perplexity comparable to that of a standard language model, given a sufficiently long context. We further explore two properties of the lexinvariant language models: First, given text generated from a substitution cipher of English, it implicitly implements Bayesian in-context deciphering and infers the mapping to the underlying real tokens with high accuracy. Second, it has on average 4X better accuracy over synthetic in-context reasoning tasks. Finally, we discuss regularizing standard language models towards lexinvariance and potential practical applications",
    "checked": true,
    "id": "ac36b65a6fa4a9e84de051f0d3e9d50348fa4160",
    "semantic_title": "lexinvariant language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qd9qcbVAwQ": {
    "title": "Parsel🐍: Algorithmic Reasoning with Language Models by Composing Decompositions",
    "volume": "spotlight",
    "abstract": "Despite recent success in large language model (LLM) reasoning, LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs. For these tasks, humans often start with a high-level algorithmic design and implement each part gradually. We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs. With Parsel, we automatically decompose algorithmic tasks into hierarchical natural language function descriptions and then search over combinations of possible function implementations using tests. We show that Parsel can be used across domains requiring hierarchical reasoning, including program synthesis and robotic planning. We find that, using Parsel, LLMs solve more competition-level problems in the APPS dataset, resulting in pass rates over 75\\% higher than prior results from directly sampling AlphaCode and Codex, while often using a smaller sample budget. Moreover, with automatically generated tests, we find that Parsel can improve the state-of-the-art pass@1 performance on HumanEval from 67\\% to 85\\%. We also find that LLM-generated robotic plans using Parsel are more than twice as likely to be considered accurate than directly generated plans. Lastly, we explore how Parsel addresses LLM limitations and discuss how Parsel may be useful for human programmers. We release our code at https://github.com/ezelikman/parsel",
    "checked": false,
    "id": "e325fe41c8c1d547ccd102ac82be3ec8b23960f2",
    "semantic_title": "parsel: algorithmic reasoning with language models by composing decompositions",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=IL5zJqfxAa": {
    "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought",
    "volume": "spotlight",
    "abstract": "Embodied AI is a crucial frontier in robotics, capable of planning and executing action sequences for robots to accomplish long-horizon tasks in physical environments. In this work, we introduce EmbodiedGPT, an end-to-end multi-modal foundation model for embodied AI, empowering embodied agents with multi-modal understanding and execution capabilities. To achieve this, we have made the following efforts: (i) We craft a large-scale embodied planning dataset, termed EgoCOT. The dataset consists of carefully selected videos from the Ego4D dataset, along with corresponding high-quality language instructions. Specifically, we generate a sequence of sub-goals with the \"Chain of Thoughts\" mode for effective embodied planning. (ii) We introduce an efficient training approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We introduce a paradigm for extracting task-related features from LLM-generated planning queries to form a closed loop between high-level planning and low-level control. Extensive experiments show the effectiveness of EmbodiedGPT on embodied tasks, including embodied planning, embodied control, visual captioning, and visual question answering. Notably, EmbodiedGPT significantly enhances the success rate of the embodied control task by extracting more effective features. It has achieved a remarkable 1.6 times increase in success rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset",
    "checked": true,
    "id": "00cb69a9f280317d1c59ac5827551ee9b10642b8",
    "semantic_title": "embodiedgpt: vision-language pre-training via embodied chain of thought",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=cx9a4Xvb3l": {
    "title": "Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?",
    "volume": "spotlight",
    "abstract": "Hand-crafted image quality metrics, such as PSNR and SSIM, are commonly used to evaluate model privacy risk under reconstruction attacks. Under these metrics, reconstructed images that are determined to resemble the original one generally indicate more privacy leakage. Images determined as overall dissimilar, on the other hand, indicate higher robustness against attack. However, there is no guarantee that these metrics well reflect human opinions, which offers trustworthy judgement for model privacy leakage. In this paper, we comprehensively study the faithfulness of these hand-crafted metrics to human perception of privacy information from the reconstructed images. On 5 datasets ranging from natural images, faces, to fine-grained classes, we use 4 existing attack methods to reconstruct images from many different classification models and, for each reconstructed image, we ask multiple human annotators to assess whether this image is recognizable. Our studies reveal that the hand-crafted metrics only have a weak correlation with the human evaluation of privacy leakage and that even these metrics themselves often contradict each other. These observations suggest risks of current metrics in the community. To address this potential risk, we propose a learning-based measure called SemSim to evaluate the Semantic Similarity between the original and reconstructed images. SemSim is trained with a standard triplet loss, using an original image as an anchor, one of its recognizable reconstructed images as a positive sample, and an unrecognizable one as a negative. By training on human annotations, SemSim exhibits a greater reflection of privacy leakage on the semantic level. We show that SemSim has a significantly higher correlation with human judgment compared with existing metrics. Moreover, this strong correlation generalizes to unseen datasets, models and attack methods. We envision this work as a milestone for image quality evaluation closer to the human level. The project webpage can be accessed at https://sites.google.com/view/semsim",
    "checked": true,
    "id": "d0739b282fb4da1a238dafd4dd43b2003312b1a9",
    "semantic_title": "privacy assessment on reconstructed images: are existing evaluation metrics faithful to human perception?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3gamyee9Yh": {
    "title": "QuantSR: Accurate Low-bit Quantization for Efficient Image Super-Resolution",
    "volume": "spotlight",
    "abstract": "Low-bit quantization in image super-resolution (SR) has attracted copious attention in recent research due to its ability to reduce parameters and operations significantly. However, many quantized SR models suffer from accuracy degradation compared to their full-precision counterparts, especially at ultra-low bit widths (2-4 bits), limiting their practical applications. To address this issue, we propose a novel quantized image SR network, called QuantSR, which achieves accurate and efficient SR processing under low-bit quantization. To overcome the representation homogeneity caused by quantization in the network, we introduce the Redistribution-driven Learnable Quantizer (RLQ). This is accomplished through an inference-agnostic efficient redistribution design, which adds additional information in both forward and backward passes to improve the representation ability of quantized networks. Furthermore, to achieve flexible inference and break the upper limit of accuracy, we propose the Depth-dynamic Quantized Architecture (DQA). Our DQA allows for the trade-off between efficiency and accuracy during inference through weight sharing. Our comprehensive experiments show that QuantSR outperforms existing state-of-the-art quantized SR networks in terms of accuracy while also providing more competitive computational efficiency. In addition, we demonstrate the scheme's satisfactory architecture generality by providing QuantSR-C and QuantSR-T for both convolution and Transformer versions, respectively. Our code and models are released at https://github.com/htqin/QuantSR",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GRHZiTbDDI": {
    "title": "4D Panoptic Scene Graph Generation",
    "volume": "spotlight",
    "abstract": "We are living in a three-dimensional space while moving forward through a fourth dimension: time. To allow artificial intelligence to develop a comprehensive understanding of such a 4D environment, we introduce **4D Panoptic Scene Graph (PSG-4D)**, a new representation that bridges the raw visual data perceived in a dynamic 4D world and high-level visual understanding. Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent entities with precise location and status information, and edges, which capture the temporal relations. To facilitate research in this new area, we build a richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of 1M frames, each of which is labeled with 4D panoptic segmentation masks as well as fine-grained, dynamic scene graphs. To solve PSG-4D, we propose PSG4DFormer, a Transformer-based model that can predict panoptic segmentation masks, track masks along the time axis, and generate the corresponding scene graphs via a relation component. Extensive experiments on the new dataset show that our method can serve as a strong baseline for future research on PSG-4D. In the end, we provide a real-world application example to demonstrate how we can achieve dynamic scene understanding by integrating a large language model into our PSG-4D system",
    "checked": false,
    "id": "3eae260abb6e0a14943492d63fad62499c8c16d6",
    "semantic_title": "panoptic scene graph generation",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=gYetLsNO8x": {
    "title": "Best Arm Identification with Fixed Budget: A Large Deviation Perspective",
    "volume": "spotlight",
    "abstract": "We consider the problem of identifying the best arm in stochastic Multi-Armed Bandits (MABs) using a fixed sampling budget. Characterizing the minimal instance-specific error probability for this problem constitutes one of the important remaining open problems in MABs. When arms are selected using a static sampling strategy, the error probability decays exponentially with the number of samples at a rate that can be explicitly derived via Large Deviation techniques. Analyzing the performance of algorithms with adaptive sampling strategies is however much more challenging. In this paper, we establish a connection between the Large Deviation Principle (LDP) satisfied by the empirical proportions of arm draws and that satisfied by the empirical arm rewards. This connection holds for any adaptive algorithm, and is leveraged (i) to improve error probability upper bounds of some existing algorithms, such as the celebrated SR (Successive Rejects) algorithm \\cite{audibert2010best}, and (ii) to devise and analyze new algorithms. In particular, we present CR (Continuous Rejects), a truly adaptive algorithm that can reject arms in {\\it any} round based on the observed empirical gaps between the rewards of various arms. Applying our Large Deviation results, we prove that CR enjoys better performance guarantees than existing algorithms, including SR. Extensive numerical experiments confirm this observation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KgqucdSwIe": {
    "title": "VoxDet: Voxel Learning for Novel Instance Detection",
    "volume": "spotlight",
    "abstract": "Detecting unseen instances based on multi-view templates is a challenging problem due to its open-world nature. Traditional methodologies, which primarily rely on $2 \\mathrm{D}$ representations and matching techniques, are often inadequate in handling pose variations and occlusions. To solve this, we introduce VoxDet, a pioneer 3D geometry-aware framework that fully utilizes the strong 3D voxel representation and reliable voxel matching mechanism. VoxDet first ingeniously proposes template voxel aggregation (TVA) module, effectively transforming multi-view 2D images into 3D voxel features. By leveraging associated camera poses, these features are aggregated into a compact 3D template voxel. In novel instance detection, this voxel representation demonstrates heightened resilience to occlusion and pose variations. We also discover that a $3 \\mathrm{D}$ reconstruction objective helps to pre-train the 2D-3D mapping in TVA. Second, to quickly align with the template voxel, VoxDet incorporates a Query Voxel Matching (QVM) module. The 2D queries are first converted into their voxel representation with the learned 2D-3D mapping. We find that since the 3D voxel representations encode the geometry, we can first estimate the relative rotation and then compare the aligned voxels, leading to improved accuracy and efficiency. In addition to method, we also introduce the first instance detection benchmark, RoboTools, where 20 unique instances are video-recorded with camera extrinsic. RoboTools also provides 24 challenging cluttered scenarios with more than $9 \\mathrm{k}$ box annotations. Exhaustive experiments are conducted on the demanding LineMod-Occlusion, YCB-video, and RoboTools benchmarks, where VoxDet outperforms various $2 \\mathrm{D}$ baselines remarkably with faster speed. To the best of our knowledge, VoxDet is the first to incorporate implicit 3D knowledge for 2D novel instance detection tasks",
    "checked": true,
    "id": "f6f60d1348b4263977de90bb6a4692c72f562a01",
    "semantic_title": "voxdet: voxel learning for novel instance detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fKwG6grp8o": {
    "title": "Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks",
    "volume": "spotlight",
    "abstract": "We analyze the dynamics of finite width effects in wide but finite feature learning neural networks. Starting from a dynamical mean field theory description of infinite width deep neural network kernel and prediction dynamics, we provide a characterization of the $\\mathcal{O}(1/\\sqrt{\\text{width}})$ fluctuations of the DMFT order parameters over random initializations of the network weights. Our results, while perturbative in width, unlike prior analyses, are non-perturbative in the strength of feature learning. In the lazy limit of network training, all kernels are random but static in time and the prediction variance has a universal form. However, in the rich, feature learning regime, the fluctuations of the kernels and predictions are dynamically coupled with a variance that can be computed self-consistently. In two layer networks, we show how feature learning can dynamically reduce the variance of the final tangent kernel and final network predictions. We also show how initialization variance can slow down online learning in wide but finite networks. In deeper networks, kernel variance can dramatically accumulate through subsequent layers at large feature learning strengths, but feature learning continues to improve the signal-to-noise ratio of the feature kernels. In discrete time, we demonstrate that large learning rate phenomena such as edge of stability effects can be well captured by infinite width dynamics and that initialization variance can decrease dynamically. For CNNs trained on CIFAR-10, we empirically find significant corrections to both the bias and variance of network dynamics due to finite width",
    "checked": true,
    "id": "fe1be27f0f3ad3399ae5aea1e5d3eb06251a64af",
    "semantic_title": "dynamics of finite width kernel and prediction fluctuations in mean field neural networks",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=WaLI8slhLw": {
    "title": "DeWave: Discrete Encoding of EEG Waves for EEG to Text Translation",
    "volume": "spotlight",
    "abstract": "The translation of brain dynamics into natural language is pivotal for brain-computer interfaces (BCIs), a field that has seen substantial growth in recent years. With the swift advancement of large language models, such as ChatGPT, the need to bridge the gap between the brain and languages becomes increasingly pressing. Current methods, however, require eye-tracking fixations or event markers to segment brain dynamics into word-level features, which can restrict the practical application of these systems. These event markers may not be readily available or could be challenging to acquire during real-time inference, and the sequence of eye fixations may not align with the order of spoken words. To tackle these issues, we introduce a novel framework, DeWave, that integrates discrete encoding sequences into open-vocabulary EEG-to-text translation tasks. DeWave uses a quantized variational encoder to derive discrete codex encoding and align it with pre-trained language models. This discrete codex representation brings forth two advantages: 1) it alleviates the order mismatch between eye fixations and spoken words by introducing text-EEG contrastive alignment training, and 2) it minimizes the interference caused by individual differences in EEG waves through an invariant discrete codex. Our model surpasses the previous baseline (40.1 and 31.7) by 3.06% and 6.34\\%, respectively, achieving 41.35 BLEU-1 and 33.71 Rouge-F on the ZuCo Dataset. Furthermore, this work is the first to facilitate the translation of entire EEG signal periods without the need for word-level order markers (e.g., eye fixations), scoring 20.5 BLEU-1 and 29.5 Rouge-1 on the ZuCo Dataset, respectively",
    "checked": false,
    "id": "053f10cd2ba7fe9c508a9e63476a4f68ab1deb57",
    "semantic_title": "dewave: discrete eeg waves encoding for brain dynamics to text translation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z764QxwETf": {
    "title": "Puzzlefusion: Unleashing the Power of Diffusion Models for Spatial Puzzle Solving",
    "volume": "spotlight",
    "abstract": "This paper presents an end-to-end neural architecture based on Diffusion Models for spatial puzzle solving, particularly jigsaw puzzle and room arrangement tasks. In the latter task, for instance, the proposed system ``PuzzleFusion'' takes a set of room layouts as polygonal curves in the top-down view and aligns the room layout pieces by estimating their 2D translations and rotations, akin to solving the jigsaw puzzle of room layouts. A surprising discovery of the paper is that the simple use of a Diffusion Model effectively solves these challenging spatial puzzle tasks as a conditional generation process. To enable learning of an end-to-end neural system, the paper introduces new datasets with ground-truth arrangements: 1) 2D Voronoi Jigsaw Dataset, a synthetic one where pieces are generated by voronoi diagram of 2D pointset; and 2) MagicPlan Dataset, a real one from a production pipeline by MagicPlan, where pieces are room layouts constructed by augmented reality App by real-estate consumers. The qualitative and quantitative evaluations demonstrate that the proposed approach outperforms the competing methods by significant margins in all three spatial puzzle tasks. We have provided code and data in https://sepidsh.github.io/puzzlefusion",
    "checked": true,
    "id": "048da9875ee5b64409b5e57a129585b36a4da5a0",
    "semantic_title": "puzzlefusion: unleashing the power of diffusion models for spatial puzzle solving",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=MfiK69Ga6p": {
    "title": "Protein Design with Guided Discrete Diffusion",
    "volume": "spotlight",
    "abstract": "A popular approach to protein design is to combine a generative model with a discriminative model for conditional sampling. The generative model samples plausible sequences while the discriminative model guides a search for sequences with high fitness. Given its broad success in conditional sampling, classifier-guided diffusion modeling is a promising foundation for protein design, leading many to develop guided diffusion models for structure with inverse folding to recover sequences. In this work, we propose diffusioN Optimized Sampling (NOS), a guidance method for discrete diffusion models that follows gradients in the hidden states of the denoising network. NOS makes it possible to perform design directly in sequence space, circumventing significant limitations of structure-based methods, including scarce data and challenging inverse design. Moreover, we use NOS to generalize LaMBO, a Bayesian optimization procedure for sequence design that facilitates multiple objectives and edit-based constraints. The resulting method, LaMBO-2, enables discrete diffusions and stronger performance with limited edits through a novel application of saliency maps. We apply LaMBO-2 to a real-world protein design task, optimizing antibodies for higher expression yield and binding affinity to several therapeutic targets under locality and developability constraints, attaining a 99\\% expression rate and 40\\% binding rate in exploratory in vitro experiments",
    "checked": true,
    "id": "7b14cef8a08519d7ea33800d52aba8410f48a3f7",
    "semantic_title": "protein design with guided discrete diffusion",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=vq11gurmUY": {
    "title": "Online PCA in Converging Self-consistent Field Equations",
    "volume": "poster",
    "abstract": "Self-consistent Field (SCF) equation is a type of nonlinear eigenvalue problem in which the matrix to be eigen-decomposed is a function of its own eigenvectors. It is of great significance in computational science for its connection to the Schrödinger equation. Traditional fixed-point iteration methods for solving such equations suffer from non-convergence issues. In this work, we present a novel perspective on such SCF equations as a principal component analysis (PCA) for non-stationary time series, in which a distribution and its own top principal components are mutually updated over time, and the equilibrium state of the model corresponds to the solution of the SCF equations. By the new perspective, online PCA techniques are able to engage in so as to enhance the convergence of the model towards the equilibrium state, acting as a new set of tools for converging the SCF equations. With several numerical adaptations, we then develop a new algorithm for converging the SCF equation, and demonstrated its high convergence capacity with experiments on both synthesized and real electronic structure scenarios",
    "checked": false,
    "id": "6d68feec617bafb5860c179f4b13e13ffb73870e",
    "semantic_title": "quantum machine learning for power system stability assessment",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=zyZkaqNnpa": {
    "title": "Don't blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
    "volume": "poster",
    "abstract": "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM's preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM's implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks",
    "checked": true,
    "id": "21cef3fcb586019ddd36c7172e5c93fdb5b08df1",
    "semantic_title": "don't blame dataset shift! shortcut learning due to gradients and cross entropy",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=JMuKfZx2xU": {
    "title": "On Slicing Optimality for Mutual Information",
    "volume": "poster",
    "abstract": "Measuring dependence between two random variables is of great importance in various domains but is difficult to compute in today's complex environments with high-dimensional data. Recently, slicing methods have shown to be a scalable approach to measuring mutual information (MI) between high-dimensional variables by projecting these variables into one-dimensional spaces. Unfortunately, these methods use uniform distributions of slicing directions, which generally discard informative features between variables and thus lead to inaccurate quantification of dependence. In this paper, we propose a principled framework that searches for an \\textit{optimal} distribution of slices for MI. Importantly, we answer theoretical questions about finding the optimal slicing distribution in the context of MI and develop corresponding theoretical analyses. We also develop a practical algorithm, connecting our theoretical results with modern machine learning frameworks. Through comprehensive experiments in benchmark domains, we demonstrate significant gains in our information measure than state-of-the-art baselines",
    "checked": false,
    "id": "a449cf87ad5774b3efbe475cbc840fbd9efbb93b",
    "semantic_title": "k-sliced mutual information: a quantitative study of scalability with dimension",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=9zV2OXCrVF": {
    "title": "k-Median Clustering via Metric Embedding: Towards Better Initialization with Differential Privacy",
    "volume": "poster",
    "abstract": "In clustering algorithms, the choice of initial centers is crucial for the quality of the learned clusters. We propose a new initialization scheme for the $k$-median problem in the general metric space (e.g., discrete space induced by graphs), based on the construction of metric embedding tree structure of the data. We propose a novel and efficient search algorithm, for good initial centers that can be used subsequently for the local search algorithm. The so-called HST initialization method can produce initial centers achieving lower error than those from another popular method $k$-median++, also with higher efficiency when $k$ is not too small. Our HST initialization can also be easily extended to the setting of differential privacy (DP) to generate private initial centers. We show that the error of applying DP local search followed by our private HST initialization improves previous results on the approximation error, and approaches the lower bound within a small factor. Experiments demonstrate the effectiveness of our proposed methods",
    "checked": true,
    "id": "cb1b92b70e687bb5d02cb0f02034d5988303d660",
    "semantic_title": "k-median clustering via metric embedding: towards better initialization with differential privacy",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7ntI4kcoqG": {
    "title": "AMAG: Additive, Multiplicative and Adaptive Graph Neural Network For Forecasting Neuron Activity",
    "volume": "poster",
    "abstract": "Latent Variable Models (LVMs) propose to model the dynamics of neural populations by capturing low-dimensional structures that represent features involved in neural activity. Recent LVMs are based on deep learning methodology where a deep neural network is trained to reconstruct the same neural activity given as input and as a result to build the latent representation. Without taking past or future activity into account such a task is non-causal. In contrast, the task of forecasting neural activity based on given input extends the reconstruction task. LVMs that are trained on such a task could potentially capture temporal causality constraints within its latent representation. Forecasting has received less attention than reconstruction due to recording challenges such as limited neural measurements and trials. In this work, we address modeling neural population dynamics via the forecasting task and improve forecasting performance by including a prior, which consists of pairwise neural unit interaction as a multivariate dynamic system. Our proposed model---Additive, Multiplicative, and Adaptive Graph Neural Network (AMAG)---leverages additive and multiplicative message-passing operations analogous to the interactions in neuronal systems and adaptively learns the interaction among neural units to forecast their future activity. We demonstrate the advantage of AMAG compared to non-GNN based methods on synthetic data and multiple modalities of neural recordings (field potentials from penetrating electrodes or surface-level micro-electrocorticography) from four rhesus macaques. Our results show the ability of AMAG to recover ground truth spatial interactions and yield estimation for future dynamics of the neural population",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GYnbubCXhE": {
    "title": "Conditional Matrix Flows for Gaussian Graphical Models",
    "volume": "poster",
    "abstract": "Studying conditional independence among many variables with few observations is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$. However, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms. In the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$. In the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers. Here we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks. As a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms. Within one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit",
    "checked": true,
    "id": "48502eca6eaecd7d3e100990c9eefba36338cd33",
    "semantic_title": "conditional matrix flows for gaussian graphical models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=36DxONZ9bA": {
    "title": "Representational Strengths and Limitations of Transformers",
    "volume": "poster",
    "abstract": "Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be efficiently solved by attention layers. The proof techniques emphasize the value of communication complexity in the analysis of transformers and related models, and the role of sparse averaging as a prototypical attention task, which even finds use in the analysis of triple detection",
    "checked": true,
    "id": "42cf52baff90952944da0409ec52ff7611ed55dc",
    "semantic_title": "representational strengths and limitations of transformers",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=Srt1hhQgqa": {
    "title": "Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small Scorer",
    "volume": "poster",
    "abstract": "Large language models (LLMs) such as T0, FLAN, and OPT-IML excel in multi-tasking under a unified instruction-following paradigm, where they also exhibit remarkable generalization abilities to unseen tasks. Despite their impressive performance, these LLMs, with sizes ranging from several billion to hundreds of billions of parameters, demand substantial computational resources, making their training and inference expensive and inefficient. Furthermore, adapting these models to downstream applications, particularly complex tasks, is often unfeasible due to the extensive hardware requirements for finetuning, even when utilizing parameter-efficient approaches such as prompt tuning. Additionally, the most powerful multi-task LLMs, such as OPT-IML-175B and FLAN-PaLM-540B, are not publicly accessible, severely limiting their customization potential. To address these challenges, we introduce a pretrained small scorer, \\textit{Cappy}, designed to enhance the performance and efficiency of multi-task LLMs. With merely 360 million parameters, Cappy functions either independently on classification tasks or serve as an auxiliary component for LLMs, boosting their performance. Moreover, Cappy enables efficiently integrating downstream supervision without requiring LLM finetuning nor the access to their parameters. Our experiments demonstrate that, when working independently on 11 language understanding tasks from PromptSource, Cappy outperforms LLMs that are several orders of magnitude larger. Besides, on 45 complex tasks from BIG-Bench, Cappy boosts the performance of the advanced multi-task LLM, FLAN-T5, by a large margin. Furthermore, Cappy is flexible to cooperate with other LLM adaptations, including finetuning and in-context learning, offering additional performance enhancement",
    "checked": true,
    "id": "3d13935886627982fc98971baa33d2f9f3115bff",
    "semantic_title": "cappy: outperforming and boosting large multi-task lms with a small scorer",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=GIlsH0T4b2": {
    "title": "Two-Stage Learning to Defer with Multiple Experts",
    "volume": "poster",
    "abstract": "We study a two-stage scenario for learning to defer with multiple experts, which is crucial in practice for many applications. In this scenario, a predictor is derived in a first stage by training with a common loss function such as cross-entropy. In the second stage, a deferral function is learned to assign the most suitable expert to each input. We design a new family of surrogate loss functions for this scenario both in the score-based and the predictor-rejector settings and prove that they are supported by $H$-consistency bounds, which implies their Bayes-consistency. Moreover, we show that, for a constant cost function, our two-stage surrogate losses are realizable $H$-consistent. While the main focus of this work is a theoretical analysis, we also report the results of several experiments on CIFAR-10 and SVHN datasets",
    "checked": false,
    "id": "cfe06cec2c078c25a722021b28a05e454382d020",
    "semantic_title": "commentary: considering radiomics in the setting of prostate cancer active surveillance",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=M6UccKMFGl": {
    "title": "Multiply Robust Federated Estimation of Targeted Average Treatment Effects",
    "volume": "poster",
    "abstract": "Federated or multi-site studies have distinct advantages over single-site studies, including increased generalizability, the ability to study underrepresented populations, and the opportunity to study rare exposures and outcomes. However, these studies are complicated by the need to preserve the privacy of each individual's data, heterogeneity in their covariate distributions, and different data structures between sites. We propose a novel federated approach to derive valid causal inferences for a target population using multi-site data. We adjust for covariate shift and accommodate covariate mismatch between sites by developing a multiply-robust and privacy-preserving nuisance function estimation approach. Our methodology incorporates transfer learning to estimate ensemble weights to combine information from source sites. We show that these learned weights are efficient and optimal under different scenarios. We showcase the finite sample advantages of our approach in terms of efficiency and robustness compared to existing state-of-the-art approaches. We apply our approach to study the treatment effect of percutaneous coronary intervention (PCI) on the duration of hospitalization for patients experiencing acute myocardial infarction (AMI) with data from the Centers for Medicare \\& Medicaid Services (CMS)",
    "checked": true,
    "id": "9432a76b2a1ea78530a36c9e68a19fbc92ee3086",
    "semantic_title": "multiply robust federated estimation of targeted average treatment effects",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NNooZoQpP4": {
    "title": "To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning",
    "volume": "poster",
    "abstract": "Transfer learning and ensembling are two popular techniques for improving the performance and robustness of neural networks. Due to the high cost of pre-training, ensembles of models fine-tuned from a single pre-trained checkpoint are often used in practice. Such models end up in the same basin of the loss landscape, which we call the pre-train basin, and thus have limited diversity. In this work, we show that ensembles trained from a single pre-trained checkpoint may be improved by better exploring the pre-train basin, however, leaving the basin results in losing the benefits of transfer learning and in degradation of the ensemble quality. Based on the analysis of existing exploration methods, we propose a more effective modification of the Snapshot Ensembles (SSE) for transfer learning setup, StarSSE, which results in stronger ensembles and uniform model soups",
    "checked": true,
    "id": "18ff657c37950d89a8ed5493f6969a9dcd367719",
    "semantic_title": "to stay or not to stay in the pre-train basin: insights on ensembling in transfer learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=frVo9MzRuU": {
    "title": "Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task",
    "volume": "poster",
    "abstract": "Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of real world, reliable use of these models in practical applications mandates they exhibit the ability to compose their capabilities, generating and reasoning over entirely novel samples never seen in the training distribution. Prior work demonstrates recent vision diffusion models exhibit intriguing compositional generalization abilities, but also fail rather unpredictably. What are the reasons underlying this behavior? Which concepts does the model generally find difficult to compose to form novel data? To address these questions, we perform a controlled study of compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model's ability to generate samples out-of-distribution. Our results show that: (i) the compositional structure of the data-generating process governs the order in which capabilities and an ability to compose them emerges; (ii) learning individual concepts impacts performance on compositional tasks, multiplicatively explaining sudden emergence; and (iii) learning and composing capabilities is difficult under correlations. We hope our study inspires further grounded research on understanding capabilities and compositionality in generative models from a data-centric perspective",
    "checked": true,
    "id": "bd206d206e78b90c9d4b7ccc0d3b57e051075e9a",
    "semantic_title": "compositional abilities emerge multiplicatively: exploring diffusion models on a synthetic task",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Al9yglQGKj": {
    "title": "Phase diagram of early training dynamics in deep neural networks: effect of the learning rate, depth, and width",
    "volume": "poster",
    "abstract": "We systematically analyze optimization dynamics in deep neural networks (DNNs) trained with stochastic gradient descent (SGD) and study the effect of learning rate $\\eta$, depth $d$, and width $w$ of the neural network. By analyzing the maximum eigenvalue $\\lambda^H_t$ of the Hessian of the loss, which is a measure of sharpness of the loss landscape, we find that the dynamics can show four distinct regimes: (i) an early time transient regime, (ii) an intermediate saturation regime, (iii) a progressive sharpening regime, and (iv) a late time \"edge of stability\" regime. The early and intermediate regimes (i) and (ii) exhibit a rich phase diagram depending on $\\eta \\equiv c / \\lambda_0^H $, $d$, and $w$. We identify several critical values of $c$, which separate qualitatively distinct phenomena in the early time dynamics of training loss and sharpness. Notably, we discover the opening up of a \"sharpness reduction\" phase, where sharpness decreases at early times, as $d$ and $ 1/w$ are increased",
    "checked": true,
    "id": "f739de44605f35481066fdff0f9be89d8a5728d6",
    "semantic_title": "phase diagram of early training dynamics in deep neural networks: effect of the learning rate, depth, and width",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=1uirUsR9E7": {
    "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
    "volume": "poster",
    "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that more comprehensively explain V1 activity. Upon enhancing task-driven CNNs with architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Moreover, analyses of the learned parameters of these components and stimuli that maximally activate neurons of the evaluated networks provide support for their role in explaining neural properties of V1. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence",
    "checked": true,
    "id": "85e49127646e4961b0234487b2d6ba128a6a9102",
    "semantic_title": "explaining v1 properties with a biologically constrained deep learning architecture",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JDoA6admhv": {
    "title": "Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness",
    "volume": "poster",
    "abstract": "The susceptibility of modern machine learning classifiers to adversarial examples has motivated theoretical results suggesting that these might be unavoidable. However, these results can be too general to be applicable to natural data distributions. Indeed, humans are quite robust for tasks involving vision. This apparent conflict motivates a deeper dive into the question: Are adversarial examples truly unavoidable? In this work, we theoretically demonstrate that a key property of the data distribution -- concentration on small-volume subsets of the input space -- determines whether a robust classifier exists. We further demonstrate that, for a data distribution concentrated on a union of low-dimensional linear subspaces, exploiting data structure naturally leads to classifiers that enjoy good robustness guarantees, improving upon methods for provable certification in certain regimes",
    "checked": true,
    "id": "5219c455e145235e206def75b43bf30e8523663f",
    "semantic_title": "adversarial examples might be avoidable: the role of data concentration in adversarial robustness",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x5ZruOa4ax": {
    "title": "Improving *day-ahead* Solar Irradiance Time Series Forecasting by Leveraging Spatio-Temporal Context",
    "volume": "poster",
    "abstract": "Solar power harbors immense potential in mitigating climate change by substantially reducing CO$_{2}$ emissions. Nonetheless, the inherent variability of solar irradiance poses a significant challenge for seamlessly integrating solar power into the electrical grid. While the majority of prior research has centered on employing purely time series-based methodologies for solar forecasting, only a limited number of studies have taken into account factors such as cloud cover or the surrounding physical context. In this paper, we put forth a deep learning architecture designed to harness spatio-temporal context using satellite data, to attain highly accurate day-ahead time-series forecasting for any given station, with a particular emphasis on forecasting Global Horizontal Irradiance (GHI). We also suggest a methodology to extract a distribution for each time step prediction, which can serve as a very valuable measure of uncertainty attached to the forecast. When evaluating models, we propose a testing scheme in which we separate particularly difficult examples from easy ones, in order to capture the model performances in crucial situations, which in the case of this study are the days suffering from varying cloudy conditions. Furthermore, we present a new multi-modal dataset gathering satellite imagery over a large zone and time series for solar irradiance and other related physical variables from multiple geographically diverse solar stations. Our approach exhibits robust performance in solar irradiance forecasting, including zero-shot generalization tests at unobserved solar stations, and holds great promise in promoting the effective integration of solar power into the grid",
    "checked": false,
    "id": "4a6efc258088dd2c2245592e5366bf475f92e674",
    "semantic_title": "improving day-ahead solar irradiance time series forecasting by leveraging spatio-temporal context",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Od6CHhPM7I": {
    "title": "Red Teaming Deep Neural Networks with Feature Synthesis Tools",
    "volume": "poster",
    "abstract": "Interpretable AI tools are often motivated by the goal of understanding model behavior in out-of-distribution (OOD) contexts. Despite the attention this area of study receives, there are comparatively few cases where these tools have identified previously unknown bugs in models. We argue that this is due, in part, to a common feature of many interpretability methods: they analyze model behavior by using a particular dataset. This only allows for the study of the model in the context of features that the user can sample in advance. To address this, a growing body of research involves interpreting models using feature synthesis methods that do not depend on a dataset. In this paper, we benchmark the usefulness of interpretability tools for model debugging. Our key insight is that we can implant human-interpretable trojans into models and then evaluate these tools based on whether they can help humans discover them. This is analogous to finding OOD bugs, except the ground truth is known, allowing us to know when a user's interpretation is correct. We make four contributions. (1) We propose trojan discovery as an evaluation task for interpretability tools and introduce a benchmark with 12 trojans of 3 different types. (2) We demonstrate the difficulty of this benchmark with a preliminary evaluation of 16 state-of-the-art feature attribution/saliency tools. Even under ideal conditions, given direct access to data with the trojan trigger, these methods still often fail to identify bugs. (3) We evaluate 7 feature-synthesis methods on our benchmark. (4) We introduce and evaluate 2 new variants of the best-performing method from the previous evaluation",
    "checked": true,
    "id": "5fdf01476628b2afe4853d747ddfc6677bab13bc",
    "semantic_title": "red teaming deep neural networks with feature synthesis tools",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ZED5wdGous": {
    "title": "Human-in-the-Loop Optimization for Deep Stimulus Encoding in Visual Prostheses",
    "volume": "poster",
    "abstract": "Neuroprostheses show potential in restoring lost sensory function and enhancing human capabilities, but the sensations produced by current devices often seem unnatural or distorted. Exact placement of implants and differences in individual perception lead to significant variations in stimulus response, making personalized stimulus optimization a key challenge. Bayesian optimization could be used to optimize patient-specific stimulation parameters with limited noisy observations, but is not feasible for high-dimensional stimuli. Alternatively, deep learning models can optimize stimulus encoding strategies, but typically assume perfect knowledge of patient-specific variations. Here we propose a novel, practically feasible approach that overcomes both of these fundamental limitations. First, a deep encoder network is trained to produce optimal stimuli for any individual patient by inverting a forward model mapping electrical stimuli to visual percepts. Second, a preferential Bayesian optimization strategy utilizes this encoder to learn the optimal patient-specific parameters for a new patient, using a minimal number of pairwise comparisons between candidate stimuli. We demonstrate the viability of this approach on a novel, state-of-the-art visual prosthesis model. Our approach quickly learns a personalized stimulus encoder and leads to dramatic improvements in the quality of restored vision, outperforming existing encoding strategies. Further, this approach is robust to noisy patient feedback and misspecifications in the underlying forward model. Overall, our results suggest that combining the strengths of deep learning and Bayesian optimization could significantly improve the perceptual experience of patients fitted with visual prostheses and may prove a viable solution for a range of neuroprosthetic technologies",
    "checked": true,
    "id": "1e0301406d3eebd63d0843b2b802a2573a94aba2",
    "semantic_title": "human-in-the-loop optimization for deep stimulus encoding in visual prostheses",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0rEJx5QAxt": {
    "title": "Convex-Concave Zero-Sum Stochastic Stackelberg Games",
    "volume": "poster",
    "abstract": "Zero-sum stochastic Stackelberg games can be used to model a large class of problems, ranging from economics to human robot interaction. In this paper, we develop policy gradient methods to solve these games from noisy gradient estimates computed from observed trajectories of play. We prove that our algorithms converge to Stackelberg equilibrium in polynomial time when the games are convex-concave. We also prove that reach-avoid problems are naturally modeled as convex-concave zero-sum stochastic Stackelberg games. Finally, we run experiments which demonstrate that modeling reach-avoid problems as Stackelberg games leads to solutions which are safer, thus less likely to result in collisions, and liver, thus more likely to reach their goals, than alternative solutions, in particular Nash equilibrium",
    "checked": false,
    "id": "e3aeba982ed32fa85edac076c298e509d1519234",
    "semantic_title": "zero-sum stochastic stackelberg games",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=frHPeRedHo": {
    "title": "Agnostically Learning Single-Index Models using Omnipredictors",
    "volume": "poster",
    "abstract": "We give the first result for agnostically learning Single-Index Models (SIMs) with arbitrary monotone and Lipschitz activations. All prior work either held only in the realizable setting or required the activation to be known. Moreover, we only require the marginal to have bounded second moments, whereas all prior work required stronger distributional assumptions (such as anticoncentration or boundedness). Our algorithm is based on recent work by Gopalan et al. [2023] on Omniprediction using predictors satisfying calibrated multiaccuracy. Our analysis is simple and relies on the relationship between Bregman divergences (or matching losses) and $\\ell_p$ distances. We also provide new guarantees for standard algorithms like GLMtron and logistic regression in the agnostic setting",
    "checked": true,
    "id": "088edd4fb2f1d44c4be5b443d18c3084468bf72f",
    "semantic_title": "agnostically learning single-index models using omnipredictors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a147pIS2Co": {
    "title": "Training Chain-of-Thought via Latent-Variable Inference",
    "volume": "poster",
    "abstract": "Large language models (LLMs) solve problems more accurately and interpretably when instructed to work out the answer step by step using a \"chain-of-thought\" (CoT) prompt. One can also improve LLMs' performance on a specific task by supervised fine-tuning, i.e., by using gradient ascent on some tunable parameters to maximize the average log-likelihood of correct answers from a labeled training set. Naively combining CoT with supervised tuning requires supervision not just of the correct answers, but also of detailed rationales that lead to those answers; these rationales are expensive to produce by hand. Instead, we propose a fine-tuning strategy that tries to maximize the \\emph{marginal} log-likelihood of generating a correct answer using CoT prompting, approximately averaging over all possible rationales. The core challenge is sampling from the posterior over rationales conditioned on the correct answer; we address it using a simple Markov-chain Monte Carlo (MCMC) expectation-maximization (EM) algorithm inspired by the self-taught reasoner (STaR), memoized wake-sleep, Markovian score climbing, and persistent contrastive divergence. This algorithm also admits a novel control-variate technique that drives the variance of our gradient estimates to zero as the model improves. Applying our technique to GSM8K and the tasks in BIG-Bench Hard, we find that this MCMC-EM fine-tuning technique typically improves the model's accuracy on held-out examples more than STaR or prompt-tuning with or without CoT",
    "checked": false,
    "id": "1effda8ce21573ed864eadfdc7b233aac39b8fe6",
    "semantic_title": "amortizing intractable inference in large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GhNCFtLSsy": {
    "title": "Combining Behaviors with the Successor Features Keyboard",
    "volume": "poster",
    "abstract": "The Option Keyboard (OK) was recently proposed as a method for transferring behavioral knowledge across tasks. OK transfers knowledge by adaptively combining subsets of known behaviors using Successor Features (SFs) and Generalized Policy Improvement (GPI). However, it relies on hand-designed state-features and task encodings which are cumbersome to design for every new environment. In this work, we propose the \"Successor Features Keyboard\" (SFK), which enables transfer with discovered state-features and task encodings. To enable discovery, we propose the \"Categorical Successor Feature Approximator\" (CSFA), a novel learning algorithm for estimating SFs while jointly discovering state-features and task encodings. With SFK and CSFA, we achieve the first demonstration of transfer with SFs in a challenging 3D environment where all the necessary representations are discovered. We first compare CSFA against other methods for approximating SFs and show that only CSFA discovers representations compatible with SF&GPI at this scale. We then compare SFK against transfer learning baselines and show that it transfers most quickly to long-horizon tasks",
    "checked": true,
    "id": "5cc1e7bcabe56578efa2527ba1d86a2f527e7f70",
    "semantic_title": "combining behaviors with the successor features keyboard",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SVBR6xBaMl": {
    "title": "Language Models Meet World Models: Embodied Experiences Enhance Language Models",
    "volume": "poster",
    "abstract": "While large language models (LMs) have shown remarkable capabilities across numerous tasks, they often struggle with simple reasoning and planning in physical environments, such as understanding object permanence or planning household activities. The limitation arises from the fact that LMs are trained only on written text and miss essential embodied knowledge and skills. In this paper, we propose a new paradigm of enhancing LMs by finetuning them with world models, to gain diverse embodied knowledge while retaining their general language capabilities. Our approach deploys an embodied agent in a world model, particularly a simulator of the physical world (VirtualHome), and acquires a diverse set of embodied experiences through both goal-oriented planning and random exploration. These experiences are then used to finetune LMs to teach diverse abilities of reasoning and acting in the physical world, e.g., planning and completing goals, object permanence and tracking, etc. Moreover, it is desirable to preserve the generality of LMs during finetuning, which facilitates generalizing the embodied knowledge across tasks rather than being tied to specific simulations. We thus further introduce the classical elastic weight consolidation (EWC) for selective weight updates, combined with low-rank adapters (LoRA) for training efficiency. Extensive experiments show our approach substantially improves base LMs on 18 downstream tasks by 64.28% on average. In particular, the small LMs (1.3B, 6B, and 13B) enhanced by our approach match or even outperform much larger LMs (e.g., ChatGPT)",
    "checked": true,
    "id": "6f821d75968bc8de070af3ce5aa7f57bc031fafb",
    "semantic_title": "language models meet world models: embodied experiences enhance language models",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=GEMHw2sd9S": {
    "title": "Smooth Flipping Probability for Differential Private Sign Random Projection Methods",
    "volume": "poster",
    "abstract": "We develop a series of differential privacy (DP) algorithms from a family of random projection (RP) and sign random projection (SignRP) methods. We first show how to improve the previous DP-RP approach using the ``optimal Gaussian mechanism''. Then, we propose a series of DP-SignRP algorithms that leverage the robustness of the ``sign flipping probability'' of random projections. That is, given $x = \\sum_{i=1}^p u_i w_{i}$ where $u$ is a $p$-dimensional data vector and $w$ is a symmetric random vector, $sign(x)$ only has a fairly small probability to be flipped if there is a small modification on data $u$, depending on the specific distribution of $w$. This robustness leads to our novel design of ``smooth flipping probability'' for SignRP-type algorithms with better utility than using the standard randomized response mechanism. Retrieval and classification experiments demonstrate that, among the presented DP-RP algorithms, \\textbf{DP-SignOPORP} (where OPORP is an improvement over the celebrated count-sketch algorithms), performs the best in general. In the industrial practice, DP methods were not very popular for machine learning or search, largely because the performance typically would drop substantially if DP is applied. Since our proposed new DP algorithms have significantly improved the performance, it is anticipated that our work will motivate a wide adoption of DP in practice. Finally, we stress that, since our methods are applied to the original data (i.e., feature vectors), the privacy of downstream tasks is naturally protected",
    "checked": false,
    "id": "8568884eb35ef18b2896a4ae2a82264b0918d2f9",
    "semantic_title": "differential privacy with random projections and sign random projections",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=sgCrNMOuXp": {
    "title": "Data Market Design through Deep Learning",
    "volume": "poster",
    "abstract": "The _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle _obedience constraints_ &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids. Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs",
    "checked": true,
    "id": "954a96cf14fa918fccf357730359d04847eed5ba",
    "semantic_title": "data market design through deep learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xkkBFePoFn": {
    "title": "Text Alignment Is An Efficient Unified Model for Massive NLP Tasks",
    "volume": "poster",
    "abstract": "Large language models (LLMs), typically designed as a function of next-word prediction, have excelled across extensive NLP tasks. Despite the generality, next-word prediction is often not an efficient formulation for many of the tasks, demanding an extreme scale of model parameters (10s or 100s of billions) and sometimes yielding suboptimal performance. In practice, it is often desirable to build more efficient models---despite being less versatile, they still apply to a substantial subset of problems, delivering on par or even superior performance with much smaller model sizes. In this paper, we propose text alignment as an efficient unified model for a wide range of crucial tasks involving text entailment, similarity, question answering (and answerability), factual consistency, and so forth. Given a pair of texts, the model measures the degree of alignment between their information. We instantiate an alignment model through lightweight finetuning of RoBERTa (355M parameters) using 5.9M examples from 28 datasets. Despite its compact size, extensive experiments show the model's efficiency and strong performance: (1) On over 20 datasets of aforementioned diverse tasks, the model matches or surpasses FLAN-T5 models that have around 2x or 10x more parameters; the single unified model also outperforms task-specific models finetuned on individual datasets; (2) When applied to evaluate factual consistency of language generation on 23 datasets, our model improves over various baselines, including the much larger GPT-3.5 (ChatGPT) and sometimes even GPT-4; (3) The lightweight model can also serve as an add-on component for LLMs such as GPT-3.5 in question answering tasks, improving the average exact match (EM) score by 17.94 and F1 score by 15.05 through identifying unanswerable questions",
    "checked": true,
    "id": "1f7540725555c9bed7c60db685ce27457f47a064",
    "semantic_title": "text alignment is an efficient unified model for massive nlp tasks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=LjWJLkSpjh": {
    "title": "When Can We Track Significant Preference Shifts in Dueling Bandits?",
    "volume": "poster",
    "abstract": "The $K$-armed dueling bandits problem, where the feedback is in the form of noisy pairwise preferences, has been widely studied due its applications in information retrieval, recommendation systems, etc. Motivated by concerns that user preferences/tastes can evolve over time, we consider the problem of _dueling bandits with distribution shifts_. Specifically, we study the recent notion of _significant shifts_ (Suk and Kpotufe, 2022), and ask whether one can design an _adaptive_ algorithm for the dueling problem with $O(\\sqrt{K\\tilde{L}T})$ dynamic regret, where $\\tilde{L}$ is the (unknown) number of significant shifts in preferences. We show that the answer to this question depends on the properties of underlying preference distributions. Firstly, we give an impossibility result that rules out any algorithm with $O(\\sqrt{K\\tilde{L}T})$ dynamic regret under the well-studied Condorcet and SST classes of preference distributions. Secondly, we show that $\\text{SST}\\cap \\text{STI}$ is the largest amongst popular classes of preference distributions where it is possible to design such an algorithm. Overall, our results provides an almost complete resolution of the above question for the hierarchy of distribution classes",
    "checked": true,
    "id": "a6d3bcb5dc35cacca1d546b3bd777351ef35fcfa",
    "semantic_title": "when can we track significant preference shifts in dueling bandits?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=vF8ukt5l1R": {
    "title": "Self-supervised video pretraining yields robust and more human-aligned visual representations",
    "volume": "poster",
    "abstract": "Humans learn powerful representations of objects and scenes by observing how they evolve over time. Yet, outside of specific tasks that require explicit temporal understanding, static image pretraining remains the dominant paradigm for learning visual foundation models. We question this mismatch, and ask whether video pretraining can yield visual representations that bear the hallmarks of human perception: generalisation across tasks, robustness to perturbations, and consistency with human judgements. To that end we propose a novel procedure for curating videos, and develop a contrastive framework which learns from the complex transformations therein. This simple paradigm for distilling knowledge from videos, called VITO, yields general representations that far outperform prior video pretraining methods on image understanding tasks, and image pretraining methods on video understanding tasks. Moreover, VITO representations are significantly more robust to natural and synthetic deformations than image-, video-, and adversarially-trained ones. Finally, VITO's predictions are strongly aligned with human judgements, surpassing models that were specifically trained for that purpose. Together, these results suggest that video pretraining could be a simple way of learning unified, robust, and human-aligned representations of the visual world",
    "checked": false,
    "id": "7840e7043614f474af8555f20b47c884f93adea7",
    "semantic_title": "self-supervised video pretraining yields human-aligned visual representations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bzs4uPLXvi": {
    "title": "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting",
    "volume": "poster",
    "abstract": "Large Language Models (LLMs) can achieve strong performance on many tasks by producing step-by-step reasoning before giving a final output, often referred to as chain-of-thought reasoning (CoT). It is tempting to interpret these CoT explanations as the LLM's process for solving a task. This level of transparency into LLMs' predictions would yield significant safety benefits. However, we find that CoT explanations can systematically misrepresent the true reason for a model's prediction. We demonstrate that CoT explanations can be heavily influenced by adding biasing features to model inputs—e.g., by reordering the multiple-choice options in a few-shot prompt to make the answer always \"(A)\"—which models systematically fail to mention in their explanations. When we bias models toward incorrect answers, they frequently generate CoT explanations rationalizing those answers. This causes accuracy to drop by as much as 36% on a suite of 13 tasks from BIG-Bench Hard, when testing with GPT-3.5 from OpenAI and Claude 1.0 from Anthropic. On a social-bias task, model explanations justify giving answers in line with stereotypes without mentioning the influence of these social biases. Our findings indicate that CoT explanations can be plausible yet misleading, which risks increasing our trust in LLMs without guaranteeing their safety. Building more transparent and explainable systems will require either improving CoT faithfulness through targeted efforts or abandoning CoT in favor of alternative methods",
    "checked": true,
    "id": "7dc928f41e15f65f1267bd87b0fcfcc7e715cb56",
    "semantic_title": "language models don't always say what they think: unfaithful explanations in chain-of-thought prompting",
    "citation_count": 72,
    "authors": []
  },
  "https://openreview.net/forum?id=EhhPtGsVAv": {
    "title": "f-Policy Gradients: A General Framework for Goal-Conditioned RL using f-Divergences",
    "volume": "poster",
    "abstract": "Goal-Conditioned Reinforcement Learning (RL) problems often have access to sparse rewards where the agent receives a reward signal only when it has achieved the goal, making policy optimization a difficult problem. Several works augment this sparse reward with a learned dense reward function, but this can lead to sub-optimal policies if the reward is misaligned. Moreover, recent works have demonstrated that effective shaping rewards for a particular problem can depend on the underlying learning algorithm. This paper introduces a novel way to encourage exploration called $f$-Policy Gradients, or $f$-PG. $f$-PG minimizes the f-divergence between the agent's state visitation distribution and the goal, which we show can lead to an optimal policy. We derive gradients for various f-divergences to optimize this objective. Our learning paradigm provides dense learning signals for exploration in sparse reward settings. We further introduce an entropy-regularized policy optimization objective, that we call $state$-MaxEnt RL (or $s$-MaxEnt RL) as a special case of our objective. We show that several metric-based shaping rewards like L2 can be used with $s$-MaxEnt RL, providing a common ground to study such metric-based shaping rewards with efficient exploration. We find that $f$-PG has better performance compared to standard policy gradient methods on a challenging gridworld as well as the Point Maze and FetchReach environments. More information on our website https://agarwalsiddhant10.github.io/projects/fpg.html",
    "checked": false,
    "id": "2095a99fd992258995157e0e1bd67a8957a8b529",
    "semantic_title": "f-policy gradients: a general framework for goal conditioned rl using f-divergences",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Eb74zfBkWa": {
    "title": "Disentangled Wasserstein Autoencoder for T-Cell Receptor Engineering",
    "volume": "poster",
    "abstract": "In protein biophysics, the separation between the functionally important residues (forming the active site or binding surface) and those that create the overall structure (the fold) is a well-established and fundamental concept. Identifying and modifying those functional sites is critical for protein engineering but computationally non-trivial, and requires significant domain knowledge. To automate this process from a data-driven perspective, we propose a disentangled Wasserstein autoencoder with an auxiliary classifier, which isolates the function-related patterns from the rest with theoretical guarantees. This enables one-pass protein sequence editing and improves the understanding of the resulting sequences and editing actions involved. To demonstrate its effectiveness, we apply it to T-cell receptors (TCRs), a well-studied structure-function case. We show that our method can be used to alter the function of TCRs without changing the structural backbone, outperforming several competing methods in generation quality and efficiency, and requiring only 10\\% of the running time needed by baseline models. To our knowledge, this is the first approach that utilizes disentangled representations for TCR engineering",
    "checked": true,
    "id": "a546dda7c000765e390d9f9a8b9e6235c26a19c5",
    "semantic_title": "disentangled wasserstein autoencoder for t-cell receptor engineering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2yXExAl0FW": {
    "title": "A Diffusion-Model of Joint Interactive Navigation",
    "volume": "poster",
    "abstract": "Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN -- a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing",
    "checked": true,
    "id": "646c49ca9e6541650dc146fdea8c72d51b49ec05",
    "semantic_title": "a diffusion-model of joint interactive navigation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ysqlhW0v26": {
    "title": "A Unifying Perspective on Multi-Calibration: Game Dynamics for Multi-Objective Learning",
    "volume": "poster",
    "abstract": "We provide a unifying framework for the design and analysis of multi-calibrated predictors. By placing the multi-calibration problem in the general setting of multi-objective learning---where learning guarantees must hold simultaneously over a set of distributions and loss functions---we exploit connections to game dynamics to achieve state-of-the-art guarantees for a diverse set of multi-calibration learning problems. In addition to shedding light on existing multi-calibration guarantees and greatly simplifying their analysis, our approach also yields improved guarantees, such as error tolerances that scale with the square-root of group size versus the constant tolerances guaranteed by prior works, and improving the complexity of $k$-class multi-calibration by an exponential factor of $k$ versus Gopalan et al.. Beyond multi-calibration, we use these game dynamics to address emerging considerations in the study of group fairness and multi-distribution learning",
    "checked": true,
    "id": "67af01974358be7fec8a08091229bf9ed05e0d74",
    "semantic_title": "a unifying perspective on multi-calibration: game dynamics for multi-objective learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8S9Fbee743": {
    "title": "Data-driven Optimal Filtering for Linear Systems with Unknown Noise Covariances",
    "volume": "poster",
    "abstract": "This paper examines learning the optimal filtering policy, known as the Kalman gain, for a linear system with unknown noise covariance matrices using noisy output data. The learning problem is formulated as a stochastic policy optimiza- tion problem, aiming to minimize the output prediction error. This formulation provides a direct bridge between data-driven optimal control and, its dual, op- timal filtering. Our contributions are twofold. Firstly, we conduct a thorough convergence analysis of the stochastic gradient descent algorithm, adopted for the filtering problem, accounting for biased gradients and stability constraints. Secondly, we carefully leverage a combination of tools from linear system theory and high-dimensional statistics to derive bias-variance error bounds that scale logarithmically with problem dimension, and, in contrast to subspace methods, the length of output trajectories only affects the bias term",
    "checked": true,
    "id": "9fc163a857c82db813a73ccba35d5fcd01cd9108",
    "semantic_title": "data-driven optimal filtering for linear systems with unknown noise covariances",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=1wOkHN9JK8": {
    "title": "Hierarchical VAEs provide a normative account of motion processing in the primate brain",
    "volume": "poster",
    "abstract": "The relationship between perception and inference, as postulated by Helmholtz in the 19th century, is paralleled in modern machine learning by generative models like Variational Autoencoders (VAEs) and their hierarchical variants. Here, we evaluate the role of hierarchical inference and its alignment with brain function in the domain of motion perception. We first introduce a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), which enables control over motion statistics and their causes. We then present a new hierarchical VAE and test it against alternative models on two downstream tasks: (i) predicting ground truth causes of retinal optic flow (e.g., self-motion); and (ii) predicting the responses of neurons in the motion processing pathway of primates. We manipulate the model architectures (hierarchical versus non-hierarchical), loss functions, and the causal structure of the motion stimuli. We find that hierarchical latent structure in the model leads to several improvements. First, it improves the linear decodability of ground truth variables and does so in a sparse and disentangled manner. Second, our hierarchical VAE outperforms previous state-of-the-art models in predicting neuronal responses and exhibits sparse latent-to-neuron relationships. These results depend on the causal structure of the world, indicating that alignment between brains and artificial neural networks depends not only on architecture but also on matching ecologically relevant stimulus statistics. Taken together, our results suggest that hierarchical Bayesian inference underlines the brain's understanding of the world, and hierarchical VAEs can effectively model this understanding",
    "checked": true,
    "id": "e8bcf515d3346672e0d856c674fe51c045bd0f23",
    "semantic_title": "hierarchical vaes provide a normative account of motion processing in the primate brain",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZcuFDaMTYw": {
    "title": "Optimal testing using combined test statistics across independent studies",
    "volume": "poster",
    "abstract": "Combining test statistics from independent trials or experiments is a popular method of meta-analysis. However, there is very limited theoretical understanding of the power of the combined test, especially in high-dimensional models considering composite hypotheses tests. We derive a mathematical framework to study standard {meta-analysis} testing approaches in the context of the many normal means model, which serves as the platform to investigate more complex models. We introduce a natural and mild restriction on the meta-level combination functions of the local trials. This allows us to mathematically quantify the cost of compressing $m$ trials into real-valued test statistics and combining these. We then derive minimax lower and matching upper bounds for the separation rates of standard combination methods for e.g. p-values and e-values, quantifying the loss relative to using the full, pooled data. We observe an elbow effect, revealing that in certain cases combining the locally optimal tests in each trial results in a sub-optimal {meta-analysis} method and develop approaches to achieve the global optima. We also explore the possible gains of allowing limited coordination between the trial designs. Our results connect meta-analysis with bandwidth constraint distributed inference and build on recent information theoretic developments in the latter field",
    "checked": true,
    "id": "8e4d0dc7a8ee786536045df73833cb0fee798c94",
    "semantic_title": "optimal testing using combined test statistics across independent studies",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SGerL9HMrp": {
    "title": "Tracking Most Significant Shifts in Nonparametric Contextual Bandits",
    "volume": "poster",
    "abstract": "We study nonparametric contextual bandits where Lipschitz mean reward functions may change over time. We first establish the minimax dynamic regret rate in this less understood setting in terms of number of changes $L$ and total-variation $V$, both capturing all changes in distribution over context space, and argue that state-of-the-art procedures are suboptimal in this setting. Next, we tend to the question of an _adaptivity_ for this setting, i.e. achieving the minimax rate without knowledge of $L$ or $V$. Quite importantly, we posit that the bandit problem, viewed locally at a given context $X_t$, should not be affected by reward changes in other parts of context space $\\cal X$. We therefore propose a notion of _change_, which we term _experienced significant shifts_, that better accounts for locality, and thus counts considerably less changes than $L$ and $V$. Furthermore, similar to recent work on non-stationary MAB (Suk & Kpotufe, 2022), _experienced significant shifts_ only count the most _significant_ changes in mean rewards, e.g., severe best-arm changes relevant to observed contexts. Our main result is to show that this more tolerant notion of change can in fact be adapted to",
    "checked": true,
    "id": "1c0fa22e1f505e3e21bcdbb16bcaad2e90a873b1",
    "semantic_title": "tracking most significant shifts in nonparametric contextual bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xp68yXQiRk": {
    "title": "SQ Lower Bounds for Non-Gaussian Component Analysis with Weaker Assumptions",
    "volume": "poster",
    "abstract": "We study the complexity of Non-Gaussian Component Analysis (NGCA) in the Statistical Query (SQ) model. Prior work developed a methodology to prove SQ lower bounds for NGCA that have been applicable to a wide range of contexts. In particular, it was known that for any univariate distribution $A$ satisfying certain conditions, distinguishing between a standard multivariate Gaussian and a distribution that behaves like $A$ in a random hidden direction and like a standard Gaussian in the orthogonal complement, is SQ-hard. The required conditions were that (1) $A$ matches many low-order moments with a standard Gaussian, and (2) the chi-squared norm of $A$ with respect to the standard Gaussian is finite. While the moment-matching condition is clearly necessary for hardness, the chi-squared condition was only required for technical reasons. In this work, we establish that the latter condition is indeed not necessary. In particular, we prove near-optimal SQ lower bounds for NGCA under the moment-matching condition only",
    "checked": false,
    "id": "4bf17660c5b1681ba7f97c5092241747ffbbbaaf",
    "semantic_title": "electronic transactions on numerical analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PMvudWa53L": {
    "title": "Fair Adaptive Experiments",
    "volume": "poster",
    "abstract": "Randomized experiments have been the gold standard for assessing the effectiveness of a treatment, policy, or intervention, spanning various fields, including social sciences, biomedical studies, and e-commerce. The classical complete randomization approach assigns treatments based on a pre-specified probability and may lead to inefficient use of data. Adaptive experiments improve upon complete randomization by sequentially learning and updating treatment assignment probabilities using accrued evidence during the experiment. Hence, they can help achieve efficient data use and higher estimation efficiency. However, their application can also raise fairness and equity concerns, as assignment probabilities may vary drastically across groups of participants. Furthermore, when treatment is expected to be extremely beneficial to certain groups of participants, it is more appropriate to expose many of these participants to favorable treatment. In response to these challenges, we propose a fair adaptive experiment strategy that simultaneously enhances data use efficiency, achieves an ``envy-free'' treatment assignment guarantee, and improves the overall welfare of participants. An important feature of our proposed strategy is that we do not impose parametric modeling assumptions on the outcome variables, making it more versatile and applicable to a wider array of applications. Through our theoretical investigation, we characterize the convergence rate of the estimated treatment effects and the associated standard deviations at the group level and further prove that our adaptive treatment assignment algorithm, despite not having a closed-form expression, approaches the optimal allocation rule asymptotically. Our proof strategy takes into account the fact that the allocation decisions in our design depend on sequentially accumulated data, which poses a significant challenge in characterizing the properties and conducting statistical inference of our method. We further provide simulation evidence and two synthetic data studies to showcase the performance of our fair adaptive experiment strategy",
    "checked": true,
    "id": "8556a2564cc22eaf9c6e0256602ba0eba6c15ec9",
    "semantic_title": "fair adaptive experiments",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yVMlYSL1Bp": {
    "title": "Diverse Shape Completion via Style Modulated Generative Adversarial Networks",
    "volume": "poster",
    "abstract": "Shape completion aims to recover the full 3D geometry of an object from a partial observation. This problem is inherently multi-modal since there can be many ways to plausibly complete the missing regions of a shape. Such diversity would be indicative of the underlying uncertainty of the shape and could be preferable for downstream tasks such as planning. In this paper, we propose a novel conditional generative adversarial network that can produce many diverse plausible completions of a partially observed point cloud. To enable our network to produce multiple completions for the same partial input, we introduce stochasticity into our network via style modulation. By extracting style codes from complete shapes during training, and learning a distribution over them, our style codes can explicitly carry shape category information leading to better completions. We further introduce diversity penalties and discriminators at multiple scales to prevent conditional mode collapse and to train without the need for multiple ground truth completions for each partial input. Evaluations across several synthetic and real datasets demonstrate that our method achieves significant improvements in respecting the partial observations while obtaining greater diversity in completions",
    "checked": true,
    "id": "2741a717114edf363b220ea229d121f66e4f71aa",
    "semantic_title": "diverse shape completion via style modulated generative adversarial networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T5h69frFF7": {
    "title": "UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures",
    "volume": "poster",
    "abstract": "In reverberant conditions with multiple concurrent speakers, each microphone acquires a mixture signal of multiple speakers at a different location. In over-determined conditions where the microphones out-number speakers, we can narrow down the solutions to speaker images and realize unsupervised speech separation by leveraging each mixture signal as a constraint (i.e., the estimated speaker images at a microphone should add up to the mixture). Equipped with this insight, we propose UNSSOR, an algorithm for $\\underline{u}$nsupervised $\\underline{n}$eural $\\underline{s}$peech $\\underline{s}$eparation by leveraging $\\underline{o}$ver-determined training mixtu$\\underline{r}$es. At each training step, we feed an input mixture to a deep neural network (DNN) to produce an intermediate estimate for each speaker, linearly filter the estimates, and optimize a loss so that, at each microphone, the filtered estimates of all the speakers can add up to the mixture to satisfy the above constraint. We show that this loss can promote unsupervised separation of speakers. The linear filters are computed in each sub-band based on the mixture and DNN estimates through the forward convolutive prediction (FCP) algorithm. To address the frequency permutation problem incurred by using sub-band FCP, a loss term based on minimizing intra-source magnitude scattering is proposed. Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR",
    "checked": true,
    "id": "25c399a231364f4a77d1dc4b59927585e63f5f11",
    "semantic_title": "unssor: unsupervised neural speech separation by leveraging over-determined training mixtures",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yageaKlk7S": {
    "title": "Understanding the detrimental class-level effects of data augmentation",
    "volume": "poster",
    "abstract": "Data augmentation (DA) encodes invariance and provides implicit regularization critical to a model's performance in image classification tasks. However, while DA improves average accuracy, recent studies have shown that its impact can be highly class dependent: achieving optimal average accuracy comes at the cost of significantly hurting individual class accuracy by as much as 20% on ImageNet. There has been little progress in resolving class-level accuracy drops due to a limited understanding of these effects. In this work, we present a framework for understanding how DA interacts with class-level learning dynamics. Using higher-quality multi-label annotations on ImageNet, we systematically categorize the affected classes and find that the majority are inherently ambiguous, co-occur, or involve fine-grained distinctions, while DA controls the model's bias towards one of the closely related classes. While many of the previously reported performance drops are explained by multi-label annotations, we identify other sources of accuracy degradations by analyzing class confusions. We show that simple class-conditional augmentation strategies informed by our framework improve performance on the negatively affected classes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j0U6XJubbP": {
    "title": "Versatile Energy-Based Probabilistic Models for High Energy Physics",
    "volume": "poster",
    "abstract": "As a classical generative modeling approach, energy-based models have the natural advantage of flexibility in the form of the energy function. Recently, energy-based models have achieved great success in modeling high-dimensional data in computer vision and natural language processing. In line with these advancements, we build a multi-purpose energy-based probabilistic model for High Energy Physics events at the Large Hadron Collider. This framework builds on a powerful generative model and describes higher-order inter-particle interactions. It suits different encoding architectures and builds on implicit generation. As for applicational aspects, it can serve as a powerful parameterized event generator for physics simulation, a generic anomalous signal detector free from spurious correlations, and an augmented event classifier for particle identification",
    "checked": true,
    "id": "ba4ba8b18da2a2e0f1932545ffd892165ecf2a68",
    "semantic_title": "versatile energy-based probabilistic models for high energy physics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LqOQ1uJmSx": {
    "title": "Compositional Generalization from First Principles",
    "volume": "poster",
    "abstract": "Leveraging the compositional nature of our world to expedite learning and facilitate generalization is a hallmark of human perception. In machine learning, on the other hand, achieving compositional generalization has proven to be an elusive goal, even for models with explicit compositional priors. To get a better handle on compositional generalization, we here approach it from the bottom up: Inspired by identifiable representation learning, we investigate compositionality as a property of the data-generating process rather than the data itself. This reformulation enables us to derive mild conditions on only the support of the training distribution and the model architecture, which are sufficient for compositional generalization. We further demonstrate how our theoretical framework applies to real-world scenarios and validate our findings empirically. Our results set the stage for a principled theoretical study of compositional generalization",
    "checked": true,
    "id": "8cb0b1047de0bfd50f52bfb6a9f8daca4f243ec7",
    "semantic_title": "compositional generalization from first principles",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=A9mHph8GJk": {
    "title": "NAS-X: Neural Adaptive Smoothing via Twisting",
    "volume": "poster",
    "abstract": "Sequential latent variable models (SLVMs) are essential tools in statistics and machine learning, with applications ranging from healthcare to neuroscience. As their flexibility increases, analytic inference and model learning can become challenging, necessitating approximate methods. Here we introduce neural adaptive smoothing via twisting (NAS-X), a method that extends reweighted wake-sleep (RWS) to the sequential setting by using smoothing sequential Monte Carlo (SMC) to estimate intractable posterior expectations. Combining RWS and smoothing SMC allows NAS-X to provide low-bias and low-variance gradient estimates, and fit both discrete and continuous latent variable models. We illustrate the theoretical advantages of NAS-X over previous methods and explore these advantages empirically in a variety of tasks, including a challenging application to mechanistic models of neuronal dynamics. These experiments show that NAS-X substantially outperforms previous VI- and RWS-based methods in inference and model learning, achieving lower parameter error and tighter likelihood bounds",
    "checked": true,
    "id": "c74de5197a2ccebb294cecafca21c1388b276b00",
    "semantic_title": "nas-x: neural adaptive smoothing via twisting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SdYHLTCC5J": {
    "title": "SpecTr: Fast Speculative Decoding via Optimal Transport",
    "volume": "poster",
    "abstract": "Autoregressive sampling from large language models has led to state-of-the-art results in several natural language tasks. However, autoregressive sampling generates tokens one at a time making it slow, and even prohibitive in certain tasks. One way to speed up sampling is *speculative decoding*: use a small model to sample a *draft* (block or sequence of tokens), and then score all tokens in the draft by the large language model in parallel. A subset of the tokens in the draft are accepted (and the rest rejected) based on a statistical method to guarantee that the final output follows the distribution of the large model. In this work, we provide a principled understanding of speculative decoding through the lens of optimal transport (OT) with *membership cost*. This framework can be viewed as an extension of the well-known *maximal-coupling* problem. This new formulation enables us to generalize the speculative decoding method to allow for a set of $k$ candidates at the token-level, which leads to an improved optimal membership cost. We show that the optimal draft selection algorithm (transport plan) can be computed via linear programming, whose best-known runtime is exponential in $k$. We then propose a valid draft selection algorithm whose acceptance probability is $(1-1/e)$-optimal multiplicatively. Moreover, it can be computed in time almost linear with size of domain of a single token. Using this new draft selection algorithm, we develop a new autoregressive sampling algorithm called *SpecTr*, which provides speedup in decoding while ensuring that there is no quality degradation in the decoded output. We experimentally demonstrate that for state-of-the-art large language models, the proposed approach achieves a wall clock speedup of 2.13X, a further 1.37X speedup over speculative decoding on standard benchmarks",
    "checked": true,
    "id": "ea1f648988c632a6dbab6d8b88432456aa021cfb",
    "semantic_title": "spectr: fast speculative decoding via optimal transport",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=cAPMmCl2f3": {
    "title": "Fair, Polylog-Approximate Low-Cost Hierarchical Clustering",
    "volume": "poster",
    "abstract": "Research in fair machine learning, and particularly clustering, has been crucial in recent years given the many ethical controversies that modern intelligent systems have posed. Ahmadian et al. [2020] established the study of fairness in hierarchical clustering, a stronger, more structured variant of its well-known flat counterpart, though their proposed algorithm that optimizes for Dasgupta's [2016] famous cost function was highly theoretical. Knittel et al. [2023] then proposed the first practical fair approximation for cost, however they were unable to break the polynomial-approximate barrier they posed as a hurdle of interest. We break this barrier, proposing the first truly polylogarithmic-approximate low-cost fair hierarchical clustering, thus greatly bridging the gap between the best fair and vanilla hierarchical clustering approximations",
    "checked": false,
    "id": "ebb8d9c9763e42da8605694ebc2a73570a0104a7",
    "semantic_title": "fair polylog-approximate low-cost hierarchical clustering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JeKXmYb4kd": {
    "title": "Minimax-Optimal Location Estimation",
    "volume": "poster",
    "abstract": "Location estimation is one of the most basic questions in parametric statistics. Suppose we have a known distribution density $f$, and we get $n$ i.i.d. samples from $f(x-\\mu)$ for some unknown shift $\\mu$. The task is to estimate $\\mu$ to high accuracy with high probability. The maximum likelihood estimator (MLE) is known to be asymptotically optimal as $n \\to \\infty$, but what is possible for finite $n$? In this paper, we give two location estimators that are optimal under different criteria: 1) an estimator that has minimax-optimal estimation error subject to succeeding with probability $1-\\delta$ and 2) a confidence interval estimator which, subject to its output interval containing $\\mu$ with probability at least $1-\\delta$, has the minimum expected squared interval width among all shift-invariant estimators. The latter construction can be generalized to minimizing the expectation of any loss function on the interval width",
    "checked": true,
    "id": "0ff10d013be0c1fa159d83935a82a4d4140c4e36",
    "semantic_title": "minimax-optimal location estimation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=RiyH3z7oIF": {
    "title": "Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation",
    "volume": "poster",
    "abstract": "Recent studies in reinforcement learning (RL) have made significant progress by leveraging function approximation to alleviate the sample complexity hurdle for better performance. Despite the success, existing provably efficient algorithms typically rely on the accessibility of immediate feedback upon taking actions. The failure to account for the impact of delay in observations can significantly degrade the performance of real-world systems due to the regret blow-up. In this work, we tackle the challenge of delayed feedback in RL with linear function approximation by employing posterior sampling, which has been shown to empirically outperform the popular UCB algorithms in a wide range of regimes. We first introduce \\textit{Delayed-PSVI}, an optimistic value-based algorithm that effectively explores the value function space via noise perturbation with posterior sampling. We provide the first analysis for posterior sampling algorithms with delayed feedback in RL and show our algorithm achieves $\\widetilde{O}(\\sqrt{d^3H^3 T} + d^2H^2 \\mathbb{E}[\\tau])$ worst-case regret in the presence of unknown stochastic delays. Here $\\mathbb{E}[\\tau]$ is the expected delay. To further improve its computational efficiency and to expand its applicability in high-dimensional RL problems, we incorporate a gradient-based approximate sampling scheme via Langevin dynamics for \\textit{Delayed-LPSVI}, which maintains the same order-optimal regret guarantee with $\\widetilde{O}(dHK)$ computational cost. Empirical evaluations are performed to demonstrate the statistical and computational efficacy of our algorithms",
    "checked": true,
    "id": "ec2aecde467988f67b6d190479cf4b7ae7806b8c",
    "semantic_title": "posterior sampling with delayed feedback for reinforcement learning with linear function approximation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WO1kHC5Lfz": {
    "title": "Projection-Free Methods for Solving Nonconvex-Concave Saddle Point Problems",
    "volume": "poster",
    "abstract": "In this paper, we investigate a class of constrained saddle point (SP) problems where the objective function is nonconvex-concave and smooth. This class of problems has wide applicability in machine learning, including robust multi-class classification and dictionary learning. Several projection-based primal-dual methods have been developed to tackle this problem; however, the availability of methods with projection-free oracles remains limited. To address this gap, we propose efficient single-loop projection-free methods reliant on first-order information. In particular, using regularization and nested approximation techniques, we propose a primal-dual conditional gradient method that solely employs linear minimization oracles to handle constraints. Assuming that the constraint set in the maximization is strongly convex, our method achieves an $\\epsilon$-stationary solution within $\\mathcal{O}(\\epsilon^{-6})$ iterations. When the projection onto the constraint set of maximization is easy to compute, we propose a one-sided projection-free method that achieves an $\\epsilon$-stationary solution within $\\mathcal{O}(\\epsilon^{-4})$ iterations. Moreover, we present improved iteration complexities of our methods under a strong concavity assumption. To the best of our knowledge, our proposed algorithms are among the first projection-free methods with convergence guarantees for solving nonconvex-concave SP problems",
    "checked": true,
    "id": "398bdd6fa4898707bc36c73ad50d8082f30c476f",
    "semantic_title": "projection-free methods for solving nonconvex-concave saddle point problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hyPUZX03Ks": {
    "title": "A polar prediction model for learning to represent visual transformations",
    "volume": "poster",
    "abstract": "All organisms make temporal predictions, and their evolutionary fitness level depends on the accuracy of these predictions. In the context of visual perception, the motions of both the observer and objects in the scene structure the dynamics of sensory signals, allowing for partial prediction of future signals based on past ones. Here, we propose a self-supervised representation-learning framework that extracts and exploits the regularities of natural videos to compute accurate predictions. We motivate the polar architecture by appealing to the Fourier shift theorem and its group-theoretic generalization, and we optimize its parameters on next-frame prediction. Through controlled experiments, we demonstrate that this approach can discover the representation of simple transformation groups acting in data. When trained on natural video datasets, our framework achieves better prediction performance than traditional motion compensation and rivals conventional deep networks, while maintaining interpretability and speed. Furthermore, the polar computations can be restructured into components resembling normalized simple and direction-selective complex cell models of primate V1 neurons. Thus, polar prediction offers a principled framework for understanding how the visual system represents sensory inputs in a form that simplifies temporal prediction",
    "checked": true,
    "id": "2e4e79d28a7e036140758c8d1ed46b4e68604673",
    "semantic_title": "a polar prediction model for learning to represent visual transformations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xF89MjFbWp": {
    "title": "Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards",
    "volume": "poster",
    "abstract": "We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. Maillard sampling\\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting\\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we analyze the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling {and a special case of Minimum Empirical Divergence (MED)~\\cite{honda2011asymptotically}} for achieving a KL-style finite-time gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has an {adaptive} worst-case regret bound of the form $O(\\sqrt{\\mu^*(1-\\mu^*) K T \\ln K} + K \\ln T)$, where $\\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length; {this is the first time such adaptivity is reported in the literature for an algorithm with asymptotic optimality guarantees.}",
    "checked": true,
    "id": "a2a89e646183de8565fbb1a9bc1b6a6792449d65",
    "semantic_title": "kullback-leibler maillard sampling for multi-armed bandits with bounded rewards",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=thbXgJ8gNK": {
    "title": "No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models",
    "volume": "poster",
    "abstract": "The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop., RHO-loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain",
    "checked": true,
    "id": "881883842c2661b41bbfc999d56c763b1ceef0bd",
    "semantic_title": "no train no gain: revisiting efficient training algorithms for transformer-based language models",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=DzaCE00jGV": {
    "title": "Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder",
    "volume": "poster",
    "abstract": "Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In order to measure perturbation-specific model-properties, we also introduce a framework for evaluation of perturbation models based on average treatment effects with links to posterior predictive checks. SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, including a combinatorial reasoning task under resource paucity, and yields interpretable latent structures which correlate strongly to known biological mechanisms. Our results suggest SAMS-VAE is an interesting addition to the modeling toolkit for machine learning-driven scientific discovery",
    "checked": true,
    "id": "6f4b1caaec3342214fc92c5e6161daa75ffd9ea8",
    "semantic_title": "modelling cellular perturbations with the sparse additive mechanism shift variational autoencoder",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DD0QJvPbTD": {
    "title": "ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP",
    "volume": "poster",
    "abstract": "Backdoor attacks have emerged as a prominent threat to natural language processing (NLP) models, where the presence of specific triggers in the input can lead poisoned models to misclassify these inputs to predetermined target classes. Current detection mechanisms are limited by their inability to address more covert backdoor strategies, such as style-based attacks. In this work, we propose an innovative test-time poisoned sample detection framework that hinges on the interpretability of model predictions, grounded in the semantic meaning of inputs. We contend that triggers (e.g., infrequent words) are not supposed to fundamentally alter the underlying semantic meanings of poisoned samples as they want to stay stealthy. Based on this observation, we hypothesize that while the model's predictions for paraphrased clean samples should remain stable, predictions for poisoned samples should revert to their true labels upon the mutations applied to triggers during the paraphrasing process. We employ ChatGPT, a state-of-the-art large language model, as our paraphraser and formulate the trigger-removal task as a prompt engineering problem. We adopt fuzzing, a technique commonly used for unearthing software vulnerabilities, to discover optimal paraphrase prompts that can effectively eliminate triggers while concurrently maintaining input semantics. Experiments on 4 types of backdoor attacks, including the subtle style backdoors, and 4 distinct datasets demonstrate that our approach surpasses baseline methods, including STRIP, RAP, and ONION, in precision and recall",
    "checked": true,
    "id": "3a733c27bff68259b17dc4f835b0d192ac8fab70",
    "semantic_title": "parafuzz: an interpretability-driven technique for detecting poisoned samples in nlp",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CpoS56pYnU": {
    "title": "HiNeRV: Video Compression with Hierarchical Encoding-based Neural Representation",
    "volume": "poster",
    "abstract": "Learning-based video compression is currently a popular research topic, offering the potential to compete with conventional standard video codecs. In this context, Implicit Neural Representations (INRs) have previously been used to represent and compress image and video content, demonstrating relatively high decoding speed compared to other methods. However, existing INR-based methods have failed to deliver rate quality performance comparable with the state of the art in video compression. This is mainly due to the simplicity of the employed network architectures, which limit their representation capability. In this paper, we propose HiNeRV, an INR that combines light weight layers with novel hierarchical positional encodings. We employs depth-wise convolutional, MLP and interpolation layers to build the deep and wide network architecture with high capacity. HiNeRV is also a unified representation encoding videos in both frames and patches at the same time, which offers higher performance and flexibility than existing methods. We further build a video codec based on HiNeRV and a refined pipeline for training, pruning and quantization that can better preserve HiNeRV's performance during lossy model compression. The proposed method has been evaluated on both UVG and MCL-JCV datasets for video compression, demonstrating significant improvement over all existing INRs baselines and competitive performance when compared to learning-based codecs (72.3\\% overall bit rate saving over HNeRV and 43.4\\% over DCVC on the UVG dataset, measured in PSNR)",
    "checked": false,
    "id": "c68fc0ba113ee54ffa8d54969563fe722a364188",
    "semantic_title": "hinerv: video compression with hierarchical encoding based neural representation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AesN5bYnJr": {
    "title": "No-Regret Online Prediction with Strategic Experts",
    "volume": "poster",
    "abstract": "We study a generalization of the online binary prediction with expert advice framework where at each round, the learner is allowed to pick $m\\geq 1$ experts from a pool of $K$ experts and the overall utility is a modular or submodular function of the chosen experts. We focus on the setting in which experts act strategically and aim to maximize their influence on the algorithm's predictions by potentially misreporting their beliefs about the events. Among others, this setting finds applications in forecasting competitions where the learner seeks not only to make predictions by aggregating different forecasters but also to rank them according to their relative performance. Our goal is to design algorithms that satisfy the following two requirements: 1) \\emph{Incentive-compatible}: Incentivize the experts to report their beliefs truthfully, and 2) \\emph{No-regret}: Achieve sublinear regret with respect to the true beliefs of the best fixed set of $m$ experts in hindsight. Prior works have studied this framework when $m=1$ and provided incentive-compatible no-regret algorithms for the problem. We first show that a simple reduction of our problem to the $m=1$ setting is neither efficient nor effective. Then, we provide algorithms that utilize the specific structure of the utility functions to achieve the two desired goals",
    "checked": true,
    "id": "fa28c67648345665299a9c78c297951cc914d968",
    "semantic_title": "no-regret online prediction with strategic experts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sL4pJBXkxu": {
    "title": "ELDEN: Exploration via Local Dependencies",
    "volume": "poster",
    "abstract": "Tasks with large state space and sparse rewards present a longstanding challenge to reinforcement learning. In these tasks, an agent needs to explore the state space efficiently until it finds a reward. To deal with this problem, the community has proposed to augment the reward function with intrinsic reward, a bonus signal that encourages the agent to visit interesting states. In this work, we propose a new way of defining interesting states for environments with factored state spaces and complex chained dependencies, where an agent's actions may change the value of one entity that, in order, may affect the value of another entity. Our insight is that, in these environments, interesting states for exploration are states where the agent is uncertain whether (as opposed to how) entities such as the agent or objects have some influence on each other. We present ELDEN, Exploration via Local DepENdencies, a novel intrinsic reward that encourages the discovery of new interactions between entities. ELDEN utilizes a novel scheme --- the partial derivative of the learned dynamics to model the local dependencies between entities accurately and computationally efficiently. The uncertainty of the predicted dependencies is then used as an intrinsic reward to encourage exploration toward new interactions. We evaluate the performance of ELDEN on four different domains with complex dependencies, ranging from 2D grid worlds to 3D robotic tasks. In all domains, ELDEN correctly identifies local dependencies and learns successful policies, significantly outperforming previous state-of-the-art exploration methods",
    "checked": true,
    "id": "c35cd153d65b6a0f72f6fb398879344eb2150198",
    "semantic_title": "elden: exploration via local dependencies",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=nI7EmXq2PL": {
    "title": "$H$-Consistency Bounds: Characterization and Extensions",
    "volume": "poster",
    "abstract": "A series of recent publications by Awasthi et al. have introduced the key notion of *$H$-consistency bounds* for surrogate loss functions. These are upper bounds on the zero-one estimation error of any predictor in a hypothesis set, expressed in terms of its surrogate loss estimation error. They are both non-asymptotic and hypothesis set-specific and thus stronger and more informative than Bayes-consistency. However, determining if they hold and deriving these bounds have required a specific proof and analysis for each surrogate loss. Can we derive more general tools and characterizations? This paper provides both a general characterization and an extension of $H$-consistency bounds for multi-class classification. We present new and tight $H$-consistency bounds for both the family of constrained losses and that of comp-sum losses, which covers the familiar cross-entropy, or logistic loss applied to the outputs of a neural network. We further extend our analysis beyond the completeness assumptions adopted in previous studies and cover more realistic bounded hypothesis sets. Our characterizations are based on error transformations, which are explicitly defined for each formulation. We illustrate the application of our general results through several special examples. A by-product of our analysis is the observation that a recently derived multi-class $H$-consistency bound for cross-entropy reduces to an excess bound and is not significant. Instead, we prove a much stronger and more significant guarantee",
    "checked": false,
    "id": "20648e75481b3ecf43faf47444913241117e893d",
    "semantic_title": "strict domain monotonicity of the principal eigenvalue and a characterization of lower boundedness for the friedrichs extension of four-coefficient sturm–liouville operators",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lkEiOZlmPm": {
    "title": "Single-Pass Pivot Algorithm for Correlation Clustering. Keep it simple!",
    "volume": "poster",
    "abstract": "We show that a simple single-pass semi-streaming variant of the Pivot algorithm for Correlation Clustering gives a (3+eps)-approximation using O(n/eps) words of memory. This is a slight improvement over the recent results of Cambus, Kuhn, Lindy, Pai, and Uitto, who gave a (3+eps)-approximation using O(n log n) words of memory, and Behnezhad, Charikar, Ma, and Tan, who gave a 5-approximation using O(n) words of memory. One of the main contributions of our paper is that the algorithm and its analysis are simple and easy to understand",
    "checked": true,
    "id": "cc25365115caace3df7491ff1706b767a70bca67",
    "semantic_title": "single-pass pivot algorithm for correlation clustering. keep it simple!",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=IrjXmIKFyx": {
    "title": "Model-free Posterior Sampling via Learning Rate Randomization",
    "volume": "poster",
    "abstract": "In this paper, we introduce Randomized Q-learning (RandQL), a novel randomized model-free algorithm for regret minimization in episodic Markov Decision Processes (MDPs). To the best of our knowledge, RandQL is the first tractable model-free posterior sampling-based algorithm. We analyze the performance of RandQL in both tabular and non-tabular metric space settings. In tabular MDPs, RandQL achieves a regret bound of order $\\widetilde{\\mathcal{O}}(\\sqrt{H^{5}SAT})$, where $H$ is the planning horizon, $S$ is the number of states, $A$ is the number of actions, and $T$ is the number of episodes. For a metric state-action space, RandQL enjoys a regret bound of order $\\widetilde{\\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where $d_z$ denotes the zooming dimension. Notably, RandQL achieves optimistic exploration without using bonuses, relying instead on a novel idea of learning rate randomization. Our empirical study shows that RandQL outperforms existing approaches on baseline exploration environments",
    "checked": true,
    "id": "56b7e773e5738f8b3fb0ee616785b9003955fe20",
    "semantic_title": "model-free posterior sampling via learning rate randomization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sw2Y0sirtM": {
    "title": "A Unified, Scalable Framework for Neural Population Decoding",
    "volume": "poster",
    "abstract": "Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both the model size and the datasets. However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals. In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings. Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity. We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities. Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings. In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels. This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale for neural decoding models",
    "checked": true,
    "id": "b1cab4d3ed28cc66b733de017cf16c58bf0c2707",
    "semantic_title": "a unified, scalable framework for neural population decoding",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=iSd8g75QvP": {
    "title": "A Trichotomy for Transductive Online Learning",
    "volume": "poster",
    "abstract": "We present new upper and lower bounds on the number of learner mistakes in the `transductive' online learning setting of Ben-David, Kushilevitz and Mansour (1997). This setting is similar to standard online learning, except that the adversary fixes a sequence of instances $x_1,\\dots,x_n$ to be labeled at the start of the game, and this sequence is known to the learner. Qualitatively, we prove a \\emph{trichotomy}, stating that the minimal number of mistakes made by the learner as $n$ grows can take only one of precisely three possible values: $n$, $\\Theta\\left(\\log (n)\\right)$, or $\\Theta(1)$. Furthermore, this behavior is determined by a combination of the VC dimension and the Littlestone dimension. Quantitatively, we show a variety of bounds relating the number of mistakes to well-known combinatorial dimensions. In particular, we improve the known lower bound on the constant in the $\\Theta(1)$ case from $\\Omega\\left(\\sqrt{\\log(d)}\\right)$ to $\\Omega(\\log(d))$ where $d$ is the Littlestone dimension. Finally, we extend our results to cover multiclass classification and the agnostic setting",
    "checked": true,
    "id": "4f02c28bfdf43a8dd474cb8240ec9819f50ab00c",
    "semantic_title": "a trichotomy for transductive online learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nafgeYknRT": {
    "title": "Generating Behaviorally Diverse Policies with Latent Diffusion Models",
    "volume": "poster",
    "abstract": "Recent progress in Quality Diversity Reinforcement Learning (QD-RL) has enabled learning a collection of behaviorally diverse, high performing policies. However, these methods typically involve storing thousands of policies, which results in high space-complexity and poor scaling to additional behaviors. Condensing the archive into a single model while retaining the performance and coverage of the original collection of policies has proved challenging. In this work, we propose using diffusion models to distill the archive into a single generative model over policy parameters. We show that our method achieves a compression ratio of 13x while recovering 98% of the original rewards and 89% of the original humanoid archive coverage. Further, the conditioning mechanism of diffusion models allows for flexibly selecting and sequencing behaviors, including using language. Project website: https://sites.google.com/view/policydiffusion/home",
    "checked": true,
    "id": "569648a84a6fa3b9e3659c60047d63ed04d5c175",
    "semantic_title": "generating behaviorally diverse policies with latent diffusion models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=KoQgA0coZ9": {
    "title": "Distributed Personalized Empirical Risk Minimization",
    "volume": "poster",
    "abstract": "This paper advocates a new paradigm Personalized Empirical Risk Minimization (PERM) to facilitate learning from heterogeneous data sources without imposing stringent constraints on computational resources shared by participating devices. In PERM, we aim at learning a distinct model for each client by personalizing the aggregation of local empirical losses by effectively estimating the statistical discrepancy among data distributions, which entails optimal statistical accuracy for all local distributions and overcomes the data heterogeneity issue. To learn personalized models at scale, we propose a distributed algorithm that replaces the standard model averaging with model shuffling to simultaneously optimize PERM objectives for all devices. This also allows to learn distinct model architectures (e.g., neural networks with different number of parameters) for different clients, thus confining to underlying memory and compute resources of individual clients. We rigorously analyze the convergence of proposed algorithm and conduct experiments that corroborates the effectiveness of proposed paradigm",
    "checked": true,
    "id": "f738fa0230694eece011e98053e51407098e2be3",
    "semantic_title": "distributed personalized empirical risk minimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YZ7ip645Ra": {
    "title": "Structured Prediction with Stronger Consistency Guarantees",
    "volume": "poster",
    "abstract": "We present an extensive study of surrogate losses for structured prediction supported by *$H$-consistency bounds*. These are recently introduced guarantees that are more relevant to learning than Bayes-consistency, since they are not asymptotic and since they take into account the hypothesis set $H$ used. We first show that no non-trivial $H$-consistency bound can be derived for widely used surrogate structured prediction losses. We then define several new families of surrogate losses, including *structured comp-sum losses* and *structured constrained losses*, for which we prove $H$-consistency bounds and thus Bayes-consistency. These loss functions readily lead to new structured prediction algorithms with stronger theoretical guarantees, based on their minimization. We describe efficient algorithms for minimizing several of these surrogate losses, including a new *structured logistic loss*",
    "checked": false,
    "id": "17027013e5e5e526422349541ad3b9793e4eeac7",
    "semantic_title": "structured prediction: statistical and computational guarantees in learning and inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PYEgC56flW": {
    "title": "Feature Learning for Interpretable, Performant Decision Trees",
    "volume": "poster",
    "abstract": "Decision trees are regarded for high interpretability arising from their hierarchical partitioning structure built on simple decision rules. However, in practice, this is not realized because axis-aligned partitioning of realistic data results in deep trees, and because ensemble methods are used to mitigate overfitting. Even then, model complexity and performance remain sensitive to transformation of the input, and extensive expert crafting of features from the raw data is common. We propose the first system to alternate sparse feature learning with differentiable decision tree construction to produce small, interpretable trees with good performance. We benchmark against conventional tree-based models and demonstrate several notions of interpretation of a model and its predictions",
    "checked": false,
    "id": "b5cd009b9b6cdc293d70aa4d869cb8ea5d9e2da6",
    "semantic_title": "deep natural language feature learning for interpretable prediction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QpZubU4yD9": {
    "title": "Advice Querying under Budget Constraint for Online Algorithms",
    "volume": "poster",
    "abstract": "Several problems have been extensively studied in the learning-augmented setting, where the algorithm has access to some, possibly incorrect, predictions. However, it is assumed in most works that the predictions are provided to the algorithm as input, with no constraint on their size. In this paper, we consider algorithms with access to a limited number of predictions, that they can request at any time during their execution. We study three classical problems in competitive analysis, the ski rental problem, the secretary problem, and the non-clairvoyant job scheduling. We address the question of when to query predictions and how to use them",
    "checked": false,
    "id": "00a98a37bb919bf504c76769df6152ed16d532ad",
    "semantic_title": "privacy budgeting for growing machine learning datasets",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=BtAz4a5xDg": {
    "title": "Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression",
    "volume": "poster",
    "abstract": "Pretrained transformers exhibit the remarkable ability of in-context learning (ICL): they can learn tasks from just a few examples provided in the prompt without updating any weights. This raises a foundational question: can ICL solve fundamentally _new_ tasks that are very different from those seen during pretraining? To probe this question, we examine ICL's performance on linear regression while varying the diversity of tasks in the pretraining dataset. We empirically demonstrate a _task diversity threshold_ for the emergence of ICL. Below this threshold, the pretrained transformer cannot solve unseen regression tasks, instead behaving like a Bayesian estimator with the _non-diverse pretraining task distribution_ as the prior. Beyond this threshold, the transformer significantly outperforms this estimator; its behavior aligns with that of ridge regression, corresponding to a Gaussian prior over _all tasks_, including those not seen during pretraining. Thus, when pretrained on data with task diversity greater than the threshold, transformers _can_ optimally solve fundamentally new tasks in-context. Importantly, this capability hinges on it deviating from the Bayes optimal estimator with the pretraining distribution as the prior. This study also explores the effect of regularization, model capacity and task structure and underscores, in a concrete example, the critical role of task diversity, alongside data and model scale, in the emergence of ICL",
    "checked": true,
    "id": "4c60ce3e5116037390b3b92866f43df83f3e9c6f",
    "semantic_title": "pretraining task diversity and the emergence of non-bayesian in-context learning for regression",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=axmY49ahVI": {
    "title": "Experiment Planning with Function Approximation",
    "volume": "poster",
    "abstract": "We study the problem of experiment planning with function approximation in contextual bandit problems. In settings where there is a significant overhead to deploying adaptive algorithms; for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies, producing in advance a set of policies for data collection is paramount. We study the setting where a large dataset of contexts -but not rewards- is available and may be used by the learner to design an effective data collection strategy. Although when rewards are linear this problem has been well studied, results are still missing for more complex reward models. In this work we propose two experiment planning strategies compatible with function approximation, first an eluder planning and sampling procedure that can recover optimality guarantees depending on the eluder dimension of the reward function class, and second we show the uniform sampler achieves competitive optimality rates in the setting where the number of actions is small. We finalize our results introducing a statistical gap fleshing out the fundamental differences between planning and adaptive learning and provide results for planning with model selection",
    "checked": false,
    "id": "88298748d970690e09fe6043d68125b93ccce89d",
    "semantic_title": "near-optimal deployment efficiency in reward-free reinforcement learning with linear function approximation",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=g1dMYenhe4": {
    "title": "MIMEx: Intrinsic Rewards from Masked Input Modeling",
    "volume": "poster",
    "abstract": "Exploring in environments with high-dimensional observations is hard. One promising approach for exploration is to use intrinsic rewards, which often boils down to estimating \"novelty\" of states, transitions, or trajectories with deep networks. Prior works have shown that conditional prediction objectives such as masked autoencoding can be seen as stochastic estimation of pseudo-likelihood. We show how this perspective naturally leads to a unified view on existing intrinsic reward approaches: they are special cases of conditional prediction, where the estimation of novelty can be seen as pseudo-likelihood estimation with different mask distributions. From this view, we propose a general framework for deriving intrinsic rewards -- Masked Input Modeling for Exploration (MIMEx) -- where the mask distribution can be flexibly tuned to control the difficulty of the underlying conditional prediction task. We demonstrate that MIMEx can achieve superior results when compared against competitive baselines on a suite of challenging sparse-reward visuomotor tasks",
    "checked": true,
    "id": "af9e69ec120e94b5542edf88b392ee3769c1379b",
    "semantic_title": "mimex: intrinsic rewards from masked input modeling",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=g78QqvhnDU": {
    "title": "Prioritizing Samples in Reinforcement Learning with Reducible Loss",
    "volume": "poster",
    "abstract": "Most reinforcement learning algorithms take advantage of an experience replay buffer to repeatedly train on samples the agent has observed in the past. Not all samples carry the same amount of significance and simply assigning equal importance to each of the samples is a naïve strategy. In this paper, we propose a method to prioritize samples based on how much we can learn from a sample. We define the learn-ability of a sample as the steady decrease of the training loss associated with this sample over time. We develop an algorithm to prioritize samples with high learn-ability, while assigning lower priority to those that are hard-to-learn, typically caused by noise or stochasticity. We empirically show that across multiple domains our method is more robust than random sampling and also better than just prioritizing with respect to the training loss, i.e. the temporal difference loss, which is used in prioritized experience replay",
    "checked": true,
    "id": "eb92cedb7e9182b8887a36d25f319196e11d9ca4",
    "semantic_title": "prioritizing samples in reinforcement learning with reducible loss",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=eT1tMdAUoc": {
    "title": "Spatially Resolved Gene Expression Prediction from Histology Images via Bi-modal Contrastive Learning",
    "volume": "poster",
    "abstract": "Histology imaging is an important tool in medical diagnosis and research, enabling the examination of tissue structure and composition at the microscopic level. Understanding the underlying molecular mechanisms of tissue architecture is critical in uncovering disease mechanisms and developing effective treatments.Gene expression profiling provides insight into the molecular processes underlying tissue architecture, but the process can be time-consuming and expensive. We present BLEEP (Bi-modaL Embedding for Expression Prediction), a bi-modal embedding framework capable of generating spatially resolved gene expression profiles of whole-slide Hematoxylin and eosin (H&E) stained histology images. BLEEP uses contrastive learning to construct a low-dimensional joint embedding space from a reference dataset using paired image and expression profiles at micrometer resolution. With this approach, the gene expression of any query image patch can be imputed using the expression profiles from the reference dataset. We demonstrate BLEEP's effectiveness in gene expression prediction by benchmarking its performance on a human liver tissue dataset captured using the 10x Visium platform, where it achieves significant improvements over existing methods. Our results demonstrate the potential of BLEEP to provide insights into the molecular mechanisms underlying tissue architecture, with important implications in diagnosis and research of various diseases. The proposed approach can significantly reduce the time and cost associated with gene expression profiling, opening up new avenues for high-throughput analysis of histology images for both research and clinical applications",
    "checked": false,
    "id": "0b61d7f9ffebf187a4cb290418b202433e85455c",
    "semantic_title": "spatially resolved gene expression prediction from h&e histology images via bi-modal contrastive learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=tLTtqySDFb": {
    "title": "Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts",
    "volume": "poster",
    "abstract": "Neuro-Symbolic (NeSy) predictive models hold the promise of improved compliance with given constraints, systematic generalization, and interpretability, as they allow to infer labels that are consistent with some prior knowledge by reasoning over high-level concepts extracted from sub-symbolic inputs. It was recently shown that NeSy predictors are affected by *reasoning shortcuts*: they can attain high accuracy but by leveraging concepts with \\textit{unintended semantics}, thus coming short of their promised advantages. Yet, a systematic characterization of reasoning shortcuts and of potential mitigation strategies is missing. This work fills this gap by characterizing them as unintended optima of the learning objective and identifying four key conditions behind their occurrence. Based on this, we derive several natural mitigation strategies, and analyze their efficacy both theoretically and empirically. Our analysis shows reasoning shortcuts are difficult to deal with, casting doubts on the trustworthiness and interpretability of existing NeSy solutions",
    "checked": true,
    "id": "0af70f21747a70f7ef336991caaca7410fb7aa9f",
    "semantic_title": "not all neuro-symbolic concepts are created equal: analysis and mitigation of reasoning shortcuts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2OcNWFHFpk": {
    "title": "Group Robust Classification Without Any Group Information",
    "volume": "poster",
    "abstract": "Empirical risk minimization (ERM) is sensitive to spurious correlations present in training data, which poses a significant risk when deploying systems trained under this paradigm in high-stake applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these quantities is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation",
    "checked": true,
    "id": "fd483916871ec8555e86ab51f031e4d5763b9bd8",
    "semantic_title": "group robust classification without any group information",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v0lkbp66Uw": {
    "title": "Egocentric Planning for Scalable Embodied Task Achievement",
    "volume": "poster",
    "abstract": "Embodied agents face significant challenges when tasked with performing actions in diverse environments, particularly in generalizing across object types and executing suitable actions to accomplish tasks. Furthermore, agents should exhibit robustness, minimizing the execution of illegal actions. In this work, we present Egocentric Planning, an innovative approach that combines symbolic planning and Object-oriented POMDPs to solve tasks in complex environments, harnessing existing models for visual perception and natural language processing. We evaluated our approach in ALFRED, a simulated environment designed for domestic tasks, and demonstrated its high scalability, achieving an impressive 36.07\\% unseen success rate in the ALFRED benchmark and winning the ALFRED challenge at CVPR Embodied AI workshop. Our method requires reliable perception and the specification or learning of a symbolic description of the preconditions and effects of the agent's actions, as well as what object types reveal information about others. It can naturally scale to solve new tasks beyond ALFRED, as long as they can be solved using the available skills. This work offers a solid baseline for studying end-to-end and hybrid methods that aim to generalize to new tasks, including recent approaches relying on LLMs, but often struggle to scale to long sequences of actions or produce robust plans for novel tasks",
    "checked": true,
    "id": "440682e0df3ee90b85f6eaee32da5c86fb5870b2",
    "semantic_title": "egocentric planning for scalable embodied task achievement",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ba4boN3W1n": {
    "title": "Lie Point Symmetry and Physics-Informed Networks",
    "volume": "poster",
    "abstract": "Symmetries have been leveraged to improve the generalization of neural networks through different mechanisms from data augmentation to equivariant architectures. However, despite their potential, their integration into neural solvers for partial differential equations (PDEs) remains largely unexplored. We explore the integration of PDE symmetries, known as Lie point symmetries, in a major family of neural solvers known as physics-informed neural networks (PINNs). We propose a loss function that informs the network about Lie point symmetries in the same way that PINN models try to enforce the underlying PDE through a loss function. Intuitively, our symmetry loss ensures that the infinitesimal generators of the Lie group conserve the PDE solutions.. Effectively, this means that once the network learns a solution, it also learns the neighbouring solutions generated by Lie point symmetries. Empirical evaluations indicate that the inductive bias introduced by the Lie point symmetries of the PDEs greatly boosts the sample efficiency of PINNs",
    "checked": false,
    "id": "4a566c1a96190993cb597c2ab504514b6b217448",
    "semantic_title": "lie point symmetry and physics informed networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=URrUpcp6Qh": {
    "title": "PAC-Bayes Generalization Certificates for Learned Inductive Conformal Prediction",
    "volume": "poster",
    "abstract": "Inductive Conformal Prediction (ICP) provides a practical and effective approach for equipping deep learning models with uncertainty estimates in the form of set-valued predictions which are guaranteed to contain the ground truth with high probability. Despite the appeal of this coverage guarantee, these sets may not be efficient: the size and contents of the prediction sets are not directly controlled, and instead depend on the underlying model and choice of score function. To remedy this, recent work has proposed learning model and score function parameters using data to directly optimize the efficiency of the ICP prediction sets. While appealing, the generalization theory for such an approach is lacking: direct optimization of empirical efficiency may yield prediction sets that are either no longer efficient on test data, or no longer obtain the required coverage on test data. In this work, we use PAC-Bayes theory to obtain generalization bounds on both the coverage and the efficiency of set-valued predictors which can be directly optimized to maximize efficiency while satisfying a desired test coverage. In contrast to prior work, our framework allows us to utilize the entire calibration dataset to learn the parameters of the model and score function, instead of requiring a separate hold-out set for obtaining test-time coverage guarantees. We leverage these theoretical results to provide a practical algorithm for using calibration data to simultaneously fine-tune the parameters of a model and score function while guaranteeing test-time coverage and efficiency of the resulting prediction sets. We evaluate the approach on regression and classification tasks, and outperform baselines calibrated using a Hoeffding bound-based PAC guarantee on ICP, especially in the low-data regime",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=toYvRJ7Zmy": {
    "title": "Derandomized novelty detection with FDR control via conformal e-values",
    "volume": "poster",
    "abstract": "Conformal inference provides a general distribution-free method to rigorously calibrate the output of any machine learning algorithm for novelty detection. While this approach has many strengths, it has the limitation of being randomized, in the sense that it may lead to different results when analyzing twice the same data and this can hinder the interpretation of any findings. We propose to make conformal inferences more stable by leveraging suitable conformal e-values instead of p-values to quantify statistical significance. This solution allows the evidence gathered from multiple analyses of the same data to be aggregated effectively while provably controlling the false discovery rate. Further, we show that the proposed method can reduce randomness without much loss of power compared to standard conformal inference, partly thanks to an innovative way of weighting conformal e-values based on additional side information carefully extracted from the same data. Simulations with synthetic and real data confirm this solution can be effective at eliminating random noise in the inferences obtained with state-of-the-art alternative techniques, sometimes also leading to higher power",
    "checked": true,
    "id": "46da050daf54a205b1ce76fcbfc11d7d1fcd5886",
    "semantic_title": "derandomized novelty detection with fdr control via conformal e-values",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=lBhRTO2uWf": {
    "title": "Adversarial Learning for Feature Shift Detection and Correction",
    "volume": "poster",
    "abstract": "Data shift is a phenomenon present in many real-world applications, and while there are multiple methods attempting to detect shifts, the task of localizing and correcting the features originating such shifts has not been studied in depth. Feature shifts can occur in many datasets, including in multi-sensor data, where some sensors are malfunctioning, or in tabular and structured data, including biomedical, financial, and survey data, where faulty standardization and data processing pipelines can lead to erroneous features. In this work, we explore using the principles of adversarial learning, where the information from several discriminators trained to distinguish between two distributions is used to both detect the corrupted features and fix them in order to remove the distribution shift between datasets. We show that mainstream supervised classifiers, such as random forest or gradient boosting trees, combined with simple iterative heuristics, can localize and correct feature shifts, outperforming current statistical and neural network-based techniques. The code is available at https://github.com/AI-sandbox/DataFix",
    "checked": false,
    "id": "23382cc8e95cbe510aeaad1bc2552cd6c31b5e44",
    "semantic_title": "machine learning optical proximity correction with generative adversarial networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=B4tkwuzeiY": {
    "title": "Grammar Prompting for Domain-Specific Language Generation with Large Language Models",
    "volume": "poster",
    "abstract": "Large language models (LLMs) can learn to perform a wide range of natural language tasks from just a handful of in-context examples. However, for generating strings from highly structured languages (e.g., semantic parsing to complex domain-specific languages), it is challenging for the LLM to generalize from just a few exemplars. We propose \\emph{grammar prompting}, a simple approach to enable LLMs to use external knowledge and domain-specific constraints, expressed through a grammar in Backus--Naur Form (BNF), during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and SMILES-based molecule generation",
    "checked": true,
    "id": "af705d648b5b16daa3dcc593bc593f2574d76c07",
    "semantic_title": "grammar prompting for domain-specific language generation with large language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=8Oukmqfek2": {
    "title": "Rethinking Gauss-Newton for learning over-parameterized models",
    "volume": "poster",
    "abstract": "This work studies the global convergence and implicit bias of Gauss Newton's (GN) when optimizing over-parameterized one-hidden layer networks in the mean-field regime. We first establish a global convergence result for GN in the continuous-time limit exhibiting a faster convergence rate compared to GD due to improved conditioning. We then perform an empirical study on a synthetic regression task to investigate the implicit bias of GN's method. While GN is consistently faster than GD in finding a global optimum, the learned model generalizes well on test data when starting from random initial weights with a small variance and using a small step size to slow down convergence. Specifically, our study shows that such a setting results in a hidden learning phenomenon, where the dynamics are able to recover features with good generalization properties despite the model having sub-optimal training and test performances due to an under-optimized linear layer. This study exhibits a trade-off between the convergence speed of GN and the generalization ability of the learned solution",
    "checked": true,
    "id": "7a468482707a48cc1fb69a020cbd35691432d020",
    "semantic_title": "rethinking gauss-newton for learning over-parameterized models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=50hs53Zb3w": {
    "title": "Recovering Simultaneously Structured Data via Non-Convex Iteratively Reweighted Least Squares",
    "volume": "poster",
    "abstract": "We propose a new algorithm for the problem of recovering data that adheres to multiple, heterogenous low-dimensional structures from linear observations. Focussing on data matrices that are simultaneously row-sparse and low-rank, we propose and analyze an iteratively reweighted least squares (IRLS) algorithm that is able to leverage both structures. In particular, it optimizes a combination of non-convex surrogates for row-sparsity and rank, a balancing of which is built into the algorithm. We prove locally quadratic convergence of the iterates to a simultaneously structured data matrix in a regime of minimal sample complexity (up to constants and a logarithmic factor), which is known to be impossible for a combination of convex surrogates. In experiments, we show that the IRLS method exhibits favorable empirical convergence, identifying simultaneously row-sparse and low-rank matrices from fewer measurements than state-of-the-art methods",
    "checked": true,
    "id": "51fcce857decb4921ee2ec97643c3f4297f01ea0",
    "semantic_title": "recovering simultaneously structured data via non-convex iteratively reweighted least squares",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=gAQCx61chN": {
    "title": "SOL: Sampling-based Optimal Linear bounding of arbitrary scalar functions",
    "volume": "poster",
    "abstract": "Finding tight linear bounds for activation functions in neural networks is an essential part of several state of the art neural network robustness certification tools. An activation function is an arbitrary, nonlinear, scalar function $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$. In the existing work on robustness certification, such bounds have been computed using human ingenuity for a handful of the most popular activation functions. While a number of heuristics have been proposed for bounding arbitrary functions, no analysis of the tightness optimality for general scalar functions has been offered yet, to the best of our knowledge. We fill this gap by formulating a concise optimality criterion for tightness of the approximation which allows us to build optimal bounds for any function convex in the region of interest $R$. For a more general class of functions Lipshitz-continuous in $R$ we propose a sampling-based approach (SOL) which, given an instance of the bounding problem, efficiently computes the tightest linear bounds within a given $\\varepsilon > 0$ threshold. We leverage an adaptive sampling technique to iteratively build a set of sample points suitable for representing the target activation function. While the theoretical worst case time complexity of our approach is $O(\\varepsilon^{-2d})$, it typically only takes $O(\\log^{\\beta} \\frac{1}{\\varepsilon})$ time for some $\\beta \\ge 1$ and is thus sufficiently fast in practice. We provide empirical evidence of SOL's practicality by incorporating it into a robustness certifier and observing that it produces similar or higher certification rates while taking as low as quarter of the time compared to the other methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w79RtqIyoM": {
    "title": "Compositional Sculpting of Iterative Generative Processes",
    "volume": "poster",
    "abstract": "High training costs of generative models and the need to fine-tune them for specific tasks have created a strong interest in model reuse and composition. A key challenge in composing iterative generative processes, such as GFlowNets and diffusion models, is that to realize the desired target distribution, all steps of the generative process need to be coordinated, and satisfy delicate balance conditions. In this work, we propose Compositional Sculpting: a general approach for defining compositions of iterative generative processes. We then introduce a method for sampling from these compositions built on classifier guidance. We showcase ways to accomplish compositional sculpting in both GFlowNets and diffusion models. We highlight two binary operations $\\\\unicode{x2014}$ the $\\\\textit{harmonic mean}\\\\unicode{x00A0}(p_1 \\\\otimes p_2$) and the $\\\\textit{contrast}\\\\unicode{x00A0}(p_1 \\\\,\\\\unicode{x25D1}\\\\,\\\\, p_2$) between pairs, and the generalization of these operations to multiple component distributions. We offer empirical results on image and molecular generation tasks. Project codebase: https://github.com/timgaripov/compositional-sculpting",
    "checked": true,
    "id": "b7e0ea06f096d4963d96739ce154ba6bfe5af7ee",
    "semantic_title": "compositional sculpting of iterative generative processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7Uix1eQZ8z": {
    "title": "A State Representation for Diminishing Rewards",
    "volume": "poster",
    "abstract": "A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution. In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function. However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli. Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\\lambda$ representation ($\\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature. We establish the $\\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging",
    "checked": true,
    "id": "585db3d5266c66b1f292d88adc9108c11efd84b7",
    "semantic_title": "a state representation for diminishing rewards",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=2Cmdh5z6ph": {
    "title": "Discriminative Calibration: Check Bayesian Computation from Simulations and Flexible Classifier",
    "volume": "poster",
    "abstract": "To check the accuracy of Bayesian computations, it is common to use rank-based simulation-based calibration (SBC). However, SBC has drawbacks: The test statistic is somewhat ad-hoc, interactions are difficult to examine, multiple testing is a challenge, and the resulting p-value is not a divergence metric. We propose to replace the marginal rank test with a flexible classification approach that learns test statistics from data. This measure typically has a higher statistical power than the SBC test and returns an interpretable divergence measure of miscalibration, computed from classification accuracy. This approach can be used with different data generating processes to address simulation-based inference or traditional inference methods like Markov chain Monte Carlo or variational inference. We illustrate an automated implementation using neural networks and statistically-inspired features, and validate the method with numerical and real data experiments",
    "checked": false,
    "id": "ad2061063d0c9bd36e75a74b2f8d385483e8f21a",
    "semantic_title": "discriminative calibration",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Cupr2yTFSx": {
    "title": "Online POMDP Planning with Anytime Deterministic Guarantees",
    "volume": "poster",
    "abstract": "Autonomous agents operating in real-world scenarios frequently encounter uncertainty and make decisions based on incomplete information. Planning under uncertainty can be mathematically formalized using partially observable Markov decision processes (POMDPs). However, finding an optimal plan for POMDPs can be computationally expensive and is feasible only for small tasks. In recent years, approximate algorithms, such as tree search and sample-based methodologies, have emerged as state-of-the-art POMDP solvers for larger problems. Despite their effectiveness, these algorithms offer only probabilistic and often asymptotic guarantees toward the optimal solution due to their dependence on sampling. To address these limitations, we derive a deterministic relationship between a simplified solution that is easier to obtain and the theoretically optimal one. First, we derive bounds for selecting a subset of the observations to branch from while computing a complete belief at each posterior node. Then, since a complete belief update may be computationally demanding, we extend the bounds to support reduction of both the state and the observation spaces. We demonstrate how our guarantees can be integrated with existing state-of-the-art solvers that sample a subset of states and observations. As a result, the returned solution holds deterministic bounds relative to the optimal policy. Lastly, we substantiate our findings with supporting experimental results",
    "checked": true,
    "id": "b2b357cdcaf12a3786b3d83897a84677e05f026d",
    "semantic_title": "online pomdp planning with anytime deterministic guarantees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KakzVASqul": {
    "title": "Prediction and Control in Continual Reinforcement Learning",
    "volume": "poster",
    "abstract": "Temporal difference (TD) learning is often used to update the estimate of the value function which is used by RL agents to extract useful policies. In this paper, we focus on value function estimation in continual reinforcement learning. We propose to decompose the value function into two components which update at different timescales: a _permanent_ value function, which holds general knowledge that persists over time, and a _transient_ value function, which allows quick adaptation to new situations. We establish theoretical results showing that our approach is well suited for continual learning and draw connections to the complementary learning systems (CLS) theory from neuroscience. Empirically, this approach improves performance significantly on both prediction and control problems",
    "checked": false,
    "id": "3659a48a7c7d2e9a3285d8c47206a1c7f7c783dd",
    "semantic_title": "importance of prefrontal meta control in human-like reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LaNeRwDrTk": {
    "title": "Residual Q-Learning: Offline and Online Policy Customization without Value",
    "volume": "poster",
    "abstract": "Imitation Learning (IL) is a widely used framework for learning imitative behavior from demonstrations. It is especially appealing for solving complex real-world tasks where handcrafting reward function is difficult, or when the goal is to mimic human expert behavior. However, the learned imitative policy can only follow the behavior in the demonstration. When applying the imitative policy, we may need to customize the policy behavior to meet different requirements coming from diverse downstream tasks. Meanwhile, we still want the customized policy to maintain its imitative nature. To this end, we formulate a new problem setting called policy customization. It defines the learning task as training a policy that inherits the characteristics of the prior policy while satisfying some additional requirements imposed by a target downstream task. We propose a novel and principled approach to interpret and determine the trade-off between the two task objectives. Specifically, we formulate the customization problem as a Markov Decision Process (MDP) with a reward function that combines 1) the inherent reward of the demonstration; and 2) the add-on reward specified by the downstream task. We propose a novel framework, Residual Q-learning, which can solve the formulated MDP by leveraging the prior policy without knowing the inherent reward or value function of the prior policy. We derive a family of residual Q-learning algorithms that can realize offline and online policy customization, and show that the proposed algorithms can effectively accomplish policy customization tasks in various environments. Demo videos and code are available on our website: https://sites.google.com/view/residualq-learning",
    "checked": true,
    "id": "436787c5977afd75a818402ddb69743d21d1dbba",
    "semantic_title": "residual q-learning: offline and online policy customization without value",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hNpedVWwoe": {
    "title": "Near Optimal Reconstruction of Spherical Harmonic Expansions",
    "volume": "poster",
    "abstract": "We propose an algorithm for robust recovery of the spherical harmonic expansion of functions defined on the $d$-dimensional unit sphere $\\mathbb{S}^{d-1}$ using a near-optimal number of function evaluations. We show that for any $f\\in L^2(\\mathbb{S}^{d-1})$, the number of evaluations of $f$ needed to recover its degree-$q$ spherical harmonic expansion equals the dimension of the space of spherical harmonics of degree at most $q$, up to a logarithmic factor. Moreover, we develop a simple yet efficient kernel regression-based algorithm to recover degree-$q$ expansion of $f$ by only evaluating the function on uniformly sampled points on $\\mathbb{S}^{d-1}$. Our algorithm is built upon the connections between spherical harmonics and Gegenbauer polynomials. Unlike the prior results on fast spherical harmonic transform, our proposed algorithm works efficiently using a nearly optimal number of samples in any dimension $d$. Furthermore, we illustrate the empirical performance of our algorithm on numerical examples",
    "checked": true,
    "id": "8c7151e5cb21e8f95cc8b92da2d9999ef421cfca",
    "semantic_title": "near optimal reconstruction of spherical harmonic expansions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zEoP4vzFKy": {
    "title": "Automated Classification of Model Errors on ImageNet",
    "volume": "poster",
    "abstract": "While the ImageNet dataset has been driving computer vision research over the past decade, significant label noise and ambiguity have made top-1 accuracy an insufficient measure of further progress. To address this, new label-sets and evaluation protocols have been proposed for ImageNet showing that state-of-the-art models already achieve over 95% accuracy and shifting the focus on investigating why the remaining errors persist. Recent work in this direction employed a panel of experts to manually categorize all remaining classification errors for two selected models. However, this process is time-consuming, prone to inconsistencies, and requires trained experts, making it unsuitable for regular model evaluation thus limiting its utility. To overcome these limitations, we propose the first automated error classification framework, a valuable tool to study how modeling choices affect error distributions. We use our framework to comprehensively evaluate the error distribution of over 900 models. Perhaps surprisingly, we find that across model architectures, scales, and pre-training corpora, top-1 accuracy is a strong predictor for the *portion* of all error types. In particular, we observe that the portion of severe errors drops significantly with top-1 accuracy indicating that, while it underreports a model's true performance, it remains a valuable performance metric. We release all our code at https://github.com/eth-sri/automated-error-analysis",
    "checked": false,
    "id": "01c5bd1c72a705fa0bfae2e59a47a1940a357318",
    "semantic_title": "automated glaucoma detection using fundus images",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h6WUKM7PCI": {
    "title": "Towards robust and generalizable representations of extracellular data using contrastive learning",
    "volume": "poster",
    "abstract": "Contrastive learning is quickly becoming an essential tool in neuroscience for extracting robust and meaningful representations of neural activity. Despite numerous applications to neuronal population data, there has been little exploration of how these methods can be adapted to key primary data analysis tasks such as spike sorting or cell-type classification. In this work, we propose a novel contrastive learning framework, CEED (Contrastive Embeddings for Extracellular Data), for high-density extracellular recordings. We demonstrate that through careful design of the network architecture and data augmentations, it is possible to generically extract representations that far outperform current specialized approaches. We validate our method across multiple high-density extracellular recordings. All code used to run CEED can be found at https://github.com/ankitvishnu23/CEED",
    "checked": true,
    "id": "4d07424f85f06969353ddc2e4aa9370806377f3f",
    "semantic_title": "towards robust and generalizable representations of extracellular data using contrastive learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OaUT4hX40s": {
    "title": "The Gain from Ordering in Online Learning",
    "volume": "poster",
    "abstract": "We study fixed-design online learning where the learner is allowed to choose the order of the datapoints in order to minimize their regret (aka self-directed online learning). We focus on the fundamental task of online linear regression: the learner is given a dataset $X$ with $n$ examples in $d$ dimensions and at step $t$ they select a point $x_t \\in X$, predict a value $\\widetilde y_t$, and suffer loss $(\\widetilde y_t - w^\\ast \\cdot x_t)^2$. The goal is to design algorithms that order the examples and achieve better regret than random- or worst-order online algorithms. For an arbitrary dataset $X$, we show that, under the Exponential Time Hypothesis, no efficient algorithm can approximate the optimal (best-order) regret within a factor of $d^{1/\\poly(\\log \\log d)}$. We then show that, for structured datasets, we can bypass the above hardness result and achieve nearly optimal regret. When the examples of $X$ are drawn i.i.d.\\ from the uniform distribution on the sphere, we present an algorithm based on the greedy heuristic of selecting ``easiest'' examples first that achieves a $\\log d$-approximation of the optimal regret",
    "checked": false,
    "id": "5a8f781683fde5f84e3ad47b2e2b558b2add4912",
    "semantic_title": "student experiences of online learning due to covid-19",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UXtLrsG4Rf": {
    "title": "Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks",
    "volume": "poster",
    "abstract": "We present a new representation learning framework, Intensity Profile Projection, for continuous-time dynamic network data. Given triples $(i,j,t)$, each representing a time-stamped ($t$) interaction between two entities ($i,j$), our procedure returns a continuous-time trajectory for each node, representing its behaviour over time. The framework consists of three stages: estimating pairwise intensity functions, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and constructing evolving node representations via the learned projection. The trajectories satisfy two properties, known as structural and temporal coherence, which we see as fundamental for reliable inference. Moreoever, we develop estimation theory providing tight control on the error of any estimated trajectory, indicating that the representations could even be used in quite noise-sensitive follow-on analyses. The theory also elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce the level of smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network",
    "checked": true,
    "id": "ba0533d6fbc51753588cc04cf643a6f6c11294f8",
    "semantic_title": "intensity profile projection: a framework for continuous-time representation learning for dynamic networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=swNtr6vGqg": {
    "title": "The noise level in linear regression with dependent data",
    "volume": "poster",
    "abstract": "We derive upper bounds for random design linear regression with dependent ($\\beta$-mixing) data absent any realizability assumptions. In contrast to the strictly realizable martingale noise regime, no sharp \\emph{instance-optimal} non-asymptotics are available in the literature. Up to constant factors, our analysis correctly recovers the variance term predicted by the Central Limit Theorem---the noise level of the problem---and thus exhibits graceful degradation as we introduce misspecification. Past a burn-in, our result is sharp in the moderate deviations regime, and in particular does not inflate the leading order term by mixing time factors",
    "checked": true,
    "id": "05efebadb988832838fd555e48d23c9e52bdf852",
    "semantic_title": "the noise level in linear regression with dependent data",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=aa8KsqfTPa": {
    "title": "MarioGPT: Open-Ended Text2Level Generation through Large Language Models",
    "volume": "poster",
    "abstract": "Procedural Content Generation (PCG) is a technique to generate complex and diverse environments in an automated way. However, while generating content with PCG methods is often straightforward, generating meaningful content that reflects specific intentions and constraints remains challenging. Furthermore, many PCG algorithms lack the ability to generate content in an open-ended manner. Recently, Large Language Models (LLMs) have shown to be incredibly effective in many diverse domains. These trained LLMs can be fine-tuned, re-using information and accelerating training for new tasks. Here, we introduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game levels, in our case Super Mario Bros levels. MarioGPT can not only generate diverse levels, but can be text-prompted for controllable level generation, addressing one of the key challenges of current PCG techniques. As far as we know, MarioGPT is the first text-to-level model and combined with novelty search it enables the generation of diverse levels with varying play-style dynamics (i.e. player paths) and the open-ended discovery of an increasingly diverse range of content. Code available at https://github.com/shyamsn97/mario-gpt",
    "checked": true,
    "id": "bbe197158adb4b6e85a6eeab4619ea0fc6857941",
    "semantic_title": "mariogpt: open-ended text2level generation through large language models",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=wPqEvmwFEh": {
    "title": "Small batch deep reinforcement learning",
    "volume": "poster",
    "abstract": "In value-based deep reinforcement learning with replay memories, the batch size parameter specifies how many transitions to sample for each gradient update. Although critical to the learning process, this value is typically not adjusted when proposing new algorithms. In this work we present a broad empirical study that suggests reducing the batch size can result in a number of significant performance gains; this is surprising, as the general tendency when training neural networks is towards larger batch sizes for improved performance. We complement our experimental findings with a set of empirical analyses towards better understanding this phenomenon",
    "checked": true,
    "id": "339e4b4aaa5c43660bf48756066433e8a2045187",
    "semantic_title": "small batch deep reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4PkBhz18in": {
    "title": "High Precision Causal Model Evaluation with Conditional Randomization",
    "volume": "poster",
    "abstract": "The gold standard for causal model evaluation involves comparing model predictions with true effects estimated from randomized controlled trials (RCT). However, RCTs are not always feasible or ethical to perform. In contrast, conditionally randomized experiments based on inverse probability weighting (IPW) offer a more realistic approach but may suffer from high estimation variance. To tackle this challenge and enhance causal model evaluation in real-world conditional randomization settings, we introduce a novel low-variance estimator for causal error, dubbed as the pairs estimator. By applying the same IPW estimator to both the model and true experimental effects, our estimator effectively cancels out the variance due to IPW and achieves a smaller asymptotic variance. Empirical studies demonstrate the improved of our estimator, highlighting its potential on achieving near-RCT performance. Our method offers a simple yet powerful solution to evaluate causal inference models in conditional randomization settings without complicated modification of the IPW estimator itself, paving the way for more robust and reliable model assessments",
    "checked": true,
    "id": "124a4c47c5f7dad733f2576e26be9b81a58d975a",
    "semantic_title": "high precision causal model evaluation with conditional randomization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IyYyKov0Aj": {
    "title": "Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference",
    "volume": "poster",
    "abstract": "We propose Conditional Adapter (CoDA), a parameter-efficient transfer learning method that also improves inference efficiency. CoDA generalizes beyond standard adapter approaches to enable a new way of balancing speed and accuracy using conditional computation. Starting with an existing dense pretrained model, CoDA adds sparse activation together with a small number of new parameters and a light-weight training phase. Our experiments demonstrate that the CoDA approach provides an unexpectedly efficient way to transfer knowledge. Across a variety of language, vision, and speech tasks, CoDA achieves a 2x to 8x inference speed-up compared to the state-of-the-art Adapter approaches with moderate to no accuracy loss and the same parameter efficiency",
    "checked": true,
    "id": "148644bf4ccef7e022b965304e8b3178be8af0fa",
    "semantic_title": "conditional adapters: parameter-efficient transfer learning with fast inference",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=V6IgkYKD8P": {
    "title": "SEEDS: Exponential SDE Solvers for Fast High-Quality Sampling from Diffusion Models",
    "volume": "poster",
    "abstract": "A potent class of generative models known as Diffusion Probabilistic Models (DPMs) has become prominent. A forward diffusion process adds gradually noise to data, while a model learns to gradually denoise. Sampling from pre-trained DPMs is obtained by solving differential equations (DE) defined by the learnt model, a process which has shown to be prohibitively slow. Numerous efforts on speeding-up this process have consisted on crafting powerful ODE solvers. Despite being quick, such solvers do not usually reach the optimal quality achieved by available slow SDE solvers. Our goal is to propose SDE solvers that reach optimal quality without requiring several hundreds or thousands of NFEs to achieve that goal. We propose Stochastic Explicit Exponential Derivative-free Solvers (SEEDS), improving and generalizing Exponential Integrator approaches to the stochastic case on several frameworks. After carefully analyzing the formulation of exact solutions of diffusion SDEs, we craft SEEDS to analytically compute the linear part of such solutions. Inspired by the Exponential Time-Differencing method, SEEDS use a novel treatment of the stochastic components of solutions, enabling the analytical computation of their variance, and contains high-order terms allowing to reach optimal quality sampling $\\sim3$-$5\\times$ faster than previous SDE methods. We validate our approach on several image generation benchmarks, showing that SEEDS outperform or are competitive with previous SDE solvers. Contrary to the latter, SEEDS are derivative and training free, and we fully prove strong convergence guarantees for them",
    "checked": true,
    "id": "675fe7e0ae5642285817ed260309d203fdbc0f55",
    "semantic_title": "seeds: exponential sde solvers for fast high-quality sampling from diffusion models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=e4XidX6AHd": {
    "title": "Gacs-Korner Common Information Variational Autoencoder",
    "volume": "poster",
    "abstract": "We propose a notion of common information that allows one to quantify and separate the information that is shared between two random variables from the information that is unique to each. Our notion of common information is defined by an optimization problem over a family of functions and recovers the G\\'acs-K\\\"orner common information as a special case. Importantly, our notion can be approximated empirically using samples from the underlying data distribution. We then provide a method to partition and quantify the common and unique information using a simple modification of a traditional variational auto-encoder. Empirically, we demonstrate that our formulation allows us to learn semantically meaningful common and unique factors of variation even on high-dimensional data such as images and videos. Moreover, on datasets where ground-truth latent factors are known, we show that we can accurately quantify the common information between the random variables",
    "checked": true,
    "id": "a1adeade3ea8f8bb1e56df0fa71a324f0831b9ed",
    "semantic_title": "gacs-korner common information variational autoencoder",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=OFDApY678F": {
    "title": "Experimental Designs for Heteroskedastic Variance",
    "volume": "poster",
    "abstract": "Most linear experimental design problems assume homogeneous variance, while the presence of heteroskedastic noise is present in many realistic settings. Let a learner have access to a finite set of measurement vectors $\\mathcal{X}\\subset \\mathbb{R}^d$ that can be probed to receive noisy linear responses of the form $y=x^{\\top}\\theta^{\\ast}+\\eta$. Here $\\theta^{\\ast}\\in \\mathbb{R}^d$ is an unknown parameter vector, and $\\eta$ is independent mean-zero $\\sigma_x^2$-sub-Gaussian noise defined by a flexible heteroskedastic variance model, $\\sigma_x^2 = x^{\\top}\\Sigma^{\\ast}x$. Assuming that $\\Sigma^{\\ast}\\in \\mathbb{R}^{d\\times d}$ is an unknown matrix, we propose, analyze and empirically evaluate a novel design for uniformly bounding estimation error of the variance parameters, $\\sigma_x^2$. We demonstrate this method on two adaptive experimental design problems under heteroskedastic noise, fixed confidence transductive best-arm identification and level-set identification and prove the first instance-dependent lower bounds in these settings. Lastly, we construct near-optimal algorithms and demonstrate the large improvements in sample complexity gained from accounting for heteroskedastic variance in these designs empirically",
    "checked": true,
    "id": "d8e7b5d7c432fd219386054f2fe03d036ea8cfd5",
    "semantic_title": "experimental designs for heteroskedastic variance",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IEJzoOBM0z": {
    "title": "Estimating Causal Effects Identifiable from a Combination of Observations and Experiments",
    "volume": "poster",
    "abstract": "Learning cause and effect relations is arguably one of the central challenges found throughout the data sciences. Formally, determining whether a collection of observational and interventional distributions can be combined to learn a target causal relation is known as the problem of generalized identification (or g-identification) [Lee et al., 2019]. Although g-identification has been well understood and solved in theory, it turns out to be challenging to apply these results in practice, in particular when considering the estimation of the target distribution from finite samples. In this paper, we develop a new, general estimator that exhibits multiply robustness properties for g-identifiable causal functionals. Specifically, we show that any g-identifiable causal effect can be expressed as a function of generalized multi-outcome sequential back-door adjustments that are amenable to estimation. We then construct a corresponding estimator for the g-identification expression that exhibits robustness properties to bias. We analyze the asymptotic convergence properties of the estimator. Finally, we illustrate the use of the proposed estimator in experimental studies. Simulation results corroborate the theory",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QxYzmYmQQe": {
    "title": "Equal Opportunity of Coverage in Fair Regression",
    "volume": "poster",
    "abstract": "We study fair machine learning (ML) under predictive uncertainty to enable reliable and trustworthy decision-making. The seminal work of 'equalized coverage' proposed an uncertainty-aware fairness notion. However, it does not guarantee equal coverage rates across more fine-grained groups (e.g., low-income females) conditioning on the true label and is biased in the assessment of uncertainty. To tackle these limitations, we propose a new uncertainty-aware fairness -- Equal Opportunity of Coverage (EOC) -- that aims to achieve two properties: (1) coverage rates for different groups with similar outcomes are close, and (2) the coverage rate for the entire population remains at a predetermined level. Further, the prediction intervals should be narrow to be informative. We propose Binned Fair Quantile Regression (BFQR), a distribution-free post-processing method to improve EOC with reasonable width for any trained ML models. It first calibrates a hold-out set to bound deviation from EOC, then leverages conformal prediction to maintain EOC on a test set, meanwhile optimizing prediction interval width. Experimental results demonstrate the effectiveness of our method in improving EOC",
    "checked": true,
    "id": "36bc8de7d8408a68bdbd40e20820f8c71befb328",
    "semantic_title": "equal opportunity of coverage in fair regression",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=U6bhCLSPun": {
    "title": "Last-Iterate Convergent Policy Gradient Primal-Dual Methods for Constrained MDPs",
    "volume": "poster",
    "abstract": "We study the problem of computing an optimal policy of an infinite-horizon discounted constrained Markov decision process (constrained MDP). Despite the popularity of Lagrangian-based policy search methods used in practice, the oscillation of policy iterates in these methods has not been fully understood, bringing out issues such as violation of constraints and sensitivity to hyper-parameters. To fill this gap, we employ the Lagrangian method to cast a constrained MDP into a constrained saddle-point problem in which max/min players correspond to primal/dual variables, respectively, and develop two single-time-scale policy-based primal-dual algorithms with non-asymptotic convergence of their policy iterates to an optimal constrained policy. Specifically, we first propose a regularized policy gradient primal-dual (RPG-PD) method that updates the policy using an entropy-regularized policy gradient, and the dual variable via a quadratic-regularized gradient ascent, simultaneously. We prove that the policy primal-dual iterates of RPG-PD converge to a regularized saddle point with a sublinear rate, while the policy iterates converge sublinearly to an optimal constrained policy. We further instantiate RPG-PD in large state or action spaces by including function approximation in policy parametrization, and establish similar sublinear last-iterate policy convergence. Second, we propose an optimistic policy gradient primal-dual (OPG-PD) method that employs the optimistic gradient method to update primal/dual variables, simultaneously. We prove that the policy primal-dual iterates of OPG-PD converge to a saddle point that contains an optimal constrained policy, with a linear rate. To the best of our knowledge, this work appears to be the first non-asymptotic policy last-iterate convergence result for single-time-scale algorithms in constrained MDPs. We further validate the merits and the effectiveness of our methods in computational experiments",
    "checked": true,
    "id": "5929b37dc79faa2af5d570bb8e739b145a0ecd5d",
    "semantic_title": "last-iterate convergent policy gradient primal-dual methods for constrained mdps",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gYWjI7wLhc": {
    "title": "Differentiable sorting for censored time-to-event data",
    "volume": "poster",
    "abstract": "Survival analysis is a crucial semi-supervised task in machine learning with significant real-world applications, especially in healthcare. The most common approach to survival analysis, Cox's partial likelihood, can be interpreted as a ranking model optimized on a lower bound of the concordance index. We follow these connections further, with listwise ranking losses that allow for a relaxation of the pairwise independence assumption. Given the inherent transitivity of ranking, we explore differentiable sorting networks as a means to introduce a stronger transitive inductive bias during optimization. Despite their potential, current differentiable sorting methods cannot account for censoring, a crucial aspect of many real-world datasets. We propose a novel method, Diffsurv, to overcome this limitation by extending differentiable sorting methods to handle censored tasks. Diffsurv predicts matrices of possible permutations that accommodate the label uncertainty introduced by censored samples. Our experiments reveal that Diffsurv outperforms established baselines in various simulated and real-world risk prediction scenarios. Furthermore, we demonstrate the algorithmic advantages of Diffsurv by presenting a novel method for top-k risk prediction that surpasses current methods",
    "checked": false,
    "id": "8788fcb0c19fec13fb35379601ad24b9601a4964",
    "semantic_title": "diffsurv: differentiable sorting for censored time-to-event data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6JrckqCxtl": {
    "title": "Polyhedron Attention Module: Learning Adaptive-order Interactions",
    "volume": "poster",
    "abstract": "Learning feature interactions can be the key for multivariate predictive modeling. ReLU-activated neural networks create piecewise linear prediction models, and other nonlinear activation functions lead to models with only high-order feature interactions. Recent methods incorporate candidate polynomial terms of fixed orders into deep learning, which is subject to the issue of combinatorial explosion, or learn the orders that are difficult to adapt to different regions of the feature space. We propose a Polyhedron Attention Module (PAM) to create piecewise polynomial models where the input space is split into polyhedrons which define the different pieces and on each piece the hyperplanes that define the polyhedron boundary multiply to form the interactive terms, resulting in interactions of adaptive order to each piece. PAM is interpretable to identify important interactions in predicting a target. Theoretic analysis shows that PAM has stronger expression capability than ReLU-activated networks. Extensive experimental results demonstrate the superior classification performance of PAM on massive datasets of the click-through rate prediction and PAM can learn meaningful interaction effects in a medical problem",
    "checked": false,
    "id": "be421b0b240c4d5f7873370055822d08030bdb6c",
    "semantic_title": "graph contrastive learning with adaptive augmentation for recommendation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=b60wLlkBta": {
    "title": "On the Robustness of Removal-Based Feature Attributions",
    "volume": "poster",
    "abstract": "To explain predictions made by complex machine learning models, many feature attribution methods have been developed that assign importance scores to input features. Some recent work challenges the robustness of these methods by showing that they are sensitive to input and model perturbations, while other work addresses this issue by proposing robust attribution methods. However, previous work on attribution robustness has focused primarily on gradient-based feature attributions, whereas the robustness of removal-based attribution methods is not currently well understood. To bridge this gap, we theoretically characterize the robustness properties of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and derive upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical results on synthetic and real-world data validate our theoretical results and demonstrate their practical implications, including the ability to increase attribution robustness by improving the model's Lipschitz regularity",
    "checked": true,
    "id": "a80e19cfb03f53b35ccb2803d5a4dd7ef1450535",
    "semantic_title": "on the robustness of removal-based feature attributions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9fb975Au9G": {
    "title": "Django: Detecting Trojans in Object Detection Models via Gaussian Focus Calibration",
    "volume": "poster",
    "abstract": "Object detection models are vulnerable to backdoor or trojan attacks, where an attacker can inject malicious triggers into the model, leading to altered behavior during inference. As a defense mechanism, trigger inversion leverages optimization to reverse-engineer triggers and identify compromised models. While existing trigger inversion methods assume that each instance from the support set is equally affected by the injected trigger, we observe that the poison effect can vary significantly across bounding boxes in object detection models due to its dense prediction nature, leading to an undesired optimization objective misalignment issue for existing trigger reverse-engineering methods. To address this challenge, we propose the first object detection backdoor detection framework Django (Detecting Trojans in Object Detection Models via Gaussian Focus Calibration). It leverages a dynamic Gaussian weighting scheme that prioritizes more vulnerable victim boxes and assigns appropriate coefficients to calibrate the optimization objective during trigger inversion. In addition, we combine Django with a novel label proposal pre-processing technique to enhance its efficiency. We evaluate Django on 3 object detection image datasets, 3 model architectures, and 2 types of attacks, with a total of 168 models. Our experimental results show that Django outperforms 6 state-of-the-art baselines, with up to 38% accuracy improvement and 10x reduced overhead. The code is available at https://github.com/PurduePAML/DJGO",
    "checked": true,
    "id": "9361ff24ee36681148bcf466879f65f3b515976f",
    "semantic_title": "django: detecting trojans in object detection models via gaussian focus calibration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dxVN2fZjx6": {
    "title": "Equivariant Single View Pose Prediction Via Induced and Restriction Representations",
    "volume": "poster",
    "abstract": "Learning about the three-dimensional world from two-dimensional images is a fundamental problem in computer vision. An ideal neural network architecture for such tasks would leverage the fact that objects can be rotated and translated in three dimensions to make predictions about novel images. However, imposing $SO(3)$-equivariance on two-dimensional inputs is difficult because the group of three-dimensional rotations does not have a natural action on the two-dimensional plane. Specifically, it is possible that an element of $SO(3)$ will rotate an image out of plane. We show that an algorithm that learns a three-dimensional representation of the world from two dimensional images must satisfy certain consistency properties which we formulate as $SO(2)$-equivariance constraints. We use the induced representation of $SO(2)$ on $SO(3)$ to construct and classify architectures that have two-dimensional inputs and which satisfy these consistency constraints. We prove that any architecture which respects said consistency constraints can be realized as an instance of our construction. We show that three previously proposed neural architectures for 3D pose prediction are special cases of our construction. We propose a new algorithm that is a learnable generalization of previously considered methods. We test our architecture on three pose predictions task and achieve SOTA results on both the PASCAL3D+ and SYMSOL pose estimation tasks",
    "checked": false,
    "id": "1906a9a9eb23ceedfab2c328f1ae3064b684c520",
    "semantic_title": "equivariant single view pose prediction via induced and restricted representations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=sxZLrBqg50": {
    "title": "Is RLHF More Difficult than Standard RL? A Theoretical Perspective",
    "volume": "poster",
    "abstract": "Reinforcement learning from Human Feedback (RLHF) learns from preference signals, while standard Reinforcement Learning (RL) directly learns from reward signals. Preferences arguably contain less information than rewards, which makes preference-based RL seemingly more difficult. This paper theoretically proves that, for a wide range of preference models, we can solve preference-based RL directly using existing algorithms and techniques for reward-based RL, with small or no extra costs. Specifically, (1) for preferences that are drawn from reward-based probabilistic models, we reduce the problem to robust reward-based RL that can tolerate small errors in rewards; (2) for general arbitrary preferences where the objective is to find the von Neumann winner, we reduce the problem to multiagent reward-based RL which finds Nash equilibria for factored Markov games under a restricted set of policies. The latter case can be further reduce to adversarial MDP when preferences only depend on the final state. We instantiate all reward-based RL subroutines by concrete provable algorithms, and apply our theory to a large class of models including tabular MDPs and MDPs with generic function approximation. We further provide guarantees when K-wise comparisons are available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qv5UZJTNda": {
    "title": "Multimodal Deep Learning Model Unveils Behavioral Dynamics of V1 Activity in Freely Moving Mice",
    "volume": "poster",
    "abstract": "Despite their immense success as a model of macaque visual cortex, deep convolutional neural networks (CNNs) have struggled to predict activity in visual cortex of the mouse, which is thought to be strongly dependent on the animal's behavioral state. Furthermore, most computational models focus on predicting neural responses to static images presented under head fixation, which are dramatically different from the dynamic, continuous visual stimuli that arise during movement in the real world. Consequently, it is still unknown how natural visual input and different behavioral variables may integrate over time to generate responses in primary visual cortex (V1). To address this, we introduce a multimodal recurrent neural network that integrates gaze-contingent visual input with behavioral and temporal dynamics to explain V1 activity in freely moving mice. We show that the model achieves state-of-the-art predictions of V1 activity during free exploration and demonstrate the importance of each component in an extensive ablation study. Analyzing our model using maximally activating stimuli and saliency maps, we reveal new insights into cortical function, including the prevalence of mixed selectivity for behavioral variables in mouse V1. In summary, our model offers a comprehensive deep-learning framework for exploring the computational principles underlying V1 neurons in freely-moving animals engaged in natural behavior",
    "checked": true,
    "id": "7e8b7c78380d052387aa9ad2ce559381bfb707ef",
    "semantic_title": "multimodal deep learning model unveils behavioral dynamics of v1 activity in freely moving mice",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Cc2fjBBlBD": {
    "title": "Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features",
    "volume": "poster",
    "abstract": "To avoid failures on out-of-distribution data, recent works have sought to extract features that have an invariant or stable relationship with the label across domains, discarding \"spurious\" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information that could boost performance if used correctly in the test domain. In this work, we show how this can be done without test-domain labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt the unstable-feature predictions in the test domain. Theoretically, we prove that SFB can learn an asymptotically-optimal predictor without test-domain labels. Empirically, we demonstrate the effectiveness of SFB on real and synthetic data",
    "checked": true,
    "id": "ff3c339d6d2a13b4c3e50bd679b89cf5a25757d2",
    "semantic_title": "spuriosity didn't kill the classifier: using invariant predictions to harness spurious features",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=z4vKRmq7UO": {
    "title": "A Regularized Conditional GAN for Posterior Sampling in Image Recovery Problems",
    "volume": "poster",
    "abstract": "In image recovery problems, one seeks to infer an image from distorted, incomplete, and/or noise-corrupted measurements. Such problems arise in magnetic resonance imaging (MRI), computed tomography, deblurring, super-resolution, inpainting, phase retrieval, image-to-image translation, and other applications. Given a training set of signal/measurement pairs, we seek to do more than just produce one good image estimate. Rather, we aim to rapidly and accurately sample from the posterior distribution. To do this, we propose a regularized conditional Wasserstein GAN that generates dozens of high-quality posterior samples per second. Our regularization comprises an $\\ell_1$ penalty and an adaptively weighted standard-deviation reward. Using quantitative evaluation metrics like conditional Fréchet inception distance, we demonstrate that our method produces state-of-the-art posterior samples in both multicoil MRI and large-scale inpainting applications. The code for our model can be found here: https://github.com/matt-bendel/rcGAN",
    "checked": true,
    "id": "a144e25c5afc794b26f89cd47d60f35d7598487b",
    "semantic_title": "a regularized conditional gan for posterior sampling in image recovery problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dYeUvLUxBQ": {
    "title": "Causal Discovery in Semi-Stationary Time Series",
    "volume": "poster",
    "abstract": "Discovering causal relations from observational time series without making the stationary assumption is a significant challenge. In practice, this challenge is common in many areas, such as retail sales, transportation systems, and medical science. Here, we consider this problem for a class of non-stationary time series problems. The structural causal model (SCM) of this type of time series, called the semi-stationary time series, exhibits that a finite number of different causal mechanisms occur sequentially and periodically across time. This model holds considerable practical utility because it can represent periodicity, including common occurrences such as seasonality and diurnal variation. We propose a constraint-based, non-parametric algorithm for discovering causal relations in this setting. The resulting algorithm, PCMCI$_{\\Omega}$, can capture the alternating and recurring changes in the causal mechanisms and then identify the underlying causal graph with conditional independence (CI) tests. We show that this algorithm is sound in identifying causal relations on discrete time series. We validate the algorithm with extensive experiments on continuous and discrete simulated data. We also apply our algorithm to a real-world climate dataset",
    "checked": false,
    "id": "a0daae92e2e0b72cb36c7bb0547ec8725779f359",
    "semantic_title": "causal discovery from conditionally stationary time-series",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=eibTaY6qGI": {
    "title": "Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis",
    "volume": "poster",
    "abstract": "We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input. Multiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation. After empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation",
    "checked": true,
    "id": "b99e58229dd7f2a5c48eefa0508c629d9c4c2b91",
    "semantic_title": "resilient multiple choice learning: a learned scoring scheme with application to audio scene analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zNA7u7wtIN": {
    "title": "P-Flow: A Fast and Data-Efficient Zero-Shot TTS through Speech Prompting",
    "volume": "poster",
    "abstract": "While recent large-scale neural codec language models have shown significant improvement in zero-shot TTS by training on thousands of hours of data, they suffer from drawbacks such as a lack of robustness, slow sampling speed similar to previous autoregressive TTS methods, and reliance on pre-trained neural codec representations. Our work proposes P-Flow, a fast and data-efficient zero-shot TTS model that uses speech prompts for speaker adaptation. P-Flow comprises a speech-prompted text encoder for speaker adaptation and a flow matching generative decoder for high-quality and fast speech synthesis. Our speech-prompted text encoder uses speech prompts and text input to generate speaker-conditional text representation. The flow matching generative decoder uses the speaker-conditional output to synthesize high-quality personalized speech significantly faster than in real-time. Unlike the neural codec language models, we specifically train P-Flow on LibriTTS dataset using a continuous mel-representation. Through our training method using continuous speech prompts, P-Flow matches the speaker similarity performance of the large-scale zero-shot TTS models with two orders of magnitude less training data and has more than 20$\\times$ faster sampling speed. Our results show that P-Flow has better pronunciation and is preferred in human likeness and speaker similarity to its recent state-of-the-art counterparts, thus defining P-Flow as an attractive and desirable alternative. We provide audio samples on our demo page: \\url{https://research.nvidia.com/labs/adlr/pflow}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=prftZp6mDH": {
    "title": "Label Poisoning is All You Need",
    "volume": "poster",
    "abstract": "In a backdoor attack, an adversary injects corrupted data into a model's training dataset in order to gain control over its predictions on images with a specific attacker-defined trigger. A typical corrupted training example requires altering both the image, by applying the trigger, and the label. Models trained on clean images, therefore, were considered safe from backdoor attacks. However, in some common machine learning scenarios, the training labels are provided by potentially malicious third-parties. This includes crowd-sourced annotation and knowledge distillation. We, hence, investigate a fundamental question: can we launch a successful backdoor attack by only corrupting labels? We introduce a novel approach to design label-only backdoor attacks, which we call FLIP, and demonstrate its strengths on three datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32, ResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels corrupted, FLIP achieves a near-perfect attack success rate of 99.4% while suffering only a 1.8% drop in the clean test accuracy. Our approach builds upon the recent advances in trajectory matching, originally introduced for dataset distillation",
    "checked": true,
    "id": "8e7dbcb0e3c78e21c9b963f0052d89417fa54993",
    "semantic_title": "label poisoning is all you need",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=19AgWnmyoV": {
    "title": "Instructing Goal-Conditioned Reinforcement Learning Agents with Temporal Logic Objectives",
    "volume": "poster",
    "abstract": "Goal-conditioned reinforcement learning (RL) is a powerful approach for learning general-purpose skills by reaching diverse goals. However, it has limitations when it comes to task-conditioned policies, where goals are specified by temporally extended instructions written in the Linear Temporal Logic (LTL) formal language. Existing approaches for finding LTL-satisfying policies rely on sampling a large set of LTL instructions during training to adapt to unseen tasks at inference time. However, these approaches do not guarantee generalization to out-of-distribution LTL objectives, which may have increased complexity. In this paper, we propose a novel approach to address this challenge. We show that simple goal-conditioned RL agents can be instructed to follow arbitrary LTL specifications without additional training over the LTL task space. Unlike existing approaches that focus on LTL specifications expressible as regular expressions, our technique is unrestricted and generalizes to $\\omega$-regular expressions. Experiment results demonstrate the effectiveness of our approach in adapting goal-conditioned RL agents to satisfy complex temporal logic task specifications zero-shot",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m6dRQJw280": {
    "title": "Equivariant Adaptation of Large Pretrained Models",
    "volume": "poster",
    "abstract": "Equivariant networks are specifically designed to ensure consistent behavior with respect to a set of input transformations, leading to higher sample efficiency and more accurate and robust predictions. However, redesigning each component of prevalent deep neural network architectures to achieve chosen equivariance is a difficult problem and can result in a computationally expensive network during both training and inference. A recently proposed alternative towards equivariance that removes the architectural constraints is to use a simple canonicalization network that transforms the input to a canonical form before feeding it to an unconstrained prediction network. We show here that this approach can effectively be used to make a large pretrained network equivariant. However, we observe that the produced canonical orientations can be misaligned with those of the training distribution, hindering performance. Using dataset-dependent priors to inform the canonicalization function, we are able to make large pretrained models equivariant while maintaining their performance. This significantly improves the robustness of these models to deterministic transformations of the data, such as rotations. We believe this equivariant adaptation of large pretrained models can help their domain-specific applications with known symmetry priors",
    "checked": true,
    "id": "a49caf95b97baf1c24456ba84550e20dd91645fd",
    "semantic_title": "equivariant adaptation of large pretrained models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=OQQoD8Vc3B": {
    "title": "Are aligned neural networks adversarially aligned?",
    "volume": "poster",
    "abstract": "Large language models are now tuned to align with the goals of their creators, namely to be \"helpful and harmless.\" These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study adversarial alignment, and ask to what extent these models remain aligned when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models",
    "checked": true,
    "id": "8724579d3f126e753a0451d98ff57b165f722e72",
    "semantic_title": "are aligned neural networks adversarially aligned?",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=0OImBCFsdf": {
    "title": "SaVeNet: A Scalable Vector Network for Enhanced Molecular Representation Learning",
    "volume": "poster",
    "abstract": "Geometric representation learning of molecules is challenging yet essential for applications in multiple domains. Despite the impressive breakthroughs made by geometric deep learning in various molecular representation learning tasks, effectively capturing complicated geometric features across spatial dimensions is still underexplored due to the significant difficulties in modeling efficient geometric representations and learning the inherent correlation in 3D structural modeling. These include computational inefficiency, underutilization of vectorial embeddings, and limited generalizability to integrate various geometric properties. To address the raised concerns, we introduce an efficient and effective framework, Scalable Vector Network (SaVeNet), designed to accommodate a range of geometric requirements without depending on costly embeddings. In addition, the proposed framework scales effectively with introduced direction noise. Theoretically, we analyze the desired properties (i.e., invariance and equivariant) and framework efficiency of the SaVeNet. Empirically, we conduct a comprehensive series of experiments to evaluate the efficiency and expressiveness of the proposed model. Our efficiency-focused experiments underscore the model's empirical superiority over existing methods. Experimental results on synthetic and real-world datasets demonstrate the expressiveness of our model, which achieves state-of-the-art performance across various tasks within molecular representation learning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kfWzpZvEUh": {
    "title": "End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes",
    "volume": "poster",
    "abstract": "Meta-Bayesian optimisation (meta-BO) aims to improve the sample efficiency of Bayesian optimisation by leveraging data from related tasks. While previous methods successfully meta-learn either a surrogate model or an acquisition function independently, joint training of both components remains an open challenge. This paper proposes the first end-to-end differentiable meta-BO framework that generalises neural processes to learn acquisition functions via transformer architectures. We enable this end-to-end framework with reinforcement learning (RL) to tackle the lack of labelled acquisition data. Early on, we notice that training transformer-based neural processes from scratch with RL is challenging due to insufficient supervision, especially when rewards are sparse. We formalise this claim with a combinatorial analysis showing that the widely used notion of regret as a reward signal exhibits a logarithmic sparsity pattern in trajectory lengths. To tackle this problem, we augment the RL objective with an auxiliary task that guides part of the architecture to learn a valid probabilistic model as an inductive bias. We demonstrate that our method achieves state-of-the-art regret results against various baselines in experiments on standard hyperparameter optimisation tasks and also outperforms others in the real-world problems of mixed-integer programming tuning, antibody design, and logic synthesis for electronic design automation",
    "checked": true,
    "id": "8ef3f06353f65ca653b396b70d089f793bfc168b",
    "semantic_title": "end-to-end meta-bayesian optimisation with transformer neural processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UINHuKeWUa": {
    "title": "Fast Attention Over Long Sequences With Dynamic Sparse Flash Attention",
    "volume": "poster",
    "abstract": "Transformer-based language models have found many diverse applications requiring them to process sequences of increasing length. For these applications, the causal self-attention---which is the only component scaling quadratically w.r.t. the sequence length---becomes a central concern. While many works have proposed schemes to sparsify the attention patterns and reduce the computational overhead of self-attention, those are often limited by implementation concerns and end up imposing a simple and static structure over the attention matrix. Conversely, implementing more dynamic sparse attention often results in runtimes significantly slower than computing the full attention using the Flash implementation from Dao et al. (2022). We extend FlashAttention to accommodate a large class of attention sparsity patterns that, in particular, encompass key/query dropping and hashing-based attention. This leads to implementations with no computational complexity overhead and a multi-fold runtime speedup on top of FlashAttention. Even with relatively low degrees of sparsity, our method improves visibly upon FlashAttention as the sequence length increases. Without sacrificing perplexity, we increase the training speed of a transformer language model by $2.0\\times$ and $3.3\\times$ for sequences of respectively $8k$ and $16k$ tokens",
    "checked": false,
    "id": "d203c764fb5dec2b053be667c8b06e516ea6ef10",
    "semantic_title": "faster causal attention over large sequences through sparse flash attention",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=4sDHLxKb1L": {
    "title": "HiBug: On Human-Interpretable Model Debug",
    "volume": "poster",
    "abstract": "Machine learning models can frequently produce systematic errors on critical subsets (or slices) of data that share common attributes. Discovering and explaining such model bugs is crucial for reliable model deployment. However, existing bug discovery and interpretation methods usually involve heavy human intervention and annotation, which can be cumbersome and have low bug coverage. In this paper, we propose HiBug, an automated framework for interpretable model debugging. Our approach utilizes large pre-trained models, such as chatGPT, to suggest human-understandable attributes that are related to the targeted computer vision tasks. By leveraging pre-trained vision-language models, we can efficiently identify common visual attributes of underperforming data slices using human-understandable terms. This enables us to uncover rare cases in the training data, identify spurious correlations in the model, and use the interpretable debug results to select or generate new training data for model improvement. Experimental results demonstrate the efficacy of the HiBug framework",
    "checked": false,
    "id": "28e81f96eab94e99febcaaee00637825c8a3e664",
    "semantic_title": "interpretable machine learning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=MUzdCW2hC6": {
    "title": "Improvements on Uncertainty Quantification for Node Classification via Distance Based Regularization",
    "volume": "poster",
    "abstract": "Deep neural networks have achieved significant success in the last decades, but they are not well-calibrated and often produce unreliable predictions. A large number of literature relies on uncertainty quantification to evaluate the reliability of a learning model, which is particularly important for applications of out-of-distribution (OOD) detection and misclassification detection. We are interested in uncertainty quantification for interdependent node-level classification. We start our analysis based on graph posterior networks (GPNs) that optimize the uncertainty cross-entropy (UCE)-based loss function. We describe the theoretical limitations of the widely-used UCE loss. To alleviate the identified drawbacks, we propose a distance-based regularization that encourages clustered OOD nodes to remain clustered in the latent space. We conduct extensive comparison experiments on eight standard datasets and demonstrate that the proposed regularization outperforms the state-of-the-art in both OOD detection and misclassification detection",
    "checked": false,
    "id": "65a8d97e25479899243512922aaae587b9a06dd4",
    "semantic_title": "improvements on uncertainty quantification for node classification via distance-based regularization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=lArwl3y9x6": {
    "title": "Normalization Layers Are All That Sharpness-Aware Minimization Needs",
    "volume": "poster",
    "abstract": "Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima and has been shown to enhance generalization performance in various settings. In this work we show that perturbing only the affine normalization parameters (typically comprising 0.1% of the total parameters) in the adversarial step of SAM can outperform perturbing all of the parameters. This finding generalizes to different SAM variants and both ResNet (Batch Normalization) and Vision Transformer (Layer Normalization) architectures. We consider alternative sparse perturbation approaches and find that these do not achieve similar performance enhancement at such extreme sparsity levels, showing that this behaviour is unique to the normalization layers. Although our findings reaffirm the effectiveness of SAM in improving generalization performance, they cast doubt on whether this is solely caused by reduced sharpness",
    "checked": true,
    "id": "fba30c42c0920bd9590ddc274658c409938b2fb2",
    "semantic_title": "normalization layers are all that sharpness-aware minimization needs",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=VMAgvbBBts": {
    "title": "UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with Vision-Language Models",
    "volume": "poster",
    "abstract": "In this study, we investigate the task of data pre-selection, which aims to select instances for labeling from an unlabeled dataset through a single pass, thereby optimizing performance for undefined downstream tasks with a limited annotation budget. Previous approaches to data pre-selection relied solely on visual features extracted from foundation models, such as CLIP and BLIP-2, but largely ignored the powerfulness of text features. In this work, we argue that, with proper design, the joint feature space of both vision and text can yield a better representation for data pre-selection. To this end, we introduce UP-DP, a simple yet effective unsupervised prompt learning approach that adapts vision-language models, like BLIP-2, for data pre-selection. Specifically, with the BLIP-2 parameters frozen, we train text prompts to extract the joint features with improved representation, ensuring a diverse cluster structure that covers the entire dataset. We extensively compare our method with the state-of-the-art using seven benchmark datasets in different settings, achieving up to a performance gain of 20\\%. Interestingly, the prompts learned from one dataset demonstrate significant generalizability and can be applied directly to enhance the feature extraction of BLIP-2 from other datasets. To the best of our knowledge, UP-DP is the first work to incorporate unsupervised prompt learning in a vision-language model for data pre-selection",
    "checked": true,
    "id": "a679c736d26dbcab41b483f2dbbc417da62c7a16",
    "semantic_title": "up-dp: unsupervised prompt learning for data pre-selection with vision-language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GqtpYUCwnu": {
    "title": "$\\varepsilon$-fractional core stability in Hedonic Games",
    "volume": "poster",
    "abstract": "Hedonic Games (HGs) are a classical framework modeling coalition formation of strategic agents guided by their individual preferences. According to these preferences, it is desirable that a coalition structure (i.e. a partition of agents into coalitions) satisfies some form of stability. The most well-known and natural of such notions is arguably core-stability. Informally, a partition is core-stable if no subset of agents would like to deviate by regrouping in a so-called core-blocking coalition. Unfortunately, core-stable partitions seldom exist and even when they do, it is often computationally intractable to find one. To circumvent these problems, we propose the notion of $\\varepsilon$-fractional core-stability, where at most an $\\varepsilon$-fraction of all possible coalitions is allowed to core-block. It turns out that such a relaxation may guarantee both existence and polynomial-time computation. Specifically, we design efficient algorithms returning an $\\varepsilon$-fractional core-stable partition, with $\\varepsilon$ exponentially decreasing in the number of agents, for two fundamental classes of HGs: Simple Fractional and Anonymous. From a probabilistic point of view, being the definition of $\\varepsilon$-fractional core equivalent to requiring that uniformly sampled coalitions core-block with probability lower than $\\varepsilon$, we further extend the definition to handle more complex sampling distributions. Along this line, when valuations have to be learned from samples in a PAC-learning fashion, we give positive and negative results on which distributions allow the efficient computation of outcomes that are $\\varepsilon$-fractional core-stable with arbitrarily high confidence",
    "checked": false,
    "id": "18ee63de8b901e8443fad31eb68ebee981326f4d",
    "semantic_title": "ε-fractional core stability in hedonic games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9mJXDcr17V": {
    "title": "Beyond Invariance: Test-Time Label-Shift Adaptation for Addressing \"Spurious\" Correlations",
    "volume": "poster",
    "abstract": "Changes in the data distribution at test time can have deleterious effects on the performance of predictive models $p(y|x)$. We consider situations where there are additional meta-data labels (such as group labels), denoted by $z$, that can account for such changes in the distribution. In particular, we assume that the prior distribution $p(y,z)$, which models the dependence between the class label $y$ and the \"nuisance\" factors $z$, may change across domains, either due to a change in the correlation between these terms, or a change in one of their marginals. However, we assume that the generative model for features $p(x|y,z)$ is invariant across domains. We note that this corresponds to an expanded version of the widely used \"label shift\" assumption, where the labels now also include the nuisance factors $z$. Based on this observation, we propose a test-time label shift correction that adapts to changes in the joint distribution $p(y, z)$ using EM applied to unlabeled samples from the target domain distribution, $p_t(x)$. Importantly, we are able to avoid fitting a generative model $p(x|y,z)$, and merely need to reweight the outputs of a discriminative model $p_s(y,z|x)$ trained on the source distribution. We evaluate our method, which we call \"Test-Time Label-Shift Adaptation\" (TTLSA), on several standard image and text datasets, as well as the CheXpert chest X-ray dataset, and show that it improves performance over methods that target invariance to changes in the distribution, as well as baseline empirical risk minimization methods. Code for reproducing experiments is available at https://github.com/nalzok/test-time-label-shift",
    "checked": true,
    "id": "835750557170821044d3f4c11381b564b98392f1",
    "semantic_title": "beyond invariance: test-time label-shift adaptation for addressing \"spurious\" correlations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6lgugutkin": {
    "title": "Language Model Alignment with Elastic Reset",
    "volume": "poster",
    "abstract": "Finetuning language models with reinforcement learning (RL), e.g. from human feedback (HF), is a prominent method for alignment. But optimizing against a reward model can improve on reward while degrading performance in other areas, a phenomenon known as reward hacking, alignment tax, or language drift. First, we argue that commonly-used test metrics are insufficient and instead measure how different algorithms tradeoff between reward and drift. The standard method modified the reward with a Kullback-Lieber (KL) penalty between the online and initial model. We propose Elastic Reset, a new algorithm that achieves higher reward with less drift without explicitly modifying the training objective. We periodically reset the online model to an exponentially moving average (EMA) of itself, then reset the EMA model to the initial model. Through the use of an EMA, our model recovers quickly after resets and achieves higher reward with less drift in the same number of steps. We demonstrate that fine-tuning language models with Elastic Reset leads to state-of-the-art performance on a small scale pivot-translation benchmark, outperforms all baselines in a medium-scale RLHF-like IMDB mock sentiment task and leads to a more performant and more aligned technical QA chatbot with LLaMA-7B. Code available https://github.com/mnoukhov/elastic-reset",
    "checked": false,
    "id": "ac113be880a94ed0f3108fbe0476824320b27b88",
    "semantic_title": "loke: linked open knowledge extraction for automated knowledge graph construction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vm1zeYqwdc": {
    "title": "Diffusion Hyperfeatures: Searching Through Time and Space for Semantic Correspondence",
    "volume": "poster",
    "abstract": "Diffusion models have been shown to be capable of generating high-quality images, suggesting that they could contain meaningful internal representations. Unfortunately, the feature maps that encode a diffusion model's internal information are spread not only over layers of the network, but also over diffusion timesteps, making it challenging to extract useful descriptors. We propose Diffusion Hyperfeatures, a framework for consolidating multi-scale and multi-timestep feature maps into per-pixel feature descriptors that can be used for downstream tasks. These descriptors can be extracted for both synthetic and real images using the generation and inversion processes. We evaluate the utility of our Diffusion Hyperfeatures on the task of semantic keypoint correspondence: our method achieves superior performance on the SPair-71k real image benchmark. We also demonstrate that our method is flexible and transferable: our feature aggregation network trained on the inversion features of real image pairs can be used on the generation features of synthetic image pairs with unseen objects and compositions. Our code is available at https://diffusion-hyperfeatures.github.io",
    "checked": true,
    "id": "c267f83a5d0fb0e4ed4c5c1174998ab6efd457aa",
    "semantic_title": "diffusion hyperfeatures: searching through time and space for semantic correspondence",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=tBib2fWr3r": {
    "title": "Understanding Deep Gradient Leakage via Inversion Influence Functions",
    "volume": "poster",
    "abstract": "Deep Gradient Leakage (DGL) is a highly effective attack that recovers private training images from gradient vectors. This attack casts significant privacy challenges on distributed learning from clients with sensitive data, where clients are required to share gradients. Defending against such attacks requires but lacks an understanding of when and how privacy leakage happens, mostly because of the black-box nature of deep networks. In this paper, we propose a novel Inversion Influence Function (I$^2$F) that establishes a closed-form connection between the recovered images and the private gradients by implicitly solving the DGL problem. Compared to directly solving DGL, I$^2$F is scalable for analyzing deep networks, requiring only oracle access to gradients and Jacobian-vector products. We empirically demonstrate that I$^2$F effectively approximated the DGL generally on different model architectures, datasets, attack implementations, and noise-based defenses. With this novel tool, we provide insights into effective gradient perturbation directions, the unfairness of privacy protection, and privacy-preferred model initialization. Our codes are provided in https://github.com/illidanlab/inversion-influence-function",
    "checked": true,
    "id": "70050b54438794a77ced84dd8e28a06a44f6fb2a",
    "semantic_title": "understanding deep gradient leakage via inversion influence functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iImnbUVhok": {
    "title": "Joint Prompt Optimization of Stacked LLMs using Variational Inference",
    "volume": "poster",
    "abstract": "Large language models (LLMs) can be seen as atomic units of computation mapping sequences to a distribution over sequences. Thus, they can be seen as stochastic language layers in a language network, where the learnable parameters are the natural language prompts at each layer. By stacking two such layers and feeding the output of one layer to the next, we obtain a Deep Language Network (DLN). We first show how to effectively perform prompt optimization for a 1-Layer language network (DLN-1). Then, we present an extension that applies to 2-layer DLNs (DLN-2), where two prompts must be learned. The key idea is to consider the output of the first layer as a latent variable, which requires inference, and prompts to be learned as the parameters of the generative distribution. We first test the effectiveness of DLN-1 in multiple reasoning and natural language understanding tasks. Then, we show that DLN-2 can reach higher performance than a single layer, showing promise that we might reach comparable performance to GPT-4, even when each LLM in the network is smaller and less powerful",
    "checked": true,
    "id": "96c5e11ffd6b4ca4468ff0c28e764e5b4bd17709",
    "semantic_title": "joint prompt optimization of stacked llms using variational inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=80g3Yqlo1a": {
    "title": "Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score Search and Grow Shrink Trees",
    "volume": "poster",
    "abstract": "Learning graphical conditional independence structures is an important machine learning problem and a cornerstone of causal discovery. However, the accuracy and execution time of learning algorithms generally struggle to scale to problems with hundreds of highly connected variables---for instance, recovering brain networks from fMRI data. We introduce the best order score search (BOSS) and grow-shrink trees (GSTs) for learning directed acyclic graphs (DAGs) in this paradigm. BOSS greedily searches over permutations of variables, using GSTs to construct and score DAGs from permutations. GSTs efficiently cache scores to eliminate redundant calculations. BOSS achieves state-of-the-art performance in accuracy and execution time, comparing favorably to a variety of combinatorial and gradient-based learning algorithms under a broad range of conditions. To demonstrate its practicality, we apply BOSS to two sets of resting-state fMRI data: simulated data with pseudo-empirical noise distributions derived from randomized empirical fMRI cortical signals and clinical data from 3T fMRI scans processed into cortical parcels. BOSS is available for use within the TETRAD project which includes Python and R wrappers",
    "checked": false,
    "id": "0ce38b197ac87bad0dcb28d3f83630c0524d0e86",
    "semantic_title": "fast scalable and accurate discovery of dags using the best order score search and grow-shrink trees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R9R7YDOar1": {
    "title": "PROTES: Probabilistic Optimization with Tensor Sampling",
    "volume": "poster",
    "abstract": "We developed a new method PROTES for black-box optimization, which is based on the probabilistic sampling from a probability density function given in the low-parametric tensor train format. We tested it on complex multidimensional arrays and discretized multivariable functions taken, among others, from real-world applications, including unconstrained binary optimization and optimal control problems, for which the possible number of elements is up to $2^{1000}$. In numerical experiments, both on analytic model functions and on complex problems, PROTES outperforms popular discrete optimization methods (Particle Swarm Optimization, Covariance Matrix Adaptation, Differential Evolution, and others)",
    "checked": true,
    "id": "c399f4724bde401589e206064e93e9663d93c675",
    "semantic_title": "protes: probabilistic optimization with tensor sampling",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=t0fkjO4aZj": {
    "title": "A unified framework for information-theoretic generalization bounds",
    "volume": "poster",
    "abstract": "This paper presents a general methodology for deriving information-theoretic generalization bounds for learning algorithms. The main technical tool is a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\\psi_p}$ Orlicz spaces. Using the decorrelation lemma in combination with other techniques, such as symmetrization, couplings, and chaining in the space of probability measures, we obtain new upper bounds on the generalization error, both in expectation and in high probability, and recover as special cases many of the existing generalization bounds, including the ones based on mutual information, conditional mutual information, stochastic chaining, and PAC-Bayes inequalities. In addition, the Fernique--Talagrand upper bound on the expected supremum of a subgaussian process emerges as a special case",
    "checked": true,
    "id": "6f45055c1b16f83ba1f9d95399b5bc1b702f7c76",
    "semantic_title": "a unified framework for information-theoretic generalization bounds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=stDm3S0CV7": {
    "title": "The Simplicity Bias in Multi-Task RNNs: Shared Attractors, Reuse of Dynamics, and Geometric Representation",
    "volume": "poster",
    "abstract": "How does a single interconnected neural population perform multiple tasks, each with its own dynamical requirements? The relation between task requirements and neural dynamics in Recurrent Neural Networks (RNNs) has been investigated for single tasks. The forces shaping joint dynamics of multiple tasks, however, are largely unexplored. In this work, we first construct a systematic framework to study multiple tasks in RNNs, minimizing interference from input and output correlations with the hidden representation. This allows us to reveal how RNNs tend to share attractors and reuse dynamics, a tendency we define as the \"simplicity bias\". We find that RNNs develop attractors sequentially during training, preferentially reusing existing dynamics and opting for simple solutions when possible. This sequenced emergence and preferential reuse encapsulate the simplicity bias. Through concrete examples, we demonstrate that new attractors primarily emerge due to task demands or architectural constraints, illustrating a balance between simplicity bias and external factors. We examine the geometry of joint representations within a single attractor, by constructing a family of tasks from a set of functions. We show that the steepness of the associated functions controls their alignment within the attractor. This arrangement again highlights the simplicity bias, as points with similar input spacings undergo comparable transformations to reach the shared attractor. Our findings propose compelling applications. The geometry of shared attractors might allow us to infer the nature of unknown tasks. Furthermore, the simplicity bias implies that without specific incentives, modularity in RNNs may not spontaneously emerge, providing insights into the conditions required for network specialization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NJK3aSB0z4": {
    "title": "Variational Gaussian processes for linear inverse problems",
    "volume": "poster",
    "abstract": "By now Bayesian methods are routinely used in practice for solving inverse problems. In inverse problems the parameter or signal of interest is observed only indirectly, as an image of a given map, and the observations are typically further corrupted with noise. Bayes offers a natural way to regularize these problems via the prior distribution and provides a probabilistic solution, quantifying the remaining uncertainty in the problem. However, the computational costs of standard, sampling based Bayesian approaches can be overly large in such complex models. Therefore, in practice variational Bayes is becoming increasingly popular. Nevertheless, the theoretical understanding of these methods is still relatively limited, especially in context of inverse problems. In our analysis we investigate variational Bayesian methods for Gaussian process priors to solve linear inverse problems. We consider both mildly and severely ill-posed inverse problems and work with the popular inducing variable variational Bayes approach proposed by Titsias [Titsias, 2009]. We derive posterior contraction rates for the variational posterior in general settings and show that the minimax estimation rate can be attained by correctly tunned procedures. As specific examples we consider a collection of inverse problems including the heat equation, Volterra operator and Radon transform and inducing variable methods based on population and empirical spectral features",
    "checked": true,
    "id": "de22e455cacc73ebbbd560b2f2fa2ef555e27b5c",
    "semantic_title": "variational gaussian processes for linear inverse problems",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=2b9aY2NgXE": {
    "title": "Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning",
    "volume": "poster",
    "abstract": "Fine-tuning vision-language models (VLMs) like CLIP to downstream tasks is often necessary to optimize their performance. However, a major obstacle is the limited availability of labeled data. We study the use of pseudolabels, i.e., heuristic labels for unlabeled data, to enhance CLIP via prompt tuning. Conventional pseudolabeling trains a model on labeled data and then generates labels for unlabeled data. VLMs' zero-shot capabilities enable a ``second generation'' of pseudolabeling approaches that do not require task-specific training on labeled data. By using zero-shot pseudolabels as a source of supervision, we observe that learning paradigms such as semi-supervised, transductive zero-shot, and unsupervised learning can all be seen as optimizing the same loss function. This unified view enables the development of versatile training strategies that are applicable across learning paradigms. We investigate them on image classification tasks where CLIP exhibits limitations, by varying prompt modalities, e.g., textual or visual prompts, and learning paradigms. We find that (1) unexplored prompt tuning strategies that iteratively refine pseudolabels consistently improve CLIP accuracy, by 19.5 points in semi-supervised learning, by 28.4 points in transductive zero-shot learning, and by 15.2 points in unsupervised learning, and (2) unlike conventional semi-supervised pseudolabeling, which exacerbates model biases toward classes with higher-quality pseudolabels, prompt tuning leads to a more equitable distribution of per-class accuracy. The code to reproduce the experiments is at https://github.com/BatsResearch/menghini-neurips23-code",
    "checked": true,
    "id": "b100bb4c40340efa87b1bfc88d1d6839127d0e86",
    "semantic_title": "enhancing clip with clip: exploring pseudolabeling for limited-label prompt tuning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=blC2kbzvNC": {
    "title": "Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction",
    "volume": "poster",
    "abstract": "The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, two issues remain unsolved in this line of work. First, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al.), this approach results in slower convergence rates under interpolation. Second, intuitive line-search methods equipped with variance-reduction (VR) fail to converge (Dubois-Taine et al.). So far, no VR methods successfully accelerate these two stepsizes with a convergence guarantee. In this work, we make two contributions: Firstly, we propose two new robust variants of SPS and SLS, called AdaSPS and AdaSLS, which achieve optimal asymptotic rates in both strongly-convex or convex and interpolation or non-interpolation settings, except for the case when we have both strong convexity and non-interpolation. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value as input. Secondly, we propose a novel VR method that can use Polyak stepsizes or line-search to achieve acceleration. When it is equipped with AdaSPS or AdaSLS, the resulting algorithms obtain the optimal rate for optimizing convex smooth functions. Finally, numerical experiments on synthetic and real datasets validate our theory and demonstrate the effectiveness and robustness of our algorithms",
    "checked": true,
    "id": "d1a06508395919e9f7d8064dd478e4ea8721142b",
    "semantic_title": "adaptive sgd with polyak stepsize and line-search: robust convergence and variance reduction",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=DI6KQhgqUr": {
    "title": "First Order Stochastic Optimization with Oblivious Noise",
    "volume": "poster",
    "abstract": "We initiate the study of stochastic optimization with oblivious noise, broadly generalizing the standard heavy-tailed noise setup. In our setting, in addition to random observation noise, the stochastic gradient may be subject to independent \\emph{oblivious noise}, which may not have bounded moments and is not necessarily centered. Specifically, we assume access to a noisy oracle for the stochastic gradient of $f$ at $x$, which returns a vector $\\nabla f(\\gamma, x) + \\xi$, where $\\gamma$ is the bounded variance observation noise and $\\xi$ is the oblivious noise that is independent of $\\gamma$ and $x$. The only assumption we make on the oblivious noise $\\xi$ is that $\\Pr[\\xi = 0] \\ge \\alpha$, for some $\\alpha \\in (0, 1)$. In this setting, it is not information-theoretically possible to recover a single solution close to the target when the fraction of inliers $\\alpha$ is less than $1/2$. Our main result is an efficient {\\em list-decodable} learner that recovers a small list of candidates at least one of which is close to the true solution. On the other hand, if $\\alpha = 1-\\epsilon$, where $0< \\epsilon < 1/2$ is sufficiently small constant, the algorithm recovers a single solution. Along the way, we develop a rejection-sampling-based algorithm to perform noisy location estimation, which may be of independent interest",
    "checked": false,
    "id": "436e34f3fd0f0a99c0d449a896c004f0643f8e85",
    "semantic_title": "first-order policy optimization for robust markov decision process",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=qgiG7WZohZ": {
    "title": "Affinity-Aware Graph Networks",
    "volume": "poster",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful technique for learning on relational data. Owing to the relatively limited number of message passing steps they perform—and hence a smaller receptive field—there has been significant interest in improving their expressivity by incorporating structural aspects of the underlying graph. In this paper, we explore the use of affinity measures as features in graph neural networks, in particular measures arising from random walks, including effective resistance, hitting and commute times. We propose message passing networks based on these features and evaluate their performance on a variety of node and graph property prediction tasks. Our architecture has low computational complexity, while our features are invariant to the permutations of the underlying graph. The measures we compute allow the network to exploit the connectivity properties of the graph, thereby allowing us to outperform relevant benchmarks for a wide variety of tasks, often with significantly fewer message passing steps. On one of the largest publicly available graph regression datasets, OGB-LSC-PCQM4Mv1, we obtain the best known single-model validation MAE at the time of writing",
    "checked": true,
    "id": "ef5f1903cfd817aafc7f0018e9ea4b2056aade31",
    "semantic_title": "affinity-aware graph networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=iqezE0EyXq": {
    "title": "Adaptive recurrent vision performs zero-shot computation scaling to unseen difficulty levels",
    "volume": "poster",
    "abstract": "Humans solving algorithmic (or) reasoning problems typically exhibit solution times that grow as a function of problem difficulty. Adaptive recurrent neural networks have been shown to exhibit this property for various language-processing tasks. However, little work has been performed to assess whether such adaptive computation can also enable vision models to extrapolate solutions beyond their training distribution's difficulty level, with prior work focusing on very simple tasks. In this study, we investigate a critical functional role of such adaptive processing using recurrent neural networks: to dynamically scale computational resources conditional on input requirements that allow for zero-shot generalization to novel difficulty levels not seen during training using two challenging visual reasoning tasks: PathFinder and Mazes. We combine convolutional recurrent neural networks (ConvRNNs) with a learnable halting mechanism based on Graves (2016). We explore various implementations of such adaptive ConvRNNs (AdRNNs) ranging from tying weights across layers to more sophisticated biologically inspired recurrent networks that possess lateral connections and gating. We show that 1) AdRNNs learn to dynamically halt processing early (or late) to solve easier (or harder) problems, 2) these RNNs zero-shot generalize to more difficult problem settings not shown during training by dynamically increasing the number of recurrent iterations at test time. Our study provides modeling evidence supporting the hypothesis that recurrent processing enables the functional advantage of adaptively allocating compute resources conditional on input requirements and hence allowing generalization to harder difficulty levels of a visual reasoning problem without training",
    "checked": true,
    "id": "ea535502e112590c1d571d68cd4e75093c596440",
    "semantic_title": "adaptive recurrent vision performs zero-shot computation scaling to unseen difficulty levels",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8uOZ0kNji6": {
    "title": "Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts",
    "volume": "poster",
    "abstract": "Rapidly increasing quality of AI-generated content makes it difficult to distinguish between human and AI-generated texts, which may lead to undesirable consequences for society. Therefore, it becomes increasingly important to study the properties of human texts that are invariant over text domains and various proficiency of human writers, can be easily calculated for any language, and can robustly separate natural and AI-generated texts regardless of the generation model and sampling method. In this work, we propose such an invariant of human texts, namely the intrinsic dimensionality of the manifold underlying the set of embeddings of a given text sample. We show that the average intrinsic dimensionality of fluent texts in natural language is hovering around the value $9$ for several alphabet-based languages and around $7$ for Chinese, while the average intrinsic dimensionality of AI-generated texts for each language is $\\approx 1.5$ lower, with a clear statistical separation between human-generated and AI-generated distributions. This property allows us to build a score-based artificial text detector. The proposed detector's accuracy is stable over text domains, generator models, and human writer proficiency levels, outperforming SOTA detectors in model-agnostic and cross-domain scenarios by a significant margin",
    "checked": true,
    "id": "a5fab19553e623e8787383cb3da76b8a3c42a8f4",
    "semantic_title": "intrinsic dimension estimation for robust detection of ai-generated texts",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=b1BhHjBxsx": {
    "title": "Sharp Recovery Thresholds of Tensor PCA Spectral Algorithms",
    "volume": "poster",
    "abstract": "Many applications seek to recover low-rank approximations of noisy tensor data. We consider several practical and effective matricization strategies which construct specific matrices from such tensors and then apply spectral methods; the strategies include tensor unfolding, partial tracing, power iteration, and recursive unfolding. We settle the behaviors of unfolding and partial tracing, identifying sharp thresholds in signal-to-noise ratio above which the signal is partially recovered. In particular, we extend previous results to a much larger class of tensor shapes where axis lengths may be different. For power iteration and recursive unfolding, we prove that under conditions where previous algorithms partially recovery the signal, these methods achieve (asymptotically) exact recovery. Our analysis deploys random matrix theory to obtain sharp thresholds which elude perturbation and concentration bounds. Specifically, we rely upon recent disproportionate random matrix results, which describe sequences of matrices with diverging aspect ratio",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Gtse4R6iS4": {
    "title": "Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model",
    "volume": "poster",
    "abstract": "Feedforward generalizable models for implicit shape reconstruction from unoriented point cloud present multiple advantages, including high performance and inference speed. However, they still suffer from generalization issues, ranging from underfitting the input point cloud, to misrepresenting samples outside of the training data distribution, or with toplogies unseen at training. We propose here an efficient mechanism to remedy some of these limitations at test time. We combine the inter-shape data prior of the network with an intra-shape regularization prior of a Nyström Kernel Ridge Regression, that we further adapt by fitting its hyperprameters to the current shape. The resulting shape function defined in a shape specific Reproducing Kernel Hilbert Space benefits from desirable stability and efficiency properties and grants a shape adaptive expressiveness-robustness trade-off. We demonstrate the improvement obtained through our method with respect to baselines and the state-of-the-art using synthetic and real data",
    "checked": true,
    "id": "271ec984da74d45b02f0fb1dfa41f348aaa36553",
    "semantic_title": "robustifying generalizable implicit shape networks with a tunable non-parametric model",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=vAElhFcKW6": {
    "title": "Reflexion: language agents with verbal reinforcement learning",
    "volume": "poster",
    "abstract": "Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents. However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning. We propose \\emph{Reflexion}, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback. Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials. Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning). For example, Reflexion achieves a 91\\% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80\\%. We also conduct ablation and analysis studies using different feedback signals, feedback incorporation methods, and agent types, and provide insights into how they affect performance. We release all code, demos, and datasets at \\url{https://github.com/noahshinn024/reflexion}",
    "checked": true,
    "id": "0671fd553dd670a4e820553a974bc48040ba0819",
    "semantic_title": "reflexion: language agents with verbal reinforcement learning",
    "citation_count": 125,
    "authors": []
  },
  "https://openreview.net/forum?id=Z6eexoCy7W": {
    "title": "Topology-Aware Uncertainty for Image Segmentation",
    "volume": "poster",
    "abstract": "Segmentation of curvilinear structures such as vasculature and road networks is challenging due to relatively weak signals and complex geometry/topology. To facilitate and accelerate large scale annotation, one has to adopt semi-automatic approaches such as proofreading by experts. In this work, we focus on uncertainty estimation for such tasks, so that highly uncertain, and thus error-prone structures can be identified for human annotators to verify. Unlike most existing works, which provide pixel-wise uncertainty maps, we stipulate it is crucial to estimate uncertainty in the units of topological structures, e.g., small pieces of connections and branches. To achieve this, we leverage tools from topological data analysis, specifically discrete Morse theory (DMT), to first capture the structures, and then reason about their uncertainties. To model the uncertainty, we (1) propose a joint prediction model that estimates the uncertainty of a structure while taking the neighboring structures into consideration (inter-structural uncertainty); (2) propose a novel Probabilistic DMT to model the inherent uncertainty within each structure (intra-structural uncertainty) by sampling its representations via a perturb-and-walk scheme. On various 2D and 3D datasets, our method produces better structure-wise uncertainty maps compared to existing works. Code available at: https://github.com/Saumya-Gupta-26/struct-uncertainty",
    "checked": true,
    "id": "77d1739b5433c3b3dd49de64407954a3e80c101f",
    "semantic_title": "topology-aware uncertainty for image segmentation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Q3FXnCPZ1X": {
    "title": "Fast and Simple Spectral Clustering in Theory and Practice",
    "volume": "poster",
    "abstract": "Spectral clustering is a popular and effective algorithm designed to find $k$ clusters in a graph $G$. In the classical spectral clustering algorithm, the vertices of $G$ are embedded into $\\mathbb{R}^k$ using $k$ eigenvectors of the graph Laplacian matrix. However, computing this embedding is computationally expensive and dominates the running time of the algorithm. In this paper, we present a simple spectral clustering algorithm based on a vertex embedding with $O(\\log(k))$ vectors computed by the power method. The vertex embedding is computed in nearly-linear time with respect to the size of the graph, and the algorithm provably recovers the ground truth clusters under natural assumptions on the input graph. We evaluate the new algorithm on several synthetic and real-world datasets, finding that it is significantly faster than alternative clustering algorithms, while producing results with approximately the same clustering accuracy",
    "checked": true,
    "id": "8625c3a2c6f7015cb79cd739da170aca712323da",
    "semantic_title": "fast and simple spectral clustering in theory and practice",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TNLO8KNFFZ": {
    "title": "Information Geometry of the Retinal Representation Manifold",
    "volume": "poster",
    "abstract": "The ability for the brain to discriminate among visual stimuli is constrained by their retinal representations. Previous studies of visual discriminability have been limited to either low-dimensional artificial stimuli or pure theoretical considerations without a realistic encoding model. Here we propose a novel framework for understanding stimulus discriminability achieved by retinal representations of naturalistic stimuli with the method of information geometry. To model the joint probability distribution of neural responses conditioned on the stimulus, we created a stochastic encoding model of a population of salamander retinal ganglion cells based on a three-layer convolutional neural network model. This model not only accurately captured the mean response to natural scenes but also a variety of second-order statistics. With the model and the proposed theory, we computed the Fisher information metric over stimuli to study the most discriminable stimulus directions. We found that the most discriminable stimulus varied substantially across stimuli, allowing an examination of the relationship between the most discriminable stimulus and the current stimulus. By examining responses generated by the most discriminable stimuli we further found that the most discriminative response mode is often aligned with the most stochastic mode. This finding carries the important implication that under natural scenes, retinal noise correlations are information-limiting rather than increasing information transmission as has been previously speculated. We additionally observed that sensitivity saturates less in the population than for single cells and that as a function of firing rate, Fisher information varies less than sensitivity. We conclude that under natural scenes, population coding benefits from complementary coding and helps to equalize the information carried by different firing rates, which may facilitate decoding of the stimulus under principles of information maximization",
    "checked": true,
    "id": "eeca6eb9453435f61e83744b1b135f2de9430ff7",
    "semantic_title": "information geometry of the retinal representation manifold",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZD65F3x1jU": {
    "title": "On Learning Latent Models with Multi-Instance Weak Supervision",
    "volume": "poster",
    "abstract": "We consider a weakly supervised learning scenario where the supervision signal is generated by a transition function $\\sigma$ of labels associated with multiple input instances. We formulate this problem as *multi-instance Partial Label Learning (multi-instance PLL)*, which is an extension to the standard PLL problem. Our problem is met in different fields, including latent structural learning and neuro-symbolic integration. Despite the existence of many learning techniques, limited theoretical analysis has been dedicated to this problem. In this paper, we provide the first theoretical study of multi-instance PLL with possibly an unknown transition $\\sigma$. Our main contributions are as follows: First, we proposed a necessary and sufficient condition for the learnability of the problem. This condition nontrivially generalizes and relaxes the existing *small ambiguity degree* in PLL literature since we allow the transition to be deterministic. Second, we derived Rademacher-style error bounds based on the top-$k$ surrogate loss that is widely used in the neuro-symbolic literature. Furthermore, we conclude with empirical experiments for learning with an unknown transition. The empirical results align with our theoretical findings; however, they also expose the issue of scalability in the weak supervision literature",
    "checked": true,
    "id": "1fcaad4365e0aea012bcc3315fb9c594e5378283",
    "semantic_title": "on learning latent models with multi-instance weak supervision",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=CdSRFn1fVe": {
    "title": "Smooth, exact rotational symmetrization for deep learning on point clouds",
    "volume": "poster",
    "abstract": "Point clouds are versatile representations of 3D objects and have found widespread application in science and engineering. Many successful deep-learning models have been proposed that use them as input. The domain of chemical and materials modeling is especially challenging because exact compliance with physical constraints is highly desirable for a model to be usable in practice. These constraints include smoothness and invariance with respect to translations, rotations, and permutations of identical atoms. If these requirements are not rigorously fulfilled, atomistic simulations might lead to absurd outcomes even if the model has excellent accuracy. Consequently, dedicated architectures, which achieve invariance by restricting their design space, have been developed. General-purpose point-cloud models are more varied but often disregard rotational symmetry. We propose a general symmetrization method that adds rotational equivariance to any given model while preserving all the other requirements. Our approach simplifies the development of better atomic-scale ML schemes by relaxing the constraints on the design space and making it possible to incorporate ideas that proved effective in other domains. We demonstrate this idea by introducing the Point Edge Transformer (PET) architecture, which is not intrinsically equivariant but achieves state-of-the-art performance on several benchmark datasets of molecules and solids. A-posteriori application of our general protocol makes PET exactly equivariant, with minimal changes to its accuracy",
    "checked": true,
    "id": "ada34d916d0396257fb8ab4ab9b19c2ccba51a85",
    "semantic_title": "smooth, exact rotational symmetrization for deep learning on point clouds",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=dL0GM9Wwtq": {
    "title": "Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control",
    "volume": "poster",
    "abstract": "Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parameterized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. We first investigate high-dimensional linear regression for imputing wage data and estimating average treatment effects, where we find that models with many more covariates than sample size can outperform simple ones. We then document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we link to an improvement in average performance. This perspective yields concrete insights into the use of synthetic control when control units are many relative to the number of pre-treatment periods",
    "checked": true,
    "id": "76e370e2ae48ef1799c04328b1abc7f2f0fc3eba",
    "semantic_title": "double and single descent in causal inference with an application to high-dimensional synthetic control",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=X6Eapo5paw": {
    "title": "Latent SDEs on Homogeneous Spaces",
    "volume": "poster",
    "abstract": "We consider the problem of variational Bayesian inference in a latent variable model where a (possibly complex) observed stochastic process is governed by the unobserved solution of a latent stochastic differential equation (SDE). Motivated by the challenges that arise when trying to learn a latent SDE in $\\mathbb{R}^n$ from large-scale data, such as efficient gradient computation, we take a step back and study a specific subclass instead. In our case, the SDE evolves inside a homogeneous latent space and is induced by stochastic dynamics of the corresponding (matrix) Lie group. In the context of learning problems, SDEs on the $n$-dimensional unit sphere are arguably the most relevant incarnation of this setup. For variational inference, the sphere not only facilitates using a uniform prior on the initial state of the SDE, but we also obtain a particularly simple and intuitive expression for the KL divergence between the approximate posterior and prior process in the evidence lower bound. We provide empirical evidence that a latent SDE of the proposed type can be learned efficiently by means of an existing one-step geometric Euler-Maruyama scheme. Despite restricting ourselves to a less diverse class of SDEs, we achieve competitive or even state-of-the-art performance on a collection of time series interpolation and classification benchmarks",
    "checked": true,
    "id": "7ff5350bc610980d2f0dee375d3d0a0614adabfd",
    "semantic_title": "latent sdes on homogeneous spaces",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CusNOTRkQw": {
    "title": "Align Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization",
    "volume": "poster",
    "abstract": "The promising zero-shot generalization of vision-language models such as CLIP has led to their adoption using prompt learning for numerous downstream tasks. Previous works have shown test-time prompt tuning using entropy minimization to adapt text prompts for unseen domains. While effective, this overlooks the key cause for performance degradation to unseen domains -- distribution shift. In this work, we explicitly handle this problem by aligning the out-of-distribution (OOD) test sample statistics to those of the source data using prompt tuning. We use a single test sample to adapt multi-modal prompts at test time by minimizing the feature distribution shift to bridge the gap in the test domain. Evaluating against the domain generalization benchmark, our method improves zero-shot top-1 accuracy beyond existing prompt-learning techniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset generalization with unseen categories across 10 datasets, our method improves consistently across all datasets compared to the existing state-of-the-art. Our source code and models are available at [https://jameelhassan.github.io/promptalign](https://jameelhassan.github.io/promptalign)",
    "checked": true,
    "id": "4a8efea3247c3d9ab458d4e2ed47d97c0661b429",
    "semantic_title": "align your prompts: test-time prompting with distribution alignment for zero-shot generalization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iKarSI2a73": {
    "title": "Bicriteria Approximation Algorithms for the Submodular Cover Problem",
    "volume": "poster",
    "abstract": "In this paper, we consider the optimization problem Submodular Cover (SCP), which is to find a minimum cardinality subset of a finite universe $U$ such that the value of a submodular function $f$ is above an input threshold $\\tau$. In particular, we consider several variants of SCP including the general case, the case where $f$ is additionally assumed to be monotone, and finally the case where $f$ is a regularized monotone submodular function. Our most significant contributions are that: (i) We propose a scalable algorithm for monotone SCP that achieves nearly the same approximation guarantees as the standard greedy algorithm in significantly faster time; (ii) We are the first to develop an algorithm for general SCP that achieves a solution arbitrarily close to being feasible; and finally (iii) we are the first to develop algorithms for regularized SCP. Our algorithms are then demonstrated to be effective in an extensive experimental section on data summarization and graph cut, two applications of SCP",
    "checked": true,
    "id": "26e3711dae16f8fd7b54b7b4a29cdc4fdaff7cff",
    "semantic_title": "bicriteria approximation algorithms for the submodular cover problem",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SWU8YLlFVH": {
    "title": "Neural Sampling in Hierarchical Exponential-family Energy-based Models",
    "volume": "poster",
    "abstract": "Bayesian brain theory suggests that the brain employs generative models to understand the external world. The sampling-based perspective posits that the brain infers the posterior distribution through samples of stochastic neuronal responses. Additionally, the brain continually updates its generative model to approach the true distribution of the external world. In this study, we introduce the Hierarchical Exponential-family Energy-based (HEE) model, which captures the dynamics of inference and learning. In the HEE model, we decompose the partition function into individual layers and leverage a group of neurons with shorter time constants to sample the gradient of the decomposed normalization term. This allows our model to estimate the partition function and perform inference simultaneously, circumventing the negative phase encountered in conventional energy-based models (EBMs). As a result, the learning process is localized both in time and space, and the model is easy to converge. To match the brain's rapid computation, we demonstrate that neural adaptation can serve as a momentum term, significantly accelerating the inference process. On natural image datasets, our model exhibits representations akin to those observed in the biological visual system. Furthermore, for the machine learning community, our model can generate observations through joint or marginal generation. We show that marginal generation outperforms joint generation and achieves performance on par with other EBMs",
    "checked": true,
    "id": "7184b290949fc985a1dc1653cbe724d059952318",
    "semantic_title": "neural sampling in hierarchical exponential-family energy-based models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1kgK0r8PGg": {
    "title": "Exponentially Convergent Algorithms for Supervised Matrix Factorization",
    "volume": "poster",
    "abstract": "Supervised matrix factorization (SMF) is a classical machine learning method that simultaneously seeks feature extraction and classification tasks, which are not necessarily a priori aligned objectives. Our goal is to use SMF to learn low-rank latent factors that offer interpretable, data-reconstructive, and class-discriminative features, addressing challenges posed by high-dimensional data. Training SMF model involves solving a nonconvex and possibly constrained optimization with at least three blocks of parameters. Known algorithms are either heuristic or provide weak convergence guarantees for special cases. In this paper, we provide a novel framework that `lifts' SMF as a low-rank matrix estimation problem in a combined factor space and propose an efficient algorithm that provably converges exponentially fast to a global minimizer of the objective with arbitrary initialization under mild assumptions. Our framework applies to a wide range of SMF-type problems for multi-class classification with auxiliary features. To showcase an application, we demonstrate that our algorithm successfully identified well-known cancer-associated gene groups for various cancers",
    "checked": true,
    "id": "0cc8190d8cb6812620767039f261a8f2ce3c851f",
    "semantic_title": "exponentially convergent algorithms for supervised matrix factorization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cezKbXsT3V": {
    "title": "On Separate Normalization in Self-supervised Transformers",
    "volume": "poster",
    "abstract": "Self-supervised training methods for transformers have demonstrated remarkable performance across various domains. Previous transformer-based models, such as masked autoencoders (MAE), typically utilize a single normalization layer for both the [CLS] symbol and the tokens. We propose in this paper a simple modification that employs separate normalization layers for the tokens and the [CLS] symbol to better capture their distinct characteristics and enhance downstream task performance. Our method aims to alleviate the potential negative effects of using the same normalization statistics for both token types, which may not be optimally aligned with their individual roles. We empirically show that by utilizing a separate normalization layer, the [CLS] embeddings can better encode the global contextual information and are distributed more uniformly in its anisotropic space. When replacing the conventional normalization layer with the two separate layers, we observe an average 2.7% performance improvement over the image, natural language, and graph domains",
    "checked": true,
    "id": "ca6a325ebecab63ada489066885a211c74c7e9a6",
    "semantic_title": "on separate normalization in self-supervised transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fFJThJ94rY": {
    "title": "Switching Autoregressive Low-rank Tensor Models",
    "volume": "poster",
    "abstract": "An important problem in time-series analysis is modeling systems with time-varying dynamics. Probabilistic models with joint continuous and discrete latent states offer interpretable, efficient, and experimentally useful descriptions of such data. Commonly used models include autoregressive hidden Markov models (ARHMMs) and switching linear dynamical systems (SLDSs), each with its own advantages and disadvantages. ARHMMs permit exact inference and easy parameter estimation, but are parameter intensive when modeling long dependencies, and hence are prone to overfitting. In contrast, SLDSs can capture long-range dependencies in a parameter efficient way through Markovian latent dynamics, but present an intractable likelihood and a challenging parameter estimation task. In this paper, we propose _switching autoregressive low-rank tensor_ SALT models, which retain the advantages of both approaches while ameliorating the weaknesses. SALT parameterizes the tensor of an ARHMM with a low-rank factorization to control the number of parameters and allow longer range dependencies without overfitting. We prove theoretical and discuss practical connections between SALT, linear dynamical systems, and SLDSs. We empirically demonstrate quantitative advantages of SALT models on a range of simulated and real prediction tasks, including behavioral and neural datasets. Furthermore, the learned low-rank tensor provides novel insights into temporal dependencies within each discrete state",
    "checked": true,
    "id": "22fc055449356776a1156e720b2167077ef0e5f8",
    "semantic_title": "switching autoregressive low-rank tensor models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jl5a3t78Uh": {
    "title": "Energy-based learning algorithms for analog computing: a comparative study",
    "volume": "poster",
    "abstract": "Energy-based learning algorithms have recently gained a surge of interest due to their compatibility with analog (post-digital) hardware. Existing algorithms include contrastive learning (CL), equilibrium propagation (EP) and coupled learning (CpL), all consisting in contrasting two states, and differing in the type of perturbation used to obtain the second state from the first one. However, these algorithms have never been explicitly compared on equal footing with same models and datasets, making it difficult to assess their scalability and decide which one to select in practice. In this work, we carry out a comparison of seven learning algorithms, namely CL and different variants of EP and CpL depending on the signs of the perturbations. Specifically, using these learning algorithms, we train deep convolutional Hopfield networks (DCHNs) on five vision tasks (MNIST, F-MNIST, SVHN, CIFAR-10 and CIFAR-100). We find that, while all algorithms yield comparable performance on MNIST, important differences in performance arise as the difficulty of the task increases. Our key findings reveal that negative perturbations are better than positive ones, and highlight the centered variant of EP (which uses two perturbations of opposite sign) as the best-performing algorithm. We also endorse these findings with theoretical arguments. Additionally, we establish new SOTA results with DCHNs on all five datasets, both in performance and speed. In particular, our DCHN simulations are 13.5 times faster with respect to Laborieux et al. (2021), which we achieve thanks to the use of a novel energy minimisation algorithm based on asynchronous updates, combined with reduced precision (16 bits)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wg3d2FKAm8": {
    "title": "Outlier-Robust Wasserstein DRO",
    "volume": "poster",
    "abstract": "Distributionally robust optimization (DRO) is an effective approach for data-driven decision-making in the presence of uncertainty. Geometric uncertainty due to~sampling or localized perturbations of data points is captured by Wasserstein DRO (WDRO), which seeks to learn a model that performs uniformly well over a Wasserstein ball centered around the observed data distribution. However, WDRO fails to account for non-geometric perturbations such as adversarial outliers, which can greatly distort the Wasserstein distance measurement and impede the learned model. We address this gap by proposing a novel outlier-robust WDRO framework for decision-making under both geometric (Wasserstein) perturbations and non-geometric (total variation (TV)) contamination that allows an $\\varepsilon$-fraction of data to be arbitrarily corrupted. We design an uncertainty set using a certain robust Wasserstein ball that accounts for both perturbation types and derive minimax optimal excess risk bounds for this procedure that explicitly capture the Wasserstein and TV risks. We prove a strong duality result that enables tractable convex reformulations and efficient computation of our outlier-robust WDRO problem. When the loss function depends only on low-dimensional features of the data, we eliminate certain dimension dependencies from the risk bounds that are unavoidable in the general setting. Finally, we present experiments validating our theory on standard regression and classification tasks",
    "checked": true,
    "id": "619c4e6d12dd484663845c437d64f60d26b3d5d7",
    "semantic_title": "outlier-robust wasserstein dro",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UdByCgCNdr": {
    "title": "MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks",
    "volume": "poster",
    "abstract": "Human commonsense understanding of the physical and social world is organized around intuitive theories. These theories support making causal and moral judgments. When something bad happens, we naturally ask: who did what, and why? A rich literature in cognitive science has studied people's causal and moral intuitions. This work has revealed a number of factors that systematically influence people's judgments, such as the violation of norms and whether the harm is avoidable or inevitable. We collected a dataset of stories from 24 cognitive science papers and developed a system to annotate each story with the factors they investigated. Using this dataset, we test whether large language models (LLMs) make causal and moral judgments about text-based scenarios that align with those of human participants. On the aggregate level, alignment has improved with more recent LLMs. However, using statistical analyses, we find that LLMs weigh the different factors quite differently from human participants. These results show how curated, challenge datasets combined with insights from cognitive science can help us go beyond comparisons based merely on aggregate metrics: we uncover LLMs implicit tendencies and show to what extent these align with human intuitions",
    "checked": true,
    "id": "708450b22ed062da7fa577e10088f25023b1437c",
    "semantic_title": "moca: measuring human-language model alignment on causal and moral judgment tasks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CFQBcz7k8n": {
    "title": "Adversarially Robust Learning with Uncertain Perturbation Sets",
    "volume": "poster",
    "abstract": "In many real-world settings exact perturbation sets to be used by an adversary are not plausibly available to a learner. While prior literature has studied both scenarios with completely known and completely unknown perturbation sets, we propose an in-between setting of learning with respect to a class of perturbation sets. We show that in this setting we can improve on previous results with completely unknown perturbation sets, while still addressing the concerns of not having perfect knowledge of these sets in real life. In particular, we give the first positive results for the learnability of infinite Littlestone classes when having access to a perfect-attack oracle. We also consider a setting of learning with abstention, where predictions are considered robustness violations, only when the wrong prediction is made within the perturbation set. We show there are classes for which perturbation-set unaware learning without query access is possible, but abstention is required",
    "checked": false,
    "id": "cce64f803053fa2fb7bf27194ad8b86f747f25c2",
    "semantic_title": "adversarially robust learning with unknown perturbation sets",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=YI4bn6aAmz": {
    "title": "Conformal Prediction Sets for Ordinal Classification",
    "volume": "poster",
    "abstract": "Ordinal classification (OC), i.e., labeling instances along classes with a natural ordering, is common in multiple applications such as size or budget based recommendations and disease severity labeling. Often in practical scenarios, it is desirable to obtain a small set of likely classes with a guaranteed high chance of including the true class. Recent works on conformal prediction (CP) address this problem for the classification setting with non-ordered labels but the resulting prediction sets (PS) are often non-contiguous and unsuitable for ordinal classification. In this work, we propose a framework to adapt existing CP methods to generate contiguous sets with guaranteed coverage and minimal cardinality. Our framework employs a novel non-parametric approach for modeling unimodal distributions. Empirical results on both synthetic and real-world datasets demonstrate our method outperforms SOTA baselines by 4% on Accuracy@K and 8% on PS size",
    "checked": false,
    "id": "65b650c866c6c21a06a80dd9d942568edb098f1c",
    "semantic_title": "conformal risk control for ordinal classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VNjJAWjuEU": {
    "title": "Graph of Circuits with GNN for Exploring the Optimal Design Space",
    "volume": "poster",
    "abstract": "The design automation of analog circuits poses significant challenges in terms of the large design space, complex interdependencies between circuit specifications, and resource-intensive simulations. To address these challenges, this paper presents an innovative framework called the Graph of Circuits Explorer (GCX). Leveraging graph structure learning along with graph neural networks, GCX enables the creation of a surrogate model that facilitates efficient exploration of the optimal design space within a semi-supervised learning framework which reduces the need for large labelled datasets. The proposed approach comprises three key stages. First, we learn the geometric representation of circuits and enrich it with technology information to create a comprehensive feature vector. Subsequently, integrating feature-based graph learning with few-shot and zero-shot learning enhances the generalizability in predictions for unseen circuits. Finally, we introduce two algorithms namely, EASCO and ASTROG which upon integration with GCX optimize the available samples to yield the optimal circuit configuration meeting the designer's criteria. The effectiveness of the proposed approach is demonstrated through simulated performance evaluation of various circuits, using derived parameters in 180nm CMOS technology. Furthermore, the generalizability of the approach is extended to higher-order topologies and different technology nodes such as 65nm and 45nm CMOS process nodes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qYAp31KwU2": {
    "title": "Multi-Objective Intrinsic Reward Learning for Conversational Recommender Systems",
    "volume": "poster",
    "abstract": "Conversational Recommender Systems (CRS) actively elicit user preferences to generate adaptive recommendations. Mainstream reinforcement learning-based CRS solutions heavily rely on handcrafted reward functions, which may not be aligned with user intent in CRS tasks. Therefore, the design of task-specific rewards is critical to facilitate CRS policy learning, which remains largely under-explored in the literature. In this work, we propose a novel approach to address this challenge by learning intrinsic rewards from interactions with users. Specifically, we formulate intrinsic reward learning as a multi-objective bi-level optimization problem. The inner level optimizes the CRS policy augmented by the learned intrinsic rewards, while the outer level drives the intrinsic rewards to optimize two CRS-specific objectives: maximizing the success rate and minimizing the number of turns to reach a successful recommendation}in conversations. To evaluate the effectiveness of our approach, we conduct extensive experiments on three public CRS benchmarks. The results show that our algorithm significantly improves CRS performance by exploiting informative learned intrinsic rewards",
    "checked": true,
    "id": "f7ea50dea238913894dde804d696f22b13c7cbdf",
    "semantic_title": "multi-objective intrinsic reward learning for conversational recommender systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h0RVoZuUl6": {
    "title": "Resilient Constrained Learning",
    "volume": "poster",
    "abstract": "When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems that adapt to disruptions by modifying their operation. We show conditions under which this balance can be achieved and introduce a practical algorithm to compute it, for which we derive approximation and generalization guarantees. We showcase the advantages of this resilient learning method in image classification tasks involving multiple potential invariances and in federated learning under distribution shift",
    "checked": true,
    "id": "75242305e5da89f683cc4af1415800e7102d666c",
    "semantic_title": "resilient constrained learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wa1GGPqjUn": {
    "title": "Online learning of long-range dependencies",
    "volume": "poster",
    "abstract": "Online learning holds the promise of enabling efficient long-term credit assignment in recurrent neural networks. However, current algorithms fall short of offline backpropagation by either not being scalable or failing to learn long-range dependencies. Here we present a high-performance online learning algorithm that merely doubles the memory and computational requirements of a single inference pass. We achieve this by leveraging independent recurrent modules in multi-layer networks, an architectural motif that has recently been shown to be particularly powerful. Experiments on synthetic memory problems and on the challenging long-range arena benchmark suite reveal that our algorithm performs competitively, establishing a new standard for what can be achieved through online learning. This ability to learn long-range dependencies offers a new perspective on learning in the brain and opens a promising avenue in neuromorphic computing",
    "checked": true,
    "id": "55d8837c72863e63259a506b56222d08812699b0",
    "semantic_title": "online learning of long-range dependencies",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=7qfkImn0dL": {
    "title": "ExPT: Synthetic Pretraining for Few-Shot Experimental Design",
    "volume": "poster",
    "abstract": "Experimental design is a fundamental problem in many science and engineering fields. In this problem, sample efficiency is crucial due to the time, money, and safety costs of real-world design evaluations. Existing approaches either rely on active data collection or access to large, labeled datasets of past experiments, making them impractical in many real-world scenarios. In this work, we address the more challenging yet realistic setting of few-shot experimental design, where only a few labeled data points of input designs and their corresponding values are available. We approach this problem as a conditional generation task, where a model conditions on a few labeled examples and the desired output to generate an optimal input design. To this end, we introduce Experiment Pretrained Transformers (ExPT), a foundation model for few-shot experimental design that employs a novel combination of synthetic pretraining with in-context learning. In ExPT, we only assume knowledge of a finite collection of unlabelled data points from the input domain and pretrain a transformer neural network to optimize diverse synthetic functions defined over this domain. Unsupervised pretraining allows ExPT to adapt to any design task at test time in an in-context fashion by conditioning on a few labeled data points from the target task and generating the candidate optima. We evaluate ExPT on few-shot experimental design in challenging domains and demonstrate its superior generality and performance compared to existing methods. The source code is available at https://github.com/tung-nd/ExPT.git",
    "checked": true,
    "id": "3d9c9848b5e21738c62b23b7684d39a5c191f473",
    "semantic_title": "expt: synthetic pretraining for few-shot experimental design",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1aQivXgZKj": {
    "title": "Incentivized Communication for Federated Bandits",
    "volume": "poster",
    "abstract": "Most existing works on federated bandits take it for granted that all clients are altruistic about sharing their data with the server for the collective good whenever needed. Despite their compelling theoretical guarantee on performance and communication efficiency, this assumption is overly idealistic and oftentimes violated in practice, especially when the algorithm is operated over self-interested clients, who are reluctant to share data without explicit benefits. Negligence of such self-interested behaviors can significantly affect the learning efficiency and even the practical operability of federated bandit learning. In light of this, we aim to spark new insights into this under-explored research area by formally introducing an incentivized communication problem for federated bandits, where the server shall motivate clients to share data by providing incentives. Without loss of generality, we instantiate this bandit problem with the contextual linear setting and propose the first incentivized communication protocol, namely, Inc-FedUCB, that achieves near-optimal regret with provable communication and incentive cost guarantees. Extensive empirical experiments on both synthetic and real-world datasets further validate the effectiveness of the proposed method across various environments",
    "checked": true,
    "id": "f9daa70353ba60d3fdb588d7cf4c604ab12f4d5e",
    "semantic_title": "incentivized communication for federated bandits",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=gUlcyeHzw1": {
    "title": "Learning Provably Robust Estimators for Inverse Problems via Jittering",
    "volume": "poster",
    "abstract": "Deep neural networks provide excellent performance for inverse problems such as denoising. However, neural networks can be sensitive to adversarial or worst-case perturbations. This raises the question of whether such networks can be trained efficiently to be worst-case robust. In this paper, we investigate whether jittering, a simple regularization technique that adds isotropic Gaussian noise during training, is effective for learning worst-case robust estimators for inverse problems. While well studied for prediction in classification tasks, the effectiveness of jittering for inverse problems has not been systematically investigated. In this paper, we present a novel analytical characterization of the optimal $\\ell_2$-worst-case robust estimator for linear denoising and show that jittering yields optimal robust denoisers. Furthermore, we examine jittering empirically via training deep neural networks (U-nets) for natural image denoising, deconvolution, and accelerated magnetic resonance imaging (MRI). The results show that jittering significantly enhances the worst-case robustness, but can be suboptimal for inverse problems beyond denoising. Moreover, our results imply that training on real data which often contains slight noise is somewhat robustness enhancing",
    "checked": true,
    "id": "63e3c1ad0cf5cdb512578d0a882047510023a6a8",
    "semantic_title": "learning provably robust estimators for inverse problems via jittering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4AQ4Fnemox": {
    "title": "On the Exploitability of Instruction Tuning",
    "volume": "poster",
    "abstract": "Instruction tuning is an effective technique to align large language models (LLMs) with human intent. In this work, we investigate how an adversary can exploit instruction tuning by injecting specific instruction-following examples into the training data that intentionally changes the model's behavior. For example, an adversary can achieve content injection by injecting training examples that mention target content and eliciting such behavior from downstream models. To achieve this goal, we propose \\textit{AutoPoison}, an automated data poisoning pipeline. It naturally and coherently incorporates versatile attack goals into poisoned data with the help of an oracle LLM. We showcase two example attacks: content injection and over-refusal attacks, each aiming to induce a specific exploitable behavior. We quantify and benchmark the strength and the stealthiness of our data poisoning scheme. Our results show that AutoPoison allows an adversary to change a model's behavior by poisoning only a small fraction of data while maintaining a high level of stealthiness in the poisoned examples. We hope our work sheds light on how data quality affects the behavior of instruction-tuned models and raises awareness of the importance of data quality for responsible deployments of LLMs",
    "checked": true,
    "id": "f5fa0b3c2ecbf17ba922932432bed46a1447ed23",
    "semantic_title": "on the exploitability of instruction tuning",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=jxhUNLoi4m": {
    "title": "Ess-InfoGAIL: Semi-supervised Imitation Learning from Imbalanced Demonstrations",
    "volume": "poster",
    "abstract": "Imitation learning aims to reproduce expert behaviors without relying on an explicit reward signal. However, real-world demonstrations often present challenges, such as multi-modal, data imbalance, and expensive labeling processes. In this work, we propose a novel semi-supervised imitation learning architecture that learns disentangled behavior representations from imbalanced demonstrations using limited labeled data. Specifically, our method consists of three key components. First, we adapt the concept of semi-supervised generative adversarial networks to the imitation learning context. Second, we employ a learnable latent distribution to align the generated and expert data distributions. Finally, we utilize a regularized information maximization approach in conjunction with an approximate label prior to further improve the semi-supervised learning performance. Experimental results demonstrate the efficiency of our method in learning multi-modal behaviors from imbalanced demonstrations compared to baseline methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YDCpf85eXc": {
    "title": "Finding Counterfactually Optimal Action Sequences in Continuous State Spaces",
    "volume": "poster",
    "abstract": "Whenever a clinician reflects on the efficacy of a sequence of treatment decisions for a patient, they may try to identify critical time steps where, had they made different decisions, the patient's health would have improved. While recent methods at the intersection of causal inference and reinforcement learning promise to aid human experts, as the clinician above, to *retrospectively* analyze sequential decision making processes, they have focused on environments with finitely many discrete states. However, in many practical applications, the state of the environment is inherently continuous in nature. In this paper, we aim to fill this gap. We start by formally characterizing a sequence of discrete actions and continuous states using finite horizon Markov decision processes and a broad class of bijective structural causal models. Building upon this characterization, we formalize the problem of finding counterfactually optimal action sequences and show that, in general, we cannot expect to solve it in polynomial time. Then, we develop a search method based on the A* algorithm that, under a natural form of Lipschitz continuity of the environment's dynamics, is guaranteed to return the optimal solution to the problem. Experiments on real clinical data show that our method is very efficient in practice, and it has the potential to offer interesting insights for sequential decision making tasks",
    "checked": true,
    "id": "ba24491c52f10ba705ae88dece4be7be058de0d4",
    "semantic_title": "finding counterfactually optimal action sequences in continuous state spaces",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=HoBbZ1vPAh": {
    "title": "Ensemble-based Deep Reinforcement Learning for Vehicle Routing Problems under Distribution Shift",
    "volume": "poster",
    "abstract": "While performing favourably on the independent and identically distributed (i.i.d.) instances, most of the existing neural methods for vehicle routing problems (VRPs) struggle to generalize in the presence of a distribution shift. To tackle this issue, we propose an ensemble-based deep reinforcement learning method for VRPs, which learns a group of diverse sub-policies to cope with various instance distributions. In particular, to prevent convergence of the parameters to the same one, we enforce diversity across sub-policies by leveraging Bootstrap with random initialization. Moreover, we also explicitly pursue inequality between sub-policies by exploiting regularization terms during training to further enhance diversity. Experimental results show that our method is able to outperform the state-of-the-art neural baselines on randomly generated instances of various distributions, and also generalizes favourably on the benchmark instances from TSPLib and CVRPLib, which confirmed the effectiveness of the whole method and the respective designs",
    "checked": false,
    "id": "0c811639ad04a8de8d2f1a06db2b48d648b3e7ab",
    "semantic_title": "deep reinforcement learning-based resource allocation for content distribution in iot-edge-cloud computing environments",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=SzYHu7EIwZ": {
    "title": "Precision-Recall Divergence Optimization for Generative Modeling with GANs and Normalizing Flows",
    "volume": "poster",
    "abstract": "Achieving a balance between image quality (precision) and diversity (recall) is a significant challenge in the domain of generative models. Current state-of-the-art models primarily rely on optimizing heuristics, such as the Fr\\'echet Inception Distance. While recent developments have introduced principled methods for evaluating precision and recall, they have yet to be successfully integrated into the training of generative models. Our main contribution is a novel training method for generative models, such as Generative Adversarial Networks and Normalizing Flows, which explicitly optimizes a user-defined trade-off between precision and recall. More precisely, we show that achieving a specified precision-recall trade-off corresponds to minimizing a unique $f$-divergence from a family we call the \\mbox{\\em PR-divergences}. Conversely, any $f$-divergence can be written as a linear combination of PR-divergences and corresponds to a weighted precision-recall trade-off. Through comprehensive evaluations, we show that our approach improves the performance of existing state-of-the-art models like BigGAN in terms of either precision or recall when tested on datasets such as ImageNet",
    "checked": true,
    "id": "c618c17c46ce9bac65cbbf192f802ca252faa00b",
    "semantic_title": "precision-recall divergence optimization for generative modeling with gans and normalizing flows",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NnXznLurw5": {
    "title": "Human spatiotemporal pattern learning as probabilistic program synthesis",
    "volume": "poster",
    "abstract": "People are adept at learning a wide variety of structured patterns from small amounts of data, presenting a conundrum from the standpoint of the bias-variance tradeoff: what kinds of representations and algorithms support the joint flexibility and data-paucity of human learning? One possibility is that people \"learn by programming\": inducing probabilistic models to fit observed data. Here, we experimentally test human learning in the domain of structured 2-dimensional patterns, using a task in which participants repeatedly predicted where a dot would move based on its previous trajectory. We evaluate human performance against standard parametric and non-parametric time-series models, as well as two Bayesian program synthesis models whose hypotheses vary in their degree of structure: a compositional Gaussian Process model and a structured \"Language of Thought\" (LoT) model. We find that signatures of human pattern learning are best explained by the LoT model, supporting the idea that the flexibility and data-efficiency of human structure learning can be understood as probabilistic inference over an expressive space of programs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N4JkStI1fe": {
    "title": "Neural Multi-Objective Combinatorial Optimization with Diversity Enhancement",
    "volume": "poster",
    "abstract": "Most of existing neural methods for multi-objective combinatorial optimization (MOCO) problems solely rely on decomposition, which often leads to repetitive solutions for the respective subproblems, thus a limited Pareto set. Beyond decomposition, we propose a novel neural heuristic with diversity enhancement (NHDE) to produce more Pareto solutions from two perspectives. On the one hand, to hinder duplicated solutions for different subproblems, we propose an indicator-enhanced deep reinforcement learning method to guide the model, and design a heterogeneous graph attention mechanism to capture the relations between the instance graph and the Pareto front graph. On the other hand, to excavate more solutions in the neighborhood of each subproblem, we present a multiple Pareto optima strategy to sample and preserve desirable solutions. Experimental results on classic MOCO problems show that our NHDE is able to generate a Pareto front with higher diversity, thereby achieving superior overall performance. Moreover, our NHDE is generic and can be applied to different neural methods for MOCO",
    "checked": true,
    "id": "50763c85f77ad3442e1af4f6e5966b30ed5b55af",
    "semantic_title": "neural multi-objective combinatorial optimization with diversity enhancement",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5eu00pcLWa": {
    "title": "Quantification of Uncertainty with Adversarial Models",
    "volume": "poster",
    "abstract": "Quantifying uncertainty is important for actionable predictions in real-world applications. A crucial part of predictive uncertainty quantification is the estimation of epistemic uncertainty, which is defined as an integral of the product between a divergence function and the posterior. Current methods such as Deep Ensembles or MC dropout underperform at estimating the epistemic uncertainty, since they primarily consider the posterior when sampling models. We suggest Quantification of Uncertainty with Adversarial Models (QUAM) to better estimate the epistemic uncertainty. QUAM identifies regions where the whole product under the integral is large, not just the posterior. Consequently, QUAM has lower approximation error of the epistemic uncertainty compared to previous methods. Models for which the product is large correspond to adversarial models (not adversarial examples!). Adversarial models have both a high posterior as well as a high divergence between their predictions and that of a reference model. Our experiments show that QUAM excels in capturing epistemic uncertainty for deep learning models and outperforms previous methods on challenging tasks in the vision domain",
    "checked": true,
    "id": "877fa88cdd5dddaa5007dd196d67d5ab170ced61",
    "semantic_title": "quantification of uncertainty with adversarial models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=W23ZTdsabj": {
    "title": "Are Vision Transformers More Data Hungry Than Newborn Visual Systems?",
    "volume": "poster",
    "abstract": "Vision transformers (ViTs) are top-performing models on many computer vision benchmarks and can accurately predict human behavior on object recognition tasks. However, researchers question the value of using ViTs as models of biological learning because ViTs are thought to be more \"data hungry\" than brains, with ViTs requiring more training data than brains to reach similar levels of performance. To test this assumption, we directly compared the learning abilities of ViTs and animals, by performing parallel controlled-rearing experiments on ViTs and newborn chicks. We first raised chicks in impoverished visual environments containing a single object, then simulated the training data available in those environments by building virtual animal chambers in a video game engine. We recorded the first-person images acquired by agents moving through the virtual chambers and used those images to train self-supervised ViTs that leverage time as a teaching signal, akin to biological visual systems. When ViTs were trained \"through the eyes\" of newborn chicks, the ViTs solved the same view-invariant object recognition tasks as the chicks. Thus, ViTs were not more data hungry than newborn chicks: both learned view-invariant object representations in impoverished visual environments. The flexible and generic attention-based learning mechanism in ViTs—combined with the embodied data streams available to newborn animals—appears sufficient to drive the development of animal-like object recognition",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YE04aRkeZb": {
    "title": "$\\textbf{A}^2\\textbf{CiD}^2$: Accelerating Asynchronous Communication in Decentralized Deep Learning",
    "volume": "poster",
    "abstract": "Distributed training of Deep Learning models has been critical to many recent successes in the field. Current standard methods primarily rely on synchronous centralized algorithms which induce major communication bottlenecks and synchronization locks at scale. Decentralized asynchronous algorithms are emerging as a potential alternative but their practical applicability still lags. In order to mitigate the increase in communication cost that naturally comes with scaling the number of workers, we introduce a principled asynchronous, randomized, gossip-based optimization algorithm which works thanks to a continuous local momentum named $\\textbf{A}^2\\textbf{CiD}^2$. Our method allows each worker to continuously process mini-batches without stopping, and run a peer-to-peer averaging routine in parallel, reducing idle time. In addition to inducing a significant communication acceleration at no cost other than adding a local momentum variable, minimal adaptation is required to incorporate $\\textbf{A}^2\\textbf{CiD}^2$ to standard asynchronous approaches. Our theoretical analysis proves accelerated rates compared to previous asynchronous decentralized baselines and we empirically show that using our $\\textbf{A}^2\\textbf{CiD}^2$ momentum significantly decrease communication costs in poorly connected networks. In particular, we show consistent improvement on the ImageNet dataset using up to 64 asynchronous workers (A100 GPUs) and various communication network topologies",
    "checked": false,
    "id": "91350630040c35a7ae2ff1ff552d79e11cd8d23e",
    "semantic_title": "a2cid2: accelerating asynchronous communication in decentralized deep learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Gij638d76O": {
    "title": "Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization",
    "volume": "poster",
    "abstract": "Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce an initial attempt to search for a latent geometry composed of a product of constant curvature model spaces with a small number of query evaluations, under some simplifying assumptions. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Hausdorff distance, we introduce a mapping function that enables the comparison of different manifolds by embedding them in a common high-dimensional ambient space. We then design a graph search space based on the notion of smoothness between latent geometries and employ the calculated distances as an additional inductive bias. Finally, we use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This is a general method which can be applied to search for the optimal latent geometry for a variety of models and downstream tasks. We perform experiments on synthetic and real-world datasets to identify the optimal latent geometry for multiple machine learning problems",
    "checked": true,
    "id": "09171af9470de221b2d8468d5c926c4b97a5b844",
    "semantic_title": "neural latent geometry search: product manifold inference via gromov-hausdorff-informed bayesian optimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=VacSQpbI0U": {
    "title": "Correlation Aware Sparsified Mean Estimation Using Random Projection",
    "volume": "poster",
    "abstract": "We study the problem of communication-efficient distributed vector mean estimation, which is a commonly used subroutine in distributed optimization and Federated Learning (FL). Rand-$k$ sparsification is a commonly used technique to reduce communication cost, where each client sends $k < d$ of its coordinates to the server. However, Rand-$k$ is agnostic to any correlations, that might exist between clients in practical scenarios. The recently proposed Rand-$k$-Spatial estimator leverages the cross-client correlation information at the server to improve Rand-$k$'s performance. Yet, the performance of Rand-$k$-Spatial is suboptimal, and improving mean estimation is key to a faster convergence in distributed optimization. We propose the Rand-Proj-Spatial estimator with a more flexible encoding-decoding procedure, which generalizes the encoding of Rand-$k$ by projecting the client vectors to a random $k$-dimensional subspace. We utilize Subsampled Randomized Hadamard Transform (SRHT) as the projection matrix, and show that Rand-Proj-Spatial with SRHT outperforms Rand-$k$-Spatial, using the correlation information more efficiently. Furthermore, we propose an approach to incorporate varying degrees of correlation, and suggest a practical variant of Rand-Proj-Spatial when the correlation information is not available to the server. Finally, experiments on real-world distributed optimization tasks showcase the superior performance of Rand-Proj-Spatial compared to Rand-$k$-Spatial and other more sophisticated sparsification techniques",
    "checked": true,
    "id": "6d63de399a959197aaf214050acbfc549d0eac24",
    "semantic_title": "correlation aware sparsified mean estimation using random projection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8bQc7oRnjm": {
    "title": "Provably Efficient Offline Reinforcement Learning in Regular Decision Processes",
    "volume": "poster",
    "abstract": "This paper deals with offline (or batch) Reinforcement Learning (RL) in episodic Regular Decision Processes (RDPs). RDPs are the subclass of Non-Markov Decision Processes where the dependency on the history of past events can be captured by a finite-state automaton. We consider a setting where the automaton that underlies the RDP is unknown, and a learner strives to learn a near-optimal policy using pre-collected data, in the form of non-Markov sequences of observations, without further exploration. We present RegORL, an algorithm that suitably combines automata learning techniques and state-of-the-art algorithms for offline RL in MDPs. RegORL has a modular design allowing one to use any off-the-shelf offline RL algorithm in MDPs. We report a non-asymptotic high-probability sample complexity bound for RegORL to yield an $\\varepsilon$-optimal policy, which makes appear a notion of concentrability relevant for RDPs. Furthermore, we present a sample complexity lower bound for offline RL in RDPs. To our best knowledge, this is the first work presenting a provably efficient algorithm for offline learning in RDPs",
    "checked": false,
    "id": "846661f07ac35af98674a57ccf524255fec6ed17",
    "semantic_title": "provably efficient offline reinforcement learning for partially observable markov decision processes",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=46x3zvYCyQ": {
    "title": "Zeroth-Order Methods for Nondifferentiable, Nonconvex, and Hierarchical Federated Optimization",
    "volume": "poster",
    "abstract": "Federated learning (FL) has emerged as an enabling framework for communication-efficient decentralized training. We study three broadly applicable problem classes in FL: (i) Nondifferentiable nonconvex optimization; (ii) Federated bilevel optimization; (iii) Federated minimax problems. Notably, in an implicit sense, both (ii) and (iii) are instances of (i). However, these hierarchical problems are often complicated by the absence of a closed-form expression for the implicit objective function. Unfortunately, research on these problems has been limited and afflicted by reliance on strong assumptions, including the need for differentiability and L-smoothness of the implicit function. We address this shortcoming by making the following contributions. In (i), by leveraging convolution-based smoothing and Clarke's subdifferential calculus, we devise a randomized smoothing-enabled zeroth-order FL method and derive communication and iteration complexity guarantees for computing an approximate Clarke stationary point. To contend with (ii) and (iii), we devise a unifying randomized implicit zeroth-order FL framework, equipped with explicit communication and iteration complexities. Importantly, our method utilizes delays during local steps to skip calling the inexact lower-level FL oracle. This results in significant reduction in communication overhead when addressing hierarchical problems. We empirically validate the theory on nonsmooth and hierarchical ML problems",
    "checked": true,
    "id": "a92567fea82cae650bf21fc9986641b94244947a",
    "semantic_title": "zeroth-order methods for nondifferentiable, nonconvex, and hierarchical federated optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IEMLNF4gK4": {
    "title": "SHAP-IQ: Unified Approximation of any-order Shapley Interactions",
    "volume": "poster",
    "abstract": "Predominately in explainable artificial intelligence (XAI) research, the Shapley value (SV) is applied to determine feature attributions for any black box model. Shapley interaction indices extend the SV to define any-order feature interactions. Defining a unique Shapley interaction index is an open research question and, so far, three definitions have been proposed, which differ by their choice of axioms. Moreover, each definition requires a specific approximation technique. Here, we propose SHAPley Interaction Quantification (SHAP-IQ), an efficient sampling-based approximator to compute Shapley interactions for arbitrary cardinal interaction indices (CII), i.e. interaction indices that satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a novel representation and, in contrast to existing methods, we provide theoretical guarantees for its approximation quality, as well as estimates for the variance of the point estimates. For the special case of SV, our approach reveals a novel representation of the SV and corresponds to Unbiased KernelSHAP with a greatly simplified calculation. We illustrate the computational efficiency and effectiveness by explaining language, image classification and high-dimensional synthetic models",
    "checked": true,
    "id": "a7f2d57b18a93577b86f687794ff8b32662514c3",
    "semantic_title": "shap-iq: unified approximation of any-order shapley interactions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=DoE3esTIEM": {
    "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations",
    "volume": "poster",
    "abstract": "Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that \\textit{CPI} overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, \\textit{CPI} consistently showed top accuracy across benchmarks. An experiment on real-world data analysis in a large-scale medical dataset showed that \\textit{CPI} provides a more parsimonious selection of statistically significant variables. Our results suggest that \\textit{CPI} can be readily used as drop-in replacement for permutation-based methods",
    "checked": true,
    "id": "402411672a4dd618f3f88b18cbbee8873637a2f1",
    "semantic_title": "statistically valid variable importance assessment through conditional permutations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fAdMly4ki5": {
    "title": "Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning",
    "volume": "poster",
    "abstract": "Diffusion models have demonstrated highly-expressive generative capabilities in vision and NLP. Recent studies in reinforcement learning (RL) have shown that diffusion models are also powerful in modeling complex policies or trajectories in offline datasets. However, these works have been limited to single-task settings where a generalist agent capable of addressing multi-task predicaments is absent. In this paper, we aim to investigate the effectiveness of a single diffusion model in modeling large-scale multi-task offline data, which can be challenging due to diverse and multimodal data distribution. Specifically, we propose Multi-Task Diffusion Model (\\textsc{MTDiff}), a diffusion-based method that incorporates Transformer backbones and prompt learning for generative planning and data synthesis in multi-task offline settings. \\textsc{MTDiff} leverages vast amounts of knowledge available in multi-task data and performs implicit knowledge sharing among tasks. For generative planning, we find \\textsc{MTDiff} outperforms state-of-the-art algorithms across 50 tasks on Meta-World and 8 maps on Maze2D. For data synthesis, \\textsc{MTDiff} generates high-quality data for testing tasks given a single demonstration as a prompt, which enhances the low-quality datasets for even unseen tasks",
    "checked": true,
    "id": "828e27fd4fcd5e8982032b903950947b12afb6bb",
    "semantic_title": "diffusion model is an effective planner and data synthesizer for multi-task reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=UBUWFEwn7p": {
    "title": "Time Series Kernels based on Nonlinear Vector AutoRegressive Delay Embeddings",
    "volume": "poster",
    "abstract": "Kernel design is a pivotal but challenging aspect of time series analysis, especially in the context of small datasets. In recent years, Reservoir Computing (RC) has emerged as a powerful tool to compare time series based on the underlying dynamics of the generating process rather than the observed data. However, the performance of RC highly depends on the hyperparameter setting, which is hard to interpret and costly to optimize because of the recurrent nature of RC. Here, we present a new kernel for time series based on the recently established equivalence between reservoir dynamics and Nonlinear Vector AutoRegressive (NVAR) processes. The kernel is non-recurrent and depends on a small set of meaningful hyperparameters, for which we suggest an effective heuristic. We demonstrate excellent performance on a wide range of real-world classification tasks, both in terms of accuracy and speed. This further advances the understanding of RC representation learning models and extends the typical use of the NVAR framework to kernel design and representation of real-world time series data",
    "checked": false,
    "id": "0c3c6dd344ee85dda495a9f7ebf377a2d97527fa",
    "semantic_title": "analysis of chaotic time series with dynamic noise",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TRuqrVsmZK": {
    "title": "BayesTune: Bayesian Sparse Deep Model Fine-tuning",
    "volume": "poster",
    "abstract": "Deep learning practice is increasingly driven by powerful foundation models (FM), pre-trained at scale and then fine-tuned for specific tasks of interest. A key property of this workflow is the efficacy of performing sparse or parameter-efficient fine-tuning, meaning that by updating only a tiny fraction of the whole FM parameters on a downstream task can lead to surprisingly good performance, often even superior to a full model update. However, it is not clear what is the optimal and principled way to select which parameters to update. Although a growing number of sparse fine-tuning ideas have been proposed, they are mostly not satisfactory, relying on hand-crafted heuristics or heavy approximation. In this paper we propose a novel Bayesian sparse fine-tuning algorithm: we place a (sparse) Laplace prior for each parameter of the FM, with the mean equal to the initial value and the scale parameter having a hyper-prior that encourages small scale. Roughly speaking, the posterior means of the scale parameters indicate how important it is to update the corresponding parameter away from its initial value when solving the downstream task. Given the sparse prior, most scale parameters are small a posteriori, and the few large-valued scale parameters identify those FM parameters that crucially need to be updated away from their initial values. Based on this, we can threshold the scale parameters to decide which parameters to update or freeze, leading to a principled sparse fine-tuning strategy. To efficiently infer the posterior distribution of the scale parameters, we adopt the Langevin MCMC sampler, requiring only two times the complexity of the vanilla SGD. Tested on popular NLP benchmarks as well as the VTAB vision tasks, our approach shows significant improvement over the state-of-the-arts (e.g., 1% point higher than the best SOTA when fine-tuning RoBERTa for GLUE and SuperGLUE benchmarks)",
    "checked": false,
    "id": "efaf62aee9275b514b1c6c97c14933206ddb8549",
    "semantic_title": "bayesian robust tensor ring model for incomplete multiway data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1tviRBNxI9": {
    "title": "Topological Obstructions and How to Avoid Them",
    "volume": "poster",
    "abstract": "Incorporating geometric inductive biases into models can aid interpretability and generalization, but encoding to a specific geometric structure can be challenging due to the imposed topological constraints. In this paper, we theoretically and empirically characterize obstructions to training encoders with geometric latent spaces. We show that local optima can arise due to singularities (e.g. self-intersection) or due to an incorrect degree or winding number. We then discuss how normalizing flows can potentially circumvent these obstructions by defining multimodal variational distributions. Inspired by this observation, we propose a new flow-based model that maps data points to multimodal distributions over geometric spaces and empirically evaluate our model on 2 domains. We observe improved stability during training and a higher chance of converging to a homeomorphic encoder",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D8nAMRRCLS": {
    "title": "On Transfer of Adversarial Robustness from Pretraining to Downstream Tasks",
    "volume": "poster",
    "abstract": "As large-scale training regimes have gained popularity, the use of pretrained models for downstream tasks has become common practice in machine learning. While pretraining has been shown to enhance the performance of models in practice, the transfer of robustness properties from pretraining to downstream tasks remains poorly understood. In this study, we demonstrate that the robustness of a linear predictor on downstream tasks can be constrained by the robustness of its underlying representation, regardless of the protocol used for pretraining. We prove (i) a bound on the loss that holds independent of any downstream task, as well as (ii) a criterion for robust classification in particular. We validate our theoretical results in practical applications, show how our results can be used for calibrating expectations of downstream robustness, and when our results are useful for optimal transfer learning. Taken together, our results offer an initial step towards characterizing the requirements of the representation function for reliable post-adaptation performance",
    "checked": true,
    "id": "9c0128f196c1000530a917a074881fc829480e4c",
    "semantic_title": "on transfer of adversarial robustness from pretraining to downstream tasks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jze2r6RDFz": {
    "title": "Generalized test utilities for long-tail performance in extreme multi-label classification",
    "volume": "poster",
    "abstract": "Extreme multi-label classification (XMLC) is a task of selecting a small subset of relevant labels from a very large set of possible labels. As such, it is characterized by long-tail labels, i.e., most labels have very few positive instances. With standard performance measures such as precision@k, a classifier can ignore tail labels and still report good performance. However, it is often argued that correct predictions in the tail are more \"interesting\" or \"rewarding,\" but the community has not yet settled on a metric capturing this intuitive concept. The existing propensity-scored metrics fall short on this goal by confounding the problems of long-tail and missing labels. In this paper, we analyze generalized metrics budgeted \"at k\" as an alternative solution. To tackle the challenging problem of optimizing these metrics, we formulate it in the \\emph{expected test utility} (ETU) framework, which aims at optimizing the expected performance on a given test set. We derive optimal prediction rules and construct their computationally efficient approximations with provable regret guarantees and being robust against model misspecification. Our algorithm, based on block coordinate descent, scales effortlessly to XMLC problems and obtains promising results in terms of long-tail performance",
    "checked": true,
    "id": "be065913eff790a4600f1dd9ba98ec04ee32dac5",
    "semantic_title": "generalized test utilities for long-tail performance in extreme multi-label classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rzDBoh1tBh": {
    "title": "Private Federated Frequency Estimation: Adapting to the Hardness of the Instance",
    "volume": "poster",
    "abstract": "In federated frequency estimation (FFE), multiple clients work together to estimate the frequency of their local data by communicating with a server, while maintaining the security constraint of $\\mathtt{secsum}$ where the server can only access the sum of client-held vectors. For FFE with a single communication round, it is known that count sketch is nearly information-theoretically optimal [Chen et al., 2022]. However, when multiple communication rounds are allowed, we propose a new sketch algorithm that is provably more accurate than a naive adaptation of count sketch. Furthermore, we show that both our sketch algorithm and count sketch can achieve better accuracy when the problem instance is simpler. Therefore, we propose a two-phase approach to enable the use of a smaller sketch size for simpler problems. Finally, we provide mechanisms to make our proposed algorithm differentially private. We verify the performance of our methods through experiments conducted on real datasets",
    "checked": true,
    "id": "25d5a53456282aad4e096f67847008f3d042f37c",
    "semantic_title": "private federated frequency estimation: adapting to the hardness of the instance",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=IwyymRXfzL": {
    "title": "Perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning",
    "volume": "poster",
    "abstract": "We introduce a new type of query mechanism for collecting human feedback, called the perceptual adjustment query (PAQ). Being both informative and cognitively lightweight, the PAQ adopts an inverted measurement scheme, and combines advantages from both cardinal and ordinal queries. We showcase the PAQ in the metric learning problem, where we collect PAQ measurements to learn an unknown Mahalanobis distance. This gives rise to a high-dimensional, low-rank matrix estimation problem to which standard matrix estimators cannot be applied. Consequently, we develop a two-stage estimator for metric learning from PAQs, and provide sample complexity guarantees for this estimator. We present numerical simulations demonstrating the performance of the estimator and its notable properties",
    "checked": true,
    "id": "a7cc93456eba6437be5419161f37ea847ec8aa04",
    "semantic_title": "perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eBXM62SqKY": {
    "title": "POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images",
    "volume": "poster",
    "abstract": "We describe an approach to predict open-vocabulary 3D semantic voxel occupancy map from input 2D images with the objective of enabling 3D grounding, segmentation and retrieval of free-form language queries. This is a challenging problem because of the 2D-3D ambiguity and the open-vocabulary nature of the target tasks, where obtaining annotated training data in 3D is difficult. The contributions of this work are three-fold. First, we design a new model architecture for open-vocabulary 3D semantic occupancy prediction. The architecture consists of a 2D-3D encoder together with occupancy prediction and 3D-language heads. The output is a dense voxel map of 3D grounded language embeddings enabling a range of open-vocabulary tasks. Second, we develop a tri-modal self-supervised learning algorithm that leverages three modalities: (i) images, (ii) language and (iii) LiDAR point clouds, and enables training the proposed architecture using a strong pre-trained vision-language model without the need for any 3D manual language annotations. Finally, we demonstrate quantitatively the strengths of the proposed model on several open-vocabulary tasks: Zero-shot 3D semantic segmentation using existing datasets; 3D grounding and retrieval of free-form language queries, using a small dataset that we propose as an extension of nuScenes",
    "checked": false,
    "id": "9fc4144cd2d1511a29da3cf0b7ce1c3cc36b453e",
    "semantic_title": "ovo: open-vocabulary occupancy",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Ehzj9F2Kmj": {
    "title": "Generative Modelling of Stochastic Actions with Arbitrary Constraints in Reinforcement Learning",
    "volume": "poster",
    "abstract": "Many problems in Reinforcement Learning (RL) seek an optimal policy with large discrete multidimensional yet unordered action spaces; these include problems in randomized allocation of resources such as placements of multiple security resources and emergency response units, etc. A challenge in this setting is that the underlying action space is categorical (discrete and unordered) and large, for which existing RL methods do not perform well. Moreover, these problems require validity of the realized action (allocation); this validity constraint is often difficult to express compactly in a closed mathematical form. The allocation nature of the problem also prefers stochastic optimal policies, if one exists. In this work, we address these challenges by (1) applying a (state) conditional normalizing flow to compactly represent the stochastic policy — the compactness arises due to the network only producing one sampled action and the corresponding log probability of the action, which is then used by an actor-critic method; and (2) employing an invalid action rejection method (via a valid action oracle) to update the base policy. The action rejection is enabled by a modified policy gradient that we derive. Finally, we conduct extensive experiments to show the scalability of our approach compared to prior methods and the ability to enforce arbitrary state-conditional constraints on the support of the distribution of actions in any state",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8fLatmFQgF": {
    "title": "Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent",
    "volume": "poster",
    "abstract": "Algorithmic stability is an important notion that has proven powerful for deriving generalization bounds for practical algorithms. The last decade has witnessed an increasing number of stability bounds for different algorithms applied on different classes of loss functions. While these bounds have illuminated various properties of optimization algorithms, the analysis of each case typically required a different proof technique with significantly different mathematical tools. In this study, we make a novel connection between learning theory and applied probability and introduce a unified guideline for proving Wasserstein stability bounds for stochastic optimization algorithms. We illustrate our approach on stochastic gradient descent (SGD) and we obtain time-uniform stability bounds (i.e., the bound does not increase with the number of iterations) for strongly convex losses and non-convex losses with additive noise, where we recover similar results to the prior art or extend them to more general cases by using a single proof technique. Our approach is flexible and can be generalizable to other popular optimizers, as it mainly requires developing Lyapunov functions, which are often readily available in the literature. It also illustrates that ergodicity is an important component for obtaining time-uniform bounds -- which might not be achieved for convex or non-convex losses unless additional noise is injected to the iterates. Finally, we slightly stretch our analysis technique and prove time-uniform bounds for SGD under convex and non-convex losses (without additional additive noise), which, to our knowledge, is novel",
    "checked": true,
    "id": "a05ed14804f09bdc2df7f005978a0543fb5174f4",
    "semantic_title": "uniform-in-time wasserstein stability bounds for (noisy) stochastic gradient descent",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=2hQ7MBQApp": {
    "title": "What is the Inductive Bias of Flatness Regularization? A Study of Deep Matrix Factorization Models",
    "volume": "poster",
    "abstract": "Recent works on over-parameterized neural networks have shown that the stochasticity in optimizers has the implicit regularization effect of minimizing the sharpness of the loss function (in particular, the trace of its Hessian) over the family zero-loss solutions. More explicit forms of flatness regularization also empirically improve the generalization performance. However, it remains unclear why and when flatness regularization leads to better generalization. This work takes the first step towards understanding the inductive bias of the minimum trace of the Hessian solutions in an important setting: learning deep linear networks from linear measurements, also known as \\emph{deep matrix factorization}. We show that with the standard Restricted Isometry Property (RIP) on the measurements, minimizing the trace of Hessian is approximately equivalent to minimizing the Schatten 1-norm of the corresponding end-to-end matrix parameters (i.e., the product of all layer matrices), which in turn leads to better generalization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z57JrmubNl": {
    "title": "Tree-Rings Watermarks: Invisible Fingerprints for Diffusion Images",
    "volume": "poster",
    "abstract": "Watermarking the outputs of generative models is a crucial technique for tracing copyright and preventing potential harm from AI-generated content. In this paper, we introduce a novel technique called Tree-Ring Watermarking that robustly fingerprints diffusion model outputs. Unlike existing methods that perform post-hoc modifications to images after sampling, Tree-Ring Watermarking subtly influences the entire sampling process, resulting in a model fingerprint that is invisible to humans. The watermark embeds a pattern into the initial noise vector used for sampling. These patterns are structured in Fourier space so that they are invariant to convolutions, crops, dilations, flips, and rotations. After image generation, the watermark signal is detected by inverting the diffusion process to retrieve the noise vector, which is then checked for the embedded signal. We demonstrate that this technique can be easily applied to arbitrary diffusion models, including text-conditioned Stable Diffusion, as a plug-in with negligible loss in FID. Our watermark is semantically hidden in the image space and is far more robust than watermarking alternatives that are currently deployed",
    "checked": false,
    "id": "f653569b131176dfed8842694b5ad2ead5e4b923",
    "semantic_title": "tree-ring watermarks: fingerprints for diffusion images that are invisible and robust",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=d1knqWjmNt": {
    "title": "Optimality of Message-Passing Architectures for Sparse Graphs",
    "volume": "poster",
    "abstract": "We study the node classification problem on feature-decorated graphs in the sparse setting, i.e., when the expected degree of a node is $O(1)$ in the number of nodes, in the fixed-dimensional asymptotic regime, i.e., the dimension of the feature data is fixed while the number of nodes is large. Such graphs are typically known to be locally tree-like. We introduce a notion of Bayes optimality for node classification tasks, called asymptotic local Bayes optimality, and compute the optimal classifier according to this criterion for a fairly general statistical data model with arbitrary distributions of the node features and edge connectivity. The optimal classifier is implementable using a message-passing graph neural network architecture. We then compute the generalization error of this classifier and compare its performance against existing learning methods theoretically on a well-studied statistical model with naturally identifiable signal-to-noise ratios (SNRs) in the data. We find that the optimal message-passing architecture interpolates between a standard MLP in the regime of low graph signal and a typical convolution in the regime of high graph signal. Furthermore, we prove a corresponding non-asymptotic result",
    "checked": true,
    "id": "6fe6e17352b26402c3dafdb84bd289672109806a",
    "semantic_title": "optimality of message-passing architectures for sparse graphs",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=qHzEFxtheD": {
    "title": "Sketching Algorithms for Sparse Dictionary Learning: PTAS and Turnstile Streaming",
    "volume": "poster",
    "abstract": "Sketching algorithms have recently proven to be a powerful approach both for designing low-space streaming algorithms as well as fast polynomial time approximation schemes (PTAS). In this work, we develop new techniques to extend the applicability of sketching-based approaches to the sparse dictionary learning and the Euclidean $k$-means clustering problems. In particular, we initiate the study of the challenging setting where the dictionary/clustering assignment for each of the $n$ input points must be output, which has surprisingly received little attention in prior work. On the fast algorithms front, we obtain a new approach for designing PTAS's for the $k$-means clustering problem, which generalizes to the first PTAS for the sparse dictionary learning problem. On the streaming algorithms front, we obtain new upper bounds and lower bounds for dictionary learning and $k$-means clustering. In particular, given a design matrix $\\mathbf A\\in\\mathbb R^{n\\times d}$ in a turnstile stream, we show an $\\tilde O(nr/\\epsilon^2 + dk/\\epsilon)$ space upper bound for $r$-sparse dictionary learning of size $k$, an $\\tilde O(n/\\epsilon^2 + dk/\\epsilon)$ space upper bound for $k$-means clustering, as well as an $\\tilde O(n)$ space upper bound for $k$-means clustering on random order row insertion streams with a natural \"bounded sensitivity\" assumption. On the lower bounds side, we obtain a general $\\tilde\\Omega(n/\\epsilon + dk/\\epsilon)$ lower bound for $k$-means clustering, as well as an $\\tilde\\Omega(n/\\epsilon^2)$ lower bound for algorithms which can estimate the cost of a single fixed set of candidate centers",
    "checked": true,
    "id": "ba6a645b6053c3d2b16794d5bfa0cf80dc94b45a",
    "semantic_title": "sketching algorithms for sparse dictionary learning: ptas and turnstile streaming",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uTlKUAm68H": {
    "title": "Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception",
    "volume": "poster",
    "abstract": "We present Integrated Multimodal Perception (IMP), a simple and scalable multimodal multi-task training and modeling approach. IMP integrates multimodal inputs including image, video, text, and audio into a single Transformer encoder with minimal modality-specific components. IMP makes use of a novel design that combines Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficient model & task scaling. We conduct extensive empirical studies and reveal the following key insights: 1) performing gradient descent updates by alternating on diverse modalities, loss functions, and tasks, with varying input resolutions, efficiently improves the model. 2) sparsification with MoE on a single modality-agnostic encoder substantially improves the performance, outperforming dense models that use modality-specific encoders or additional fusion layers and greatly mitigating the conflicts between modalities. IMP achieves competitive performance on a wide range of downstream tasks including video classification, image classification, image-text, and video-text retrieval. Most notably, we train a sparse IMP-MoE-L focusing on video tasks that achieves new state-of-the-art in zero-shot video classification: 77.0% on Kinetics-400, 76.8% on Kinetics-600, and 68.3% on Kinetics-700, improving the previous state-of-the-art by +5%, +6.7%, and +5.8%, respectively, while using only 15% of their total training computational cost",
    "checked": true,
    "id": "8d3cc62fbe79b280a9084a43b295a4c77f7092ad",
    "semantic_title": "alternating gradient descent and mixture-of-experts for integrated multimodal perception",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qieeNlO3C7": {
    "title": "Transformers learn through gradual rank increase",
    "volume": "poster",
    "abstract": "We identify incremental learning dynamics in transformers, where the difference between trained and initial weights progressively increases in rank. We rigorously prove this occurs under the simplifying assumptions of diagonal weight matrices and small initialization. Our experiments support the theory and also show that phenomenon can occur in practice without the simplifying assumptions",
    "checked": true,
    "id": "194a048814acc5cd5a9ee08102df3dcb61b2dfc9",
    "semantic_title": "transformers learn through gradual rank increase",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=7eW6NzSE4g": {
    "title": "Information Maximizing Curriculum: A Curriculum-Based Approach for Learning Versatile Skills",
    "volume": "poster",
    "abstract": "Imitation learning uses data for training policies to solve complex tasks. However, when the training data is collected from human demonstrators, it often leads to multimodal distributions because of the variability in human actions. Most imitation learning methods rely on a maximum likelihood (ML) objective to learn a parameterized policy, but this can result in suboptimal or unsafe behavior due to the mode-averaging property of the ML objective. In this work, we propose Information Maximizing Curriculum, a curriculum-based approach that assigns a weight to each data point and encourages the model to specialize in the data it can represent, effectively mitigating the mode-averaging problem by allowing the model to ignore data from modes it cannot represent. To cover all modes and thus, enable versatile behavior, we extend our approach to a mixture of experts (MoE) policy, where each mixture component selects its own subset of the training data for learning. A novel, maximum entropy-based objective is proposed to achieve full coverage of the dataset, thereby enabling the policy to encompass all modes within the data distribution. We demonstrate the effectiveness of our approach on complex simulated control tasks using versatile human demonstrations, achieving superior performance compared to state-of-the-art methods",
    "checked": false,
    "id": "26d062c67ad616413ab23b51248e28cf04a59cb1",
    "semantic_title": "information maximizing curriculum: a curriculum-based approach for imitating diverse skills",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Itorzn4Kwf": {
    "title": "Accelerating Exploration with Unlabeled Prior Data",
    "volume": "poster",
    "abstract": "Learning to solve tasks from a sparse reward signal is a major challenge for standard reinforcement learning (RL) algorithms. However, in the real world, agents rarely need to solve sparse reward tasks entirely from scratch. More often, we might possess prior experience to draw on that provides considerable guidance about which actions and outcomes are possible in the world, which we can use to explore more effectively for new tasks. In this work, we study how prior data without reward labels may be used to guide and accelerate exploration for an agent solving a new sparse reward task. We propose a simple approach that learns a reward model from online experience, labels the unlabeled prior data with optimistic rewards, and then uses it concurrently alongside the online data for downstream policy and critic optimization. This general formula leads to rapid exploration in several challenging sparse-reward domains where tabula rasa exploration is insufficient, including the AntMaze domain, Adroit hand manipulation domain, and a visual simulated robotic manipulation domain. Our results highlight the ease of incorporating unlabeled prior data into existing online RL algorithms, and the (perhaps surprising) effectiveness of doing so",
    "checked": true,
    "id": "05603c65d813105eb136e867abfc412ea1735cf0",
    "semantic_title": "accelerating exploration with unlabeled prior data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e5srDjF9l7": {
    "title": "Accessing Higher Dimensions for Unsupervised Word Translation",
    "volume": "poster",
    "abstract": "The striking ability of unsupervised word translation has been demonstrated recently with the help of low-dimensional word vectors / pretraining, which is used by all successful methods and assumed to be necessary. We test and challenge this assumption by developing a method that can also make use of high dimensional signal. Freed from the limits of low dimensions, we show that relying on low-dimensional vectors and their incidental properties miss out on better denoising methods and signals in high dimensions, thus stunting the potential of the data. Our results show that unsupervised translation can be achieved more easily and robustly than previously thought -- less than 80MB and minutes of CPU time is required to achieve over 50\\% accuracy for English to Finnish, Hungarian, and Chinese translations when trained in the same domain; even under domain mismatch, the method still works fully unsupervised on English NewsCrawl to Chinese Wikipedia and English Europarl to Spanish Wikipedia, among others. These results challenge prevailing assumptions on the necessity and superiority of low-dimensional vectors and show that the higher dimension signal can be used rather than thrown away",
    "checked": true,
    "id": "00562c28308864e52e0e4070895cd93c63c589a4",
    "semantic_title": "accessing higher dimensions for unsupervised word translation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jnCPN1vpSR": {
    "title": "D-CIPHER: Discovery of Closed-form Partial Differential Equations",
    "volume": "poster",
    "abstract": "Closed-form differential equations, including partial differential equations and higher-order ordinary differential equations, are one of the most important tools used by scientists to model and better understand natural phenomena. Discovering these equations directly from data is challenging because it requires modeling relationships between various derivatives that are not observed in the data (equation-data mismatch) and it involves searching across a huge space of possible equations. Current approaches make strong assumptions about the form of the equation and thus fail to discover many well-known phenomena. Moreover, many of them resolve the equation-data mismatch by estimating the derivatives, which makes them inadequate for noisy and infrequent observations. To this end, we propose D-CIPHER, which is robust to measurement artifacts and can uncover a new and very general class of differential equations. We further design a novel optimization procedure, CoLLie, to help D-CIPHER search through this class efficiently. Finally, we demonstrate empirically that it can discover many well-known equations that are beyond the capabilities of current methods",
    "checked": true,
    "id": "5334f19bc51d526e1a2532e332185da818958288",
    "semantic_title": "d-cipher: discovery of closed-form partial differential equations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VOstHxDdsN": {
    "title": "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery",
    "volume": "poster",
    "abstract": "The strength of modern generative models lies in their ability to be controlled through prompts. Hard prompts comprise interpretable words and tokens, and are typically hand-crafted by humans. Soft prompts, on the other hand, consist of continuous feature vectors. These can be discovered using powerful optimization methods, but they cannot be easily edited, re-used across models, or plugged into a text-based interface. We describe an easy-to-use approach to automatically optimize hard text prompts through efficient gradient-based optimization. Our approach can be readily applied to text-to-image and text-only applications alike. This method allows API users to easily generate, discover, and mix and match image concepts without prior knowledge of how to prompt the model. Furthermore, using our method, we can bypass token-level content filters imposed by Midjourney by optimizing through the open-sourced text encoder",
    "checked": true,
    "id": "0c26bfc15a7caecce0ed4567dc2f2909b80e5bdd",
    "semantic_title": "hard prompts made easy: gradient-based discrete optimization for prompt tuning and discovery",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=gLfgyIWiWW": {
    "title": "Labeling Neural Representations with Inverse Recognition",
    "volume": "poster",
    "abstract": "Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning complex hierarchical data representations, but the nature of these representations remains largely unknown. Existing global explainability methods, such as Network Dissection, face limitations such as reliance on segmentation masks, lack of statistical significance testing, and high computational demands. We propose Inverse Recognition (INVERT), a scalable approach for linking the learned representations to human-interpretable concepts based on the ability to differentiate between concepts. In contrast to prior work, INVERT is capable of handling diverse types of neurons, exhibits less computational complexity, and does not rely on the availability of segmentation masks. Moreover, INVERT provides an interpretable metric assessing the alignment between the representation and its corresponding explanation and delivering a measure of statistical significance, emphasizing its utility and credibility. We demonstrate the applicability of INVERT in various scenarios, including the identification of representations affected by spurious correlations, and the interpretation of the hierarchical structure of decision-making within the models",
    "checked": true,
    "id": "037613dd9c9cb48cdfd9deb6023795a5aa1fb837",
    "semantic_title": "labeling neural representations with inverse recognition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LGKxz9clGG": {
    "title": "Handling Data Heterogeneity via Architectural Design for Federated Visual Recognition",
    "volume": "poster",
    "abstract": "Federated Learning (FL) is a promising research paradigm that enables the collaborative training of machine learning models among various parties without the need for sensitive information exchange. Nonetheless, retaining data in individual clients introduces fundamental challenges to achieving performance on par with centrally trained models. Our study provides an extensive review of federated learning applied to visual recognition. It underscores the critical role of thoughtful architectural design choices in achieving optimal performance, a factor often neglected in the FL literature. Many existing FL solutions are tested on shallow or simple networks, which may not accurately reflect real-world applications. This practice restricts the transferability of research findings to large-scale visual recognition models. Through an in-depth analysis of diverse cutting-edge architectures such as convolutional neural networks, transformers, and MLP-mixers, we experimentally demonstrate that architectural choices can substantially enhance FL systems' performance, particularly when handling heterogeneous data. We study visual recognition models from five different architectural families on four challenging FL datasets. We also re-investigate the inferior performance convolution-based architectures in the FL setting and analyze the influence of normalization layers on the FL performance. Our findings emphasize the importance of architectural design for computer vision tasks in practical scenarios, effectively narrowing the performance gap between federated and centralized learning",
    "checked": true,
    "id": "d78642d28e439537e08f449754fa9a55d1efe56d",
    "semantic_title": "handling data heterogeneity via architectural design for federated visual recognition",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QB7ot7p6j7": {
    "title": "DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification",
    "volume": "poster",
    "abstract": "Diffusion-based purification defenses leverage diffusion models to remove crafted perturbations of adversarial examples and achieve state-of-the-art robustness. Recent studies show that even advanced attacks cannot break such defenses effectively, since the purification process induces an extremely deep computational graph which poses the potential problem of gradient obfuscation, high memory cost, and unbounded randomness. In this paper, we propose a unified framework DiffAttack to perform effective and efficient attacks against diffusion-based purification defenses, including both DDPM and score-based approaches. In particular, we propose a deviated-reconstruction loss at intermediate diffusion steps to induce inaccurate density gradient estimation to tackle the problem of vanishing/exploding gradients. We also provide a segment-wise forwarding-backwarding algorithm, which leads to memory-efficient gradient backpropagation. We validate the attack effectiveness of DiffAttack compared with existing adaptive attacks on CIFAR-10 and ImageNet. We show that DiffAttack decreases the robust accuracy of models compared with SOTA attacks by over 20\\% on CIFAR-10 under $\\ell_\\infty$ attack $(\\epsilon=8/255)$, and over 10\\% on ImageNet under $\\ell_\\infty$ attack $(\\epsilon=4/255)$. We conduct a series of ablations studies, and we find 1) DiffAttack with the deviated-reconstruction loss added over uniformly sampled time steps is more effective than that added over only initial/final steps, and 2) diffusion-based purification with a moderate diffusion length is more robust under DiffAttack",
    "checked": false,
    "id": "227feac3b9e56063e8e086d11193865ce21381f9",
    "semantic_title": "robust evaluation of diffusion-based adversarial purification",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=4SoTUaTK8N": {
    "title": "Reversible and irreversible bracket-based dynamics for deep graph neural networks",
    "volume": "poster",
    "abstract": "Recent works have shown that physics-inspired architectures allow the training of deep graph neural networks (GNNs) without oversmoothing. The role of these physics is unclear, however, with successful examples of both reversible (e.g., Hamiltonian) and irreversible (e.g., diffusion) phenomena producing comparable results despite diametrically opposed mechanisms, and further complications arising due to empirical departures from mathematical theory. This work presents a series of novel GNN architectures based upon structure-preserving bracket-based dynamical systems, which are provably guaranteed to either conserve energy or generate positive dissipation with increasing depth. It is shown that the theoretically principled framework employed here allows for inherently explainable constructions, which contextualize departures from theory in current architectures and better elucidate the roles of reversibility and irreversibility in network performance. Code is available at the Github repository \\url{https://github.com/natrask/BracketGraphs}",
    "checked": true,
    "id": "71395e0be94802971611ec88130af780d4ba90d0",
    "semantic_title": "reversible and irreversible bracket-based dynamics for deep graph neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=UvBwXdL95b": {
    "title": "UP-NeRF: Unconstrained Pose Prior-Free Neural Radiance Field",
    "volume": "poster",
    "abstract": "Neural Radiance Field (NeRF) has enabled novel view synthesis with high fidelity given images and camera poses. Subsequent works even succeeded in eliminating the necessity of pose priors by jointly optimizing NeRF and camera pose. However, these works are limited to relatively simple settings such as photometrically consistent and occluder-free image collections or a sequence of images from a video. So they have difficulty handling unconstrained images with varying illumination and transient occluders. In this paper, we propose **UP-NeRF** (**U**nconstrained **P**ose-prior-free **Ne**ural **R**adiance **F**ields) to optimize NeRF with unconstrained image collections without camera pose prior. We tackle these challenges with surrogate tasks that optimize color-insensitive feature fields and a separate module for transient occluders to block their influence on pose estimation. In addition, we introduce a candidate head to enable more robust pose estimation and transient-aware depth supervision to minimize the effect of incorrect prior. Our experiments verify the superior performance of our method compared to the baselines including BARF and its variants in a challenging internet photo collection, *Phototourism dataset*. The code of UP-NeRF is available at https://github.com/mlvlab/UP-NeRF",
    "checked": false,
    "id": "009f9b5bf28b0082cb8d4f5030dcbfd529393ea1",
    "semantic_title": "up-nerf: unconstrained pose-prior-free neural radiance fields",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4mwORQjAim": {
    "title": "Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures",
    "volume": "poster",
    "abstract": "Persistent homology (PH) provides topological descriptors for geometric data, such as weighted graphs, which are interpretable, stable to perturbations, and invariant under, e.g., relabeling. Most applications of PH focus on the one-parameter case---where the descriptors summarize the changes in topology of data as it is filtered by a single quantity of interest---and there is now a wide array of methods enabling the use of one-parameter PH descriptors in data science, which rely on the stable vectorization of these descriptors as elements of a Hilbert space. Although the multiparameter PH (MPH) of data that is filtered by several quantities of interest encodes much richer information than its one-parameter counterpart, the scarceness of stability results for MPH descriptors has so far limited the available options for the stable vectorization of MPH. In this paper, we aim to bring together the best of both worlds by showing how the interpretation of signed barcodes---a recent family of MPH descriptors---as signed Radon measures leads to natural extensions of vectorization strategies from one parameter to multiple parameters. The resulting feature vectors are easy to define and to compute, and provably stable. While, as a proof of concept, we focus on simple choices of signed barcodes and vectorizations, we already see notable performance improvements when comparing our feature vectors to state-of-the-art topology-based methods on various types of data",
    "checked": true,
    "id": "55c00afdb3f244a891deec5e39322a94d7879548",
    "semantic_title": "stable vectorization of multiparameter persistent homology using signed barcodes as measures",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2tfG9QaFA7": {
    "title": "Training on Foveated Images Improves Robustness to Adversarial Attacks",
    "volume": "poster",
    "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25% higher accuracy on perturbed data",
    "checked": true,
    "id": "74664618ad3b44eb191ba96fdff5b93f27a29ced",
    "semantic_title": "training on foveated images improves robustness to adversarial attacks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JOHp5SmckS": {
    "title": "Towards Combinatorial Generalization for Catalysts: A Kohn-Sham Charge-Density Approach",
    "volume": "poster",
    "abstract": "The Kohn-Sham equations underlie many important applications such as the discovery of new catalysts. Recent machine learning work on catalyst modeling has focused on prediction of the energy, but has so far not yet demonstrated significant out-of-distribution generalization. Here we investigate another approach based on the pointwise learning of the Kohn-Sham charge-density. On a new dataset of bulk catalysts with charge densities, we show density models can generalize to new structures with combinations of elements not seen at train time, a form of combinatorial generalization. We show that over 80% of binary and ternary test cases achieve faster convergence than standard baselines in Density Functional Theory, amounting to an average reduction of 13% in the number of iterations required to reach convergence, which may be of independent interest. Our results suggest that density learning is a viable alternative, trading greater inference costs for a step towards combinatorial generalization, a key property for applications",
    "checked": true,
    "id": "979f465b67f9b6d6835ff8157793c6256f910be7",
    "semantic_title": "towards combinatorial generalization for catalysts: a kohn-sham charge-density approach",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7hLlZNrkt5": {
    "title": "A Theory of Link Prediction via Relational Weisfeiler-Leman on Knowledge Graphs",
    "volume": "poster",
    "abstract": "Graph neural networks are prominent models for representation learning over graph-structured data. While the capabilities and limitations of these models are well-understood for simple graphs, our understanding remains incomplete in the context of knowledge graphs. Our goal is to provide a systematic understanding of the landscape of graph neural networks for knowledge graphs pertaining to the prominent task of link prediction. Our analysis entails a unifying perspective on seemingly unrelated models and unlocks a series of other models. The expressive power of various models is characterized via a corresponding relational Weisfeiler-Leman algorithm. This analysis is extended to provide a precise logical characterization of the class of functions captured by a class of graph neural networks. The theoretical findings presented in this paper explain the benefits of some widely employed practical design choices, which are validated empirically",
    "checked": false,
    "id": "3f4dff0c50a2edc4d38973669f8459449f114e28",
    "semantic_title": "a theory of link prediction via relational weisfeiler-leman",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=hExFOGZTSt": {
    "title": "Creating a Public Repository for Joining Private Data",
    "volume": "poster",
    "abstract": "How can one publish a dataset with sensitive attributes in a way that both preserves privacy and enables joins with other datasets on those same sensitive attributes? This problem arises in many contexts, e.g., a hospital and an airline may want to jointly determine whether people who take long-haul flights are more likely to catch respiratory infections. If they join their data by a common keyed user identifier such as email address, they can determine the answer, though it breaks privacy. This paper shows how the hospital can generate a private sketch and how the airline can privately join with the hospital's sketch by email address. The proposed solution satisfies pure differential privacy and gives approximate answers to linear queries and optimization problems over those joins. Whereas prior work such as secure function evaluation requires sender/receiver interaction, a distinguishing characteristic of the proposed approach is that it is non-interactive. Consequently, the sketch can be published to a repository for any organization to join with, facilitating data discovery. The accuracy of the method is demonstrated through both theoretical analysis and extensive empirical evidence",
    "checked": false,
    "id": "693e07b45bd583c58e2f57e0e54e425a60636871",
    "semantic_title": "build semic.eu in the cloud",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jnIBiP2di1": {
    "title": "Learning Reliable Logical Rules with SATNet",
    "volume": "poster",
    "abstract": "Bridging logical reasoning and deep learning is crucial for advanced AI systems. In this work, we present a new framework that addresses this goal by generating interpretable and verifiable logical rules through differentiable learning, without relying on pre-specified logical structures. Our approach builds upon SATNet, a differentiable MaxSAT solver that learns the underlying rules from input-output examples. Despite its efficacy, the learned weights in SATNet are not straightforwardly interpretable, failing to produce human-readable rules. To address this, we propose a novel specification method called ``maximum equality'', which enables the interchangeability between the learned weights of SATNet and a set of propositional logical rules in weighted MaxSAT form. With the decoded weighted MaxSAT formula, we further introduce several effective verification techniques to validate it against the ground truth rules. Experiments on stream transformations and Sudoku problems show that our decoded rules are highly reliable: using exact solvers on them could achieve 100% accuracy, whereas the original SATNet fails to give correct solutions in many cases. Furthermore, we formally verify that our decoded logical rules are functionally equivalent to the ground truth ones",
    "checked": true,
    "id": "ec0e707d8519d286beffb9a7c4f6374729d40acc",
    "semantic_title": "learning reliable logical rules with satnet",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y1sJJW3pID": {
    "title": "A Unified Approach for Maximizing Continuous DR-submodular Functions",
    "volume": "poster",
    "abstract": "This paper presents a unified approach for maximizing continuous DR-submodular functions that encompasses a range of settings and oracle access types. Our approach includes a Frank-Wolfe type offline algorithm for both monotone and non-monotone functions, with different restrictions on the general convex set. We consider settings where the oracle provides access to either the gradient of the function or only the function value, and where the oracle access is either deterministic or stochastic. We determine the number of required oracle accesses in all cases. Our approach gives new/improved results for nine out of the sixteen considered cases, avoids computationally expensive projections in three cases, with the proposed framework matching performance of state-of-the-art approaches in the remaining four cases. Notably, our approach for the stochastic function value-based oracle enables the first regret bounds with bandit feedback for stochastic DR-submodular functions",
    "checked": true,
    "id": "f910bee4a4102be291ddfaaaebc1380e163efb9b",
    "semantic_title": "a unified approach for maximizing continuous dr-submodular functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hVVp8TXIPs": {
    "title": "Hardware Resilience Properties of Text-Guided Image Classifiers",
    "volume": "poster",
    "abstract": "This paper presents a novel method to enhance the reliability of image classification models during deployment in the face of transient hardware errors. By utilizing enriched text embeddings derived from GPT-3 with question prompts per class and CLIP pretrained text encoder, we investigate their impact as an initialization for the classification layer. Our approach achieves a remarkable $5.5\\times$ average increase in hardware reliability (and up to $14\\times$) across various architectures in the most critical layer, with minimal accuracy drop ($0.3\\%$ on average) compared to baseline PyTorch models. Furthermore, our method seamlessly integrates with any image classification backbone, showcases results across various network architectures, decreases parameter and FLOPs overhead, and follows a consistent training recipe. This research offers a practical and efficient solution to bolster the robustness of image classification models against hardware failures, with potential implications for future studies in this domain. Our code and models are released at https://github.com/TalalWasim/TextGuidedResilience",
    "checked": true,
    "id": "dca449c895290fad5eed9f0fef9bee25e160ffb0",
    "semantic_title": "hardware resilience properties of text-guided image classifiers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aCOKUvqHtD": {
    "title": "Polynomial-Time Linear-Swap Regret Minimization in Imperfect-Information Sequential Games",
    "volume": "poster",
    "abstract": "No-regret learners seek to minimize the difference between the loss they cumulated through the actions they played, and the loss they would have cumulated in hindsight had they consistently modified their behavior according to some strategy transformation function. The size of the set of transformations considered by the learner determines a natural notion of rationality. As the set of transformations each learner considers grows, the strategies played by the learners recover more complex game-theoretic equilibria, including correlated equilibria in normal-form games and extensive-form correlated equilibria in extensive-form games. At the extreme, a no-swap-regret agent is one that minimizes regret against the set of all functions from the set of strategies to itself. While it is known that the no-swap-regret condition can be attained efficiently in nonsequential (normal-form) games, understanding what is the strongest notion of rationality that can be attained efficiently in the worst case in sequential (extensive-form) games is a longstanding open problem. In this paper we provide a positive result, by showing that it is possible, in any sequential game, to retain polynomial-time (in the game tree size) iterations while achieving sublinear regret with respect to all linear transformations of the mixed strategy space, a notion called no-linear-swap regret. This notion of hindsight rationality is as strong as no-swap-regret in nonsequential games, and stronger than no-trigger-regret in sequential games—thereby proving the existence of a subset of extensive-form correlated equilibria robust to linear deviations, which we call linear-deviation correlated equilibria, that can be approached efficiently",
    "checked": true,
    "id": "cb50198dced629fad04f70ac2aa32461fd32975c",
    "semantic_title": "polynomial-time linear-swap regret minimization in imperfect-information sequential games",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FkAwlqBuyO": {
    "title": "Direct Preference-based Policy Optimization without Reward Modeling",
    "volume": "poster",
    "abstract": "Preference-based reinforcement learning (PbRL) is an approach that enables RL agents to learn from preference, which is particularly useful when formulating a reward function is challenging. Existing PbRL methods generally involve a two-step procedure: they first learn a reward model based on given preference data and then employ off-the-shelf reinforcement learning algorithms using the learned reward model. However, obtaining an accurate reward model solely from preference information, especially when the preference is from human teachers, can be difficult. Instead, we propose a PbRL algorithm that directly learns from preference without requiring any reward modeling. To achieve this, we adopt a contrastive learning framework to design a novel policy scoring metric that assigns a high score to policies that align with the given preferences. We apply our algorithm to offline RL tasks with actual human preference labels and show that our algorithm outperforms or is on par with the existing PbRL methods. Notably, on high-dimensional control tasks, our algorithm surpasses offline RL methods that learn with ground-truth reward information. Finally, we show that our algorithm can be successfully applied to fine-tune large language models",
    "checked": true,
    "id": "4f0bfeadd39e64456d15d400fda8ecc2197c3265",
    "semantic_title": "direct preference-based policy optimization without reward modeling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ds7Vd83HlC": {
    "title": "Faster Query Times for Fully Dynamic $k$-Center Clustering with Outliers",
    "volume": "poster",
    "abstract": "Given a point set $P\\subseteq M$ from a metric space $(M,d)$ and numbers $k, z \\in N$, the *metric $k$-center problem with $z$ outliers* is to find a set $C^\\ast\\subseteq P$ of $k$ points such that the maximum distance of all but at most $z$ outlier points of $P$ to their nearest center in ${C}^\\ast$ is minimized. We consider this problem in the fully dynamic model, i.e., under insertions and deletions of points, for the case that the metric space has a bounded doubling dimension $dim$. We utilize a hierarchical data structure to maintain the points and their neighborhoods, which enables us to efficiently find the clusters. In particular, our data structure can be queried at any time to generate a $(3+\\varepsilon)$-approximate solution for input values of $k$ and $z$ in worst-case query time $\\varepsilon^{-O(dim)}k \\log{n} \\log\\log{\\Delta}$, where $\\Delta$ is the ratio between the maximum and minimum distance between two points in $P$. Moreover, it allows insertion/deletion of a point in worst-case update time $\\varepsilon^{-O(dim)}\\log{n}\\log{\\Delta}$. Our result achieves a significantly faster query time with respect to $k$ and $z$ than the current state-of-the-art by Pellizzoni, Pietracaprina, and Pucci, which uses $\\varepsilon^{-O(dim)}(k+z)^2\\log{\\Delta}$ query time to obtain a $(3+\\varepsilon)$-approximation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xfBeVGJwyL": {
    "title": "Physics-Informed Bayesian Optimization of Variational Quantum Circuits",
    "volume": "poster",
    "abstract": "In this paper, we propose a novel and powerful method to harness Bayesian optimization for variational quantum eigensolvers (VQEs) - a hybrid quantum-classical protocol used to approximate the ground state of a quantum Hamiltonian. Specifically, we derive a *VQE-kernel* which incorporates important prior information about quantum circuits: the kernel feature map of the VQE-kernel exactly matches the known functional form of the VQE's objective function and thereby significantly reduces the posterior uncertainty. Moreover, we propose a novel acquisition function for Bayesian optimization called \\emph{Expected Maximum Improvement over Confident Regions} (EMICoRe) which can actively exploit the inductive bias of the VQE-kernel by treating regions with low predictive uncertainty as indirectly \"observed\". As a result, observations at as few as three points in the search domain are sufficient to determine the complete objective function along an entire one-dimensional subspace of the optimization landscape. Our numerical experiments demonstrate that our approach improves over state-of-the-art baselines",
    "checked": false,
    "id": "f4613763a41221c88547423a664d6aae1441809e",
    "semantic_title": "translational quantum machine intelligence for modeling tumor dynamics in oncology",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=3WAnGWLpSQ": {
    "title": "Why Does Sharpness-Aware Minimization Generalize Better Than SGD?",
    "volume": "poster",
    "abstract": "The challenge of overfitting, in which the model memorizes the training data and fails to generalize to test data, has become increasingly significant in the training of large neural networks. To tackle this challenge, Sharpness-Aware Minimization (SAM) has emerged as a promising training method, which can improve the generalization of neural networks even in the presence of label noise. However, a deep understanding of how SAM works, especially in the setting of nonlinear neural networks and classification tasks, remains largely missing. This paper fills this gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks. The loss landscape of our studied problem is nonsmooth, thus current explanations for the success of SAM based on the Hessian information are insufficient. Our result explains the benefits of SAM, particularly its ability to prevent noise learning in the early stages, thereby facilitating more effective learning of features. Experiments on both synthetic and real data corroborate our theory",
    "checked": true,
    "id": "0522f97eebe1e653dd875883d10fae8a3dde0d53",
    "semantic_title": "why does sharpness-aware minimization generalize better than sgd?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4xckZu4MPG": {
    "title": "Attention as Implicit Structural Inference",
    "volume": "poster",
    "abstract": "Attention mechanisms play a crucial role in cognitive systems by allowing them to flexibly allocate cognitive resources. Transformers, in particular, have become a dominant architecture in machine learning, with attention as their central innovation. However, the underlying intuition and formalism of attention in Transformers is based on ideas of keys and queries in database management systems. In this work, we pursue a structural inference perspective, building upon, and bringing together, previous theoretical descriptions of attention such as; Gaussian Mixture Models, alignment mechanisms and Hopfield Networks. Specifically, we demonstrate that attention can be viewed as inference over an implicitly defined set of possible adjacency structures in a graphical model, revealing the generality of such a mechanism. This perspective unifies different attentional architectures in machine learning and suggests potential modifications and generalizations of attention. Here we investigate two and demonstrate their behaviour on explanatory toy problems: (a) extending the value function to incorporate more nodes of a graphical model yielding a mechanism with a bias toward attending multiple tokens; (b) introducing a geometric prior (with conjugate hyper-prior) over the adjacency structures producing a mechanism which dynamically scales the context window depending on input. Moreover, by describing a link between structural inference and precision-regulation in Predictive Coding Networks, we discuss how this framework can bridge the gap between attentional mechanisms in machine learning and Bayesian conceptions of attention in Neuroscience. We hope by providing a new lens on attention architectures our work can guide the development of new and improved attentional mechanisms",
    "checked": false,
    "id": "fed7e166c596f60129834aaaa9508fe3963a2978",
    "semantic_title": "o bject r epresentations as e quilibria : t raining i terative i nference a lgorithms with i mplicit d ifferentiation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9Ihu0VBOTq": {
    "title": "Provable Advantage of Curriculum Learning on Parity Targets with Mixed Inputs",
    "volume": "poster",
    "abstract": "Experimental results have shown that curriculum learning, i.e., presenting simpler examples before more complex ones, can improve the efficiency of learning. Some recent theoretical results also showed that changing the sampling distribution can help neural networks learn parities, with formal results only for large learning rates and one-step arguments. Here we show a separation result in the number of training steps with standard (bounded) learning rates on a common sample distribution: if the data distribution is a mixture of sparse and dense inputs, there exists a regime in which a 2-layer ReLU neural network trained by a curriculum noisy-GD (or SGD) algorithm that uses sparse examples first, can learn parities of sufficiently large degree, while any fully connected neural network of possibly larger width or depth trained by noisy-GD on the unordered samples cannot learn without additional steps. We also provide experimental results supporting the qualitative separation beyond the specific regime of the theoretical results",
    "checked": true,
    "id": "1de63f374706b35f351ae04bf0a5fba3fae20ce5",
    "semantic_title": "provable advantage of curriculum learning on parity targets with mixed inputs",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S2k5dBb91q": {
    "title": "Transportability for Bandits with Data from Different Environments",
    "volume": "poster",
    "abstract": "A unifying theme in the design of intelligent agents is to efficiently optimize a policy based on what prior knowledge of the problem is available and what actions can be taken to learn more about it. Bandits are a canonical instance of this task that has been intensely studied in the literature. Most methods, however, typically rely solely on an agent's experimentation in a single environment (or multiple closely related environments). In this paper, we relax this assumption and consider the design of bandit algorithms from a combination of batch data and qualitative assumptions about the relatedness across different environments, represented in the form of causal models. In particular, we show that it is possible to exploit invariances across environments, wherever they may occur in the underlying causal model, to consistently improve learning. The resulting bandit algorithm has a sub-linear regret bound with an explicit dependency on a term that captures how informative related environments are for the task at hand; and may have substantially lower regret than experimentation-only bandit instances",
    "checked": false,
    "id": "91ef3cc1cb74ba1484576757585858ce81bb9b4b",
    "semantic_title": "exploiting causal structure for transportability in online, multi-agent environments",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eZbqD9BoXe": {
    "title": "Graph-Structured Gaussian Processes for Transferable Graph Learning",
    "volume": "poster",
    "abstract": "Transferable graph learning involves knowledge transferability from a source graph to a relevant target graph. The major challenge of transferable graph learning is the distribution shift between source and target graphs induced by individual node attributes and complex graph structures. To solve this problem, in this paper, we propose a generic graph-structured Gaussian process framework (GraphGP) for adaptively transferring knowledge across graphs with either homophily or heterophily assumptions. Specifically, GraphGP is derived from a novel graph structure-aware neural network in the limit on the layer width. The generalization analysis of GraphGP explicitly investigates the connection between knowledge transferability and graph domain similarity. Extensive experiments on several transferable graph learning benchmarks demonstrate the efficacy of GraphGP over state-of-the-art Gaussian process baselines",
    "checked": false,
    "id": "6a7e86550dfe2652e63ae65bf9eed9ce54a3128d",
    "semantic_title": "graph neural network-inspired kernels for gaussian processes in semi-supervised learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=4L2OlXhiTM": {
    "title": "FIRAL: An Active Learning Algorithm for Multinomial Logistic Regression",
    "volume": "poster",
    "abstract": "We investigate theory and algorithms for pool-based active learning for multiclass classification using multinomial logistic regression. Using finite sample analysis, we prove that the Fisher Information Ratio (FIR) lower and upper bounds the excess risk. Based on our theoretical analysis, we propose an active learning algorithm that employs regret minimization to minimize the FIR. To verify our derived excess risk bounds, we conduct experiments on synthetic datasets. Furthermore, we compare FIRAL with five other methods and found that our scheme outperforms them: it consistently produces the smallest classification error in the multiclass logistic regression setting, as demonstrated through experiments on MNIST, CIFAR-10, and 50-class ImageNet",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iM0MWWBr4W": {
    "title": "A Unified Model and Dimension for Interactive Estimation",
    "volume": "poster",
    "abstract": "We study an abstract framework for interactive learning called interactive estimation in which the goal is to estimate a target from its ``similarity'' to points queried by the learner. We introduce a combinatorial measure called Dissimilarity dimension which largely captures learnability in our model. We present a simple, general, and broadly-applicable algorithm, for which we obtain both regret and PAC generalization bounds that are polynomial in the new dimension. We show that our framework subsumes and thereby unifies two classic learning models: statistical-query learning and structured bandits. We also delineate how the Dissimilarity dimension is related to well-known parameters for both frameworks, in some cases yielding significantly improved analyses",
    "checked": true,
    "id": "a64dff274698a5269a5654ddeb6f5e114b37c63d",
    "semantic_title": "a unified model and dimension for interactive estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MG0mYskXN2": {
    "title": "Should Under-parameterized Student Networks Copy or Average Teacher Weights?",
    "volume": "poster",
    "abstract": "Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n< k$ neurons can thus be seen as fitting an under-parameterized \"student\" network with $n$ neurons to a \"teacher\" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that \"copy-average\" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the student network with $n=1$ neuron, we provide additionally a closed-form solution of the non-trivial critical point(s) for commonly used activation functions through solving an equivalent constrained optimization problem. Empirically, we find for the erf activation function that gradient flow converges either to the optimal copy-average critical point or to another point where each student neuron approximately copies a different teacher neuron. Finally, we find similar results for the ReLU activation function, suggesting that the optimal solution of underparameterized networks has a universal structure",
    "checked": true,
    "id": "c221ee005c728e726853c3e21b07ebf1b82c9163",
    "semantic_title": "should under-parameterized student networks copy or average teacher weights?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yx8Sw2H5Q7": {
    "title": "Compositional Policy Learning in Stochastic Control Systems with Formal Guarantees",
    "volume": "poster",
    "abstract": "Reinforcement learning has shown promising results in learning neural network policies for complicated control tasks. However, the lack of formal guarantees about the behavior of such policies remains an impediment to their deployment. We propose a novel method for learning a composition of neural network policies in stochastic environments, along with a formal certificate which guarantees that a specification over the policy's behavior is satisfied with the desired probability. Unlike prior work on verifiable RL, our approach leverages the compositional nature of logical specifications provided in SpectRL, to learn over graphs of probabilistic reach-avoid specifications. The formal guarantees are provided by learning neural network policies together with reach-avoid supermartingales (RASM) for the graph's sub-tasks and then composing them into a global policy. We also derive a tighter lower bound compared to previous work on the probability of reach-avoidance implied by a RASM, which is required to find a compositional policy with an acceptable probabilistic threshold for complex tasks with multiple edge policies. We implement a prototype of our approach and evaluate it on a Stochastic Nine Rooms environment",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wNxyDofh74": {
    "title": "Progressive Ensemble Distillation: Building Ensembles for Efficient Inference",
    "volume": "poster",
    "abstract": "Knowledge distillation is commonly used to compress an ensemble of models into a single model. In this work we study the problem of progressive ensemble distillation: Given a large, pretrained teacher model , we seek to decompose the model into an ensemble of smaller, low-inference cost student models . The resulting ensemble allows for flexibly tuning accuracy vs. inference cost, which can be useful for a multitude of applications in efficient inference. Our method, B-DISTIL, uses a boosting procedure that allows function composition based aggregation rules to construct expressive ensembles with similar performance as using much smaller student models. We demonstrate the effectiveness of B-DISTIL by decomposing pretrained models across a variety of image, speech, and sensor datasets. Our method comes with strong theoretical guarantees in terms of convergence as well as generalization",
    "checked": true,
    "id": "e215d1d0feae993bfaa93b16a505c6a8b8a62487",
    "semantic_title": "progressive ensemble distillation: building ensembles for efficient inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0tEjORCGFD": {
    "title": "Collaborative Score Distillation for Consistent Visual Editing",
    "volume": "poster",
    "abstract": "Generative priors of large-scale text-to-image diffusion models enable a wide range of new generation and editing applications on diverse visual modalities. However, when adapting these priors to complex visual modalities, often represented as multiple images (e.g., video or 3D scene), achieving consistency across a set of images is challenging. In this paper, we address this challenge with a novel method, Collaborative Score Distillation (CSD). CSD is based on the Stein Variational Gradient Descent (SVGD). Specifically, we propose to consider multiple samples as \"particles\" in the SVGD update and combine their score functions to distill generative priors over a set of images synchronously. Thus, CSD facilitates the seamless integration of information across 2D images, leading to a consistent visual synthesis across multiple samples. We show the effectiveness of CSD in a variety of editing tasks, encompassing the visual editing of panorama images, videos, and 3D scenes. Our results underline the competency of CSD as a versatile method for enhancing inter-sample consistency, thereby broadening the applicability of text-to-image diffusion models",
    "checked": false,
    "id": "81583156b7786f50f3a2ede06ccd308c6c80f2e1",
    "semantic_title": "collaborative score distillation for consistent visual synthesis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WPbIAdB6aQ": {
    "title": "A Robust Exact Algorithm for the Euclidean Bipartite Matching Problem",
    "volume": "poster",
    "abstract": "Algorithms for the minimum-cost bipartite matching can be used to estimate Wasserstein distance between two distributions. Given two sets $A$ and $B$ of $n$ points in a $2$-dimensional Euclidean space, one can use a fast implementation of the Hungarian method to compute a minimum-cost bipartite matching of $A$ and $B$ in $\\tilde{O}(n^2)$ time. Let $\\Delta$ be the spread, i.e., the ratio of the distance of the farthest to the closest pair of points in $A\\cup B$. In this paper, we present a new algorithm to compute a minimum-cost bipartite matching of $A$ and $B$ with a similar worst-case execution time of $\\tilde{O}(n^2 \\log \\Delta)$. However, when $A$ and $B$ are drawn independently and identically from a fixed distribution that is not known to the algorithm, the execution time of our algorithm is, in expectation, $\\tilde{O}(n^{7/4}\\log \\Delta)$. To the best of our knowledge, our algorithm is the first one to achieve a sub-quadratic execution time even for stochastic point sets with real-valued coordinates. Our algorithm extends to any dimension $d$, where it runs in $\\tilde{O}(n^{2-\\frac{1}{2d}}\\Phi(n))$ time for stochastic point sets $A$ and $B$; here $\\Phi(n)$ is the query/update time of a dynamic weighted nearest neighbor data structure. Our algorithm can be seen as a careful adaptation of the Hungarian method in the geometric divide-and-conquer framework",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OiatK9W6tR": {
    "title": "Quantum speedups for stochastic optimization",
    "volume": "poster",
    "abstract": "We consider the problem of minimizing a continuous function given given access to a natural quantum generalization of a stochastic gradient oracle. We provide two new methods for the special case of minimizing a Lipschitz convex function. Each method obtains a dimension versus accuracy trade-off which is provably unachievable classically and we prove that one method is asymptotically optimal in low-dimensional settings. Additionally, we provide quantum algorithms for computing a critical point of a smooth non-convex function at rates not known to be achievable classically. To obtain these results we build upon the quantum multivariate mean estimation result of Cornelissen et al. and provide a general quantum variance reduction technique of independent interest",
    "checked": true,
    "id": "23540cc01ce11f686cd3eb854ceff3ba4b3f2ec6",
    "semantic_title": "quantum speedups for stochastic optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LDhhi8HBO3": {
    "title": "Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization",
    "volume": "poster",
    "abstract": "To improve the robustness of deep classifiers against adversarial perturbations, many approaches have been proposed, such as designing new architectures with better robustness properties (e.g., Lipschitz-capped networks), or modifying the training process itself (e.g., min-max optimization, constrained learning, or regularization). These approaches, however, might not be effective at increasing the margin in the input (feature) space. In this paper, we propose a differentiable regularizer that is a lower bound on the distance of the data points to the classification boundary. The proposed regularizer requires knowledge of the model's Lipschitz constant along certain directions. To this end, we develop a scalable method for calculating guaranteed differentiable upper bounds on the Lipschitz constant of neural networks accurately and efficiently. The relative accuracy of the bounds prevents excessive regularization and allows for more direct manipulation of the decision boundary. Furthermore, our Lipschitz bounding algorithm exploits the monotonicity and Lipschitz continuity of the activation layers, and the resulting bounds can be used to design new layers with controllable bounds on their Lipschitz constant. Experiments on the MNIST, CIFAR-10, and Tiny-ImageNet data sets verify that our proposed algorithm obtains competitively improved results compared to the state-of-the-art",
    "checked": true,
    "id": "d84e86788d688e47de6b33c7d52b418037ef9f05",
    "semantic_title": "certified robustness via dynamic margin maximization and improved lipschitz regularization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dxhv8Oja2V": {
    "title": "Convergence Analysis of Sequential Federated Learning on Heterogeneous Data",
    "volume": "poster",
    "abstract": "There are two categories of methods in Federated Learning (FL) for joint training across multiple clients: i) parallel FL (PFL), where clients train models in a parallel manner; and ii) sequential FL (SFL), where clients train models in a sequential manner. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. In this paper, we establish the convergence guarantees of SFL for strongly/general/non-convex objectives on heterogeneous data. The convergence guarantees of SFL are better than that of PFL on heterogeneous data with both full and partial client participation. Experimental results validate the counterintuitive analysis result that SFL outperforms PFL on extremely heterogeneous data in cross-device settings",
    "checked": true,
    "id": "20cfbfbc2b17a26efae013beb14a645ab9a4d8a4",
    "semantic_title": "convergence analysis of sequential federated learning on heterogeneous data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DkKHSsmVuA": {
    "title": "Optimal Rates for Bandit Nonstochastic Control",
    "volume": "poster",
    "abstract": "Linear Quadratic Regulator (LQR) and Linear Quadratic Gaussian (LQG) control are foundational and extensively researched problems in optimal control. We investigate LQR and LQG problems with semi-adversarial perturbations and time-varying adversarial bandit loss functions. The best-known sublinear regret algorithm~\\cite{gradu2020non} has a $T^{\\frac{3}{4}}$ time horizon dependence, and its authors posed an open question about whether a tight rate of $\\sqrt{T}$ could be achieved. We answer in the affirmative, giving an algorithm for bandit LQR and LQG which attains optimal regret, up to logarithmic factors. A central component of our method is a new scheme for bandit convex optimization with memory, which is of independent interest",
    "checked": true,
    "id": "c2eb79cd8e313ebeaf13992e92882b4a61c2a599",
    "semantic_title": "optimal rates for bandit nonstochastic control",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=pH4Fv7C3yC": {
    "title": "Causal Effect Identification in Uncertain Causal Networks",
    "volume": "poster",
    "abstract": "Causal identification is at the core of the causal inference literature, where complete algorithms have been proposed to identify causal queries of interest. The validity of these algorithms hinges on the restrictive assumption of having access to a correctly specified causal structure. In this work, we study the setting where a probabilistic model of the causal structure is available. Specifically, the edges in a causal graph exist with uncertainties which may, for example, represent degree of belief from domain experts. Alternatively, the uncertainty about an edge may reflect the confidence of a particular statistical test. The question that naturally arises in this setting is: Given such a probabilistic graph and a specific causal effect of interest, what is the subgraph which has the highest plausibility and for which the causal effect is identifiable? We show that answering this question reduces to solving an NP-hard combinatorial optimization problem which we call the edge ID problem. We propose efficient algorithms to approximate this problem and evaluate them against both real-world networks and randomly generated graphs",
    "checked": true,
    "id": "672aada2df911bf47db62da52466564f66e9ee84",
    "semantic_title": "causal effect identification in uncertain causal networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=xINPCvgULc": {
    "title": "Robust Bayesian Satisficing",
    "volume": "poster",
    "abstract": "Distributional shifts pose a significant challenge to achieving robustness in contemporary machine learning. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. This paper focuses on the problem of RS in contextual Bayesian optimization when there is a discrepancy between the true and reference distributions of the context. We propose a novel robust Bayesian satisficing algorithm called RoBOS for noisy black-box optimization. Our algorithm guarantees sublinear lenient regret under certain assumptions on the amount of distribution shift. In addition, we define a weaker notion of regret called robust satisficing regret, in which our algorithm achieves a sublinear upper bound independent of the amount of distribution shift. To demonstrate the effectiveness of our method, we apply it to various learning problems and compare it to other approaches, such as distributionally robust optimization",
    "checked": true,
    "id": "a1c32b3835a3031ee892a80b06f5452375919a46",
    "semantic_title": "robust bayesian satisficing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lpx9LZPVtZ": {
    "title": "SPA: A Graph Spectral Alignment Perspective for Domain Adaptation",
    "volume": "poster",
    "abstract": "Unsupervised domain adaptation (UDA) is a pivotal form in machine learning to extend the in-domain model to the distinctive target domains where the data distributions differ. Most prior works focus on capturing the inter-domain transferability but largely overlook rich intra-domain structures, which empirically results in even worse discriminability. In this work, we introduce a novel graph SPectral Alignment (SPA) framework to tackle the tradeoff. The core of our method is briefly condensed as follows: (i)-by casting the DA problem to graph primitives, SPA composes a coarse graph alignment mechanism with a novel spectral regularizer towards aligning the domain graphs in eigenspaces; (ii)-we further develop a fine-grained message propagation module --- upon a novel neighbor-aware self-training mechanism --- in order for enhanced discriminability in the target domain. On standardized benchmarks, the extensive experiments of SPA demonstrate that its performance has surpassed the existing cutting-edge DA methods. Coupled with dense model analysis, we conclude that our approach indeed possesses superior efficacy, robustness, discriminability, and transferability. Code and data are available at: https://github.com/CrownX/SPA",
    "checked": true,
    "id": "246bc31156f92d3edc84659ffbc266f46788fac1",
    "semantic_title": "spa: a graph spectral alignment perspective for domain adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9OqezkNxnX": {
    "title": "Incentives in Federated Learning: Equilibria, Dynamics, and Mechanisms for Welfare Maximization",
    "volume": "poster",
    "abstract": "Federated learning (FL) has emerged as a powerful scheme to facilitate the collaborative learning of models amongst a set of agents holding their own private data. Although the agents benefit from the global model trained on shared data, by participating in federated learning, they may also incur costs (related to privacy and communication) due to data sharing. In this paper, we model a collaborative FL framework, where every agent attempts to achieve an optimal trade-off between her learning payoff and data sharing cost. We show the existence of Nash equilibrium (NE) under mild assumptions on agents' payoff and costs. Furthermore, we show that agents can discover the NE via best response dynamics. However, some of the NE may be bad in terms of overall welfare for the agents, implying little incentive for some fraction of the agents to participate in the learning. To remedy this, we design a budget-balanced mechanism involving payments to the agents, that ensures that any $p$-mean welfare function of the agents' utilities is maximized at NE. In addition, we introduce a FL protocol FedBR-BG that incorporates our budget-balanced mechanism, utilizing best response dynamics. Our empirical validation on MNIST and CIFAR-10 substantiates our theoretical analysis. We show that FedBR-BG outperforms the basic best-response-based protocol without additional incentivization, the standard federated learning protocol FedAvg, as well as a recent baseline MWFed in terms of achieving superior $p$-mean welfare",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dbVRDk2wt7": {
    "title": "Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning",
    "volume": "poster",
    "abstract": "The success of contrastive learning is well known to be dependent on data augmentation. Although the degree of data augmentations has been well controlled by utilizing pre-defined techniques in some domains like vision, time-series data augmentation is less explored and remains a challenging problem due to the complexity of the data generation mechanism, such as the intricate mechanism involved in the cardiovascular system. Moreover, there is no widely recognized and general time-series augmentation method that can be applied across different tasks. In this paper, we propose a novel data augmentation method for time-series tasks that aims to connect intra-class samples together, and thereby find order in the latent space. Our method builds upon the well-known data augmentation technique of mixup by incorporating a novel approach that accounts for the non-stationary nature of time-series data. Also, by controlling the degree of chaos created by data augmentation, our method leads to improved feature representations and performance on downstream tasks. We evaluate our proposed method on three time-series tasks, including heart rate estimation, human activity recognition, and cardiovascular disease detection. Extensive experiments against the state-of-the-art methods show that the proposed method outperforms prior works on optimal data generation and known data augmentation techniques in three tasks, reflecting the effectiveness of the presented method. The source code is available at double-blind policy",
    "checked": true,
    "id": "76314ab64dc3b2f195389b3c87d555b24692fc34",
    "semantic_title": "finding order in chaos: a novel data augmentation method for time series in contrastive learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qVeDwgYsho": {
    "title": "CoPriv: Network/Protocol Co-Optimization for Communication-Efficient Private Inference",
    "volume": "poster",
    "abstract": "Deep neural network (DNN) inference based on secure 2-party computation (2PC) can offer cryptographically-secure privacy protection but suffers from orders of magnitude latency overhead due to enormous communication. Previous works heavily rely on a proxy metric of ReLU counts to approximate the communication overhead and focus on reducing the ReLUs to improve the communication efficiency. However, we observe these works achieve limited communication reduction for state-of-the-art (SOTA) 2PC protocols due to the ignorance of other linear and non-linear operations, which now contribute to the majority of communication. In this work, we present CoPriv, a framework that jointly optimizes the 2PC inference protocol and the DNN architecture. CoPriv features a new 2PC protocol for convolution based on Winograd transformation and develops DNN-aware optimization to significantly reduce the inference communication. CoPriv further develops a 2PC-aware network optimization algorithm that is compatible with the proposed protocol and simultaneously reduces the communication for all the linear and non-linear operations. We compare CoPriv with the SOTA 2PC protocol, CrypTFlow2, and demonstrate 2.1× communication reduction for both ResNet-18 and ResNet-32 on CIFAR-100. We also compare CoPriv with SOTA network optimization methods, including SNL, MetaPruning, etc. CoPriv achieves 9.98× and 3.88× online and total communication reduction with a higher accuracy compare to SNL, respectively. CoPriv also achieves 3.87× online communication reduction with more than 3% higher accuracy compared to MetaPruning",
    "checked": true,
    "id": "4056f1cb8c80365bfd74edd89e1fe42991044acf",
    "semantic_title": "copriv: network/protocol co-optimization for communication-efficient private inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TqW5PL1Poi": {
    "title": "SatLM: Satisfiability-Aided Language Models Using Declarative Prompting",
    "volume": "poster",
    "abstract": "Prior work has combined chain-of-thought prompting in large language models (LLMs) with programmatic representations to perform effective and transparent reasoning. While such an approach works well for tasks that only require forward reasoning (e.g., straightforward arithmetic), it is less effective for constraint solving problems that require more sophisticated planning and search. In this paper, we propose a new satisfiability-aided language modeling (SatLM) approach for improving the reasoning capabilities of LLMs. We use an LLM to generate a declarative task specification rather than an imperative program and leverage an off-the-shelf automated theorem prover to derive the final answer. This approach has two key advantages. The declarative specification is closer to the problem description than the reasoning steps are, so the LLM can parse it out of the description more accurately. Furthermore, by offloading the actual reasoning task to an automated theorem prover, our approach can guarantee the correctness of the answer with respect to the parsed specification and avoid planning errors in the solving process. We evaluate SATLM on 8 different datasets and show that it consistently outperforms program-aided LMs in the imperative paradigm. In particular, SATLM outperforms program-aided LMs by 23% on a challenging subset of the GSM arithmetic reasoning dataset; SATLM also achieves a new SoTA on LSAT and BoardgameQA, surpassing previous models that are trained on the respective training sets",
    "checked": false,
    "id": "f27f6d1d521d189e78f5623098ced0deea613d33",
    "semantic_title": "satisfiability-aided language models using declarative prompting",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=SouroWC5Un": {
    "title": "Robust and Actively Secure Serverless Collaborative Learning",
    "volume": "poster",
    "abstract": "Collaborative machine learning (ML) is widely used to enable institutions to learn better models from distributed data. While collaborative approaches to learning intuitively protect user data, they remain vulnerable to either the server, the clients, or both, deviating from the protocol. Indeed, because the protocol is asymmetric, a malicious server can abuse its power to reconstruct client data points. Conversely, malicious clients can corrupt learning with malicious updates. Thus, both clients and servers require a guarantee when the other cannot be trusted to fully cooperate. In this work, we propose a peer-to-peer (P2P) learning scheme that is secure against malicious servers and robust to malicious clients. Our core contribution is a generic framework that transforms any (compatible) algorithm for robust aggregation of model updates to the setting where servers and clients can act maliciously. Finally, we demonstrate the computational efficiency of our approach even with 1-million parameter models trained by 100s of peers on standard datasets",
    "checked": true,
    "id": "d44ed5a2e13b44b9301c9960532517076d0f0009",
    "semantic_title": "robust and actively secure serverless collaborative learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MXxZ0Z5MNz": {
    "title": "Efficient Training of Energy-Based Models Using Jarzynski Equality",
    "volume": "poster",
    "abstract": "Energy-based models (EBMs) are generative models inspired by statistical physics with a wide range of applications in unsupervised learning. Their performance is well measured by the cross-entropy (CE) of the model distribution relative to the data distribution. Using the CE as the objective for training is however challenging because the computation of its gradient with respect to the model parameters requires sampling the model distribution. Here we show how results for nonequilibrium thermodynamics based on Jarzynski equality together with tools from sequential Monte-Carlo sampling can be used to perform this computation efficiently and avoid the uncontrolled approximations made using the standard contrastive divergence algorithm. Specifically, we introduce a modification of the unadjusted Langevin algorithm (ULA) in which each walker acquires a weight that enables the estimation of the gradient of the cross-entropy at any step during GD, thereby bypassing sampling biases induced by slow mixing of ULA. We illustrate these results with numerical experiments on Gaussian mixture distributions as well as the MNIST and CIFAR-10 datasets. We show that the proposed approach outperforms methods based on the contrastive divergence algorithm in all the considered situations",
    "checked": true,
    "id": "f0ef0711262bf818d49c744f74a9ba3306313956",
    "semantic_title": "efficient training of energy-based models using jarzynski equality",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hzND3ZEFg2": {
    "title": "Learning to Influence Human Behavior with Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "When interacting with people, AI agents do not just influence the state of the world -- they also influence the actions people take in response to the agent, and even their underlying intentions and strategies. Accounting for and leveraging this influence has mostly been studied in settings where it is sufficient to assume that human behavior is near-optimal: competitive games, or general-sum settings like autonomous driving alongside human drivers. Instead, we focus on influence in settings where there is a need to capture human suboptimality. For instance, imagine a collaborative task in which, due either to cognitive biases or lack of information, people do not perform very well -- how could an agent influence them towards more optimal behavior? Assuming near-optimal human behavior will not work here, and so the agent needs to learn from real human data. But experimenting online with humans is potentially unsafe, and creating a high-fidelity simulator of the environment is often impractical. Hence, we focus on learning from an offline dataset of human-human interactions. Our observation is that offline reinforcement learning (RL) can learn to effectively influence suboptimal humans by extending and combining elements of observed human-human behavior. We demonstrate that offline RL can solve two challenges with effective influence. First, we show that by learning from a dataset of suboptimal human-human interaction on a variety of tasks -- none of which contains examples of successful influence -- an agent can learn influence strategies to steer humans towards better performance even on new tasks. Second, we show that by also modeling and conditioning on human behavior, offline RL can learn to affect not just the human's actions but also their underlying strategy, and adapt to changes in their strategy",
    "checked": true,
    "id": "2b62e91ab690a5fbc46fec6e8c39fb9fdb59b579",
    "semantic_title": "learning to influence human behavior with offline reinforcement learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=jcnvDO96N5": {
    "title": "MKOR: Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 Updates",
    "volume": "poster",
    "abstract": "This work proposes a Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 updates, called MKOR, that improves the training time and convergence properties of deep neural networks (DNNs). Second-order techniques, while enjoying higher convergence rates vs first-order counterparts, have cubic complexity with respect to either the model size and/or the training batch size. Hence they exhibit poor scalability and performance in transformer models, e.g. large language models (LLMs), because the batch sizes in these models scale by the attention mechanism sequence length, leading to large model size and batch sizes. MKOR's complexity is quadratic with respect to the model size, alleviating the computation bottlenecks in second-order methods. Because of their high computation complexity, state-of-the-art implementations of second-order methods can only afford to update the second order information infrequently, and thus do not fully exploit the promise of better convergence from these updates. By reducing the communication complexity of the second-order updates as well as achieving a linear communication complexity, MKOR increases the frequency of second order updates. We also propose a hybrid version of MKOR (called MKOR-H) that mid-training falls backs to a first order optimizer if the second order updates no longer accelerate convergence. Our experiments show that MKOR outperforms state -of-the-art first order methods, e.g. the LAMB optimizer, and best implementations of second-order methods, i.e. KAISA/KFAC, up to 2.57x and 1.85x respectively on BERT-Large-Uncased on 64 GPUs",
    "checked": true,
    "id": "2b1c86705e329e80cac96b6bf5df353d079ff10b",
    "semantic_title": "mkor: momentum-enabled kronecker-factor-based optimizer using rank-1 updates",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Y3NjoeO4Q1": {
    "title": "Detection Based Part-level Articulated Object Reconstruction from Single RGBD Image",
    "volume": "poster",
    "abstract": "We propose an end-to-end trainable, cross-category method for reconstructing multiple man-made articulated objects from a single RGBD image, focusing on part-level shape reconstruction and pose and kinematics estimation. We depart from previous works that rely on learning instance-level latent space, focusing on man-made articulated objects with predefined part counts. Instead, we propose a novel alternative approach that employs part-level representation, representing instances as combinations of detected parts. While our detect-then-group approach effectively handles instances with diverse part structures and various part counts, it faces issues of false positives, varying part sizes and scales, and an increasing model size due to end-to-end training. To address these challenges, we propose 1) test-time kinematics-aware part fusion to improve detection performance while suppressing false positives, 2) anisotropic scale normalization for part shape learning to accommodate various part sizes and scales, and 3) a balancing strategy for cross-refinement between feature space and output space to improve part detection while maintaining model size. Evaluation on both synthetic and real data demonstrates that our method successfully reconstructs variously structured multiple instances that previous works cannot handle, and outperforms prior works in shape reconstruction and kinematics estimation",
    "checked": false,
    "id": "13b7073f012a9ee711f0bb8a3914055180db21e9",
    "semantic_title": "saor: single-view articulated object reconstruction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pvSKVt3EsM": {
    "title": "Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask Detection",
    "volume": "poster",
    "abstract": "Anti-spoofing detection has become a necessity for face recognition systems due to the security threat posed by spoofing attacks. Despite great success in traditional attacks, most deep-learning-based methods perform poorly in 3D masks, which can highly simulate real faces in appearance and structure, suffering generalizability insufficiency while focusing only on the spatial domain with single frame input. This has been mitigated by the recent introduction of a biomedical technology called rPPG (remote photoplethysmography). However, rPPG-based methods are sensitive to noisy interference and require at least one second (> 25 frames) of observation time, which induces high computational overhead. To address these challenges, we propose a novel 3D mask detection framework, called FASTEN (Flow-Attention-based Spatio-Temporal aggrEgation Network). We tailor the network for focusing more on fine-grained details in large movements, which can eliminate redundant spatio-temporal feature interference and quickly capture splicing traces of 3D masks in fewer frames. Our proposed network contains three key modules: 1) a facial optical flow network to obtain non-RGB inter-frame flow information; 2) flow attention to assign different significance to each frame; 3) spatio-temporal aggregation to aggregate high-level spatial features and temporal transition features. Through extensive experiments, FASTEN only requires five frames of input and outperforms eight competitors for both intra-dataset and cross-dataset evaluations in terms of multiple detection metrics. Moreover, FASTEN has been deployed in real-world mobile devices for practical 3D mask detection",
    "checked": true,
    "id": "b9997f748ddf3702942d56c8cd0d36e25c47ee8c",
    "semantic_title": "flow-attention-based spatio-temporal aggregation network for 3d mask detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bzXpQUnule": {
    "title": "Federated Linear Bandits with Finite Adversarial Actions",
    "volume": "poster",
    "abstract": "We study a federated linear bandits model, where $M$ clients communicate with a central server to solve a linear contextual bandits problem with finite adversarial action sets that may be different across clients. To address the unique challenges of **adversarial finite** action sets, we propose the FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a total regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm pulls from all clients, and $d$ is the ambient dimension of the linear model. This matches the minimax lower bound and thus is order-optimal (up to polylog terms). We study both asynchronous and synchronous cases and show that the communication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and $O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further extended to two scenarios: (1) variance-adaptive, where a total regret of $\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with $\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial corruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be achieved with $C_p$ being the total corruption budget. Experiment results corroborate the theoretical analysis and demonstrate the effectiveness of \\alg on both synthetic and real-world datasets",
    "checked": true,
    "id": "4b8644c3f155add0938176585c1d00776539ae38",
    "semantic_title": "federated linear bandits with finite adversarial actions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BJ0fQUU32w": {
    "title": "Recommender Systems with Generative Retrieval",
    "volume": "poster",
    "abstract": "Modern recommender systems perform large-scale retrieval by embedding queries and item candidates in the same unified space, followed by approximate nearest neighbor search to select top candidates given a query embedding. In this paper, we propose a novel generative retrieval approach, where the retrieval model autoregressively decodes the identifiers of the target candidates. To that end, we create semantically meaningful tuple of codewords to serve as a Semantic ID for each item. Given Semantic IDs for items in a user session, a Transformer-based sequence-to-sequence model is trained to predict the Semantic ID of the next item that the user will interact with. We show that recommender systems trained with the proposed paradigm significantly outperform the current SOTA models on various datasets. In addition, we show that incorporating Semantic IDs into the sequence-to-sequence model enhances its ability to generalize, as evidenced by the improved retrieval performance observed for items with no prior interaction history",
    "checked": true,
    "id": "a289100678e7d94af836d91cd48d7821ebc5b83d",
    "semantic_title": "recommender systems with generative retrieval",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=jcRB6xHdJ2": {
    "title": "Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions",
    "volume": "poster",
    "abstract": "Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \\geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhance computational efficiency. We illustrate our results numerically with validations on synthetic data, and through an application to neuroimaging data",
    "checked": true,
    "id": "d7764088b516c59ab4efa5f959d6f11bdc7d8adc",
    "semantic_title": "interaction measures, partition lattices and kernel tests for high-order interactions",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=aIpGtPwXny": {
    "title": "Learning to Modulate pre-trained Models in RL",
    "volume": "poster",
    "abstract": "Reinforcement Learning (RL) has been successful in various domains like robotics, game playing, and simulation. While RL agents have shown impressive capabilities in their specific tasks, they insufficiently adapt to new tasks. In supervised learning, this adaptation problem is addressed by large-scale pre-training followed by fine-tuning to new down-stream tasks. Recently, pre-training on multiple tasks has been gaining traction in RL. However, fine-tuning a pre-trained model often suffers from catastrophic forgetting. That is, the performance on the pre-training tasks deteriorates when fine-tuning on new tasks. To investigate the catastrophic forgetting phenomenon, we first jointly pre-train a model on datasets from two benchmark suites, namely Meta-World and DMControl. Then, we evaluate and compare a variety of fine-tuning methods prevalent in natural language processing, both in terms of performance on new tasks, and how well performance on pre-training tasks is retained. Our study shows that with most fine-tuning approaches, the performance on pre-training tasks deteriorates significantly. Therefore, we propose a novel method, Learning-to-Modulate (L2M), that avoids the degradation of learned skills by modulating the information flow of the frozen pre-trained model via a learnable modulation pool. Our method achieves state-of-the-art performance on the Continual-World benchmark, while retaining performance on the pre-training tasks. Finally, to aid future research in this area, we release a dataset encompassing 50 Meta-World and 16 DMControl tasks",
    "checked": true,
    "id": "80543d5e827605d5d42f0af7ea42697e2dd7f62a",
    "semantic_title": "learning to modulate pre-trained models in rl",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=og9V7NgOrQ": {
    "title": "Learning Efficient Coding of Natural Images with Maximum Manifold Capacity Representations",
    "volume": "poster",
    "abstract": "The efficient coding hypothesis proposes that the response properties of sensory systems are adapted to the statistics of their inputs such that they capture maximal information about the environment, subject to biological constraints. While elegant, information theoretic properties are notoriously difficult to measure in practical settings or to employ as objective functions in optimization. This difficulty has necessitated that computational models designed to test the hypothesis employ several different information metrics ranging from approximations and lower bounds to proxy measures like reconstruction error. Recent theoretical advances have characterized a novel and ecologically relevant efficiency metric, the ``manifold capacity,\" which is the number of object categories that may be represented in a linearly separable fashion. However, calculating manifold capacity is a computationally intensive iterative procedure that until now has precluded its use as an objective. Here we outline the simplifying assumptions that allow manifold capacity to be optimized directly, yielding Maximum Manifold Capacity Representations (MMCR). The resulting method is closely related to and inspired by advances in the field of self supervised learning (SSL), and we demonstrate that MMCRs are competitive with state of the art results on standard SSL benchmarks. Empirical analyses reveal differences between MMCRs and representations learned by other SSL frameworks, and suggest a mechanism by which manifold compression gives rise to class separability. Finally we evaluate a set of SSL methods on a suite of neural predicitivity benchmarks, and find MMCRs are higly competitive as models of the ventral stream",
    "checked": true,
    "id": "edcdb546d54bf4305aa853bbdc238227dc6c4740",
    "semantic_title": "learning efficient coding of natural images with maximum manifold capacity representations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=xgTV6rmH6n": {
    "title": "Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks",
    "volume": "poster",
    "abstract": "Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real learning curves from four learning curve benchmarks (LCBench, NAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model architectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets with varying input modalities (tabular, image, text, and protein data). Finally, we investigate its potential in the context of model selection and find that a simple LC-PFN based predictive early stopping criterion obtains 2 - 6x speed-ups on 45 of these datasets, at virtually no overhead",
    "checked": true,
    "id": "19edd41688c844d4ffd5230b417b99b5fd041cf1",
    "semantic_title": "efficient bayesian learning curve extrapolation using prior-data fitted networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=yw1v4RqvPk": {
    "title": "Computing Optimal Equilibria and Mechanisms via Learning in Zero-Sum Extensive-Form Games",
    "volume": "poster",
    "abstract": "We introduce a new approach for computing optimal equilibria via learning in games. It applies to extensive-form settings with any number of players, including mechanism design, information design, and solution concepts such as correlated, communication, and certification equilibria. We observe that optimal equilibria are minimax equilibrium strategies of a player in an extensive-form zero-sum game. This reformulation allows to apply techniques for learning in zero-sum games, yielding the first learning dynamics that converge to optimal equilibria, not only in empirical averages, but also in iterates. We demonstrate the practical scalability and flexibility of our approach by attaining state-of-the-art performance in benchmark tabular games, and by computing an optimal mechanism for a sequential auction design problem using deep reinforcement learning",
    "checked": true,
    "id": "2075f2b11c6f6b72ec968dee74a9cd98266e648c",
    "semantic_title": "computing optimal equilibria and mechanisms via learning in zero-sum extensive-form games",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=eTMHsUp3Ii": {
    "title": "Double Randomized Underdamped Langevin with Dimension-Independent Convergence Guarantee",
    "volume": "poster",
    "abstract": "This paper focuses on the high-dimensional sampling of log-concave distributions with composite structures: $p^*(\\mathrm{d}x)\\propto \\exp(-g(x)-f(x))\\mathrm{d}x$. We develop a double randomization technique, which leads to a fast underdamped Langevin algorithm with a dimension-independent convergence guarantee. We prove that the algorithm enjoys an overall $\\tilde{\\mathcal{O}}\\left(\\frac{\\left(\\mathrm{tr}(H)\\right)^{1/3}}{\\epsilon^{2/3}}\\right)$ iteration complexity to reach an $\\epsilon$-tolerated sample whose distribution $p$ admits $W_2(p,p^*)\\leq \\epsilon$. Here, $H$ is an upper bound of the Hessian matrices for $f$ and does not explicitly depend on dimension $d$. For the posterior sampling over linear models with normalized data, we show a clear superiority of convergence rate which is dimension-free and outperforms the previous best-known results by a $d^{1/3}$ factor. The analysis to achieve a faster convergence rate brings new insights into high-dimensional sampling",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lLztVBaBVU": {
    "title": "PDP: Parameter-free Differentiable Pruning is All You Need",
    "volume": "poster",
    "abstract": "DNN pruning is a popular way to reduce the size of a model, improve the inference latency, and minimize the power consumption on DNN accelerators. However, existing approaches might be too complex, expensive or ineffective to apply to a variety of vision/language tasks, DNN architectures and to honor structured pruning constraints. In this paper, we propose an efficient yet effective train-time pruning scheme, Parameter-free Differentiable Pruning (PDP), which offers state- of-the-art qualities in model size, accuracy, and training cost. PDP uses a dynamic function of weights during training to generate soft pruning masks for the weights in a parameter-free manner for a given pruning target. While differentiable, the simplicity and efficiency of PDP make it universal enough to deliver state-of-the-art random/structured/channel pruning results on various vision and natural language tasks. For example, for MobileNet-v1, PDP can achieve 68.2% top-1 ImageNet1k accuracy at 86.6% sparsity, which is 1.7% higher accuracy than those from the state-of-the-art algorithms. Also, PDP yields over 83.1% accuracy on Multi-Genre Natural Language Inference with 90% sparsity for BERT, while the next best from the existing techniques shows 81.5% accuracy. In addition, PDP can be applied to structured pruning, such as N:M pruning and channel pruning. For 1:4 structured pruning of ResNet18, PDP improved the top-1 ImageNet1k accuracy by over 3.6% over the state-of-the-art. For channel pruning of ResNet50, PDP reduced the top-1 ImageNet1k accuracy by 0.6% from the state-of-the-art",
    "checked": true,
    "id": "c9052f3ccd02c3a841c1ca9ebda6b24dfd847762",
    "semantic_title": "pdp: parameter-free differentiable pruning is all you need",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Lqv7VS1iBF": {
    "title": "Stabilizing the Optimization of Neural Signed Distance Functions and Finer Shape Representation",
    "volume": "poster",
    "abstract": "We present new insights and a novel paradigm for learning implicit neural representations (INR) of shapes. In particular, we shed light on the popular eikonal loss used for imposing a signed distance function constraint in INR. We show analytically that as the representation power of the network increases, the optimization approaches a partial differential equation (PDE) in the continuum limit that is unstable. We show that this instability can manifest in existing network optimization, leading to irregularities in the reconstructed surface and/or convergence to sub-optimal local minima, and thus fails to capture fine geometric and topological structure. We show analytically how other terms added to the loss, currently used in the literature for other purposes, can actually eliminate these instabilities. However, such terms can over-regularize the surface, preventing the representation of fine shape detail. Based on a similar PDE theory for the continuum limit, we introduce a new regularization term that still counteracts the eikonal instability but without over-regularizing. Furthermore, since stability is now guaranteed in the continuum limit, this stabilization also allows for considering new network structures that are able to represent finer shape detail. We introduce such a structure based on quadratic layers. Experiments on multiple benchmark data sets show that our new regularization and network are able to capture more precise shape details and more accurate topology than existing state-of-the-art",
    "checked": false,
    "id": "fbc2a1007fa003265b88707c4926be34b951243f",
    "semantic_title": "steik: stabilizing the optimization of neural signed distance functions and finer shape representation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PR5znB6BZ2": {
    "title": "Efficient Beam Tree Recursion",
    "volume": "poster",
    "abstract": "Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as an extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks. However, although better than previous approaches in terms of memory usage, BT-RvNN can be still exorbitantly expensive. In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function. We propose strategies to remove this bottleneck and further simplify its memory usage. Overall, our strategies not only reduce the memory usage of BT-RvNN by $10-16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks. In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{d}$ into a token contextualizer of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{n \\times d}$. Thus, our proposals not only open up a path for further scalability of RvNNs but also standardize a way to use BT-RvNNs as another building block in the deep learning toolkit that can be easily stacked or interfaced with other popular models such as Transformers and Structured State Space models. Our code is available at the link: https://github.com/JRC1995/BeamRecursionFamily",
    "checked": true,
    "id": "9e3e56957e249cdebdd8673fd1174980ed694560",
    "semantic_title": "efficient beam tree recursion",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=sOOg1xJADA": {
    "title": "Projection-Free Online Convex Optimization via Efficient Newton Iterations",
    "volume": "poster",
    "abstract": "This paper presents new projection-free algorithms for Online Convex Optimization (OCO) over a convex domain $\\mathcal{K} \\subset \\mathbb{R}^d$. Classical OCO algorithms (such as Online Gradient Descent) typically need to perform Euclidean projections onto the convex set $\\mathcal{K}$ to ensure feasibility of their iterates. Alternative algorithms, such as those based on the Frank-Wolfe method, swap potentially-expensive Euclidean projections onto $\\mathcal{K}$ for linear optimization over $\\mathcal{K}$. However, such algorithms have a sub-optimal regret in OCO compared to projection-based algorithms. In this paper, we look at a third type of algorithms that output approximate Newton iterates using a self-concordant barrier for the set of interest. The use of a self-concordant barrier automatically ensures feasibility without the need of projections. However, the computation of the Newton iterates requires a matrix inverse, which can still be expensive. As our main contribution, we show how the stability of the Newton iterates can be leveraged to only compute the inverse Hessian a vanishing fractions of the rounds, leading to a new efficient projection-free OCO algorithm with a state-of-the-art regret bound",
    "checked": true,
    "id": "d67dc1d5259e2846767cdd7c42221c5a22775d32",
    "semantic_title": "projection-free online convex optimization via efficient newton iterations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Ht79ZTVMsn": {
    "title": "Addressing the speed-accuracy simulation trade-off for adaptive spiking neurons",
    "volume": "poster",
    "abstract": "The adaptive leaky integrate-and-fire (ALIF) model is fundamental within computational neuroscience and has been instrumental in studying our brains $\\textit{in silico}$. Due to the sequential nature of simulating these neural models, a commonly faced issue is the speed-accuracy trade-off: either accurately simulate a neuron using a small discretisation time-step (DT), which is slow, or more quickly simulate a neuron using a larger DT and incur a loss in simulation accuracy. Here we provide a solution to this dilemma, by algorithmically reinterpreting the ALIF model, reducing the sequential simulation complexity and permitting a more efficient parallelisation on GPUs. We computationally validate our implementation to obtain over a $50\\times$ training speedup using small DTs on synthetic benchmarks. We also obtained a comparable performance to the standard ALIF implementation on different supervised classification tasks - yet in a fraction of the training time. Lastly, we showcase how our model makes it possible to quickly and accurately fit real electrophysiological recordings of cortical neurons, where very fine sub-millisecond DTs are crucial for capturing exact spike timing",
    "checked": true,
    "id": "eb03c355a3f4eda145cd500779f8b0b449f05f46",
    "semantic_title": "addressing the speed-accuracy simulation trade-off for adaptive spiking neurons",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XWYv4BNShP": {
    "title": "On the Size and Approximation Error of Distilled Datasets",
    "volume": "poster",
    "abstract": "Dataset Distillation is the task of synthesizing small datasets from large ones while still retaining comparable predictive accuracy to the original uncompressed dataset. Despite significant empirical progress in recent years, there is little understanding of the theoretical limitations/guarantees of dataset distillation, specifically, what excess risk is achieved by distillation compared to the original dataset, and how large are distilled datasets? In this work, we take a theoretical view on kernel ridge regression (KRR) based methods of dataset distillation such as Kernel Inducing Points. By transforming ridge regression in random Fourier features (RFF) space, we provide the first proof of the existence of small (size) distilled datasets and their corresponding excess risk for shift-invariant kernels. We prove that a small set of instances exists in the original input space such that its solution in the RFF space coincides with the solution of the original data. We further show that a KRR solution can be generated using this distilled set of instances which gives an approximation towards the KRR solution optimized on the full input data. The size of this set is linear in the dimension of the RFF space of the input set or alternatively near linear in the number of effective degrees of freedom, which is a function of the kernel, number of data points, and the regularization parameter $\\lambda$. The error bound of this distilled set is also a function of $\\lambda$. We verify our bounds analytically and empirically",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LClyG4vZmS": {
    "title": "Cascading Bandits: Optimizing Recommendation Frequency in Delayed Feedback Environments",
    "volume": "poster",
    "abstract": "Delayed feedback is a critical problem in dynamic recommender systems. In practice, the feedback result often depends on the frequency of recommendation. Most existing online learning literature fails to consider optimization of the recommendation frequency, and regards the reward from each successfully recommended message to be equal. In this paper, we consider a novel cascading bandits setting, where individual messages from a selected list are sent to a user periodically. Whenever a user does not like a message, she may abandon the system with a probability positively correlated with the recommendation frequency. A learning agent needs to learn both the underlying message attraction probabilities and users' abandonment probabilities through the randomly delayed feedback. We first show a dynamic programming solution to finding the optimal message sequence in deterministic scenarios, in which the reward is allowed to vary with different messages. Then we propose a polynomial time UCB-based offline learning algorithm, and discuss its performance by characterizing its regret bound. For the online setting, we propose a learning algorithm which allows adaptive content for a given user. Numerical experiment on AmEx dataset confirms the effectiveness of our algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bNXVRJjmOl": {
    "title": "Structured Neural Networks for Density Estimation and Causal Inference",
    "volume": "poster",
    "abstract": "Injecting structure into neural networks enables learning functions that satisfy invariances with respect to subsets of inputs. For instance, when learning generative models using neural networks, it is advantageous to encode the conditional independence structure of observed variables, often in the form of Bayesian networks. We propose the Structured Neural Network (StrNN), which injects structure through masking pathways in a neural network. The masks are designed via a novel relationship we explore between neural network architectures and binary matrix factorization, to ensure that the desired independencies are respected. We devise and study practical algorithms for this otherwise NP-hard design problem based on novel objectives that control the model architecture. We demonstrate the utility of StrNN in three applications: (1) binary and Gaussian density estimation with StrNN, (2) real-valued density estimation with Structured Autoregressive Flows (StrAFs) and Structured Continuous Normalizing Flows (StrCNF), and (3) interventional and counterfactual analysis with StrAFs for causal inference. Our work opens up new avenues for learning neural networks that enable data-efficient generative modeling and the use of normalizing flows for causal effect estimation",
    "checked": true,
    "id": "3c7b35a391190b261705c587d95eefc0b66a9003",
    "semantic_title": "structured neural networks for density estimation and causal inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CniUitfEY3": {
    "title": "Reusable Slotwise Mechanisms",
    "volume": "poster",
    "abstract": "Agents with the ability to comprehend and reason about the dynamics of objects would be expected to exhibit improved robustness and generalization in novel scenarios. However, achieving this capability necessitates not only an effective scene representation but also an understanding of the mechanisms governing interactions among object subsets. Recent studies have made significant progress in representing scenes using object slots. In this work, we introduce Reusable Slotwise Mechanisms, or RSM, a framework that models object dynamics by leveraging communication among slots along with a modular architecture capable of dynamically selecting reusable mechanisms for predicting the future states of each object slot. Crucially, RSM leverages the Central Contextual Information (CCI), enabling selected mechanisms to access the remaining slots through a bottleneck, effectively allowing for modeling of higher order and complex interactions that might require a sparse subset of objects. Experimental results demonstrate the superior performance of RSM compared to state-of-the-art methods across various future prediction and related downstream tasks, including Visual Question Answering and action planning. Furthermore, we showcase RSM's Out-of-Distribution generalization ability to handle scenes in intricate scenarios",
    "checked": true,
    "id": "cf9e6ff7eb6a79e977717efb51444d40d0493fbf",
    "semantic_title": "reusable slotwise mechanisms",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=S75ccNdOYG": {
    "title": "Posterior Sampling for Competitive RL: Function Approximation and Partial Observation",
    "volume": "poster",
    "abstract": "This paper investigates posterior sampling algorithms for competitive reinforcement learning (RL) in the context of general function approximations. Focusing on zero-sum Markov games (MGs) under two critical settings, namely self-play and adversarial learning, we first propose the self-play and adversarial generalized eluder coefficient (GEC) as complexity measures for function approximation, capturing the exploration-exploitation trade-off in MGs. Based on self-play GEC, we propose a model-based self-play posterior sampling method to control both players to learn Nash equilibrium, which can successfully handle the partial observability of states. Furthermore, we identify a set of partially observable MG models fitting MG learning with the adversarial policies of the opponent. Incorporating the adversarial GEC, we propose a model-based posterior sampling method for learning adversarial MG with potential partial observability. We further provide low regret bounds for proposed algorithms that can scale sublinearly with the proposed GEC and the number of episodes $T$. To the best of our knowledge, we for the first time develop generic model-based posterior sampling algorithms for competitive RL that can be applied to a majority of tractable zero-sum MG classes in both fully observable and partially observable MGs with self-play and adversarial learning",
    "checked": true,
    "id": "b24ba4c315e82c080357f20e1c578ad66e9dfa2c",
    "semantic_title": "posterior sampling for competitive rl: function approximation and partial observation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yft4JlxsRf": {
    "title": "A generative model of the hippocampal formation trained with theta driven local learning rules",
    "volume": "poster",
    "abstract": "Advances in generative models have recently revolutionised machine learning. Meanwhile, in neuroscience, generative models have long been thought fundamental to animal intelligence. Understanding the biological mechanisms that support these processes promises to shed light on the relationship between biological and artificial intelligence. In animals, the hippocampal formation is thought to learn and use a generative model to support its role in spatial and non-spatial memory. Here we introduce a biologically plausible model of the hippocampal formation tantamount to a Helmholtz machine that we apply to a temporal stream of inputs. A novel component of our model is that fast theta-band oscillations (5-10 Hz) gate the direction of information flow throughout the network, training it akin to a high-frequency wake-sleep algorithm. Our model accurately infers the latent state of high-dimensional sensory environments and generates realistic sensory predictions. Furthermore, it can learn to path integrate by developing a ring attractor connectivity structure matching previous theoretical proposals and flexibly transfer this structure between environments. Whereas many models trade-off biological plausibility with generality, our model captures a variety of hippocampal cognitive functions under one biologically plausible local learning rule",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tw4QaiiJex": {
    "title": "The Bayesian Stability Zoo",
    "volume": "poster",
    "abstract": "We show that many definitions of stability found in the learning theory literature are equivalent to one another. We distinguish between two families of definitions of stability: distribution-dependent and distribution-independent Bayesian stability. Within each family, we establish equivalences between various definitions, encompassing approximate differential privacy, pure differential privacy, replicability, global stability, perfect generalization, TV stability, mutual information stability, KL-divergence stability, and Rényi-divergence stability. Along the way, we prove boosting results that enable the amplification of the stability of a learning rule. This work is a step towards a more systematic taxonomy of stability notions in learning theory, which can promote clarity and an improved understanding of an array of stability concepts that have emerged in recent years",
    "checked": true,
    "id": "77d9bfab0d0ff418f230e127ba8d0cb19a128e3e",
    "semantic_title": "the bayesian stability zoo",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tW2KSph9o8": {
    "title": "Ignorance is Bliss: Robust Control via Information Gating",
    "volume": "poster",
    "abstract": "Informational parsimony provides a useful inductive bias for learning representations that achieve better generalization by being robust to noise and spurious correlations. We propose *information gating* as a way to learn parsimonious representations that identify the minimal information required for a task. When gating information, we can learn to reveal as little information as possible so that a task remains solvable, or hide as little information as possible so that a task becomes unsolvable. We gate information using a differentiable parameterization of the signal-to-noise ratio, which can be applied to arbitrary values in a network, e.g., erasing pixels at the input layer or activations in some intermediate layer. When gating at the input layer, our models learn which visual cues matter for a given task. When gating intermediate layers, our models learn which activations are needed for subsequent stages of computation. We call our approach *InfoGating*. We apply InfoGating to various objectives such as multi-step forward and inverse dynamics models, Q-learning, and behavior cloning, highlighting how InfoGating can naturally help in discarding information not relevant for control. Results show that learning to identify and use minimal information can improve generalization in downstream tasks. Policies based on InfoGating are considerably more robust to irrelevant visual features, leading to improved pretraining and finetuning of RL models",
    "checked": true,
    "id": "613fc9579505bed343e6381b6fb1c1d8ac9ffa4f",
    "semantic_title": "ignorance is bliss: robust control via information gating",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZmSg4f16uo": {
    "title": "Optimistic Meta-Gradients",
    "volume": "poster",
    "abstract": "We study the connection between gradient-based meta-learning and convex optimisation. We observe that gradient descent with momentum is a special case of meta-gradients, and building on recent results in optimisation, we prove convergence rates for meta learning in the single task setting. While a meta-learned update rule can yield faster convergence up to constant factor, it is not sufficient for acceleration. Instead, some form of optimism is required. We show that optimism in meta-learning can be captured through the recently proposed Bootstrapped Meta-Gradient (Flennerhag et. al., 2022) method, providing deeper insight into its underlying mechanics",
    "checked": true,
    "id": "df05d3d8a3a82edcea13cf0e3be88365a02dc203",
    "semantic_title": "optimistic meta-gradients",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=o6yTKfdnbA": {
    "title": "Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability",
    "volume": "poster",
    "abstract": "Binary Balanced Tree Recursive Neural Networks (BBT-RvNNs) enforce sequence composition according to a preset balanced binary tree structure. Thus, their non-linear recursion depth (which is the tree depth) is just $\\log_2 n$ ($n$ being the sequence length). Such logarithmic scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as Long Range Arena (LRA). However, such computational efficiency comes at a cost because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the flip side, RvNN models (e.g., Beam Tree RvNN) that do succeed on ListOps (and other structure-sensitive tasks like formal logical inference) are generally several times more expensive (in time and space) than even Recurrent Neural Networks. In this paper, we introduce a novel framework --- Recursion in Recursion (RIR) to strike a balance between the two sides - getting some of the benefits from both worlds. In RIR, we use a form of two-level nested recursion - where the outer recursion is a $k$-ary balanced tree model with another recursive model (inner recursion) implementing its cell function. For the inner recursion, we choose Beam Tree RvNNs. To adjust Beam Tree RvNNs within RIR we also propose a novel strategy of beam alignment. Overall, this entails that the total recursive depth in RIR is upper-bounded by $k \\log_k n$. Our best RIR-based model is the first model that demonstrates high ($\\geq 90\\%$) length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA (it can reduce the memory usage of the original Beam Tree RvNN by hundreds of times). Moreover, in terms of accuracy in the LRA language tasks, it performs competitively with Structured State Space Models (SSMs) without any special initialization - outperforming Transformers by a large margin. On the other hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to length-generalize on ListOps. Our code is available at: https://github.com/JRC1995/BeamRecursionFamily/",
    "checked": true,
    "id": "2fc074288f66711e4ee37350d364e74c1c401163",
    "semantic_title": "recursion in recursion: two-level nested recursion for length generalization with scalability",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=aig7sgdRfI": {
    "title": "Learning Mixtures of Gaussians Using the DDPM Objective",
    "volume": "poster",
    "abstract": "Recent works have shown that diffusion models can learn essentially any distribution provided one can perform score estimation. Yet it remains poorly understood under what settings score estimation is possible, let alone when practical gradient-based algorithms for this task can provably succeed. In this work, we give the first provably efficient results for one of the most fundamental distribution families, Gaussian mixture models. We prove that GD on the denoising diffusion probabilistic model (DDPM) objective can efficiently recover the ground truth parameters of the mixture model in the following two settings: 1. We show GD with random initialization learns mixtures of two spherical Gaussians in $d$ dimensions with $1/\\text{poly}(d)$-separated centers. 2. We show GD with a warm start learns mixtures of $K$ spherical Gaussians with $\\Omega(\\sqrt{\\log(\\min(K,d))})$-separated centers. A key ingredient in our proofs is a new connection between score-based methods and two other approaches to distribution learning, EM and spectral methods",
    "checked": true,
    "id": "60eef3b81e50bbd1582bb24fc173f7d93552bb53",
    "semantic_title": "learning mixtures of gaussians using the ddpm objective",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=djyn8Q0anK": {
    "title": "Scalable Transformer for PDE Surrogate Modeling",
    "volume": "poster",
    "abstract": "Transformer has shown state-of-the-art performance on various applications and has recently emerged as a promising tool for surrogate modeling of partial differential equations (PDEs). Despite the introduction of linear-complexity attention, applying Transformer to problems with a large number of grid points can be numerically unstable and computationally expensive. In this work, we propose Factorized Transformer (FactFormer), which is based on an axial factorized kernel integral. Concretely, we introduce a learnable projection operator that decomposes the input function into multiple sub-functions with one-dimensional domain. These sub-functions are then evaluated and used to compute the instance-based kernel with an axial factorized scheme. We showcase that the proposed model is able to simulate 2D Kolmogorov flow on a $256\\times 256$ grid and 3D smoke buoyancy on a $64\\times64\\times64$ grid with good accuracy and efficiency. The proposed factorized scheme can serve as a computationally efficient low-rank surrogate for the full attention scheme when dealing with multi-dimensional problems",
    "checked": true,
    "id": "a4a2326cf7f16ea0988ffc65eabf48ffe47c432f",
    "semantic_title": "scalable transformer for pde surrogate modeling",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=AwzbQVuDBk": {
    "title": "ProteinNPT: Improving protein property prediction and design with non-parametric transformers",
    "volume": "poster",
    "abstract": "Protein design holds immense potential for optimizing naturally occurring sequences, with broad applications in drug discovery, material design, and sustainability. However, computational methods for protein engineering are confronted with significant challenges, including an expansive design space, sparse functional regions, and scarcity of available labels. Furthermore, real-life design scenarios often necessitate the simultaneous optimization of multiple properties, exacerbating label sparsity issues. In this paper, we present ProteinNPT, a non-parametric transformer variant tailored for protein sequences and particularly suited to label-scarce and multi-task optimization settings. We first expand the ProteinGym benchmark to evaluate models in supervised settings and develop several cross-validation schemes for robust assessment. Subsequently, we reimplement existing top-performing baselines, introduce several extensions of these baselines by integrating diverse branches of protein engineering literature, and demonstrate that ProteinNPT consistently outperforms all of them across a diverse set of protein property prediction tasks. Finally, we demonstrate the value of our approach for iterative protein design in several in silico Bayesian optimization experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YPHIrNKI0d": {
    "title": "Spatio-Angular Convolutions for Super-resolution in Diffusion MRI",
    "volume": "poster",
    "abstract": "Diffusion MRI (dMRI) is a widely used imaging modality, but requires long scanning times to acquire high resolution datasets. By leveraging the unique geometry present within this domain, we present a novel approach to dMRI angular super-resolution that extends upon the parametric continuous convolution (PCConv) framework. We introduce several additions to the operation including a Fourier feature mapping, 'global' co-ordinates, and domain specific context. Using this framework, we build a fully parametric continuous convolution network (PCCNN) and compare against existing models. We demonstrate the PCCNN performs competitively while using significantly fewer parameters. Moreover, we show that this formulation generalises well to clinically relevant downstream analyses such as fixel-based analysis, and neurite orientation dispersion and density imaging",
    "checked": true,
    "id": "73bca8ca381cab3668339e902f04244e0cdfb6d6",
    "semantic_title": "spatio-angular convolutions for super-resolution in diffusion mri",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=noyleECBam": {
    "title": "Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits",
    "volume": "poster",
    "abstract": "Off-Policy Evaluation (OPE) in contextual bandits is crucial for assessing new policies using existing data without costly experimentation. However, current OPE methods, such as Inverse Probability Weighting (IPW) and Doubly Robust (DR) estimators, suffer from high variance, particularly in cases of low overlap between target and behaviour policies or large action and context spaces. In this paper, we introduce a new OPE estimator for contextual bandits, the Marginal Ratio (MR) estimator, which focuses on the shift in the marginal distribution of outcomes $Y$ instead of the policies themselves. Through rigorous theoretical analysis, we demonstrate the benefits of the MR estimator compared to conventional methods like IPW and DR in terms of variance reduction. Additionally, we establish a connection between the MR estimator and the state-of-the-art Marginalized Inverse Propensity Score (MIPS) estimator, proving that MR achieves lower variance among a generalized family of MIPS estimators. We further illustrate the utility of the MR estimator in causal inference settings, where it exhibits enhanced performance in estimating Average Treatment Effects (ATE). Our experiments on synthetic and real-world datasets corroborate our theoretical findings and highlight the practical advantages of the MR estimator in OPE for contextual bandits",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0OU1ZXXxs5": {
    "title": "Pruning vs Quantization: Which is Better?",
    "volume": "poster",
    "abstract": "Neural network pruning and quantization techniques are almost as old as neural networks themselves. However, to date, only ad-hoc comparisons between the two have been published. In this paper, we set out to answer the question of which is better: neural network quantization or pruning? By answering this question, we hope to inform design decisions made on neural network hardware going forward. We provide an extensive comparison between the two techniques for compressing deep neural networks. First, we give an analytical comparison of expected quantization and pruning error for general data distributions. Then, we provide lower and upper bounds for the per-layer pruning and quantization error in trained networks and compare these to empirical error after optimization. Finally, we provide an extensive experimental comparison for training 8 large-scale models trained on 3 tasks and provide insights into the representations learned during fine-tuning with quantization and pruning in the loop. Our results show that in most cases quantization outperforms pruning. Only in some scenarios with a very high compression ratio, compression might be beneficial from an accuracy standpoint",
    "checked": true,
    "id": "a9f1026e426c1067a1943e5eee2ea2aff50abf4c",
    "semantic_title": "pruning vs quantization: which is better?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zmWNe1V6jg": {
    "title": "Scalable Fair Influence Maximization",
    "volume": "poster",
    "abstract": "Given a graph $G$, a community structure $\\mathcal{C}$, and a budget $k$, the fair influence maximization problem aims to select a seed set $S$ ($|S|\\leq k$) that maximizes the influence spread while narrowing the influence gap between different communities. While various fairness notions exist, the welfare fairness notion, which balances fairness level and influence spread, has shown promising effectiveness. However, the lack of efficient algorithms for optimizing the welfare fairness objective function restricts its application to small-scale networks with only a few hundred nodes. In this paper, we adopt the objective function of welfare fairness to maximize the exponentially weighted summation over the influenced fraction of all communities. We first introduce an unbiased estimator for the fractional power of the arithmetic mean. Then, by adapting the reverse influence sampling (RIS) approach, we convert the optimization problem to a weighted maximum coverage problem. We also analyze the number of reverse reachable sets needed to approximate the fair influence at a high probability. Further, we present an efficient algorithm that guarantees $1-1/e - \\varepsilon$ approximation",
    "checked": true,
    "id": "e5e91c6c9dac1e3d8544bb62b0b3b2bc0818a463",
    "semantic_title": "scalable fair influence maximization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yc9bqbnrbs": {
    "title": "Fast and Regret Optimal Best Arm Identification: Fundamental Limits and Low-Complexity Algorithms",
    "volume": "poster",
    "abstract": "This paper considers a stochastic Multi-Armed Bandit (MAB) problem with dual objectives: (i) quick identification and commitment to the optimal arm, and (ii) reward maximization throughout a sequence of $T$ consecutive rounds. Though each objective has been individually well-studied, i.e., best arm identification for (i) and regret minimization for (ii), the simultaneous realization of both objectives remains an open problem, despite its practical importance. This paper introduces \\emph{Regret Optimal Best Arm Identification} (ROBAI) which aims to achieve these dual objectives. To solve ROBAI with both pre-determined stopping time and adaptive stopping time requirements, we present an algorithm called EOCP and its variants respectively, which not only achieve asymptotic optimal regret in both Gaussian and general bandits, but also commit to the optimal arm in $\\mathcal{O}(\\log T)$ rounds with pre-determined stopping time and $\\mathcal{O}(\\log^2 T)$ rounds with adaptive stopping time. We further characterize lower bounds on the commitment time (equivalent to the sample complexity) of ROBAI, showing that EOCP and its variants are sample optimal with pre-determined stopping time, and almost sample optimal with adaptive stopping time. Numerical results confirm our theoretical analysis and reveal an interesting ``over-exploration'' phenomenon carried by classic UCB algorithms, such that EOCP has smaller regret even though it stops exploration much earlier than UCB, i.e., $\\mathcal{O}(\\log T)$ versus $\\mathcal{O}(T)$, which suggests over-exploration is unnecessary and potentially harmful to system performance",
    "checked": true,
    "id": "b85f16e0a89ad64afc29af407b8026b6329f039d",
    "semantic_title": "fast and regret optimal best arm identification: fundamental limits and low-complexity algorithms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nQ84YY9Iut": {
    "title": "Multiclass Boosting: Simple and Intuitive Weak Learning Criteria",
    "volume": "poster",
    "abstract": "We study a generalization of boosting to the multiclass setting. We introduce a weak learning condition for multiclass classification that captures the original notion of weak learnability as being \"slightly better than random guessing\". We give a simple and efficient boosting algorithm, that does not require realizability assumptions and its sample and oracle complexity bounds are independent of the number of classes. In addition, we utilize our new boosting technique in several theoretical applications within the context of List PAC Learning. First, we establish an equivalence to weak PAC learning. Furthermore, we present a new result on boosting for list learners, as well as provide a novel proof for the characterization of multiclass PAC learning and List PAC learning. Notably, our technique gives rise to simplified algorithms and analysis compared to previous works",
    "checked": true,
    "id": "9dabf2ab96e242975b5a6c76b870071c39df12fa",
    "semantic_title": "multiclass boosting: simple and intuitive weak learning criteria",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7p5YWe8GqG": {
    "title": "MeGraph: Capturing Long-Range Interactions by Alternating Local and Hierarchical Aggregation on Multi-Scaled Graph Hierarchy",
    "volume": "poster",
    "abstract": "Graph neural networks, which typically exchange information between local neighbors, often struggle to capture long-range interactions (LRIs) within the graph. Building a graph hierarchy via graph pooling methods is a promising approach to address this challenge; however, hierarchical information propagation cannot entirely take over the role of local information aggregation. To balance locality and hierarchy, we integrate the local and hierarchical structures, represented by intra- and inter-graphs respectively, of a multi-scale graph hierarchy into a single mega graph. Our proposed MeGraph model consists of multiple layers alternating between local and hierarchical information aggregation on the mega graph. Each layer first performs local-aware message-passing on graphs of varied scales via the intra-graph edges, then fuses information across the entire hierarchy along the bidirectional pathways formed by inter-graph edges. By repeating this fusion process, local and hierarchical information could intertwine and complement each other. To evaluate our model, we establish a new Graph Theory Benchmark designed to assess LRI capture ability, in which MeGraph demonstrates dominant performance. Furthermore, MeGraph exhibits superior or equivalent performance to state-of-the-art models on the Long Range Graph Benchmark. The experimental results on commonly adopted real-world datasets further demonstrate the broad applicability of MeGraph",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xWCp0uLcpG": {
    "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy",
    "volume": "poster",
    "abstract": "Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy and generalization performance. Extensive experiments on four real and one synthetic noisy datasets show that Prune4Rel outperforms the baselines with Re-labeling models by up to 9.1% as well as those with a standard model by up to 21.6%",
    "checked": true,
    "id": "ca622fde1f31e86a3328504c17605298c6129414",
    "semantic_title": "robust data pruning under label noise via maximizing re-labeling accuracy",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=VLnEFGu9V7": {
    "title": "Regret Minimization via Saddle Point Optimization",
    "volume": "poster",
    "abstract": "A long line of works characterizes the sample complexity of regret minimization in sequential decision-making by min-max programs. In the corresponding saddle-point game, the min-player optimizes the sampling distribution against an adversarial max-player that chooses confusing models leading to large regret. The most recent instantiation of this idea is the decision-estimation coefficient (DEC), which was shown to provide nearly tight lower and upper bounds on the worst-case expected regret in structured bandits and reinforcement learning. By re-parametrizing the offset DEC with the confidence radius and solving the corresponding min-max program, we derive an anytime variant of the Estimation-To-Decisions algorithm (Anytime-E2D). Importantly, the algorithm optimizes the exploration-exploitation trade-off online instead of via the analysis. Our formulation leads to a practical algorithm for finite model classes and linear feedback models. We illustrate the results by deriving improved rates for high-dimensional linear bandits. Lastly, we point out connections to the information ratio, decoupling coefficient and PAC-DEC, and numerically evaluate the performance of E2D on simple examples",
    "checked": false,
    "id": "cbf5398e835f2fd198cfba4ab8bf42caa966c45f",
    "semantic_title": "robust bond portfolio construction via convex-concave saddle point optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NsVEjx6YPd": {
    "title": "Reverse Engineering Self-Supervised Learning",
    "volume": "poster",
    "abstract": "Understanding the learned representation and underlying mechanisms of Self-Supervised Learning (SSL) often poses a challenge. In this paper, we ‘reverse engineer' SSL, conducting an in-depth empirical analysis of its learned internal representations, encompassing diverse models, architectures, and hyperparameters. Our study reveals an intriguing process within the SSL training: an inherent facilitation of semantic label-based clustering, which is surprisingly driven by the regularization component of the SSL objective. This clustering not only enhances downstream classification, but also compresses the information. We further illustrate that the alignment of the SSL-trained representation is more pronounced with semantic classes rather than random functions. Remarkably, the learned representations align with semantic classes across various hierarchical levels, with this alignment intensifying when going deeper into the network. This ‘reverse engineering' approach provides valuable insights into the inner mechanism of SSL and their influences on the performance across different class sets",
    "checked": true,
    "id": "a2b8ff257658b8291deb9e40ec1c164c8fefeb06",
    "semantic_title": "reverse engineering self-supervised learning",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Ay3WvSrtpO": {
    "title": "Model-Free Reinforcement Learning with the Decision-Estimation Coefficient",
    "volume": "poster",
    "abstract": "We consider the problem of interactive decision making, encompassing structured bandits and reinforcement learning with general function approximation. Recently, Foster et al. (2021) introduced the Decision-Estimation Coefficient, a measure of statistical complexity that lower bounds the optimal regret for interactive decision making, as well as a meta-algorithm, Estimation-to-Decisions, which achieves upper bounds in terms of the same quantity. Estimation-to-Decisions is a reduction, which lifts algorithms for (supervised) online estimation into algorithms for decision making. In this paper, we show that by combining Estimation-to-Decisions with a specialized form of \"optimistic\" estimation introduced by Zhang (2022), it is possible to obtain guarantees that improve upon those of Foster et al. (2021) by accommodating more lenient notions of estimation error. We use this approach to derive regret bounds for model-free reinforcement learning with value function approximation, and give structural results showing when it can and cannot help more generally",
    "checked": true,
    "id": "b4698d868a31d48421d53b016f49677da53d5cba",
    "semantic_title": "model-free reinforcement learning with the decision-estimation coefficient",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=A18PgVSUgf": {
    "title": "Accelerating Molecular Graph Neural Networks via Knowledge Distillation",
    "volume": "poster",
    "abstract": "Recent advances in graph neural networks (GNNs) have enabled more comprehensive modeling of molecules and molecular systems, thereby enhancing the precision of molecular property prediction and molecular simulations. Nonetheless, as the field has been progressing to bigger and more complex architectures, state-of-the-art GNNs have become largely prohibitive for many large-scale applications. In this paper, we explore the utility of knowledge distillation (KD) for accelerating molecular GNNs. To this end, we devise KD strategies that facilitate the distillation of hidden representations in directional and equivariant GNNs, and evaluate their performance on the regression task of energy and force prediction. We validate our protocols across different teacher-student configurations and datasets, and demonstrate that they can consistently boost the predictive accuracy of student models without any modifications to their architecture. Moreover, we conduct comprehensive optimization of various components of our framework, and investigate the potential of data augmentation to further enhance performance. All in all, we manage to close the gap in predictive accuracy between teacher and student models by as much as 96.7\\% and 62.5\\% for energy and force prediction respectively, while fully preserving the inference throughput of the more lightweight models",
    "checked": true,
    "id": "0aa2cdc4c1f7c8d2aedc9b739272ba1d3bd4b9e7",
    "semantic_title": "accelerating molecular graph neural networks via knowledge distillation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=RZGtK2nDDJ": {
    "title": "Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder",
    "volume": "poster",
    "abstract": "Despite its practical importance across a wide range of modalities, recent advances in self-supervised learning (SSL) have been primarily focused on a few well-curated domains, e.g., vision and language, often relying on their domain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become one of the popular architectures in these domains, but less has explored its potential in other modalities. In this paper, we develop MAE as a unified, modality-agnostic SSL framework. In turn, we argue meta-learning as a key to interpreting MAE as a modality-agnostic learner, and propose enhancements to MAE from the motivation to jointly improve its SSL across diverse modalities, coined MetaMAE as a result. Our key idea is to view the mask reconstruction of MAE as a meta-learning task: masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens. Based on this novel interpretation, we propose to integrate two advanced meta-learning techniques. First, we adapt the amortized latent of the Transformer encoder using gradient-based meta-learning to enhance the reconstruction. Then, we maximize the alignment between amortized and adapted latents through task contrastive learning which guides the Transformer encoder to better encode the task-specific knowledge. Our experiment demonstrates the superiority of MetaMAE in the modality-agnostic SSL benchmark (called DABS), significantly outperforming prior baselines",
    "checked": true,
    "id": "3f12da8f29e89579f5c133567955bbc9485bd9ec",
    "semantic_title": "modality-agnostic self-supervised learning with meta-learned masked auto-encoder",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gPylY8sCbw": {
    "title": "Partial Matrix Completion",
    "volume": "poster",
    "abstract": "The matrix completion problem involves reconstructing a low-rank matrix by using a given set of revealed (and potentially noisy) entries. Although existing methods address the completion of the entire matrix, the accuracy of the completed entries can vary significantly across the matrix, due to differences in the sampling distribution. For instance, users may rate movies primarily from their country or favorite genres, leading to inaccurate predictions for the majority of completed entries. We propose a novel formulation of the problem as Partial Matrix Completion, where the objective is to complete a substantial subset of the entries with high confidence. Our algorithm efficiently handles the unknown and arbitrarily complex nature of the sampling distribution, ensuring high accuracy for all completed entries and sufficient coverage across the matrix. Additionally, we introduce an online version of the problem and present a low-regret efficient algorithm based on iterative gradient updates. Finally, we conduct a preliminary empirical evaluation of our methods",
    "checked": true,
    "id": "d7c39e86100764d02dc87e56d0b9a614642ec3d0",
    "semantic_title": "partial matrix completion",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=6MQ5cheYDZ": {
    "title": "Decision-Aware Actor-Critic with Function Approximation and Theoretical Guarantees",
    "volume": "poster",
    "abstract": "Actor-critic (AC) methods are widely used in reinforcement learning (RL), and benefit from the flexibility of using any policy gradient method as the actor and value-based method as the critic. The critic is usually trained by minimizing the TD error, an objective that is potentially decorrelated with the true goal of achieving a high reward with the actor. We address this mismatch by designing a joint objective for training the actor and critic in a decision-aware fashion. We use the proposed objective to design a generic, AC algorithm that can easily handle any function approximation. We explicitly characterize the conditions under which the resulting algorithm guarantees monotonic policy improvement, regardless of the choice of the policy and critic parameterization. Instantiating the generic algorithm results in an actor that involves maximizing a sequence of surrogate functions (similar to TRPO, PPO), and a critic that involves minimizing a closely connected objective. Using simple bandit examples, we provably establish the benefit of the proposed critic objective over the standard squared error. Finally, we empirically demonstrate the benefit of our decision-aware actor-critic framework on simple RL problems",
    "checked": true,
    "id": "fe6be96be8d023a026f7754c8421fb3c3c6a72eb",
    "semantic_title": "decision-aware actor-critic with function approximation and theoretical guarantees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E3ZUEaeFYS": {
    "title": "Strategic Distribution Shift of Interacting Agents via Coupled Gradient Flows",
    "volume": "poster",
    "abstract": "We propose a novel framework for analyzing the dynamics of distribution shift in real-world systems that captures the feedback loop between learning algorithms and the distributions on which they are deployed. Prior work largely models feedback-induced distribution shift as adversarial or via an overly simplistic distribution-shift structure. In contrast, we propose a coupled partial differential equation model that captures fine-grained changes in the distribution over time by accounting for complex dynamics that arise due to strategic responses to algorithmic decision-making, non-local endogenous population interactions, and other exogenous sources of distribution shift. We consider two common settings in machine learning: cooperative settings with information asymmetries, and competitive settings where a learner faces strategic users. For both of these settings, when the algorithm retrains via gradient descent, we prove asymptotic convergence of the retraining procedure to a steady-state, both in finite and in infinite dimensions, obtaining explicit rates in terms of the model parameters. To do so we derive new results on the convergence of coupled PDEs that extends what is known on multi-species systems. Empirically, we show that our approach captures well-documented forms of distribution shifts like polarization and disparate impacts that simpler models cannot capture",
    "checked": true,
    "id": "6ea73db959517dcaae96075276f8970411123b9a",
    "semantic_title": "strategic distribution shift of interacting agents via coupled gradient flows",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MWxsYPVmLS": {
    "title": "Explainable and Efficient Randomized Voting Rules",
    "volume": "poster",
    "abstract": "With a rapid growth in the deployment of AI tools for making critical decisions (or aiding humans in doing so), there is a growing demand to be able to explain to the stakeholders how these tools arrive at a decision. Consequently, voting is frequently used to make such decisions due to its inherent explainability. Recent work suggests that using randomized (as opposed to deterministic) voting rules can lead to significant efficiency gains measured via the distortion framework. However, rules that use intricate randomization can often become too complex to explain to the stakeholders; losing explainability can eliminate the key advantage of voting over black-box AI tools, which may outweigh the efficiency gains. We study the efficiency gains which can be unlocked by using voting rules that add a simple randomization step to a deterministic rule, thereby retaining explainability. We focus on two such families of rules, randomized positional scoring rules and random committee member rules, and show, theoretically and empirically, that they indeed achieve explainability and efficiency simultaneously to some extent",
    "checked": true,
    "id": "3f562dea2d5c9e1b08dd3aebe0cbbc79c04244d1",
    "semantic_title": "explainable and efficient randomized voting rules",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NEawU0TgKG": {
    "title": "Frequency Domain-Based Dataset Distillation",
    "volume": "poster",
    "abstract": "This paper presents FreD, a novel parameterization method for dataset distillation, which utilizes the frequency domain to distill a small-sized synthetic dataset from a large-sized original dataset. Unlike conventional approaches that focus on the spatial domain, FreD employs frequency-based transforms to optimize the frequency representations of each data instance. By leveraging the concentration of spatial domain information on specific frequency components, FreD intelligently selects a subset of frequency dimensions for optimization, leading to a significant reduction in the required budget for synthesizing an instance. Through the selection of frequency dimensions based on the explained variance, FreD demonstrates both theoretical and empirical evidence of its ability to operate efficiently within a limited budget, while better preserving the information of the original dataset compared to conventional parameterization methods. Furthermore, Based on the orthogonal compatibility of FreD with existing methods, we confirm that FreD consistently improves the performances of existing distillation methods over the evaluation scenarios with different benchmark datasets. We release the code at https://github.com/sdh0818/FreD",
    "checked": true,
    "id": "f2f1265458df97ea67dcea66b5d763087e7ef006",
    "semantic_title": "frequency domain-based dataset distillation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ia4AL3QnOv": {
    "title": "Similarity-based cooperative equilibrium",
    "volume": "poster",
    "abstract": "As machine learning agents act more autonomously in the world, they will increasingly interact with each other. Unfortunately, in many social dilemmas like the one-shot Prisoner's Dilemma, standard game theory predicts that ML agents will fail to cooperate with each other. Prior work has shown that one way to enable cooperative outcomes in the one-shot Prisoner's Dilemma is to make the agents mutually transparent to each other, i.e., to allow them to access one another's source code (Rubinstein, 1998; Tennenholtz, 2004) – or weights in the case of ML agents. However, full transparency is often unrealistic, whereas partial transparency is commonplace. Moreover, it is challenging for agents to learn their way to cooperation in the full transparency setting. In this paper, we introduce a more realistic setting in which agents only observe a single number indicating how similar they are to each other. We prove that this allows for the same set of cooperative outcomes as the full transparency setting. We also demonstrate experimentally that cooperation can be learned using simple ML methods",
    "checked": true,
    "id": "435dbef1d60cf2bf282b2b139703fd1609ad0a81",
    "semantic_title": "similarity-based cooperative equilibrium",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=GItLpB1vhK": {
    "title": "Estimating Koopman operators with sketching to provably learn large scale dynamical systems",
    "volume": "poster",
    "abstract": "The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems. Estimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. Scaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. In this paper, we boost the efficiency of different kernel-based Koopman operator estimators using random projections (sketching). We derive, implement and test the new ``sketched'' estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. Further, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency. Our empirical and theoretical analysis shows that the proposed estimators provide a sound and efficient way to learn large scale dynamical systems. In particular our experiments indicate that the proposed estimators retain the same accuracy of PCR or RRR, while being much faster",
    "checked": true,
    "id": "ede13930637701d839b2402ea2fd2a723e74e0d5",
    "semantic_title": "estimating koopman operators with sketching to provably learn large scale dynamical systems",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=iGmDQn4CRj": {
    "title": "Simplifying Neural Network Training Under Class Imbalance",
    "volume": "poster",
    "abstract": "Real-world datasets are often highly class-imbalanced, which can adversely impact the performance of deep learning models. The majority of research on training neural networks under class imbalance has focused on specialized loss functions and sampling techniques. Notably, we demonstrate that simply tuning existing components of standard deep learning pipelines, such as the batch size, data augmentation, architecture size, pre-training, optimizer, and label smoothing, can achieve state-of-the-art performance without any specialized loss functions or samplers. We also provide key prescriptions and considerations for training under class imbalance, and an understanding of why imbalance methods succeed or fail",
    "checked": false,
    "id": "4f3ba371500d706ea056a3e24926e2a772628972",
    "semantic_title": "constrained optimization for training deep neural networks under class imbalance",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=ubap5FKbJs": {
    "title": "Domain Agnostic Fourier Neural Operators",
    "volume": "poster",
    "abstract": "Fourier neural operators (FNOs) can learn highly nonlinear mappings between function spaces, and have recently become a popular tool for learning responses of complex physical systems. However, to achieve good accuracy and efficiency, FNOs rely on the Fast Fourier transform (FFT), which is restricted to modeling problems on rectangular domains. To lift such a restriction and permit FFT on irregular geometries as well as topology changes, we introduce domain agnostic Fourier neural operator (DAFNO), a novel neural operator architecture for learning surrogates with irregular geometries and evolving domains. The key idea is to incorporate a smoothed characteristic function in the integral layer architecture of FNOs, and leverage FFT to achieve rapid computations, in such a way that the geometric information is explicitly encoded in the architecture. In our empirical evaluation, DAFNO has achieved state-of-the-art accuracy as compared to baseline neural operator models on two benchmark datasets of material modeling and airfoil simulation. To further demonstrate the capability and generalizability of DAFNO in handling complex domains with topology changes, we consider a brittle material fracture evolution problem. With only one training crack simulation sample, DAFNO has achieved generalizability to unseen loading scenarios and substantially different crack patterns from the trained scenario. Our code and data accompanying this paper are available at https://github.com/ningliu-iga/DAFNO",
    "checked": true,
    "id": "65c7aaf5b8d108b003074fbb8d15bc1f1a001aa6",
    "semantic_title": "domain agnostic fourier neural operators",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=cGeLeh995N": {
    "title": "On the Role of Entanglement and Statistics in Learning",
    "volume": "poster",
    "abstract": "In this work we make progress in understanding the relationship between learning models when given access to entangled measurements, separable measurements and statistical measurements in the quantum statistical query ($\\mathsf{QSQ}$) model. To this end, we show the following results. $\\textbf{Entanglement versus separable measurements.}$ The goal here is to learn an unknown $f$ from the concept class $\\mathcal{C} \\subseteq \\{f:\\{0,1\\}^n\\rightarrow [k]\\}$ given copies of $\\frac{1}{\\sqrt{2^n}}\\sum_x \\ket{x,f(x)}$. We show that, if $T$ copies suffice to learn $f$ using entangled measurements, then $O(nT^2)$ copies suffice to learn $f$ using just separable measurements. Additionally, we exhibit a concept class $\\mathcal{C}$ for which, in order to learn some \\emph{property} of $f$, the sample complexity of learning using entangled measurements is exponentially smaller than separable measurements. $\\textbf{Entangled versus statistical measurements}$ The goal here is to learn a function $f \\in \\mathcal{C}$ given access to separable measurements and statistical measurements. We exhibit a concept class $\\mathcal{C}$ based on degree-$2$ functions that gives an exponential separation between $\\mathsf{QSQ}$ learning and quantum learning with entangled measurements (even in the presence of noise). This proves the \"quantum analogue\" of the seminal result of (Blum, 2003) that separates classical $\\mathsf{SQ}$ learning from classical $\\mathsf{PAC}$ learning with classification~noise. $\\textbf{$\\mathsf{QSQ}$ lower bounds for learning states.}$ The main technical contribution is to introduce a quantum statistical query dimension ($\\mathsf{QSDA}$), which we use to give lower bounds on the $\\mathsf{QSQ}$ complexity of learning. Using this, we prove exponential $\\mathsf{QSQ}$ lower bounds for testing purity of quantum states, learning CCHL states, coset states of Abelian groups, degree-$2$ functions, planted bi-clique states and learning output states of Clifford circuits of depth polylog($n$). $\\textbf{Further applications.}$ Using our $\\mathsf{QSQ}$ lower bounds give an $\\textit{unconditional}$ separation between weak and strong error mitigation and prove lower bounds for learning distributions in the $\\mathsf{QSQ}$ model. Prior works by (Quek et al., 2022), (Hinsche et al., 2022), and (Neitner et al., 23) proved the analogous results $\\textit{assuming}$ diagonal measurements and our work removes this assumption",
    "checked": true,
    "id": "ad53a3b24e7cfb96a593ea53b510d5fc581f75c3",
    "semantic_title": "on the role of entanglement and statistics in learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Rs6pzz21U4": {
    "title": "A Partially-Supervised Reinforcement Learning Framework for Visual Active Search",
    "volume": "poster",
    "abstract": "Visual active search (VAS) has been proposed as a modeling framework in which visual cues are used to guide exploration, with the goal of identifying regions of interest in a large geospatial area. Its potential applications include identifying hot spots of rare wildlife poaching activity, search-and-rescue scenarios, identifying illegal trafficking of weapons, drugs, or people, and many others. State of the art approaches to VAS include applications of deep reinforcement learning (DRL), which yield end-to-end search policies, and traditional active search, which combines predictions with custom algorithmic approaches. While the DRL framework has been shown to greatly outperform traditional active search in such domains, its end-to-end nature does not make full use of supervised information attained either during training, or during actual search, a significant limitation if search tasks differ significantly from those in the training distribution. We propose an approach that combines the strength of both DRL and conventional active search approaches by decomposing the search policy into a prediction module, which produces a geospatial distribution of regions of interest based on task embedding and search history, and a search module, which takes the predictions and search history as input and outputs the search distribution. In addition, we develop a novel meta-learning approach for jointly learning the resulting combined policy that can make effective use of supervised information obtained both at training and decision time. Our extensive experiments demonstrate that the proposed representation and meta-learning frameworks significantly outperform state of the art in visual active search on several problem domains",
    "checked": false,
    "id": "b09e54855068d0a1c7e3fea28b3eda56b8ccb27c",
    "semantic_title": "a partially supervised reinforcement learning framework for visual active search",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XH3ArccntI": {
    "title": "Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise",
    "volume": "poster",
    "abstract": "Standard diffusion models involve an image transform -- adding Gaussian noise -- and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact, an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community's understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference and paves the way for generalized diffusion models that invert arbitrary processes",
    "checked": true,
    "id": "525f459f369032e2f2fa3eb1d60da34ab99191bc",
    "semantic_title": "cold diffusion: inverting arbitrary image transforms without noise",
    "citation_count": 118,
    "authors": []
  },
  "https://openreview.net/forum?id=u359tNBpxF": {
    "title": "Robust Data Valuation with Weighted Banzhaf Values",
    "volume": "poster",
    "abstract": "Data valuation, a principled way to rank the importance of each training datum, has become increasingly important. However, existing value-based approaches (e.g., Shapley) are known to suffer from the stochasticity inherent in utility functions that render consistent and reliable ranking difficult. Recently, Wang and Jia (2023) proposed the noise-structure-agnostic framework to advocate the Banzhaf value for its robustness against such stochasticity as it achieves the largest safe margin among many alternatives. Surprisingly, our empirical study shows that the Banzhaf value is not always the most robust when compared with a broader family: weighted Banzhaf values. To analyze this scenario, we introduce the concept of Kronecker noise to parameterize stochasticity, through which we prove that the uniquely robust semi-value, which can be analytically derived from the underlying Kronecker noise, lies in the family of weighted Banzhaf values while minimizing the worst-case entropy. In addition, we adopt the maximum sample reuse principle to design an estimator to efficiently approximate weighted Banzhaf values, and show that it enjoys the best time complexity in terms of achieving an $(\\epsilon, \\delta)$-approximation. Our theory is verified under both synthetic and authentic noises. For the latter, we fit a Kronecker noise to the inherent stochasticity, which is then plugged in to generate the predicted most robust semi-value. Our study suggests that weighted Banzhaf values are promising when facing undue noises in data valuation",
    "checked": false,
    "id": "6fa3f84affb5af66ec3fe94e618e0124493bb28e",
    "semantic_title": "data banzhaf: a robust data valuation framework for machine learning",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=WAd5ZRdFoc": {
    "title": "Nonparametric Boundary Geometry in Physics Informed Deep Learning",
    "volume": "poster",
    "abstract": "Engineering design problems frequently require solving systems of partial differential equations with boundary conditions specified on object geometries in the form of a triangular mesh. These boundary geometries are provided by a designer and are problem dependent. The efficiency of the design process greatly benefits from fast turnaround times when repeatedly solving PDEs on various geometries. However, most current work that uses machine learning to speed up the solution process relies heavily on a fixed parameterization of the geometry, which cannot be changed after training. This severely limits the possibility of reusing a trained model across a variety of design problems. In this work, we propose a novel neural operator architecture which accepts boundary geometry, in the form of triangular meshes, as input and produces an approximate solution to a given PDE as output. Once trained, the model can be used to rapidly estimate the PDE solution over a new geometry, without the need for retraining or representation of the geometry to a pre-specified parameterization",
    "checked": false,
    "id": "75f258b9b55468efc2dcfd1cb05c1468575a3e96",
    "semantic_title": "deepphysics: a physics aware deep learning framework for real‐time simulation",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=1h2TAUEfc4": {
    "title": "Exact Verification of ReLU Neural Control Barrier Functions",
    "volume": "poster",
    "abstract": "Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety. Based on this condition, we propose an algorithm for safety verification of NCBFs that first decomposes the NCBF into piecewise linear segments and then solves a nonlinear program to verify safety of each segment as well as the intersections of the linear segments. We mitigate the complexity by only considering the boundary of the safe region and by pruning the segments with Interval Bound Propagation (IBP) and linear relaxation. We evaluate our approach through numerical studies with comparison to state-of-the-art SMT-based methods. Our code is available at https://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23",
    "checked": true,
    "id": "a10de1c39b73f3cc9f9f4990505c08e8897f4eb6",
    "semantic_title": "exact verification of relu neural control barrier functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pZ2Ww45GkL": {
    "title": "Enhancing Robot Program Synthesis Through Environmental Context",
    "volume": "poster",
    "abstract": "Program synthesis aims to automatically generate an executable program that conforms to the given specification. Recent advancements have demonstrated that deep neural methodologies and large-scale pretrained language models are highly proficient in capturing program semantics. For robot programming, prior works have facilitated program synthesis by incorporating global environments. However, the assumption of acquiring a comprehensive understanding of the entire environment is often excessively challenging to achieve. In this work, we present a framework that learns to synthesize a program by rectifying potentially erroneous code segments, with the aid of partially observed environments. To tackle the issue of inadequate attention to partial observations, we propose to first learn an environment embedding space that can implicitly evaluate the impacts of each program token based on the precondition. Furthermore, by employing a graph structure, the model can aggregate both environmental and syntactic information flow and furnish smooth program rectification guidance. Extensive experimental evaluations and ablation studies on the partially observed VizDoom domain authenticate that our method offers superior generalization capability across various tasks and greater robustness when encountering noises",
    "checked": false,
    "id": "50bc14e6fcb5960186a911926995bce41e3eeb13",
    "semantic_title": "enhancing legged robot navigation of rough terrain via tail tapping",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=q3fCWoC9l0": {
    "title": "Efficient Data Subset Selection to Generalize Training Across Models: Transductive and Inductive Networks",
    "volume": "poster",
    "abstract": "Existing subset selection methods for efficient learning predominantly employ discrete combinatorial and model-specific approaches, which lack generalizability--- for each new model, the algorithm has to be executed from the beginning. Therefore, for an unseen architecture, one cannot use the subset chosen for a different model. In this work, we propose $\\texttt{SubSelNet}$, a non-adaptive subset selection framework, which tackles these problems. Here, we first introduce an attention-based neural gadget that leverages the graph structure of architectures and acts as a surrogate to trained deep neural networks for quick model prediction. Then, we use these predictions to build subset samplers. This naturally provides us two variants of $\\texttt{SubSelNet}$. The first variant is transductive (called Transductive-$\\texttt{SubSelNet}$), which computes the subset separately for each model by solving a small optimization problem. Such an optimization is still super fast, thanks to the replacement of explicit model training by the model approximator. The second variant is inductive (called Inductive-$\\texttt{SubSelNet}$), which computes the subset using a trained subset selector, without any optimization. Our experiments show that our model outperforms several methods across several real datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BRqlkTDvvm": {
    "title": "BQ-NCO: Bisimulation Quotienting for Efficient Neural Combinatorial Optimization",
    "volume": "poster",
    "abstract": "Despite the success of neural-based combinatorial optimization methods for end-to-end heuristic learning, out-of-distribution generalization remains a challenge. In this paper, we present a novel formulation of Combinatorial Optimization Problems (COPs) as Markov Decision Processes (MDPs) that effectively leverages common symmetries of COPs to improve out-of-distribution robustness. Starting from a direct MDP formulation of a constructive method, we introduce a generic way to reduce the state space, based on Bisimulation Quotienting (BQ) in MDPs. Then, for COPs with a recursive nature, we specialize the bisimulation and show how the reduced state exploits the symmetries of these problems and facilitates MDP solving. Our approach is principled and we prove that an optimal policy for the proposed BQ-MDP actually solves the associated COPs. We illustrate our approach on five classical problems: the Euclidean and Asymmetric Traveling Salesman, Capacitated Vehicle Routing, Orienteering and Knapsack Problems. Furthermore, for each problem, we introduce a simple attention-based policy network for the BQ-MDPs, which we train by imitation of (near) optimal solutions of small instances from a single distribution. We obtain new state-of-the-art results for the five COPs on both synthetic and realistic benchmarks. Notably, in contrast to most existing neural approaches, our learned policies show excellent generalization performance to much larger instances than seen during training, without any additional search procedure. Our code is available at: [link](https://github.com/naver/bq-nco)",
    "checked": true,
    "id": "72da01c00ef44b039cefe7e9701da2b3d3412f71",
    "semantic_title": "bq-nco: bisimulation quotienting for efficient neural combinatorial optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8U31BCquNF": {
    "title": "Learning Shared Safety Constraints from Multi-task Demonstrations",
    "volume": "poster",
    "abstract": "Regardless of the particular task we want to perform in an environment, there are often shared safety constraints we want our agents to respect. For example, regardless of whether it is making a sandwich or clearing the table, a kitchen robot should not break a plate. Manually specifying such a constraint can be both time-consuming and error-prone. We show how to learn constraints from expert demonstrations of safe task completion by extending inverse reinforcement learning (IRL) techniques to the space of constraints. Intuitively, we learn constraints that forbid highly rewarding behavior that the expert could have taken but chose not to. Unfortunately, the constraint learning problem is rather ill-posed and typically leads to overly conservative constraints that forbid all behavior that the expert did not take. We counter this by leveraging diverse demonstrations that naturally occur in multi-task setting to learn a tighter set of constraints. We validate our method with simulation experiments on high-dimensional continuous control tasks",
    "checked": true,
    "id": "a22b88c046bd84d29ae592ba1e247e7891476920",
    "semantic_title": "learning shared safety constraints from multi-task demonstrations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7otRtfrRqo": {
    "title": "Dis-inhibitory neuronal circuits can control the sign of synaptic plasticity",
    "volume": "poster",
    "abstract": "How neuronal circuits achieve credit assignment remains a central unsolved question in systems neuroscience. Various studies have suggested plausible solutions for back-propagating error signals through multi-layer networks. These purely functionally motivated models assume distinct neuronal compartments to represent local error signals that determine the sign of synaptic plasticity. However, this explicit error modulation is inconsistent with phenomenological plasticity models in which the sign depends primarily on postsynaptic activity. Here we show how a plausible microcircuit model and Hebbian learning rule derived within an adaptive control theory framework can resolve this discrepancy. Assuming errors are encoded in top-down dis-inhibitory synaptic afferents, we show that error-modulated learning emerges naturally at the circuit level when recurrent inhibition explicitly influences Hebbian plasticity. The same learning rule accounts for experimentally observed plasticity in the absence of inhibition and performs comparably to back-propagation of error (BP) on several non-linearly separable benchmarks. Our findings bridge the gap between functional and experimentally observed plasticity rules and make concrete predictions on inhibitory modulation of excitatory plasticity",
    "checked": true,
    "id": "928cd751dcb662a0dff7e724970ad942f6e702ad",
    "semantic_title": "dis-inhibitory neuronal circuits can control the sign of synaptic plasticity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jZYf1GxH1V": {
    "title": "Design from Policies: Conservative Test-Time Adaptation for Offline Policy Optimization",
    "volume": "poster",
    "abstract": "In this work, we decouple the iterative bi-level offline RL (value estimation and policy extraction) from the offline training phase, forming a non-iterative bi-level paradigm and avoiding the iterative error propagation over two levels. Specifically, this non-iterative paradigm allows us to conduct inner-level optimization (value estimation) in training, while performing outer-level optimization (policy extraction) in testing. Naturally, such a paradigm raises three core questions that are not fully answered by prior non-iterative offline RL counterparts like reward-conditioned policy: (q1) What information should we transfer from the inner-level to the outer-level? (q2) What should we pay attention to when exploiting the transferred information for safe/confident outer-level optimization? (q3) What are the benefits of concurrently conducting outer-level optimization during testing? Motivated by model-based optimization (MBO), we propose DROP (design from policies), which fully answers the above questions. Specifically, in the inner-level, DROP decomposes offline data into multiple subsets, and learns an MBO score model (a1). To keep safe exploitation to the score model in the outer-level, we explicitly learn a behavior embedding and introduce a conservative regularization (a2). During testing, we show that DROP permits deployment adaptation, enabling an adaptive inference across states (a3). Empirically, we evaluate DROP on various tasks, showing that DROP gains comparable or better performance compared to prior methods",
    "checked": true,
    "id": "535c385767b188d8112f2748ce5433b744b18361",
    "semantic_title": "design from policies: conservative test-time adaptation for offline policy optimization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=WBXYGBQXiB": {
    "title": "NCDL: A Framework for Deep Learning on non-Cartesian Lattices",
    "volume": "poster",
    "abstract": "The use of non-Cartesian grids is a niche but important topic in sub-fields of the numerical sciences such as simulation and scientific visualization. However, non-Cartesian approaches are virtually unexplored in machine learning. This is likely due to the difficulties in the representation of data on non-Cartesian domains and the lack of support for standard machine learning operations on non-Cartesian data. This paper proposes a new data structure called the lattice tensor which generalizes traditional tensor spatio-temporal operations to lattice tensors, enabling the use of standard machine learning algorithms on non-Cartesian data. However, data need not reside on a non-Cartesian structure, we use non-Dyadic downsampling schemes to bring Cartesian data into a non-Cartesian space for further processing. We introduce a software library that implements the lattice tensor container (with some common machine learning operations), and demonstrate its effectiveness. Our method provides a general framework for machine learning on non-Cartesian domains, addressing the challenges mentioned above and filling a gap in the current literature",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Uzi22WryyX": {
    "title": "A Path to Simpler Models Starts With Noise",
    "volume": "poster",
    "abstract": "The Rashomon set is the set of models that perform approximately equally well on a given dataset, and the Rashomon ratio is the fraction of all models in a given hypothesis space that are in the Rashomon set. Rashomon ratios are often large for tabular datasets in criminal justice, healthcare, lending, education, and in other areas, which has practical implications about whether simpler models can attain the same level of accuracy as more complex models. An open question is why Rashomon ratios often tend to be large. In this work, we propose and study a mechanism of the data generation process, coupled with choices usually made by the analyst during the learning process, that determines the size of the Rashomon ratio. Specifically, we demonstrate that noisier datasets lead to larger Rashomon ratios through the way that practitioners train models. Additionally, we introduce a measure called pattern diversity, which captures the average difference in predictions between distinct classification patterns in the Rashomon set, and motivate why it tends to increase with label noise. Our results explain a key aspect of why simpler models often tend to perform as well as black box models on complex, noisier datasets",
    "checked": true,
    "id": "c371e4fff5c5be5f6abd2faf549001c47dddccca",
    "semantic_title": "a path to simpler models starts with noise",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=toEGuA9Qfn": {
    "title": "SafeDICE: Offline Safe Imitation Learning with Non-Preferred Demonstrations",
    "volume": "poster",
    "abstract": "We consider offline safe imitation learning (IL), where the agent aims to learn the safe policy that mimics preferred behavior while avoiding non-preferred behavior from non-preferred demonstrations and unlabeled demonstrations. This problem setting corresponds to various real-world scenarios, where satisfying safety constraints is more important than maximizing the expected return. However, it is very challenging to learn the policy to avoid constraint-violating (i.e. non-preferred) behavior, as opposed to standard imitation learning which learns the policy to mimic given demonstrations. In this paper, we present a hyperparameter-free offline safe IL algorithm, SafeDICE, that learns safe policy by leveraging the non-preferred demonstrations in the space of stationary distributions. Our algorithm directly estimates the stationary distribution corrections of the policy that imitate the demonstrations excluding the non-preferred behavior. In the experiments, we demonstrate that our algorithm learns a more safe policy that satisfies the cost constraint without degrading the reward performance, compared to baseline algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VQ1heZKSLQ": {
    "title": "Batchnorm Allows Unsupervised Radial Attacks",
    "volume": "poster",
    "abstract": "The construction of adversarial examples usually requires the existence of soft or hard labels for each instance, with respect to which a loss gradient provides the signal for construction of the example. We show that for batch normalized deep image recognition architectures, intermediate latents that are produced after a batch normalization step by themselves suffice to produce adversarial examples using an intermediate loss solely utilizing angular deviations, without relying on any label. We motivate our loss through the geometry of batch normed representations and their concentration of norm on a hypersphere and distributional proximity to Gaussians. Our losses expand intermediate latent based attacks that usually require labels. The success of our method implies that leakage of intermediate representations may create a security breach for deployed models, which persists even when the model is transferred to downstream usage. Removal of batch norm weakens our attack, indicating it contributes to this vulnerability. Our attacks also succeed against LayerNorm empirically, thus being relevant for transformer architectures, most notably vision transformers which we analyze",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l3yxZS3QdT": {
    "title": "BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning",
    "volume": "poster",
    "abstract": "Backdoor attacks pose a severe threat to the supply chain management of deep reinforcement learning (DRL) policies. Despite initial defenses proposed in recent studies, these methods have very limited generalizability and scalability. To address this issue, we propose BIRD, a technique to detect and remove backdoors from a pretrained DRL policy in a clean environment without requiring any knowledge about the attack specifications and accessing its training process. By analyzing the unique properties and behaviors of backdoor attacks, we formulate trigger restoration as an optimization problem and design a novel metric to detect backdoored policies. We also design a finetuning method to remove the backdoor, while maintaining the agent's performance in the clean environment. We evaluate BIRD against three backdoor attacks in ten different single-agent or multi-agent environments. Our results verify the effectiveness, efficiency, and generalizability of BIRD, as well as its robustness to different attack variations and adaptions",
    "checked": true,
    "id": "a771a7eeb5edc5071c2ad9fa25bd5ecbe0f4882e",
    "semantic_title": "bird: generalizable backdoor detection and removal for deep reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zXckveawHa": {
    "title": "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
    "volume": "poster",
    "abstract": "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator",
    "checked": true,
    "id": "ed5668d91dbb297717ff85c74f366d1539deb511",
    "semantic_title": "statistical limits of adaptive linear models: low-dimensional estimation and inference",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AtHJ7TLheF": {
    "title": "Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational and Temporal Graphs",
    "volume": "poster",
    "abstract": "As a powerful framework for graph representation learning, Graph Neural Networks (GNNs) have garnered significant attention in recent years. However, to the best of our knowledge, there has been no formal analysis of the logical expressiveness of GNNs as Boolean node classifiers over multi-relational graphs, where each edge carries a specific relation type. In this paper, we investigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two variables and counting quantifiers. On the negative side, we demonstrate that the R$^2$-GNN architecture, which extends the local message passing GNN by incorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in the general case. Nevertheless, on the positive side, we establish that R$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs regarding expressiveness, we propose a simple graph transformation technique, akin to a preprocessing step, which can be executed in linear time. This transformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$ classifiers when applied to the \"transformed\" input graph. Moreover, we extend our analysis of expressiveness and graph transformation to temporal graphs, exploring several temporal GNN architectures and providing an expressiveness hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the graph transformation technique and conduct empirical tests in node classification tasks against various well-known GNN architectures that support multi-relational or temporal graphs. Our experimental results consistently demonstrate that R$^2$-GNN with the graph transformation outperforms the baseline methods on both synthetic and real-world datasets",
    "checked": true,
    "id": "26be1434167ac1455194890a2a527b255fc10b3d",
    "semantic_title": "calibrate and boost logical expressiveness of gnn over multi-relational and temporal graphs",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nKCUDd9GYu": {
    "title": "A Framework for Fast and Stable Representations of Multiparameter Persistent Homology Decompositions",
    "volume": "poster",
    "abstract": "Topological data analysis (TDA) is an area of data science that focuses on using invariants from algebraic topology to provide multiscale shape descriptors for geometric data sets such as point clouds. One of the most important such descriptors is persistent homology, which encodes the change in shape as a filtration parameter changes; a typical parameter is the feature scale. For many data sets, it is useful to simultaneously vary multiple filtration parameters, for example feature scale and density. While the theoretical properties of single parameter persistent homology are well understood, less is known about the multiparameter case. A central question is the problem of representing multiparameter persistent homology by elements of a vector space for integration with standard machine learning algorithms. Existing approaches to this problem either ignore most of the multiparameter information to reduce to the one-parameter case or are heuristic and potentially unstable in the face of noise. In this article, we introduce a new general representation framework that leverages recent results on decompositions of multiparameter persistent homology. This framework is rich in information, fast to compute, and encompasses previous approaches. Moreover, we establish theoretical stability guarantees under this framework as well as efficient algorithms for practical computation, making this framework an applicable and versatile tool for analyzing geometric and point cloud data. We validate our stability results and algorithms with numerical experiments that demonstrate statistical convergence, prediction accuracy, and fast running times on several real data sets",
    "checked": true,
    "id": "0fddca6b52859c6dbe8dd3ca260253479ae7ee30",
    "semantic_title": "a framework for fast and stable representations of multiparameter persistent homology decompositions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SOEF0i0G1z": {
    "title": "Cognitive Model Discovery via Disentangled RNNs",
    "volume": "poster",
    "abstract": "Computational cognitive models are a fundamental tool in behavioral neuroscience. They embody in software precise hypotheses about the cognitive mechanisms underlying a particular behavior. Constructing these models is typically a difficult iterative process that requires both inspiration from the literature and the creativity of an individual researcher. Here, we adopt an alternative approach to learn parsimonious cognitive models directly from data. We fit behavior data using a recurrent neural network that is penalized for carrying excess information between timesteps, leading to sparse, interpretable representations and dynamics. When fitting synthetic behavioral data from known cognitive models, our method recovers the underlying form of those models. When fit to choice data from rats performing a bandit task, our method recovers simple and interpretable models that make testable predictions about neural mechanisms",
    "checked": true,
    "id": "4d4d2491afa2b7cb7633cd9779a1be883e811414",
    "semantic_title": "cognitive model discovery via disentangled rnns",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=lCThtrJxoH": {
    "title": "Team-PSRO for Learning Approximate TMECor in Large Team Games via Cooperative Reinforcement Learning",
    "volume": "poster",
    "abstract": "Recent algorithms have achieved superhuman performance at a number of two-player zero-sum games such as poker and go. However, many real-world situations are multi-player games. Zero-sum two-team games, such as bridge and football, involve two teams where each member of the team shares the same reward with every other member of that team, and each team has the negative of the reward of the other team. A popular solution concept in this setting, called TMECor, assumes that teams can jointly correlate their strategies before play, but are not able to communicate during play. This setting is harder than two-player zero-sum games because each player on a team has different information and must use their public actions to signal to other members of the team. Prior works either have game-theoretic guarantees but only work in very small games, or are able to scale to large games but do not have game-theoretic guarantees. In this paper we introduce two algorithms: Team-PSRO, an extension of PSRO from two-player games to team games, and Team-PSRO Mix-and-Match which improves upon Team PSRO by better using population policies. In Team-PSRO, in every iteration both teams learn a joint best response to the opponent's meta-strategy via reinforcement learning. As the reinforcement learning joint best response approaches the optimal best response, Team-PSRO is guaranteed to converge to a TMECor. In experiments on Kuhn poker and Liar's Dice, we show that a tabular version of Team-PSRO converges to TMECor, and a version of Team PSRO using deep cooperative reinforcement learning beats self-play reinforcement learning in the large game of Google Research Football",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D2cS6SoYlP": {
    "title": "Flow Matching for Scalable Simulation-Based Inference",
    "volume": "poster",
    "abstract": "Neural posterior estimation methods based on discrete normalizing flows have become established tools for simulation-based inference (SBI), but scaling them to high-dimensional problems can be challenging. Building on recent advances in generative modeling, we here present flow matching posterior estimation (FMPE), a technique for SBI using continuous normalizing flows. Like diffusion models, and in contrast to discrete flows, flow matching allows for unconstrained architectures, providing enhanced flexibility for complex data modalities. Flow matching, therefore, enables exact density evaluation, fast training, and seamless scalability to large architectures---making it ideal for SBI. We show that FMPE achieves competitive performance on an established SBI benchmark, and then demonstrate its improved scalability on a challenging scientific problem: for gravitational-wave inference, FMPE outperforms methods based on comparable discrete flows, reducing training time by 30\\% with substantially improved accuracy. Our work underscores the potential of FMPE to enhance performance in challenging inference scenarios, thereby paving the way for more advanced applications to scientific problems",
    "checked": true,
    "id": "ecf1530ff9cc50058fb915329b59161e461c371c",
    "semantic_title": "flow matching for scalable simulation-based inference",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=6fuZs3ibGA": {
    "title": "Optimal and Fair Encouragement Policy Evaluation and Learning",
    "volume": "poster",
    "abstract": "In consequential domains, it is often impossible to compel individuals to take treatment, so that optimal policy rules are merely suggestions in the presence of human non-adherence to treatment recommendations. In these same domains, there may be heterogeneity both in who responds in taking-up treatment, and heterogeneity in treatment efficacy. For example, in social services, a persistent puzzle is the gap in take-up of beneficial services among those who may benefit from them the most. When in addition the decision-maker has distributional preferences over both access and average outcomes, the optimal decision rule changes. We study identification, doubly-robust estimation, and robust estimation under potential violations of positivity. We consider fairness constraints such as demographic parity in treatment take-up, and other constraints, via constrained optimization. Our framework can be extended to handle algorithmic recommendations under an often-reasonable covariate-conditional exclusion restriction, using our robustness checks for lack of positivity in the recommendation. We develop a two-stage, online learning-based algorithm for solving over parametrized policy classes under general constraints to obtain variance-sensitive regret bounds. We assess improved recommendation rules in a stylized case study of optimizing recommendation of supervised release in the PSA-DMF pretrial risk-assessment tool while reducing surveillance disparities",
    "checked": true,
    "id": "958450d279a5e90dcc34fef552002735a0d188d9",
    "semantic_title": "optimal and fair encouragement policy evaluation and learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GI4Pp01prW": {
    "title": "Machine learning detects terminal singularities",
    "volume": "poster",
    "abstract": "Algebraic varieties are the geometric shapes defined by systems of polynomial equations; they are ubiquitous across mathematics and science. Amongst these algebraic varieties are Q-Fano varieties: positively curved shapes which have Q-factorial terminal singularities. Q-Fano varieties are of fundamental importance in geometry as they are `atomic pieces' of more complex shapes – the process of breaking a shape into simpler pieces in this sense is called the Minimal Model Programme. Despite their importance, the classification of Q-Fano varieties remains unknown. In this paper we demonstrate that machine learning can be used to understand this classification. We focus on eight-dimensional positively-curved algebraic varieties that have toric symmetry and Picard rank two, and develop a neural network classifier that predicts with 95% accuracy whether or not such an algebraic variety is Q-Fano. We use this to give a first sketch of the landscape of Q-Fano varieties in dimension eight. How the neural network is able to detect Q-Fano varieties with such accuracy remains mysterious, and hints at some deep mathematical theory waiting to be uncovered. Furthermore, when visualised using the quantum period, an invariant that has played an important role in recent theoretical developments, we observe that the classification as revealed by ML appears to fall within a bounded region, and is stratified by the Fano index. This suggests that it may be possible to state and prove conjectures on completeness in the future. Inspired by the ML analysis, we formulate and prove a new global combinatorial criterion for a positively curved toric variety of Picard rank two to have terminal singularities. Together with the first sketch of the landscape of Q-Fano varieties in higher dimensions, this gives strong new evidence that machine learning can be an essential tool in developing mathematical conjectures and accelerating theoretical discovery",
    "checked": true,
    "id": "710fb27acf757347c6534249bbb7939831475c87",
    "semantic_title": "machine learning detects terminal singularities",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PU3deePP2S": {
    "title": "Universality laws for Gaussian mixtures in generalized linear models",
    "volume": "poster",
    "abstract": "A recent line of work in high-dimensional statistics working under the Gaussian mixture hypothesis has led to a number of results in the context of empirical risk minimization, Bayesian uncertainty quantification, separation of kernel methods and neural networks, ensembling and fluctuation of random features. We provide rigorous proofs for the applicability of these results to a general class of datasets $(\\mathbf{x_i},y_i, {i=1,\\dots,n})$ containing independent samples from a mixture distribution $\\sum_{c\\in\\mathcal{C}} \\rho_{c}P_{c}^{\\mathbf{x}}$. Specifically, we consider the hypothesis class of generalized linear models $\\hat{y} = F(\\mathbf{\\Theta}^{\\top}\\mathbf{x})$ and investigate the asymptotic joint statistics of a family of generalized linear estimators $(\\mathbf{\\Theta}^{(1)}, \\dots, \\mathbf{\\Theta}^{(M)})$, obtained either from (a) minimizing an empirical risk $\\hat{R_n}^{(m)}(\\mathbf{\\Theta}^{(m)};\\mathbf{X},\\mathbf{y})$ or (b) sampling from the associated Gibbs measure $\\exp(-\\beta n \\hat{R_n}^{(m)}(\\mathbf{\\Theta}^{(m)};\\mathbf{X},\\mathbf{y}))$. Our main contribution is to characterize under which conditions the asymptotic joint statistics of this family depends (on a weak sense) only on the means and covariances of the class conditional features distribution $P_{c}^{\\mathbf{x}}$. This allows us to prove the universality of different quantities of interest, including training, generalization errors, as well as the geometrical properties and correlations of the estimators",
    "checked": true,
    "id": "8c178ea44577486e5b3cfdc646b4621bc21e2664",
    "semantic_title": "universality laws for gaussian mixtures in generalized linear models",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=2NncD8AaFK": {
    "title": "CoLLAT: On Adding Fine-grained Audio Understanding to Language Models using Token-Level Locked-Language Tuning",
    "volume": "poster",
    "abstract": "Humans can easily understand various audio concepts, but conventional audio classification models fail due to their inability to predict unseen classes during training. To address this challenge, recent literature has explored contrastive language-audio pretraining to learn an audio understanding model using natural language supervision from a pretrained language model. However, despite their reasonable zero-shot performance in audio understanding, these models typically fail to achieve optimal performance while preserving the text understanding capabilities of the pretrained language model. They also perform poorly when comprehending audio clips with multiple audio concepts. To bridge these gaps, we propose $CoLLAT$: $Co$ntrastive $L$ocked $L$anguage and $A$udio $T$uning. This is a framework to effectively learn an audio understanding model with a locked language model, which is learned using a novel pretraining objective for audio-to-text grounding to yield fine-grained audio understanding. Our extensive experiments, which include several downstream applications such as audio classification, cross-modal retrieval, and audio-guided image generation, demonstrate that $CoLLAT$ yields state-of-the-art performance for audio understanding. Additionally, it unlocks audio guidance to applications built on top of pretrained language models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=md68e8iZK1": {
    "title": "Large Language Models Are Zero-Shot Time Series Forecasters",
    "volume": "poster",
    "abstract": "By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text. Developing this approach, we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can surprisingly zero-shot extrapolate time series at a level comparable to or exceeding the performance of purpose-built time series models trained on the downstream tasks. To facilitate this performance, we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values. We argue the success of LLMs for time series stems from their ability to naturally represent multimodal distributions, in conjunction with biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends. We also show how LLMs can naturally handle missing data without imputation through non-numerical text, accommodate textual side information, and answer questions to help explain predictions. While we find that increasing model size generally improves performance on time series, we show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers, and poor uncertainty calibration, which is likely the result of alignment interventions such as RLHF",
    "checked": true,
    "id": "123acfbccca0460171b6b06a4012dbb991cde55b",
    "semantic_title": "large language models are zero-shot time series forecasters",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=xNUmTRYtV1": {
    "title": "Optimal Algorithms for the Inhomogeneous Spiked Wigner Model",
    "volume": "poster",
    "abstract": "We study a spiked Wigner problem with an inhomogeneous noise profile. Our aim in this problem is to recover the signal passed through an inhomogeneous low-rank matrix channel. While the information-theoretic performances are well-known, we focus on the algorithmic problem. First, we derive an approximate message-passing algorithm (AMP) for the inhomogeneous problem and show that its rigorous state evolution coincides with the information-theoretic optimal Bayes fixed-point equations. Second, we deduce a simple and efficient spectral method that outperforms PCA and is shown to match the information-theoretic transition",
    "checked": true,
    "id": "b9e51821f5dc316abc8e7fbd457ba057e18da186",
    "semantic_title": "optimal algorithms for the inhomogeneous spiked wigner model",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=mkve1raJUc": {
    "title": "Robust Mean Estimation Without Moments for Symmetric Distributions",
    "volume": "poster",
    "abstract": "We study the problem of robustly estimating the mean or location parameter without moment assumptions. Known computationally efficient algorithms rely on strong distributional assumptions, such as sub-Gaussianity, or (certifiably) bounded moments. Moreover, the guarantees that they achieve in the heavy-tailed setting are weaker than those for sub-Gaussian distributions with known covariance. In this work, we show that such a tradeoff, between error guarantees and heavy-tails, is not necessary for symmetric distributions. We show that for a large class of symmetric distributions, the same error as in the Gaussian setting can be achieved efficiently. The distributions we study include products of arbitrary symmetric one-dimensional distributions, such as product Cauchy distributions, as well as elliptical distributions, a vast generalization of the Gaussian distribution. For product distributions and elliptical distributions with known scatter (covariance) matrix, we show that given an $\\varepsilon$-corrupted sample, we can with probability at least $1-\\delta$ estimate its location up to error $O(\\varepsilon \\sqrt{\\log(1/\\varepsilon)})$ using $\\tfrac{d\\log(d) + \\log(1/\\delta)}{\\varepsilon^2 \\log(1/\\varepsilon)}$ samples. This result matches the best-known guarantees for the Gaussian distribution and known SQ lower bounds (up to the $\\log(d)$ factor). For elliptical distributions with unknown scatter (covariance) matrix, we propose a sequence of efficient algorithms that approaches this optimal error. Specifically, for every $k \\in \\mathbb{N}$, we design an estimator using time and samples $\\tilde{O}({d^k})$ achieving error $O(\\varepsilon^{1-\\frac{1}{2k}})$. This matches the error and running time guarantees when assuming certifiably bounded moments of order up to $k$. For unknown covariance, such error bounds of $o(\\sqrt{\\varepsilon})$ are not even known for (general) sub-Gaussian distributions. Our algorithms are based on a generalization of the well-known filtering technique [DK22]. More specifically, we show how this machinery can be combined with Huber-loss-based techniques to work with projections of the noise that behave more nicely than the initial noise. Moreover, we show how sum-of-squares proofs can be used to obtain algorithmic guarantees even for distributions without a first moment. We believe that this approach may find other applications in future works",
    "checked": true,
    "id": "4a8db7531a405faa5bd29301ca6993469a55a25d",
    "semantic_title": "robust mean estimation without moments for symmetric distributions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AfC8PVQZ9z": {
    "title": "Multi-task Representation Learning for Pure Exploration in Bilinear Bandits",
    "volume": "poster",
    "abstract": "We study multi-task representation learning for the problem of pure exploration in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms from two different entity types and the reward is a bilinear function of the known feature vectors of the arms. In the \\textit{multi-task bilinear bandit problem}, we aim to find optimal actions for multiple tasks that share a common low-dimensional linear representation. The objective is to leverage this characteristic to expedite the process of identifying the best pair of arms for all tasks. We propose the algorithm GOBLIN that uses an experimental design approach to optimize sample allocations for learning the global representation as well as minimize the number of samples needed to identify the optimal pair of arms in individual tasks. To the best of our knowledge, this is the first study to give sample complexity analysis for pure exploration in bilinear bandits with shared representation. Our results demonstrate that by learning the shared representation across tasks, we achieve significantly improved sample complexity compared to the traditional approach of solving tasks independently",
    "checked": true,
    "id": "fcef252234d90de9190cc70da69054d5a8b36ac7",
    "semantic_title": "multi-task representation learning for pure exploration in bilinear bandits",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QVpfk2C3Dm": {
    "title": "Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff",
    "volume": "poster",
    "abstract": "Previous work has shown that DNNs with large depth $L$ and $L_{2}$-regularization are biased towards learning low-dimensional representations of the inputs, which can be interpreted as minimizing a notion of rank $R^{(0)}(f)$ of the learned function $f$, conjectured to be the Bottleneck rank. We compute finite depth corrections to this result, revealing a measure $R^{(1)}$ of regularity which bounds the pseudo-determinant of the Jacobian $\\left\\|Jf(x)\\right\\|\\_\\+$ and is subadditive under composition and addition. This formalizes a balance between learning low-dimensional representations and minimizing complexity/irregularity in the feature maps, allowing the network to learn the `right' inner dimension. Finally, we prove the conjectured bottleneck structure in the learned features as $L\\to\\infty$: for large depths, almost all hidden representations are approximately $R^{(0)}(f)$-dimensional, and almost all weight matrices $W_{\\ell}$ have $R^{(0)}(f)$ singular values close to 1 while the others are $O(L^{-\\frac{1}{2}})$. Interestingly, the use of large learning rates is required to guarantee an order $O(L)$ NTK which in turns guarantees infinite depth convergence of the representations of almost all layers",
    "checked": true,
    "id": "28835fd8d4cb7b62c09fce9e85fe52afe82ba4f5",
    "semantic_title": "bottleneck structure in learned features: low-dimension vs regularity tradeoff",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=V5Oh7Aqfft": {
    "title": "Causal Effect Regularization: Automated Detection and Removal of Spurious Correlations",
    "volume": "poster",
    "abstract": "In many classification datasets, the task labels are spuriously correlated with some input attributes. Classifiers trained on such datasets often rely on these attributes for prediction, especially when the spurious correlation is high, and thus fail to generalize whenever there is a shift in the attributes' correlation at deployment. If we assume that the spurious attributes are known a priori, several methods have been proposed to learn a classifier that is invariant to the specified attributes. However, in real-world data, information about spurious attributes is typically unavailable. Therefore, we propose a method to automatically identify spurious attributes by estimating their causal effect on the label and then use a regularization objective to mitigate the classifier's reliance on them. Compared to a recent method for identifying spurious attributes, we find that our method is more accurate in removing the attribute from the learned model, especially when spurious correlation is high. Specifically, across synthetic, semi-synthetic, and real-world datasets, our method shows significant improvement in a metric used to quantify the dependence of a classifier on spurious attributes ($\\Delta$Prob), while obtaining better or similar accuracy. In addition, our method mitigates the reliance on spurious attributes even under noisy estimation of causal effects. To explain the empirical robustness of our method, we create a simple linear classification task with two sets of attributes: causal and spurious. We prove that our method only requires that the ranking of estimated causal effects is correct across attributes to select the correct classifier",
    "checked": false,
    "id": "b59849cc90bcc367aec6ea1670b53496d413e2fa",
    "semantic_title": "causal effect regularization: automated detection and removal of spurious attributes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7nXaoclHed": {
    "title": "A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing Time",
    "volume": "poster",
    "abstract": "We address the problem of designing a sublinear-time spectral clustering oracle for graphs that exhibit strong clusterability. Such graphs contain $k$ latent clusters, each characterized by a large inner conductance (at least $\\varphi$) and a small outer conductance (at most $\\varepsilon$). Our aim is to preprocess the graph to enable clustering membership queries, with the key requirement that both preprocessing and query answering should be performed in sublinear time, and the resulting partition should be consistent with a $k$-partition that is close to the ground-truth clustering. Previous oracles have relied on either a $\\textrm{poly}(k)\\log n$ gap between inner and outer conductances or exponential (in $k/\\varepsilon$) preprocessing time. Our algorithm relaxes these assumptions, albeit at the cost of a slightly higher misclassification ratio. We also show that our clustering oracle is robust against a few random edge deletions. To validate our theoretical bounds, we conducted experiments on synthetic networks",
    "checked": true,
    "id": "7d2cff85f34873fb3a9566359b430faf05000bb2",
    "semantic_title": "a sublinear-time spectral clustering oracle with improved preprocessing time",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ce9B2x3zQa": {
    "title": "Max-Sliced Mutual Information",
    "volume": "poster",
    "abstract": "Quantifying dependence between high-dimensional random variables is central to statistical learning and inference. Two classical methods are canonical correlation analysis (CCA), which identifies maximally correlated projected versions of the original variables, and Shannon's mutual information, which is a universal dependence measure that also captures high-order dependencies. However, CCA only accounts for linear dependence, which may be insufficient for certain applications, while mutual information is often infeasible to compute/estimate in high dimensions. This work proposes a middle ground in the form of a scalable information-theoretic generalization of CCA, termed max-sliced mutual information (mSMI). mSMI equals the maximal mutual information between low-dimensional projections of the high-dimensional variables, which reduces back to CCA in the Gaussian case. It enjoys the best of both worlds: capturing intricate dependencies in the data while being amenable to fast computation and scalable estimation from samples. We show that mSMI retains favorable structural properties of Shannon's mutual information, like variational forms and identification of independence. We then study statistical estimation of mSMI, propose an efficiently computable neural estimator, and couple it with formal non-asymptotic error bounds. We present experiments that demonstrate the utility of mSMI for several tasks, encompassing independence testing, multi-view representation learning, algorithmic fairness, and generative modeling. We observe that mSMI consistently outperforms competing methods with little-to-no computational overhead",
    "checked": true,
    "id": "4a6fc60ac2c69e9c34fc39073a7867c1c08560ec",
    "semantic_title": "max-sliced mutual information",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9yQ2aaArDn": {
    "title": "Probabilistic Inference in Reinforcement Learning Done Right",
    "volume": "poster",
    "abstract": "A popular perspective in Reinforcement learning (RL) casts the problem as probabilistic inference on a graphical model of the Markov decision process (MDP). The core object of study is the probability of each state-action pair being visited under the optimal policy. Previous approaches to approximate this quantity can be arbitrarily poor, leading to algorithms that do not implement genuine statistical inference and consequently do not perform well in challenging problems. In this work, we undertake a rigorous Bayesian treatment of the posterior probability of state-action optimality and clarify how it flows through the MDP. We first reveal that this quantity can indeed be used to generate a policy that explores efficiently, as measured by regret. Unfortunately, computing it is intractable, so we derive a new variational Bayesian approximation yielding a tractable convex optimization problem and establish that the resulting policy also explores efficiently. We call our approach VAPOR and show that it has strong connections to Thompson sampling, K-learning, and maximum entropy exploration. We conclude with some experiments demonstrating the performance advantage of a deep RL version of VAPOR",
    "checked": true,
    "id": "1675bce7fca4eb2171f68755e79c399060087f23",
    "semantic_title": "probabilistic inference in reinforcement learning done right",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=O453PHSthc": {
    "title": "Training biologically plausible recurrent neural networks on cognitive tasks with long-term dependencies",
    "volume": "poster",
    "abstract": "Training recurrent neural networks (RNNs) has become a go-to approach for generating and evaluating mechanistic neural hypotheses for cognition. The ease and efficiency of training RNNs with backpropagation through time and the availability of robustly supported deep learning libraries has made RNN modeling more approachable and accessible to neuroscience. Yet, a major technical hindrance remains. Cognitive processes such as working memory and decision making involve neural population dynamics over a long period of time within a behavioral trial and across trials. It is difficult to train RNNs to accomplish tasks where neural representations and dynamics have long temporal dependencies without gating mechanisms such as LSTMs or GRUs which currently lack experimental support and prohibit direct comparison between RNNs and biological neural circuits. We tackled this problem based on the idea of specialized skip-connections through time to support the emergence of task-relevant dynamics, and subsequently reinstitute biological plausibility by reverting to the original architecture. We show that this approach enables RNNs to successfully learn cognitive tasks that prove impractical if not impossible to learn using conventional methods. Over numerous tasks considered here, we achieve less training steps and shorter wall-clock times, particularly in tasks that require learning long-term dependencies via temporal integration over long timescales or maintaining a memory of past events in hidden-states. Our methods expand the range of experimental tasks that biologically plausible RNN models can learn, thereby supporting the development of theory for the emergent neural mechanisms of computations involving long-term dependencies",
    "checked": true,
    "id": "2dad09b9eb927126e7ee9afb03f68431b92549ad",
    "semantic_title": "training biologically plausible recurrent neural networks on cognitive tasks with long-term dependencies",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Uafbv4rfJc": {
    "title": "Active Negative Loss Functions for Learning with Noisy Labels",
    "volume": "poster",
    "abstract": "Robust loss functions are essential for training deep neural networks in the presence of noisy labels. Some robust loss functions use Mean Absolute Error (MAE) as its necessary component. For example, the recently proposed Active Passive Loss (APL) uses MAE as its passive loss function. However, MAE treats every sample equally, slows down the convergence and can make training difficult. In this work, we propose a new class of theoretically robust passive loss functions different from MAE, namely *Normalized Negative Loss Functions* (NNLFs), which focus more on memorized clean samples. By replacing the MAE in APL with our proposed NNLFs, we improve APL and propose a new framework called *Active Negative Loss* (ANL). Experimental results on benchmark and real-world datasets demonstrate that the new set of loss functions created by our ANL framework can outperform state-of-the-art methods. The code is available at https://github.com/Virusdoll/Active-Negative-Loss",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0rVXQEeFEL": {
    "title": "Transformer-based Planning for Symbolic Regression",
    "volume": "poster",
    "abstract": "Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the effectiveness of pre-trained transformer-based models in generating equations as sequences, leveraging large-scale pre-training on synthetic datasets and offering notable advantages in terms of inference time over classical Genetic Programming (GP) methods. However, these models primarily rely on supervised pre-training goals borrowed from text generation and overlook equation discovery objectives like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search into the transformer decoding process. Unlike conventional decoding strategies, TPSR enables the integration of non-differentiable feedback, such as fitting accuracy and complexity, as external sources of knowledge into the transformer-based equation generation process. Extensive experiments on various datasets show that our approach outperforms state-of-the-art methods, enhancing the model's fitting-complexity trade-off, extrapolation abilities, and robustness to noise",
    "checked": true,
    "id": "b7016f306bb22ed98036c218c30f1c4d301d034c",
    "semantic_title": "transformer-based planning for symbolic regression",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=4Sn2vUs0zA": {
    "title": "Reference-Based POMDPs",
    "volume": "poster",
    "abstract": "Making good decisions in partially observable and non-deterministic scenarios is a crucial capability for robots. A Partially Observable Markov Decision Process (POMDP) is a general framework for the above problem. Despite advances in POMDP solving, problems with long planning horizons and evolving environments remain difficult to solve even by the best approximate solvers today. To alleviate this difficulty, we propose a slightly modified POMDP problem, called a Reference-Based POMDP, where the POMDP objective function is slightly modified to balance between maximizing the expected total reward and being close to a given reference (stochastic) policy. The optimal policy of a Reference-Based POMDP can be computed via iterative expectations using the given reference policy, thereby avoiding exhaustive enumeration of actions at each belief node of the search tree. We demonstrate theoretically that the standard POMDP under stochastic policies is related to the Reference-Based POMDP under suitable conditions. To demonstrate the feasibility of exploiting the Reference-Based POMDP formulation, we present a basic algorithm RefSolver. Results from experiments on long-horizon navigation problems indicate that this basic algorithm substantially outperforms POMCP",
    "checked": false,
    "id": "a7d58bd29778ef0d15b9e9e3eb2f37a8cf1ea70c",
    "semantic_title": "recurrent model-free rl can be a strong baseline for many pomdps",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=2ioRi2uwLR": {
    "title": "Neuro-symbolic Learning Yielding Logical Constraints",
    "volume": "poster",
    "abstract": "Neuro-symbolic systems combine the abilities of neural perception and logical reasoning. However, end-to-end learning of neuro-symbolic systems is still an unsolved challenge. This paper proposes a natural framework that fuses neural network training, symbol grounding, and logical constraint synthesis into a coherent and efficient end-to-end learning process. The capability of this framework comes from the improved interactions between the neural and the symbolic parts of the system in both the training and inference stages. Technically, to bridge the gap between the continuous neural network and the discrete logical constraint, we introduce a difference-of-convex programming technique to relax the logical constraints while maintaining their precision. We also employ cardinality constraints as the language for logical constraint learning and incorporate a trust region method to avoid the degeneracy of logical constraint in learning. Both theoretical analyses and empirical evaluations substantiate the effectiveness of the proposed framework",
    "checked": false,
    "id": "a0fd6cff760a8d563fdf2f59ce4588900ddca005",
    "semantic_title": "neuro-symbolic rule learning in real-world classification tasks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rQI3FOzo1f": {
    "title": "Efficient Learning of Linear Graph Neural Networks via Node Subsampling",
    "volume": "poster",
    "abstract": "Graph Neural Networks (GNNs) are a powerful class of machine learning models with applications in recommender systems, drug discovery, social network analysis, and computer vision. One challenge with their implementation is that GNNs often take large-scale graphs as inputs, which imposes significant computational/storage costs in the training and testing phases. In particular, the message passing operations of a GNN require multiplication of the graph adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$ and the data matrix $X \\in \\mathbb{R}^{n \\times d}$, and the $O(n^2 d)$ time complexity can be prohibitive for large $n$. Thus, a natural question is whether it is possible to perform the GNN operations in (quasi-)linear time by avoiding the full computation of $A X$. To study this question, we consider the setting of a regression task on a two-layer Linear Graph Convolutional Network (GCN). We develop an efficient training algorithm based on (1) performing node subsampling, (2) estimating the leverage scores of $A X$ based on the subsampled graph, and (3) performing leverage score sampling on $A X$. We show that our proposed scheme learns the regression model observing only $O(nd\\epsilon^{-2}\\log n)$ entries of $A$ in time $O(nd^2 \\epsilon^{-2}\\log n)$, with the guarantee that the learned weights deviate by at most $\\epsilon$ under the $\\ell_2$ norm from the model learned using the entire adjacency matrix $A$. We present empirical results for regression problems on real-world graphs and show that our algorithm significantly outperforms other baseline sampling strategies that exploit the same number of observations",
    "checked": false,
    "id": "400fdf470c4320c472a111a60ac3a6b238c6953d",
    "semantic_title": "schash: speedy simplicial complex neural networks via randomized hashing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LziniAXEI9": {
    "title": "Transformers learn to implement preconditioned gradient descent for in-context learning",
    "volume": "poster",
    "abstract": "Motivated by the striking ability of transformers for in-context learning, several works demonstrate that transformers can implement algorithms like gradient descent. By a careful construction of weights, these works show that multiple layers of transformers are expressive enough to simulate gradient descent iterations. Going beyond the question of expressivity, we ask: \\emph{Can transformers can learn to implement such algorithms by training over random problem instances?} To our knowledge, we make the first theoretical progress toward this question via analysis of the loss landscape for linear transformers trained over random instances of linear regression. For a single attention layer, we prove the global minimum of the training objective implements a single iteration of preconditioned gradient descent. Notably, the preconditioning matrix not only adapts to the input distribution but also to the variance induced by data inadequacy. For a transformer with $k$ attention layers, we prove certain critical points of the training objective implement $k$ iterations of preconditioned gradient descent. Our results call for future theoretical studies on learning algorithms by training transformers",
    "checked": true,
    "id": "f5e9337477d7a9eb6267d0310549fdefafbb7fe2",
    "semantic_title": "transformers learn to implement preconditioned gradient descent for in-context learning",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=PcNpL9Q39p": {
    "title": "Responsible AI (RAI) Games and Ensembles",
    "volume": "poster",
    "abstract": "Several recent works have studied the societal effects of AI; these include issues such as fairness, robustness, and safety. In many of these objectives, a learner seeks to minimize its worst-case loss over a set of predefined distributions (known as uncertainty sets), with usual examples being perturbed versions of the empirical distribution. In other words, the aforementioned problems can be written as min-max problems over these uncertainty sets. In this work, we provide a general framework for studying these problems, which we refer to as Responsible AI (RAI) games. We provide two classes of algorithms for solving these games: (a) game-play based algorithms, and (b) greedy stagewise estimation algorithms. The former class is motivated by online learning and game theory, whereas the latter class is motivated by the classical statistical literature on boosting, and regression. We empirically demonstrate the applicability and competitive performance of our techniques for solving several RAI problems, particularly around subpopulation shift",
    "checked": true,
    "id": "2e31851572706a5bf0df883ddfc1949458c56ec0",
    "semantic_title": "responsible ai (rai) games and ensembles",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YZGWhs1H7F": {
    "title": "GAN You See Me? Enhanced Data Reconstruction Attacks against Split Inference",
    "volume": "poster",
    "abstract": "Split Inference (SI) is an emerging deep learning paradigm that addresses computational constraints on edge devices and preserves data privacy through collaborative edge-cloud approaches. However, SI is vulnerable to Data Reconstruction Attacks (DRA), which aim to reconstruct users' private prediction instances. Existing attack methods suffer from various limitations. Optimization-based DRAs do not leverage public data effectively, while Learning-based DRAs depend heavily on auxiliary data quantity and distribution similarity. Consequently, these approaches yield unsatisfactory attack results and are sensitive to defense mechanisms. To overcome these challenges, we propose a GAN-based LAtent Space Search attack (GLASS) that harnesses abundant prior knowledge from public data using advanced StyleGAN technologies. Additionally, we introduce GLASS++ to enhance reconstruction stability. Our approach represents the first GAN-based DRA against SI, and extensive evaluation across different split points and adversary setups demonstrates its state-of-the-art performance. Moreover, we thoroughly examine seven defense mechanisms, highlighting our method's capability to reveal private information even in the presence of these defenses",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fpHfRD3f4N": {
    "title": "Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds",
    "volume": "poster",
    "abstract": "While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \\emph{heavy-tailed}, i.e., with only finite $(1+\\epsilon)$-th moments for some $\\epsilon\\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \\textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \\emph{instance-dependent} $T$-round regret of $\\tilde{O}\\big(d T^{\\frac{1-\\epsilon}{2(1+\\epsilon)}} \\sqrt{\\sum_{t=1}^T \\nu_t^2} + d T^{\\frac{1-\\epsilon}{2(1+\\epsilon)}}\\big)$, the \\emph{first} of this kind. Here, $d$ is the feature dimension, and $\\nu_t^{1+\\epsilon}$ is the $(1+\\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in stochastic and deterministic linear bandits. We then extend this algorithm to the RL settings with linear function approximation. Our algorithm, termed as \\textsc{Heavy-LSVI-UCB}, achieves the \\emph{first} computationally efficient \\emph{instance-dependent} $K$-episode regret of $\\tilde{O}(d \\sqrt{H \\mathcal{U}^*} K^\\frac{1}{1+\\epsilon} + d \\sqrt{H \\mathcal{V}^* K})$. Here, $H$ is length of the episode, and $\\mathcal{U}^*, \\mathcal{V}^*$ are instance-dependent quantities scaling with the central moment of reward and value functions, respectively. We also provide a matching minimax lower bound $\\Omega(d H K^{\\frac{1}{1+\\epsilon}} + d \\sqrt{H^3 K})$ to demonstrate the optimality of our algorithm in the worst case. Our result is achieved via a novel robust self-normalized concentration inequality that may be of independent interest in handling heavy-tailed noise in general online regression problems",
    "checked": true,
    "id": "64a1c75ee91a46ce317a5a4428412f7120a666ee",
    "semantic_title": "tackling heavy-tailed rewards in reinforcement learning with function approximation: minimax optimal and instance-dependent regret bounds",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=q1JukwH2yP": {
    "title": "Learning to Search Feasible and Infeasible Regions of Routing Problems with Flexible Neural k-Opt",
    "volume": "poster",
    "abstract": "In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search (L2S) solver for routing problems. It learns to perform flexible k-opt exchanges based on a tailored action factorization method and a customized recurrent dual-stream decoder. As a pioneering work to circumvent the pure feasibility masking scheme and enable the autonomous exploration of both feasible and infeasible regions, we then propose the Guided Infeasible Region Exploration (GIRE) scheme, which supplements the NeuOpt policy network with feasibility-related features and leverages reward shaping to steer reinforcement learning more effectively. Additionally, we equip NeuOpt with Dynamic Data Augmentation (D2A) for more diverse searches during inference. Extensive experiments on the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) demonstrate that our NeuOpt not only significantly outstrips existing (masking-based) L2S solvers, but also showcases superiority over the learning-to-construct (L2C) and learning-to-predict (L2P) solvers. Notably, we offer fresh perspectives on how neural solvers can handle VRP constraints. Our code is available: https://github.com/yining043/NeuOpt",
    "checked": true,
    "id": "b615a12df5eb24e2f01cbb8316ae17a6e19554e0",
    "semantic_title": "learning to search feasible and infeasible regions of routing problems with flexible neural k-opt",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mkKQr56xdB": {
    "title": "Memory-Constrained Algorithms for Convex Optimization",
    "volume": "poster",
    "abstract": "We propose a family of recursive cutting-plane algorithms to solve feasibility problems with constrained memory, which can also be used for first-order convex optimization. Precisely, in order to find a point within a ball of radius $\\epsilon$ with a separation oracle in dimension $d$---or to minimize $1$-Lipschitz convex functions to accuracy $\\epsilon$ over the unit ball---our algorithms use $\\mathcal O(\\frac{d^2}{p}\\ln \\frac{1}{\\epsilon})$ bits of memory, and make $\\mathcal O((C\\frac{d}{p}\\ln \\frac{1}{\\epsilon})^p)$ oracle calls. The family is parametrized by $p\\in[d]$ and provides an oracle-complexity/memory trade-off in the sub-polynomial regime $\\ln\\frac{1}{\\epsilon}\\gg\\ln d$. While several works gave lower-bound trade-offs (impossibility results)---we explicit here their dependence with $\\ln\\frac{1}{\\epsilon}$, showing that these also hold in any sub-polynomial regime---to the best of our knowledge this is the first class of algorithms that provides a positive trade-off between gradient descent and cutting-plane methods in any regime with $\\epsilon\\leq 1/\\sqrt d$. The algorithms divide the $d$ variables into $p$ blocks and optimize over blocks sequentially, with approximate separation vectors constructed using a variant of Vaidya's method. In the regime $\\epsilon \\leq d^{-\\Omega(d)}$, our algorithm with $p=d$ achieves the information-theoretic optimal memory usage and improves the oracle-complexity of gradient descent",
    "checked": false,
    "id": "7684c442498dd4bf1c7ff1e2df6c92c3c4743501",
    "semantic_title": "memory-constrained algorithms for convex optimization via recursive cutting-planes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=SqTUGq0R7j": {
    "title": "Persuading Farsighted Receivers in MDPs: the Power of Honesty",
    "volume": "poster",
    "abstract": "Bayesian persuasion studies the problem faced by an informed sender who strategically discloses information to influence the behavior of an uninformed receiver. Recently, a growing attention has been devoted to settings where the sender and the receiver interact sequentially, in which the receiver's decision-making problem is usually modeled as a Markov decision process (MDP). However, the literature focuses on computing optimal information-revelation policies (a.k.a. signaling schemes) under the restrictive assumption that the receiver acts myopically, selecting actions to maximize the one-step utility and disregarding future rewards. This is justified by the fact that, when the receiver is farsighted and thus considers future rewards, finding an optimal Markovian signaling scheme is NP-hard. In this paper, we show that Markovian signaling schemes do not constitute the \"right\" class of policies. Indeed, differently from most of the MDPs settings, we show that Markovian signaling schemes are not optimal, and general history-dependent signaling schemes should be considered. Moreover, we also show that history-dependent signaling schemes circumvent the negative complexity results affecting Markovian signaling schemes. Formally, we design an algorithm that computes an optimal and $\\epsilon$-persuasive history-dependent signaling scheme in time polynomial in ${1}/{\\epsilon}$ and in the instance size. The crucial challenge is that general history-dependent signaling schemes cannot be represented in polynomial space. Nevertheless, we introduce a convenient subclass of history-dependent signaling schemes, called promise-form, which are as powerful as general history-dependent ones and efficiently representable. Intuitively, promise-form signaling schemes compactly encode histories in the form of honest promises on future receiver's rewards",
    "checked": true,
    "id": "cb88fb7c62a14c35484f58e169616f558844a7ae",
    "semantic_title": "persuading farsighted receivers in mdps: the power of honesty",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lD8xaUWw24": {
    "title": "An information-theoretic quantification of the content of communication between brain regions",
    "volume": "poster",
    "abstract": "Quantifying the amount, content and direction of communication between brain regions is key to understanding brain function. Traditional methods to analyze brain activity based on the Wiener-Granger causality principle quantify the overall information propagated by neural activity between simultaneously recorded brain regions, but do not reveal the information flow about specific features of interest (such as sensory stimuli). Here, we develop a new information theoretic measure termed Feature-specific Information Transfer (FIT), quantifying how much information about a specific feature flows between two regions. FIT merges the Wiener-Granger causality principle with information-content specificity. We first derive FIT and prove analytically its key properties. We then illustrate and test them with simulations of neural activity, demonstrating that FIT identifies, within the total information propagated between regions, the information that is transmitted about specific features. We then analyze three neural datasets obtained with different recording methods, magneto- and electro-encephalography, and spiking activity, to demonstrate the ability of FIT to uncover the content and direction of information flow between brain regions beyond what can be discerned with traditional analytical methods. FIT can improve our understanding of how brain regions communicate by uncovering previously unaddressed feature-specific information flow",
    "checked": true,
    "id": "670c735821c4240e3f3ae71f129fe96372785bb3",
    "semantic_title": "an information-theoretic quantification of the content of communication between brain regions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Op9z2QfXbC": {
    "title": "Modulated Neural ODEs",
    "volume": "poster",
    "abstract": "Neural ordinary differential equations (NODEs) have been proven useful for learning non-linear dynamics of arbitrary trajectories. However, current NODE methods capture variations across trajectories only via the initial state value or by auto-regressive encoder updates. In this work, we introduce Modulated Neural ODEs (MoNODEs), a novel framework that sets apart dynamics states from underlying static factors of variation and improves the existing NODE methods. In particular, we introduce *time-invariant modulator variables* that are learned from the data. We incorporate our proposed framework into four existing NODE variants. We test MoNODE on oscillating systems, videos and human walking trajectories, where each trajectory has trajectory-specific modulation. Our framework consistently improves the existing model ability to generalize to new dynamic parameterizations and to perform far-horizon forecasting. In addition, we verify that the proposed modulator variables are informative of the true unknown factors of variation as measured by $R^2$ scores",
    "checked": true,
    "id": "c83ca61aacb05c6d3b757ce0ff842a2f98b2adfe",
    "semantic_title": "modulated neural odes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G7Y145tm2F": {
    "title": "CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion",
    "volume": "poster",
    "abstract": "Electroencephalography (EEG) is a prominent non-invasive neuroimaging technique providing insights into brain function. Unfortunately, EEG data exhibit a high degree of noise and variability across subjects hampering generalizable signal extraction. Therefore, a key aim in EEG analysis is to extract the underlying neural activation (content) as well as to account for the individual subject variability (style). We hypothesize that the ability to convert EEG signals between tasks and subjects requires the extraction of latent representations accounting for content and style. Inspired by recent advancements in voice conversion technologies, we propose a novel contrastive split-latent permutation autoencoder (CSLP-AE) framework that directly optimizes for EEG conversion. Importantly, the latent representations are guided using contrastive learning to promote the latent splits to explicitly represent subject (style) and task (content). We contrast CSLP-AE to conventional supervised, unsupervised (AE), and self-supervised (contrastive learning) training and find that the proposed approach provides favorable generalizable characterizations of subject and task. Importantly, the procedure also enables zero-shot conversion between unseen subjects. While the present work only considers conversion of EEG, the proposed CSLP-AE provides a general framework for signal conversion and extraction of content (task activation) and style (subject variability) components of general interest for the modeling and analysis of biological signals",
    "checked": true,
    "id": "74ff5f75ec2426b4a67806a7bebf708ebf2fe1c3",
    "semantic_title": "cslp-ae: a contrastive split-latent permutation autoencoder framework for zero-shot electroencephalography signal conversion",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s1FjXzJ0jy": {
    "title": "Focused Transformer: Contrastive Training for Context Scaling",
    "volume": "poster",
    "abstract": "Large language models have an exceptional capability to incorporate new information in a contextual manner. However, the full potential of such an approach is often restrained due to a limitation in the effective context length. One solution to this issue is to endow an attention layer with access to an additional context, which comprises of (key, value) pairs. Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys. We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish. To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length. Our method allows for fine-tuning pre-existing, large-scale models to lengthen their effective context. This is demonstrated by our fine-tuning of $3 B$ and $7 B$ OpenLLaMA checkpoints. The resulting models, which we name LongLLaMA, exhibit advancements in tasks requiring a long context. We further illustrate that our LongLLaMA models adeptly manage a $256 k$ context length for passkey retrieval",
    "checked": true,
    "id": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68",
    "semantic_title": "focused transformer: contrastive training for context scaling",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=BW6nZf7TnK": {
    "title": "Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields",
    "volume": "poster",
    "abstract": "Despite the remarkable achievements of neural radiance fields (NeRF) in representing 3D scenes and generating novel view images, the aliasing issue, rendering 'jaggies' or 'blurry' images at varying camera distances, remains unresolved in most existing approaches. The recently proposed mip-NeRF has effectively addressed this challenge by introducing integrated positional encodings (IPE). However, it relies on MLP architecture to represent the radiance fields, missing out on the fast training speed offered by the latest grid-based methods. In this work, we present mip-Grid, a novel approach that integrates anti-aliasing techniques into grid-based representations for radiance fields, mitigating the aliasing artifacts while enjoying fast training time. Notably, the proposed method uses a single-scale shared grid representation and a single-sampling approach, which only introduces minimal additions to the model parameters and computational costs. To handle scale ambiguity, mip-Grid generates multiple grids by applying simple convolution operations over the shared grid and uses the scale-aware coordinate to retrieve the appropriate features from the generated multiple grids. To test the effectiveness, we incorporated the proposed approach into the two recent representative grid-based methods, TensoRF and K-Planes. The experimental results demonstrated that mip-Grid greatly improved the rendering performance of both methods and showed comparable performance to mip-NeRF on multi-scale datasets while achieving significantly faster training time",
    "checked": false,
    "id": "9eafa581e0268d471b9c61c87db79710dab9274e",
    "semantic_title": "zip-nerf: anti-aliased grid-based neural radiance fields",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=P3Z59Okb5I": {
    "title": "EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient Federated Learning",
    "volume": "poster",
    "abstract": "Federated Learning (FL) is a decentralized machine learning paradigm that enables collaborative model training across dispersed nodes without having to force individual nodes to share data. However, its broad adoption is hindered by the high communication costs of transmitting a large number of model parameters. This paper presents EvoFed, a novel approach that integrates Evolutionary Strategies (ES) with FL to address these challenges. EvoFed employs a concept of `fitness-based information sharing', deviating significantly from the conventional model-based FL. Rather than exchanging the actual updated model parameters, each node transmits a distance-based similarity measure between the locally updated model and each member of the noise-perturbed model population. Each node, as well as the server, generates an identical population set of perturbed models in a completely synchronized fashion using the same random seeds. With properly chosen noise variance and population size, perturbed models can be combined to closely reflect the actual model updated using the local dataset, allowing the transmitted similarity measures (or fitness values) to carry nearly the complete information about the model parameters. As the population size is typically much smaller than the number of model parameters, the savings in communication load is large. The server aggregates these fitness values and is able to update the global model. This global fitness vector is then disseminated back to the nodes, each of which applies the same update to be synchronized to the global model. Our analysis shows that EvoFed converges, and our experimental results validate that at the cost of increased local processing loads, EvoFed achieves performance comparable to FedAvg while reducing overall communication requirements drastically in various practical settings",
    "checked": true,
    "id": "aa3e267ff6cde337ef633d91f82d6371c28dbd16",
    "semantic_title": "evofed: leveraging evolutionary strategies for communication-efficient federated learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C9wlNF1Ooj": {
    "title": "Bicriteria Multidimensional Mechanism Design with Side Information",
    "volume": "poster",
    "abstract": "We develop a versatile new methodology for multidimensional mechanism design that incorporates side information about agent types to generate high social welfare and high revenue simultaneously. Prominent sources of side information in practice include predictions from a machine-learning model trained on historical agent data, advice from domain experts, and even the mechanism designer's own gut instinct. In this paper we adopt a prior-free perspective that makes no assumptions on the correctness, accuracy, or source of the side information. First, we design a meta-mechanism that integrates input side information with an improvement of the classical VCG mechanism. The welfare, revenue, and incentive properties of our meta-mechanism are characterized by novel constructions we introduce based on the notion of a weakest competitor, which is an agent that has the smallest impact on welfare. We show that our meta-mechanism, when carefully instantiated, simultaneously achieves strong welfare and revenue guarantees parameterized by errors in the side information. When the side information is highly informative and accurate, our mechanism achieves welfare and revenue competitive with the total social surplus, and its performance decays continuously and gradually as the quality of the side information decreases. Finally, we apply our meta-mechanism to a setting where each agent's type is determined by a constant number of parameters. Specifically, agent types lie on constant-dimensional subspaces (of the potentially high-dimensional ambient type space) that are known to the mechanism designer. We use our meta-mechanism to obtain the first known welfare and revenue guarantees in this setting",
    "checked": true,
    "id": "0bebb8838a970efbfa668389eec8ac1d6fa564e5",
    "semantic_title": "bicriteria multidimensional mechanism design with side information",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ytTfonl9Wd": {
    "title": "Expressivity-Preserving GNN Simulation",
    "volume": "poster",
    "abstract": "We systematically investigate graph transformations that enable standard message passing to simulate state-of-the-art graph neural networks (GNNs) without loss of expressivity. Using these, many state-of-the-art GNNs can be implemented with message passing operations from standard libraries, eliminating many sources of implementation issues and allowing for better code optimization. We distinguish between weak and strong simulation: weak simulation achieves the same expressivity only after several message passing steps while strong simulation achieves this after every message passing step. Our contribution leads to a direct way to translate common operations of non-standard GNNs to graph transformations that allow for strong or weak simulation. Our empirical evaluation shows competitive predictive performance of message passing on transformed graphs for various molecular benchmark datasets, in several cases surpassing the original GNNs",
    "checked": false,
    "id": "71234f875820b2edb4382631cd0ac006226ab3d7",
    "semantic_title": "distribution preserving graph representation learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tt7bQnTdRm": {
    "title": "Secure Out-of-Distribution Task Generalization with Energy-Based Models",
    "volume": "poster",
    "abstract": "The success of meta-learning on out-of-distribution (OOD) tasks in the wild has proved to be hit-and-miss. To safeguard the generalization capability of the meta-learned prior knowledge to OOD tasks, in particularly safety-critical applications, necessitates detection of an OOD task followed by adaptation of the task towards the prior. Nonetheless, the reliability of estimated uncertainty on OOD tasks by existing Bayesian meta-learning methods is restricted by incomplete coverage of the feature distribution shift and insufficient expressiveness of the meta-learned prior. Besides, they struggle to adapt an OOD task, running parallel to the line of cross-domain task adaptation solutions which are vulnerable to overfitting. To this end, we build a single coherent framework that supports both detection and adaptation of OOD tasks, while remaining compatible with off-the-shelf meta-learning backbones. The proposed Energy-Based Meta-Learning (EBML) framework learns to characterize any arbitrary meta-training task distribution with the composition of two expressive neural-network-based energy functions. We deploy the sum of the two energy functions, being proportional to the joint distribution of a task, as a reliable score for detecting OOD tasks; during meta-testing, we adapt the OOD task to in-distribution tasks by energy minimization. Experiments on four regression and classification datasets demonstrate the effectiveness of our proposal",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3jAsfo8x8k": {
    "title": "PERFOGRAPH: A Numerical Aware Program Graph Representation for Performance Optimization and Program Analysis",
    "volume": "poster",
    "abstract": "The remarkable growth and significant success of machine learning have expanded its applications into programming languages and program analysis. However, a key challenge in adopting the latest machine learning methods is the representation of programming languages which has a direct impact on the ability of machine learning methods to reason about programs. The absence of numerical awareness, aggregate data structure information, and improper way of presenting variables in previous representation works have limited their performances. To overcome the limitations and challenges of current program representations, we propose a novel graph-based program representation called PERFOGRAPH. PERFOGRAPH can capture numerical information and the aggregate data structure by introducing new nodes and edges. Furthermore, we propose an adapted embedding method to incorporate numerical awareness. These enhancements make PERFOGRAPH a highly flexible and scalable representation that can effectively capture programs' intricate dependencies and semantics. Consequently, it serves as a powerful tool for various applications such as program analysis, performance optimization, and parallelism discovery. Our experimental results demonstrate that PERFOGRAPH outperforms existing representations and sets new state-of-the-art results by reducing the error rate by 7.4% (AMD dataset) and 10% (NVIDIA dataset) in the well-known Device Mapping challenge. It also sets new state-of-the-art results in various performance optimization tasks like Parallelism Discovery and Numa and Prefetchers Configuration prediction",
    "checked": true,
    "id": "bb344ef6280c7c6521587f27b4e1b4b8ab89dd75",
    "semantic_title": "perfograph: a numerical aware program graph representation for performance optimization and program analysis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qL3zPoWJda": {
    "title": "TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion",
    "volume": "poster",
    "abstract": "Continual learning (CL) has remained a persistent challenge for deep neural networks due to catastrophic forgetting (CF) of previously learned tasks. Several techniques such as weight regularization, experience rehearsal, and parameter isolation have been proposed to alleviate CF. Despite their relative success, these research directions have predominantly remained orthogonal and suffer from several shortcomings, while missing out on the advantages of competing strategies. On the contrary, the brain continually learns, accommodates, and transfers knowledge across tasks by simultaneously leveraging several neurophysiological processes, including neurogenesis, active forgetting, neuromodulation, metaplasticity, experience rehearsal, and context-dependent gating, rarely resulting in CF. Inspired by how the brain exploits multiple mechanisms concurrently, we propose TriRE, a novel CL paradigm that encompasses retaining the most prominent neurons for each task, revising and solidifying the extracted knowledge of current and past tasks, and actively promoting less active neurons for subsequent tasks through rewinding and relearning. Across CL settings, TriRE significantly reduces task interference and surpasses different CL approaches considered in isolation",
    "checked": true,
    "id": "62f0678a88fcb2a8e9257db270e911dfbc1b9684",
    "semantic_title": "trire: a multi-mechanism learning paradigm for continual knowledge retention and promotion",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TSuq3debnD": {
    "title": "Scalarization for Multi-Task and Multi-Domain Learning at Scale",
    "volume": "poster",
    "abstract": "Training a single model on multiple input domains and/or output tasks allows for compressing information from multiple sources into a unified backbone hence improves model efficiency. It also enables potential positive knowledge transfer across tasks/domains, leading to improved accuracy and data-efficient training. However, optimizing such networks is a challenge, in particular due to discrepancies between the different tasks or domains: Despite several hypotheses and solutions proposed over the years, recent work has shown that uniform scalarization training, i.e., simply minimizing the average of the task losses, yields on-par performance with more costly SotA optimization methods. This raises the issue of how well we understand the training dynamics of multi-task and multi-domain networks. In this work, we first devise a large-scale unified analysis of multi-domain and multi-task learning to better understand the dynamics of scalarization across varied task/domain combinations and model sizes. Following these insights, we then propose to leverage population-based training to efficiently search for the optimal scalarization weights when dealing with a large number of tasks or domains",
    "checked": true,
    "id": "611bd91e0050185319513493ad9a135a639438bd",
    "semantic_title": "scalarization for multi-task and multi-domain learning at scale",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eKFrXWb0sT": {
    "title": "Frequency-Enhanced Data Augmentation for Vision-and-Language Navigation",
    "volume": "poster",
    "abstract": "Vision-and-Language Navigation (VLN) is a challenging task that requires an agent to navigate through complex environments based on natural language instructions. In contrast to conventional approaches, which primarily focus on the spatial domain exploration, we propose a paradigm shift toward the Fourier domain. This alternative perspective aims to enhance visual-textual matching, ultimately improving the agent's ability to understand and execute navigation tasks based on the given instructions. In this study, we first explore the significance of high-frequency information in VLN and provide evidence that it is instrumental in bolstering visual-textual matching processes. Building upon this insight, we further propose a sophisticated and versatile Frequency-enhanced Data Augmentation (FDA) technique to improve the VLN model's capability of capturing critical high-frequency information. Specifically, this approach requires the agent to navigate in environments where only a subset of high-frequency visual information corresponds with the provided textual instructions, ultimately fostering the agent's ability to selectively discern and capture pertinent high-frequency features according to the given instructions. Promising results on R2R, RxR, CVDN and REVERIE demonstrate that our FDA can be readily integrated with existing VLN approaches, improving performance without adding extra parameters, and keeping models simple and efficient. The code is available at https://github.com/hekj/FDA",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X9Vjq9Fuhq": {
    "title": "Non-Convex Bilevel Optimization with Time-Varying Objective Functions",
    "volume": "poster",
    "abstract": "Bilevel optimization has become a powerful tool in a wide variety of machine learning problems. However, the current nonconvex bilevel optimization considers an offline dataset and static functions, which may not work well in emerging online applications with streaming data and time-varying functions. In this work, we study online bilevel optimization (OBO) where the functions can be time-varying and the agent continuously updates the decisions with online streaming data. To deal with the function variations and the unavailability of the true hypergradients in OBO, we propose a single-loop online bilevel optimizer with window averaging (SOBOW), which updates the outer-level decision based on a window average of the most recent hypergradient estimations stored in the memory. Compared to existing algorithms, SOBOW is computationally efficient and does not need to know previous functions. To handle the unique technical difficulties rooted in single-loop update and function variations for OBO, we develop a novel analytical technique that disentangles the complex couplings between decision variables, and carefully controls the hypergradient estimation error. We show that SOBOW can achieve a sublinear bilevel local regret under mild conditions. Extensive experiments across multiple domains corroborate the effectiveness of SOBOW",
    "checked": true,
    "id": "6f6e2139eb762f857ca1093e699de243fa0613dd",
    "semantic_title": "non-convex bilevel optimization with time-varying objective functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oss2jXD1Zs": {
    "title": "Linear Time Algorithms for k-means with Multi-Swap Local Search",
    "volume": "poster",
    "abstract": "The local search methods have been widely used to solve the clustering problems. In practice, local search algorithms for clustering problems mainly adapt the single-swap strategy, which enables them to handle large-scale datasets and achieve linear running time in the data size. However, compared with multi-swap local search algorithms, there is a considerable gap on the approximation ratios of the single-swap local search algorithms. Although the current multi-swap local search algorithms provide small constant approximation, the proposed algorithms tend to have large polynomial running time, which cannot be used to handle large-scale datasets. In this paper, we propose a multi-swap local search algorithm for the $k$-means problem with linear running time in the data size. Given a swap size $t$, our proposed algorithm can achieve a $(50(1+\\frac{1}{t})+\\epsilon)$-approximation, which improves the current best result 509 (ICML 2019) with linear running time in the data size. Our proposed method, compared with previous multi-swap local search algorithms, is the first one to achieve linear running time in the data size. To obtain a more practical algorithm for the problem with better clustering quality and running time, we propose a sampling-based method which accelerates the process of clustering cost update during swaps. Besides, a recombination mechanism is proposed to find potentially better solutions. Empirical experiments show that our proposed algorithms achieve better performances compared with branch and bound solver (NeurIPS 2022) and other existing state-of-the-art local search algorithms on both small and large datasets",
    "checked": false,
    "id": "1877ad548befec6308260bd98da42f2149b89ef1",
    "semantic_title": "an exact algorithm for stable instances of the $ k $-means problem with penalties in fixed-dimensional euclidean space",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eE5L1RkxW0": {
    "title": "Revisiting Visual Model Robustness: A Frequency Long-Tailed Distribution View",
    "volume": "poster",
    "abstract": "A widely discussed hypothesis regarding the cause of visual models' lack of robustness is that they can exploit human-imperceptible high-frequency components (HFC) in images, which in turn leads to model vulnerabilities, such as the adversarial examples. However, (1) inconsistent findings regarding the validation of this hypothesis reflect in a limited understanding of HFC, and (2) solutions inspired by the hypothesis tend to involve a robustness-accuracy trade-off and leaning towards suppressing the model's learning on HFC. In this paper, inspired by the long-tailed characteristic observed in frequency spectrum, we first formally define the HFC from long-tailed perspective and then revisit the relationship between HFC and model robustness. In the frequency long-tailed scenario, experimental results on common datasets and various network structures consistently indicate that models in standard training exhibit high sensitivity to HFC. We investigate the reason of the sensitivity, which reflects in model's under-fitting behavior on HFC. Furthermore, the cause of the model's under-fitting behavior is attributed to the limited information content in HFC. Based on these findings, we propose a Balance Spectrum Sampling (BaSS) strategy, which effectively counteracts the long-tailed effect and enhances the model's learning on HFC. Extensive experimental results demonstrate that our method achieves a substantially better robustness-accuracy trade-off when combined with existing defense methods, while also indicating the potential of encouraging HFC learning in improving model performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o91in9tDEs": {
    "title": "Distributional Policy Evaluation: a Maximum Entropy approach to Representation Learning",
    "volume": "poster",
    "abstract": "The Maximum Entropy (Max-Ent) framework has been effectively employed in a variety of Reinforcement Learning (RL) tasks. In this paper, we first propose a novel Max-Ent framework for policy evaluation in a distributional RL setting, named *Distributional Maximum Entropy Policy Evaluation* (D-Max-Ent PE). We derive a generalization-error bound that depends on the complexity of the representation employed, showing that this framework can explicitly take into account the features used to represent the state space while evaluating a policy. Then, we exploit these favorable properties to drive the representation learning of the state space in a Structural Risk Minimization fashion. We employ state-aggregation functions as feature functions and we specialize the D-Max-Ent approach into an algorithm, named *D-Max-Ent Progressive Factorization*, which constructs a progressively finer-grained representation of the state space by balancing the trade-off between preserving information (bias) and reducing the effective number of states, i.e., the complexity of the representation space (variance). Finally, we report the results of some illustrative numerical simulations, showing that the proposed algorithm matches the expected theoretical behavior and highlighting the relationship between aggregations and sample regimes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dLmDPVv19z": {
    "title": "Constrained Policy Optimization with Explicit Behavior Density For Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "Due to the inability to interact with the environment, offline reinforcement learning (RL) methods face the challenge of estimating the Out-of-Distribution (OOD) points. Existing methods for addressing this issue either control policy to exclude the OOD action or make the $Q$ function pessimistic. However, these methods can be overly conservative or fail to identify OOD areas accurately. To overcome this problem, we propose a Constrained Policy optimization with Explicit Behavior density (CPED) method that utilizes a flow-GAN model to explicitly estimate the density of behavior policy. By estimating the explicit density, CPED can accurately identify the safe region and enable exploration within the region, resulting in less conservative learning policies. We further provide theoretical results for both the flow-GAN estimator and performance guarantee for CPED by showing that CPED can find the optimal $Q$-function value. Empirically, CPED outperforms existing alternatives on various standard offline reinforcement learning tasks, yielding higher expected returns",
    "checked": false,
    "id": "d373059e20daa0b4d91ef2a5fdd09d56692e7ca5",
    "semantic_title": "supported policy optimization for offline reinforcement learning",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=zMNUNd9zs1": {
    "title": "Implicit variance regularization in non-contrastive SSL",
    "volume": "poster",
    "abstract": "Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with the EMA target network typically used with non-contrastive methods. Our analysis sheds light on the variance regularization mechanisms of non-contrastive SSL and lays the theoretical grounds for crafting novel loss functions that shape the learning dynamics of the predictor's spectrum",
    "checked": true,
    "id": "8fdb23e99b90e09412ff7660b428fc4104533d59",
    "semantic_title": "implicit variance regularization in non-contrastive ssl",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=FIv84qGPFT": {
    "title": "Pseudo-Likelihood Inference",
    "volume": "poster",
    "abstract": "Simulation-Based Inference (SBI) is a common name for an emerging family of approaches that infer the model parameters when the likelihood is intractable. Existing SBI methods either approximate the likelihood, such as Approximate Bayesian Computation (ABC) or directly model the posterior, such as Sequential Neural Posterior Estimation (SNPE). While ABC is efficient on low-dimensional problems, on higher-dimensional tasks, it is generally outperformed by SNPE, which leverages function approximation. In this paper, we propose Pseudo-Likelihood Inference (PLI), a new method that brings neural approximation into ABC, making it competitive on challenging Bayesian system identification tasks. By utilizing integral probability metrics, we introduce a smooth likelihood kernel with an adaptive bandwidth that is updated based on information-theoretic trust regions. Thanks to this formulation, our method (i) allows for optimizing neural posteriors via gradient descent, (ii) does not rely on summary statistics, and (iii) enables multiple observations as input. In comparison to SNPE, it leads to improved performance when more data is available. The effectiveness of PLI is evaluated on four classical SBI benchmark tasks and on a highly dynamic physical system, showing particular advantages on stochastic simulations and multi-modal posterior landscapes",
    "checked": false,
    "id": "41ae9b8e3e32cdf63a689cd1b8ad8761be41091a",
    "semantic_title": "generalized bayesian likelihood-free inference",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=yYUdgbmhh9": {
    "title": "Star-Shaped Denoising Diffusion Probabilistic Models",
    "volume": "poster",
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) provide the foundation for the recent breakthroughs in generative modeling. Their Markovian structure makes it difficult to define DDPMs with distributions other than Gaussian or discrete. In this paper, we introduce Star-Shaped DDPM (SS-DDPM). Its *star-shaped diffusion process* allows us to bypass the need to define the transition probabilities or compute posteriors. We establish duality between star-shaped and specific Markovian diffusions for the exponential family of distributions and derive efficient algorithms for training and sampling from SS-DDPMs. In the case of Gaussian distributions, SS-DDPM is equivalent to DDPM. However, SS-DDPMs provide a simple recipe for designing diffusion models with distributions such as Beta, von Mises–Fisher, Dirichlet, Wishart and others, which can be especially useful when data lies on a constrained manifold. We evaluate the model in different settings and find it competitive even on image data, where Beta SS-DDPM achieves results comparable to a Gaussian DDPM. Our implementation is available at https://github.com/andrey-okhotin/star-shaped",
    "checked": true,
    "id": "6bdc3a4a2c462acecc33722453831a79ac52ebf8",
    "semantic_title": "star-shaped denoising diffusion probabilistic models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=KAlSIL4tXU": {
    "title": "PromptIR: Prompting for All-in-One Image Restoration",
    "volume": "poster",
    "abstract": "Image restoration involves recovering a high-quality clean image from its degraded version. Deep learning-based methods have significantly improved image restoration performance, however, they have limited generalization ability to different degradation types and levels. This restricts their real-world application since it requires training individual models for each specific degradation and knowing the input degradation type to apply the relevant model. We present a prompt-based learning approach, PromptIR, for All-In-One image restoration that can effectively restore images from various types and levels of degradation. In particular, our method uses prompts to encode degradation-specific information, which is then used to dynamically guide the restoration network. This allows our method to generalize to different degradation types and levels, while still achieving state-of-the-art results on image denoising, deraining, and dehazing. Overall, PromptIR offers a generic and efficient plugin module with few lightweight prompts that can be used to restore images of various types and levels of degradation with no prior information on the corruptions present in the image. Our code and pre-trained models are available here: https://github.com/va1shn9v/PromptIR",
    "checked": false,
    "id": "c17f50017272c908cebdf2181675b7c6406b7218",
    "semantic_title": "promptir: prompting for all-in-one blind image restoration",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=paTESG8iSE": {
    "title": "Kernel-Based Tests for Likelihood-Free Hypothesis Testing",
    "volume": "poster",
    "abstract": "Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \\emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax sample complexity for non-parametric classes of densities under \\textit{maximum mean discrepancy} (MMD) separation; and (c) investigate the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images. For both problems we confirm the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off",
    "checked": true,
    "id": "6a0ef90c6d4be76f666b6431adea56c4104d287f",
    "semantic_title": "kernel-based tests for likelihood-free hypothesis testing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xPLaXSuSvQ": {
    "title": "Learning DAGs from Data with Few Root Causes",
    "volume": "poster",
    "abstract": "We present a novel perspective and algorithm for learning directed acyclic graphs (DAGs) from data generated by a linear structural equation model (SEM). First, we show that a linear SEM can be viewed as a linear transform that, in prior work, computes the data from a dense input vector of random valued root causes (as we will call them) associated with the nodes. Instead, we consider the case of (approximately) few root causes and also introduce noise in the measurement of the data. Intuitively, this means that the DAG data is produced by few data generating events whose effect percolates through the DAG. We prove identifiability in this new setting and show that the true DAG is the global minimizer of the $L^0$-norm of the vector of root causes. For data satisfying the few root causes assumption, we show superior performance compared to prior DAG learning methods",
    "checked": true,
    "id": "5d55b3ad5426547b002a8998818fee9cab0b1160",
    "semantic_title": "learning dags from data with few root causes",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=HszLRiHyfO": {
    "title": "Causal Component Analysis",
    "volume": "poster",
    "abstract": "Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically _dependent_) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed _Causal Component Analysis (CauCA)_. CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a corollary, this interventional perspective also leads to new identifiability results for nonlinear ICA—a special case of CauCA with an empty graph—requiring strictly fewer datasets than previous results. We introduce a likelihood-based approach using normalizing flows to estimate both the unmixing function and the causal mechanisms, and demonstrate its effectiveness through extensive synthetic experiments in the CauCA and ICA setting",
    "checked": true,
    "id": "263041108b4e045e6459aa437bbd0d869decb332",
    "semantic_title": "causal component analysis",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=I3k2NHt1zu": {
    "title": "Randomized and Deterministic Maximin-share Approximations for Fractionally Subadditive Valuations",
    "volume": "poster",
    "abstract": "We consider the problem of guaranteeing maximin-share ($\\MMS$) when allocating a set of indivisible items to a set of agents with fractionally subadditive ($\\XOS$) valuations. For $\\XOS$ valuations, it has been previously shown that for some instances no allocation can guarantee a fraction better than $1/2$ of maximin-share to all the agents. Also, a deterministic allocation exists that guarantees $0.219225$ of the maximin-share of each agent. Our results involve both deterministic and randomized allocations. On the deterministic side, we improve the best approximation guarantee for fractionally subadditive valuations to $3/13 = 0.230769$. We develop new ideas on allocating large items in our allocation algorithm which might be of independent interest. Furthermore, we investigate randomized algorithms and the Best-of-both-worlds fairness guarantees. We propose a randomized allocation that is $1/4$-$\\MMS$ ex-ante and $1/8$-$\\MMS$ ex-post for $\\XOS$ valuations. Moreover, we prove an upper bound of $3/4$ on the ex-ante guarantee for this class of valuations",
    "checked": true,
    "id": "842167ab7f107f0787947b489cedbb0f59338179",
    "semantic_title": "randomized and deterministic maximin-share approximations for fractionally subadditive valuations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IKvxmnHjkL": {
    "title": "Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks",
    "volume": "poster",
    "abstract": "We analytically investigate how over-parameterization of models in randomized machine learning algorithms impacts the information leakage about their training data. Specifically, we prove a privacy bound for the KL divergence between model distributions on worst-case neighboring datasets, and explore its dependence on the initialization, width, and depth of fully connected neural networks. We find that this KL privacy bound is largely determined by the expected squared gradient norm relative to model parameters during training. Notably, for the special setting of linearized network, our analysis indicates that the squared gradient norm (and therefore the escalation of privacy loss) is tied directly to the per-layer variance of the initialization distribution. By using this analysis, we demonstrate that privacy bound improves with increasing depth under certain initializations (LeCun and Xavier), while degrades with increasing depth under other initializations (He and NTK). Our work reveals a complex interplay between privacy and depth that depends on the chosen initialization distribution. We further prove excess empirical risk bounds under a fixed KL privacy budget, and show that the interplay between privacy utility trade-off and depth is similarly affected by the initialization",
    "checked": true,
    "id": "f494f0563fe1c7f6f3947b601e0f2344f500bb1a",
    "semantic_title": "initialization matters: privacy-utility analysis of overparameterized neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0Tq1RGJBid": {
    "title": "A Fast and Accurate Estimator for Large Scale Linear Model via Data Averaging",
    "volume": "poster",
    "abstract": "This work is concerned with the estimation problem of linear model when the sample size is extremely large and the data dimension can vary with the sample size. In this setting, the least square estimator based on the full data is not feasible with limited computational resources. Many existing methods for this problem are based on the sketching technique which uses the sketched data to perform least square estimation. We derive fine-grained lower bounds of the conditional mean squared error for sketching methods. For sampling methods, our lower bound provides an attainable optimal convergence rate. Our result implies that when the dimension is large, there is hardly a sampling method can have a faster convergence rate than the uniform sampling method. To achieve a better statistical performance, we propose a new sketching method based on data averaging. The proposed method reduces the original data to a few averaged observations. These averaged observations still satisfy the linear model and are used to estimate the regression coefficients. The asymptotic behavior of the proposed estimation procedure is studied. Our theoretical results show that the proposed method can achieve a faster convergence rate than the optimal convergence rate for sampling methods. Theoretical and numerical results show that the proposed estimator has good statistical performance as well as low computational cost",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YSFQRVkkl0": {
    "title": "Implicit Regularization in Over-Parameterized Support Vector Machine",
    "volume": "poster",
    "abstract": "In this paper, we design a regularization-free algorithm for high-dimensional support vector machines (SVMs) by integrating over-parameterization with Nesterov's smoothing method, and provide theoretical guarantees for the induced implicit regularization phenomenon. In particular, we construct an over-parameterized hinge loss function and estimate the true parameters by leveraging regularization-free gradient descent on this loss function. The utilization of Nesterov's method enhances the computational efficiency of our algorithm, especially in terms of determining the stopping criterion and reducing computational complexity. With appropriate choices of initialization, step size, and smoothness parameter, we demonstrate that unregularized gradient descent achieves a near-oracle statistical convergence rate. Additionally, we verify our theoretical findings through a variety of numerical experiments and compare the proposed method with explicit regularization. Our results illustrate the advantages of employing implicit regularization via gradient descent in conjunction with over-parameterization in sparse SVMs",
    "checked": true,
    "id": "1cc3d262ec0781f86814edcc933bdfb3ba1341f1",
    "semantic_title": "implicit regularization in over-parameterized support vector machine",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jvYXln6Gzn": {
    "title": "Auxiliary Losses for Learning Generalizable Concept-based Models",
    "volume": "poster",
    "abstract": "The increasing use of neural networks in various applications has lead to increasing apprehensions, underscoring the necessity to understand their operations beyond mere final predictions. As a solution to enhance model transparency, Concept Bottleneck Models (CBMs) have gained popularity since their introduction. CBMs essentially limit the latent space of a model to human-understandable high-level concepts. While beneficial, CBMs have been reported to often learn irrelevant concept representations that consecutively damage model performance. To overcome the performance trade-off, we propose a cooperative-Concept Bottleneck Model (coop-CBM). The concept representation of our model is particularly meaningful when fine-grained concept labels are absent. Furthermore, we introduce the concept orthogonal loss (COL) to encourage the separation between the concept representations and to reduce the intra-concept distance. This paper presents extensive experiments on real-world datasets for image classification tasks, namely CUB, AwA2, CelebA and TIL. We also study the performance of coop-CBM models under various distributional shift settings. We show that our proposed method achieves higher accuracy in all distributional shift settings even compared to the black-box models with the highest concept accuracy",
    "checked": true,
    "id": "c2f929c9c8d5caa3ac12fd2f7b134c3c1bc646c0",
    "semantic_title": "auxiliary losses for learning generalizable concept-based models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ifbF4WdT8f": {
    "title": "EvoPrompting: Language Models for Code-Level Neural Architecture Search",
    "volume": "poster",
    "abstract": "Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as general adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design *novel* architectures that outperform current state-of-the-art models on 21 out of 30 algorithmic reasoning tasks while maintaining similar model size. EvoPrompting is successful at designing accurate and efficient neural network architectures across a variety of machine learning tasks, while also being general enough for easy adaptation to other tasks beyond neural network design",
    "checked": true,
    "id": "411b16add23976ffcdf6422f932453f6ebcca119",
    "semantic_title": "evoprompting: language models for code-level neural architecture search",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=XEBzQP3e7B": {
    "title": "GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection",
    "volume": "poster",
    "abstract": "Detecting out-of-distribution (OOD) examples is crucial to guarantee the reliability and safety of deep neural networks in real-world settings. In this paper, we offer an innovative perspective on quantifying the disparities between in-distribution (ID) and OOD data---analyzing the uncertainty that arises when models attempt to explain their predictive decisions. This perspective is motivated by our observation that gradient-based attribution methods encounter challenges in assigning feature importance to OOD data, thereby yielding divergent explanation patterns. Consequently, we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for OOD detection: the zero-deflation abnormality and the channel-wise average abnormality. We then propose GAIA, a simple and effective approach that incorporates Gradient Abnormality Inspection and Aggregation. The effectiveness of GAIA is validated on both commonly utilized (CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces the average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to advanced post-hoc methods",
    "checked": true,
    "id": "08925eef04eada4dd46dd3a33ea35f05795b12a9",
    "semantic_title": "gaia: delving into gradient-based attribution abnormality for out-of-distribution detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LswqtKU9op": {
    "title": "Prompt-augmented Temporal Point Process for Streaming Event Sequence",
    "volume": "poster",
    "abstract": "Neural Temporal Point Processes (TPPs) are the prevalent paradigm for modeling continuous-time event sequences, such as user activities on the web and financial transactions. In real world applications, the event data typically comes in a streaming manner, where the distribution of the patterns may shift over time. Under the privacy and memory constraints commonly seen in real scenarios, how to continuously monitor a TPP to learn the streaming event sequence is an important yet under-investigated problem. In this work, we approach this problem by adopting Continual Learning (CL), which aims to enable a model to continuously learn a sequence of tasks without catastrophic forgetting. While CL for event sequence is less well studied, we present a simple yet effective framework, PromptTPP, by integrating the base TPP with a continuous-time retrieval prompt pool. In our proposed framework, prompts are small learnable parameters, maintained in a memory space and jointly optimized with the base TPP so that the model is properly instructed to learn event streams arriving sequentially without buffering past examples or task-specific attributes. We formalize a novel and realistic experimental setup for modeling event streams, where PromptTPP consistently sets state-of-the-art performance across two real user behavior datasets",
    "checked": true,
    "id": "f3f9cd510ab2e0518e85e1ea88e5c8d9a9d98202",
    "semantic_title": "prompt-augmented temporal point process for streaming event sequence",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=H2udtfMbl4": {
    "title": "Grassmann Manifold Flows for Stable Shape Generation",
    "volume": "poster",
    "abstract": "Recently, studies on machine learning have focused on methods that use symmetry implicit in a specific manifold as an inductive bias. Grassmann manifolds provide the ability to handle fundamental shapes represented as shape spaces, enabling stable shape analysis. In this paper, we present a novel approach in which we establish the theoretical foundations for learning distributions on the Grassmann manifold via continuous normalization flows, with the explicit goal of generating stable shapes. Our approach facilitates more robust generation by effectively eliminating the influence of extraneous transformations, such as rotations and inversions, through learning and generating within a Grassmann manifold designed to accommodate the essential shape information of the object. The experimental results indicated that the proposed method could generate high-quality samples by capturing the data structure. Furthermore, the proposed method significantly outperformed state-of-the-art methods in terms of the log-likelihood or evidence lower bound. The results obtained are expected to stimulate further research in this field, leading to advances for stable shape generation and analysis",
    "checked": true,
    "id": "a3ff13db01ffd9bac96c10e7c589aad0948e9b1d",
    "semantic_title": "grassmann manifold flows for stable shape generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UuNd9A6noD": {
    "title": "Bayesian Optimisation of Functions on Graphs",
    "volume": "poster",
    "abstract": "The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework",
    "checked": true,
    "id": "95ba649a8db6ab4d6a4dfc05aa1e38e331f07129",
    "semantic_title": "bayesian optimisation of functions on graphs",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=4W9FVg1j6I": {
    "title": "Structured State Space Models for In-Context Reinforcement Learning",
    "volume": "poster",
    "abstract": "Structured state space sequence (S4) models have recently achieved state-of-the-art performance on long-range sequence modeling tasks. These models also have fast inference speeds and parallelisable training, making them potentially useful in many reinforcement learning settings. We propose a modification to a variant of S4 that enables us to initialise and reset the hidden state in parallel, allowing us to tackle reinforcement learning tasks. We show that our modified architecture runs asymptotically faster than Transformers in sequence length and performs better than RNN's on a simple memory-based task. We evaluate our modified architecture on a set of partially-observable environments and find that, in practice, our model outperforms RNN's while also running over five times faster. Then, by leveraging the model's ability to handle long-range sequences, we achieve strong performance on a challenging meta-learning task in which the agent is given a randomly-sampled continuous control environment, combined with a randomly-sampled linear projection of the environment's observations and actions. Furthermore, we show the resulting model can adapt to out-of-distribution held-out tasks. Overall, the results presented in this paper show that structured state space models are fast and performant for in-context reinforcement learning tasks. We provide code at https://github.com/luchris429/s5rl",
    "checked": true,
    "id": "d98b5c1d0f9a4e39dc79ea7a3f74e54789df5e13",
    "semantic_title": "structured state space models for in-context reinforcement learning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=RFgv7cfMUy": {
    "title": "On-the-Fly Adapting Code Summarization on Trainable Cost-Effective Language Models",
    "volume": "poster",
    "abstract": "Deep learning models are emerging to summarize source code to comment, facilitating tasks of code documentation and program comprehension. Scaled-up large language models trained on large open corpus have achieved good performance in such tasks. However, in practice, the subject code in one certain project can be specific, which may not align with the overall training corpus. Some code samples from other projects may be contradictory and introduce inconsistencies when the models try to fit all the samples. In this work, we introduce a novel approach, Adacom, to improve the performance of comment generators by on-the-fly model adaptation. This research is motivated by the observation that deep comment generators often need to strike a balance as they need to fit all the training samples. Specifically, for one certain target code $c$, some training samples $S_p$ could have made more contributions while other samples $S_o$ could have counter effects. However, the traditional fine-tuned models need to fit both $S_p$ and $S_o$ from a global perspective, leading to compromised performance for one certain target code $c$. In this context, we design Adacom to (1) detect whether the model might have a compromised performance on a target code $c$ and (2) retrieve a few helpful training samples $S_p$ that have contradictory samples in the training dataset and, (3) adapt the model on the fly by re-training the $S_p$ to strengthen the helpful samples and unlearn the harmful samples. Our extensive experiments on 7 comment generators and 4 public datasets show that (1) can significantly boost the performance of comment generation (BLEU4 score by on average 14.9\\%, METEOR by 12.2\\%, and ROUGE-L by 7.4\\%), (2) the adaptation on one code sample is cost-effective and acceptable as an on-the-fly solution, and (3) can adapt well on out-of-distribution code samples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fX64q0SNfL": {
    "title": "Sample based Explanations via Generalized Representers",
    "volume": "poster",
    "abstract": "We propose a general class of sample based explanations of machine learning models, which we term generalized representers. To measure the effect of a training sample on a model's test prediction, generalized representers use two components: a global sample importance that quantifies the importance of the training point to the model and is invariant to test samples, and a local sample importance that measures similarity between the training sample and the test point with a kernel. A key contribution of the paper is to show that generalized representers are the only class of sample based explanations satisfying a natural set of axiomatic properties. We discuss approaches to extract global importances given a kernel, and also natural choices of kernels given modern non-linear models. As we show, many popular existing sample based explanations could be cast as generalized representers with particular choices of kernels and approaches to extract global importances. Additionally, we conduct empirical comparisons of different generalized representers on two image classification datasets",
    "checked": true,
    "id": "968a5d418c8a4b68eb8b95ec9f72dce2b776d4c9",
    "semantic_title": "sample based explanations via generalized representers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l2VKZkolT7": {
    "title": "Feature Likelihood Score: Evaluating the Generalization of Generative Models Using Samples",
    "volume": "poster",
    "abstract": "The past few years have seen impressive progress in the development of deep generative models capable of producing high-dimensional, complex, and photo-realistic data. However, current methods for evaluating such models remain incomplete: standard likelihood-based metrics do not always apply and rarely correlate with perceptual fidelity, while sample-based metrics, such as FID, are insensitive to overfitting, i.e., inability to generalize beyond the training set. To address these limitations, we propose a new metric called the Feature Likelihood Score (FLS), a parametric sample-based score that uses density estimation to provide a comprehensive trichotomic evaluation accounting for novelty (i.e., different from the training samples), fidelity, and diversity of generated samples. We empirically demonstrate the ability of FLS to identify specific overfitting problem cases, where previously proposed metrics fail. We also extensively evaluate FLS on various image datasets and model classes, demonstrating its ability to match intuitions of previous metrics like FID while offering a more comprehensive evaluation of generative models",
    "checked": false,
    "id": "757de10dd72ff25810e98d56a4733b77fd31c066",
    "semantic_title": "feature likelihood score: evaluating generalization of generative models using samples",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=cay8LnKSro": {
    "title": "Empowering Convolutional Neural Nets with MetaSin Activation",
    "volume": "poster",
    "abstract": "ReLU networks have remained the default choice for models in the area of image prediction despite their well-established spectral bias towards learning low frequencies faster, and consequently their difficulty of reproducing high frequency visual details. As an alternative, sin networks showed promising results in learning implicit representations of visual data. However training these networks in practically relevant settings proved to be difficult, requiring careful initialization, dealing with issues due to inconsistent gradients, and a degeneracy in local minima. In this work, we instead propose replacing a baseline network's existing activations with a novel ensemble function with trainable parameters. The proposed MetaSin activation can be trained reliably without requiring intricate initialization schemes, and results in consistently lower test loss compared to alternatives. We demonstrate our method in the areas of Monte-Carlo denoising and image resampling where we set new state-of-the-art through a knowledge distillation based training procedure. We present ablations on hyper-parameter settings, comparisons with alternative activation function formulations, and discuss the use of our method in other domains, such as image classification",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VnfeOjR73Q": {
    "title": "Bounded rationality in structured density estimation",
    "volume": "poster",
    "abstract": "Learning to accurately represent environmental uncertainty is crucial for adaptive and optimal behaviors in various cognitive tasks. However, it remains unclear how the human brain, constrained by finite cognitive resources, constructs an internal model from an infinite space of probability distributions. In this study, we explore how these learned distributions deviate from the ground truth, resulting in observable inconsistency in a novel structured density estimation task. During each trial, human participants were asked to form and report the latent probability distribution functions underlying sequentially presented independent observations. As the number of observations increased, the reported predictive density became closer to the ground truth. Nevertheless, we observed an intriguing inconsistency in human structure estimation, specifically a large error in the number of reported clusters. Such inconsistency is invariant to the scale of the distribution and persists across stimulus modalities. We modeled uncertainty learning as approximate Bayesian inference in a nonparametric mixture prior of distributions. Human reports were best explained under resource rationality embodied in a decaying tendency towards model expansion. Our study offers insights into human cognitive processes under uncertainty and lays the groundwork for further exploration of resource-rational representations in the brain under more complex tasks",
    "checked": false,
    "id": "0917a33b5b99919cc6d7694555b45bd534bbb3e1",
    "semantic_title": "information theoretic structured generative modeling",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=5q8xovQF7r": {
    "title": "Pairwise Causality Guided Transformers for Event Sequences",
    "volume": "poster",
    "abstract": "Although pairwise causal relations have been extensively studied in observational longitudinal analyses across many disciplines, incorporating knowledge of causal pairs into deep learning models for temporal event sequences remains largely unexplored. In this paper, we propose a novel approach for enhancing the performance of transformer-based models in multivariate event sequences by injecting pairwise qualitative causal knowledge such as `event Z amplifies future occurrences of event Y'. We establish a new framework for causal inference in temporal event sequences using a transformer architecture, providing a theoretical justification for our approach, and show how to obtain unbiased estimates of the proposed measure. Experimental results demonstrate that our approach outperforms several state-of-the-art models in terms of prediction accuracy by effectively leveraging knowledge about causal pairs. We also consider a unique application where we extract knowledge around sequences of societal events by generating them from a large language model, and demonstrate how a causal knowledge graph can help with event prediction in such sequences. Overall, our framework offers a practical means of improving the performance of transformer-based models in multivariate event sequences by explicitly exploiting pairwise causal information",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bHS7qjLOAy": {
    "title": "Riemannian Laplace approximations for Bayesian neural networks",
    "volume": "poster",
    "abstract": "Bayesian neural networks often approximate the weight-posterior with a Gaussian distribution. However, practical posteriors are often, even locally, highly non-Gaussian, and empirical performance deteriorates. We propose a simple parametric approximate posterior that adapts to the shape of the true posterior through a Riemannian metric that is determined by the log-posterior gradient. We develop a Riemannian Laplace approximation where samples naturally fall into weight-regions with low negative log-posterior. We show that these samples can be drawn by solving a system of ordinary differential equations, which can be done efficiently by leveraging the structure of the Riemannian metric and automatic differentiation. Empirically, we demonstrate that our approach consistently improves over the conventional Laplace approximation across tasks. We further show that, unlike the conventional Laplace approximation, our method is not overly sensitive to the choice of prior, which alleviates a practical pitfall of current approaches",
    "checked": true,
    "id": "57ff0410cfabd77d2846bda1aef9744da15e475e",
    "semantic_title": "riemannian laplace approximations for bayesian neural networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=02Uc0G2Cym": {
    "title": "Robustness Guarantees for Adversarially Trained Neural Networks",
    "volume": "poster",
    "abstract": "We study robust adversarial training of two-layer neural networks as a bi-level optimization problem. In particular, for the inner loop that implements the adversarial attack during training using projected gradient descent (PGD), we propose maximizing a \\emph{lower bound} on the $0/1$-loss by reflecting a surrogate loss about the origin. This allows us to give a convergence guarantee for the inner-loop PGD attack. Furthermore, assuming the data is linearly separable, we provide precise iteration complexity results for end-to-end adversarial training, which holds for any width and initialization. We provide empirical evidence to support our theoretical results",
    "checked": false,
    "id": "1b9c0eb395118579be38feb9ecae1a0019ebc140",
    "semantic_title": "robustness against adversarial attacks in neural networks using incremental dissipativity",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=FUnEkOkodU": {
    "title": "Token-Scaled Logit Distillation for Ternary Weight Generative Language Models",
    "volume": "poster",
    "abstract": "Generative Language Models (GLMs) have shown impressive performance in tasks such as text generation, understanding, and reasoning. However, the large model size poses challenges for practical deployment. To solve this problem, Quantization-Aware Training (QAT) has become increasingly popular. However, current QAT methods for generative models have resulted in a noticeable loss of accuracy. To counteract this issue, we propose a novel knowledge distillation method specifically designed for GLMs. Our method, called token-scaled logit distillation, prevents overfitting and provides superior learning from the teacher model and ground truth. This research marks the first evaluation of ternary weight quantization-aware training of large-scale GLMs with less than 1.0 degradation in perplexity and achieves enhanced accuracy in tasks like common-sense QA and arithmetic reasoning as well as natural language understanding. Our code is available at https://github.com/aiha-lab/TSLD",
    "checked": true,
    "id": "d58c87575a4e00da93be0d63af568ac10532aab4",
    "semantic_title": "token-scaled logit distillation for ternary weight generative language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XSCYxDp3yE": {
    "title": "A Bayesian Approach To Analysing Training Data Attribution In Deep Learning",
    "volume": "poster",
    "abstract": "Training data attribution (TDA) techniques find influential training data for the model's prediction on the test data of interest. They approximate the impact of down- or up-weighting a particular training sample. While conceptually useful, they are hardly applicable to deep models in practice, particularly because of their sensitivity to different model initialisation. In this paper, we introduce a Bayesian perspective on the TDA task, where the learned model is treated as a Bayesian posterior and the TDA estimates as random variables. From this novel viewpoint, we observe that the influence of an individual training sample is often overshadowed by the noise stemming from model initialisation and SGD batch composition. Based on this observation, we argue that TDA can only be reliably used for explaining deep model predictions that are consistently influenced by certain training data, independent of other noise factors. Our experiments demonstrate the rarity of such noise-independent training-test data pairs but confirm their existence. We recommend that future researchers and practitioners trust TDA estimates only in such cases. Further, we find a disagreement between ground truth and estimated TDA distributions and encourage future work to study this gap. Code is provided at https://github.com/ElisaNguyen/bayesian-tda",
    "checked": true,
    "id": "a9b5d16a3a66ad54ec34acbc3acacf89627330a4",
    "semantic_title": "a bayesian approach to analysing training data attribution in deep learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=tSEeRl7ACo": {
    "title": "Human-Guided Complexity-Controlled Abstractions",
    "volume": "poster",
    "abstract": "Neural networks often learn task-specific latent representations that fail to generalize to novel settings or tasks. Conversely, humans learn discrete representations (i.e., concepts or words) at a variety of abstraction levels (e.g., \"bird\" vs. \"sparrow'\") and use the appropriate abstraction based on tasks. Inspired by this, we train neural models to generate a spectrum of discrete representations, and control the complexity of the representations (roughly, how many bits are allocated for encoding inputs) by tuning the entropy of the distribution over representations. In finetuning experiments, using only a small number of labeled examples for a new task, we show that (1) tuning the representation to a task-appropriate complexity level supports the greatest finetuning performance, and (2) in a human-participant study, users were able to identify the appropriate complexity level for a downstream task via visualizations of discrete representations. Our results indicate a promising direction for rapid model finetuning by leveraging human insight",
    "checked": true,
    "id": "9ada63c92c53af1d13813a182180e910efc0d3c0",
    "semantic_title": "human-guided complexity-controlled abstractions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZARAiV25CW": {
    "title": "Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation",
    "volume": "poster",
    "abstract": "Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a parameter and observed data. The trained network can then be used with MCMC to infer GBI posteriors for any observation without running additional simulations. We show that, on several benchmark tasks, ACE accurately predicts cost and provides predictive simulations that are closer to synthetic observations than other SBI methods, especially for misspecified simulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley model given real intracellular recordings from the Allen Cell Types Database. ACE identifies better data-matching parameters while being an order of magnitude more simulation-efficient than a standard SBI method. In summary, ACE combines the strengths of SBI methods and GBI to perform robust and simulation-amortized inference for scientific simulators",
    "checked": true,
    "id": "1deee4545bd95160e93914c7418b4d4ef6151837",
    "semantic_title": "generalized bayesian inference for scientific simulators via amortized cost estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IkD1EWFF8c": {
    "title": "Perturbation Towards Easy Samples Improves Targeted Adversarial Transferability",
    "volume": "poster",
    "abstract": "The transferability of adversarial perturbations provides an effective shortcut for black-box attacks. Targeted perturbations have greater practicality but are more difficult to transfer between models. In this paper, we experimentally and theoretically demonstrated that neural networks trained on the same dataset have more consistent performance in High-Sample-Density-Regions (HSDR) of each class instead of low sample density regions. Therefore, in the target setting, adding perturbations towards HSDR of the target class is more effective in improving transferability. However, density estimation is challenging in high-dimensional scenarios. Further theoretical and experimental verification demonstrates that easy samples with low loss are more likely to be located in HSDR. Perturbations towards such easy samples in the target class can avoid density estimation for HSDR location. Based on the above facts, we verified that adding perturbations to easy samples in the target class improves targeted adversarial transferability of existing attack methods. A generative targeted attack strategy named Easy Sample Matching Attack (ESMA) is proposed, which has a higher success rate for targeted attacks and outperforms the SOTA generative method. Moreover, ESMA requires only $5\\%$ of the storage space and much less computation time comparing to the current SOTA, as ESMA attacks all classes with only one model instead of seperate models for each class. Our code is available at https://github.com/gjq100/ESMA",
    "checked": false,
    "id": "96ea0658b9813706834966433107f9343e8389db",
    "semantic_title": "danaa: towards transferable attacks with double adversarial neuron attribution",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SLx7paoaTU": {
    "title": "Variational Annealing on Graphs for Combinatorial Optimization",
    "volume": "poster",
    "abstract": "Several recent unsupervised learning methods use probabilistic approaches to solve combinatorial optimization (CO) problems based on the assumption of statistically independent solution variables. We demonstrate that this assumption imposes performance limitations in particular on difficult problem instances. Our results corroborate that an autoregressive approach which captures statistical dependencies among solution variables yields superior performance on many popular CO problems. We introduce Subgraph Tokenization in which the configuration of a set of solution variables is represented by a single token. This tokenization technique alleviates the drawback of the long sequential sampling procedure which is inherent to autoregressive methods without sacrificing expressivity. Importantly, we theoretically motivate an annealed entropy regularization and show empirically that it is essential for efficient and stable learning",
    "checked": true,
    "id": "687eaf56170c4ac3b8c97badc4f98ad187bfef92",
    "semantic_title": "variational annealing on graphs for combinatorial optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OMDgOjdqoZ": {
    "title": "EICIL: Joint Excitatory Inhibitory Cycle Iteration Learning for Deep Spiking Neural Networks",
    "volume": "poster",
    "abstract": "Spiking neural networks (SNNs) have undergone continuous development and extensive study for decades, leading to increased biological plausibility and optimal energy efficiency. However, traditional training methods for deep SNNs have some limitations, as they rely on strategies such as pre-training and fine-tuning, indirect coding and reconstruction, and approximate gradients. These strategies lack a complete training model and require gradient approximation. To overcome these limitations, we propose a novel learning method named Joint Excitatory Inhibitory Cycle Iteration learning for Deep Spiking Neural Networks (EICIL) that integrates both excitatory and inhibitory behaviors inspired by the signal transmission of biological neurons.By organically embedding these two behavior patterns into one framework, the proposed EICIL significantly improves the bio-mimicry and adaptability of spiking neuron models, as well as expands the representation space of spiking neurons. Extensive experiments based on EICIL and traditional learning methods demonstrate that EICIL outperforms traditional methods on various datasets, such as CIFAR10 and CIFAR100, revealing the crucial role of the learning approach that integrates both behaviors during training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XmpthbaJql": {
    "title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone",
    "volume": "poster",
    "abstract": "Parameter-efficient tuning has become a trend in transferring large-scale foundation models to downstream applications. Existing methods typically embed some light-weight tuners into the backbone, where both the design and the learning of the tuners are highly dependent on the base model. This work offers a new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners from the backbone. With both theoretical and empirical evidence, we show that popular tuning approaches have their equivalent counterparts under our unbinding formulation, and hence can be integrated into our framework effortlessly. Thanks to the structural disentanglement, we manage to free the design of tuners from the network architecture, facilitating flexible combination of various tuning strategies. We further propose a memory-efficient variant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners) is effectively detached from the main branch, such that the gradients are back-propagated only to the tuners but not to the backbone. Such a detachment also allows one-time backbone forward for multi-task inference. Extensive experiments on both discriminative and generative tasks demonstrate the superiority of our method over existing alternatives from the perspectives of efficacy and efficiency. Project page: https://res-tuning.github.io/",
    "checked": true,
    "id": "227204838c27d26c524cb3e5fa7ee7101a32aab9",
    "semantic_title": "res-tuning: a flexible and efficient tuning paradigm via unbinding tuner from backbone",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aDLmRMb0K9": {
    "title": "Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning",
    "volume": "poster",
    "abstract": "We study matrix estimation problems arising in reinforcement learning with low-rank structure. In low-rank bandits, the matrix to be recovered specifies the expected arm rewards, and for low-rank Markov Decision Processes (MDPs), it characterizes the transition kernel of the MDP. In both cases, each entry of the matrix carries important information, and we seek estimation methods with low entry-wise prediction error. Importantly, these methods further need to accommodate for inherent correlations in the available data (e.g. for MDPs, the data consists of system trajectories). We investigate the performance of simple spectral-based matrix estimation approaches: we show that they efficiently recover the singular subspaces of the matrix and exhibit nearly-minimal entry-wise prediction error. These new results on low-rank matrix estimation make it possible to devise reinforcement learning algorithms that fully exploit the underlying low-rank structure. We provide two examples of such algorithms: a regret minimization algorithm for low-rank bandit problems, and a best policy identification algorithm for low-rank MDPs. Both algorithms yield state-of-the-art performance guarantees",
    "checked": true,
    "id": "4117da29b7c4020a637bcd30e9e62c222602604d",
    "semantic_title": "spectral entry-wise matrix estimation for low-rank reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B7QRV4XXiK": {
    "title": "An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient",
    "volume": "poster",
    "abstract": "Restricting the variance of a policy's return is a popular choice in risk-averse Reinforcement Learning (RL) due to its clear mathematical definition and easy interpretability. Traditional methods directly restrict the total return variance. Recent methods restrict the per-step reward variance as a proxy. We thoroughly examine the limitations of these variance-based methods, such as sensitivity to numerical scale and hindering of policy learning, and propose to use an alternative risk measure, Gini deviation, as a substitute. We study various properties of this new risk measure and derive a policy gradient algorithm to minimize it. Empirical evaluation in domains where risk-aversion can be clearly defined, shows that our algorithm can mitigate the limitations of variance-based risk measures and achieves high return with low risk in terms of variance and Gini deviation when others fail to learn a reasonable policy",
    "checked": true,
    "id": "486eed2b7f940b88ceeacc92297b765dd85bcbfe",
    "semantic_title": "an alternative to variance: gini deviation for risk-averse policy gradient",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oSYjkJKHZx": {
    "title": "Neural Harmonics: Bridging Spectral Embedding and Matrix Completion in Self-Supervised Learning",
    "volume": "poster",
    "abstract": "Self-supervised methods received tremendous attention thanks to their seemingly heuristic approach to learning representations that respect the semantics of the data without any apparent supervision in the form of labels. A growing body of literature is already being published in an attempt to build a coherent and theoretically grounded understanding of the workings of a zoo of losses used in modern self-supervised representation learning methods. In this paper, we attempt to provide an understanding from the perspective of a Laplace operator and connect the inductive bias stemming from the augmentation process to a low-rank matrix completion problem. To this end, we leverage the results from low-rank matrix completion to provide theoretical analysis on the convergence of modern SSL methods and a key property that affects their downstream performance",
    "checked": false,
    "id": "f4f657d8e256a3ab0e506f263a2a8d0439c81df5",
    "semantic_title": "spectal harmonics: bridging spectral embedding and matrix completion in self-supervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=05P1U0jk8r": {
    "title": "Exploiting hidden structures in non-convex games for convergence to Nash equilibrium",
    "volume": "poster",
    "abstract": "A wide array of modern machine learning applications – from adversarial models to multi-agent reinforcement learning – can be formulated as non-cooperative games whose Nash equilibria represent the system's desired operational states. Despite having a highly non-convex loss landscape, many cases of interest possess a latent convex structure that could potentially be leveraged to yield convergence to an equilibrium. Driven by this observation, our paper proposes a flexible first-order method that successfully exploits such \"hidden structures\" and achieves convergence under minimal assumptions for the transformation connecting the players' control variables to the game's latent, convex-structured layer. The proposed method – which we call preconditioned hidden gradient descent (PHGD) – hinges on a judiciously chosen gradient preconditioning scheme related to natural gradient methods. Importantly, we make no separability assumptions for the game's hidden structure, and we provide explicit convergence rate guarantees for both deterministic and stochastic environments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hE7PG1lUZx": {
    "title": "UniTSFace: Unified Threshold Integrated Sample-to-Sample Loss for Face Recognition",
    "volume": "poster",
    "abstract": "Sample-to-class-based face recognition models can not fully explore the cross-sample relationship among large amounts of facial images, while sample-to-sample-based models require sophisticated pairing processes for training. Furthermore, neither method satisfies the requirements of real-world face verification applications, which expect a unified threshold separating positive from negative facial pairs. In this paper, we propose a unified threshold integrated sample-to-sample based loss (USS loss), which features an explicit unified threshold for distinguishing positive from negative pairs. Inspired by our USS loss, we also derive the sample-to-sample based softmax and BCE losses, and discuss their relationship. Extensive evaluation on multiple benchmark datasets, including MFR, IJB-C, LFW, CFP-FP, AgeDB, and MegaFace, demonstrates that the proposed USS loss is highly efficient and can work seamlessly with sample-to-class-based losses. The embedded loss (USS and sample-to-class Softmax loss) overcomes the pitfalls of previous approaches and the trained facial model UniTSFace exhibits exceptional performance, outperforming state-of-the-art methods, such as CosFace, ArcFace, VPL, AnchorFace, and UNPG. Our code is available at https://github.com/CVI-SZU/UniTSFace",
    "checked": true,
    "id": "4ac3c4d6491421f94d0d6d6937c7662bf2211eb4",
    "semantic_title": "unitsface: unified threshold integrated sample-to-sample loss for face recognition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5Fr8Nwi5KF": {
    "title": "Diffusion Model for Graph Inverse Problems: Towards Effective Source Localization on Complex Networks",
    "volume": "poster",
    "abstract": "Information diffusion problems, such as the spread of epidemics or rumors, are widespread in society. The inverse problems of graph diffusion, which involve locating the sources and identifying the paths of diffusion based on currently observed diffusion graphs, are crucial to controlling the spread of information. The problem of localizing the source of diffusion is highly ill-posed, presenting a major obstacle in accurately assessing the uncertainty involved. Besides, while comprehending how information diffuses through a graph is crucial, there is a scarcity of research on reconstructing the paths of information propagation. To tackle these challenges, we propose a probabilistic model called DDMSL (Discrete Diffusion Model for Source Localization). Our approach is based on the natural diffusion process of information propagation over complex networks, which can be formulated using a message-passing function. First, we model the forward diffusion of information using Markov chains. Then, we design a reversible residual network to construct a denoising-diffusion model in discrete space for both source localization and reconstruction of information diffusion paths. We provide rigorous theoretical guarantees for DDMSL and demonstrate its effectiveness through extensive experiments on five real-world datasets",
    "checked": false,
    "id": "d4838211d7f65628f56b9f6faab30a95ff7b51f8",
    "semantic_title": "for prediction city region re-weighting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=htkdwc6jDB": {
    "title": "$p$-value Adjustment for Monotonous, Unbiased, and Fast Clustering Comparison",
    "volume": "poster",
    "abstract": "Popular metrics for clustering comparison, like the Adjusted Rand Index and the Adjusted Mutual Information, are type II biased. The Standardized Mutual Information removes this bias but suffers from counterintuitive non-monotonicity and poor computational efficiency. We introduce the $p$-value adjusted Rand Index ($\\operatorname{PMI}_2$), the first cluster comparison method that is type II unbiased and provably monotonous. The $\\operatorname{PMI}_2$ has fast approximations that outperform the Standardized Mutual information. We demonstrate its unbiased clustering selection, approximation quality, and runtime efficiency on synthetic benchmarks. In experiments on image and social network datasets, we show how the $\\operatorname{PMI}_2$ can help practitioners choose better clustering and community detection algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uN71BdBEG8": {
    "title": "The Graph Pencil Method: Mapping Subgraph Densities to Stochastic Block Models",
    "volume": "poster",
    "abstract": "In this work, we describe a method that determines an exact map from a finite set of subgraph densities to the parameters of a stochastic block model (SBM) matching these densities. Given a number K of blocks, the subgraph densities of a finite number of stars and bistars uniquely determines a single element of the class of all degree-separated stochastic block models with K blocks. Our method makes it possible to translate estimates of these subgraph densities into model parameters, and hence to use subgraph densities directly for inference. The computational overhead is negligible; computing the translation map is polynomial in K, but independent of the graph size once the subgraph densities are given",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0K1ZTfHZ0N": {
    "title": "Dynamic Non-monotone Submodular Maximization",
    "volume": "poster",
    "abstract": "Maximizing submodular functions has been increasingly used in many applications of machine learning, such as data summarization, recommendation systems, and feature selection. Moreover, there has been a growing interest in both submodular maximization and dynamic algorithms. In 2020, Monemizadeh and Lattanzi, Mitrovic, Norouzi-Fard, Tarnawski, and Zadimoghaddam initiated developing dynamic algorithms for the monotone submodular maximization problem under the cardinality constraint $k$. In 2022, Chen and Peng studied the complexity of this problem and raised an important open question: \"\\emph{Can we extend [fully dynamic] results (algorithm or hardness) to non-monotone submodular maximization?}\". We affirmatively answer their question by demonstrating a reduction from maximizing a non-monotone submodular function under the cardinality constraint $k$ to maximizing a monotone submodular function under the same constraint. Through this reduction, we obtain the first dynamic algorithms to solve the non-monotone submodular maximization problem under the cardinality constraint $k$. Our algorithms maintain an $(8+\\epsilon)$-approximate of the solution and use expected amortized $O(\\epsilon^{-3}k^3\\log^3(n)\\log(k))$ or $O(\\epsilon^{-1}k^2\\log^3(k))$ oracle queries per update, respectively. Furthermore, we showcase the benefits of our dynamic algorithm for video summarization and max-cut problems on several real-world data sets",
    "checked": true,
    "id": "e20bd78f2e00e223343f309e8cbc5b5b2b7644ad",
    "semantic_title": "dynamic non-monotone submodular maximization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SLtNFERsHo": {
    "title": "CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra",
    "volume": "poster",
    "abstract": "Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation. The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure. In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra). By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms. Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch. CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-in tool for virtually any computational effort that requires linear algebra. We showcase its efficacy across a broad range of applications, including partial differential equations, Gaussian processes, equivariant model construction, and unsupervised learning",
    "checked": true,
    "id": "22e2a3344e959e5cdd2f0ec10b03a85d02121a9d",
    "semantic_title": "cola: exploiting compositional structure for automatic and efficient numerical linear algebra",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wEiUGpcr0M": {
    "title": "Improving Self-supervised Molecular Representation Learning using Persistent Homology",
    "volume": "poster",
    "abstract": "Self-supervised learning (SSL) has great potential for molecular representation learning given the complexity of molecular graphs, the large amounts of unlabelled data available, the considerable cost of obtaining labels experimentally, and the hence often only small training datasets. The importance of the topic is reflected in the variety of paradigms and architectures that have been investigated recently. Yet the differences in performance seem often minor and are barely understood to date. In this paper, we study SSL based on persistent homology (PH), a mathematical tool for modeling topological features of data that persist across multiple scales. It has several unique features which particularly suit SSL, naturally offering: different views of the data, stability in terms of distance preservation, and the opportunity to flexibly incorporate domain knowledge. We (1) investigate an autoencoder, which shows the general representational power of PH, and (2) propose a contrastive loss that complements existing approaches. We rigorously evaluate our approach for molecular property prediction and demonstrate its particular features in improving the embedding space: after SSL, the representations are better and offer considerably more predictive power than the baselines over different probing tasks; our loss increases baseline performance, sometimes largely; and we often obtain substantial improvements over very small datasets, a common scenario in practice",
    "checked": false,
    "id": "0cd87100a992967737709cbccb6db3a8a24b3603",
    "semantic_title": "molcpt: molecule continuous prompt tuning to generalize molecular representation learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=InB9Loet1u": {
    "title": "Utilitarian Algorithm Configuration",
    "volume": "poster",
    "abstract": "We present the first nontrivial procedure for configuring heuristic algorithms to maximize the utility provided to their end users while also offering theoretical guarantees about performance. Existing procedures seek configurations that minimize expected runtime. However, very recent theoretical work argues that expected runtime minimization fails to capture algorithm designers' preferences. Here we show that the utilitarian objective also confers significant algorithmic benefits. Intuitively, this is because mean runtime is dominated by extremely long runs even when they are incredibly rare; indeed, even when an algorithm never gives rise to such long runs, configuration procedures that provably minimize mean runtime must perform a huge number of experiments to demonstrate this fact. In contrast, utility is bounded and monotonically decreasing in runtime, allowing for meaningful empirical bounds on a configuration's performance. This paper builds on this idea to describe effective and theoretically sound configuration procedures. We prove upper bounds on the runtime of these procedures that are similar to theoretical lower bounds, while also demonstrating their performance empirically",
    "checked": true,
    "id": "3c1e83ac9936de8114eb0dc0a13ef505d2691ddb",
    "semantic_title": "utilitarian algorithm configuration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zTSlm4nmlH": {
    "title": "Beta Diffusion",
    "volume": "poster",
    "abstract": "We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them",
    "checked": true,
    "id": "5c1d5d8bfc930b0f51f068d47f8ad301e5de2f28",
    "semantic_title": "beta diffusion",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=jtiQ26sCJi": {
    "title": "Simple and Controllable Music Generation",
    "volume": "poster",
    "abstract": "We tackle the task of conditional music generation. We introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage transformer LM together with efficient token interleaving patterns, which eliminates the need for cascading several models, e.g., hierarchically or upsampling. Following this approach, we demonstrate how MusicGen can generate high-quality samples, both mono and stereo, while being conditioned on textual description or melodic features, allowing better controls over the generated output. We conduct extensive empirical evaluation, considering both automatic and human studies, showing the proposed approach is superior to the evaluated baselines on a standard text-to-music benchmark. Through ablation studies, we shed light over the importance of each of the components comprising MusicGen. Music samples, code, and models are available at https://github.com/facebookresearch/audiocraft",
    "checked": true,
    "id": "4cc8e18f5eece0b0d8e1abcb8ee10fb33680fbb2",
    "semantic_title": "simple and controllable music generation",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=8Xn3D9OtqI": {
    "title": "Mitigating the Effect of Incidental Correlations on Part-based Learning",
    "volume": "poster",
    "abstract": "Intelligent systems possess a crucial characteristic of breaking complicated problems into smaller reusable components or parts and adjusting to new tasks using these part representations. However, current part-learners encounter difficulties in dealing with incidental correlations resulting from the limited observations of objects that may appear only in specific arrangements or with specific backgrounds. These incidental correlations may have a detrimental impact on the generalization and interpretability of learned part representations. This study asserts that part-based representations could be more interpretable and generalize better with limited data, employing two innovative regularization methods. The first regularization separates foreground and background information's generative process via a unique mixture-of-parts formulation. Structural constraints are imposed on the parts using a weakly-supervised loss, guaranteeing that the mixture-of-parts for foreground and background entails soft, object-agnostic masks. The second regularization assumes the form of a distillation loss, ensuring the invariance of the learned parts to the incidental background correlations. Furthermore, we incorporate sparse and orthogonal constraints to facilitate learning high-quality part representations. By reducing the impact of incidental background correlations on the learned parts, we exhibit state-of-the-art (SoTA) performance on few-shot learning tasks on benchmark datasets, including MiniImagenet, TieredImageNet, and FC100. We also demonstrate that the part-based representations acquired through our approach generalize better than existing techniques, even under domain shifts of the background and common data corruption on the ImageNet-9 dataset",
    "checked": true,
    "id": "e63a0ebcbc26fa958e5897d916d10051607ce7fc",
    "semantic_title": "mitigating the effect of incidental correlations on part-based learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yubwSWol6K": {
    "title": "Canonical normalizing flows for manifold learning",
    "volume": "poster",
    "abstract": "Manifold learning flows are a class of generative modelling techniques that assume a low-dimensional manifold description of the data. The embedding of such a manifold into the high-dimensional space of the data is achieved via learnable invertible transformations. Therefore, once the manifold is properly aligned via a reconstruction loss, the probability density is tractable on the manifold and maximum likelihood can be used to optimize the network parameters. Naturally, the lower-dimensional representation of the data requires an injective-mapping. Recent approaches were able to enforce that the density aligns with the modelled manifold, while efficiently calculating the density volume-change term when embedding to the higher-dimensional space. However, unless the injective-mapping is analytically predefined, the learned manifold is not necessarily an \\emph{efficient representation} of the data. Namely, the latent dimensions of such models frequently learn an entangled intrinsic basis, with degenerate information being stored in each dimension. Alternatively, if a locally orthogonal and/or sparse basis is to be learned, here coined canonical intrinsic basis, it can serve in learning a more compact latent space representation. Toward this end, we propose a canonical manifold learning flow method, where a novel optimization objective enforces the transformation matrix to have few prominent and non-degenerate basis functions. We demonstrate that by minimizing the off-diagonal manifold metric elements $\\ell_1$-norm, we can achieve such a basis, which is simultaneously sparse and/or orthogonal. Canonical manifold flow yields a more efficient use of the latent space, automatically generating fewer prominent and distinct dimensions to represent data, and consequently a better approximation of target distributions than other manifold flow methods in most experiments we conducted, resulting in lower FID scores",
    "checked": true,
    "id": "4860d11504e3aeaad96b5b128a1444969bc63f63",
    "semantic_title": "canonical normalizing flows for manifold learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dwIeEhbaD0": {
    "title": "SmoothHess: ReLU Network Feature Interactions via Stein's Lemma",
    "volume": "poster",
    "abstract": "Several recent methods for interpretability model feature interactions by looking at the Hessian of a neural network. This poses a challenge for ReLU networks, which are piecewise-linear and thus have a zero Hessian almost everywhere. We propose SmoothHess, a method of estimating second-order interactions through Stein's Lemma. In particular, we estimate the Hessian of the network convolved with a Gaussian through an efficient sampling algorithm, requiring only network gradient calls. SmoothHess is applied post-hoc, requires no modifications to the ReLU network architecture, and the extent of smoothing can be controlled explicitly. We provide a non-asymptotic bound on the sample complexity of our estimation procedure. We validate the superior ability of SmoothHess to capture interactions on benchmark datasets and a real-world medical spirometry dataset",
    "checked": true,
    "id": "adfce099979086aff59b6b32cc6c0a486a2b276d",
    "semantic_title": "smoothhess: relu network feature interactions via stein's lemma",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SLTQluG80x": {
    "title": "Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning",
    "volume": "poster",
    "abstract": "We consider the problem of learning models for risk-sensitive reinforcement learning. We theoretically demonstrate that proper value equivalence, a method of learning models which can be used to plan optimally in the risk-neutral setting, is not sufficient to plan optimally in the risk-sensitive setting. We leverage distributional reinforcement learning to introduce two new notions of model equivalence, one which is general and can be used to plan for any risk measure, but is intractable; and a practical variation which allows one to choose which risk measures they may plan optimally for. We demonstrate how our models can be used to augment any model-free risk-sensitive algorithm, and provide both tabular and large-scale experiments to demonstrate our method's ability",
    "checked": true,
    "id": "f3322ef61ba5572bd4964626715452d3ef810f3e",
    "semantic_title": "distributional model equivalence for risk-sensitive reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c5WOU7p4ES": {
    "title": "PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning",
    "volume": "poster",
    "abstract": "In Reinforcement Learning (RL), enhancing sample efficiency is crucial, particularly in scenarios when data acquisition is costly and risky. In principle, off-policy RL algorithms can improve sample efficiency by allowing multiple updates per environment interaction. However, these multiple updates often lead the model to overfit to earlier interactions, which is referred to as the loss of plasticity. Our study investigates the underlying causes of this phenomenon by dividing plasticity into two aspects. Input plasticity, which denotes the model's adaptability to changing input data, and label plasticity, which denotes the model's adaptability to evolving input-output relationships. Synthetic experiments on the CIFAR-10 dataset reveal that finding smoother minima of loss landscape enhances input plasticity, whereas refined gradient propagation improves label plasticity. Leveraging these findings, we introduce the **PLASTIC** algorithm, which harmoniously combines techniques to address both concerns. With minimal architectural modifications, PLASTIC achieves competitive performance on benchmarks including Atari-100k and Deepmind Control Suite. This result emphasizes the importance of preserving the model's plasticity to elevate the sample efficiency in RL. The code is available at https://github.com/dojeon-ai/plastic",
    "checked": true,
    "id": "eb989c7ad4d9b0c5b8b32d0ae4a92b14b09b4fe8",
    "semantic_title": "plastic: improving input and label plasticity for sample efficient reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=A6EquH0enk": {
    "title": "Effective Bayesian Heteroscedastic Regression with Deep Neural Networks",
    "volume": "poster",
    "abstract": "Flexibly quantifying both irreducible aleatoric and model-dependent epistemic uncertainties plays an important role for complex regression problems. While deep neural networks in principle can provide this flexibility and learn heteroscedastic aleatoric uncertainties through non-linear functions, recent works highlight that maximizing the log likelihood objective parameterized by mean and variance can lead to compromised mean fits since the gradient are scaled by the predictive variance, and propose adjustments in line with this premise. We instead propose to use the natural parametrization of the Gaussian, which has been shown to be more stable for heteroscedastic regression based on non-linear feature maps and Gaussian processes. Further, we emphasize the significance of principled regularization of the network parameters and prediction. We therefore propose an efficient Laplace approximation for heteroscedastic neural networks that allows automatic regularization through empirical Bayes and provides epistemic uncertainties, both of which improve generalization. We showcase on a range of regression problems—including a new heteroscedastic image regression benchmark—that our methods are scalable, improve over previous approaches for heteroscedastic regression, and provide epistemic uncertainty without requiring hyperparameter tuning",
    "checked": false,
    "id": "bd243084093da9e8a257f10250abbc3aa0969c41",
    "semantic_title": "learning active subspaces for effective and scalable uncertainty quantification in deep neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BvslVXlUvF": {
    "title": "Improving the Knowledge Gradient Algorithm",
    "volume": "poster",
    "abstract": "The knowledge gradient (KG) algorithm is a popular policy for the best arm identification (BAI) problem. It is built on the simple idea of always choosing the measurement that yields the greatest expected one-step improvement in the estimate of the best mean of the arms. In this research, we show that this policy has limitations, causing the algorithm not asymptotically optimal. We next provide a remedy for it, by following the manner of one-step look ahead of KG, but instead choosing the measurement that yields the greatest one-step improvement in the probability of selecting the best arm. The new policy is called improved knowledge gradient (iKG). iKG can be shown to be asymptotically optimal. In addition, we show that compared to KG, it is easier to extend iKG to variant problems of BAI, with the $\\epsilon$-good arm identification and feasible arm identification as two examples. The superior performances of iKG on these problems are further demonstrated using numerical examples",
    "checked": true,
    "id": "31fdb63e5acd5a1cf7343c0214450951a4b6aeb7",
    "semantic_title": "improving the knowledge gradient algorithm",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bkrmr9LjeI": {
    "title": "Learning to Discover Skills through Guidance",
    "volume": "poster",
    "abstract": "In the field of unsupervised skill discovery (USD), a major challenge is limited exploration, primarily due to substantial penalties when skills deviate from their initial trajectories. To enhance exploration, recent methodologies employ auxiliary rewards to maximize the epistemic uncertainty or entropy of states. However, we have identified that the effectiveness of these rewards declines as the environmental complexity rises. Therefore, we present a novel USD algorithm, skill **disco**very with gui**dance** (**DISCO-DANCE**), which (1) selects the guide skill that possesses the highest potential to reach unexplored states, (2) guides other skills to follow guide skill, then (3) the guided skills are dispersed to maximize their discriminability in unexplored states. Empirical evaluation demonstrates that DISCO-DANCE outperforms other USD baselines in challenging environments, including two navigation benchmarks and a continuous control benchmark. Qualitative visualizations and code of DISCO-DANCE are available at https://mynsng.github.io/discodance/",
    "checked": true,
    "id": "2892b19b1ac3c3e7d1bb95ceb39b2d4273b2939b",
    "semantic_title": "learning to discover skills through guidance",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Lmxo0RVNx2": {
    "title": "Individualized Dosing Dynamics via Neural Eigen Decomposition",
    "volume": "poster",
    "abstract": "Dosing models often use differential equations to model biological dynamics. Neural differential equations in particular can learn to predict the derivative of a process, which permits predictions at irregular points of time. However, this temporal flexibility often comes with a high sensitivity to noise, whereas medical problems often present high noise and limited data. Moreover, medical dosing models must generalize reliably over individual patients and changing treatment policies. To address these challenges, we introduce the Neural Eigen Stochastic Differential Equation algorithm (NESDE). NESDE provides individualized modeling (using a hypernetwork over patient-level parameters); generalization to new treatment policies (using decoupled control); tunable expressiveness according to the noise level (using piecewise linearity); and fast, continuous, closed-form prediction (using spectral representation). We demonstrate the robustness of NESDE in both synthetic and real medical problems, and use the learned dynamics to publish simulated medical gym environments",
    "checked": true,
    "id": "30105ed80801a2c197e4fc9f96fea37473c9f4fa",
    "semantic_title": "individualized dosing dynamics via neural eigen decomposition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gdwcoBCMVi": {
    "title": "xTrimoGene: An Efficient and Scalable Representation Learner for Single-Cell RNA-Seq Data",
    "volume": "poster",
    "abstract": "Advances in high-throughput sequencing technology have led to significant progress in measuring gene expressions at the single-cell level. The amount of publicly available single-cell RNA-seq (scRNA-seq) data is already surpassing 50M records for humans with each record measuring 20,000 genes. This highlights the need for unsupervised representation learning to fully ingest these data, yet classical transformer architectures are prohibitive to train on such data in terms of both computation and memory. To address this challenge, we propose a novel asymmetric encoder-decoder transformer for scRNA-seq data, called xTrimoGene$^\\alpha$ (or xTrimoGene for short), which leverages the sparse characteristic of the data to scale up the pre-training. This scalable design of xTrimoGene reduces FLOPs by one to two orders of magnitude compared to classical transformers while maintaining high accuracy, enabling us to train the largest transformer models over the largest scRNA-seq dataset today. Our experiments also show that the performance of xTrimoGene improves as we scale up the model sizes, and it also leads to SOTA performance over various downstream tasks, such as cell type annotation, perturb-seq effect prediction, and drug combination prediction. xTrimoGene model is now available for use as a service via the following link: https://api.biomap.com/xTrimoGene/apply",
    "checked": true,
    "id": "424132ec245c3173685751ac1101c3be6cc55a67",
    "semantic_title": "xtrimogene: an efficient and scalable representation learner for single-cell rna-seq data",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=WjlCQxpuxU": {
    "title": "Action Inference by Maximising Evidence: Zero-Shot Imitation from Observation with World Models",
    "volume": "poster",
    "abstract": "Unlike most reinforcement learning agents which require an unrealistic amount of environment interactions to learn a new behaviour, humans excel at learning quickly by merely observing and imitating others. This ability highly depends on the fact that humans have a model of their own embodiment that allows them to infer the most likely actions that led to the observed behaviour. In this paper, we propose Action Inference by Maximising Evidence (AIME) to replicate this behaviour using world models. AIME consists of two distinct phases. In the first phase, the agent learns a world model from its past experience to understand its own body by maximising the ELBO. While in the second phase, the agent is given some observation-only demonstrations of an expert performing a novel task and tries to imitate the expert's behaviour. AIME achieves this by defining a policy as an inference model and maximising the evidence of the demonstration under the policy and world model. Our method is \"zero-shot\" in the sense that it does not require further training for the world model or online interactions with the environment after given the demonstration. We empirically validate the zero-shot imitation performance of our method on the Walker and Cheetah embodiment of the DeepMind Control Suite and find it outperforms the state-of-the-art baselines. Code is available at: https://github.com/argmax-ai/aime",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aw1vLo7TE7": {
    "title": "Risk-Averse Active Sensing for Timely Outcome Prediction under Cost Pressure",
    "volume": "poster",
    "abstract": "Timely outcome prediction is essential in healthcare to enable early detection and intervention of adverse events. However, in longitudinal follow-ups to patients' health status, cost-efficient acquisition of patient covariates is usually necessary due to the significant expense involved in screening and lab tests. To balance the timely and accurate outcome predictions with acquisition costs, an effective active sensing strategy is crucial. In this paper, we propose a novel risk-averse active sensing approach RAS that addresses the composite decision problem of when to conduct the acquisition and which measurements to make. Our approach decomposes the policy into two sub-policies: acquisition scheduler and feature selector, respectively. Moreover, we introduce a novel risk-aversion training strategy to focus on the underrepresented subgroup of high-risk patients for whom timely and accurate prediction of disease progression is of greater value. Our method outperforms baseline active sensing approaches in experiments with both synthetic and real-world datasets, and we illustrate the significance of our policy decomposition and the necessity of a risk-averse sensing policy through case studies",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kjkLJ7NJJZ": {
    "title": "Offline Minimax Soft-Q-learning Under Realizability and Partial Coverage",
    "volume": "poster",
    "abstract": "We consider offline reinforcement learning (RL) where we only have only access to offline data. In contrast to numerous offline RL algorithms that necessitate the uniform coverage of the offline data over state and action space, we propose value-based algorithms with PAC guarantees under partial coverage, specifically, coverage of offline data against a single policy, and realizability of soft Q-function (a.k.a., entropy-regularized Q-function) and another function, which is defined as a solution to a saddle point of certain minimax optimization problem). Furthermore, we show the analogous result for Q-functions instead of soft Q-functions. To attain these guarantees, we use novel algorithms with minimax loss functions to accurately estimate soft Q-functions and Q-functions with -convergence guarantees measured on the offline data. We introduce these loss functions by casting the estimation problems into nonlinear convex optimization problems and taking the Lagrange functions",
    "checked": true,
    "id": "c42f14d71ff85ed3bef449d6df3e47ccbedcb176",
    "semantic_title": "offline minimax soft-q-learning under realizability and partial coverage",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=uNnPWR66b8": {
    "title": "Sample Complexity Bounds for Score-Matching: Causal Discovery and Generative Modeling",
    "volume": "poster",
    "abstract": "This paper provides statistical sample complexity bounds for score-matching and its applications in causal discovery. We demonstrate that accurate estimation of the score function is achievable by training a standard deep ReLU neural network using stochastic gradient descent. We establish bounds on the error rate of recovering causal relationships using the score-matching-based causal discovery method of Rolland et al. [2022], assuming a sufficiently good estimation of the score function. Finally, we analyze the upper bound of score-matching estimation within the score-based generative modeling, which has been applied for causal discovery but is also of independent interest within the domain of generative models",
    "checked": true,
    "id": "fed787fae9bdc09f78e87f99f1758a3a8b22ec8d",
    "semantic_title": "sample complexity bounds for score-matching: causal discovery and generative modeling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3DMDNwd7ND": {
    "title": "Posthoc privacy guarantees for collaborative inference with modified Propose-Test-Release",
    "volume": "poster",
    "abstract": "Cloud-based machine learning inference is an emerging paradigm where users query by sending their data through a service provider who runs an ML model on that data and returns back the answer. Due to increased concerns over data privacy, recent works have proposed Collaborative Inference (CI) to learn a privacy-preserving encoding of sensitive user data before it is shared with an untrusted service provider. Existing works so far evaluate the privacy of these encodings through empirical reconstruction attacks. In this work, we develop a new framework that provides formal privacy guarantees for an arbitrarily trained neural network by linking its local Lipschitz constant with its local sensitivity. To guarantee privacy using local sensitivity, we extend the Propose-Test-Release (PTR) framework to make it tractable for neural network queries. We verify the efficacy of our framework experimentally on real-world datasets and elucidate the role of Adversarial Representation Learning (ARL) in improving the privacy-utility trade-off",
    "checked": true,
    "id": "b35359847414451137a0352deed729807f6b1706",
    "semantic_title": "posthoc privacy guarantees for collaborative inference with modified propose-test-release",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8d9wVXri89": {
    "title": "Accurate Interpolation for Scattered Data through Hierarchical Residual Refinement",
    "volume": "poster",
    "abstract": "Accurate interpolation algorithms are highly desired in various theoretical and engineering scenarios. Unlike the traditional numerical algorithms that have exact zero-residual constraints on observed points, the neural network-based interpolation methods exhibit non-zero residuals at these points. These residuals, which provide observations of an underlying residual function, can guide predicting interpolation functions, but have not been exploited by the existing approaches. To fill this gap, we propose Hierarchical INTerpolation Network (HINT), which utilizes the residuals on observed points to guide target function estimation in a hierarchical fashion. HINT consists of several sequentially arranged lightweight interpolation blocks. The first interpolation block estimates the main component of the target function, while subsequent blocks predict the residual components using observed points residuals of the preceding blocks. The main component and residual components are accumulated to form the final interpolation results. Furthermore, under the assumption that finer residual prediction requires a more focused attention range on observed points, we utilize hierarchical local constraints in correlation modeling between observed and target points. Extensive experiments demonstrate that HINT outperforms existing interpolation algorithms significantly in terms of interpolation accuracy across a wide variety of datasets, which underscores its potential for practical scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LftAvFt54C": {
    "title": "Hybrid Policy Optimization from Imperfect Demonstrations",
    "volume": "poster",
    "abstract": "Exploration is one of the main challenges in Reinforcement Learning (RL), especially in environments with sparse rewards. Learning from Demonstrations (LfD) is a promising approach to solving this problem by leveraging expert demonstrations. However, expert demonstrations of high quality are usually costly or even impossible to collect in real-world applications. In this work, we propose a novel RL algorithm called HYbrid Policy Optimization (HYPO), which uses a small number of imperfect demonstrations to accelerate an agent's online learning process. The key idea is to train an offline guider policy using imitation learning in order to instruct an online agent policy to explore efficiently. Through mutual update of the guider policy and the agent policy, the agent can leverage suboptimal demonstrations for efficient exploration while avoiding the conservative policy caused by imperfect demonstrations. Empirical results show that HYPO significantly outperforms several baselines in various challenging tasks, such as MuJoCo with sparse rewards, Google Research Football, and the AirSim drone simulation",
    "checked": false,
    "id": "c28c30a846d97f7e9c0722fbc35bb88aba3c6b04",
    "semantic_title": "guarded policy optimization with imperfect online demonstrations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Pk9CdOZYRA": {
    "title": "Optimal Preconditioning and Fisher Adaptive Langevin Sampling",
    "volume": "poster",
    "abstract": "We define an optimal preconditioning for the Langevin diffusion by analytically optimizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler",
    "checked": true,
    "id": "0952b553f497983cbff480463dc2b6e9c8cba3f9",
    "semantic_title": "optimal preconditioning and fisher adaptive langevin sampling",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Nn0daSf6CW": {
    "title": "Policy Optimization in a Noisy Neighborhood: On Return Landscapes in Continuous Control",
    "volume": "poster",
    "abstract": "Deep reinforcement learning agents for continuous control are known to exhibit significant instability in their performance over time. In this work, we provide a fresh perspective on these behaviors by studying the return landscape: the mapping between a policy and a return. We find that popular algorithms traverse noisy neighborhoods of this landscape, in which a single update to the policy parameters leads to a wide range of returns. By taking a distributional view of these returns, we map the landscape, characterizing failure-prone regions of policy space and revealing a hidden dimension of policy quality. We show that the landscape exhibits surprising structure by finding simple paths in parameter space which improve the stability of a policy. To conclude, we develop a distribution-aware procedure which finds such paths, navigating away from noisy neighborhoods in order to improve the robustness of a policy. Taken together, our results provide new insight into the optimization, evaluation, and design of agents",
    "checked": true,
    "id": "3009c368bba4e27acb8af50112a9d0b0e32cf445",
    "semantic_title": "policy optimization in a noisy neighborhood: on return landscapes in continuous control",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=V87gZeSOL4": {
    "title": "Nonparametric Identifiability of Causal Representations from Unknown Interventions",
    "volume": "poster",
    "abstract": "We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions (\"mixtures\") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that the observational distribution and one perfect intervention per node suffice for identifiability, subject to a genericity condition. This condition rules out spurious solutions that involve fine-tuning of the intervened and observational distributions, mirroring similar conditions for nonlinear cause-effect inference. For an arbitrary number of variables, we show that at least one pair of distinct perfect interventional domains per node guarantees identifiability. Further, we demonstrate that the strengths of causal influences among the latent variables are preserved by all equivalent solutions, rendering the inferred representation appropriate for drawing causal conclusions from new data. Our study provides the first identifiability results for the general nonparametric setting with unknown interventions, and elucidates what is possible and impossible for causal representation learning without more direct supervision",
    "checked": true,
    "id": "4cd70b7e17a57688a34ba1bd54c5a7f12cfc09d8",
    "semantic_title": "nonparametric identifiability of causal representations from unknown interventions",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=ebMPmx5mr7": {
    "title": "Semantic HELM: A Human-Readable Memory for Reinforcement Learning",
    "volume": "poster",
    "abstract": "Reinforcement learning agents deployed in the real world often have to cope with partially observable environments. Therefore, most agents employ memory mechanisms to approximate the state of the environment. Recently, there have been impressive success stories in mastering partially observable environments, mostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft. However, existing methods lack interpretability in the sense that it is not comprehensible for humans what the agent stores in its memory. In this regard, we propose a novel memory mechanism that represents past events in human language. Our method uses CLIP to associate visual inputs with language tokens. Then we feed these tokens to a pretrained language model that serves the agent as memory and provides it with a coherent and human-readable representation of the past. We train our memory mechanism on a set of partially observable environments and find that it excels on tasks that require a memory component, while mostly attaining performance on-par with strong baselines on tasks that do not. On a challenging continuous recognition task, where memorizing the past is crucial, our memory mechanism converges two orders of magnitude faster than prior methods. Since our memory mechanism is human-readable, we can peek at an agent's memory and check whether crucial pieces of information have been stored. This significantly enhances troubleshooting and paves the way toward more interpretable agents",
    "checked": true,
    "id": "c50348d3491567b2cdad5ea981620c31f876dad9",
    "semantic_title": "semantic helm: a human-readable memory for reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d8j3lsBWpV": {
    "title": "ZipLM: Inference-Aware Structured Pruning of Language Models",
    "volume": "poster",
    "abstract": "The breakthrough performance of large language models (LLMs) comes with major computational footprints and high deployment costs. In this paper, we progress towards resolving this problem by proposing a novel structured compression approach for LLMs, called ZipLM. ZipLM achieves state-of-the-art accuracy-vs-speedup, while matching a set of desired target runtime speedups in any given inference environment. Specifically, given a model, a dataset, an inference environment, as well as a set of speedup targets, ZipLM iteratively identifies and removes components with the worst loss-runtime trade-off. Unlike prior methods that specialize in either the *post-training/one-shot* or the *gradual compression* setting, and only for specific families of models such as BERT (*encoder*) or GPT (*decoder*), ZipLM produces state-of-the-art compressed models across all these settings. Furthermore, ZipLM achieves superior results for a fraction of the computational cost relative to prior distillation and pruning techniques, making it a cost-effective approach for generating an entire family of smaller, faster, and highly accurate models, guaranteed to meet the desired inference specifications. In particular, ZipLM outperforms all prior BERT-base distillation and pruning techniques, such as CoFi, MiniLM, and TinyBERT. Moreover, it matches the performance of the heavily optimized MobileBERT model, obtained via extensive architecture search, by simply pruning the baseline BERT-large model. When compressing GPT2, ZipLM outperforms DistilGPT2 while being 60\\% smaller and 30\\% faster. Our code is available at: https://github.com/IST-DASLab/ZipLM",
    "checked": true,
    "id": "2b66cc9e3b46cf2cd30c4ffdca596480c8de6331",
    "semantic_title": "ziplm: inference-aware structured pruning of language models",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=oRn953uhFq": {
    "title": "Analyzing the Sample Complexity of Self-Supervised Image Reconstruction Methods",
    "volume": "poster",
    "abstract": "Supervised training of deep neural networks on pairs of clean image and noisy measurement achieves state-of-the-art performance for many image reconstruction tasks, but such training pairs are difficult to collect. Self-supervised methods enable training based on noisy measurements only, without clean images. In this work, we investigate the cost of self-supervised training in terms of sample complexity for a class of self-supervised methods that enable the computation of unbiased estimates of gradients of the supervised loss, including noise2noise methods. We analytically show that a model trained with such self-supervised training is as good as the same model trained in a supervised fashion, but self-supervised training requires more examples than supervised training. We then study self-supervised denoising and accelerated MRI empirically and characterize the cost of self-supervised training in terms of the number of additional samples required, and find that the performance gap between self-supervised and supervised training vanishes as a function of the training examples, at a problem-dependent rate, as predicted by our theory",
    "checked": true,
    "id": "560e6237b48c5c7b280f1c0035b3660546c8d4a9",
    "semantic_title": "analyzing the sample complexity of self-supervised image reconstruction methods",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=593fc38lhN": {
    "title": "Efficient Meta Neural Heuristic for Multi-Objective Combinatorial Optimization",
    "volume": "poster",
    "abstract": "Recently, neural heuristics based on deep reinforcement learning have exhibited promise in solving multi-objective combinatorial optimization problems (MOCOPs). However, they are still struggling to achieve high learning efficiency and solution quality. To tackle this issue, we propose an efficient meta neural heuristic (EMNH), in which a meta-model is first trained and then fine-tuned with a few steps to solve corresponding single-objective subproblems. Specifically, for the training process, a (partial) architecture-shared multi-task model is leveraged to achieve parallel learning for the meta-model, so as to speed up the training; meanwhile, a scaled symmetric sampling method with respect to the weight vectors is designed to stabilize the training. For the fine-tuning process, an efficient hierarchical method is proposed to systematically tackle all the subproblems. Experimental results on the multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) show that, EMNH is able to outperform the state-of-the-art neural heuristics in terms of solution quality and learning efficiency, and yield competitive solutions to the strong traditional heuristics while consuming much shorter time",
    "checked": true,
    "id": "d4267ea03855bd776c924fb3c375bb6223914175",
    "semantic_title": "efficient meta neural heuristic for multi-objective combinatorial optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wcdF6jR0Sp": {
    "title": "Consistent Aggregation of Objectives with Diverse Time Preferences Requires Non-Markovian Rewards",
    "volume": "poster",
    "abstract": "As the capabilities of artificial agents improve, they are being increasingly deployed to service multiple diverse objectives and stakeholders. However, the composition of these objectives is often performed ad hoc, with no clear justification. This paper takes a normative approach to multi-objective agency: from a set of intuitively appealing axioms, it is shown that Markovian aggregation of Markovian reward functions is not possible when the time preference (discount factor) for each objective may vary. It follows that optimal multi-objective agents must admit rewards that are non-Markovian with respect to the individual objectives. To this end, a practical non-Markovian aggregation scheme is proposed, which overcomes the impossibility with only one additional parameter for each objective. This work offers new insights into sequential, multi-objective agency and intertemporal choice, and has practical implications for the design of AI systems deployed to serve multiple generations of principals with varying time preference",
    "checked": true,
    "id": "d6f452265914d8f5ecf185f999170f6a106602e8",
    "semantic_title": "consistent aggregation of objectives with diverse time preferences requires non-markovian rewards",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GfITbjrIOd": {
    "title": "Human-Aligned Calibration for AI-Assisted Decision Making",
    "volume": "poster",
    "abstract": "Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exists data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values—an optimal decision maker would need to sometimes place more (less) trust on predictions with lower (higher) confidence values. However, we then show that, if the confidence values satisfy a natural alignment property with respect to the decision maker's confidence on her own predictions, there always exists an optimal decision policy under which the level of trust the decision maker would need to place on predictions is monotone on the confidence values, facilitating its discoverability. Further, we show that multicalibration with respect to the decision maker's confidence on her own prediction is a sufficient condition for alignment. Experiments on a real AI-assisted decision making scenario where a classifier provides decision support to human decision makers validate our theoretical results and suggest that alignment may lead to better decisions",
    "checked": true,
    "id": "28f5160cdd7c186c9c457b06fe6b505d317df96a",
    "semantic_title": "human-aligned calibration for ai-assisted decision making",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qdM260dXsa": {
    "title": "Cross-Domain Policy Adaptation via Value-Guided Data Filtering",
    "volume": "poster",
    "abstract": "Generalizing policies across different domains with dynamics mismatch poses a significant challenge in reinforcement learning. For example, a robot learns the policy in a simulator, but when it is deployed in the real world, the dynamics of the environment may be different. Given the source and target domain with dynamics mismatch, we consider the online dynamics adaptation problem, in which case the agent can access sufficient source domain data while online interactions with the target domain are limited. Existing research has attempted to solve the problem from the dynamics discrepancy perspective. In this work, we reveal the limitations of these methods and explore the problem from the value difference perspective via a novel insight on the value consistency across domains. Specifically, we present the Value-Guided Data Filtering (VGDF) algorithm, which selectively shares transitions from the source domain based on the proximity of paired value targets across the two domains. Empirical results on various environments with kinematic and morphology shifts demonstrate that our method achieves superior performance compared to prior approaches",
    "checked": true,
    "id": "1b5ff30f0f6bbf48373a691315b67208a0e1b38d",
    "semantic_title": "cross-domain policy adaptation via value-guided data filtering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C9cgwmJ8Pt": {
    "title": "Fast Projected Newton-like Method for Precision Matrix Estimation under Total Positivity",
    "volume": "poster",
    "abstract": "We study the problem of estimating precision matrices in Gaussian distributions that are multivariate totally positive of order two ($\\mathrm{MTP}_2$). The precision matrix in such a distribution is an M-matrix. This problem can be formulated as a sign-constrained log-determinant program. Current algorithms are designed using the block coordinate descent method or the proximal point algorithm, which becomes computationally challenging in high-dimensional cases due to the requirement to solve numerous nonnegative quadratic programs or large-scale linear systems. To address this issue, we propose a novel algorithm based on the two-metric projection method, incorporating a carefully designed search direction and variable partitioning scheme. Our algorithm substantially reduces computational complexity, and its theoretical convergence is established. Experimental results on synthetic and real-world datasets demonstrate that our proposed algorithm provides a significant improvement in computational efficiency compared to the state-of-the-art methods",
    "checked": true,
    "id": "7c8f8bf6d9308aae5e75cb5499ce7f0d4f07d62a",
    "semantic_title": "fast projected newton-like method for precision matrix estimation under total positivity",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=wzg0BsV8rQ": {
    "title": "FAST: a Fused and Accurate Shrinkage Tree for Heterogeneous Treatment Effects Estimation",
    "volume": "poster",
    "abstract": "This paper proposes a novel strategy for estimating the heterogeneous treatment effect called the Fused and Accurate Shrinkage Tree ($\\mathrm{FAST}$). Our approach utilizes both trial and observational data to improve the accuracy and robustness of the estimator. Inspired by the concept of shrinkage estimation in statistics, we develop an optimal weighting scheme and a corresponding estimator that balances the unbiased estimator based on the trial data with the potentially biased estimator based on the observational data. Specifically, combined with tree-based techniques, we introduce a new split criterion that utilizes both trial data and observational data to more accurately estimate the treatment effect. Furthermore, we confirm the consistency of our proposed tree-based estimator and demonstrate the effectiveness of our criterion in reducing prediction error through theoretical analysis. The advantageous finite sample performance of the $\\mathrm{FAST}$ and its ensemble version over existing methods is demonstrated via simulations and real data analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=scG0cwftEe": {
    "title": "Unleashing the Full Potential of Product Quantization for Large-Scale Image Retrieval",
    "volume": "poster",
    "abstract": "Due to its promising performance, deep hashing has become a prevalent method for approximate nearest neighbors search (ANNs). However, most of current deep hashing methods are validated on relatively small-scale datasets, leaving potential threats when are applied to large-scale real-world scenarios. Specifically, they can be constrained either by the computational cost due to the large number of training categories and samples, or unsatisfactory accuracy. To tackle those issues, we propose a novel deep hashing framework based on product quantization (PQ). It uses a softmax-based differentiable PQ branch to learn a set of predefined PQ codes of the classes. Our method is easy to implement, does not involve large-scale matrix operations, and learns highly discriminate compact codes. We validate our method on multiple large-scaled datasets, including ImageNet100, ImageNet1K, and Glint360K, where the category size scales from 100 to 360K and sample number scales from 10K to 17 million, respectively. Extensive experiments demonstrate the superiority of our method. Code is available at https://github.com/yuleung/FPPQ",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q0ntwxVtcy": {
    "title": "Near-optimal learning with average Hölder smoothness",
    "volume": "poster",
    "abstract": "We generalize the notion of average Lipschitz smoothness proposed by Ashlagi et al. (COLT 2021) by extending it to Hölder smoothness. This measure of the \"effective smoothness\" of a function is sensitive to the underlying distribution and can be dramatically smaller than its classic \"worst-case\" Hölder constant. We consider both the realizable and the agnostic (noisy) regression settings, proving upper and lower risk bounds in terms of the average Hölder smoothness; these rates improve upon both previously known rates even in the special case of average Lipschitz smoothness. Moreover, our lower bound is tight in the realizable setting up to log factors, thus we establish the minimax rate. From an algorithmic perspective, since our notion of average smoothness is defined with respect to the unknown underlying distribution, the learner does not have an explicit representation of the function class, hence is unable to execute ERM. Nevertheless, we provide distinct learning algorithms that achieve both (nearly) optimal learning rates. Our results hold in any totally bounded metric space, and are stated in terms of its intrinsic geometry. Overall, our results show that the classic worst-case notion of Hölder smoothness can be essentially replaced by its average, yielding considerably sharper guarantees",
    "checked": true,
    "id": "b4200edccd78a9209e9a8d46b7fb493e60e60db8",
    "semantic_title": "near-optimal learning with average hölder smoothness",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=yE62KM4qsO": {
    "title": "Advancing Bayesian Optimization via Learning Correlated Latent Space",
    "volume": "poster",
    "abstract": "Bayesian optimization is a powerful method for optimizing black-box functions with limited function evaluations. Recent works have shown that optimization in a latent space through deep generative models such as variational autoencoders leads to effective and efficient Bayesian optimization for structured or discrete data. However, as the optimization does not take place in the input space, it leads to an inherent gap that results in potentially suboptimal solutions. To alleviate the discrepancy, we propose Correlated latent space Bayesian Optimization (CoBO), which focuses on learning correlated latent spaces characterized by a strong correlation between the distances in the latent space and the distances within the objective function. Specifically, our method introduces Lipschitz regularization, loss weighting, and trust region recoordination to minimize the inherent gap around the promising areas. We demonstrate the effectiveness of our approach on several optimization tasks in discrete data, such as molecule design and arithmetic expression fitting, and achieve high performance within a small budget",
    "checked": true,
    "id": "acd4d6c8cfc9df063e303cdc6746817f8496c659",
    "semantic_title": "advancing bayesian optimization via learning correlated latent space",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zfCNwRQ569": {
    "title": "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
    "volume": "poster",
    "abstract": "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction. First, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. We conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xE7oH5iVGK": {
    "title": "LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching",
    "volume": "poster",
    "abstract": "Obtaining large pre-trained models that can be fine-tuned to new tasks with limited annotated samples has remained an open challenge for medical imaging data. While pre-trained networks on ImageNet and vision-language foundation models trained on web-scale data are the prevailing approaches, their effectiveness on medical tasks is limited due to the significant domain shift between natural and medical images. To bridge this gap, we introduce LVM-Med, the first family of deep networks trained on large-scale medical datasets. We have collected approximately 1.3 million medical images from 55 publicly available datasets, covering a large number of organs and modalities such as CT, MRI, X-ray, and Ultrasound. We benchmark several state-of-the-art self-supervised algorithms on this dataset and propose a novel self-supervised contrastive learning algorithm using a graph-matching formulation. The proposed approach makes three contributions: (i) it integrates prior pair-wise image similarity metrics based on local and global information; (ii) it captures the structural constraints of feature embeddings through a loss function constructed through a combinatorial graph-matching objective, and (iii) it can be trained efficiently end-to-end using modern gradient-estimation techniques for black-box solvers. We thoroughly evaluate the proposed LVM-Med on 15 downstream medical tasks ranging from segmentation and classification to object detection, and both for the in and out-of-distribution settings. LVM-Med empirically outperforms a number of state-of-the-art supervised, self-supervised, and foundation models. For challenging tasks such as Brain Tumor Classification or Diabetic Retinopathy Grading, LVM-Med improves previous vision-language models trained on 1 billion masks by 6-7% while using only a ResNet-50",
    "checked": true,
    "id": "f51017a549c1d858ae7d0650e1bad0186cb17808",
    "semantic_title": "lvm-med: learning large-scale self-supervised vision models for medical imaging via second-order graph matching",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=i5sSWKbF3b": {
    "title": "Decentralized Matrix Sensing: Statistical Guarantees and Fast Convergence",
    "volume": "poster",
    "abstract": "We explore the matrix sensing problem from near-isotropic linear measurements, distributed across a network of agents modeled as an undirected graph, with no centralized node. We provide the first study of statistical, computational/communication guarantees for a decentralized gradient algorithm that solves the (nonconvex) Burer-Monteiro type decomposition associated to the low-rank matrix estimation. With small random initialization, the algorithm displays an approximate two-phase convergence: (i) a spectral phase that aligns the iterates' column space with the underlying low-rank matrix, mimicking centralized spectral initialization (not directly implementable over networks); and (ii) a local refinement phase that diverts the iterates from certain degenerate saddle points, while ensuring swift convergence to the underlying low-rank matrix. Central to our analysis is a novel \"in-network\" Restricted Isometry Property which accommodates for the decentralized nature of the optimization, revealing an intriguing interplay between sample complexity and network connectivity, topology, and communication complexity",
    "checked": false,
    "id": "d3ef760e824e685586deb2a71edb606e8e0f91c8",
    "semantic_title": "asynchronous gradient play in zero-sum multi-agent games",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=VMz5GhfxgV": {
    "title": "Hyperbolic Space with Hierarchical Margin Boosts Fine-Grained Learning from Coarse Labels",
    "volume": "poster",
    "abstract": "Learning fine-grained embeddings from coarse labels is a challenging task due to limited label granularity supervision, i.e., lacking the detailed distinctions required for fine-grained tasks. The task becomes even more demanding when attempting few-shot fine-grained recognition, which holds practical significance in various applications. To address these challenges, we propose a novel method that embeds visual embeddings into a hyperbolic space and enhances their discriminative ability with a hierarchical cosine margins manner. Specifically, the hyperbolic space offers distinct advantages, including the ability to capture hierarchical relationships and increased expressive power, which favors modeling fine-grained objects. Based on the hyperbolic space, we further enforce relatively large/small similarity margins between coarse/fine classes, respectively, yielding the so-called hierarchical cosine margins manner. While enforcing similarity margins in the regular Euclidean space has become popular for deep embedding learning, applying it to the hyperbolic space is non-trivial and validating the benefit for coarse-to-fine generalization is valuable. Extensive experiments conducted on five benchmark datasets showcase the effectiveness of our proposed method, yielding state-of-the-art results surpassing competing methods",
    "checked": true,
    "id": "e517898f1186ed970bd8e29bf1f27a8396aaf387",
    "semantic_title": "hyperbolic space with hierarchical margin boosts fine-grained learning from coarse labels",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yN6NHZOXkg": {
    "title": "Generalized Information-theoretic Multi-view Clustering",
    "volume": "poster",
    "abstract": "In an era of more diverse data modalities, multi-view clustering has become a fundamental tool for comprehensive data analysis and exploration. However, existing multi-view unsupervised learning methods often rely on strict assumptions on semantic consistency among samples. In this paper, we reformulate the multi-view clustering problem from an information-theoretic perspective and propose a general theoretical model. In particular, we define three desiderata under multi-view unsupervised learning in terms of mutual information, namely, comprehensiveness, concentration, and cross-diversity. The multi-view variational lower bound is then obtained by approximating the samples' high-dimensional mutual information. The Kullback–Leibler divergence is utilized to deduce sample assignments. Ultimately the information-based multi-view clustering model leverages deep neural networks and Stochastic Gradient Variational Bayes to achieve representation learning and clustering simultaneously. Extensive experiments on both synthetic and real datasets with wide types demonstrate that the proposed method exhibits a more stable and superior clustering performance than state-of-the-art algorithms",
    "checked": false,
    "id": "ea6a0e4568affb6ee29ae6292206ddd7d0b8ba68",
    "semantic_title": "self-supervised information bottleneck for deep multi-view subspace clustering",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=ZZS9WEWYbD": {
    "title": "A Definition of Continual Reinforcement Learning",
    "volume": "poster",
    "abstract": "In a standard view of the reinforcement learning problem, an agent's goal is to efficiently identify a policy that maximizes long-term reward. However, this perspective is based on a restricted view of learning as finding a solution, rather than treating learning as endless adaptation. In contrast, continual reinforcement learning refers to the setting in which the best agents never stop learning. Despite the importance of continual reinforcement learning, the community lacks a simple definition of the problem that highlights its commitments and makes its primary concepts precise and clear. To this end, this paper is dedicated to carefully defining the continual reinforcement learning problem. We formalize the notion of agents that \"never stop learning\" through a new mathematical language for analyzing and cataloging agents. Using this new language, we define a continual learning agent as one that can be understood as carrying out an implicit search process indefinitely, and continual reinforcement learning as the setting in which the best agents are all continual learning agents. We provide two motivating examples, illustrating that traditional views of multi-task reinforcement learning and continual supervised learning are special cases of our definition. Collectively, these definitions and perspectives formalize many intuitive concepts at the heart of learning, and open new research pathways surrounding continual learning agents",
    "checked": true,
    "id": "da1766e02346e7eb238249d06643459450ffdde6",
    "semantic_title": "a definition of continual reinforcement learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=sZNBYvunEr": {
    "title": "DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views",
    "volume": "poster",
    "abstract": "Synthesizing novel view images from a few views is a challenging but practical problem. Existing methods often struggle with producing high-quality results or necessitate per-object optimization in such few-view settings due to the insufficient information provided. In this work, we explore leveraging the strong 2D priors in pre-trained diffusion models for synthesizing novel view images. 2D diffusion models, nevertheless, lack 3D awareness, leading to distorted image synthesis and compromising the identity. To address these problems, we propose $\\textit{DreamSparse}$, a framework that enables the frozen pre-trained diffusion model to generate geometry and identity-consistent novel view images. Specifically, DreamSparse incorporates a geometry module designed to capture features about spatial information from sparse views as a 3D prior. Subsequently, a spatial guidance model is introduced to convert rendered feature maps as spatial information for the generative process. This information is then used to guide the pre-trained diffusion model to encourage the synthesis of geometrically consistent images without further tuning. Leveraging the strong image priors in the pre-trained diffusion models, DreamSparse is capable of synthesizing high-quality novel views for both object and object-centric scene-level images and generalising to open-set images. Experimental results demonstrate that our framework can effectively synthesize novel view images from sparse views and outperforms baselines in both trained and open-set category images. More results can be found on our project page: https://sites.google.com/view/dreamsparse-webpage",
    "checked": false,
    "id": "48dc3d9acdc624add5b68984d6419a10883a7b7e",
    "semantic_title": "dreamsparse: escaping from plato's cave with 2d frozen diffusion model given sparse views",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=dxPcdEeQk9": {
    "title": "Few-shot Generation via Recalling Brain-Inspired Episodic-Semantic Memory",
    "volume": "poster",
    "abstract": "Aimed at adapting a generative model to a novel generation task with only a few given data samples, the capability of few-shot generation is crucial for many real-world applications with limited data, \\emph{e.g.}, artistic domains. Instead of training from scratch, recent works tend to leverage the prior knowledge stored in previous datasets, which is quite similar to the memory mechanism of human intelligence, but few of these works directly imitate the memory-recall mechanism that humans make good use of in accomplishing creative tasks, \\emph{e.g.}, painting and writing. Inspired by the memory mechanism of human brain, in this work, we carefully design a variational structured memory module (VSM), which can simultaneously store both episodic and semantic memories to assist existing generative models efficiently recall these memories during sample generation. Meanwhile, we introduce a bionic memory updating strategy for the conversion between episodic and semantic memories, which can also model the uncertainty during conversion. Then, we combine the developed VSM with various generative models under the Bayesian framework, and evaluate these memory-augmented generative models with few-shot generation tasks, demonstrating the effectiveness of our methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4jEjq5nhg1": {
    "title": "Operator Learning with Neural Fields: Tackling PDEs on General Geometries",
    "volume": "poster",
    "abstract": "Machine learning approaches for solving partial differential equations require learning mappings between function spaces. While convolutional or graph neural networks are constrained to discretized functions, neural operators present a promising milestone toward mapping functions directly. Despite impressive results they still face challenges with respect to the domain geometry and typically rely on some form of discretization. In order to alleviate such limitations, we present CORAL, a new method that leverages coordinate-based networks for solving PDEs on general geometries. CORAL is designed to remove constraints on the input mesh, making it applicable to any spatial sampling and geometry. Its ability extends to diverse problem domains, including PDE solving, spatio-temporal forecasting, and inverse problems like geometric design. CORAL demonstrates robust performance across multiple resolutions and performs well in both convex and non-convex domains, surpassing or performing on par with state-of-the-art models",
    "checked": true,
    "id": "d2e8d1c41039fa39d3ff49131f667e5ab5c59c19",
    "semantic_title": "operator learning with neural fields: tackling pdes on general geometries",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pBa70rGHlr": {
    "title": "Latent Space Translation via Semantic Alignment",
    "volume": "poster",
    "abstract": "While different neural models often exhibit latent spaces that are alike when exposed to semantically related data, this intrinsic similarity is not always immediately discernible. Towards a better understanding of this phenomenon, our work shows how representations learned from these neural modules can be translated between different pre-trained networks via simpler transformations than previously thought. An advantage of this approach is the ability to estimate these transformations using standard, well-understood algebraic procedures that have closed-form solutions. Our method directly estimates a transformation between two given latent spaces, thereby enabling effective stitching of encoders and decoders without additional training. We extensively validate the adaptability of this translation procedure in different experimental settings: across various trainings, domains, architectures (e.g., ResNet, CNN, ViT), and in multiple downstream tasks (classification, reconstruction). Notably, we show how it is possible to zero-shot stitch text encoders and vision decoders, or vice-versa, yielding surprisingly good classification performance in this multimodal setting",
    "checked": true,
    "id": "dc7d6d42a21fb14795ccd92e290a422ea8e33688",
    "semantic_title": "latent space translation via semantic alignment",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DjX2Nr15kY": {
    "title": "NAR-Former V2: Rethinking Transformer for Universal Neural Network Representation Learning",
    "volume": "poster",
    "abstract": "As more deep learning models are being applied in real-world applications, there is a growing need for modeling and learning the representations of neural networks themselves. An effective representation can be used to predict target attributes of networks without the need for actual training and deployment procedures, facilitating efficient network design and deployment. Recently, inspired by the success of Transformer, some Transformer-based representation learning frameworks have been proposed and achieved promising performance in handling cell-structured models. However, graph neural network (GNN) based approaches still dominate the field of learning representation for the entire network. In this paper, we revisit the Transformer and compare it with GNN to analyze their different architectural characteristics. We then propose a modified Transformer-based universal neural network representation learning model NAR-Former V2. It can learn efficient representations from both cell-structured networks and entire networks. Specifically, we first take the network as a graph and design a straightforward tokenizer to encode the network into a sequence. Then, we incorporate the inductive representation learning capability of GNN into Transformer, enabling Transformer to generalize better when encountering unseen architecture. Additionally, we introduce a series of simple yet effective modifications to enhance the ability of the Transformer in learning representation from graph structures. In encoding entire networks and then predicting the latency, our proposed method surpasses the GNN-based method NNLP by a significant margin on the NNLQP dataset. Furthermore, regarding accuracy prediction on the cell-structured NASBench101 and NASBench201 datasets, our method achieves highly comparable performance to other state-of-the-art methods. The code is available at https://github.com/yuny220/NAR-Former-V2",
    "checked": true,
    "id": "a12c76a21fc18f61f6acd74f2e44b9249c2022f5",
    "semantic_title": "nar-former v2: rethinking transformer for universal neural network representation learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0kz5RmHxmE": {
    "title": "Graph Contrastive Learning with Stable and Scalable Spectral Encoding",
    "volume": "poster",
    "abstract": "Graph contrastive learning (GCL) aims to learn representations by capturing the agreements between different graph views. Traditional GCL methods generate views in the spatial domain, but it has been recently discovered that the spectral domain also plays a vital role in complementing spatial views. However, existing spectral-based graph views either ignore the eigenvectors that encode valuable positional information or suffer from high complexity when trying to address the instability of spectral features. To tackle these challenges, we first design an informative, stable, and scalable spectral encoder, termed EigenMLP, to learn effective representations from the spectral features. Theoretically, EigenMLP is invariant to the rotation and reflection transformations on eigenvectors and robust against perturbations. Then, we propose a spatial-spectral contrastive framework (Sp$^{2}$GCL) to capture the consistency between the spatial information encoded by graph neural networks and the spectral information learned by EigenMLP, thus effectively fusing these two graph views. Experiments on the node- and graph-level datasets show that our method not only learns effective graph representations but also achieves a 2--10x speedup over other spectral-based methods",
    "checked": false,
    "id": "b029d810d34829db20d2e42ac32f0b6b2cc86ce5",
    "semantic_title": "learning cross-modal interaction for rgb-t tracking",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kR5ycmBclj": {
    "title": "NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA",
    "volume": "poster",
    "abstract": "Multi-hop Knowledge Graph Question Answering (KGQA) is a task that involves retrieving nodes from a knowledge graph (KG) to answer natural language questions. Recent GNN-based approaches formulate this task as a KG path searching problem, where messages are sequentially propagated from the seed node towards the answer nodes. However, these messages are past-oriented, and they do not consider the full KG context. To make matters worse, KG nodes often represent pronoun entities and are sometimes encrypted, being uninformative in selecting between paths. To address these problems, we propose Neural Tree Search (NuTrea), a tree search-based GNN model that incorporates the broader KG context. Our model adopts a message-passing scheme that probes the unreached subtree regions to boost the past-oriented embeddings. In addition, we introduce the Relation Frequency-Inverse Entity Frequency (RF-IEF) node embedding that considers the global KG context to better characterize ambiguous KG nodes. The general effectiveness of our approach is demonstrated through experiments on three major multi-hop KGQA benchmark datasets, and our extensive analyses further validate its expressiveness and robustness. Overall, NuTrea provides a powerful means to query the KG with complex natural language questions. Code is available at https://github.com/mlvlab/NuTrea",
    "checked": true,
    "id": "8f0c0de1ec55529e8b11779178730602ab6ef618",
    "semantic_title": "nutrea: neural tree search for context-guided multi-hop kgqa",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4L3RfWnDzL": {
    "title": "Object-centric Learning with Cyclic Walks between Parts and Whole",
    "volume": "poster",
    "abstract": "Learning object-centric representations from complex natural environments enables both humans and machines with reasoning abilities from low-level perceptual features. To capture compositional entities of the scene, we proposed cyclic walks between perceptual features extracted from vision transformers and object entities. First, a slot-attention module interfaces with these perceptual features and produces a finite set of slot representations. These slots can bind to any object entities in the scene via inter-slot competitions for attention. Next, we establish entity-feature correspondence with cyclic walks along high transition probability based on the pairwise similarity between perceptual features (aka \"parts\") and slot-binded object representations (aka \"whole\"). The whole is greater than its parts and the parts constitute the whole. The part-whole interactions form cycle consistencies, as supervisory signals, to train the slot-attention module. Our rigorous experiments on \\textit{seven} image datasets in \\textit{three} \\textit{unsupervised} tasks demonstrate that the networks trained with our cyclic walks can disentangle foregrounds and backgrounds, discover objects, and segment semantic objects in complex scenes. In contrast to object-centric models attached with a decoder for the pixel-level or feature-level reconstructions, our cyclic walks provide strong learning signals, avoiding computation overheads and enhancing memory efficiency. Our source code and data are available at: \\href{https://github.com/ZhangLab-DeepNeuroCogLab/Parts-Whole-Object-Centric-Learning/}{link}",
    "checked": true,
    "id": "4c493f2bc9cfe5ef763c6187fab8134c135fe949",
    "semantic_title": "object-centric learning with cyclic walks between parts and whole",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=KsICioDlYs": {
    "title": "Circuit as Set of Points",
    "volume": "poster",
    "abstract": "As the size of circuit designs continues to grow rapidly, artificial intelligence technologies are being extensively used in Electronic Design Automation (EDA) to assist with circuit design. Placement and routing are the most time-consuming parts of the physical design process, and how to quickly evaluate the placement has become a hot research topic. Prior works either transformed circuit designs into images using hand-crafted methods and then used Convolutional Neural Networks (CNN) to extract features, which are limited by the quality of the hand-crafted methods and could not achieve end-to-end training, or treated the circuit design as a graph structure and used Graph Neural Networks (GNN) to extract features, which require time-consuming preprocessing. In our work, we propose a novel perspective for circuit design by treating circuit components as point clouds and using Transformer-based point cloud perception methods to extract features from the circuit. This approach enables direct feature extraction from raw data without any preprocessing, allows for end-to-end training, and results in high performance. Experimental results show that our method achieves state-of-the-art performance in congestion prediction tasks on both the CircuitNet and ISPD2015 datasets, as well as in design rule check (DRC) violation prediction tasks on the CircuitNet dataset. Our method establishes a bridge between the relatively mature point cloud perception methods and the fast-developing EDA algorithms, enabling us to leverage more collective intelligence to solve this task. To facilitate the research of open EDA design, source codes and pre-trained models are released at https://github.com/hustvl/circuitformer",
    "checked": true,
    "id": "a5c96657d02b89b548aeed3d1721ef9ae70a8e7a",
    "semantic_title": "circuit as set of points",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1moStpWGUj": {
    "title": "Energy Guided Diffusion for Generating Neurally Exciting Images",
    "volume": "poster",
    "abstract": "In recent years, most exciting inputs (MEIs) synthesized from encoding models of neuronal activity have become an established method for studying tuning properties of biological and artificial visual systems. However, as we move up the visual hierarchy, the complexity of neuronal computations increases. Consequently, it becomes more challenging to model neuronal activity, requiring more complex models. In this study, we introduce a novel readout architecture inspired by the mechanism of visual attention. This new architecture, which we call attention readout, together with a data-driven convolutional core outperforms previous task-driven models in predicting the activity of neurons in macaque area V4. However, as our predictive network becomes deeper and more complex, synthesizing MEIs via straightforward gradient ascent (GA) can struggle to produce qualitatively good results and overfit to idiosyncrasies of a more complex model, potentially decreasing the MEI's model-to-brain transferability. To solve this problem, we propose a diffusion-based method for generating MEIs via Energy Guidance (EGG). We show that for models of macaque V4, EGG generates single neuron MEIs that generalize better across varying model architectures than the state-of-the-art GA, while at the same time reducing computational costs by a factor of 4.7x, facilitating experimentally challenging closed-loop experiments. Furthermore, EGG diffusion can be used to generate other neurally exciting images, like most exciting naturalistic images that are on par with a selection of highly activating natural images, or image reconstructions that generalize better across architectures. Finally, EGG is simple to implement, requires no retraining of the diffusion model, and can easily be generalized to provide other characterizations of the visual system, such as invariances. Thus, EGG provides a general and flexible framework to study the coding properties of the visual system in the context of natural images",
    "checked": true,
    "id": "b3eedc72773aec00803312b04b4fbd485e08cb0e",
    "semantic_title": "energy guided diffusion for generating neurally exciting images",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=5La4Y8BnQw": {
    "title": "Fast Bellman Updates for Wasserstein Distributionally Robust MDPs",
    "volume": "poster",
    "abstract": "Markov decision processes (MDPs) often suffer from the sensitivity issue under model ambiguity. In recent years, robust MDPs have emerged as an effective framework to overcome this challenge. Distributionally robust MDPs extend the robust MDP framework by incorporating distributional information of the uncertain model parameters to alleviate the conservative nature of robust MDPs. This paper proposes a computationally efficient solution framework for solving distributionally robust MDPs with Wasserstein ambiguity sets. By exploiting the specific problem structure, the proposed framework decomposes the optimization problems associated with distributionally robust Bellman updates into smaller subproblems, which can be solved efficiently. The overall complexity of the proposed algorithm is quasi-linear in both the numbers of states and actions when the distance metric of the Wasserstein distance is chosen to be $L_1$, $L_2$, or $L_{\\infty}$ norm, and so the computational cost of distributional robustness is substantially reduced. Our numerical experiments demonstrate that the proposed algorithms outperform other state-of-the-art solution methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cemEOP8YoC": {
    "title": "IBA: Towards Irreversible Backdoor Attacks in Federated Learning",
    "volume": "poster",
    "abstract": "Federated learning (FL) is a distributed learning approach that enables machine learning models to be trained on decentralized data without compromising end devices' personal, potentially sensitive data. However, the distributed nature and uninvestigated data intuitively introduce new security vulnerabilities, including backdoor attacks. In this scenario, an adversary implants backdoor functionality into the global model during training, which can be activated to cause the desired misbehaviors for any input with a specific adversarial pattern. Despite having remarkable success in triggering and distorting model behavior, prior backdoor attacks in FL often hold impractical assumptions, limited imperceptibility, and durability. Specifically, the adversary needs to control a sufficiently large fraction of clients or know the data distribution of other honest clients. In many cases, the trigger inserted is often visually apparent, and the backdoor effect is quickly diluted if the adversary is removed from the training process. To address these limitations, we propose a novel backdoor attack framework in FL, \\dung{the \\textbf{Irreversible Backdoor Attack} (\\texttt{IBA})}, that jointly learns the optimal and visually stealthy trigger and then gradually implants the backdoor into a global model. This approach allows the adversary to execute a backdoor attack that can evade both human and machine inspections. Additionally, we enhance the efficiency and durability of the proposed attack by selectively poisoning the model's parameters that are least likely updated by the main task's learning process and constraining the poisoned model update to the vicinity of the global model. Finally, we evaluate the proposed attack framework on several benchmark datasets, including MNIST, CIFAR-10, and Tiny ImageNet, and achieved high success rates while simultaneously bypassing existing backdoor defenses and achieving a more durable backdoor effect compared to other backdoor attacks. Overall, \\texttt{IBA}\\footnote{Code for this paper is published at \\url{https://github.com/sail-research/iba}.} offers a more effective, stealthy, and durable approach to backdoor attacks in FL",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kBBsj9KRgh": {
    "title": "SAME: Uncovering GNN Black Box with Structure-aware Shapley-based Multipiece Explanations",
    "volume": "poster",
    "abstract": "Post-hoc explanation techniques on graph neural networks (GNNs) provide economical solutions for opening the black-box graph models without model retraining. Many GNN explanation variants have achieved state-of-the-art explaining results on a diverse set of benchmarks, while they rarely provide theoretical analysis for their inherent properties and explanatory capability. In this work, we propose $\\underline{\\text{S}}$tructure-$\\underline{\\text{A}}$ware Shapley-based $\\underline{\\text{M}}$ultipiece $\\underline{\\text{E}}$xplanation (SAME) method to address the structure-aware feature interactions challenges for GNNs explanation. Specifically, SAME leverages an expansion-based Monte Carlo tree search to explore the multi-grained structure-aware connected substructure. Afterward, the explanation results are encouraged to be informative of the graph properties by optimizing the combination of distinct single substructures. With the consideration of fair feature interactions in the process of investigating multiple connected important substructures, the explanation provided by SAME has the potential to be as explainable as the theoretically optimal explanation obtained by the Shapley value within polynomial time. Extensive experiments on real-world and synthetic benchmarks show that SAME improves the previous state-of-the-art fidelity performance by 12.9\\% on BBBP, 7.01\\% on MUTAG, 42.3\\% on Graph-SST2, 38.9\\% on Graph-SST5, 11.3\\% on BA-2Motifs and 18.2\\% on BA-Shapes under the same testing condition. Code is available at https://github.com/same2023neurips/same",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tJ88RBqupo": {
    "title": "Can You Rely on Your Model Evaluation? Improving Model Evaluation with Synthetic Test Data",
    "volume": "poster",
    "abstract": "Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model's deployment setting, which may not align with the available test data. In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S-Testing outperforms traditional baselines---including real test data alone---in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches. Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data",
    "checked": true,
    "id": "56274dc93093a4cebf327f68285234537e9699e0",
    "semantic_title": "can you rely on your model evaluation? improving model evaluation with synthetic test data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FLFasCFJNo": {
    "title": "Meta-learning families of plasticity rules in recurrent spiking networks using simulation-based inference",
    "volume": "poster",
    "abstract": "There is substantial experimental evidence that learning and memory-related behaviours rely on local synaptic changes, but the search for distinct plasticity rules has been driven by human intuition, with limited success for multiple, co-active plasticity rules in biological networks. More recently, automated meta-learning approaches have been used in simplified settings, such as rate networks and small feed-forward spiking networks. Here, we develop a simulation-based inference (SBI) method for sequentially filtering plasticity rules through an increasingly fine mesh of constraints that can be modified on-the-fly. This method, _filter SBI_, allows us to infer entire families of complex and co-active plasticity rules in spiking networks. We first consider flexibly parameterized doublet (Hebbian) rules, and find that the set of inferred rules contains solutions that extend and refine -and also reject- predictions from mean-field theory. Next, we expand the search space of plasticity rules by modelling them as multi-layer perceptrons that combine several plasticity-relevant factors, such as weight, voltage, triplets and co-dependency. Out of the millions of possible rules, we identify thousands of unique rule combinations that satisfy biological constraints like plausible activity and weight dynamics. The resulting rules can be used as a starting point for further investigations into specific network computations, and already suggest refinements and predictions for classical experimental approaches on plasticity. This flexible approach for principled exploration of complex plasticity rules in large recurrent spiking networks presents the most advanced search tool to date for enabling robust predictions and deep insights into the plasticity mechanisms underlying brain function",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7cnMLZvTy9": {
    "title": "Certification of Distributional Individual Fairness",
    "volume": "poster",
    "abstract": "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees",
    "checked": true,
    "id": "16ab5911ca99c30800570035b1316dc864ca894f",
    "semantic_title": "certification of distributional individual fairness",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UHwmoJYwSV": {
    "title": "Attacks on Online Learners: a Teacher-Student Analysis",
    "volume": "poster",
    "abstract": "Machine learning models are famously vulnerable to adversarial attacks: small ad-hoc perturbations of the data that can catastrophically alter the model predictions. While a large literature has studied the case of test-time attacks on pre-trained models, the important case of attacks in an online learning setting has received little attention so far. In this work, we use a control-theoretical perspective to study the scenario where an attacker may perturb data labels to manipulate the learning dynamics of an online learner. We perform a theoretical analysis of the problem in a teacher-student setup, considering different attack strategies, and obtaining analytical results for the steady state of simple linear learners. These results enable us to prove that a discontinuous transition in the learner's accuracy occurs when the attack strength exceeds a critical threshold. We then study empirically attacks on learners with complex architectures using real data, confirming the insights of our theoretical analysis. Our findings show that greedy attacks can be extremely efficient, especially when data stream in small batches",
    "checked": true,
    "id": "6ec8c42880ef5f39f26db552dc66611dfbae0a29",
    "semantic_title": "attacks on online learners: a teacher-student analysis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ZuaVKlWdD2": {
    "title": "Injecting Multimodal Information into Rigid Protein Docking via Bi-level Optimization",
    "volume": "poster",
    "abstract": "The structure of protein-protein complexes is critical for understanding binding dynamics, biological mechanisms, and intervention strategies. Rigid protein docking, a fundamental problem in this field, aims to predict the 3D structure of complexes from their unbound states without conformational changes. In this scenario, we have access to two types of valuable information: sequence-modal information, such as coevolutionary data obtained from multiple sequence alignments, and structure-modal information, including the 3D conformations of rigid structures. However, existing docking methods typically utilize single-modal information, resulting in suboptimal predictions. In this paper, we propose xTrimoBiDock (or BiDock for short), a novel rigid docking model that effectively integrates sequence- and structure-modal information through bi-level optimization. Specifically, a cross-modal transformer combines multimodal information to predict an inter-protein distance map. To achieve rigid docking, the roto-translation transformation is optimized to align the docked pose with the predicted distance map. In order to tackle this bi-level optimization problem, we unroll the gradient descent of the inner loop and further derive a better initialization for roto-translation transformation based on spectral estimation. Compared to baselines, BiDock achieves a promising result of a maximum 234% relative improvement in challenging antibody-antigen docking problem",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ogPBujRhiN": {
    "title": "Disentangling Cognitive Diagnosis with Limited Exercise Labels",
    "volume": "poster",
    "abstract": "Cognitive diagnosis is an important task in intelligence education, which aims at measuring students' proficiency in specific knowledge concepts. Given a fully labeled exercise-concept matrix, most existing models focused on mining students' response records for cognitive diagnosis. Despite their success, due to the huge cost of labeling exercises, a more practical scenario is that limited exercises are labeled with concepts. Performing cognitive diagnosis with limited exercise labels is under-explored and remains pretty much open. In this paper, we propose Disentanglement based Cognitive Diagnosis (DCD) to address the challenges of limited exercise labels. Specifically, we utilize students' response records to model student proficiency, exercise difficulty and exercise label distribution. Then, we introduce two novel modules - group-based disentanglement and limited-labeled alignment modules - to disentangle the factors relevant to concepts and align them with real limited labels. Particularly, we introduce the tree-like structure of concepts with negligible cost for group-based disentangling, as concepts of different levels exhibit different independence relationships. Extensive experiments on widely used benchmarks demonstrate the superiority of our proposed model",
    "checked": false,
    "id": "dda30e6f24d9fa2f933a04379049736dcc92a3cb",
    "semantic_title": "society for neuroscience 2019 satellite symposium",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BHZsJ2sTkG": {
    "title": "An Improved Relaxation for Oracle-Efficient Adversarial Contextual Bandits",
    "volume": "poster",
    "abstract": "We present an oracle-efficient relaxation for the adversarial contextual bandits problem, where the contexts are sequentially drawn i.i.d from a known distribution and the cost sequence is chosen by an online adversary. Our algorithm has a regret bound of $O(T^{\\frac{2}{3}}(K\\log(|\\Pi|))^{\\frac{1}{3}})$ and makes at most $O(K)$ calls per round to an offline optimization oracle, where $K$ denotes the number of actions, $T$ denotes the number of rounds and $\\Pi$ denotes the set of policies. This is the first result to improve the prior best bound of $O((TK)^{\\frac{2}{3}}(\\log(|\\Pi|))^{\\frac{1}{3}})$ as obtained by Syrgkanis et al. at NeurIPS 2016, and the first to match the original bound of Langford and Zhang at NeurIPS 2007 which was obtained for the stochastic case",
    "checked": true,
    "id": "e7eb00086b243f746f8e866083257595c08abb41",
    "semantic_title": "an improved relaxation for oracle-efficient adversarial contextual bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JXvszuOqY3": {
    "title": "Switching Temporary Teachers for Semi-Supervised Semantic Segmentation",
    "volume": "poster",
    "abstract": "The teacher-student framework, prevalent in semi-supervised semantic segmentation, mainly employs the exponential moving average (EMA) to update a single teacher's weights based on the student's. However, EMA updates raise a problem in that the weights of the teacher and student are getting coupled, causing a potential performance bottleneck. Furthermore, this problem may become more severe when training with more complicated labels such as segmentation masks but with few annotated data. This paper introduces Dual Teacher, a simple yet effective approach that employs dual temporary teachers aiming to alleviate the coupling problem for the student. The temporary teachers work in shifts and are progressively improved, so consistently prevent the teacher and student from becoming excessively close. Specifically, the temporary teachers periodically take turns generating pseudo-labels to train a student model and maintain the distinct characteristics of the student model for each epoch. Consequently, Dual Teacher achieves competitive performance on the PASCAL VOC, Cityscapes, and ADE20K benchmarks with remarkably shorter training times than state-of-the-art methods. Moreover, we demonstrate that our approach is model-agnostic and compatible with both CNN- and Transformer-based models. Code is available at https://github.com/naver-ai/dual-teacher",
    "checked": true,
    "id": "c258146bdcc9581357b4aed4b74aa08491558df2",
    "semantic_title": "switching temporary teachers for semi-supervised semantic segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=guyhQMSp2F": {
    "title": "Use perturbations when learning from explanations",
    "volume": "poster",
    "abstract": "Machine learning from explanations (MLX) is an approach to learning that uses human-provided explanations of relevant or irrelevant features for each input to ensure that model predictions are right for the right reasons. Existing MLX approaches rely on local model interpretation methods and require strong model smoothing to align model and human explanations, leading to sub-optimal performance. We recast MLX as a robustness problem, where human explanations specify a lower dimensional manifold from which perturbations can be drawn, and show both theoretically and empirically how this approach alleviates the need for strong model smoothing. We consider various approaches to achieving robustness, leading to improved performance over prior MLX methods. Finally, we show how to combine robustness with an earlier MLX method, yielding state-of-the-art results on both synthetic and real-world benchmarks",
    "checked": true,
    "id": "0fa49a6a6ae4935218d5ca831d3c4c7a2ce8210b",
    "semantic_title": "use perturbations when learning from explanations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dWDEBW2raJ": {
    "title": "Train Faster, Perform Better: Modular Adaptive Training in Over-Parameterized Models",
    "volume": "poster",
    "abstract": "Despite their prevalence in deep-learning communities, over-parameterized models convey high demands of computational costs for proper training. This work studies the fine-grained, modular-level learning dynamics of over-parameterized models to attain a more efficient and fruitful training strategy. Empirical evidence reveals that when scaling down into network modules, such as heads in self-attention models, we can observe varying learning patterns implicitly associated with each module's trainability. To describe such modular-level learning capabilities, we introduce a novel concept dubbed modular neural tangent kernel (mNTK), and we demonstrate that the quality of a module's learning is tightly associated with its mNTK's principal eigenvalue $\\lambda_{\\max}$. A large $\\lambda_{\\max}$ indicates that the module learns features with better convergence, while those miniature ones may impact generalization negatively. Inspired by the discovery, we propose a novel training strategy termed Modular Adaptive Training (MAT) to update those modules with their $\\lambda_{\\max}$ exceeding a dynamic threshold selectively, concentrating the model on learning common features and ignoring those inconsistent ones. Unlike most existing training schemes with a complete BP cycle across all network modules, MAT can significantly save computations by its partially-updating strategy and can further improve performance. Experiments show that MAT nearly halves the computational cost of model training and outperforms the accuracy of baselines",
    "checked": false,
    "id": "2516652a00f5620ff27a1a7c99a99a7926466ca2",
    "semantic_title": "mlaas : a framework for exposing machine learning as a service on cloud platforms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oU4QHdcIWW": {
    "title": "Learning Cuts via Enumeration Oracles",
    "volume": "poster",
    "abstract": "Cutting-planes are one of the most important building blocks for solving large-scale integer programming (IP) problems to (near) optimality. The majority of cutting plane approaches rely on explicit rules to derive valid inequalities that can separate the target point from the feasible set. Local cuts, on the other hand, seek to directly derive the facets of the underlying polyhedron and use them as cutting planes. However, current approaches rely on solving Linear Programming (LP) problems in order to derive such a hyperplane. In this paper, we present a novel generic approach for learning the facets of the underlying polyhedron by accessing it implicitly via an enumeration oracle in a reduced dimension. This is achieved by embedding the oracle in a variant of the Frank-Wolfe algorithm which is capable of generating strong cutting planes, effectively turning the enumeration oracle into a separation oracle. We demonstrate the effectiveness of our approach with a case study targeting the multidimensional knapsack problem (MKP)",
    "checked": true,
    "id": "54ef6a112c348ba663674e5b810792ea3c43001e",
    "semantic_title": "learning cuts via enumeration oracles",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=W3cDd5xlKZ": {
    "title": "Fair Canonical Correlation Analysis",
    "volume": "poster",
    "abstract": "This paper investigates fairness and bias in Canonical Correlation Analysis (CCA), a widely used statistical technique for examining the relationship between two sets of variables. We present a framework that alleviates unfairness by minimizing the correlation disparity error associated with protected attributes. Our approach enables the CCA model to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices. Experimental evaluation on both synthetic and real-world datasets demonstrates the efficacy of our method in reducing unfairness without compromising CCA model accuracy. These findings emphasize the importance of considering fairness in CCA applications to real-world problems",
    "checked": true,
    "id": "bd807a83f27d6e280ce794db32bc79612cd3dc64",
    "semantic_title": "fair canonical correlation analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d4X0QWS2Ln": {
    "title": "Towards Test-Time Refusals via Concept Negation",
    "volume": "poster",
    "abstract": "Generative models produce unbounded outputs, necessitating the use of refusal techniques to confine their output space. Employing generative refusals is crucial in upholding the ethical and copyright integrity of synthesized content, particularly when working with widely adopted diffusion models. \"Concept negation'' presents a promising paradigm to achieve generative refusals, as it effectively defines and governs the model's output space based on concepts, utilizing natural language interfaces that are readily comprehensible to humans. However, despite the valuable contributions of prior research to the field of concept negation, it still suffers from significant limitations. The existing concept negation methods, which operate based on the composition of score or noise predictions from the diffusion process, are limited to independent concepts (e.g., ``a blonde girl`` without ``glasses``) and fail to consider the interconnected nature of concepts in reality (e.g., ``Mickey mouse eats ice cream`` without ``Disney characters``). Keeping the limitations in mind, we propose a novel framework, called $ProtoRe$, to improve the flexibility of concept negation via test-time negative concept identification along with purification in the feature space. $ProtoRe$ works by incorporating CLIP's language-contrastive knowledge to identify the prototype of negative concepts, extract the negative features from outputs using the prototype as a prompt, and further refine the attention maps by retrieving negative features. Our evaluation on multiple benchmarks shows that $ProtoRe$ outperforms state-of-the-art methods under various settings, in terms of the effectiveness of purification and the fidelity of generative images",
    "checked": false,
    "id": "85110935299ae6888bea78ed90a2001669d6cee7",
    "semantic_title": "towards a smart and sustainable industry : cycle time optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0x2Ou3xHbH": {
    "title": "On the Convergence of No-Regret Learning Dynamics in Time-Varying Games",
    "volume": "poster",
    "abstract": "Most of the literature on learning in games has focused on the restrictive setting where the underlying repeated game does not change over time. Much less is known about the convergence of no-regret learning algorithms in dynamic multiagent settings. In this paper, we characterize the convergence of optimistic gradient descent (OGD) in time-varying games. Our framework yields sharp convergence bounds for the equilibrium gap of OGD in zero-sum games parameterized on natural variation measures of the sequence of games, subsuming known results for static games. Furthermore, we establish improved second-order variation bounds under strong convexity-concavity, as long as each game is repeated multiple times. Our results also apply to time-varying general-sum multi-player games via a bilinear formulation of correlated equilibria, which has novel implications for meta-learning and for obtaining refined variation-dependent regret bounds, addressing questions left open in prior papers. Finally, we leverage our framework to also provide new insights on dynamic regret guarantees in static games",
    "checked": true,
    "id": "8ee3099493cc536827cce6c45bcfc15cb6d3085b",
    "semantic_title": "on the convergence of no-regret learning dynamics in time-varying games",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=9tUjsRLjf2": {
    "title": "Dynamic Regret of Adversarial Linear Mixture MDPs",
    "volume": "poster",
    "abstract": "We study reinforcement learning in episodic inhomogeneous MDPs with adversarial full-information rewards and the unknown transition kernel. We consider the linear mixture MDPs whose transition kernel is a linear mixture model and choose the \\emph{dynamic regret} as the performance measure. Denote by $d$ the dimension of the feature mapping, $H$ the horizon, $K$ the number of episodes, $P_T$ the non-stationary measure, we propose a novel algorithm that enjoys an $\\widetilde{\\mathcal{O}}\\big(\\sqrt{d^2 H^3K} + \\sqrt{H^4(K+P_T)(1+P_T)}\\big)$ dynamic regret under the condition that $P_T$ is known, which improves previously best-known dynamic regret for adversarial linear mixture MDP and adversarial tabular MDPs. We also establish an $\\Omega\\big(\\sqrt{d^2 H^3 K} + \\sqrt{H K (H+P_T)}\\big)$ lower bound, indicating our algorithm is \\emph{optimal} in $K$ and $P_T$. Furthermore, when the non-stationary measure $P_T$ is unknown, we design an online ensemble algorithm with a meta-base structure, which is proved to achieve an $\\widetilde{\\mathcal{O}}\\big(\\sqrt{d^2 H^3K} + \\sqrt{H^4(K+P_T)(1+P_T) + H^2 S_T^2}\\big)$ dynamic regret and here $S_T$ is the expected switching number of the best base-learner. The result can be optimal under certain regimes",
    "checked": false,
    "id": "d5eb1ac1923139dd6b00c3bd27f6da30b79aa691",
    "semantic_title": "horizon-free reinforcement learning in adversarial linear mixture mdps",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1jhmWkZGy6": {
    "title": "Neural Sculpting: Uncovering hierarchically modular task structure in neural networks through pruning and network analysis",
    "volume": "poster",
    "abstract": "Natural target functions and tasks typically exhibit hierarchical modularity -- they can be broken down into simpler sub-functions that are organized in a hierarchy. Such sub-functions have two important features: they have a distinct set of inputs (input-separability) and they are reused as inputs higher in the hierarchy (reusability). Previous studies have established that hierarchically modular neural networks, which are inherently sparse, offer benefits such as learning efficiency, generalization, multi-task learning, and transfer. However, identifying the underlying sub-functions and their hierarchical structure for a given task can be challenging. The high-level question in this work is: if we learn a task using a sufficiently deep neural network, how can we uncover the underlying hierarchy of sub-functions in that task? As a starting point, we examine the domain of Boolean functions, where it is easier to determine whether a task is hierarchically modular. We propose an approach based on iterative unit and edge pruning (during training), combined with network analysis for module detection and hierarchy inference. Finally, we demonstrate that this method can uncover the hierarchical modularity of a wide range of Boolean functions and two vision tasks based on the MNIST digits dataset",
    "checked": false,
    "id": "1ffdd834926cefd94279b5638e2d67d9bfd11f6c",
    "semantic_title": "neural sculpting: uncovering hierarchically modular task structure through pruning and network analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8GSCaoFot9": {
    "title": "Conservative State Value Estimation for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline reinforcement learning faces a significant challenge of value over-estimation due to the distributional drift between the dataset and the current learned policy, leading to learning failure in practice. The common approach is to incorporate a penalty term to reward or value estimation in the Bellman iterations. Meanwhile, to avoid extrapolation on out-of-distribution (OOD) states and actions, existing methods focus on conservative Q-function estimation. In this paper, we propose Conservative State Value Estimation (CSVE), a new approach that learns conservative V-function via directly imposing penalty on OOD states. Compared to prior work, CSVE allows more effective state value estimation with conservative guarantees and further better policy optimization. Further, we apply CSVE and develop a practical actor-critic algorithm in which the critic does the conservative value estimation by additionally sampling and penalizing the states around the dataset, and the actor applies advantage weighted updates extended with state exploration to improve the policy. We evaluate in classic continual control tasks of D4RL, showing that our method performs better than the conservative Q-function learning methods and is strongly competitive among recent SOTA methods",
    "checked": true,
    "id": "8c4a2558851522b0344c7d605aac7d2a36b740aa",
    "semantic_title": "conservative state value estimation for offline reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lRxpVfDMzz": {
    "title": "Extensible Prompts for Language Models on Zero-shot Language Style Customization",
    "volume": "poster",
    "abstract": "We propose eXtensible Prompt (X-Prompt) for prompting a large language model (LLM) beyond natural language (NL). X-Prompt instructs an LLM with not only NL but also an extensible vocabulary of imaginary words. Registering new imaginary words allows us to instruct the LLM to comprehend concepts that are difficult to describe with NL words, thereby making a prompt more descriptive. Also, these imaginary words are designed to be out-of-distribution (OOD) robust so that they can be (re)used like NL words in various prompts, distinguishing X-Prompt from soft prompt that is for fitting in-distribution data. We propose context-augmented learning (CAL) to learn imaginary words for general usability, enabling them to work properly in OOD (unseen) prompts. We experiment X-Prompt for zero-shot language style customization as a case study. The promising results of X-Prompt demonstrate its potential to facilitate advanced interaction beyond the natural language interface, bridging the communication gap between humans and LLMs",
    "checked": false,
    "id": "d8cc40fae75afcd09a9a08a1dbfb8ad8f5ad8515",
    "semantic_title": "distilling vision-language foundation models: a data-free approach via prompt diversification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yh0OkiUk5h": {
    "title": "FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations",
    "volume": "poster",
    "abstract": "Unsupervised node representations learnt using contrastive learning-based methods have shown good performance on downstream tasks. However, these methods rely on augmentations that mimic low-pass filters, limiting their performance on tasks requiring different eigen-spectrum parts. This paper presents a simple filter-based augmentation method to capture different parts of the eigen-spectrum. We show significant improvements using these augmentations. Further, we show that sharing the same weights across these different filter augmentations is possible, reducing the computational load. In addition, previous works have shown that good performance on downstream tasks requires high dimensional representations. Working with high dimensions increases the computations, especially when multiple augmentations are involved. We mitigate this problem and recover good performance through lower dimensional embeddings using simple random Fourier feature projections. Our method, FiGURe, achieves an average gain of up to 4.4\\%, compared to the state-of-the-art unsupervised models, across all datasets in consideration, both homophilic and heterophilic. Our code can be found at: https://github.com/Microsoft/figure",
    "checked": true,
    "id": "d0c199b4e56ab22146be76a620ea74690b3f70bd",
    "semantic_title": "figure: simple and efficient unsupervised node representations with filter augmentations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lM0xyViO90": {
    "title": "On the Interplay between Social Welfare and Tractability of Equilibria",
    "volume": "poster",
    "abstract": "Computational tractability and social welfare (aka. efficiency) of equilibria are two fundamental but in general orthogonal considerations in algorithmic game theory. Nevertheless, we show that when (approximate) full efficiency can be guaranteed via a smoothness argument a la Roughgarden, Nash equilibria are approachable under a family of no-regret learning algorithms, thereby enabling fast and decentralized computation. We leverage this connection to obtain new convergence results in large games---wherein the number of players $n \\gg 1$---under the well-documented property of full efficiency via smoothness in the limit. Surprisingly, our framework unifies equilibrium computation in disparate classes of problems including games with vanishing strategic sensitivity and two-player zero-sum games, illuminating en route an immediate but overlooked equivalence between smoothness and a well-studied condition in the optimization literature known as the Minty property. Finally, we establish that a family of no-regret dynamics attains a welfare bound that improves over the smoothness framework while at the same time guaranteeing convergence to the set of coarse correlated equilibria. We show this by employing the clairvoyant mirror descent algortihm recently introduced by Piliouras et al",
    "checked": true,
    "id": "e0dc87d05e4f639da6adbb47dc1db4d4189a7fbb",
    "semantic_title": "on the interplay between social welfare and tractability of equilibria",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wpfsnu5syT": {
    "title": "ContinuAR: Continuous Autoregression For Infinite-Fidelity Fusion",
    "volume": "poster",
    "abstract": "Multi-fidelity fusion has become an important surrogate technique, which provides insights into expensive computer simulations and effectively improves decision-making, e.g., optimization, with less computational cost. Multi-fidelity fusion is much more computationally efficient compared to traditional single-fidelity surrogates. Despite the fast advancement of multi-fidelity fusion techniques, they lack a systematic framework to make use of the fidelity indicator, deal with high-dimensional and arbitrary data structure, and scale well to infinite-fidelity problems. In this work, we first generalize the popular autoregression (AR) to derive a novel linear fidelity differential equation (FiDE), paving the way to tractable infinite-fidelity fusion. We generalize FiDE to a high-dimensional system, which also provides a unifying framework to seemly bridge the gap between many multi- and single-fidelity GP-based models. We then propose ContinuAR, a rank-1 approximation solution to FiDEs, which is tractable to train, compatible with arbitrary multi-fidelity data structure, linearly scalable to the output dimension, and most importantly, delivers consistent SOTA performance with a significant margin over the baseline methods. Compared to the SOTA infinite-fidelity fusion, IFC, ContinuAR achieves up to 4x improvement in accuracy and 62,500x speedup in training time",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Lkc0KjsDFv": {
    "title": "CS-Isolate: Extracting Hard Confident Examples by Content and Style Isolation",
    "volume": "poster",
    "abstract": "Label noise widely exists in large-scale image datasets. To mitigate the side effects of label noise, state-of-the-art methods focus on selecting confident examples by leveraging semi-supervised learning. Existing research shows that the ability to extract hard confident examples, which are close to the decision boundary, significantly influences the generalization ability of the learned classifier. In this paper, we find that a key reason for some hard examples being close to the decision boundary is due to the entanglement of style factors with content factors. The hard examples become more discriminative when we focus solely on content factors, such as semantic information, while ignoring style factors. Nonetheless, given only noisy data, content factors are not directly observed and have to be inferred. To tackle the problem of inferring content factors for classification when learning with noisy labels, our objective is to ensure that the content factors of all examples in the same underlying clean class remain unchanged as their style information changes. To achieve this, we utilize different data augmentation techniques to alter the styles while regularizing content factors based on some confident examples. By training existing methods with our inferred content factors, CS-Isolate proves their effectiveness in learning hard examples on benchmark datasets. The implementation is available at https://github.com/tmllab/2023_NeurIPS_CS-isolate",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=niHkj9ixUZ": {
    "title": "Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial Defense",
    "volume": "poster",
    "abstract": "Recent advancements in masked image modeling (MIM) have made it a prevailing framework for self-supervised visual representation learning. The MIM pretrained models, like most deep neural network methods, remain vulnerable to adversarial attacks, limiting their practical application, and this issue has received little research attention. In this paper, we investigate how this powerful self-supervised learning paradigm can provide adversarial robustness to downstream classifiers. During the exploration, we find that noisy image modeling (NIM), a simple variant of MIM that adopts denoising as the pre-text task, reconstructs noisy images surprisingly well despite severe corruption. Motivated by this observation, we propose an adversarial defense method, referred to as De^3, by exploiting the pretrained decoder for denoising. Through De^3, NIM is able to enhance adversarial robustness beyond providing pretrained features. Furthermore, we incorporate a simple modification, sampling the noise scale hyperparameter from random distributions, and enable the defense to achieve a better and tunable trade-off between accuracy and robustness. Experimental results demonstrate that, in terms of adversarial robustness, NIM is superior to MIM thanks to its effective denoising capability. Moreover, the defense provided by NIM achieves performance on par with adversarial training while offering the extra tunability advantage. Source code and models are available at https://github.com/youzunzhi/NIM-AdvDef",
    "checked": true,
    "id": "8d814ca8a323af3afafde8fc0bc2d7f27473b4e2",
    "semantic_title": "beyond pretrained features: noisy image modeling provides adversarial defense",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VfP6VTVsHc": {
    "title": "RDumb: A simple approach that questions our progress in continual test-time adaptation",
    "volume": "poster",
    "abstract": "Test-Time Adaptation (TTA) allows to update pre-trained models to changing data distributions at deployment time. While early work tested these algorithms for individual fixed distribution shifts, recent work proposed and applied methods for continual adaptation over long timescales. To examine the reported progress in the field, we propose the Continually Changing Corruptions (CCC) benchmark to measure asymptotic performance of TTA techniques. We find that eventually all but one state-of-the-art methods collapse and perform worse than a non-adapting model, including models specifically proposed to be robust to performance collapse. In addition, we introduce a simple baseline, \"RDumb\", that periodically resets the model to its pretrained state. RDumb performs better or on par with the previously proposed state-of-the-art in all considered benchmarks. Our results show that previous TTA approaches are neither effective at regularizing adaptation to avoid collapse nor able to outperform a simplistic resetting strategy",
    "checked": true,
    "id": "3fe8b8c3476dcbfeb7592366ae4118f4581be9ee",
    "semantic_title": "rdumb: a simple approach that questions our progress in continual test-time adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k1Xy5zCNOJ": {
    "title": "Lookaround Optimizer: $k$ steps around, 1 step average",
    "volume": "poster",
    "abstract": "Weight Average (WA) is an active research topic due to its simplicity in ensembling deep networks and the effectiveness in promoting generalization. Existing weight average approaches, however, are often carried out along only one training trajectory in a post-hoc manner (i.e., the weights are averaged after the entire training process is finished), which significantly degrades the diversity between networks and thus impairs the effectiveness. In this paper, inspired by weight average, we propose Lookaround, a straightforward yet effective SGD-based optimizer leading to flatter minima with better generalization. Specifically, Lookaround iterates two steps during the whole training period: the around step and the average step. In each iteration, 1) the around step starts from a common point and trains multiple networks simultaneously, each on transformed data by a different data augmentation, and 2) the average step averages these trained networks to get the averaged network, which serves as the starting point for the next iteration. The around step improves the functionality diversity while the average step guarantees the weight locality of these networks during the whole training, which is essential for WA to work. We theoretically explain the superiority of Lookaround by convergence analysis, and make extensive experiments to evaluate Lookaround on popular benchmarks including CIFAR and ImageNet with both CNNs and ViTs, demonstrating clear superiority over state-of-the-arts. Our code is available at https://github.com/Ardcy/Lookaround",
    "checked": false,
    "id": "e35776788d031de23050caadbb22bcb6e469a526",
    "semantic_title": "lookaround optimizer: k steps around, 1 step average",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bmdnWIuypV": {
    "title": "Bringing regularized optimal transport to lightspeed: a splitting method adapted for GPUs",
    "volume": "poster",
    "abstract": "We present an efficient algorithm for regularized optimal transport. In contrast to previous methods, we use the Douglas-Rachford splitting technique to develop an efficient solver that can handle a broad class of regularizers. The algorithm has strong global convergence guarantees, low per-iteration cost, and can exploit GPU parallelization, making it considerably faster than the state-of-the-art for many problems. We illustrate its competitiveness in several applications, including domain adaptation and learning of generative models",
    "checked": true,
    "id": "7d5320b30a2610c47d79fcb405cd86aaca872dfa",
    "semantic_title": "bringing regularized optimal transport to lightspeed: a splitting method adapted for gpus",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=fyfmHi8ay3": {
    "title": "Template-free Articulated Neural Point Clouds for Reposable View Synthesis",
    "volume": "poster",
    "abstract": "Dynamic Neural Radiance Fields (NeRFs) achieve remarkable visual quality when synthesizing novel views of time-evolving 3D scenes. However, the common reliance on backward deformation fields makes reanimation of the captured object poses challenging. Moreover, the state of the art dynamic models are often limited by low visual fidelity, long reconstruction time or specificity to narrow application domains. In this paper, we present a novel method utilizing a point-based representation and Linear Blend Skinning (LBS) to jointly learn a Dynamic NeRF and an associated skeletal model from even sparse multi-view video. Our forward-warping approach achieves state-of-the-art visual fidelity when synthesizing novel views and poses while significantly reducing the necessary learning time when compared to existing work. We demonstrate the versatility of our representation on a variety of articulated objects from common datasets and obtain reposable 3D reconstructions without the need of object-specific skeletal templates",
    "checked": true,
    "id": "1956e9c389f8d3a765fccc297f9e2bb87cef9685",
    "semantic_title": "template-free articulated neural point clouds for reposable view synthesis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=dOxm4FnMFu": {
    "title": "Locally Invariant Explanations: Towards Stable and Unidirectional Explanations through Local Invariant Learning",
    "volume": "poster",
    "abstract": "Locally interpretable model agnostic explanations (LIME) method is one of the most popular methods used to explain black-box models at a per example level. Although many variants have been proposed, few provide a simple way to produce high fidelity explanations that are also stable and intuitive. In this work, we provide a novel perspective by proposing a model agnostic local explanation method inspired by the invariant risk minimization (IRM) principle -- originally proposed for (global) out-of-distribution generalization -- to provide such high fidelity explanations that are also stable and unidirectional across nearby examples. Our method is based on a game theoretic formulation where we theoretically show that our approach has a strong tendency to eliminate features where the gradient of the black-box function abruptly changes sign in the locality of the example we want to explain, while in other cases it is more careful and will choose a more conservative (feature) attribution, a behavior which can be highly desirable for recourse. Empirically, we show on tabular, image and text data that the quality of our explanations with neighborhoods formed using random perturbations are much better than LIME and in some cases even comparable to other methods that use realistic neighbors sampled from the data manifold. This is desirable given that learning a manifold to either create realistic neighbors or to project explanations is typically expensive or may even be impossible. Moreover, our algorithm is simple and efficient to train, and can ascertain stable input features for local decisions of a black-box without access to side information such as a (partial) causal graph as has been seen in some recent works",
    "checked": true,
    "id": "d11fd8a361cd1a438ce40fef2abfc814301b2141",
    "semantic_title": "locally invariant explanations: towards stable and unidirectional explanations through local invariant learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dnGEPkmnzO": {
    "title": "Fully Dynamic $k$-Clustering in $\\tilde O(k)$ Update Time",
    "volume": "poster",
    "abstract": "We present a $O(1)$-approximate fully dynamic algorithm for the $k$-median and $k$-means problems on metric spaces with amortized update time $\\tilde O(k)$ and worst-case query time $\\tilde O(k^2)$. We complement our theoretical analysis with the first in-depth experimental study for the dynamic $k$-median problem on general metrics, focusing on comparing our dynamic algorithm to the current state-of-the-art by Henzinger and Kale [ESA'20]. Finally, we also provide a lower bound for dynamic $k$-median which shows that any $O(1)$-approximate algorithm with $\\tilde O(\\text{poly}(k))$ query time must have $\\tilde \\Omega(k)$ amortized update time, even in the incremental setting",
    "checked": true,
    "id": "629821f9b4e9e053de725a8a78d2b47ba3710f33",
    "semantic_title": "fully dynamic $k$-clustering in $\\tilde o(k)$ update time",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T2lM4ohRwb": {
    "title": "Connecting Certified and Adversarial Training",
    "volume": "poster",
    "abstract": "Training certifiably robust neural networks remains a notoriously hard problem. While adversarial training optimizes under-approximations of the worst-case loss, which leads to insufficient regularization for certification, sound certified training methods, optimize loose over-approximations, leading to over-regularization and poor (standard) accuracy. In this work, we propose TAPS, an (unsound) certified training method that combines IBP and PGD training to optimize more precise, although not necessarily sound, worst-case loss approximations, reducing over-regularization and increasing certified and standard accuracies. Empirically, TAPS achieves a new state-of-the-art in many settings, e.g., reaching a certified accuracy of $22$% on TinyImageNet for $\\ell_\\infty$-perturbations with radius $\\epsilon=1/255$. We make our implementation and networks public at https://github.com/eth-sri/taps",
    "checked": false,
    "id": "c605cec07d7d190510e5487add246e1b52de423f",
    "semantic_title": "taps: connecting certified and adversarial training",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=sbusw6LD41": {
    "title": "Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing",
    "volume": "poster",
    "abstract": "Transformer models have been widely adopted in various domains over the last years and especially large language models have advanced the field of AI significantly. Due to their size, the capability of these networks has increased tremendously, but this has come at the cost of a significant increase in necessary compute. Quantization is one of the most effective ways for reducing the computational time and memory consumption of neural networks. Many studies have shown, however, that modern transformer models tend to learn strong outliers in their activations, making them difficult to quantize. To retain acceptable performance, the existence of these outliers requires activations to be in higher-bitwidth or the use of different numeric formats, extra fine-tuning, or other workarounds. We show that strong outliers are related to very specific behavior of attention heads that try to learn a \"no-op\", or just a partial update of the residual. To achieve the exact zeros needed in the attention matrix for a no-update, the input to the softmax is pushed to be larger and larger during training, causing outliers in other parts of the network. Based on these observations, we propose two simple (independent) modifications to the attention mechanism - _clipped softmax_ and _gated attention_. We empirically show that models pre-trained using our methods learn significantly smaller outliers while maintaining and sometimes even improving the floating-point task performance. This enables us to quantize transformers to full INT8 quantization of the activations without any additional effort. We demonstrate the effectiveness of our methods on both language models (BERT, OPT) and vision transformers",
    "checked": true,
    "id": "d193675b92fbfbf22ed82fda35cd2e73587e33bd",
    "semantic_title": "quantizable transformers: removing outliers by helping attention heads do nothing",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=W5Clq1bSrR": {
    "title": "Toward Understanding Generative Data Augmentation",
    "volume": "poster",
    "abstract": "Generative data augmentation, which scales datasets by obtaining fake labeled examples from a trained conditional generative model, boosts classification performance in various learning tasks including (semi-)supervised learning, few-shot learning, and adversarially robust learning. However, little work has theoretically investigated the effect of generative data augmentation. To fill this gap, we establish a general stability bound in this not independently and identically distributed (non-i.i.d.) setting, where the learned distribution is dependent on the original train set and generally not the same as the true distribution. Our theoretical result includes the divergence between the learned distribution and the true distribution. It shows that generative data augmentation can enjoy a faster learning rate when the order of divergence term is $o(\\max\\left( \\log(m)\\beta_m, 1 / \\sqrt{m})\\right)$, where $m$ is the train set size and $\\beta_m$ is the corresponding stability constant. We further specify the learning setup to the Gaussian mixture model and generative adversarial nets. We prove that in both cases, though generative data augmentation does not enjoy a faster learning rate, it can improve the learning guarantees at a constant level when the train set is small, which is significant when the awful overfitting occurs. Simulation results on the Gaussian mixture model and empirical results on generative adversarial nets support our theoretical conclusions",
    "checked": true,
    "id": "cf5c2563f0ffa6c6057787cd6e710312d751fa85",
    "semantic_title": "toward understanding generative data augmentation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=1G7CBp8o7L": {
    "title": "Adapting Neural Link Predictors for Data-Efficient Complex Query Answering",
    "volume": "poster",
    "abstract": "Answering complex queries on incomplete knowledge graphs is a challenging task where a model needs to answer complex logical queries in the presence of missing knowledge. Prior work in the literature has proposed to address this problem by designing architectures trained end-to-end for the complex query answering task with a reasoning process that is hard to interpret while requiring data and resource-intensive training. Other lines of research have proposed re-using simple neural link predictors to answer complex queries, reducing the amount of training data by orders of magnitude while providing interpretable answers. The neural link predictor used in such approaches is not explicitly optimised for the complex query answering task, implying that its scores are not calibrated to interact together. We propose to address these problems via CQD$^{\\mathcal{A}}$, a parameter-efficient score \\emph{adaptation} model optimised to re-calibrate neural link prediction scores for the complex query answering task. While the neural link predictor is frozen, the adaptation component -- which only increases the number of model parameters by $0.03\\%$ -- is trained on the downstream complex query answering task. Furthermore, the calibration component enables us to support reasoning over queries that include atomic negations, which was previously impossible with link predictors. In our experiments, CQD$^{\\mathcal{A}}$ produces significantly more accurate results than current state-of-the-art methods, improving from $34.4$ to $35.1$ Mean Reciprocal Rank values averaged across all datasets and query types while using $\\leq 30\\%$ of the available training query types. We further show that CQD$^{\\mathcal{A}}$ is data-efficient, achieving competitive results with only $1\\%$ of the complex training queries and robust in out-of-domain evaluations. Source code and datasets are available at https://github.com/EdinburghNLP/adaptive-cqd",
    "checked": true,
    "id": "d3aa244f42c598d58d055c177b2ca1fdc1a172ad",
    "semantic_title": "adapting neural link predictors for data-efficient complex query answering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F5FVsfCxt8": {
    "title": "Decision Tree for Locally Private Estimation with Public Data",
    "volume": "poster",
    "abstract": "We propose conducting locally differentially private (LDP) estimation with the aid of a small amount of public data to enhance the performance of private estimation. Specifically, we introduce an efficient algorithm called Locally differentially Private Decision Tree (LPDT) for LDP regression. We first use the public data to grow a decision tree partition and then fit an estimator according to the partition privately. From a theoretical perspective, we show that LPDT is $\\varepsilon$-LDP and has a mini-max optimal convergence rate under a mild assumption of similarity between public and private data, whereas the lower bound of the convergence rate of LPDT without public data is strictly slower, which implies that the public data helps to improve the convergence rates of LDP estimation. We conduct experiments on both synthetic and real-world data to demonstrate the superior performance of LPDT compared with other state-of-the-art LDP regression methods. Moreover, we show that LPDT remains effective despite considerable disparities between public and private data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eLH2NFOO1B": {
    "title": "Equivariant flow matching",
    "volume": "poster",
    "abstract": "Normalizing flows are a class of deep generative models that are especially interesting for modeling probability distributions in physics, where the exact likelihood of flows allows reweighting to known target energy functions and computing unbiased observables. For instance, Boltzmann generators tackle the long-standing sampling problem in statistical physics by training flows to produce equilibrium samples of many-body systems such as small molecules and proteins. To build effective models for such systems, it is crucial to incorporate the symmetries of the target energy into the model, which can be achieved by equivariant continuous normalizing flows (CNFs). However, CNFs can be computationally expensive to train and generate samples from, which has hampered their scalability and practical application. In this paper, we introduce equivariant flow matching, a new training objective for equivariant CNFs that is based on the recently proposed optimal transport flow matching. Equivariant flow matching exploits the physical symmetries of the target energy for efficient, simulation-free training of equivariant CNFs. We demonstrate the effectiveness of flow matching on rotation and permutation invariant many-particle systems and a small molecule, alanine dipeptide, where for the first time we obtain a Boltzmann generator with significant sampling efficiency without relying on tailored internal coordinate featurization. Our results show that the equivariant flow matching objective yields flows with shorter integration paths, improved sampling efficiency, and higher scalability compared to existing methods",
    "checked": true,
    "id": "6551658db09e8a0e53bbc5db41ff04c50f20b1b9",
    "semantic_title": "equivariant flow matching",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=co4p15OMoc": {
    "title": "Implicit Manifold Gaussian Process Regression",
    "volume": "poster",
    "abstract": "Gaussian process regression is widely used because of its ability to provide well-calibrated uncertainty estimates and handle small or sparse datasets. However, it struggles with high-dimensional data. One possible way to scale this technique to higher dimensions is to leverage the implicit low-dimensional manifold upon which the data actually lies, as postulated by the manifold hypothesis. Prior work ordinarily requires the manifold structure to be explicitly provided though, i.e. given by a mesh or be known to be one of the well-known manifolds like the sphere. In contrast, in this paper we propose a Gaussian process regression technique capable of inferring implicit structure directly from data (labeled and unlabeled) in a fully differentiable way. For the resulting model, we discuss its convergence to the Matérn Gaussian process on the assumed manifold. Our technique scales up to hundreds of thousands of data points, and may improve the predictive performance and calibration of the standard Gaussian process regression in high-dimensional settings",
    "checked": true,
    "id": "a737516059624dcfbfae4060a5e128de21146497",
    "semantic_title": "implicit manifold gaussian process regression",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3pEBW2UPAD": {
    "title": "ReHLine: Regularized Composite ReLU-ReHU Loss Minimization with Linear Computation and Linear Convergence",
    "volume": "poster",
    "abstract": "Empirical risk minimization (ERM) is a crucial framework that offers a general approach to handling a broad range of machine learning tasks. In this paper, we propose a novel algorithm, called ReHLine, for minimizing a set of regularized ERMs with convex piecewise linear-quadratic loss functions and optional linear constraints. The proposed algorithm can effectively handle diverse combinations of loss functions, regularization, and constraints, making it particularly well-suited for complex domain-specific problems. Examples of such problems include FairSVM, elastic net regularized quantile regression, Huber minimization, etc. In addition, ReHLine enjoys a provable linear convergence rate and exhibits a per-iteration computational complexity that scales linearly with the sample size. The algorithm is implemented with both Python and R interfaces, and its performance is benchmarked on various tasks and datasets. Our experimental results demonstrate that ReHLine significantly surpasses generic optimization solvers in terms of computational efficiency on large-scale datasets. Moreover, it also outperforms specialized solvers such as Liblinear in SVMs, hqreg in Huber minimization, and Lightning (SAGA, SAG, SDCA, SVRG) in smoothed SVMs, exhibiting exceptional flexibility and efficiency. The source code, project page, accompanying software, and the Python/R interface can be accessed through the link: https://github.com/softmin/ReHLine",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hlkhPdhuAO": {
    "title": "Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction",
    "volume": "poster",
    "abstract": "Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and prior-enhanced queries, leveraging the benefits of spatial localization and human body prior knowledge. Comprehensive experiments on CAPE and THuman2.0 datasets illustrate that our method outperforms state-of-the-art approaches in both geometry and texture reconstruction, exhibiting high robustness to challenging poses and loose clothing, and producing higher-resolution textures. Codes are available at https://github.com/River-Zhang/GTA",
    "checked": true,
    "id": "18240c1d699a1717de28a9804908123dc93717a2",
    "semantic_title": "global-correlated 3d-decoupling transformer for clothed avatar reconstruction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BdvCo8RVlx": {
    "title": "The Contextual Lasso: Sparse Linear Models via Deep Neural Networks",
    "volume": "poster",
    "abstract": "Sparse linear models are one of several core tools for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the network with a novel lasso regularizer in the form of a projection layer that maps the network's output onto the space of $\\ell_1$-constrained linear models. An extensive suite of experiments on real and synthetic data suggests that the learned models, which remain highly transparent, can be sparser than the regular lasso without sacrificing the predictive power of a standard deep neural network",
    "checked": true,
    "id": "338cab5c432e3927092b003abf3db57077c5d8c5",
    "semantic_title": "the contextual lasso: sparse linear models via deep neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wYkfog48Bq": {
    "title": "Optimal Block-wise Asymmetric Graph Construction for Graph-based Semi-supervised Learning",
    "volume": "poster",
    "abstract": "Graph-based semi-supervised learning (GSSL) serves as a powerful tool to model the underlying manifold structures of samples in high-dimensional spaces. It involves two phases: constructing an affinity graph from available data and inferring labels for unlabeled nodes on this graph. While numerous algorithms have been developed for label inference, the crucial graph construction phase has received comparatively less attention, despite its significant influence on the subsequent phase. In this paper, we present an optimal asymmetric graph structure for the label inference phase with theoretical motivations. Unlike existing graph construction methods, we differentiate the distinct roles that labeled nodes and unlabeled nodes could play. Accordingly, we design an efficient block-wise graph learning algorithm with a global convergence guarantee. Other benefits induced by our method, such as enhanced robustness to noisy node features, are explored as well. Finally, we perform extensive experiments on synthetic and real-world datasets to demonstrate its superiority to the state-of-the-art graph construction methods in GSSL",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XhNlBvb4XV": {
    "title": "Deep Insights into Noisy Pseudo Labeling on Graph Data",
    "volume": "poster",
    "abstract": "Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view consistency. Finally, extensive experiments demonstrate that the proposed strategy improves graph learning process and outperforms other PL strategies on link prediction and node classification tasks",
    "checked": true,
    "id": "49a7b78fc6c6886b1c28bb563beb91e49108e62e",
    "semantic_title": "deep insights into noisy pseudo labeling on graph data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DS4rKySlYC": {
    "title": "Causal Interpretation of Self-Attention in Pre-Trained Transformers",
    "volume": "poster",
    "abstract": "We propose a causal interpretation of self-attention in the Transformer neural network architecture. We interpret self-attention as a mechanism that estimates a structural equation model for a given input sequence of symbols (tokens). The structural equation model can be interpreted, in turn, as a causal structure over the input symbols under the specific context of the input sequence. Importantly, this interpretation remains valid in the presence of latent confounders. Following this interpretation, we estimate conditional independence relations between input symbols by calculating partial correlations between their corresponding representations in the deepest attention layer. This enables learning the causal structure over an input sequence using existing constraint-based algorithms. In this sense, existing pre-trained Transformers can be utilized for zero-shot causal-discovery. We demonstrate this method by providing causal explanations for the outcomes of Transformers in two tasks: sentiment classification (NLP) and recommendation",
    "checked": true,
    "id": "085cd67ae1a544b5aced388d3c42e5675cbd62b4",
    "semantic_title": "causal interpretation of self-attention in pre-trained transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yCBqKTvYe9": {
    "title": "Credal Marginal MAP",
    "volume": "poster",
    "abstract": "Credal networks extend Bayesian networks to allow for imprecision in probability values. Marginal MAP is a widely applicable mixed inference task that identifies the most likely assignment for a subset of variables (called MAP variables). However, the task is extremely difficult to solve in credal networks particularly because the evaluation of each complete MAP assignment involves exact likelihood computations (combinatorial sums) over the vertices of a complex joint credal set representing the space of all possible marginal distributions of the MAP variables. In this paper, we explore Credal Marginal MAP inference and develop new exact methods based on variable elimination and depth-first search as well as several approximation schemes based on the mini-bucket partitioning and stochastic local search. An extensive empirical evaluation demonstrates the effectiveness of our new methods on random as well as real-world benchmark problems",
    "checked": false,
    "id": "b342a663fdd480f445680e7e3be58ba21b353bed",
    "semantic_title": "solving marginal map exactly by probabilistic circuit transformations",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=XetXfkYZ6i": {
    "title": "Deep Recurrent Optimal Stopping",
    "volume": "poster",
    "abstract": "Deep neural networks (DNNs) have recently emerged as a powerful paradigm for solving Markovian optimal stopping problems. However, a ready extension of DNN-based methods to non-Markovian settings requires significant state and parameter space expansion, manifesting the curse of dimensionality. Further, efficient state-space transformations permitting Markovian approximations, such as those afforded by recurrent neural networks (RNNs), are either structurally infeasible or are confounded by the curse of non-Markovianity. Considering these issues, we introduce, for the first time, an optimal stopping policy gradient algorithm (OSPG) that can leverage RNNs effectively in non-Markovian settings by implicitly optimizing value functions without recursion, mitigating the curse of non-Markovianity. The OSPG algorithm is derived from an inference procedure on a novel Bayesian network representation of discrete-time non-Markovian optimal stopping trajectories and, as a consequence, yields an offline policy gradient algorithm that eliminates expensive Monte Carlo policy rollouts",
    "checked": false,
    "id": "1aec0c340834cf168c4a6693ea23fb8036462759",
    "semantic_title": "neural optimal stopping boundary",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=X6mwdEVYvc": {
    "title": "Stochastic Approximation Algorithms for Systems of Interacting Particles",
    "volume": "poster",
    "abstract": "Interacting particle systems have proven highly successful in various machine learning tasks, including approximate Bayesian inference and neural network optimization. However, the analysis of these systems often relies on the simplifying assumption of the \\emph{mean-field} limit, where particle numbers approach infinity and infinitesimal step sizes are used. In practice, discrete time steps, finite particle numbers, and complex integration schemes are employed, creating a theoretical gap between continuous-time and discrete-time processes. In this paper, we present a novel framework that establishes a precise connection between these discrete-time schemes and their corresponding mean-field limits in terms of convergence properties and asymptotic behavior. By adopting a dynamical system perspective, our framework seamlessly integrates various numerical schemes that are typically analyzed independently. For example, our framework provides a unified treatment of optimizing an infinite-width two-layer neural network and sampling via Stein Variational Gradient descent, which were previously studied in isolation",
    "checked": false,
    "id": "3a3b0e4c7f693db260f7b61ad3c3e49424164577",
    "semantic_title": "efficient derivative-free bayesian inference for large-scale inverse problems",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=L7Whl9pXd0": {
    "title": "Efficient Batched Algorithm for Contextual Linear Bandits with Large Action Space via Soft Elimination",
    "volume": "poster",
    "abstract": "In this paper, we provide the first efficient batched algorithm for contextual linear bandits with large action spaces. Unlike existing batched algorithms that rely on action elimination, which are not implementable for large action sets, our algorithm only uses a linear optimization oracle over the action set to design the policy. The proposed algorithm achieves a regret upper bound $\\tilde{O}(\\sqrt{T})$ with high probability, and uses $O(\\log\\log T)$ batches, matching the lower bound on the number of batches (Gao et al., 2019). When specialized to linear bandits, our algorithm can achieve a high probability gap-dependent regret bound of $\\tilde{O}(1/\\Delta_{\\min})$ with the optimal $\\log T$ number of batches, where $\\Delta_{\\min}$ is the minimum reward gap between a suboptimal arm and the optimal. Our result is achieved via a novel soft elimination approach, that entails $\\text{``}$shaping$\\text{\"}$ the action sets at each batch so that we can efficiently identify (near) optimal actions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vf77fTbgG3": {
    "title": "Structured Voronoi Sampling",
    "volume": "poster",
    "abstract": "Gradient-based sampling algorithms have demonstrated their effectiveness in text generation, especially in the context of controlled text generation. However, there exists a lack of theoretically grounded and principled approaches for this task. In this paper, we take an important step toward building a principled approach for sampling from language models with gradient-based methods. We use discrete distributions given by language models to define densities and develop an algorithm based on Hamiltonian Monte Carlo to sample from them. We name our gradient-based technique Structured Voronoi Sampling (SVS). In an experimental setup where the reference distribution is known, we show that the empirical distribution of SVS samples is closer to the reference distribution compared to alternative sampling schemes. Furthermore, in a controlled generation task, SVS is able to generate fluent and diverse samples while following the control targets significantly better than other methods",
    "checked": true,
    "id": "b0b293312d0314b56f1e59e00441f3f5873e2389",
    "semantic_title": "structured voronoi sampling",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7zkFc9TGKz": {
    "title": "LD2: Scalable Heterophilous Graph Neural Network with Decoupled Embeddings",
    "volume": "poster",
    "abstract": "Heterophilous Graph Neural Network (GNN) is a family of GNNs that specializes in learning graphs under heterophily, where connected nodes tend to have different labels. Most existing heterophilous models incorporate iterative non-local computations to capture node relationships. However, these approaches have limited application to large-scale graphs due to their high computational costs and challenges in adopting minibatch schemes. In this work, we study the scalability issues of heterophilous GNN and propose a scalable model, LD2, which simplifies the learning process by decoupling graph propagation and generating expressive embeddings prior to training. Theoretical analysis demonstrates that LD2 achieves optimal time complexity in training, as well as a memory footprint that remains independent of the graph scale. We conduct extensive experiments to showcase that our model is capable of lightweight minibatch training on large-scale heterophilous graphs, with up to $15\\times$ speed improvement and efficient memory utilization, while maintaining comparable or better performance than the baselines",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tj86aGVNb3": {
    "title": "Feature learning via mean-field Langevin dynamics: classifying sparse parities and beyond",
    "volume": "poster",
    "abstract": "Neural network in the mean-field regime is known to be capable of \\textit{feature learning}, unlike the kernel (NTK) counterpart. Recent works have shown that mean-field neural networks can be globally optimized by a noisy gradient descent update termed the \\textit{mean-field Langevin dynamics} (MFLD). However, all existing guarantees for MFLD only considered the \\textit{optimization} efficiency, and it is unclear if this algorithm leads to improved \\textit{generalization} performance and sample complexity due to the presence of feature learning. To fill this gap, in this work we study the statistical and computational complexity of MFLD in learning a class of binary classification problems. Unlike existing margin bounds for neural networks, we avoid the typical norm control by utilizing the perspective that MFLD optimizes the \\textit{distribution} of parameters rather than the parameter itself; this leads to an improved analysis of the sample complexity and convergence rate. We apply our general framework to the learning of $k$-sparse parity functions, where we prove that unlike kernel methods, two-layer neural networks optimized by MFLD achieves a sample complexity where the degree $k$ is ``decoupled'' from the exponent in the dimension dependence",
    "checked": false,
    "id": "a3ebed9b1e75a528f8e943275bdb99ffe515ab2c",
    "semantic_title": "optimal mass transport meets thermodynamics: on power and efficiency of finite-time thermodynamic engines",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3CJOaJugMG": {
    "title": "On the Last-iterate Convergence in Time-varying Zero-sum Games: Extra Gradient Succeeds where Optimism Fails",
    "volume": "poster",
    "abstract": "Last-iterate convergence has received extensive study in two player zero-sum games starting from bilinear, convex-concave up to settings that satisfy the MVI condition. Typical methods that exhibit last-iterate convergence for the aforementioned games include extra-gradient (EG) and optimistic gradient descent ascent (OGDA). However, all the established last-iterate convergence results hold for the restrictive setting where the underlying repeated game does not change over time. Recently, a line of research has focused on regret analysis of OGDA in time-varying games, i.e., games where payoffs evolve with time; the last-iterate behavior of OGDA and EG in time-varying environments remains unclear though. In this paper, we study the last-iterate behavior of various algorithms in two types of unconstrained, time-varying, bilinear zero-sum games: periodic and convergent perturbed games. These models expand upon the usual repeated game formulation and incorporate external environmental factors, such as the seasonal effects on species competition and vanishing external noise. In periodic games, we prove that EG will converge while OGDA and momentum method will diverge. This is quite surprising, as to the best of our knowledge, it is the first result that indicates EG and OGDA have qualitatively different last-iterate behaviors and do not exhibit similar behavior. In convergent perturbed games, we prove all these algorithms converge as long as the game itself stabilizes with a faster rate than $1/t$",
    "checked": true,
    "id": "da5bd745f1081690b7863373473f36986b60057c",
    "semantic_title": "on the last-iterate convergence in time-varying zero-sum games: extra gradient succeeds where optimism fails",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WRGldGm5Hz": {
    "title": "DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting",
    "volume": "poster",
    "abstract": "While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for training diffusion models for dynamics forecasting that leverages the temporal dynamics encoded in the data, directly coupling it with the diffusion steps in the network. We train a stochastic, time-conditioned interpolator and a backbone forecaster network that mimic the forward and reverse processes of conventional diffusion models, respectively. This design choice naturally encodes multi-step and long-range forecasting capabilities, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process imposes a strong inductive bias, allowing for improved computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic skill score metrics in complex dynamics forecasting of sea surface temperatures, Navier-Stokes flows, and spring mesh systems",
    "checked": true,
    "id": "195dc158fa820c70f9d9892b7f2a150ca0cfc939",
    "semantic_title": "dyffusion: a dynamics-informed diffusion model for spatiotemporal forecasting",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=GuErIOGLie": {
    "title": "Unified Segment-to-Segment Framework for Simultaneous Sequence Generation",
    "volume": "poster",
    "abstract": "Simultaneous sequence generation is a pivotal task for real-time scenarios, such as streaming speech recognition, simultaneous machine translation and simultaneous speech translation, where the target sequence is generated while receiving the source sequence. The crux of achieving high-quality generation with low latency lies in identifying the optimal moments for generating, accomplished by learning a mapping between the source and target sequences. However, existing methods often rely on task-specific heuristics for different sequence types, limiting the model's capacity to adaptively learn the source-target mapping and hindering the exploration of multi-task learning for various simultaneous tasks. In this paper, we propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation, which learns the mapping in an adaptive and unified manner. During the process of simultaneous generation, the model alternates between waiting for a source segment and generating a target segment, making the segment serve as the natural bridge between the source and target. To accomplish this, Seg2Seg introduces a latent segment as the pivot between source to target and explores all potential source-target mappings via the proposed expectation training, thereby learning the optimal moments for generating. Experiments on multiple simultaneous generation tasks demonstrate that Seg2Seg achieves state-of-the-art performance and exhibits better generality across various tasks",
    "checked": true,
    "id": "6dd1bb6d84c48a9f0066d9a3937fa55153cf6acc",
    "semantic_title": "unified segment-to-segment framework for simultaneous sequence generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lRG11M91dx": {
    "title": "Functional-Group-Based Diffusion for Pocket-Specific Molecule Generation and Elaboration",
    "volume": "poster",
    "abstract": "In recent years, AI-assisted drug design methods have been proposed to generate molecules given the pockets' structures of target proteins. Most of them are {\\em atom-level-based} methods, which consider atoms as basic components and generate atom positions and types. In this way, however, it is hard to generate realistic fragments with complicated structures. To solve this, we propose \\textsc{D3FG}, a {\\em functional-group-based} diffusion model for pocket-specific molecule generation and elaboration. \\textsc{D3FG} decomposes molecules into two categories of components: functional groups defined as rigid bodies and linkers as mass points. And the two kinds of components can together form complicated fragments that enhance ligand-protein interactions. To be specific, in the diffusion process, \\textsc{D3FG} diffuses the data distribution of the positions, orientations, and types of the components into a prior distribution; In the generative process, the noise is gradually removed from the three variables by denoisers parameterized with designed equivariant graph neural networks. In the experiments, our method can generate molecules with more realistic 3D structures, competitive affinities toward the protein targets, and better drug properties. Besides, \\textsc{D3FG} as a solution to a new task of molecule elaboration, could generate molecules with high affinities based on existing ligands and the hotspots of target proteins",
    "checked": true,
    "id": "e499649e26e12971a6d62a23491d64620913af72",
    "semantic_title": "functional-group-based diffusion for pocket-specific molecule generation and elaboration",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=lOCHMGO6ow": {
    "title": "Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models",
    "volume": "poster",
    "abstract": "Despite the remarkable performance of text-to-image diffusion models in image generation tasks, recent studies have raised the issue that generated images sometimes cannot capture the intended semantic contents of the text prompts, which phenomenon is often called semantic misalignment. To address this, here we present a novel energy-based model (EBM) framework for adaptive context control by modeling the posterior of context vectors. Specifically, we first formulate EBMs of latent image representations and text embeddings in each cross-attention layer of the denoising autoencoder. Then, we obtain the gradient of the log posterior of context vectors, which can be updated and transferred to the subsequent cross-attention layer, thereby implicitly minimizing a nested hierarchy of energy functions. Our latent EBMs further allow zero-shot compositional generation as a linear combination of cross-attention outputs from different contexts. Using extensive experiments, we demonstrate that the proposed method is highly effective in handling various image generation tasks, including multi-concept generation, text-guided image inpainting, and real and synthetic image editing. Code: https://github.com/EnergyAttention/Energy-Based-CrossAttention",
    "checked": true,
    "id": "8745157f991013b23fbb79d300ba560f9005c8d4",
    "semantic_title": "energy-based cross attention for bayesian context update in text-to-image diffusion models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bY0c46ZtXa": {
    "title": "Hybrid Search for Efficient Planning with Completeness Guarantees",
    "volume": "poster",
    "abstract": "Solving complex planning problems has been a long-standing challenge in computer science. Learning-based subgoal search methods have shown promise in tackling these problems, but they often suffer from a lack of completeness guarantees, meaning that they may fail to find a solution even if one exists. In this paper, we propose an efficient approach to augment a subgoal search method to achieve completeness in discrete action spaces. Specifically, we augment the high-level search with low-level actions to execute a multi-level (hybrid) search, which we call complete subgoal search. This solution achieves the best of both worlds: the practical efficiency of high-level search and the completeness of low-level search. We apply the proposed search method to a recently proposed subgoal search algorithm and evaluate the algorithm trained on offline data on complex planning problems. We demonstrate that our complete subgoal search not only guarantees completeness but can even improve performance in terms of search expansions for instances that the high-level could solve without low-level augmentations. Our approach makes it possible to apply subgoal-level planning for systems where completeness is a critical requirement",
    "checked": true,
    "id": "707d85c8ec94ced2cccc8cb242868d944f7a5163",
    "semantic_title": "hybrid search for efficient planning with completeness guarantees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N7tw0QXx3z": {
    "title": "SLaM: Student-Label Mixing for Distillation with Unlabeled Examples",
    "volume": "poster",
    "abstract": "Knowledge distillation with unlabeled examples is a powerful training paradigm for generating compact and lightweight student models in applications where the amount of labeled data is limited but one has access to a large pool of unlabeled data. In this setting, a large teacher model generates \"soft\" pseudo-labels for the unlabeled dataset which are then used for training the student model. Despite its success in a wide variety of applications, a shortcoming of this approach is that the teacher's pseudo-labels are often noisy, leading to impaired student performance. In this paper, we present a principled method for knowledge distillation with unlabeled examples that we call Student-Label Mixing (SLaM) and we show that it consistently improves over prior approaches by evaluating it on several standard benchmarks. Finally, we show that SLaM comes with theoretical guarantees; along the way we give an algorithm improving the best-known sample complexity for learning halfspaces with margin under random classification noise, and provide the first convergence analysis for so-called ``forward loss-adjustment\" methods",
    "checked": true,
    "id": "6c2d676c040915a6dab6172c68fb2e8a651c8c11",
    "semantic_title": "slam: student-label mixing for distillation with unlabeled examples",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XfKnoW4Zef": {
    "title": "Towards Robust and Expressive Whole-body Human Pose and Shape Estimation",
    "volume": "poster",
    "abstract": "Whole-body pose and shape estimation aims to jointly predict different behaviors (e.g., pose, hand gesture, facial expression) of the entire human body from a monocular image. Existing methods often exhibit suboptimal performance due to the complexity of in-the-wild scenarios. We argue that the prediction accuracy of these models is significantly affected by the quality of the _bounding box_, e.g., scale, alignment. The natural discrepancy between the ideal bounding box annotations and model detection results is particularly detrimental to the performance of whole-body pose and shape estimation. In this paper, we propose a novel framework to enhance the robustness of whole-body pose and shape estimation. Our framework incorporates three new modules to address the above challenges from three perspectives: (1) a **Localization Module** enhances the model's awareness of the subject's location and semantics within the image space; (2) a **Contrastive Feature Extraction Module** encourages the model to be invariant to robust augmentations by incorporating a contrastive loss and positive samples; (3) a **Pixel Alignment Module** ensures the reprojected mesh from the predicted camera and body model parameters are more accurate and pixel-aligned. We perform comprehensive experiments to demonstrate the effectiveness of our proposed framework on body, hands, face and whole-body benchmarks",
    "checked": false,
    "id": "ffa18932d2b7bb5248bbc9454da54e8d4f5ad514",
    "semantic_title": "kbody: towards general, robust, and aligned monocular whole-body estimation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=TUGoUNkccV": {
    "title": "Correlative Information Maximization: A Biologically Plausible Approach to Supervised Deep Neural Networks without Weight Symmetry",
    "volume": "poster",
    "abstract": "The backpropagation algorithm has experienced remarkable success in training large-scale artificial neural networks; however, its biological plausibility has been strongly criticized, and it remains an open question whether the brain employs supervised learning mechanisms akin to it. Here, we propose correlative information maximization between layer activations as an alternative normative approach to describe the signal propagation in biological neural networks in both forward and backward directions. This new framework addresses many concerns about the biological-plausibility of conventional artificial neural networks and the backpropagation algorithm. The coordinate descent-based optimization of the corresponding objective, combined with the mean square error loss function for fitting labeled supervision data, gives rise to a neural network structure that emulates a more biologically realistic network of multi-compartment pyramidal neurons with dendritic processing and lateral inhibitory neurons. Furthermore, our approach provides a natural resolution to the weight symmetry problem between forward and backward signal propagation paths, a significant critique against the plausibility of the conventional backpropagation algorithm. This is achieved by leveraging two alternative, yet equivalent forms of the correlative mutual information objective. These alternatives intrinsically lead to forward and backward prediction networks without weight symmetry issues, providing a compelling solution to this long-standing challenge",
    "checked": true,
    "id": "3f3458d01f05139a86cc36d1b4954045dfb6c9a5",
    "semantic_title": "correlative information maximization: a biologically plausible approach to supervised deep neural networks without weight symmetry",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6kRQTPEVip": {
    "title": "AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways via Contrastive Learning",
    "volume": "poster",
    "abstract": "Deep learning-based reaction predictors have undergone significant architectural evolution. However, their reliance on reactions from the US Patent Office results in a lack of interpretable predictions and limited generalizability to other chemistry domains, such as radical and atmospheric chemistry. To address these challenges, we introduce a new reaction predictor system, RMechRP, that leverages contrastive learning in conjunction with mechanistic pathways, the most interpretable representation of chemical reactions. Specifically designed for radical reactions, RMechRP provides different levels of interpretation of chemical reactions. We develop and train multiple deep-learning models using RMechDB, a public database of radical reactions, to establish the first benchmark for predicting radical reactions. Our results demonstrate the effectiveness of RMechRP in providing accurate and interpretable predictions of radical reactions, and its potential for various applications in atmospheric chemistry",
    "checked": true,
    "id": "37de2fe0e44dc337332c92dd94b9e70b208126b2",
    "semantic_title": "ai for interpretable chemistry: predicting radical mechanistic pathways via contrastive learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=43ruO2fMjq": {
    "title": "A Unified Framework for U-Net Design and Analysis",
    "volume": "poster",
    "abstract": "U-Nets are a go-to neural architecture across numerous tasks for continuous signals on a square such as images and Partial Differential Equations (PDE), however their design and architecture is understudied. In this paper, we provide a framework for designing and analysing general U-Net architectures. We present theoretical results which characterise the role of the encoder and decoder in a U-Net, their high-resolution scaling limits and their conjugacy to ResNets via preconditioning. We propose Multi-ResNets, U-Nets with a simplified, wavelet-based encoder without learnable parameters. Further, we show how to design novel U-Net architectures which encode function constraints, natural bases, or the geometry of the data. In diffusion models, our framework enables us to identify that high-frequency information is dominated by noise exponentially faster, and show how U-Nets with average pooling exploit this. In our experiments, we demonstrate how Multi-ResNets achieve competitive and often superior performance compared to classical U-Nets in image segmentation, PDE surrogate modelling, and generative modelling with diffusion models. Our U-Net framework paves the way to study the theoretical properties of U-Nets and design natural, scalable neural architectures for a multitude of problems beyond the square",
    "checked": true,
    "id": "36a22d5028424d2429f602e2b92bb299eb639f60",
    "semantic_title": "a unified framework for u-net design and analysis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NLpXRrjpa6": {
    "title": "Policy Gradient for Rectangular Robust Markov Decision Processes",
    "volume": "poster",
    "abstract": "Policy gradient methods have become a standard for training reinforcement learning agents in a scalable and efficient manner. However, they do not account for transition uncertainty, whereas learning robust policies can be computationally expensive. In this paper, we introduce robust policy gradient (RPG), a policy-based method that efficiently solves rectangular robust Markov decision processes (MDPs). We provide a closed-form expression for the worst occupation measure. Incidentally, we find that the worst kernel is a rank-one perturbation of the nominal. Combining the worst occupation measure with a robust Q-value estimation yields an explicit form of the robust gradient. Our resulting RPG can be estimated from data with the same time complexity as its non-robust equivalent. Hence, it relieves the computational burden of convex optimization problems required for training robust policies by current policy gradient approaches",
    "checked": false,
    "id": "1735e8dc1a5ca6363d68649cb84e8cd89e0a4b9a",
    "semantic_title": "policy gradient for s-rectangular robust markov decision processes",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=cUuXVaMmmv": {
    "title": "Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning",
    "volume": "poster",
    "abstract": "Discovering achievements with a hierarchical structure in procedurally generated environments presents a significant challenge. This requires an agent to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods have been built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be advantageous for learning hierarchical dependencies. However, these methods demand an excessive number of environment interactions or large model sizes, limiting their practicality. In this work, we demonstrate that proximal policy optimization (PPO), a simple yet versatile model-free algorithm, outperforms previous methods when optimized with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, albeit with limited confidence. Based on this observation, we introduce a novel contrastive learning method, called achievement distillation, which strengthens the agent's ability to predict the next achievement. Our method exhibits a strong capacity for discovering hierarchical achievements and shows state-of-the-art performance on the challenging Crafter environment in a sample-efficient manner while utilizing fewer model parameters",
    "checked": true,
    "id": "8d481d04c72d884e20bc15de4c8e92b81bece710",
    "semantic_title": "discovering hierarchical achievements in reinforcement learning via contrastive learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GJtP1ZEzua": {
    "title": "D4Explainer: In-distribution Explanations of Graph Neural Network via Discrete Denoising Diffusion",
    "volume": "poster",
    "abstract": "The widespread deployment of Graph Neural Networks (GNNs) sparks significant interest in their explainability, which plays a vital role in model auditing and ensuring trustworthy graph learning. The objective of GNN explainability is to discern the underlying graph structures that have the most significant impact on model predictions. Ensuring that explanations generated are reliable necessitates consideration of the in-distribution property, particularly due to the vulnerability of GNNs to out-of-distribution data. Unfortunately, prevailing explainability methods tend to constrain the generated explanations to the structure of the original graph, thereby downplaying the significance of the in-distribution property and resulting in explanations that lack reliability. To address these challenges, we propose D4Explainer, a novel approach that provides in-distribution GNN explanations for both counterfactual and model-level explanation scenarios. The proposed D4Explainer incorporates generative graph distribution learning into the optimization objective, which accomplishes two goals: 1) generate a collection of diverse counterfactual graphs that conform to the in-distribution property for a given instance, and 2) identify the most discriminative graph patterns that contribute to a specific class prediction, thus serving as model-level explanations. It is worth mentioning that D4Explainer is the first unified framework that combines both counterfactual and model-level explanations. Empirical evaluations conducted on synthetic and real-world datasets provide compelling evidence of the state-of-the-art performance achieved by D4Explainer in terms of explanation accuracy, faithfulness, diversity, and robustness",
    "checked": false,
    "id": "c5df459fd578c019a651583eef95dd512fc8a603",
    "semantic_title": "d4explainer: in-distribution gnn explanations via discrete denoising diffusion",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=exiXmAfuDK": {
    "title": "An Adaptive Algorithm for Learning with Unknown Distribution Drift",
    "volume": "poster",
    "abstract": "We develop and analyze a general technique for learning with an unknown distribution drift. Given a sequence of independent observations from the last $T$ steps of a drifting distribution, our algorithm agnostically learns a family of functions with respect to the current distribution at time $T$. Unlike previous work, our technique does not require prior knowledge about the magnitude of the drift. Instead, the algorithm adapts to the sample data. Without explicitly estimating the drift, the algorithm learns a family of functions with almost the same error as a learning algorithm that knows the magnitude of the drift in advance. Furthermore, since our algorithm adapts to the data, it can guarantee a better learning error than an algorithm that relies on loose bounds on the drift. We demonstrate the application of our technique in two fundamental learning scenarios: binary classification and linear regression",
    "checked": true,
    "id": "2c7f80548ef03ac6b6e1e949acb02c882f8eec98",
    "semantic_title": "an adaptive algorithm for learning with unknown distribution drift",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=PkKpTK7hJ6": {
    "title": "Truncating Trajectories in Monte Carlo Policy Evaluation: an Adaptive Approach",
    "volume": "poster",
    "abstract": "Policy evaluation via Monte Carlo (MC) simulation is at the core of many MC Reinforcement Learning (RL) algorithms (e.g., policy gradient methods). In this context, the designer of the learning system specifies an interaction budget that the agent usually spends by collecting trajectories of *fixed length* within a simulator. However, is this data collection strategy the best option? To answer this question, in this paper, we consider as quality index the variance of an unbiased policy return estimator that uses trajectories of different lengths, i.e., *truncated*. We first derive a closed-form expression of this variance that clearly shows the sub-optimality of the fixed-length trajectory schedule. Furthermore, it suggests that adaptive data collection strategies that spend the available budget sequentially might be able to allocate a larger portion of transitions in timesteps in which more accurate sampling is required to reduce the variance of the final estimate. Building on these findings, we present an *adaptive* algorithm called **R**obust and **I**terative **D**ata collection strategy **O**ptimization (RIDO). The main intuition behind RIDO is to split the available interaction budget into mini-batches. At each round, the agent determines the most convenient schedule of trajectories that minimizes an empirical and robust estimate of the estimator's variance. After discussing the theoretical properties of our method, we conclude by assessing its performance across multiple domains. Our results show that RIDO can adapt its trajectory schedule toward timesteps where more sampling is required to increase the quality of the final estimation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6OOgw4boZI": {
    "title": "TempME: Towards the Explainability of Temporal Graph Neural Networks via Motif Discovery",
    "volume": "poster",
    "abstract": "Temporal graphs are widely used to model dynamic systems with time-varying interactions. In real-world scenarios, the underlying mechanisms of generating future interactions in dynamic systems are typically governed by a set of recurring substructures within the graph, known as temporal motifs. Despite the success and prevalence of current temporal graph neural networks (TGNN), it remains uncertain which temporal motifs are recognized as the significant indications that trigger a certain prediction from the model, which is a critical challenge for advancing the explainability and trustworthiness of current TGNNs. To address this challenge, we propose a novel approach, called **Temp**oral **M**otifs **E**xplainer (**TempME**), which uncovers the most pivotal temporal motifs guiding the prediction of TGNNs. Derived from the information bottleneck principle, TempME extracts the most interaction-related motifs while minimizing the amount of contained information to preserve the sparsity and succinctness of the explanation. Events in the explanations generated by TempME are verified to be more spatiotemporally correlated than those of existing approaches, providing more understandable insights. Extensive experiments validate the superiority of TempME, with up to 8.21% increase in terms of explanation accuracy across six real-world datasets and up to 22.96% increase in boosting the prediction Average Precision of current TGNNs",
    "checked": true,
    "id": "b40863427d4d2f5440ece176f4b8e6cec75b7d6e",
    "semantic_title": "tempme: towards the explainability of temporal graph neural networks via motif discovery",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=08hStXdT1s": {
    "title": "Knowledge Diffusion for Distillation",
    "volume": "poster",
    "abstract": "The representation gap between teacher and student is an emerging topic in knowledge distillation (KD). To reduce the gap and improve the performance, current methods often resort to complicated training schemes, loss functions, and feature alignments, which are task-specific and feature-specific. In this paper, we state that the essence of these methods is to discard the noisy information and distill the valuable information in the feature, and propose a novel KD method dubbed DiffKD, to explicitly denoise and match features using diffusion models. Our approach is based on the observation that student features typically contain more noises than teacher features due to the smaller capacity of student model. To address this, we propose to denoise student features using a diffusion model trained by teacher features. This allows us to perform better distillation between the refined clean feature and teacher feature. Additionally, we introduce a light-weight diffusion model with a linear autoencoder to reduce the computation cost and an adaptive noise matching module to improve the denoising performance. Extensive experiments demonstrate that DiffKD is effective across various types of features and achieves state-of-the-art performance consistently on image classification, object detection, and semantic segmentation tasks. Code is available at https://github.com/hunto/DiffKD",
    "checked": true,
    "id": "ba2e92ad284f944b667ec0f8134846b69f5920e5",
    "semantic_title": "knowledge diffusion for distillation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=yIcCkMUCtL": {
    "title": "Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift",
    "volume": "poster",
    "abstract": "Covariate shift occurs prevalently in practice, where the input distributions of the source and target data are substantially different. Despite its practical importance in various learning problems, most of the existing methods only focus on some specific learning tasks and are not well validated theoretically and numerically. To tackle this problem, we propose a unified analysis of general nonparametric methods in a reproducing kernel Hilbert space (RKHS) under covariate shift. Our theoretical results are established for a general loss belonging to a rich loss function family, which includes many commonly used methods as special cases, such as mean regression, quantile regression, likelihood-based classification, and margin-based classification. Two types of covariate shift problems are the focus of this paper and the sharp convergence rates are established for a general loss function to provide a unified theoretical analysis, which concurs with the optimal results in literature where the squared loss is used. Extensive numerical studies on synthetic and real examples confirm our theoretical findings and further illustrate the effectiveness of our proposed method",
    "checked": true,
    "id": "2eacd1fb6cf395d13b968fc9822ecc49a87fba23",
    "semantic_title": "towards a unified analysis of kernel-based methods under covariate shift",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=o7HckkxOZH": {
    "title": "Regression with Cost-based Rejection",
    "volume": "poster",
    "abstract": "Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method",
    "checked": true,
    "id": "1bec321eefb028ffdd5a8810c443c068c5b78b5b",
    "semantic_title": "regression with cost-based rejection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nBFMCyEi0j": {
    "title": "Predicting Global Label Relationship Matrix for Graph Neural Networks under Heterophily",
    "volume": "poster",
    "abstract": "Graph Neural Networks (GNNs) have been shown to achieve remarkable performance on node classification tasks by exploiting both graph structures and node features. The majority of existing GNNs rely on the implicit homophily assumption. Recent studies have demonstrated that GNNs may struggle to model heterophilous graphs where nodes with different labels are more likely connected. To address this issue, we propose a generic GNN applicable to both homophilous and heterophilous graphs, namely Low-Rank Graph Neural Network (LRGNN). Our analysis demonstrates that a signed graph's global label relationship matrix has a low rank. This insight inspires us to predict the label relationship matrix by solving a robust low-rank matrix approximation problem, as prior research has proven that low-rank approximation could achieve perfect recovery under certain conditions. The experimental results reveal that the solution bears a strong resemblance to the label relationship matrix, presenting two advantages for graph modeling: a block diagonal structure and varying distributions of within-class and between-class entries",
    "checked": false,
    "id": "5af294d2ea7ccddb52ccd3025584a2a1b9b895ea",
    "semantic_title": "revisiting homophily ratio: a relation-aware graph neural network for homophily and heterophily",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Deb1yP1zMN": {
    "title": "Automatic Integration for Spatiotemporal Neural Point Processes",
    "volume": "poster",
    "abstract": "Learning continuous-time point processes is essential to many discrete event forecasting tasks. However, integration poses a major challenge, particularly for spatiotemporal point processes (STPPs), as it involves calculating the likelihood through triple integrals over space and time. Existing methods for integrating STPP either assume a parametric form of the intensity function, which lacks flexibility; or approximating the intensity with Monte Carlo sampling, which introduces numerical errors. Recent work by Omi et al. proposes a dual network approach for efficient integration of flexible intensity function. However, their method only focuses on the 1D temporal point process. In this paper, we introduce a novel paradigm: `Auto-STPP` (Automatic Integration for Spatiotemporal Neural Point Processes) that extends the dual network approach to 3D STPP. While previous work provides a foundation, its direct extension overly restricts the intensity function and leads to computational challenges. In response, we introduce a decomposable parametrization for the integral network using ProdNet. This approach, leveraging the product of simplified univariate graphs, effectively sidesteps the computational complexities inherent in multivariate computational graphs. We prove the consistency of `Auto-STPP` and validate it on synthetic data and benchmark real-world datasets. `Auto-STPP` shows a significant advantage in recovering complex intensity functions from irregular spatiotemporal events, particularly when the intensity is sharply localized. Our code is open-source at https://github.com/Rose-STL-Lab/AutoSTPP",
    "checked": true,
    "id": "1f42deffeb98c8c269a34054a05ae221ec9986c4",
    "semantic_title": "automatic integration for spatiotemporal neural point processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jgIrJeHHlz": {
    "title": "Debiasing Scores and Prompts of 2D Diffusion for View-consistent Text-to-3D Generation",
    "volume": "poster",
    "abstract": "Existing score-distilling text-to-3D generation techniques, despite their considerable promise, often encounter the view inconsistency problem. One of the most notable issues is the Janus problem, where the most canonical view of an object (\\textit{e.g}., face or head) appears in other views. In this work, we explore existing frameworks for score-distilling text-to-3D generation and identify the main causes of the view inconsistency problem---the embedded bias of 2D diffusion models. Based on these findings, we propose two approaches to debias the score-distillation frameworks for view-consistent text-to-3D generation. Our first approach, called score debiasing, involves cutting off the score estimated by 2D diffusion models and gradually increasing the truncation value throughout the optimization process. Our second approach, called prompt debiasing, identifies conflicting words between user prompts and view prompts using a language model, and adjusts the discrepancy between view prompts and the viewing direction of an object. Our experimental results show that our methods improve the realism of the generated 3D objects by significantly reducing artifacts and achieve a good trade-off between faithfulness to the 2D diffusion models and 3D consistency with little overhead. Our project page is available at~\\url{https://susunghong.github.io/Debiased-Score-Distillation-Sampling/}",
    "checked": true,
    "id": "23e806b147afcc44690f0867c0597ebe792378e4",
    "semantic_title": "debiasing scores and prompts of 2d diffusion for view-consistent text-to-3d generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6IhNHKyuJO": {
    "title": "Hierarchical Randomized Smoothing",
    "volume": "poster",
    "abstract": "Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness certificates for discrete and continuous domains. We experimentally demonstrate the importance of hierarchical smoothing in image and node classification, where it yields superior robustness-accuracy trade-offs. Overall, hierarchical smoothing is an important contribution towards models that are both - certifiably robust to perturbations and accurate",
    "checked": true,
    "id": "40e650548978dcde06435aab35e55670ffe44344",
    "semantic_title": "hierarchical randomized smoothing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eTF3VDH2b6": {
    "title": "Direct Training of SNN using Local Zeroth Order Method",
    "volume": "poster",
    "abstract": "Spiking neural networks are becoming increasingly popular for their low energy requirement in real-world tasks with accuracy comparable to traditional ANNs. SNN training algorithms face the loss of gradient information and non-differentiability due to the Heaviside function in minimizing the model loss over model parameters. To circumvent this problem, the surrogate method employs a differentiable approximation of the Heaviside function in the backward pass, while the forward pass continues to use the Heaviside as the spiking function. We propose to use the zeroth-order technique at the local or neuron level in training SNNs, motivated by its regularizing and potential energy-efficient effects and establish a theoretical connection between it and the existing surrogate methods. We perform experimental validation of the technique on standard static datasets (CIFAR-10, CIFAR-100, ImageNet-100) and neuromorphic datasets (DVS-CIFAR-10, DVS-Gesture, N-Caltech-101, NCARS) and obtain results that offer improvement over the state-of-the-art results. The proposed method also lends itself to efficient implementations of the back-propagation method, which could provide 3-4 times overall speedup in training time. The code is available at \\url{https://github.com/BhaskarMukhoty/LocalZO}",
    "checked": false,
    "id": "41ccf8438295b3aa439cf54944ab96d0f7f368e9",
    "semantic_title": "energy efficient training of snn using local zeroth order method",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KoFYzuwjCA": {
    "title": "Disentangling Voice and Content with Self-Supervision for Speaker Recognition",
    "volume": "poster",
    "abstract": "For speaker recognition, it is difficult to extract an accurate speaker representation from speech because of its mixture of speaker traits and content. This paper proposes a disentanglement framework that simultaneously models speaker traits and content variability in speech. It is realized with the use of three Gaussian inference layers, each consisting of a learnable transition model that extracts distinct speech components. Notably, a strengthened transition model is specifically designed to model complex speech dynamics. We also propose a self-supervision method to dynamically disentangle content without the use of labels other than speaker identities. The efficacy of the proposed framework is validated via experiments conducted on the VoxCeleb and SITW datasets with 9.56\\% and 8.24\\% average reductions in EER and minDCF, respectively. Since neither additional model training nor data is specifically needed, it is easily applicable in practical use",
    "checked": true,
    "id": "6bcc1eb830ee1a59e7b9e818091b557826e195f1",
    "semantic_title": "disentangling voice and content with self-supervision for speaker recognition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N5uUTWLz0E": {
    "title": "Understanding and Improving Ensemble Adversarial Defense",
    "volume": "poster",
    "abstract": "The strategy of ensemble has become popular in adversarial defense, which trains multiple base classifiers to defend against adversarial attacks in a cooperative manner. Despite the empirical success, theoretical explanations on why an ensemble of adversarially trained classifiers is more robust than single ones remain unclear. To fill in this gap, we develop a new error theory dedicated to understanding ensemble adversarial defense, demonstrating a provable 0-1 loss reduction on challenging sample sets in adversarial defense scenarios. Guided by this theory, we propose an effective approach to improve ensemble adversarial defense, named interactive global adversarial training (iGAT). The proposal includes (1) a probabilistic distributing rule that selectively allocates to different base classifiers adversarial examples that are globally challenging to the ensemble, and (2) a regularization term to rescue the severest weaknesses of the base classifiers. Being tested over various existing ensemble adversarial defense techniques, iGAT is capable of boosting their performance by up to 17\\% evaluated using CIFAR10 and CIFAR100 datasets under both white-box and black-box attacks",
    "checked": true,
    "id": "59790c35eb5a228f85846728bb1bcd0351c226db",
    "semantic_title": "understanding and improving ensemble adversarial defense",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xs6Xwc0Glj": {
    "title": "Is This Loss Informative? Faster Text-to-Image Customization by Tracking Objective Dynamics",
    "volume": "poster",
    "abstract": "Text-to-image generation models represent the next step of evolution in image synthesis, offering a natural way to achieve flexible yet fine-grained control over the result. One emerging area of research is the fast adaptation of large text-to-image models to smaller datasets or new visual concepts. However, many efficient methods of adaptation have a long training time, which limits their practical applications, slows down experiments, and spends excessive GPU resources. In this work, we study the training dynamics of popular text-to-image personalization methods (such as Textual Inversion or DreamBooth), aiming to speed them up. We observe that most concepts are learned at early stages and do not improve in quality later, but standard training convergence metrics fail to indicate that. Instead, we propose a simple drop-in early stopping criterion that only requires computing the regular training objective on a fixed set of inputs for all training iterations. Our experiments on Stable Diffusion for 48 different concepts and three personalization methods demonstrate the competitive performance of our approach, which makes adaptation up to 8 times faster with no significant drops in quality",
    "checked": true,
    "id": "3821c2d78758084cfbdd5071e7d6d31a151c10e8",
    "semantic_title": "is this loss informative? faster text-to-image customization by tracking objective dynamics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nF6X3u0FaA": {
    "title": "Contrastive Training of Complex-Valued Autoencoders for Object Discovery",
    "volume": "poster",
    "abstract": "Current state-of-the-art object-centric models use slots and attention-based routing for binding. However, this class of models has several conceptual limitations: the number of slots is hardwired; all slots have equal capacity; training has high computational cost; there are no object-level relational factors within slots. Synchrony-based models in principle can address these limitations by using complex-valued activations which store binding information in their phase components. However, working examples of such synchrony-based models have been developed only very recently, and are still limited to toy grayscale datasets and simultaneous storage of less than three objects in practice. Here we introduce architectural modifications and a novel contrastive learning method that greatly improve the state-of-the-art synchrony-based model. For the first time, we obtain a class of synchrony-based models capable of discovering objects in an unsupervised manner in multi-object color datasets and simultaneously representing more than three objects",
    "checked": true,
    "id": "fd7d2e45ff8bad1518c0ac307efc3a5f1db1cb75",
    "semantic_title": "contrastive training of complex-valued autoencoders for object discovery",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=cAaTbLa3ad": {
    "title": "Estimating the Rate-Distortion Function by Wasserstein Gradient Descent",
    "volume": "poster",
    "abstract": "In the theory of lossy compression, the rate-distortion (R-D) function $R(D)$ describes how much a data source can be compressed (in bit-rate) at any given level of fidelity (distortion). Obtaining $R(D)$ for a given data source establishes the fundamental performance limit for all compression algorithms. We propose a new method to estimate $R(D)$ from the perspective of optimal transport. Unlike the classic Blahut--Arimoto algorithm which fixes the support of the reproduction distribution in advance, our Wasserstein gradient descent algorithm learns the support of the optimal reproduction distribution by moving particles. We prove its local convergence and analyze the sample complexity of our R-D estimator based on a connection to entropic optimal transport. Experimentally, we obtain comparable or tighter bounds than state-of-the-art neural network methods on low-rate sources while requiring considerably less tuning and computation effort. We also highlight a connection to maximum-likelihood deconvolution and introduce a new class of sources that can be used as test cases with known solutions to the R-D problem",
    "checked": true,
    "id": "25ee53d80c48e56bdab4a4f4989f0772d931b09b",
    "semantic_title": "estimating the rate-distortion function by wasserstein gradient descent",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qPUbKxKvXq": {
    "title": "Monitor-Guided Decoding of Code LMs with Static Analysis of Repository Context",
    "volume": "poster",
    "abstract": "Language models of code (LMs) work well when the surrounding code provides sufficient context. This is not true when it becomes necessary to use types, functionality or APIs defined elsewhere in the repository or a linked library, especially those not seen during training. LMs suffer from limited awareness of such global context and end up hallucinating. Integrated development environments (IDEs) assist developers in understanding repository context using static analysis. We extend this assistance, enjoyed by developers, to LMs. We propose monitor-guided decoding (MGD) where a monitor uses static analysis to guide the decoding. We construct a repository-level dataset PragmaticCode for method-completion in Java and evaluate MGD on it. On models of varying parameter scale, by monitoring for type-consistent object dereferences, MGD consistently improves compilation rates and agreement with ground truth. Further, LMs with fewer parameters, when augmented with MGD, can outperform larger LMs. With MGD, SantaCoder-1.1B achieves better compilation rate and next-identifier match than the much larger text-davinci-003 model. We also conduct a generalizability study to evaluate the ability of MGD to generalize to multiple programming languages (Java, C# and Rust), coding scenarios (e.g., correct number of arguments to method calls), and to enforce richer semantic constraints (e.g., stateful API protocols). Our data and implementation are available at https://github.com/microsoft/monitors4codegen",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eP6cDDwBNC": {
    "title": "TRIAGE: Characterizing and auditing training data for improved regression",
    "volume": "poster",
    "abstract": "Data quality is crucial for robust machine learning algorithms, with the recent interest in data-centric AI emphasizing the importance of training data characterization. However, current data characterization methods are largely focused on classification settings, with regression settings largely understudied. To address this, we introduce TRIAGE, a novel data characterization framework tailored to regression tasks and compatible with a broad class of regressors. TRIAGE utilizes conformal predictive distributions to provide a model-agnostic scoring method, the TRIAGE score. We operationalize the score to analyze individual samples' training dynamics and characterize samples as under-, over-, or well-estimated by the model. We show that TRIAGE's characterization is consistent and highlight its utility to improve performance via data sculpting/filtering, in multiple regression settings. Additionally, beyond sample level, we show TRIAGE enables new approaches to dataset selection and feature acquisition. Overall, TRIAGE highlights the value unlocked by data characterization in real-world regression applications",
    "checked": true,
    "id": "fd9901038e32a2d561e26ee2e6268b66e9c4a090",
    "semantic_title": "triage: characterizing and auditing training data for improved regression",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=M4h1UAxI3b": {
    "title": "H-nobs: Achieving Certified Fairness and Robustness in Distributed Learning on Heterogeneous Datasets",
    "volume": "poster",
    "abstract": "Fairness and robustness are two important goals in the design of modern distributed learning systems. Despite a few prior works attempting to achieve both fairness and robustness, some key aspects of this direction remain underexplored. In this paper, we try to answer three largely unnoticed and unaddressed questions that are of paramount significance to this topic: (i) What makes jointly satisfying fairness and robustness difficult? (ii) Is it possible to establish theoretical guarantee for the dual property of fairness and robustness? (iii) How much does fairness have to sacrifice at the expense of robustness being incorporated into the system? To address these questions, we first identify data heterogeneity as the key difficulty of combining fairness and robustness. Accordingly, we propose a fair and robust framework called H-nobs which can offer certified fairness and robustness through the adoption of two key components, a fairness-promoting objective function and a simple robust aggregation scheme called norm-based screening (NBS). We explain in detail why NBS is the suitable scheme in our algorithm in contrast to other robust aggregation measures. In addition, we derive three convergence theorems for H-nobs in cases of the learning model being nonconvex, convex, and strongly convex respectively, which provide theoretical guarantees for both fairness and robustness. Further, we empirically investigate the influence of the robust mechanism (NBS) on the fairness performance of H-nobs, the very first attempt of such exploration",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pk49a9snPe": {
    "title": "ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields",
    "volume": "poster",
    "abstract": "We introduce ViCA-NeRF, a view-consistency-aware method for 3D editing with text instructions. In addition to the implicit NeRF modeling, our key insight is to exploit two sources of regularization that {\\em explicitly} propagate the editing information across different views, thus ensuring multi-view consistency. As {\\em geometric regularization}, we leverage the depth information derived from the NeRF model to establish image correspondence between different views. As {\\em learned regularization}, we align the latent codes in the 2D diffusion model between edited and unedited images, enabling us to edit key views and propagate the update to the whole scene. Incorporating these two regularizations, our ViCA-NeRF framework consists of two stages. In the initial stage, we blend edits from different views to create a preliminary 3D edit. This is followed by a second stage of NeRF training that is dedicated to further refining the scene's appearance. Experiments demonstrate that ViCA-NeRF provides more flexible, efficient editing with higher levels of consistency and details, compared with the state of the art",
    "checked": false,
    "id": "89f34202280da149f34afdd31ec58871cab6cab7",
    "semantic_title": "palettenerf: palette-based appearance editing of neural radiance fields",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=bPJmu1PbZD": {
    "title": "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
    "volume": "poster",
    "abstract": "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o4RtDFMSNL": {
    "title": "Causal de Finetti: On the Identification of Invariant Causal Structure in Exchangeable Data",
    "volume": "poster",
    "abstract": "Constraint-based causal discovery methods leverage conditional independence tests to infer causal relationships in a wide variety of applications. Just as the majority of machine learning methods, existing work focuses on studying $\\textit{independent and identically distributed}$ data. However, it is known that even with infinite $i.i.d.\\$ data, constraint-based methods can only identify causal structures up to broad Markov equivalence classes, posing a fundamental limitation for causal discovery. In this work, we observe that exchangeable data contains richer conditional independence structure than $i.i.d.\\$ data, and show how the richer structure can be leveraged for causal discovery. We first present causal de Finetti theorems, which state that exchangeable distributions with certain non-trivial conditional independences can always be represented as $\\textit{independent causal mechanism (ICM)}$ generative processes. We then present our main identifiability theorem, which shows that given data from an ICM generative process, its unique causal structure can be identified through performing conditional independence tests. We finally develop a causal discovery algorithm and demonstrate its applicability to inferring causal relationships from multi-environment data",
    "checked": true,
    "id": "ce93b38e44d2ec97682b583fb141bf3a9c57a587",
    "semantic_title": "causal de finetti: on the identification of invariant causal structure in exchangeable data",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=QNUs3Ramad": {
    "title": "Adversarial Self-Training Improves Robustness and Generalization for Gradual Domain Adaptation",
    "volume": "poster",
    "abstract": "Gradual Domain Adaptation (GDA), in which the learner is provided with additional intermediate domains, has been theoretically and empirically studied in many contexts. Despite its vital role in security-critical scenarios, the adversarial robustness of the GDA model remains unexplored. In this paper, we adopt the effective gradual self-training method and replace vanilla self-training with adversarial self-training (AST). AST first predicts labels on the unlabeled data and then adversarially trains the model on the pseudo-labeled distribution. Intriguingly, we find that gradual AST improves not only adversarial accuracy but also clean accuracy on the target domain. We reveal that this is because adversarial training (AT) performs better than standard training when the pseudo-labels contain a portion of incorrect labels. Accordingly, we first present the generalization error bounds for gradual AST in a multiclass classification setting. We then use the optimal value of the Subset Sum Problem to bridge the standard error on a real distribution and the adversarial error on a pseudo-labeled distribution. The result indicates that AT may obtain a tighter bound than standard training on data with incorrect pseudo-labels. We further present an example of a conditional Gaussian distribution to provide more insights into why gradual AST can improve the clean accuracy for GDA",
    "checked": false,
    "id": "2314a9c503d2c4fd8d8b555dc7d7730f7399b3a8",
    "semantic_title": "robust source-free domain adaptation for fundus image segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j9wGUcS30B": {
    "title": "On Masked Pre-training and the Marginal Likelihood",
    "volume": "poster",
    "abstract": "Masked pre-training removes random input dimensions and learns a model that can predict the missing values. Empirical results indicate that this intuitive form of self-supervised learning yields models that generalize very well to new domains. A theoretical understanding is, however, lacking. This paper shows that masked pre-training with a suitable cumulative scoring function corresponds to maximizing the model's marginal likelihood, which is de facto the Bayesian model selection measure of generalization. Beyond shedding light on the success of masked pre-training, this insight also suggests that Bayesian models can be trained with appropriately designed self-supervision. Empirically, we confirm the developed theory and explore the main learning principles of masked pre-training in large language models",
    "checked": true,
    "id": "2c600b2829a608ce366614dc4911ef672f2e4255",
    "semantic_title": "on masked pre-training and the marginal likelihood",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PnJaA0A8Lr": {
    "title": "Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory",
    "volume": "poster",
    "abstract": "Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe the Edge of Stability (EoS) phenomenon. The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \\text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature",
    "checked": true,
    "id": "31a310772a0ce58692f0dcce9a0a972262bf95f3",
    "semantic_title": "trajectory alignment: understanding the edge of stability phenomenon via bifurcation theory",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=SQouRKRIXY": {
    "title": "MomentDiff: Generative Video Moment Retrieval from Random to Real",
    "volume": "poster",
    "abstract": "Video moment retrieval pursues an efficient and generalized solution to identify the specific temporal segments within an untrimmed video that correspond to a given language description. To achieve this goal, we provide a generative diffusion-based framework called MomentDiff, which simulates a typical human retrieval process from random browsing to gradual localization. Specifically, we first diffuse the real span to random noise, and learn to denoise the random noise to the original span with the guidance of similarity between text and video. This allows the model to learn a mapping from arbitrary random locations to real moments, enabling the ability to locate segments from random initialization. Once trained, MomentDiff could sample random temporal segments as initial guesses and iteratively refine them to generate an accurate temporal boundary. Different from discriminative works (e.g., based on learnable proposals or queries), MomentDiff with random initialized spans could resist the temporal location biases from datasets. To evaluate the influence of the temporal location biases, we propose two ``anti-bias'' datasets with location distribution shifts, named Charades-STA-Len and Charades-STA-Mom. The experimental results demonstrate that our efficient framework consistently outperforms state-of-the-art methods on three public benchmarks, and exhibits better generalization and robustness on the proposed anti-bias datasets. The code, model, and anti-bias evaluation datasets will be released publicly",
    "checked": true,
    "id": "276d80c7bb09d32e364e633ed5b49ac26c191842",
    "semantic_title": "momentdiff: generative video moment retrieval from random to real",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=D1sECc9fiG": {
    "title": "Temporal Dynamic Quantization for Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion model has gained popularity in vision applications due to its remarkable generative performance and versatility. However, its high storage and computation demands, resulting from the model size and iterative generation, hinder its use on mobile devices. Existing quantization techniques struggle to maintain performance even in 8-bit precision due to the diffusion model's unique property of temporal variation in activation. We introduce a novel quantization method that dynamically adjusts the quantization interval based on time step information, significantly improving output quality. Unlike conventional dynamic quantization techniques, our approach has no computational overhead during inference and is compatible with both post-training quantization (PTQ) and quantization-aware training (QAT). Our extensive experiments demonstrate substantial improvements in output quality with the quantized model across various configurations",
    "checked": true,
    "id": "9eccc707103ccd8039b5e360c58c836a394da920",
    "semantic_title": "temporal dynamic quantization for diffusion models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=psXVkKO9No": {
    "title": "Self-Predictive Universal AI",
    "volume": "poster",
    "abstract": "Reinforcement Learning (RL) algorithms typically utilize learning and/or planning techniques to derive effective policies. The integration of both approaches has proven to be highly successful in addressing complex sequential decision-making challenges, as evidenced by algorithms such as AlphaZero and MuZero, which consolidate the planning process into a parametric search-policy. AIXI, the most potent theoretical universal agent, leverages planning through comprehensive search as its primary means to find an optimal policy. Here we define an alternative universal agent, which we call Self-AIXI, that on the contrary to AIXI, maximally exploits learning to obtain good policies. It does so by self-predicting its own stream of action data, which is generated, similarly to other TD(0) agents, by taking an action maximization step over the current on-policy (universal mixture-policy) Q-value estimates. We prove that Self-AIXI converges to AIXI, and inherits a series of properties like maximal Legg-Hutter intelligence and the self-optimizing property",
    "checked": false,
    "id": "7563420be8dd775423f170d2f86ddc69135161ea",
    "semantic_title": "small-molecule autocatalytic networks are universal metabolic fossils",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=PnWakgg1RL": {
    "title": "FABind: Fast and Accurate Protein-Ligand Binding",
    "volume": "poster",
    "abstract": "Modeling the interaction between proteins and ligands and accurately predicting their binding structures is a critical yet challenging task in drug discovery. Recent advancements in deep learning have shown promise in addressing this challenge, with sampling-based and regression-based methods emerging as two prominent approaches. However, these methods have notable limitations. Sampling-based methods often suffer from low efficiency due to the need for generating multiple candidate structures for selection. On the other hand, regression-based methods offer fast predictions but may experience decreased accuracy. Additionally, the variation in protein sizes often requires external modules for selecting suitable binding pockets, further impacting efficiency. In this work, we propose FABind, an end-to-end model that combines pocket prediction and docking to achieve accurate and fast protein-ligand binding. FABind incorporates a unique ligand-informed pocket prediction module, which is also leveraged for docking pose estimation. The model further enhances the docking process by incrementally integrating the predicted pocket to optimize protein-ligand binding, reducing discrepancies between training and inference. Through extensive experiments on benchmark datasets, our proposed FABind demonstrates strong advantages in terms of effectiveness and efficiency compared to existing methods. Our code is available at https://github.com/QizhiPei/FABind",
    "checked": true,
    "id": "ef5fceee2925cb8441bf1de100b67a33eeeef3a3",
    "semantic_title": "fabind: fast and accurate protein-ligand binding",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NTSbj2otOA": {
    "title": "First- and Second-Order Bounds for Adversarial Linear Contextual Bandits",
    "volume": "poster",
    "abstract": "We consider the adversarial linear contextual bandit setting, which allows for the loss functions associated with each of $K$ arms to change over time without restriction. Assuming the $d$-dimensional contexts are drawn from a fixed known distribution, the worst-case expected regret over the course of $T$ rounds is known to scale as $\\tilde O(\\sqrt{Kd T})$. Under the additional assumption that the density of the contexts is log-concave, we obtain a second-order bound of order $\\tilde O(K\\sqrt{d V_T})$ in terms of the cumulative second moment of the learner's losses $V_T$, and a closely related first-order bound of order $\\tilde O(K\\sqrt{d L_T^*})$ in terms of the cumulative loss of the best policy $L_T^*$. Since $V_T$ or $L_T^*$ may be significantly smaller than $T$, these improve over the worst-case regret whenever the environment is relatively benign. Our results are obtained using a truncated version of the continuous exponential weights algorithm over the probability simplex, which we analyse by exploiting a novel connection to the linear bandit setting without contexts",
    "checked": true,
    "id": "efee4e416d955a01ffcbf6cde8b276c2fe1d9a0e",
    "semantic_title": "first- and second-order bounds for adversarial linear contextual bandits",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bETvUctiTR": {
    "title": "Differentiable Neuro-Symbolic Reasoning on Large-Scale Knowledge Graphs",
    "volume": "poster",
    "abstract": "Knowledge graph (KG) reasoning utilizes two primary techniques, i.e., rule-based and KG-embedding based. The former provides precise inferences, but inferring via concrete rules is not scalable. The latter enables efficient reasoning at the cost of ambiguous inference accuracy. Neuro-symbolic reasoning seeks to amalgamate the advantages of both techniques. The crux of this approach is replacing the predicted existence of all possible triples (i.e., truth scores inferred from rules) with a suitable approximation grounded in embedding representations. However, constructing an effective approximation of all possible triples' truth scores is a challenging task, because it needs to balance the tradeoff between accuracy and efficiency, while compatible with both the rule-based and KG-embedding models. To this end, we proposed a differentiable framework - DiffLogic. Instead of directly approximating all possible triples, we design a tailored filter to adaptively select essential triples based on the dynamic rules and weights. The truth scores assessed by KG-embedding are continuous, so we employ a continuous Markov logic network named probabilistic soft logic (PSL). It employs the truth scores of essential triples to assess the overall agreement among rules, weights, and observed triples. PSL enables end-to-end differentiable optimization, so we can alternately update embedding and weighted rules. On benchmark datasets, we empirically show that DiffLogic surpasses baselines in both effectiveness and efficiency",
    "checked": false,
    "id": "81e51c5d677338208f94f19488d86e6658f927af",
    "semantic_title": "lprules: rule induction in knowledge graphs using linear programming",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=HUuEMMM8Ik": {
    "title": "Detecting hidden confounding in observational data using multiple environments",
    "volume": "poster",
    "abstract": "A common assumption in causal inference from observational data is that there is no hidden confounding. Yet it is, in general, impossible to verify the presence of hidden confounding factors from a single dataset. Under the assumption of independent causal mechanisms underlying the data-generating process, we demonstrate a way to detect unobserved confounders when having multiple observational datasets coming from different environments. We present a theory for testable conditional independencies that are only absent when there is hidden confounding and examine cases where we violate its assumptions: degenerate & dependent mechanisms, and faithfulness violations. Additionally, we propose a procedure to test these independencies and study its empirical finite-sample behavior using simulation studies and semi-synthetic data based on a real-world dataset. In most cases, the proposed procedure correctly predicts the presence of hidden confounding, particularly when the confounding bias is large",
    "checked": true,
    "id": "8bbfa9baae47e559a8ae5f2e0e708c40bfa3ffdd",
    "semantic_title": "detecting hidden confounding in observational data using multiple environments",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eeeqORvJbf": {
    "title": "Learning and processing the ordinal information of temporal sequences in recurrent neural circuits",
    "volume": "poster",
    "abstract": "Temporal sequence processing is fundamental in brain cognitive functions. Experimental data has indicated that the representations of ordinal information and contents of temporal sequences are disentangled in the brain, but the neural mechanism underlying this disentanglement remains largely unclear. Here, we investigate how recurrent neural circuits learn to represent the abstract order structure of temporal sequences, and how this disentangled representation of order structure from that of contents facilitates the processing of temporal sequences. We show that with an appropriate learn protocol, a recurrent neural circuit can learn a set of tree-structured attractor states to encode the corresponding tree-structured orders of given temporal sequences. This abstract temporal order template can then be bound with different contents, allowing for flexible and robust temporal sequence processing. Using a transfer learning task, we demonstrate that the reuse of a temporal order template facilitates the acquisition of new temporal sequences of the same or similar ordinal structure. Using a key-word spotting task, we demonstrate that the attractor representation of order structure improves the robustness of temporal sequence discrimination, if the ordinal information is the key to differentiate different sequences. We hope this study gives us insights into the neural mechanism of representing the ordinal information of temporal sequences in the brain, and helps us to develop brain-inspired temporal sequence processing algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CFhpBJ8eZ5": {
    "title": "Dual Mean-Teacher: An Unbiased Semi-Supervised Framework for Audio-Visual Source Localization",
    "volume": "poster",
    "abstract": "Audio-Visual Source Localization (AVSL) aims to locate sounding objects within video frames given the paired audio clips. Existing methods predominantly rely on self-supervised contrastive learning of audio-visual correspondence. Without any bounding-box annotations, they struggle to achieve precise localization, especially for small objects, and suffer from blurry boundaries and false positives. Moreover, the naive semi-supervised method is poor in effectively utilizing the abundance of unlabeled audio-visual pairs. In this paper, we propose a novel Semi-Supervised Learning framework for AVSL, namely Dual Mean-Teacher (DMT), comprising two teacher-student structures to circumvent the confirmation bias issue. Specifically, two teachers, pre-trained on limited labeled data, are employed to filter out noisy samples via the consensus between their predictions, and then generate high-quality pseudo-labels by intersecting their confidence maps. The optimal utilization of both labeled and unlabeled data combined with this unbiased framework enable DMT to outperform current state-of-the-art methods by a large margin, with CIoU of $\\textbf{90.4\\%}$ and $\\textbf{48.8\\%}$ on Flickr-SoundNet and VGG-Sound Source, obtaining $\\textbf{8.9\\%}$ and $\\textbf{9.6\\%}$ improvements respectively, given only $3\\%$ of data positional-annotated. We also extend our framework to some existing AVSL methods and consistently boost their performance. Our code is publicly available at https://github.com/gyx-gloria/DMT",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CtXXOaxDw7": {
    "title": "V-InFoR: A Robust Graph Neural Networks Explainer for Structurally Corrupted Graphs",
    "volume": "poster",
    "abstract": "GNN explanation method aims to identify an explanatory subgraph which contains the most informative components of the full graph. However, a major limitation of existing GNN explainers is that they are not robust to the structurally corrupted graphs, e.g., graphs with noisy or adversarial edges. On the one hand, existing GNN explainers mostly explore explanations based on either the raw graph features or the learned latent representations, both of which can be easily corrupted. On the other hand, the corruptions in graphs are irregular in terms of the structural properties, e.g., the size or connectivity of graphs, which makes the rigorous constraints used by previous GNN explainers unfeasible. To address these issues, we propose a robust GNN explainer called V-InfoR. Specifically, a robust graph representation extractor, which takes insights of variational inference, is proposed to infer the latent distribution of graph representations. Instead of directly using the corrupted raw features or representations of each single graph, we sample the graph representations from the inferred distribution for the downstream explanation generator, which can effectively eliminate the minor corruption. We next formulate the explanation exploration as a graph information bottleneck (GIB) optimization problem. As a more general method that does not need any rigorous structural constraints, our GIB-based method can adaptively capture both the regularity and irregularity of the severely corrupted graphs for explanation. Extensive evaluations on both synthetic and real-world datasets indicate that V-InfoR significantly improves the GNN explanation performance for the structurally corrupted graphs. Code and dataset are available at https://anonymous.4open.science/r/V-InfoR-EF88",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fljrZsJ2I8": {
    "title": "Prototypical Variational Autoencoder for 3D Few-shot Object Detection",
    "volume": "poster",
    "abstract": "Few-Shot 3D Point Cloud Object Detection (FS3D) is a challenging task, aiming to detect 3D objects of novel classes using only limited annotated samples for training. Considering that the detection performance highly relies on the quality of the latent features, we design a VAE-based prototype learning scheme, named prototypical VAE (P-VAE), to learn a probabilistic latent space for enhancing the diversity and distinctiveness of the sampled features. The network encodes a multi-center GMM-like posterior, in which each distribution centers at a prototype. For regularization, P-VAE incorporates a reconstruction task to preserve geometric information. To adopt P-VAE for the detection framework, we formulate Geometric-informative Prototypical VAE (GP-VAE) to handle varying geometric components and Class-specific Prototypical VAE (CP-VAE) to handle varying object categories. In the first stage, we harness GP-VAE to aid feature extraction from the input scene. In the second stage, we cluster the geometric-informative features into per-instance features and use CP-VAE to refine each instance feature with category-level guidance. Experimental results show the top performance of our approach over the state of the arts on two FS3D benchmarks. Quantitative ablations and qualitative prototype analysis further demonstrate that our probabilistic modeling can significantly boost prototype learning for FS3D",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YEtstXIpP3": {
    "title": "Model-Free Active Exploration in Reinforcement Learning",
    "volume": "poster",
    "abstract": "We study the problem of exploration in Reinforcement Learning and present a novel model-free solution. We adopt an information-theoretical viewpoint and start from the instance-specific lower bound of the number of samples that have to be collected to identify a nearly-optimal policy. Deriving this lower bound along with the optimal exploration strategy entails solving an intricate optimization problem and requires a model of the system. In turn, most existing sample optimal exploration algorithms rely on estimating the model. We derive an approximation of the instance-specific lower bound that only involves quantities that can be inferred using model-free approaches. Leveraging this approximation, we devise an ensemble-based model-free exploration strategy applicable to both tabular and continuous Markov decision processes. Numerical results demonstrate that our strategy is able to identify efficient policies faster than state-of-the-art exploration approaches",
    "checked": false,
    "id": "3e91fd5c878b59eafea9c537f641ca045481a8f4",
    "semantic_title": "active exploration for inverse reinforcement learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=DKHEkP7Idx": {
    "title": "Optimal Convergence Rate for Exact Policy Mirror Descent in Discounted Markov Decision Processes",
    "volume": "poster",
    "abstract": "Policy Mirror Descent (PMD) is a general family of algorithms that covers a wide range of novel and fundamental methods in reinforcement learning. Motivated by the instability of policy iteration (PI) with inexact policy evaluation, unregularised PMD algorithmically regularises the policy improvement step of PI without regularising the objective function. With exact policy evaluation, PI is known to converge linearly with a rate given by the discount factor $\\gamma$ of a Markov Decision Process. In this work, we bridge the gap between PI and PMD with exact policy evaluation and show that the dimension-free $\\gamma$-rate of PI can be achieved by the general family of unregularised PMD algorithms under an adaptive step-size. We show that both the rate and step-size are unimprovable for PMD: we provide matching lower bounds that demonstrate that the $\\gamma$-rate is optimal for PMD methods as well as PI and that the adaptive step-size is necessary to achieve it. Our work is the first to relate PMD to rate-optimality and step-size necessity. Our study of the convergence of PMD avoids the use of the performance difference lemma, which leads to a direct analysis of independent interest. We also extend the analysis to the inexact setting and establish the first dimension-optimal sample complexity for unregularised PMD under a generative model, improving upon the best-known result",
    "checked": true,
    "id": "bf2c42468e601540553520921f772008bddc90df",
    "semantic_title": "optimal convergence rate for exact policy mirror descent in discounted markov decision processes",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=enfx8HM4Rp": {
    "title": "Train Once and Explain Everywhere: Pre-training Interpretable Graph Neural Networks",
    "volume": "poster",
    "abstract": "Intrinsic interpretable graph neural networks aim to provide transparent predictions by identifying the influential fraction of the input graph that guides the model prediction, i.e., the explanatory subgraph. However, current interpretable GNNs mostly are dataset-specific and hard to generalize to different graphs. A more generalizable GNN interpretation model which can effectively distill the universal structural patterns of different graphs is until-now unexplored. Motivated by the great success of recent pre-training techniques, we for the first time propose the Pre-training Interpretable Graph Neural Network ($\\pi$-GNN) to distill the universal interpretability of GNNs by pre-training over synthetic graphs with ground-truth explanations. Specifically, we introduce a structural pattern learning module to extract diverse universal structure patterns and integrate them together to comprehensively represent the graphs of different types. Next, a hypergraph refining module is proposed to identify the explanatory subgraph by incorporating the universal structure patterns with local edge interactions. Finally, the task-specific predictor is cascaded with the pre-trained $\\pi$-GNN model and fine-tuned over downstream tasks. Extensive experiments demonstrate that $\\pi$-GNN significantly surpasses the leading interpretable GNN baselines with up to 9.98\\% interpretation improvement and 16.06\\% classification accuracy improvement. Meanwhile, $\\pi$-GNN pre-trained on graph classification task also achieves the top-tier interpretation performance on node classification task, which further verifies its promising generalization performance among different downstream tasks. Our code and datasets are available at https://anonymous.4open.science/r/PI-GNN-F86C",
    "checked": false,
    "id": "f726f137c73bf173357b3b6cdb10e57658829e06",
    "semantic_title": "asdexplainer : an interpretable graph neural network framework for brain network based autism spectrum disorder analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uRewSnLJAa": {
    "title": "Self-Supervised Reinforcement Learning that Transfers using Random Features",
    "volume": "poster",
    "abstract": "Model-free reinforcement learning algorithms have exhibited great potential in solving single-task sequential decision-making problems with high-dimensional observations and long horizons, but are known to be hard to generalize across tasks. Model-based RL, on the other hand, learns task-agnostic models of the world that naturally enables transfer across different reward functions, but struggles to scale to complex environments due to the compounding error. To get the best of both worlds, we propose a self-supervised reinforcement learning method that enables the transfer of behaviors across tasks with different rewards, while circumventing the challenges of model-based RL. In particular, we show self-supervised pre-training of model-free reinforcement learning with a number of random features as rewards allows implicit modeling of long-horizon environment dynamics. Then, planning techniques like model-predictive control using these implicit models enable fast adaptation to problems with new reward functions. Our method is self-supervised in that it can be trained on offline datasets without reward labels, but can then be quickly deployed on new tasks. We validate that our proposed method enables transfer across tasks on a variety of manipulation and locomotion domains in simulation, opening the door to generalist decision-making agents",
    "checked": true,
    "id": "e325dd94c54ce753534fd2571cf89cff129e32f1",
    "semantic_title": "self-supervised reinforcement learning that transfers using random features",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GAsRl2ElHk": {
    "title": "KAKURENBO: Adaptively Hiding Samples in Deep Neural Network Training",
    "volume": "poster",
    "abstract": "This paper proposes a method for hiding the least-important samples during the training of deep neural networks to increase efficiency, i.e., to reduce the cost of training. Using information about the loss and prediction confidence during training, we adaptively find samples to exclude in a given epoch based on their contribution to the overall learning process, without significantly degrading accuracy. We explore the converge properties when accounting for the reduction in the number of SGD updates. Empirical results on various large-scale datasets and models used directly in image classification and segmentation show that while the with-replacement importance sampling algorithm performs poorly on large datasets, our method can reduce total training time by up to 22\\% impacting accuracy only by 0.4\\% compared to the baseline",
    "checked": true,
    "id": "0e7e5d8dcfb83a8ff5f041aaea6f48c2b73a74b9",
    "semantic_title": "kakurenbo: adaptively hiding samples in deep neural network training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f6a9XVFYIo": {
    "title": "SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose SA-Solver, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that SA-Solver achieves: 1) improved or comparable performance compared with the existing state-of-the-art (SOTA) sampling methods for few-step sampling; 2) SOTA FID on substantial benchmark datasets under a suitable number of function evaluations (NFEs)",
    "checked": true,
    "id": "22ee3aab390c3adeb8cf08eacf079e9445e222da",
    "semantic_title": "sa-solver: stochastic adams solver for fast sampling of diffusion models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=OveBaTtUAT": {
    "title": "Towards Unbounded Machine Unlearning",
    "volume": "poster",
    "abstract": "Deep machine unlearning is the problem of 'removing' from a trained neural network a subset of its training set. This problem is very timely and has many applications, including the key tasks of removing biases (RB), resolving confusion (RC) (caused by mislabelled data in trained models), as well as allowing users to exercise their 'right to be forgotten' to protect User Privacy (UP). This paper is the first, to our knowledge, to study unlearning for different applications (RB, RC, UP), with the view that each has its own desiderata, definitions for 'forgetting' and associated metrics for forget quality. For UP, we propose a novel adaptation of a strong Membership Inference Attack for unlearning. We also propose SCRUB, a novel unlearning algorithm, which is the only method that is consistently a top performer for forget quality across the different application-dependent metrics for RB, RC, and UP. At the same time, SCRUB is also consistently a top performer on metrics that measure model utility (i.e. accuracy on retained data and generalization), and is more efficient than previous work. The above are substantiated through a comprehensive empirical evaluation against previous state-of-the-art",
    "checked": true,
    "id": "570a341a8fd511cf0e05687110f053aaac646010",
    "semantic_title": "towards unbounded machine unlearning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=S8hg5LpFvz": {
    "title": "$p$-Poisson surface reconstruction in curl-free flow from point clouds",
    "volume": "poster",
    "abstract": "The aim of this paper is the reconstruction of a smooth surface from an unorganized point cloud sampled by a closed surface, with the preservation of geometric shapes, without any further information other than the point cloud. Implicit neural representations (INRs) have recently emerged as a promising approach to surface reconstruction. However, the reconstruction quality of existing methods relies on ground truth implicit function values or surface normal vectors. In this paper, we show that proper supervision of partial differential equations and fundamental properties of differential vector fields are sufficient to robustly reconstruct high-quality surfaces. We cast the $p$-Poisson equation to learn a signed distance function (SDF) and the reconstructed surface is implicitly represented by the zero-level set of the SDF. For efficient training, we develop a variable splitting structure by introducing a gradient of the SDF as an auxiliary variable and impose the $p$-Poisson equation directly on the auxiliary variable as a hard constraint. Based on the curl-free property of the gradient field, we impose a curl-free constraint on the auxiliary variable, which leads to a more faithful reconstruction. Experiments on standard benchmark datasets show that the proposed INR provides a superior and robust reconstruction. The code is available at https://github.com/Yebbi/PINC",
    "checked": false,
    "id": "89c8d4829e5bd94fac51ac231acc03d20491d41b",
    "semantic_title": "p-poisson surface reconstruction in curl-free flow from point clouds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NvcVXzJvhX": {
    "title": "Sheaf Hypergraph Networks",
    "volume": "poster",
    "abstract": "Higher-order relations are widespread in nature, with numerous phenomena involving complex interactions that extend beyond simple pairwise connections. As a result, advancements in higher-order processing can accelerate the growth of various fields requiring structured data. Current approaches typically represent these interactions using hypergraphs. We enhance this representation by introducing cellular sheaves for hypergraphs, a mathematical construction that adds extra structure to the conventional hypergraph while maintaining their local, higher-order connectivity. Drawing inspiration from existing Laplacians in the literature, we develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear. Our theoretical analysis demonstrates that incorporating sheaves into the hypergraph Laplacian provides a more expressive inductive bias than standard hypergraph diffusion, creating a powerful instrument for effectively modelling complex data structures. We employ these sheaf hypergraph Laplacians to design two categories of models: Sheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks. These models generalize classical Hypergraph Networks often found in the literature. Through extensive experimentation, we show that this generalization significantly improves performance, achieving top results on multiple benchmark datasets for hypergraph node classification",
    "checked": true,
    "id": "d46909af1c46728a3c635196c6cc8aee1f8005d9",
    "semantic_title": "sheaf hypergraph networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W9pJx9sFCh": {
    "title": "BadTrack: A Poison-Only Backdoor Attack on Visual Object Tracking",
    "volume": "poster",
    "abstract": "Visual object tracking (VOT) is one of the most fundamental tasks in computer vision community. State-of-the-art VOT trackers extract positive and negative examples that are used to guide the tracker to distinguish the object from the background. In this paper, we show that this characteristic can be exploited to introduce new threats and hence propose a simple yet effective poison-only backdoor attack. To be specific, we poison a small part of the training data by attaching a predefined trigger pattern to the background region of each video frame, so that the trigger appears almost exclusively in the extracted negative examples. To the best of our knowledge, this is the first work that reveals the threat of poison-only backdoor attack on VOT trackers. We experimentally show that our backdoor attack can significantly degrade the performance of both two-stream Siamese and one-stream Transformer trackers on the poisoned data while gaining comparable performance with the benign trackers on the clean data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lAbCgNcxm7": {
    "title": "DrugCLIP: Contrasive Protein-Molecule Representation Learning for Virtual Screening",
    "volume": "poster",
    "abstract": "Virtual screening, which identifies potential drugs from vast compound databases to bind with a particular protein pocket, is a critical step in AI-assisted drug discovery. Traditional docking methods are highly time-consuming, and can only work with a restricted search library in real-life applications. Recent supervised learning approaches using scoring functions for binding-affinity prediction, although promising, have not yet surpassed docking methods due to their strong dependency on limited data with reliable binding-affinity labels. In this paper, we propose a novel contrastive learning framework, DrugCLIP, by reformulating virtual screening as a dense retrieval task and employing contrastive learning to align representations of binding protein pockets and molecules from a large quantity of pairwise data without explicit binding-affinity scores. We also introduce a biological-knowledge inspired data augmentation strategy to learn better protein-molecule representations. Extensive experiments show that DrugCLIP significantly outperforms traditional docking and supervised learning methods on diverse virtual screening benchmarks with highly reduced computation time, especially in zero-shot setting",
    "checked": false,
    "id": "0bcf59e63365863875e6b3d31e56caad84ca093c",
    "semantic_title": "drugclip: contrastive protein-molecule representation learning for virtual screening",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a2svOXTVgO": {
    "title": "On the Convergence of CART under Sufficient Impurity Decrease Condition",
    "volume": "poster",
    "abstract": "The decision tree is a flexible machine-learning model that finds its success in numerous applications. It is usually fitted in a recursively greedy manner using CART. In this paper, we study the convergence rate of CART under a regression setting. First, we prove an upper bound on the prediction error of CART under a sufficient impurity decrease (SID) condition \\cite{chi2020asymptotic} -- our result is an improvement over the known result by \\cite{chi2020asymptotic} under a similar assumption. We show via examples that this error bound cannot be further improved by more than a constant or a log factor. Second, we introduce a few easy-to-check sufficient conditions of the SID condition. In particular, we show that the SID condition can be satisfied by an additive model when the component functions satisfy a ``locally reverse Poincare inequality\". We discuss a few familiar function classes in non-parametric estimation to demonstrate the usefulness of this conception",
    "checked": true,
    "id": "3a95eb757fce375b08da69efa5a75b63e5b4fed8",
    "semantic_title": "on the convergence of cart under sufficient impurity decrease condition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p1gzxzJ4Y5": {
    "title": "FlowPG: Action-constrained Policy Gradient with Normalizing Flows",
    "volume": "poster",
    "abstract": "Action-constrained reinforcement learning (ACRL) is a popular approach for solving safety-critical and resource-allocation related decision making problems. A major challenge in ACRL is to ensure agent taking a valid action satisfying constraints in each RL step. Commonly used approach of using a projection layer on top of the policy network requires solving an optimization program which can result in longer training time, slow convergence, and zero gradient problem. To address this, first we use a normalizing flow model to learn an invertible, differentiable mapping between the feasible action space and the support of a simple distribution on a latent variable, such as Gaussian. Second, learning the flow model requires sampling from the feasible action space, which is also challenging. We develop multiple methods, based on Hamiltonian Monte-Carlo and probabilistic sentential decision diagrams for such action sampling for convex and non-convex constraints. Third, we integrate the learned normalizing flow with the DDPG algorithm. By design, a well-trained normalizing flow will transform policy output into a valid action without requiring an optimization solver. Empirically, our approach results in significantly fewer constraint violations (upto an order-of-magnitude for several instances) and is multiple times faster on a variety of continuous control tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N1feehMSG9": {
    "title": "Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization",
    "volume": "poster",
    "abstract": "In many applications, e.g. in healthcare and e-commerce, the goal of a contextual bandit may be to learn an optimal treatment assignment policy at the end of the experiment. That is, to minimize simple regret. However, this objective remains understudied. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit setting, where a tuning parameter determines the weight placed on cumulative regret minimization (where we establish near-optimal minimax guarantees) versus simple regret minimization (where we establish state-of-the-art guarantees). Our algorithms work with any function class, are robust to model misspecification, and can be used in continuous arm settings. This flexibility comes from constructing and relying on \"conformal arm sets\" (CASs). CASs provide a set of arms for every context, encompassing the context-specific optimal arm with a certain probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted with a negative result, which shows that no algorithm can achieve instance-dependent simple regret guarantees while simultaneously achieving minimax optimal cumulative regret guarantees",
    "checked": true,
    "id": "e5bfbad37b68da6835d8eaa50edddb9a241bb657",
    "semantic_title": "proportional response: contextual bandits for simple and cumulative regret minimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FBNyccPfAu": {
    "title": "Variational Monte Carlo on a Budget — Fine-tuning pre-trained Neural Wavefunctions",
    "volume": "poster",
    "abstract": "Obtaining accurate solutions to the Schrödinger equation is the key challenge in computational quantum chemistry. Deep-learning-based Variational Monte Carlo (DL-VMC) has recently outperformed conventional approaches in terms of accuracy, but only at large computational cost. Whereas in many domains models are trained once and subsequently applied for inference, accurate DL-VMC so far requires a full optimization for every new problem instance, consuming thousands of GPUhs even for small molecules. We instead propose a DL-VMC model which has been pre-trained using self-supervised wavefunction optimization on a large and chemically diverse set of molecules. Applying this model to new molecules without any optimization, yields wavefunctions and absolute energies that outperform established methods such as CCSD(T)-2Z. To obtain accurate relative energies, only few fine-tuning steps of this base model are required. We accomplish this with a fully end-to-end machine-learned model, consisting of an improved geometry embedding architecture and an existing SE(3)-equivariant model to represent molecular orbitals. Combining this architecture with continuous sampling of geometries, we improve zero-shot accuracy by two orders of magnitude compared to the state of the art. We extensively evaluate the accuracy, scalability and limitations of our base model on a wide variety of test systems",
    "checked": false,
    "id": "5e91307ff39dc482d3ee56c563b68021d777eb02",
    "semantic_title": "variational monte carlo on a budget - fine-tuning pre-trained neural wavefunctions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X25L5AjHig": {
    "title": "Nearly Optimal Bounds for Cyclic Forgetting",
    "volume": "poster",
    "abstract": "We provide theoretical bounds on the forgetting quantity in the continual learning setting for linear tasks, where each round of learning corresponds to projecting onto a linear subspace. For a cyclic task ordering on $T$ tasks repeated $m$ times each, we prove the best known upper bound of $O(T^2/m)$ on the forgetting. Notably, our bound holds uniformly over all choices of tasks and is independent of the ambient dimension. Our main technical contribution is a characterization of the union of all numerical ranges of products of $T$ (real or complex) projections as a sinusoidal spiral, which may be of independent interest",
    "checked": false,
    "id": "40f554bc48c5dc3920ea154cd69a26c484c5bb62",
    "semantic_title": "precision marketing strategy of insurance market from the perspective of big data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R4xpvDTWkV": {
    "title": "Simplifying and Empowering Transformers for Large-Graph Representations",
    "volume": "poster",
    "abstract": "Learning representations on large-sized graphs is a long-standing challenge due to the inter-dependence nature involved in massive data points. Transformers, as an emerging class of foundation encoders for graph-structured data, have shown promising performance on small graphs due to its global attention capable of capturing all-pair influence beyond neighboring nodes. Even so, existing approaches tend to inherit the spirit of Transformers in language and vision tasks, and embrace complicated models by stacking deep multi-head attentions. In this paper, we critically demonstrate that even using a one-layer attention can bring up surprisingly competitive performance across node property prediction benchmarks where node numbers range from thousand-level to billion-level. This encourages us to rethink the design philosophy for Transformers on large graphs, where the global attention is a computation overhead hindering the scalability. We frame the proposed scheme as Simplified Graph Transformers (SGFormer), which is empowered by a simple attention model that can efficiently propagate information among arbitrary nodes in one layer. SGFormer requires none of positional encodings, feature/graph pre-processing or augmented loss. Empirically, SGFormer successfully scales to the web-scale graph ogbn-papers100M and yields up to 141x inference acceleration over SOTA Transformers on medium-sized graphs. Beyond current results, we believe the proposed methodology alone enlightens a new technical path of independent interest for building Transformers on large graphs",
    "checked": true,
    "id": "1a4b9ceb3dbecd3ec08b93f68ba44bc3178b1df5",
    "semantic_title": "simplifying and empowering transformers for large-graph representations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FkpMm9avyP": {
    "title": "Entropy-dissipation Informed Neural Network for McKean-Vlasov Type PDEs",
    "volume": "poster",
    "abstract": "The McKean-Vlasov equation (MVE) describes the collective behavior of particles subject to drift, diffusion, and mean-field interaction. In physical systems, the interaction term can be singular, i.e. it diverges when two particles collide. Notable examples of such interactions include the Coulomb interaction, fundamental in plasma physics, and the Biot-Savart interaction, present in the vorticity formulation of the 2D Navier-Stokes equation (NSE) in fluid dynamics. Solving MVEs that involve singular interaction kernels presents a significant challenge, especially when aiming to provide rigorous theoretical guarantees. In this work, we propose a novel approach based on the concept of entropy dissipation in the underlying system. We derive a potential function that effectively controls the KL divergence between a hypothesis solution and the ground truth. Building upon this theoretical foundation, we introduce the Entropy-dissipation Informed Neural Network (EINN) framework for solving MVEs. In EINN, we utilize neural networks (NN) to approximate the underlying velocity field and minimize the proposed potential function. By leveraging the expressive power of NNs, our approach offers a promising avenue for tackling the complexities associated with singular interactions. To assess the empirical performance of our method, we compare EINN with SOTA NN-based MVE solvers. The results demonstrate the effectiveness of our approach in solving MVEs across various example problems",
    "checked": true,
    "id": "b9a4520eb37c217005cbe4010b19295db9b8b7bf",
    "semantic_title": "entropy-dissipation informed neural network for mckean-vlasov type pdes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=PqfPjS9JRX": {
    "title": "The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit",
    "volume": "poster",
    "abstract": "In deep learning theory, the covariance matrix of the representations serves as a proxy to examine the network's trainability. Motivated by the success of Transform- ers, we study the covariance matrix of a modified Softmax-based attention model with skip connections in the proportional limit of infinite-depth-and-width. We show that at initialization the limiting distribution can be described by a stochastic differential equation (SDE) indexed by the depth-to-width ratio. To achieve a well-defined stochastic limit, the Transformer's attention mechanism is modified by centering the Softmax output at identity, and scaling the Softmax logits by a width-dependent temperature parameter. We examine the stability of the network through the corresponding SDE, showing how the scale of both the drift and diffu- sion can be elegantly controlled with the aid of residual connections. The existence of a stable SDE implies that the covariance structure is well-behaved, even for very large depth and width, thus preventing the notorious issues of rank degeneracy in deep attention models. Finally, we show, through simulations, that the SDE provides a surprisingly good description of the corresponding finite-size model. We coin the name shaped Transformer for these architectural modifications",
    "checked": true,
    "id": "c1738f21ea2460e1015d590906a4f43e155f60c8",
    "semantic_title": "the shaped transformer: attention models in the infinite depth-and-width limit",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=sABYNWKcwK": {
    "title": "Doubly Robust Augmented Transfer for Meta-Reinforcement Learning",
    "volume": "poster",
    "abstract": "Meta-reinforcement learning (Meta-RL), though enabling a fast adaptation to learn new skills by exploiting the common structure shared among different tasks, suffers performance degradation in the sparse-reward setting. Current hindsight-based sample transfer approaches can alleviate this issue by transferring relabeled trajectories from other tasks to a new task so as to provide informative experience for the target reward function, but are unfortunately constrained with the unrealistic assumption that tasks differ only in reward functions. In this paper, we propose a doubly robust augmented transfer (DRaT) approach, aiming at addressing the more general sparse reward meta-RL scenario with both dynamics mismatches and varying reward functions across tasks. Specifically, we design a doubly robust augmented estimator for efficient value-function evaluation, which tackles dynamics mismatches with the optimal importance weight of transition distributions achieved by minimizing the theoretically derived upper bound of mean squared error (MSE) between the estimated values of transferred samples and their true values in the target task. Due to its intractability, we then propose an interval-based approximation to this optimal importance weight, which is guaranteed to cover the optimum with a constrained and sample-independent upper bound on the MSE approximation error. Based on our theoretical findings, we finally develop a DRaT algorithm for transferring informative samples across tasks during the training of meta-RL. We implement DRaT on an off-policy meta-RL baseline, and empirically show that it significantly outperforms other hindsight-based approaches on various sparse-reward MuJoCo locomotion tasks with varying dynamics and reward functions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XFE6zpevLc": {
    "title": "Convergence analysis of ODE models for accelerated first-order methods via positive semidefinite kernels",
    "volume": "poster",
    "abstract": "We propose a novel methodology that systematically analyzes ordinary differential equation (ODE) models for first-order optimization methods by converting the task of proving convergence rates into verifying the positive semidefiniteness of specific Hilbert-Schmidt integral operators. Our approach is based on the performance estimation problems (PEP) introduced by Drori and Teboulle. Unlike previous works on PEP, which rely on finite-dimensional linear algebra, we use tools from functional analysis. Using the proposed method, we establish convergence rates of various accelerated gradient flow models, some of which are new. As an immediate consequence of our framework, we show a correspondence between minimizing function values and minimizing gradient norms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YiRX7nQ77Q": {
    "title": "Anytime Model Selection in Linear Bandits",
    "volume": "poster",
    "abstract": "Model selection in the context of bandit optimization is a challenging problem, as it requires balancing exploration and exploitation not only for action selection, but also for model selection. One natural approach is to rely on online learning algorithms that treat different models as experts. Existing methods, however, scale poorly ($\\mathrm{poly}M$) with the number of models $M$ in terms of their regret. Our key insight is that, for model selection in linear bandits, we can emulate full-information feedback to the online learner with a favorable bias-variance trade-off. This allows us to develop ALEXP, which has an exponentially improved ($\\log M$) dependence on $M$ for its regret. ALEXP has anytime guarantees on its regret, and neither requires knowledge of the horizon $n$, nor relies on an initial purely exploratory stage. Our approach utilizes a novel time-uniform analysis of the Lasso, establishing a new connection between online learning and high-dimensional statistics",
    "checked": true,
    "id": "3cdf1b5b4c758d56c44c229ce83ed5af4141318d",
    "semantic_title": "anytime model selection in linear bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mLe63bAYc7": {
    "title": "(Provable) Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More",
    "volume": "poster",
    "abstract": "A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, which enables architecture-agnostic certification. We additionally derive the first architecture-specific graph edit distance certificates, i.e. sound robustness guarantees for isomorphism equivariant tasks like node classification. Overall, a sound notion of robustness is an important prerequisite for future work at the intersection of robust and geometric machine learning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6XPPfZkhKi": {
    "title": "HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception",
    "volume": "poster",
    "abstract": "Model pre-training is essential in human-centric perception. In this paper, we first introduce masked image modeling (MIM) as a pre-training approach for this task. Upon revisiting the MIM training strategy, we reveal that human structure priors offer significant potential. Motivated by this insight, we further incorporate an intuitive human structure prior - human parts - into pre-training. Specifically, we employ this prior to guide the mask sampling process. Image patches, corresponding to human part regions, have high priority to be masked out. This encourages the model to concentrate more on body structure information during pre-training, yielding substantial benefits across a range of human-centric perception tasks. To further capture human characteristics, we propose a structure-invariant alignment loss that enforces different masked views, guided by the human part prior, to be closely aligned for the same image. We term the entire method as HAP. HAP simply uses a plain ViT as the encoder yet establishes new state-of-the-art performance on 11 human-centric benchmarks, and on-par result on one dataset. For example, HAP achieves 78.1% mAP on MSMT17 for person re-identification, 86.54% mA on PA-100K for pedestrian attribute recognition, 78.2% AP on MS COCO for 2D pose estimation, and 56.0 PA-MPJPE on 3DPW for 3D pose and shape estimation",
    "checked": true,
    "id": "5a35a6d11e527b3671acd875569f4842c02e262d",
    "semantic_title": "hap: structure-aware masked image modeling for human-centric perception",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ORmVvN94B9": {
    "title": "Rigorous Runtime Analysis of MOEA/D for Solving Multi-Objective Minimum Weight Base Problems",
    "volume": "poster",
    "abstract": "We study the multi-objective minimum weight base problem, an abstraction of classical NP-hard combinatorial problems such as the multi-objective minimum spanning tree problem. We prove some important properties of the convex hull of the non-dominated front, such as its approximation quality and an upper bound on the number of extreme points. Using these properties, we give the first run-time analysis of the MOEA/D algorithm for this problem, an evolutionary algorithm that effectively optimizes by decomposing the objectives into single-objective components. We show that the MOEA/D, given an appropriate decomposition setting, finds all extreme points within expected fixed-parameter polynomial time, in the oracle model. Experiments are conducted on random bi-objective minimum spanning tree instances, and the results agree with our theoretical findings. Furthermore, compared with a previously studied evolutionary algorithm for the problem GSEMO, MOEA/D finds all extreme points much faster across all instances",
    "checked": true,
    "id": "c905f279c2f747042200bf1f522ad014529b1658",
    "semantic_title": "rigorous runtime analysis of moea/d for solving multi-objective minimum weight base problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4WPhXYMK6N": {
    "title": "Learning Sample Difficulty from Pre-trained Models for Reliable Prediction",
    "volume": "poster",
    "abstract": "Large-scale pre-trained models have achieved remarkable success in many applications, but how to leverage them to improve the prediction reliability of downstream models is undesirably under-explored. Moreover, modern neural networks have been found to be poorly calibrated and make overconfident predictions regardless of inherent sample difficulty and data uncertainty. To address this issue, we propose to utilize large-scale pre-trained models to guide downstream model training with sample difficulty-aware entropy regularization. Pre-trained models that have been exposed to large-scale datasets and do not overfit the downstream training classes enable us to measure each training sample's difficulty via feature-space Gaussian modeling and relative Mahalanobis distance computation. Importantly, by adaptively penalizing overconfident prediction based on the sample difficulty, we simultaneously improve accuracy and uncertainty calibration across challenging benchmarks (e.g., +0.55% ACC and −3.7% ECE on ImageNet1k using ResNet34), consistently surpassing competitive baselines for reliable prediction. The improved uncertainty estimate further improves selective classification (abstaining from erroneous predictions) and out-of-distribution detection",
    "checked": true,
    "id": "f8d7ce62ad988915b070136351328ccb2fdc27d3",
    "semantic_title": "learning sample difficulty from pre-trained models for reliable prediction",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Z1W0u3Cr74": {
    "title": "Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification",
    "volume": "poster",
    "abstract": "Meta-learning has demonstrated promising results in few-shot classification (FSC) by learning to solve new problems using prior knowledge. Bayesian methods are effective at characterizing uncertainty in FSC, which is crucial in high-risk fields. In this context, the logistic-softmax likelihood is often employed as an alternative to the softmax likelihood in multi-class Gaussian process classification due to its conditional conjugacy property. However, the theoretical property of logistic-softmax is not clear and previous research indicated that the inherent uncertainty of logistic-softmax leads to suboptimal performance. To mitigate these issues, we revisit and redesign the logistic-softmax likelihood, which enables control of the \\textit{a priori} confidence level through a temperature parameter. Furthermore, we theoretically and empirically show that softmax can be viewed as a special case of logistic-softmax and logistic-softmax induces a larger family of data distribution than softmax. Utilizing modified logistic-softmax, we integrate the data augmentation technique into the deep kernel based Gaussian process meta-learning framework, and derive an analytical mean-field approximation for task-specific updates. Our approach yields well-calibrated uncertainty estimates and achieves comparable or superior results on standard benchmark datasets. Code is publicly available at \\url{https://github.com/keanson/revisit-logistic-softmax}",
    "checked": true,
    "id": "15282d063c77f1709ac53ea14734e81ffdebabc1",
    "semantic_title": "revisiting logistic-softmax likelihood in bayesian meta-learning for few-shot classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5HahZRA0fy": {
    "title": "Computational Guarantees for Doubly Entropic Wasserstein Barycenters",
    "volume": "poster",
    "abstract": "We study the computation of doubly regularized Wasserstein barycenters, a recently introduced family of entropic barycenters governed by inner and outer regularization strengths. Previous research has demonstrated that various regularization parameter choices unify several notions of entropy-penalized barycenters while also revealing new ones, including a special case of debiased barycenters. In this paper, we propose and analyze an algorithm for computing doubly regularized Wasserstein barycenters. Our procedure builds on damped Sinkhorn iterations followed by exact maximization/minimization steps and guarantees convergence for any choice of regularization parameters. An inexact variant of our algorithm, implementable using approximate Monte Carlo sampling, offers the first non-asymptotic convergence guarantees for approximating Wasserstein barycenters between discrete point clouds in the free-support/grid-free setting",
    "checked": false,
    "id": "bbd800ec499ddf6f4aa357adf91f627d2f8ee9b3",
    "semantic_title": "computational guarantees for doubly entropic wasserstein barycenters via damped sinkhorn iterations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=t2hEZadBBk": {
    "title": "Tailoring Self-Attention for Graph via Rooted Subtrees",
    "volume": "poster",
    "abstract": "Attention mechanisms have made significant strides in graph learning, yet they still exhibit notable limitations: local attention faces challenges in capturing long-range information due to the inherent problems of the message-passing scheme, while global attention cannot reflect the hierarchical neighborhood structure and fails to capture fine-grained local information. In this paper, we propose a novel multi-hop graph attention mechanism, named Subtree Attention (STA), to address the aforementioned issues. STA seamlessly bridges the fully-attentional structure and the rooted subtree, with theoretical proof that STA approximates the global attention under extreme settings. By allowing direct computation of attention weights among multi-hop neighbors, STA mitigates the inherent problems in existing graph attention mechanisms. Further we devise an efficient form for STA by employing kernelized softmax, which yields a linear time complexity. Our resulting GNN architecture, the STAGNN, presents a simple yet performant STA-based graph neural network leveraging a hop-aware attention strategy. Comprehensive evaluations on ten node classification datasets demonstrate that STA-based models outperform existing graph transformers and mainstream GNNs. The code is available at https://github.com/LUMIA-Group/SubTree-Attention",
    "checked": true,
    "id": "09a19b1323fed7044367329b9d033e4ee4346cff",
    "semantic_title": "tailoring self-attention for graph via rooted subtrees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J8McuwS3zY": {
    "title": "Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning",
    "volume": "poster",
    "abstract": "Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs) has emerged as a highly successful approach, with training only a small number of parameters without sacrificing performance and becoming the de-facto learning paradigm with the increasing size of PLMs. However, existing PEFT methods are not memory-efficient, because they still require caching most of the intermediate activations for the gradient calculation, akin to fine-tuning. One effective way to reduce the activation memory is to apply a reversible model, so the intermediate activations are not necessary to be cached and can be recomputed. Nevertheless, modifying a PLM to its reversible variant is not straightforward, since the reversible model has a distinct architecture from the currently released PLMs. In this paper, we first investigate what is a key factor for the success of existing PEFT methods, and realize that it's essential to preserve the PLM's starting point when initializing a PEFT method. With this finding, we propose memory-efficient fine-tuning (MEFT) that inserts adapters into a PLM, preserving the PLM's starting point and making it reversible without additional pre-training. We evaluate MEFT on the GLUE benchmark and five question-answering tasks with various backbones, BERT, RoBERTa, BART and OPT. MEFT significantly reduces the activation memory up to 84% of full fine-tuning with a negligible amount of trainable parameters. Moreover, MEFT achieves the same score on GLUE and a comparable score on the question-answering tasks as full fine-tuning. A similar finding is also observed for the image classification task",
    "checked": true,
    "id": "08e0b903f56f77c6d8a66b66f9cdbc0e40586324",
    "semantic_title": "make pre-trained model reversible: from parameter to memory efficient fine-tuning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=v6VpqGcGAR": {
    "title": "Winner Takes It All: Training Performant RL Populations for Combinatorial Optimization",
    "volume": "poster",
    "abstract": "Applying reinforcement learning (RL) to combinatorial optimization problems is attractive as it removes the need for expert knowledge or pre-solved instances. However, it is unrealistic to expect an agent to solve these (often NP-)hard problems in a single shot at inference due to their inherent complexity. Thus, leading approaches often implement additional search strategies, from stochastic sampling and beam-search to explicit fine-tuning. In this paper, we argue for the benefits of learning a population of complementary policies, which can be simultaneously rolled out at inference. To this end, we introduce Poppy, a simple training procedure for populations. Instead of relying on a predefined or hand-crafted notion of diversity, Poppy induces an unsupervised specialization targeted solely at maximizing the performance of the population. We show that Poppy produces a set of complementary policies, and obtains state-of-the-art RL results on three popular NP-hard problems: traveling salesman, capacitated vehicle routing, and job-shop scheduling",
    "checked": true,
    "id": "afa519d9f4104dd35764d7ff2187f4995084ab7c",
    "semantic_title": "winner takes it all: training performant rl populations for combinatorial optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JKhyQHpx7B": {
    "title": "Vocabulary-free Image Classification",
    "volume": "poster",
    "abstract": "Recent advances in large vision-language models have revolutionized the image classification paradigm. Despite showing impressive zero-shot capabilities, a pre-defined set of categories, a.k.a. the vocabulary, is assumed at test time for composing the textual prompts. However, such assumption can be impractical when the semantic context is unknown and evolving. We thus formalize a novel task, termed as Vocabulary-free Image Classification (VIC), where we aim to assign to an input image a class that resides in an unconstrained language-induced semantic space, without the prerequisite of a known vocabulary. VIC is a challenging task as the semantic space is extremely large, containing millions of concepts, with hard-to-discriminate fine-grained categories. In this work, we first empirically verify that representing this semantic space by means of an external vision-language database is the most effective way to obtain semantically relevant content for classifying the image. We then propose Category Search from External Databases (CaSED), a method that exploits a pre-trained vision-language model and an external vision-language database to address VIC in a training-free manner. CaSED first extracts a set of candidate categories from captions retrieved from the database based on their semantic similarity to the image, and then assigns to the image the best matching candidate category according to the same vision-language model. Experiments on benchmark datasets validate that CaSED outperforms other complex vision-language frameworks, while being efficient with much fewer parameters, paving the way for future research in this direction",
    "checked": true,
    "id": "77424562deba33e94ea5ca3c662ccfdc2b95fb5c",
    "semantic_title": "vocabulary-free image classification",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hpYb4eUinX": {
    "title": "Boosting Verification of Deep Reinforcement Learning via Piece-Wise Linear Decision Neural Networks",
    "volume": "poster",
    "abstract": "Formally verifying deep reinforcement learning (DRL) systems suffers from both inaccurate verification results and limited scalability. The major obstacle lies in the large overestimation introduced inherently during training and then transforming the inexplicable decision-making models, i.e., deep neural networks (DNNs), into easy-to-verify models. In this paper, we propose an inverse transform-then-train approach, which first encodes a DNN into an equivalent set of efficiently and tightly verifiable linear control policies and then optimizes them via reinforcement learning. We accompany our inverse approach with a novel neural network model called piece-wise linear decision neural networks (PLDNNs), which are compatible with most existing DRL training algorithms with comparable performance against conventional DNNs. Our extensive experiments show that, compared to DNN-based DRL systems, PLDNN-based systems can be more efficiently and tightly verified with up to $438$ times speedup and a significant reduction in overestimation. In particular, even a complex $12$-dimensional DRL system is efficiently verified with up to 7 times deeper computation steps",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4ULTSBBY4U": {
    "title": "Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis",
    "volume": "poster",
    "abstract": "Diffusion models (DMs) have recently gained attention with state-of-the-art performance in text-to-image synthesis. Abiding by the tradition in deep learning, DMs are trained and evaluated on the images with fixed sizes. However, users are demanding for various images with specific sizes and various aspect ratio. This paper focuses on adapting text-to-image diffusion models to handle such variety while maintaining visual fidelity. First we observe that, during the synthesis, lower resolution images suffer from incomplete object portrayal, while higher resolution images exhibit repetitively disordered presentation. Next, we establish a statistical relationship indicating that attention entropy changes with token quantity, suggesting that models aggregate spatial information in proportion to image resolution. The subsequent interpretation on our observations is that objects are incompletely depicted due to limited spatial information for low resolutions, while repetitively disorganized presentation arises from redundant spatial information for high resolutions. From this perspective, we propose a scaling factor to alleviate the change of attention entropy and mitigate the defective pattern observed. Extensive experimental results validate the efficacy of the proposed scaling factor, enabling models to achieve better visual effects, image quality, and text alignment. Notably, these improvements are achieved without additional training or fine-tuning techniques",
    "checked": true,
    "id": "166b8c2ee52794c46615c5c52d0390d896b79794",
    "semantic_title": "training-free diffusion model adaptation for variable-sized text-to-image synthesis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=yAOwkf4FyL": {
    "title": "Operation-Level Early Stopping for Robustifying Differentiable NAS",
    "volume": "poster",
    "abstract": "Differentiable NAS (DARTS) is a simple and efficient neural architecture search method that has been extensively adopted in various machine learning tasks. % Nevertheless, DARTS still encounters several robustness issues, mainly the domination of skip connections. % The resulting architectures are full of parametric-free operations, leading to performance collapse. % Existing methods suggest that the skip connection has additional advantages in optimization compared to other parametric operations and propose to alleviate the domination of skip connections by eliminating these additional advantages. % In this paper, we analyze this issue from a simple and straightforward perspective and propose that the domination of skip connections results from parametric operations overfitting the training data while architecture parameters are trained on the validation data, leading to undesired behaviors. % Based on this observation, we propose the operation-level early stopping (OLES) method to overcome this issue and robustify DARTS without introducing any computation overhead. % Extensive experimental results can verify our hypothesis and the effectiveness of OLES",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xdOoCWCYaY": {
    "title": "Towards Data-Agnostic Pruning At Initialization: What Makes a Good Sparse Mask?",
    "volume": "poster",
    "abstract": "Pruning at initialization (PaI) aims to remove weights of neural networks before training in pursuit of training efficiency besides the inference. While off-the-shelf PaI methods manage to find trainable subnetworks that outperform random pruning, their performance in terms of both accuracy and computational reduction is far from satisfactory compared to post-training pruning and the understanding of PaI is missing. For instance, recent studies show that existing PaI methods only able to find good layerwise sparsities not weights, as the discovered subnetworks are surprisingly resilient against layerwise random mask shuffling and weight re-initialization. In this paper, we study PaI from a brand-new perspective -- the topology of subnetworks. In particular, we propose a principled framework for analyzing the performance of Pruning and Initialization (PaI) methods with two quantities, namely, the number of effective paths and effective nodes. These quantities allow for a more comprehensive understanding of PaI methods, giving us an accurate assessment of different subnetworks at initialization. We systematically analyze the behavior of various PaI methods through our framework and observe a guiding principle for constructing effective subnetworks: *at a specific sparsity, the top-performing subnetwork always presents a good balance between the number of effective nodes and the number of effective paths.* Inspired by this observation, we present a novel data-agnostic pruning method by solving a multi-objective optimization problem. By conducting extensive experiments across different architectures and datasets, our results demonstrate that our approach outperforms state-of-the-art PaI methods while it is able to discover subnetworks that have much lower inference FLOPs (up to 3.4$\\times$). Code will be fully released",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PmlNxZoXr4": {
    "title": "Neural Processes with Stability",
    "volume": "poster",
    "abstract": "Unlike traditional statistical models depending on hand-specified priors, neural processes (NPs) have recently emerged as a class of powerful neural statistical models that combine the strengths of neural networks and stochastic processes. NPs can define a flexible class of stochastic processes well suited for highly non-trivial functions by encoding contextual knowledge into the function space. However, noisy context points introduce challenges to the algorithmic stability that small changes in training data may significantly change the models and yield lower generalization performance. In this paper, we provide theoretical guidelines for deriving stable solutions with high generalization by introducing the notion of algorithmic stability into NPs, which can be flexible to work with various NPs and achieves less biased approximation with theoretical guarantees. To illustrate the superiority of the proposed model, we perform experiments on both synthetic and real-world data, and the results demonstrate that our approach not only helps to achieve more accurate performance but also improves model robustness",
    "checked": false,
    "id": "44ac744d553e990e7bd4bcc817238fadb992c7ca",
    "semantic_title": "conditional neural processes for model-based reinforcement learning with stability guarantees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XzTM9gVRT4": {
    "title": "Minimax Risks and Optimal Procedures for Estimation under Functional Local Differential Privacy",
    "volume": "poster",
    "abstract": "As concerns about data privacy continue to grow, differential privacy (DP) has emerged as a fundamental concept that aims to guarantee privacy by ensuring individuals' indistinguishability in data analysis. Local differential privacy (LDP) is a rigorous type of DP that requires individual data to be privatized before being sent to the collector, thus removing the need for a trusted third party to collect data. Among the numerous (L)DP-based approaches, functional DP has gained considerable attention in the DP community because it connects DP to statistical decision-making by formulating it as a hypothesis-testing problem and also exhibits Gaussian-related properties. However, the utility of privatized data is generally lower than that of non-private data, prompting research into optimal mechanisms that maximize the statistical utility for given privacy constraints. In this study, we investigate how functional LDP preserves the statistical utility by analyzing minimax risks of univariate mean estimation as well as nonparametric density estimation. We leverage the contraction property of functional LDP mechanisms and classical information-theoretical bounds to derive private minimax lower bounds. Our theoretical study reveals that it is possible to establish an interpretable, continuous balance between the statistical utility and privacy level, which has not been achieved under the $\\epsilon$-LDP framework. Furthermore, we suggest minimax optimal mechanisms based on Gaussian LDP (a type of functional LDP) that achieve the minimax upper bounds and show via a numerical study that they are superior to the counterparts derived under $\\epsilon$-LDP. The theoretical and empirical findings of this work suggest that Gaussian LDP should be considered a reliable standard for LDP",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RgD92idA32": {
    "title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks",
    "volume": "poster",
    "abstract": "Parallelization techniques have become ubiquitous for accelerating inference and training of deep neural networks. Despite this, several operations are still performed in a sequential manner. For instance, the forward and backward passes are executed layer-by-layer, and the output of diffusion models is produced by applying a sequence of denoising steps. This sequential approach results in a computational cost proportional to the number of steps involved, presenting a potential bottleneck as the number of steps increases. In this work, we introduce DeepPCR, a novel algorithm which parallelizes typically sequential operations in order to speed up inference and training of neural networks. DeepPCR is based on interpreting a sequence of $L$ steps as the solution of a specific system of equations, which we recover using the Parallel Cyclic Reduction algorithm. This reduces the complexity of computing the sequential operations from $\\mathcal{O}(L)$ to $\\mathcal{O}(\\log_2L)$, thus yielding a speedup for large $L$. To verify the theoretical lower complexity of the algorithm, and to identify regimes for speedup, we test the effectiveness of DeepPCR in parallelizing the forward and backward pass in multi-layer perceptrons, and reach speedups of up to $30\\times$ for the forward and $200\\times$ for the backward pass. We additionally showcase the flexibility of DeepPCR by parallelizing training of ResNets with as many as 1024 layers, and generation in diffusion models, enabling up to $7\\times$ faster training and $11\\times$ faster generation, respectively, when compared to the sequential approach",
    "checked": true,
    "id": "6d99a203b2d9105e94c0a5d6c23dfa904507b16d",
    "semantic_title": "deeppcr: parallelizing sequential operations in neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JCCi58IUsh": {
    "title": "Grounded Decoding: Guiding Text Generation with Grounded Models for Embodied Agents",
    "volume": "poster",
    "abstract": "Recent progress in large language models (LLMs) has demonstrated the ability to learn and leverage Internet-scale knowledge through pre-training with autoregressive models. Unfortunately, applying such models to settings with embodied agents, such as robots, is challenging due to their lack of experience with the physical world, inability to parse non-language observations, and ignorance of rewards or safety constraints that robots may require. On the other hand, language-conditioned robotic policies that learn from interaction data can provide the necessary grounding that allows the agent to be correctly situated in the real world, but such policies are limited by the lack of high-level semantic understanding due to the limited breadth of the interaction data available for training them. Thus, if we want to make use of the semantic knowledge in a language model while still situating it in an embodied setting, we must construct an action sequence that is both likely according to the language model and also realizable according to grounded models of the environment. We frame this as a problem similar to probabilistic filtering: decode a sequence that both has high probability under the language model and high probability under a set of grounded model objectives. We demonstrate how such grounded models can be obtained across three simulation and real-world domains, and that the proposed decoding strategy is able to solve complex, long-horizon embodiment tasks in a robotic setting by leveraging the knowledge of both models",
    "checked": false,
    "id": "33af17e7cc5cd4ee18c9e6e8c5fca7e224592ec0",
    "semantic_title": "grounded decoding: guiding text generation with grounded models for robot control",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=Xy7DoWSNZX": {
    "title": "CAP: Correlation-Aware Pruning for Highly-Accurate Sparse Vision Models",
    "volume": "poster",
    "abstract": "Driven by significant improvements in architectural design and training pipelines, computer vision has recently experienced dramatic progress in terms of accuracy on classic benchmarks such as ImageNet. These highly-accurate models are challenging to deploy, as they appear harder to compress using standard techniques such as pruning. We address this issue by introducing the Correlation Aware Pruner (CAP), a new unstructured pruning framework which significantly pushes the compressibility limits for state-of-the-art architectures. Our method is based on two technical advancements: a new theoretically-justified pruner, which can handle complex weight correlations accurately and efficiently during the pruning process itself, and an efficient finetuning procedure for post-compression recovery. We validate our approach via extensive experiments on several modern vision models such as Vision Transformers (ViT), modern CNNs, and ViT-CNN hybrids, showing for the first time that these can be pruned to high sparsity levels (e.g. $\\geq 75$%) with low impact on accuracy ($\\leq 1$% relative drop). Our approach is also compatible with structured pruning and quantization, and can lead to practical speedups of 1.5 to 2.4x without accuracy loss. To further showcase CAP's accuracy and scalability, we use it to show for the first time that extremely-accurate large vision models, trained via self-supervised techniques, can also be pruned to moderate sparsities, with negligible accuracy loss",
    "checked": true,
    "id": "3137c3ae4d21cf19d1bec8648f5f2935b5a3378e",
    "semantic_title": "cap: correlation-aware pruning for highly-accurate sparse vision models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WpGLxnOWhn": {
    "title": "Joint Training of Deep Ensembles Fails Due to Learner Collusion",
    "volume": "poster",
    "abstract": "Ensembles of machine learning models have been well established as a powerful method of improving performance over a single model. Traditionally, ensembling algorithms train their base learners independently or sequentially with the goal of optimizing their joint performance. In the case of deep ensembles of neural networks, we are provided with the opportunity to directly optimize the true objective: the joint performance of the ensemble as a whole. Surprisingly, however, directly minimizing the loss of the ensemble appears to rarely be applied in practice. Instead, most previous research trains individual models independently with ensembling performed _post hoc_. In this work, we show that this is for good reason - _joint optimization of ensemble loss results in degenerate behavior_. We approach this problem by decomposing the ensemble objective into the strength of the base learners and the diversity between them. We discover that joint optimization results in a phenomenon in which base learners collude to artificially inflate their apparent diversity. This pseudo-diversity fails to generalize beyond the training data, causing a larger generalization gap. We proceed to comprehensively demonstrate the practical implications of this effect on a range of standard machine learning tasks and architectures by smoothly interpolating between independent training and joint optimization",
    "checked": true,
    "id": "672b6c1e0ec7e920ec7caa103df50b16944b8fa6",
    "semantic_title": "joint training of deep ensembles fails due to learner collusion",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=6gcY0MGNhj": {
    "title": "Statistical Analysis of Quantum State Learning Process in Quantum Neural Networks",
    "volume": "poster",
    "abstract": "Quantum neural networks (QNNs) have been a promising framework in pursuing near-term quantum advantage in various fields, where many applications can be viewed as learning a quantum state that encodes useful data. As a quantum analog of probability distribution learning, quantum state learning is theoretically and practically essential in quantum machine learning. In this paper, we develop a no-go theorem for learning an unknown quantum state with QNNs even starting from a high-fidelity initial state. We prove that when the loss value is lower than a critical threshold, the probability of avoiding local minima vanishes exponentially with the qubit count, while only grows polynomially with the circuit depth. The curvature of local minima is concentrated to the quantum Fisher information times a loss-dependent constant, which characterizes the sensibility of the output state with respect to parameters in QNNs. These results hold for any circuit structures, initialization strategies, and work for both fixed ansatzes and adaptive methods. Extensive numerical simulations are performed to validate our theoretical results. Our findings place generic limits on good initial guesses and adaptive methods for improving the learnability and scalability of QNNs, and deepen the understanding of prior information's role in QNNs",
    "checked": true,
    "id": "f1e85bee7ee2ddbe09bb6e5df919486bed40e6bc",
    "semantic_title": "statistical analysis of quantum state learning process in quantum neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m0vfXMrLwF": {
    "title": "Learn to Categorize or Categorize to Learn? Self-Coding for Generalized Category Discovery",
    "volume": "poster",
    "abstract": "In the quest for unveiling novel categories at test time, we confront the inherent limitations of traditional supervised recognition models that are restricted by a predefined category set. While strides have been made in the realms of self-supervised and open-world learning towards test-time category discovery, a crucial yet often overlooked question persists: what exactly delineates a category? In this paper, we conceptualize a category through the lens of optimization, viewing it as an optimal solution to a well-defined problem. Harnessing this unique conceptualization, we propose a novel, efficient and self-supervised method capable of discovering previously unknown categories at test time. A salient feature of our approach is the assignment of minimum length category codes to individual data instances, which encapsulates the implicit category hierarchy prevalent in real-world datasets. This mechanism affords us enhanced control over category granularity, thereby equipping our model to handle fine-grained categories adeptly. Experimental evaluations, bolstered by state-of-the-art benchmark comparisons, testify to the efficacy of our solution in managing unknown categories at test time. Furthermore, we fortify our proposition with a theoretical foundation, providing proof of its optimality. Our code is available at: https://github.com/SarahRastegar/InfoSieve",
    "checked": true,
    "id": "4f818684a18fb8ebc62ad2f5bfe7d0ac53d93fe4",
    "semantic_title": "learn to categorize or categorize to learn? self-coding for generalized category discovery",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8xTOtxinMH": {
    "title": "TMT-VIS: Taxonomy-aware Multi-dataset Joint Training for Video Instance Segmentation",
    "volume": "poster",
    "abstract": "Training on large-scale datasets can boost the performance of video instance segmentation while the annotated datasets for VIS are hard to scale up due to the high labor cost. What we possess are numerous isolated filed-specific datasets, thus, it is appealing to jointly train models across the aggregation of datasets to enhance data volume and diversity. However, due to the heterogeneity in category space, as mask precision increase with the data volume, simply utilizing multiple datasets will dilute the attention of models on different taxonomy. Thus, increasing the data scale and enriching taxonomy space while improving classification precision is important. In this work, we analyze that providing extra taxonomy information can help models concentrate on specific taxonomy, and propose our model named Taxonomy-aware Multi-dataset Joint Training for Video Instance Segmentation (TMT-VIS) to address this vital challenge. Specifically, we design a two-stage taxonomy aggregation module that first compiles taxonomy information from input videos and then aggregates these taxonomy priors into instance queries before the transformer decoder. We conduct extensive experimental evaluations on four popular and challenging benchmarks, including YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and UVO. Our model shows significant improvement over the baseline solutions, and sets new state-of-the-art records on all these benchmarks. These appealing and encouraging results demonstrate the effectiveness and generality of our proposed approach. The code and trained models will be publicly available",
    "checked": false,
    "id": "5cc50ca5d5181457e5f3eeac0df02163c558d46c",
    "semantic_title": "devis: making deformable transformers work for video instance segmentation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=LmmjiTwYm0": {
    "title": "What functions can Graph Neural Networks compute on random graphs? The role of Positional Encoding",
    "volume": "poster",
    "abstract": "We aim to deepen the theoretical understanding of Graph Neural Networks (GNNs) on large graphs, with a focus on their expressive power. Existing analyses relate this notion to the graph isomorphism problem, which is mostly relevant for graphs of small sizes, or studied graph classification or regression tasks, while prediction tasks on \\emph{nodes} are far more relevant on large graphs. Recently, several works showed that, on very general random graphs models, GNNs converge to certains functions as the number of nodes grows. In this paper, we provide a more complete and intuitive description of the function space generated by equivariant GNNs for node-tasks, through general notions of convergence that encompass several previous examples. We emphasize the role of input node features, and study the impact of \\emph{node Positional Encodings} (PEs), a recent line of work that has been shown to yield state-of-the-art results in practice. Through the study of several examples of PEs on large random graphs, we extend previously known universality results to significantly more general models. Our theoretical results hint at some normalization tricks, which is shown numerically to have a positive impact on GNN generalization on synthetic and real data. Our proofs contain new concentration inequalities of independent interest",
    "checked": true,
    "id": "a793c5a5125b2fedbd251ff5b964def24345916c",
    "semantic_title": "what functions can graph neural networks compute on random graphs? the role of positional encoding",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=nrbR2F29vU": {
    "title": "A Scale-Invariant Sorting Criterion to Find a Causal Order in Additive Noise Models",
    "volume": "poster",
    "abstract": "Additive Noise Models (ANMs) are a common model class for causal discovery from observational data. Due to a lack of real-world data for which an underlying ANM is known, ANMs with randomly sampled parameters are commonly used to simulate data for the evaluation of causal discovery algorithms. While some parameters may be fixed by explicit assumptions, fully specifying an ANM requires choosing all parameters. Reisach et al. (2021) show that, for many ANM parameter choices, sorting the variables by increasing variance yields an ordering close to a causal order and introduce ‘var-sortability' to quantify this alignment. Since increasing variances may be unrealistic and cannot be exploited when data scales are arbitrary, ANM data are often rescaled to unit variance in causal discovery benchmarking. We show that synthetic ANM data are characterized by another pattern that is scale-invariant and thus persists even after standardization: the explainable fraction of a variable's variance, as captured by the coefficient of determination $R^2$, tends to increase along the causal order. The result is high ‘$R^2$-sortability', meaning that sorting the variables by increasing $R^2$ yields an ordering close to a causal order. We propose a computationally efficient baseline algorithm termed ‘$R^2$-SortnRegress' that exploits high $R^2$-sortability and that can match and exceed the performance of established causal discovery algorithms. We show analytically that sufficiently high edge weights lead to a relative decrease of the noise contributions along causal chains, resulting in increasingly deterministic relationships and high $R^2$. We characterize $R^2$-sortability on synthetic data with different simulation parameters and find high values in common settings. Our findings reveal high $R^2$-sortability as an assumption about the data generating process relevant to causal discovery and implicit in many ANM sampling schemes. It should be made explicit, as its prevalence in real-world data is an open question. For causal discovery benchmarking, we provide implementations of $R^2$-sortability, the $R^2$-SortnRegress algorithm, and ANM simulation procedures in our library CausalDisco at https://causaldisco.github.io/CausalDisco/",
    "checked": true,
    "id": "3b227285d0a4c8033d2da2b2e0bd085cf5d37e69",
    "semantic_title": "a scale-invariant sorting criterion to find a causal order in additive noise models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=1zKRwh5Rl2": {
    "title": "Comparing Causal Frameworks: Potential Outcomes, Structural Models, Graphs, and Abstractions",
    "volume": "poster",
    "abstract": "The aim of this paper is to make clear and precise the relationship between the Rubin causal model (RCM) and structural causal model (SCM) frameworks for causal inference. Adopting a neutral logical perspective, and drawing on previous work, we show what is required for an RCM to be representable by an SCM. A key result then shows that every RCM---including those that violate algebraic principles implied by the SCM framework---emerges as an abstraction of some representable RCM. Finally, we illustrate the power of this ameliorative perspective by pinpointing an important role for SCM principles in classic applications of RCMs; conversely, we offer a characterization of the algebraic constraints implied by a graph, helping to substantiate further comparisons between the two frameworks",
    "checked": true,
    "id": "71e705eb64e3c2c2d43b36e5d6d83e3d605a339f",
    "semantic_title": "comparing causal frameworks: potential outcomes, structural models, graphs, and abstractions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=zrCmeqV3Sz": {
    "title": "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
    "volume": "poster",
    "abstract": "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance",
    "checked": false,
    "id": "1f86010608ca56f74041fdf5d707a6d24f4ae357",
    "semantic_title": "representing graphs via gromov-wasserstein factorization",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=65aDEXIhih": {
    "title": "Computational Complexity of Learning Neural Networks: Smoothness and Degeneracy",
    "volume": "poster",
    "abstract": "Understanding when neural networks can be learned efficiently is a fundamental question in learning theory. Existing hardness results suggest that assumptions on both the input distribution and the network's weights are necessary for obtaining efficient algorithms. Moreover, it was previously shown that depth-$2$ networks can be efficiently learned under the assumptions that the input distribution is Gaussian, and the weight matrix is non-degenerate. In this work, we study whether such assumptions may suffice for learning deeper networks and prove negative results. We show that learning depth-$3$ ReLU networks under the Gaussian input distribution is hard even in the smoothed-analysis framework, where a random noise is added to the network's parameters. It implies that learning depth-$3$ ReLU networks under the Gaussian distribution is hard even if the weight matrices are non-degenerate. Moreover, we consider depth-$2$ networks, and show hardness of learning in the smoothed-analysis framework, where both the network parameters and the input distribution are smoothed. Our hardness results are under a well-studied assumption on the existence of local pseudorandom generators",
    "checked": true,
    "id": "0001ea6c840bfd2921c8e28888d60fbd2f57423c",
    "semantic_title": "computational complexity of learning neural networks: smoothness and degeneracy",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=NGiq8qCQNk": {
    "title": "Zero-sum Polymatrix Markov Games: Equilibrium Collapse and Efficient Computation of Nash Equilibria",
    "volume": "poster",
    "abstract": "The works of (Daskalakis et al., 2009, 2022; Jin et al., 2022; Deng et al., 2023) indicate that computing Nash equilibria in multi-player Markov games is a computationally hard task. This fact raises the question of whether or not computational intractability can be circumvented if one focuses on specific classes of Markov games. One such example is two-player zero-sum Markov games, in which efficient ways to compute a Nash equilibrium are known. Inspired by zero-sum polymatrix normal-form games (Cai et al., 2016), we define a class of zero-sum multi-agent Markov games in which there are only pairwise interactions described by a graph that changes per state. For this class of Markov games, we show that an $\\epsilon$-approximate Nash equilibrium can be found efficiently. To do so, we generalize the techniques of (Cai et al., 2016), by showing that the set of coarse-correlated equilibria collapses to the set of Nash equilibria. Afterwards, it is possible to use any algorithm in the literature that computes approximate coarse-correlated equilibria Markovian policies to get an approximate Nash equilibrium",
    "checked": true,
    "id": "eb9a93acadbb8e2e1132a7415c81c5c2b32aeb80",
    "semantic_title": "zero-sum polymatrix markov games: equilibrium collapse and efficient computation of nash equilibria",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=3bdXag2rUd": {
    "title": "SoTTA: Robust Test-Time Adaptation on Noisy Data Streams",
    "volume": "poster",
    "abstract": "Test-time adaptation (TTA) aims to address distributional shifts between training and testing data using only unlabeled test data streams for continual model adaptation. However, most TTA methods assume benign test streams, while test samples could be unexpectedly diverse in the wild. For instance, an unseen object or noise could appear in autonomous driving. This leads to a new threat to existing TTA algorithms; we found that prior TTA algorithms suffer from those noisy test samples as they blindly adapt to incoming samples. To address this problem, we present Screening-out Test-Time Adaptation (SoTTA), a novel TTA algorithm that is robust to noisy samples. The key enabler of SoTTA is two-fold: (i) input-wise robustness via high-confidence uniform-class sampling that effectively filters out the impact of noisy samples and (ii) parameter-wise robustness via entropy-sharpness minimization that improves the robustness of model parameters against large gradients from noisy samples. Our evaluation with standard TTA benchmarks with various noisy scenarios shows that our method outperforms state-of-the-art TTA methods under the presence of noisy samples and achieves comparable accuracy to those methods without noisy samples. The source code is available at https://github.com/taeckyung/SoTTA",
    "checked": true,
    "id": "ec60f3875cb91fd777d2ff62d77090caa94af694",
    "semantic_title": "sotta: robust test-time adaptation on noisy data streams",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kDQwossJuI": {
    "title": "Limits, approximation and size transferability for GNNs on sparse graphs via graphops",
    "volume": "poster",
    "abstract": "Can graph neural networks generalize to graphs that are different from the graphs they were trained on, e.g., in size? In this work, we study this question from a theoretical perspective. While recent work established such transferability and approximation results via graph limits, e.g., via graphons, these only apply nontrivially to dense graphs. To include frequently encountered sparse graphs such as bounded-degree or power law graphs, we take a perspective of taking limits of operators derived from graphs, such as the aggregation operation that makes up GNNs. This leads to the recently introduced limit notion of graphops (Backhausz and Szegedy, 2022). We demonstrate how the operator perspective allows us to develop quantitative bounds on the distance between a finite GNN and its limit on an infinite graph, as well as the distance between the GNN on graphs of different sizes that share structural properties, under a regularity assumption verified for various graph sequences. Our results hold for dense and sparse graphs, and various notions of graph limits",
    "checked": true,
    "id": "3307275bf6d20fcc73181cb090afe25c528a27ac",
    "semantic_title": "limits, approximation and size transferability for gnns on sparse graphs via graphops",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=gh9JNeqjzo": {
    "title": "Reducing Shape-Radiance Ambiguity in Radiance Fields with a Closed-Form Color Estimation Method",
    "volume": "poster",
    "abstract": "Neural radiance field (NeRF) enables the synthesis of cutting-edge realistic novel view images of a 3D scene. It includes density and color fields to model the shape and radiance of a scene, respectively. Supervised by the photometric loss in an end-to-end training manner, NeRF inherently suffers from the shape-radiance ambiguity problem, i.e., it can perfectly fit training views but does not guarantee decoupling the two fields correctly. To deal with this issue, existing works have incorporated prior knowledge to provide an independent supervision signal for the density field, including total variation loss, sparsity loss, distortion loss, etc. These losses are based on general assumptions about the density field, e.g., it should be smooth, sparse, or compact, which are not adaptive to a specific scene. In this paper, we propose a more adaptive method to reduce the shape-radiance ambiguity. The key is a rendering method that is only based on the density field. Specifically, we first estimate the color field based on the density field and posed images in a closed form. Then NeRF's rendering process can proceed. We address the problems in estimating the color field, including occlusion and non-uniformly distributed views. Afterward, it is applied to regularize NeRF's density field. As our regularization is guided by photometric loss, it is more adaptive compared to existing ones. Experimental results show that our method improves the density field of NeRF both qualitatively and quantitatively. Our code is available at https://github.com/qihangGH/Closed-form-color-field",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pvPujuvjQd": {
    "title": "Most Neural Networks Are Almost Learnable",
    "volume": "poster",
    "abstract": "We present a PTAS for learning random constant-depth networks. We show that for any fixed $\\epsilon>0$ and depth $i$, there is a poly-time algorithm that for any distribution on $\\sqrt{d} \\cdot \\mathbb{S}^{d-1}$ learns random Xavier networks of depth $i$, up to an additive error of $\\epsilon$. The algorithm runs in time and sample complexity of $(\\bar{d})^{\\mathrm{poly}(\\epsilon^{-1})}$, where $\\bar d$ is the size of the network. For some cases of sigmoid and ReLU-like activations the bound can be improved to $(\\bar{d})^{\\mathrm{polylog}(\\epsilon^{-1})}$, resulting in a quasi-poly-time algorithm for learning constant depth random networks",
    "checked": true,
    "id": "6852b8c38f955366b96ccdd06a9ae64d72d7c500",
    "semantic_title": "most neural networks are almost learnable",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3iSj4l8ZGT": {
    "title": "Learning Interpretable Low-dimensional Representation via Physical Symmetry",
    "volume": "poster",
    "abstract": "We have recently seen great progress in learning interpretable music representations, ranging from basic factors, such as pitch and timbre, to high-level concepts, such as chord and texture. However, most methods rely heavily on music domain knowledge. It remains an open question what general computational principles *give rise to* interpretable representations, especially low-dim factors that agree with human perception. In this study, we take inspiration from modern physics and use *physical symmetry* as a self-consistency constraint for the latent space. Specifically, it requires the prior model that characterises the dynamics of the latent states to be *equivariant* with respect to certain group transformations. We show that physical symmetry leads the model to learn a *linear* pitch factor from unlabelled monophonic music audio in a self-supervised fashion. In addition, the same methodology can be applied to computer vision, learning a 3D Cartesian space from videos of a simple moving object without labels. Furthermore, physical symmetry naturally leads to *representation augmentation*, a new technique which improves sample efficiency",
    "checked": true,
    "id": "4869230f4d1535027433eeb3cba337540829c1e6",
    "semantic_title": "learning interpretable low-dimensional representation via physical symmetry",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zO2dAQfvHf": {
    "title": "Stabilized Neural Differential Equations for Learning Dynamics with Explicit Constraints",
    "volume": "poster",
    "abstract": "Many successful methods to learn dynamical systems from data have recently been introduced. However, ensuring that the inferred dynamics preserve known constraints, such as conservation laws or restrictions on the allowed system states, remains challenging. We propose stabilized neural differential equations (SNDEs), a method to enforce arbitrary manifold constraints for neural differential equations. Our approach is based on a stabilization term that, when added to the original dynamics, renders the constraint manifold provably asymptotically stable. Due to its simplicity, our method is compatible with all common neural differential equation (NDE) models and broadly applicable. In extensive empirical evaluations, we demonstrate that SNDEs outperform existing methods while broadening the types of constraints that can be incorporated into NDE training",
    "checked": true,
    "id": "e33477691c0ee4c69e5eacf421d7a4fba7a37e35",
    "semantic_title": "stabilized neural differential equations for learning dynamics with explicit constraints",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j7x9wW3tCf": {
    "title": "Learning from Both Structural and Textual Knowledge for Inductive Knowledge Graph Completion",
    "volume": "poster",
    "abstract": "Learning rule-based systems plays a pivotal role in knowledge graph completion (KGC). Existing rule-based systems restrict the input of the system to structural knowledge only, which may omit some useful knowledge for reasoning, e.g., textual knowledge. In this paper, we propose a two-stage framework that imposes both structural and textual knowledge to learn rule-based systems. In the first stage, we compute a set of triples with confidence scores (called \\emph{soft triples}) from a text corpus by distant supervision, where a textual entailment model with multi-instance learning is exploited to estimate whether a given triple is entailed by a set of sentences. In the second stage, these soft triples are used to learn a rule-based model for KGC. To mitigate the negative impact of noise from soft triples, we propose a new formalism for rules to be learnt, named \\emph{text enhanced rules} or \\emph{TE-rules} for short. To effectively learn TE-rules, we propose a neural model that simulates the inference of TE-rules. We theoretically show that any set of TE-rules can always be interpreted by a certain parameter assignment of the neural model. We introduce three new datasets to evaluate the effectiveness of our method. Experimental results demonstrate that the introduction of soft triples and TE-rules results in significant performance improvements in inductive link prediction",
    "checked": false,
    "id": "8aa60d7802659dd18c80a3411a905599fc431226",
    "semantic_title": "unifying structure and language semantic for efficient contrastive knowledge graph completion with structured entity anchors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8JsbdJjRvY": {
    "title": "3D Indoor Instance Segmentation in an Open-World",
    "volume": "poster",
    "abstract": "Existing 3D instance segmentation methods typically assume that all semantic classes to be segmented would be available during training and only seen categories are segmented at inference. We argue that such a closed-world assumption is restrictive and explore for the first time 3D indoor instance segmentation in an open-world setting, where the model is allowed to distinguish a set of known classes as well as identify an unknown object as unknown and then later incrementally learning the semantic category of the unknown when the corresponding category labels are available. To this end, we introduce an open-world 3D indoor instance segmentation method, where an auto-labeling scheme is employed to produce pseudo-labels during training and induce separation to separate known and unknown category labels. We further improve the pseudo-labels quality at inference by adjusting the unknown class probability based on the objectness score distribution. We also introduce carefully curated open-world splits leveraging realistic scenarios based on inherent object distribution, region-based indoor scene exploration and randomness aspect of open-world classes. Extensive experiments reveal the efficacy of the proposed contributions leading to promising open-world 3D instance segmentation performance. Code and splits are available at: https://github.com/aminebdj/3D-OWIS",
    "checked": true,
    "id": "b60fcdb171b448bb9ac1bb6acc7c9aa2df6002e2",
    "semantic_title": "3d indoor instance segmentation in an open-world",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GDYuzX0rwj": {
    "title": "Facing Off World Model Backbones: RNNs, Transformers, and S4",
    "volume": "poster",
    "abstract": "World models are a fundamental component in model-based reinforcement learning (MBRL). To perform temporally extended and consistent simulations of the future in partially observable environments, world models need to possess long-term memory. However, state-of-the-art MBRL agents, such as Dreamer, predominantly employ recurrent neural networks (RNNs) as their world model backbone, which have limited memory capacity. In this paper, we seek to explore alternative world model backbones for improving long-term memory. In particular, we investigate the effectiveness of Transformers and Structured State Space Sequence (S4) models, motivated by their remarkable ability to capture long-range dependencies in low-dimensional sequences and their complementary strengths. We propose S4WM, the first world model compatible with parallelizable SSMs including S4 and its variants. By incorporating latent variable modeling, S4WM can efficiently generate high-dimensional image sequences through latent imagination. Furthermore, we extensively compare RNN-, Transformer-, and S4-based world models across four sets of environments, which we have tailored to assess crucial memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning. Our findings demonstrate that S4WM outperforms Transformer-based world models in terms of long-term memory, while exhibiting greater efficiency during training and imagination. These results pave the way for the development of stronger MBRL agents",
    "checked": true,
    "id": "6be311f44289cfd62456ae86204aa86fa81effc5",
    "semantic_title": "facing off world model backbones: rnns, transformers, and s4",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=rUFckPrzXR": {
    "title": "Homotopy-based training of NeuralODEs for accurate dynamics discovery",
    "volume": "poster",
    "abstract": "Neural Ordinary Differential Equations (NeuralODEs) present an attractive way to extract dynamical laws from time series data, as they bridge neural networks with the differential equation-based modeling paradigm of the physical sciences. However, these models often display long training times and suboptimal results, especially for longer duration data. While a common strategy in the literature imposes strong constraints to the NeuralODE architecture to inherently promote stable model dynamics, such methods are ill-suited for dynamics discovery as the unknown governing equation is not guaranteed to satisfy the assumed constraints. In this paper, we develop a new training method for NeuralODEs, based on synchronization and homotopy optimization, that does not require changes to the model architecture. We show that synchronizing the model dynamics and the training data tames the originally irregular loss landscape, which homotopy optimization can then leverage to enhance training. Through benchmark experiments, we demonstrate our method achieves competitive or better training loss while often requiring less than half the number of training epochs compared to other model-agnostic techniques. Furthermore, models trained with our method display better extrapolation capabilities, highlighting the effectiveness of our method",
    "checked": true,
    "id": "52d5bc698684d676a407c879fc826d2d5596211b",
    "semantic_title": "homotopy-based training of neuralodes for accurate dynamics discovery",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=vpMBqdt9Hl": {
    "title": "Combinatorial Optimization with Policy Adaptation using Latent Space Search",
    "volume": "poster",
    "abstract": "Combinatorial Optimization underpins many real-world applications and yet, designing performant algorithms to solve these complex, typically NP-hard, problems remains a significant research challenge. Reinforcement Learning (RL) provides a versatile framework for designing heuristics across a broad spectrum of problem domains. However, despite notable progress, RL has not yet supplanted industrial solvers as the go-to solution. Current approaches emphasize pre-training heuristics that construct solutions, but often rely on search procedures with limited variance, such as stochastically sampling numerous solutions from a single policy, or employing computationally expensive fine-tuning of the policy on individual problem instances. Building on the intuition that performant search at inference time should be anticipated during pre-training, we propose COMPASS, a novel RL approach that parameterizes a distribution of diverse and specialized policies conditioned on a continuous latent space. We evaluate COMPASS across three canonical problems - Travelling Salesman, Capacitated Vehicle Routing, and Job-Shop Scheduling - and demonstrate that our search strategy (i) outperforms state-of-the-art approaches in 9 out of 11 standard benchmarking tasks and (ii) generalizes better, surpassing all other approaches on a set of 18 procedurally transformed instance distributions",
    "checked": true,
    "id": "112b25f0116b461810ae042c9995b495470e3324",
    "semantic_title": "combinatorial optimization with policy adaptation using latent space search",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y44NurSDjq": {
    "title": "Quantum Bayesian Optimization",
    "volume": "poster",
    "abstract": "Kernelized bandits, also known as Bayesian optimization (BO), has been a prevalent method for optimizing complicated black-box reward functions. Various BO algorithms have been theoretically shown to enjoy upper bounds on their cumulative regret which are sub-linear in the number $T$ of iterations, and a regret lower bound of $\\Omega(\\sqrt{T})$ has been derived which represents the unavoidable regrets for any classical BO algorithm. Recent works on quantum bandits have shown that with the aid of quantum computing, it is possible to achieve tighter regret upper bounds better than their corresponding classical lower bounds. However, these works are restricted to either multi-armed or linear bandits, and are hence not able to solve sophisticated real-world problems with non-linear reward functions. To this end, we introduce the quantum-Gaussian process-upper confidence bound (Q-GP-UCB) algorithm. To the best of our knowledge, our Q-GP-UCB is the first BO algorithm able to achieve a regret upper bound of $\\mathcal{O}(\\text{poly}\\log T)$, which is significantly smaller than its regret lower bound of $\\Omega(\\sqrt{T})$ in the classical setting. Moreover, thanks to our novel analysis of the confidence ellipsoid, our Q-GP-UCB with the linear kernel achieves a smaller regret than the quantum linear UCB algorithm from the previous work. We use simulations, as well as an experiment using a real quantum computer, to verify that the theoretical quantum speedup achieved by our Q-GP-UCB is also potentially relevant in practice",
    "checked": true,
    "id": "db81a05dd29b9e4df94df3d445ffec161d4748d4",
    "semantic_title": "quantum bayesian optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=IyTArtpuCK": {
    "title": "Assumption violations in causal discovery and the robustness of score matching",
    "volume": "poster",
    "abstract": "When domain knowledge is limited and experimentation is restricted by ethical, financial, or time constraints, practitioners turn to observational causal discovery methods to recover the causal structure, exploiting the statistical properties of their data. Because causal discovery without further assumptions is an ill-posed problem, each algorithm comes with its own set of usually untestable assumptions, some of which are hard to meet in real datasets. Motivated by these considerations, this paper extensively benchmarks the empirical performance of recent causal discovery methods on observational _iid_ data generated under different background conditions, allowing for violations of the critical assumptions required by each selected approach. Our experimental findings show that score matching-based methods demonstrate surprising performance in the false positive and false negative rate of the inferred graph in these challenging scenarios, and we provide theoretical insights into their performance. This work is also the first effort to benchmark the stability of causal discovery algorithms with respect to the values of their hyperparameters. Finally, we hope this paper will set a new standard for the evaluation of causal discovery methods and can serve as an accessible entry point for practitioners interested in the field, highlighting the empirical implications of different algorithm choices",
    "checked": true,
    "id": "8829483527c0bd1e9161a1483f299b54313cfb06",
    "semantic_title": "assumption violations in causal discovery and the robustness of score matching",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Ncb0MvVqRV": {
    "title": "Minimum Description Length and Generalization Guarantees for Representation Learning",
    "volume": "poster",
    "abstract": "A major challenge in designing efficient statistical supervised learning algorithms is finding representations that perform well not only on available training samples but also on unseen data. While the study of representation learning has spurred much interest, most existing such approaches are heuristic; and very little is known about theoretical generalization guarantees. For example, the information bottleneck method seeks a good generalization by finding a minimal description of the input that is maximally informative about the label variable, where minimality and informativeness are both measured by Shannon's mutual information. In this paper, we establish a compressibility framework that allows us to derive upper bounds on the generalization error of a representation learning algorithm in terms of the \"Minimum Description Length'' (MDL) of the labels or the latent variables (representations). Rather than the mutual information between the encoder's input and the representation, which is often believed to reflect the algorithm's generalization capability in the related literature but in fact, falls short of doing so, our new bounds involve the \"multi-letter\" relative entropy between the distribution of the representations (or labels) of the training and test sets and a fixed prior. In particular, these new bounds reflect the structure of the encoder and are not vacuous for deterministic algorithms. Our compressibility approach, which is information-theoretic in nature, builds upon that of Blum-Langford for PAC-MDL bounds and introduces two essential ingredients: block-coding and lossy-compression. The latter allows our approach to subsume the so-called geometrical compressibility as a special case. To the best knowledge of the authors, the established generalization bounds are the first of their kind for Information Bottleneck type encoders and representation learning. Finally, we partly exploit the theoretical results by introducing a new data-dependent prior. Numerical simulations illustrate the advantages of well-chosen such priors over classical priors used in IB",
    "checked": false,
    "id": "41bba26e8b607d1c0be9fb494c545c233d51a887",
    "semantic_title": "minimum description length control",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=SFfOt1oDsX": {
    "title": "Graph Convolutional Kernel Machine versus Graph Convolutional Networks",
    "volume": "poster",
    "abstract": "Graph convolutional networks (GCN) with one or two hidden layers have been widely used in handling graph data that are prevalent in various disciplines. Many studies showed that the gain of making GCNs deeper is tiny or even negative. This implies that the complexity of graph data is often limited and shallow models are often sufficient to extract expressive features for various tasks such as node classification. Therefore, in this work, we present a framework called graph convolutional kernel machine (GCKM) for graph-based machine learning. GCKMs are built upon kernel functions integrated with graph convolution. An example is the graph convolutional kernel support vector machine (GCKSVM) for node classification, for which we analyze the generalization error bound and discuss the impact of the graph structure. Compared to GCNs, GCKMs require much less effort in architecture design, hyperparameter tuning, and optimization. More importantly, GCKMs are guaranteed to obtain globally optimal solutions and have strong generalization ability and high interpretability. GCKMs are composable, can be extended to large-scale data, and are applicable to various tasks (e.g., node or graph classification, clustering, feature extraction, dimensionality reduction). The numerical results on benchmark datasets show that, besides the aforementioned advantages, GCKMs have at least competitive accuracy compared to GCNs",
    "checked": false,
    "id": "9e19f942e1babecf5526b3969f3f18747993a727",
    "semantic_title": "evolution-driven randomized graph convolutional networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=zQ4yraDiRe": {
    "title": "Multi-scale Diffusion Denoised Smoothing",
    "volume": "poster",
    "abstract": "Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple \"denoise-and-classify\" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we present scalable methods to address the current trade-off between certified robustness and accuracy in denoised smoothing. Our key idea is to \"selectively\" apply smoothing among multiple noise scales, coined multi-scale smoothing, which can be efficiently implemented with a single diffusion model. This approach also suggests a new objective to compare the collective robustness of multi-scale smoothed classifiers, and questions which representation of diffusion model would maximize the objective. To address this, we propose to further fine-tune diffusion model (a) to perform consistent denoising whenever the original image is recoverable, but (b) to generate rather diverse outputs otherwise. Our experiments show that the proposed multi-scale smoothing scheme, combined with diffusion fine-tuning, not only allows strong certified robustness at high noise scales but also maintains accuracy close to non-smoothed classifiers. Code is available at https://github.com/jh-jeong/smoothing-multiscale",
    "checked": true,
    "id": "c6cb3c55ea5597b0cd8dbdbf1052f2f8b23d0a53",
    "semantic_title": "multi-scale diffusion denoised smoothing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qUlpDjYnsp": {
    "title": "Multi-resolution Spectral Coherence for Graph Generation with Score-based Diffusion",
    "volume": "poster",
    "abstract": "Successful graph generation depends on the accurate estimation of the joint distribution of graph components such as nodes and edges from training data. While recent deep neural networks have demonstrated sampling of realistic graphs together with diffusion models, however, they still suffer from oversmoothing problems which are inherited from conventional graph convolution and thus high-frequency characteristics of nodes and edges become intractable. To overcome such issues and generate graphs with high fidelity, this paper introduces a novel approach that captures the dependency between nodes and edges at multiple resolutions in the spectral space. By modeling the joint distribution of node and edge signals in a shared graph wavelet space, together with a score-based diffusion model, we propose a Wavelet Graph Diffusion Model (Wave-GD) which lets us sample synthetic graphs with real-like frequency characteristics of nodes and edges. Experimental results on four representative benchmark datasets validate the superiority of the Wave-GD over existing approaches, highlighting its potential for a wide range of applications that involve graph data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xj4LJiXvlX": {
    "title": "Batch Bayesian Optimization For Replicable Experimental Design",
    "volume": "poster",
    "abstract": "Many real-world experimental design problems (a) evaluate multiple experimental conditions in parallel and (b) replicate each condition multiple times due to large and heteroscedastic observation noise. Given a fixed total budget, this naturally induces a trade-off between evaluating more unique conditions while replicating each of them fewer times vs. evaluating fewer unique conditions and replicating each more times. Moreover, in these problems, practitioners may be risk-averse and hence prefer an input with both good average performance and small variability. To tackle both challenges, we propose the Batch Thompson Sampling for Replicable Experimental Design (BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and BTS-RED-Unknown algorithms, for, respectively, known and unknown noise variance, choose the number of replications adaptively rather than deterministically such that an input with a larger noise variance is replicated more times. As a result, despite the noise heteroscedasticity, both algorithms enjoy a theoretical guarantee and are asymptotically no-regret. Our Mean-Var-BTS-RED algorithm aims at risk-averse optimization and is also asymptotically no-regret. We also show the effectiveness of our algorithms in two practical real-world applications: precision agriculture and AutoML",
    "checked": true,
    "id": "69f711ebe8f5ad0a3d79a627af4f0686d0bfe99b",
    "semantic_title": "batch bayesian optimization for replicable experimental design",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z7Cz9un2Fy": {
    "title": "NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks",
    "volume": "poster",
    "abstract": "While multi-exit neural networks are regarded as a promising solution for making efficient inference via early exits, combating adversarial attacks remains a challenging problem. In multi-exit networks, due to the high dependency among different submodels, an adversarial example targeting a specific exit not only degrades the performance of the target exit but also reduces the performance of all other exits concurrently. This makes multi-exit networks highly vulnerable to simple adversarial attacks. In this paper, we propose NEO-KD, a knowledge-distillation-based adversarial training strategy that tackles this fundamental challenge based on two key contributions. NEO-KD first resorts to neighbor knowledge distillation to guide the output of the adversarial examples to tend to the ensemble outputs of neighbor exits of clean data. NEO-KD also employs exit-wise orthogonal knowledge distillation for reducing adversarial transferability across different submodels. The result is a significantly improved robustness against adversarial attacks. Experimental results on various datasets/models show that our method achieves the best adversarial accuracy with reduced computation budgets, compared to the baselines relying on existing adversarial training or knowledge distillation techniques for multi-exit networks",
    "checked": true,
    "id": "5a65f8c083449ee4b16a2c28c731062df4606063",
    "semantic_title": "neo-kd: knowledge-distillation-based adversarial training for robust multi-exit neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pbpk9jUzAi": {
    "title": "Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",
    "volume": "poster",
    "abstract": "While adversarial training has been extensively studied for ResNet architectures and low resolution datasets like CIFAR-10, much less is known for ImageNet. Given the recent debate about whether transformers are more robust than convnets, we revisit adversarial training on ImageNet comparing ViTs and ConvNeXts. Extensive experiments show that minor changes in architecture, most notably replacing PatchStem with ConvStem, and training scheme have a significant impact on the achieved robustness. These changes not only increase robustness in the seen $\\ell_\\infty$-threat model, but even more so improve generalization to unseen $\\ell_1/\\ell_2$-attacks. Our modified ConvNeXt, ConvNeXt + ConvStem, yields the most robust $\\ell_\\infty$-models across different ranges of model parameters and FLOPs, while our ViT + ConvStem yields the best generalization to unseen threat models",
    "checked": true,
    "id": "a2c041f9c32ce382735648f584cf4332ff0a6e33",
    "semantic_title": "revisiting adversarial training for imagenet: architectures, training and generalization across threat models",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=lmXNcKhj4c": {
    "title": "Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning",
    "volume": "poster",
    "abstract": "Reinforcement learning (RL) agents have long sought to approach the efficiency of human learning. Humans are great observers who can learn by aggregating external knowledge from various sources, including observations from others' policies of attempting a task. Prior studies in RL have incorporated external knowledge policies to help agents improve sample efficiency. However, it remains non-trivial to perform arbitrary combinations and replacements of those policies, an essential feature for generalization and transferability. In this work, we present Knowledge-Grounded RL (KGRL), an RL paradigm fusing multiple knowledge policies and aiming for human-like efficiency and flexibility. We propose a new actor architecture for KGRL, Knowledge-Inclusive Attention Network (KIAN), which allows free knowledge rearrangement due to embedding-based attentive action prediction. KIAN also addresses entropy imbalance, a problem arising in maximum entropy KGRL that hinders an agent from efficiently exploring the environment, through a new design of policy distributions. The experimental results demonstrate that KIAN outperforms alternative methods incorporating external knowledge policies and achieves efficient and flexible learning. Our implementation is available at https://github.com/Pascalson/KGRL.git",
    "checked": true,
    "id": "579cd3b80cb633fd23ff6d6b25dd754a197b3e9e",
    "semantic_title": "flexible attention-based multi-policy fusion for efficient deep reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=9Tx2znbyTm": {
    "title": "Diffused Task-Agnostic Milestone Planner",
    "volume": "poster",
    "abstract": "Addressing decision-making problems using sequence modeling to predict future trajectories shows promising results in recent years. In this paper, we take a step further to leverage the sequence predictive method in wider areas such as long-term planning, vision-based control, and multi-task decision-making. To this end, we propose a method to utilize a diffusion-based generative sequence model to plan a series of milestones in a latent space and to have an agent to follow the milestones to accomplish a given task. The proposed method can learn control-relevant, low-dimensional latent representations of milestones, which makes it possible to efficiently perform long-term planning and vision-based control. Furthermore, our approach exploits generation flexibility of the diffusion model, which makes it possible to plan diverse trajectories for multi-task decision-making. We demonstrate the proposed method across offline reinforcement learning (RL) benchmarks and an visual manipulation environment. The results show that our approach outperforms offline RL methods in solving long-horizon, sparse-reward tasks and multi-task problems, while also achieving the state-of-the-art performance on the most challenging vision-based manipulation benchmark",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EETqXXdqkI": {
    "title": "PICProp: Physics-Informed Confidence Propagation for Uncertainty Quantification",
    "volume": "poster",
    "abstract": "Standard approaches for uncertainty quantification in deep learning and physics-informed learning have persistent limitations. Indicatively, strong assumptions regarding the data likelihood are required, the performance highly depends on the selection of priors, and the posterior can be sampled only approximately, which leads to poor approximations because of the associated computational cost. This paper introduces and studies confidence interval (CI) estimation for deterministic partial differential equations as a novel problem. That is, to propagate confidence, in the form of CIs, from data locations to the entire domain with probabilistic guarantees. We propose a method, termed Physics-Informed Confidence Propagation (PICProp), based on bi-level optimization to compute a valid CI without making heavy assumptions. We provide a theorem regarding the validity of our method, and computational experiments, where the focus is on physics-informed learning. Code is available at https://github.com/ShenQianli/PICProp",
    "checked": true,
    "id": "49f5066cf3a4e7a3a15712ab6d2868a80d330286",
    "semantic_title": "picprop: physics-informed confidence propagation for uncertainty quantification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=strvrjSi3C": {
    "title": "Riemannian SAM: Sharpness-Aware Minimization on Riemannian Manifolds",
    "volume": "poster",
    "abstract": "Contemporary advances in the field of deep learning have embarked upon an exploration of the underlying geometric properties of data, thus encouraging the investigation of techniques that consider general manifolds, for example, hyperbolic or orthogonal neural networks. However, the optimization algorithms for training such geometric deep learning models still remain highly under-explored. In this paper, we introduce Riemannian SAM by generalizing conventional Euclidean SAM to Riemannian manifolds. We successfully formulate the sharpness-aware minimization on Riemannian manifolds, leading to one of a novel instantiation, Lorentz SAM. In addition, SAM variants proposed in previous studies such as Fisher SAM can be derived as special examples under our Riemannian SAM framework. We provide the convergence analysis of Riemannian SAM under a less aggressively decaying ascent learning rate than Euclidean SAM. Our analysis serves as a theoretically sound contribution encompassing a diverse range of manifolds, also providing the guarantees for SAM variants such as Fisher SAM, whose convergence analyses are absent. Lastly, we illustrate the superiority of Riemannian SAM in terms of generalization over previous Riemannian optimization algorithms through experiments on knowledge graph completion and machine translation tasks",
    "checked": false,
    "id": "1d810318c5ee19995be8930273f4ad63b1f0d480",
    "semantic_title": "rsam: learning on manifolds with riemannian sharpness-aware minimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=LdvVd0bNyO": {
    "title": "ODE-based Recurrent Model-free Reinforcement Learning for POMDPs",
    "volume": "poster",
    "abstract": "Neural ordinary differential equations (ODEs) are widely recognized as the standard for modeling physical mechanisms, which help to perform approximate inference in unknown physical or biological environments. In partially observable (PO) environments, how to infer unseen information from raw observations puzzled the agents. By using a recurrent policy with a compact context, context-based reinforcement learning provides a flexible way to extract unobservable information from historical transitions. To help the agent extract more dynamics-related information, we present a novel ODE-based recurrent model combines with model-free reinforcement learning (RL) framework to solve partially observable Markov decision processes (POMDPs). We experimentally demonstrate the efficacy of our methods across various PO continuous control and meta-RL tasks. Furthermore, our experiments illustrate that our method is robust against irregular observations, owing to the ability of ODEs to model irregularly-sampled time series",
    "checked": true,
    "id": "f42c709b401553a2639c1507d4028417e8693d60",
    "semantic_title": "ode-based recurrent model-free reinforcement learning for pomdps",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=awIpKpwTwF": {
    "title": "LEACE: Perfect linear concept erasure in closed form",
    "volume": "poster",
    "abstract": "Concept erasure aims to remove specified features from a representation. It can improve fairness (e.g. preventing a classifier from using gender or race) and interpretability (e.g. removing a concept to observe changes in model behavior). We introduce LEAst-squares Concept Erasure (LEACE), a closed-form method which provably prevents all linear classifiers from detecting a concept while changing the representation as little as possible, as measured by a broad class of norms. We apply LEACE to large language models with a novel procedure called concept scrubbing, which erases target concept information from _every_ layer in the network. We demonstrate our method on two tasks: measuring the reliance of language models on part-of-speech information, and reducing gender bias in BERT embeddings. Our code is available at https://github.com/EleutherAI/concept-erasure",
    "checked": true,
    "id": "22ae20f20d0b4e6451ae41cc76e58a9221e90df9",
    "semantic_title": "leace: perfect linear concept erasure in closed form",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=NXLjaYdgaL": {
    "title": "Intra-Modal Proxy Learning for Zero-Shot Visual Categorization with CLIP",
    "volume": "poster",
    "abstract": "Vision-language pre-training methods, e.g., CLIP, demonstrate an impressive zero-shot performance on visual categorizations with the class proxy from the text embedding of the class name. However, the modality gap between the text and vision space can result in a sub-optimal performance. We theoretically show that the gap cannot be reduced sufficiently by minimizing the contrastive loss in CLIP and the optimal proxy for vision tasks may reside only in the vision space. Therefore, given unlabeled target vision data, we propose to learn the vision proxy directly with the help from the text proxy for zero-shot transfer. Moreover, according to our theoretical analysis, strategies are developed to further refine the pseudo label obtained by the text proxy to facilitate the intra-modal proxy learning (InMaP) for vision. Experiments on extensive downstream tasks confirm the effectiveness and efficiency of our proposal. Concretely, InMaP can obtain the vision proxy within one minute on a single GPU while improving the zero-shot accuracy from $77.02\\%$ to $80.21\\%$ on ImageNet with ViT-L/14@336 pre-trained by CLIP",
    "checked": true,
    "id": "43abdd72a50706ca76e77a2d613a7435324f4997",
    "semantic_title": "intra-modal proxy learning for zero-shot visual categorization with clip",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m11TbsaQQI": {
    "title": "Efficient Hyper-parameter Optimization with Cubic Regularization",
    "volume": "poster",
    "abstract": "As hyper-parameters are ubiquitous and can significantly affect the model performance, hyper-parameter optimization is extremely important in machine learning. In this paper, we consider a sub-class of hyper-parameter optimization problems, where the hyper-gradients are not available. Such problems frequently appear when the performance metric is non-differentiable or the hyper-parameter is not continuous. However, existing algorithms, like Bayesian optimization and reinforcement learning, often get trapped in local optimals with poor performance. To address the above limitations, we propose to use cubic regularization to accelerate convergence and avoid saddle points. First, we adopt stochastic relaxation, which allows obtaining gradient and Hessian information without hyper-gradients. Then, we exploit the rich curvature information by cubic regularization. Theoretically, we prove that the proposed method can converge to approximate second-order stationary points, and the convergence is also guaranteed when the lower-level problem is inexactly solved. Experiments on synthetic and real-world data demonstrate the effectiveness of our proposed method",
    "checked": false,
    "id": "26bd86d04fc5d741d36868ff4aceeb65db1be441",
    "semantic_title": "lifelong hyper-policy optimization with multiple importance sampling regularization",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=6zyFgr1b8Q": {
    "title": "Causes and Effects of Unanticipated Numerical Deviations in Neural Network Inference Frameworks",
    "volume": "poster",
    "abstract": "Hardware-specific optimizations in machine learning (ML) frameworks can cause numerical deviations of inference results. Quite surprisingly, despite using a fixed trained model and fixed input data, inference results are not consistent across platforms, and sometimes not even deterministic on the same platform. We study the causes of these numerical deviations for convolutional neural networks (CNN) on realistic end-to-end inference pipelines and in isolated experiments. Results from 75 distinct platforms suggest that the main causes of deviations on CPUs are differences in SIMD use, and the selection of convolution algorithms at runtime on GPUs. We link the causes and propagation effects to properties of the ML model and evaluate potential mitigations. We make our research code publicly available",
    "checked": true,
    "id": "e32feea21029b43cda408e360622c150c0898b9f",
    "semantic_title": "causes and effects of unanticipated numerical deviations in neural network inference frameworks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2f0dlMZlNb": {
    "title": "Effective Targeted Attacks for Adversarial Self-Supervised Learning",
    "volume": "poster",
    "abstract": "Recently, unsupervised adversarial training (AT) has been highlighted as a means of achieving robustness in models without any label information. Previous studies in unsupervised AT have mostly focused on implementing self-supervised learning (SSL) frameworks, which maximize the instance-wise classification loss to generate adversarial examples. However, we observe that simply maximizing the self-supervised training loss with an untargeted adversarial attack often results in generating ineffective adversaries that may not help improve the robustness of the trained model, especially for non-contrastive SSL frameworks without negative examples. To tackle this problem, we propose a novel positive mining for targeted adversarial attack to generate effective adversaries for adversarial SSL frameworks. Specifically, we introduce an algorithm that selects the most confusing yet similar target example for a given instance based on entropy and similarity, and subsequently perturbs the given instance towards the selected target. Our method demonstrates significant enhancements in robustness when applied to non-contrastive SSL frameworks, and less but consistent robustness improvements with contrastive SSL frameworks, on the benchmark datasets",
    "checked": true,
    "id": "bdb1ea6d9d433e2be935d25a0dbe70145a7f21f5",
    "semantic_title": "effective targeted attacks for adversarial self-supervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ge8Mhggq0z": {
    "title": "May the Force be with You: Unified Force-Centric Pre-Training for 3D Molecular Conformations",
    "volume": "poster",
    "abstract": "Recent works have shown the promise of learning pre-trained models for 3D molecular representation. However, existing pre-training models focus predominantly on equilibrium data and largely overlook off-equilibrium conformations. It is challenging to extend these methods to off-equilibrium data because their training objective relies on assumptions of conformations being the local energy minima. We address this gap by proposing a force-centric pretraining model for 3D molecular conformations covering both equilibrium and off-equilibrium data. For off-equilibrium data, our model learns directly from their atomic forces. For equilibrium data, we introduce zero-force regularization and forced-based denoising techniques to approximate near-equilibrium forces. We obtain a unified pre-trained model for 3D molecular representation with over 15 million diverse conformations. Experiments show that, with our pre-training objective, we increase forces accuracy by around 3 times compared to the un-pre-trained Equivariant Transformer model. By incorporating regularizations on equilibrium data, we solved the problem of unstable MD simulations in vanilla Equivariant Transformers, achieving state-of-the-art simulation performance with 2.45 times faster inference time than NequIP. As a powerful molecular encoder, our pre-trained model achieves on-par performance with state-of-the-art property prediction tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FAGY52HbyV": {
    "title": "Debiased and Denoised Entity Recognition from Distant Supervision",
    "volume": "poster",
    "abstract": "While distant supervision has been extensively explored and exploited in NLP tasks like named entity recognition, a major obstacle stems from the inevitable noisy distant labels tagged unsupervisedly. A few past works approach this problem by adopting a self-training framework with a sample-selection mechanism. In this work, we innovatively identify two types of biases that were omitted by prior work, and these biases lead to inferior performance of the distant-supervised NER setup. First, we characterize the noise concealed in the distant labels as highly structural rather than fully randomized. Second, the self-training framework would ubiquitously introduce an inherent bias that causes erroneous behavior in both sample selection and eventually prediction. To cope with these problems, we propose a novel self-training framework, dubbed DesERT. This framework augments the conventional NER predicative pathway to a dual form that effectively adapts the sample-selection process to conform to its innate distributional-bias structure. The other crucial component of DesERT composes a debiased module aiming to enhance the token representations, hence the quality of the pseudo-labels. Extensive experiments are conducted to validate the DesERT. The results show that our framework establishes a new state-of-art performance, it achieves a +2.22% average F1 score improvement on five standardized benchmarking datasets. Lastly, DesERT demonstrates its effectiveness under a new DSNER benchmark where additional distant supervision comes from the ChatGPT model",
    "checked": false,
    "id": "20af1061f27bb44dab8e09aeb80c07efc5e23ac7",
    "semantic_title": "improving distantly-supervised named entity recognition with self-collaborative denoising learning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=2EVTB1idyR": {
    "title": "Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning",
    "volume": "poster",
    "abstract": "In this paper, we prove state-of-the-art Bayesian regret bounds for Thompson Sampling in reinforcement learning in a multitude of settings. We present a refined analysis of the information ratio, and show an upper bound of order $\\widetilde{O}(H\\sqrt{d_{l_1}T})$ in the time inhomogeneous reinforcement learning problem where $H$ is the episode length and $d_{l_1}$ is the Kolmogorov $l_1-$dimension of the space of environments. We then find concrete bounds of $d_{l_1}$ in a variety of settings, such as tabular, linear and finite mixtures, and discuss how our results improve the state-of-the-art",
    "checked": true,
    "id": "9796b9e6dfbbbbd274a999e31701206e6ee3814e",
    "semantic_title": "improved bayesian regret bounds for thompson sampling in reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tJN664ZNVG": {
    "title": "Offline RL with Discrete Proxy Representations for Generalizability in POMDPs",
    "volume": "poster",
    "abstract": "Offline Reinforcement Learning (RL) has demonstrated promising results in various applications by learning policies from previously collected datasets, reducing the need for online exploration and interactions. However, real-world scenarios usually involve partial observability, which brings crucial challenges of the deployment of offline RL methods: i) the policy trained on data with full observability is not robust against the masked observations during execution, and ii) the information of which parts of observations are masked is usually unknown during training. In order to address these challenges, we present Offline RL with DiscrEte pRoxy representations (ORDER), a probabilistic framework which leverages novel state representations to improve the robustness against diverse masked observabilities. Specifically, we propose a discrete representation of the states and use a proxy representation to recover the states from masked partial observable trajectories. The training of ORDER can be compactly described as the following three steps. i) Learning the discrete state representations on data with full observations, ii) Training the decision module based on the discrete representations, and iii) Training the proxy discrete representations on the data with various partial observations, aligning with the discrete representations. We conduct extensive experiments to evaluate ORDER, showcasing its effectiveness in offline RL for diverse partially observable scenarios and highlighting the significance of discrete proxy representations in generalization performance. ORDER is a flexible framework to employ any offline RL algorithms and we hope that ORDER can pave the way for the deployment of RL policy against various partial observabilities in the real world",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fezV91IJIo": {
    "title": "Analysis of Variance of Multiple Causal Networks",
    "volume": "poster",
    "abstract": "Constructing a directed cyclic graph (DCG) is challenged by both algorithmic difficulty and computational burden. Comparing multiple DCGs is even more difficult, compounded by the need of identifying variational causalities across graphs. We propose to unify multiple DCGs with a single structural model and develop a limited-information-based method to simultaneously construct multiple networks and infer their disparities, which can be visualized by appropriate correspondence analysis. The algorithm provides DCGs with robust non-asymptotic theoretical properties. It is designed with two sequential stages, each of which involves parallel computation tasks that are scalable to the network complexity. Taking advantage of high-performance clusters, our method makes it possible to evaluate the statistical significance of DCGs using the bootstrap method. We demonstrated the effectiveness of our method by applying it to synthetic and real datasets",
    "checked": false,
    "id": "695c3bf981a5d1d2fe60db9967acb239a03bedcb",
    "semantic_title": "only relative speed matters",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vNsdFwjPtL": {
    "title": "Suggesting Variable Order for Cylindrical Algebraic Decomposition via Reinforcement Learning",
    "volume": "poster",
    "abstract": "Cylindrical Algebraic Decomposition (CAD) is one of the pillar algorithms of symbolic computation, and its worst-case complexity is double exponential to the number of variables. Researchers found that variable order dramatically affects efficiency and proposed various heuristics. The existing learning-based methods are all supervised learning methods that cannot cope with diverse polynomial sets. This paper proposes two Reinforcement Learning (RL) approaches combined with Graph Neural Networks (GNN) for Suggesting Variable Order (SVO). One is GRL-SVO(UP), a branching heuristic integrated with CAD. The other is GRL-SVO(NUP), a fast heuristic providing a total order directly. We generate a random dataset and collect a real-world dataset from SMT-LIB. The experiments show that our approaches outperform state-of-the-art learning-based heuristics and are competitive with the best expert-based heuristics. Interestingly, our models show a strong generalization ability, working well on various datasets even if they are only trained on a 3-var random dataset. The source code and data are available at https://github.com/dongyuhang22/GRL-SVO",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1DTCoyAFiV": {
    "title": "Cascading Contextual Assortment Bandits",
    "volume": "poster",
    "abstract": "We present a new combinatorial bandit model, the \\textit{cascading contextual assortment bandit}. This model serves as a generalization of both existing cascading bandits and assortment bandits, broadening their applicability in practice. For this model, we propose our first UCB bandit algorithm, UCB-CCA. We prove that this algorithm achieves a $T$-step regret upper-bound of $\\tilde{\\mathcal{O}}(\\frac{1}{\\kappa}d\\sqrt{T})$, sharper than existing bounds for cascading contextual bandits by eliminating dependence on cascade length $K$. To improve the dependence on problem-dependent constant $\\kappa$, we introduce our second algorithm, UCB-CCA+, which leverages a new Bernstein-type concentration result. This algorithm achieves $\\tilde{\\mathcal{O}}(d\\sqrt{T})$ without dependence on $\\kappa$ in the leading term. We substantiate our theoretical claims with numerical experiments, demonstrating the practical efficacy of our proposed methods",
    "checked": false,
    "id": "f3811cda345099e71ad47c07774aa2f99d7b834b",
    "semantic_title": "exposure-aware recommendation using contextual bandits",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=3NWWgB2SuF": {
    "title": "Undirected Probabilistic Model for Tensor Decomposition",
    "volume": "poster",
    "abstract": "Tensor decompositions (TDs) serve as a powerful tool for analyzing multiway data. Traditional TDs incorporate prior knowledge about the data into the model, such as a directed generative process from latent factors to observations. In practice, selecting proper structural or distributional assumptions beforehand is crucial for obtaining a promising TD representation. However, since such prior knowledge is typically unavailable in real-world applications, choosing an appropriate TD model can be challenging. This paper aims to address this issue by introducing a flexible TD framework that discards the structural and distributional assumptions, in order to learn as much information from the data. Specifically, we construct a TD model that captures the joint probability of the data and latent tensor factors through a deep energy-based model (EBM). Neural networks are then employed to parameterize the joint energy function of tensor factors and tensor entries. The flexibility of EBM and neural networks enables the learning of underlying structures and distributions. In addition, by designing the energy function, our model unifies the learning process of different types of tensors, such as static tensors and dynamic tensors with time stamps. The resulting model presents a doubly intractable nature due to the presence of latent tensor factors and the unnormalized probability function. To efficiently train the model, we derive a variational upper bound of the conditional noise-contrastive estimation objective that learns the unnormalized joint probability by distinguishing data from conditional noises. We show advantages of our model on both synthetic and several real-world datasets",
    "checked": false,
    "id": "23ca8dfa61866a926aaed66a873c5cbd29b965a6",
    "semantic_title": "probabilistic tensor decomposition of neural population spiking activity",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=3gxiOEf2D6": {
    "title": "Differentiable and Stable Long-Range Tracking of Multiple Posterior Modes",
    "volume": "poster",
    "abstract": "Particle filters flexibly represent multiple posterior modes nonparametrically, via a collection of weighted samples, but have classically been applied to tracking problems with known dynamics and observation likelihoods. Such generative models may be inaccurate or unavailable for high-dimensional observations like images. We instead leverage training data to discriminatively learn particle-based representations of uncertainty in latent object states, conditioned on arbitrary observations via deep neural network encoders. While prior discriminative particle filters have used heuristic relaxations of discrete particle resampling, or biased learning by truncating gradients at resampling steps, we achieve unbiased and low-variance gradient estimates by representing posteriors as continuous mixture densities. Our theory and experiments expose dramatic failures of existing reparameterization-based estimators for mixture gradients, an issue we address via an importance-sampling gradient estimator. Unlike standard recurrent neural networks, our mixture density particle filter represents multimodal uncertainty in continuous latent states, improving accuracy and robustness. On a range of challenging tracking and robot localization problems, our approach achieves dramatic improvements in accuracy, will also showing much greater stability across multiple training runs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KffE8iXAw7": {
    "title": "Towards Optimal Effective Resistance Estimation",
    "volume": "poster",
    "abstract": "We provide new algorithms and conditional hardness for the problem of estimating effective resistances in $n$-node $m$-edge undirected, expander graphs. We provide an $\\widetilde{O}(m\\epsilon^{-1})$-time algorithm that produces with high probability, an $\\widetilde{O}(n\\epsilon^{-1})$-bit sketch from which the effective resistance between any pair of nodes can be estimated, to $(1 \\pm \\epsilon)$-multiplicative accuracy, in $\\widetilde{O}(1)$-time. Consequently, we obtain an $\\widetilde{O}(m\\epsilon^{-1})$-time algorithm for estimating the effective resistance of all edges in such graphs, improving (for sparse graphs) on the previous fastest runtimes of $\\widetilde{O}(m\\epsilon^{-3/2})$ [Chu et. al. 2018] and $\\widetilde{O}(n^2\\epsilon^{-1})$ [Jambulapati, Sidford, 2018] for general graphs and $\\widetilde{O}(m + n\\epsilon^{-2})$ for expanders [Li, Sachdeva 2022]. We complement this result by showing a conditional lower bound that a broad set of algorithms for computing such estimates of the effective resistances between all pairs of nodes require $\\widetilde{\\Omega}(n^2 \\epsilon^{-1/2})$-time, improving upon the previous best such lower bound of $\\widetilde{\\Omega}(n^2 \\epsilon^{-1/13})$ [Musco et. al. 2017]. Further, we leverage the tools underlying these results to obtain improved algorithms and conditional hardness for more general problems of sketching the pseudoinverse of positive semidefinite matrices and estimating functions of their eigenvalues",
    "checked": true,
    "id": "c9afd3867f53c7bc0e3547d1f1bc5dd3cf4ee3c7",
    "semantic_title": "towards optimal effective resistance estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9o6KQrklrE": {
    "title": "Geometric Transformer with Interatomic Positional Encoding",
    "volume": "poster",
    "abstract": "The widespread adoption of Transformer architectures in various data modalities has opened new avenues for the applications in molecular modeling. Nevertheless, it remains elusive that whether the Transformer-based architecture can do molecular modeling as good as equivariant GNNs. In this paper, by designing Interatomic Positional Encoding (IPE) that parameterizes atomic environments as Transformer's positional encodings, we propose Geoformer, a novel geometric Transformer to effectively model molecular structures for various molecular property prediction. We evaluate Geoformer on several benchmarks, including the QM9 dataset and the recently proposed Molecule3D dataset. Compared with both Transformers and equivariant GNN models, Geoformer outperforms the state-of-the-art (SoTA) algorithms on QM9, and achieves the best performance on Molecule3D for both random and scaffold splits. By introducing IPE, Geoformer paves the way for molecular geometric modeling based on Transformer architecture",
    "checked": false,
    "id": "a90030cab839032a7e3e504a9c0c4cfe9549eb7f",
    "semantic_title": "geometric transformer for end-to-end molecule properties prediction",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=R45A8eKcax": {
    "title": "Scaling MLPs: A Tale of Inductive Bias",
    "volume": "poster",
    "abstract": "In this work we revisit the most fundamental building block in deep learning, the multi-layer perceptron (MLP), and study the limits of its performance on vision tasks. Empirical insights into MLPs are important for multiple reasons. (1) Given the recent narrative \"less inductive bias is better\", popularized due to transformers eclipsing convolutional models, it is natural to explore the limits of this hypothesis. To that end, MLPs offer an ideal test bed, as they lack any vision-specific inductive bias. (2) MLPs have almost exclusively been the main protagonist in the deep learning theory literature due to their mathematical simplicity, serving as a proxy to explain empirical phenomena observed for more complex architectures. Surprisingly, experimental datapoints for MLPs are very difficult to find in the literature, especially when coupled with large pre-training protocols. This discrepancy between practice and theory is worrying: \\textit{Do MLPs reflect the empirical advances exhibited by practical models?} Or do theorists need to rethink the role of MLPs as a proxy? We provide insights into both these aspects. We show that the performance of MLPs drastically improves with scale (95% on CIFAR10, 82% on CIFAR100, 58% on ImageNet ReaL), highlighting that lack of inductive bias can indeed be compensated. We observe that MLPs mimic the behaviour of their modern counterparts faithfully, with some components in the learning setting however exhibiting stronger or unexpected behaviours. Due to their inherent computational efficiency, large pre-training experiments become more accessible for academic researchers. All of our experiments were run on a single GPU",
    "checked": true,
    "id": "61e608a70faefb8faaf92124c4a8a7a8bf1fe099",
    "semantic_title": "scaling mlps: a tale of inductive bias",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=Iq0DvhB4Kf": {
    "title": "Emergent and Predictable Memorization in Large Language Models",
    "volume": "poster",
    "abstract": "Memorization, or the tendency of large language models (LLMs) to output entire sequences from their training data verbatim, is a key concern for deploying language models. In particular, it is vital to minimize a model's memorization of sensitive datapoints such as those containing personal identifiable information (PII). The prevalence of such undesirable memorization can pose issues for model trainers, and may even require discarding an otherwise functional model. We therefore seek to predict which sequences will be memorized before a large model's full train-time by extrapolating the memorization behavior of lower-compute trial runs. We measure memorization in the Pythia model suite and plot scaling laws for forecasting memorization, allowing us to provide equi-compute recommendations to maximize the reliability (recall) of such predictions. We additionally provide further novel discoveries on the distribution of memorization scores across models and data. We release all code and data necessary to reproduce the results in this paper at https://github.com/EleutherAI/pythia",
    "checked": true,
    "id": "deb8f26509ae320fc975b32922416cb156c61bbd",
    "semantic_title": "emergent and predictable memorization in large language models",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=V5FNSilWiC": {
    "title": "Strategic Behavior in Two-sided Matching Markets with Prediction-enhanced Preference-formation",
    "volume": "poster",
    "abstract": "Two-sided matching markets have long existed to pair agents in the absence of regulated exchanges. A common example is school choice, where a matching mechanism uses student and school preferences to assign students to schools. In such settings, forming preferences is both difficult and critical. Prior work has suggested various prediction mechanisms that help agents make decisions about their preferences. Although often deployed together, these matching and prediction mechanisms are almost always analyzed separately. The present work shows that at the intersection of the two lies a previously unexplored type of strategic behavior: agents returning to the market (e.g., schools) can attack future predictions by interacting short-term non-optimally with their matches. Here, we first introduce this type of strategic behavior, which we call an adversarial interaction attack. Next, we construct a formal economic model that captures the feedback loop between prediction mechanisms designed to assist agents and the matching mechanism used to pair them. Finally, in a simplified setting, we prove that returning agents can benefit from using adversarial interaction attacks and gain progressively more as the trust in and accuracy of predictions increases. We also show that this attack increases inequality in the student population",
    "checked": false,
    "id": "580e930c08be764f99a56bc0e73f224537f34e02",
    "semantic_title": "incentives in two-sided matching markets with prediction-enhanced preference-formation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ih2yL7o2Gq": {
    "title": "Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization",
    "volume": "poster",
    "abstract": "We present a novel method for tuning the regularization hyper-parameter, $\\lambda$, of a ridge regression that is faster to compute than leave-one-out cross-validation (LOOCV) while yielding estimates of the regression parameters of equal, or particularly in the setting of sparse covariates, superior quality to those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from multiple and bad local minima for finite $n$ and thus requires the specification of a set of candidate $\\lambda$, which can fail to provide good solutions. In contrast, we show that the proposed method is guaranteed to find a unique optimal solution for large enough $n$, under relatively mild conditions, without requiring the specification of any difficult to determine hyper-parameters. This is based on a Bayesian formulation of ridge regression that we prove to have a unimodal posterior for large enough $n$, allowing for both the optimal $\\lambda$ and the regression coefficients to be jointly learned within an iterative expectation maximization (EM) procedure. Importantly, we show that by utilizing an appropriate preprocessing step, a single iteration of the main EM loop can be implemented in $O(\\min(n, p))$ operations, for input data with $n$ rows and $p$ columns. In contrast, evaluating a single value of $\\lambda$ using fast LOOCV costs $O(n \\min(n, p))$ operations when using the same preprocessing. This advantage amounts to an asymptotic improvement of a factor of $l$ for $l$ candidate values for $\\lambda$ (in the regime $q, p \\in O(\\sqrt{n})$ where $q$ is the number of regression targets)",
    "checked": true,
    "id": "0c74668384653c14cb58eb161af43155677451a3",
    "semantic_title": "bayes beats cross validation: efficient and accurate ridge regression via expectation maximization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gx20B4ItIw": {
    "title": "Emergent Communication for Rules Reasoning",
    "volume": "poster",
    "abstract": "Research on emergent communication between deep-learning-based agents has received extensive attention due to its inspiration for linguistics and artificial intelligence. However, previous attempts have hovered around emerging communication under perception-oriented environmental settings, that forces agents to describe low-level perceptual features intra image or symbol contexts. In this work, inspired by the classic human reasoning test (namely Raven's Progressive Matrix), we propose the Reasoning Game, a cognition-oriented environment that encourages agents to reason and communicate high-level rules, rather than perceived low-level contexts. Moreover, we propose 1) an unbiased dataset (namely rule-RAVEN) as a benchmark to avoid overfitting, 2) and a two-stage curriculum agent training method as a baseline for more stable convergence in the Reasoning Game, where contexts and semantics are bilaterally drifting. Experimental results show that, in the Reasoning Game, a semantically stable and compositional language emerges to solve reasoning problems. The emerged language helps agents apply the extracted rules to the generalization of unseen context attributes, and to the transfer between different context attributes or even tasks",
    "checked": true,
    "id": "9b0e74e86d698059ff683818b6b6d80e9c2bb50e",
    "semantic_title": "emergent communication for rules reasoning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zyhxRc9bew": {
    "title": "What is Flagged in Uncertainty Quantification? Latent Density Models for Uncertainty Categorization",
    "volume": "poster",
    "abstract": "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark",
    "checked": true,
    "id": "85e27aec760b3d16ab779e335fc195bc578d0840",
    "semantic_title": "what is flagged in uncertainty quantification? latent density models for uncertainty categorization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=SHVwG9yOEk": {
    "title": "Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach",
    "volume": "poster",
    "abstract": "The progress in hyperbolic neural networks (HNNs) research is hindered by their absence of inductive bias mechanisms, which are essential for generalizing to new tasks and facilitating scalable learning over large datasets. In this paper, we aim to alleviate these issues by learning generalizable inductive biases from the nodes' local subgraph and transfer them for faster learning over new subgraphs with a disjoint set of nodes, edges, and labels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph Meta Learner (H-GRAM), that, for the tasks of node classification and link prediction, learns transferable information from a set of support local subgraphs in the form of hyperbolic meta gradients and label hyperbolic protonets to enable faster learning over a query set of new tasks dealing with disjoint subgraphs. Furthermore, we show that an extension of our meta-learning framework also mitigates the scalability challenges seen in HNNs faced by existing approaches. Our comparative analysis shows that H-GRAM effectively learns and transfers information in multiple challenging few-shot settings compared to other state-of-the-art baselines. Additionally, we demonstrate that, unlike standard HNNs, our approach is able to scale over large graph datasets and improve performance over its Euclidean counterparts",
    "checked": true,
    "id": "883dab9410349f0660c6d6b05e4409525185f0c3",
    "semantic_title": "hyperbolic graph neural networks at scale: a meta learning approach",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aMjaEkkXJx": {
    "title": "The emergence of clusters in self-attention dynamics",
    "volume": "poster",
    "abstract": "Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time-dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. Using techniques from dynamical systems and partial differential equations, we show that type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. [ VSP`17 ] that leaders appear in a sequence of tokens when processed by Transformers",
    "checked": true,
    "id": "e5526fcee23b6dc7b7bf0d83607d88d12cf6baf2",
    "semantic_title": "the emergence of clusters in self-attention dynamics",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=XEUc1JegGt": {
    "title": "An Inductive Bias for Tabular Deep Learning",
    "volume": "poster",
    "abstract": "Deep learning methods have achieved state-of-the-art performance in most modeling tasks involving images, text and audio, however, they typically underperform tree-based methods on tabular data. In this paper, we hypothesize that a significant contributor to this performance gap is the interaction between irregular target functions resulting from the heterogeneous nature of tabular feature spaces, and the well-known tendency of neural networks to learn smooth functions. Utilizing tools from spectral analysis, we show that functions described by tabular datasets often have high irregularity, and that they can be smoothed by transformations such as scaling and ranking in order to improve performance. However, because these transformations tend to lose information or negatively impact the loss landscape during optimization, they need to be rigorously fine-tuned for each feature to achieve performance gains. To address these problems, we propose introducing frequency reduction as an inductive bias. We realize this bias as a neural network layer that promotes learning low-frequency representations of the input features, allowing the network to operate in a space where the target function is more regular. Our proposed method introduces less computational complexity than a fully connected layer, while significantly improving neural network performance, and speeding up its convergence on 14 tabular datasets",
    "checked": false,
    "id": "d41c2ecc159e545ef02dac198a6be7b066d9563d",
    "semantic_title": "goggle: generative modelling for tabular data by learning relational structure",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=TW3ipYdDQG": {
    "title": "Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint",
    "volume": "poster",
    "abstract": "Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called probably approximately fair and optimal (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called fair streaming PCA along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its statistical guarantee in terms of PAFO-learnability, which is the first of its kind in fair PCA literature. We verify our algorithm in the CelebA dataset without any pre-processing; while the existing approaches are inapplicable due to memory limitations, by turning it into a streaming setting, we show that our algorithm performs fair PCA efficiently and effectively",
    "checked": true,
    "id": "28dbb804bf2a358a1ae30756272a39ddfa039604",
    "semantic_title": "fair streaming principal component analysis: statistical and algorithmic viewpoint",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=suzMI2P1rT": {
    "title": "CEIL: Generalized Contextual Imitation Learning",
    "volume": "poster",
    "abstract": "In this paper, we present ContExtual Imitation Learning (CEIL), a general and broadly applicable algorithm for imitation learning (IL). Inspired by the formulation of hindsight information matching, we derive CEIL by explicitly learning a hindsight embedding function together with a contextual policy using the hindsight embeddings. To achieve the expert matching objective for IL, we advocate for optimizing a contextual variable such that it biases the contextual policy towards mimicking expert behaviors. Beyond the typical learning from demonstrations (LfD) setting, CEIL is a generalist that can be effectively applied to multiple settings including: 1) learning from observations (LfO), 2) offline IL, 3) cross-domain IL (mismatched experts), and 4) one-shot IL settings. Empirically, we evaluate CEIL on the popular MuJoCo tasks (online) and the D4RL dataset (offline). Compared to prior state-of-the-art baselines, we show that CEIL is more sample-efficient in most online IL tasks and achieves better or competitive performances in offline tasks",
    "checked": true,
    "id": "5d9c1bddc2b884e69dbeae710c42cb8233a2ddc7",
    "semantic_title": "ceil: generalized contextual imitation learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=H9hWlfMT6O": {
    "title": "Training Transformers with 4-bit Integers",
    "volume": "poster",
    "abstract": "Quantizing the activation, weight, and gradient to 4-bit is promising to accelerate neural network training. However, existing 4-bit training methods require custom numerical formats which are not supported by contemporary hardware. In this work, we propose a training method for transformers with all matrix multiplications implemented with the INT4 arithmetic. Training with an ultra-low INT4 precision is challenging. To achieve this, we carefully analyze the specific structures of activation and gradients in transformers to propose dedicated quantizers for them. For forward propagation, we identify the challenge of outliers and propose a Hadamard quantizer to suppress the outliers. For backpropagation, we leverage the structural sparsity of gradients by proposing bit splitting and leverage score sampling techniques to quantize gradients accurately. Our algorithm achieves competitive accuracy on a wide range of tasks including natural language understanding, machine translation, and image classification. Unlike previous 4-bit training methods, our algorithm can be implemented on the current generation of GPUs. Our prototypical linear operator implementation is up to 2.2 times faster than the FP16 counterparts and speeds up the training by 17.8\\% on average for sufficiently large models. Our code is available at https://github.com/xijiu9/Train\\_Transformers\\_with\\_INT4",
    "checked": true,
    "id": "7505337d88e4d36e2e37891c542947a2e3c9e009",
    "semantic_title": "training transformers with 4-bit integers",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=2hhIDEHhkk": {
    "title": "Estimating Propensity for Causality-based Recommendation without Exposure Data",
    "volume": "poster",
    "abstract": "Causality-based recommendation systems focus on the causal effects of user-item interactions resulting from item exposure (i.e., which items are recommended or exposed to the user), as opposed to conventional correlation-based recommendation. They are gaining popularity due to their multi-sided benefits to users, sellers and platforms alike. However, existing causality-based recommendation methods require additional input in the form of exposure data and/or propensity scores (i.e., the probability of exposure) for training. Such data, crucial for modeling causality in recommendation, are often not available in real-world situations due to technical or privacy constraints. In this paper, we bridge the gap by proposing a new framework, called Propensity Estimation for Causality-based Recommendation (PropCare). It can estimate the propensity and exposure from a more practical setup, where only interaction data are available *without* any ground truth on exposure or propensity in training and inference. We demonstrate that, by relating the pairwise characteristics between propensity and item popularity, PropCare enables competitive causality-based recommendation given only the conventional interaction data. We further present a theoretical analysis on the bias of the causal effect under our model estimation. Finally, we empirically evaluate PropCare through both quantitative and qualitative experiments",
    "checked": true,
    "id": "867c3cd2e5e17ec191a2b8d21e734cf757c44904",
    "semantic_title": "estimating propensity for causality-based recommendation without exposure data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gUEekxYr6D": {
    "title": "BiSLS/SPS: Auto-tune Step Sizes for Stable Bi-level Optimization",
    "volume": "poster",
    "abstract": "The popularity of bi-level optimization (BO) in deep learning has spurred a growing interest in studying gradient-based BO algorithms. However, existing algorithms involve two coupled learning rates that can be affected by approximation errors when computing hypergradients, making careful fine-tuning necessary to ensure fast convergence. To alleviate this issue, we investigate the use of recently proposed adaptive step-size methods, namely stochastic line search (SLS) and stochastic Polyak step size (SPS), for computing both the upper and lower-level learning rates. First, we revisit the use of SLS and SPS in single-level optimization without the additional interpolation condition that is typically assumed in prior works. For such settings, we investigate new variants of SLS and SPS that improve upon existing suggestions in the literature and are simpler to implement. Importantly, these two variants can be seen as special instances of general family of methods with an envelope-type step-size. This unified envelope strategy allows for the extension of the algorithms and their convergence guarantees to BO settings. Finally, our extensive experiments demonstrate that the new algorithms, which are available in both SGD and Adam versions, can find large learning rates with minimal tuning and converge faster than corresponding vanilla SGD or Adam BO algorithms that require fine-tuning",
    "checked": true,
    "id": "a4d9dd70428d22adb5d39a51fe184bcb92c5c95e",
    "semantic_title": "bisls/sps: auto-tune step sizes for stable bi-level optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CY1xatvEQj": {
    "title": "DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models",
    "volume": "poster",
    "abstract": "Even though trained mainly on images, we discover that pretrained diffusion models show impressive power in guiding sketch synthesis. In this paper, we present DiffSketcher, an innovative algorithm that creates \\textit{vectorized} free-hand sketches using natural language input. DiffSketcher is developed based on a pre-trained text-to-image diffusion model. It performs the task by directly optimizing a set of Bézier curves with an extended version of the score distillation sampling (SDS) loss, which allows us to use a raster-level diffusion model as a prior for optimizing a parametric vectorized sketch generator. Furthermore, we explore attention maps embedded in the diffusion model for effective stroke initialization to speed up the generation process. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual details of the subject drawn. Our experiments show that DiffSketcher achieves greater quality than prior work. The code and demo of DiffSketcher can be found at https://ximinng.github.io/DiffSketcher-project/",
    "checked": true,
    "id": "34509b045b625bab87f5d3747fcae0736ea4f880",
    "semantic_title": "diffsketcher: text guided vector sketch synthesis through latent diffusion models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=rxsCTtkqA9": {
    "title": "Matrix Compression via Randomized Low Rank and Low Precision Factorization",
    "volume": "poster",
    "abstract": "Matrices are exceptionally useful in various fields of study as they provide a convenient framework to organize and manipulate data in a structured manner. However, modern matrices can involve billions of elements, making their storage and processing quite demanding in terms of computational resources and memory usage. Although prohibitively large, such matrices are often approximately low rank. We propose an algorithm that exploits this structure to obtain a low rank decomposition of any matrix $\\mathbf{A}$ as $\\mathbf{A} \\approx \\mathbf{L}\\mathbf{R}$, where $\\mathbf{L}$ and $\\mathbf{R}$ are the low rank factors. The total number of elements in $\\mathbf{L}$ and $\\mathbf{R}$ can be significantly less than that in $\\mathbf{A}$. Furthermore, the entries of $\\mathbf{L}$ and $\\mathbf{R}$ are quantized to low precision formats -- compressing $\\mathbf{A}$ by giving us a low rank and low precision factorization. Our algorithm first computes an approximate basis of the range space of $\\mathbf{A}$ by randomly sketching its columns, followed by a quantization of the vectors constituting this basis. It then computes approximate projections of the columns of $\\mathbf{A}$ onto this quantized basis. We derive upper bounds on the approximation error of our algorithm, and analyze the impact of target rank and quantization bit-budget. The tradeoff between compression ratio and approximation accuracy allows for flexibility in choosing these parameters based on specific application requirements. We empirically demonstrate the efficacy of our algorithm in image compression, nearest neighbor classification of image and text embeddings, and compressing the layers of LlaMa-$7$b. Our results illustrate that we can achieve compression ratios as aggressive as one bit per matrix coordinate, all while surpassing or maintaining the performance of traditional compression techniques",
    "checked": true,
    "id": "43017a16dfe593c09533c5fb3c3612c83761a98a",
    "semantic_title": "matrix compression via randomized low rank and low precision factorization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ad3JNoR2np": {
    "title": "Adapting to Continuous Covariate Shift via Online Density Ratio Estimation",
    "volume": "poster",
    "abstract": "Dealing with distribution shifts is one of the central challenges for modern machine learning. One fundamental situation is the covariate shift, where the input distributions of data change from the training to testing stages while the input-conditional output distribution remains unchanged. In this paper, we initiate the study of a more challenging scenario --- continuous covariate shift --- in which the test data appear sequentially, and their distributions can shift continuously. Our goal is to adaptively train the predictor such that its prediction risk accumulated over time can be minimized. Starting with the importance-weighted learning, we theoretically show the method works effectively if the time-varying density ratios of test and train inputs can be accurately estimated. However, existing density ratio estimation methods would fail due to data scarcity at each time step. To this end, we propose an online density ratio estimation method that can appropriately reuse historical information. Our method is proven to perform well by enjoying a dynamic regret bound, which finally leads to an excess risk guarantee for the predictor. Empirical results also validate the effectiveness",
    "checked": true,
    "id": "905f8c3324ff1867b1edbd76737b29b08aecf35d",
    "semantic_title": "adapting to continuous covariate shift via online density ratio estimation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9WSxQZ9mG7": {
    "title": "Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering",
    "volume": "poster",
    "abstract": "As the field of automated machine learning (AutoML) advances, it becomes increasingly important to incorporate domain knowledge into these systems. We present an approach for doing so by harnessing the power of large language models (LLMs). Specifically, we introduce Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method for tabular datasets that utilizes an LLM to iteratively generate additional semantically meaningful features for tabular datasets based on the description of the dataset. The method produces both Python code for creating new features and explanations for the utility of the generated features. Despite being methodologically simple, CAAFE improves performance on 11 out of 14 datasets -- boosting mean ROC AUC performance from 0.798 to 0.822 across all dataset - similar to the improvement achieved by using a random forest instead of logistic regression on our datasets. Furthermore, CAAFE is interpretable by providing a textual explanation for each generated feature. CAAFE paves the way for more extensive semi-automation in data science tasks and emphasizes the significance of context-aware solutions that can extend the scope of AutoML systems to semantic AutoML. We release our [code](url{https://github.com/automl/CAAFE), a simple [demo](url{https://colab.research.google.com/drive/1mCA8xOAJZ4MaB_alZvyARTMjhl6RZf0a) and a [python package](url{https://pypi.org/project/caafe/)",
    "checked": true,
    "id": "36877d3608fb391bad5a22fabd81c6669e721e69",
    "semantic_title": "large language models for automated data science: introducing caafe for context-aware automated feature engineering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q0sdoFIfNg": {
    "title": "SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning",
    "volume": "poster",
    "abstract": "Alleviating overestimation bias is a critical challenge for deep reinforcement learning to achieve successful performance on more complex tasks or offline datasets containing out-of-distribution data. In order to overcome overestimation bias, ensemble methods for Q-learning have been investigated to exploit the diversity of multiple Q-functions. Since network initialization has been the predominant approach to promote diversity in Q-functions, heuristically designed diversity injection methods have been studied in the literature. However, previous studies have not attempted to approach guaranteed independence over an ensemble from a theoretical perspective. By introducing a novel regularization loss for Q-ensemble independence based on random matrix theory, we propose spiked Wishart Q-ensemble independence regularization (SPQR) for reinforcement learning. Specifically, we modify the intractable hypothesis testing criterion for the Q-ensemble independence into a tractable KL divergence between the spectral distribution of the Q-ensemble and the target Wigner's semicircle distribution. We implement SPQR in several online and offline ensemble Q-learning algorithms. In the experiments, SPQR outperforms the baseline algorithms in both online and offline RL benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H57w5EOj6O": {
    "title": "Facilitating Graph Neural Networks with Random Walk on Simplicial Complexes",
    "volume": "poster",
    "abstract": "Node-level random walk has been widely used to improve Graph Neural Networks. However, there is limited attention to random walk on edge and, more generally, on $k$-simplices. This paper systematically analyzes how random walk on different orders of simplicial complexes (SC) facilitates GNNs in their theoretical expressivity. First, on $0$-simplices or node level, we establish a connection between existing positional encoding (PE) and structure encoding (SE) methods through the bridge of random walk. Second, on $1$-simplices or edge level, we bridge edge-level random walk and Hodge $1$-Laplacians and design corresponding edge PE respectively. In spatial domain, we directly make use of edge level random walk to construct EdgeRWSE. Based on spectral analysis of Hodge $1$-Laplcians, we propose Hodge1Lap, a permutation equivariant and expressive edge-level positional encoding. Third, we generalize our theory to random walk on higher-order simplices and propose the general principle to design PE on simplices based on random walk and Hodge Laplacians. Inter-level random walk is also introduced to unify a wide range of simplicial networks. Extensive experiments verify the effectiveness of our random walk-based methods",
    "checked": true,
    "id": "1d099eddeba2655ad82b894c7f79052ad3f3f922",
    "semantic_title": "facilitating graph neural networks with random walk on simplicial complexes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SAzaC8f3cM": {
    "title": "Towards Self-Interpretable Graph-Level Anomaly Detection",
    "volume": "poster",
    "abstract": "Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not only measure the abnormality of each graph based on cross-view mutual information but also provide informative graph rationales by extracting bottleneck subgraphs from the input graph and its dual hypergraph in a self-supervised way. Extensive experiments on 16 datasets demonstrate the anomaly detection capability and self-interpretability of SIGNET",
    "checked": true,
    "id": "db27a18d04e22ddc91ff74204e074c1aaa6d239b",
    "semantic_title": "towards self-interpretable graph-level anomaly detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DAdfU1ASLb": {
    "title": "Optimal Transport for Treatment Effect Estimation",
    "volume": "poster",
    "abstract": "Estimating individual treatment effects from observational data is challenging due to treatment selection bias. Prevalent methods mainly mitigate this issue by aligning different treatment groups in the latent space, the core of which is the calculation of distribution discrepancy. However, two issues that are often overlooked can render these methods invalid: (1) mini-batch sampling effects (MSE), where the calculated discrepancy is erroneous in non-ideal mini-batches with outcome imbalance and outliers; (2) unobserved confounder effects (UCE), where the unobserved confounders are not considered in the discrepancy calculation. Both of these issues invalidate the calculated discrepancy, mislead the training of estimators, and thus impede the handling of treatment selection bias. To tackle these issues, we propose Entire Space CounterFactual Regression (ESCFR), which is a new take on optimal transport technology in the context of causality. Specifically, based on the canonical optimal transport framework, we propose a relaxed mass-preserving regularizer to address the MSE issue and design a proximal factual outcome regularizer to handle the UCE issue. Extensive experiments demonstrate that ESCFR estimates distribution discrepancy accurately, handles the treatment selection bias effectively, and outperforms prevalent competitors significantly",
    "checked": true,
    "id": "5e9a01144dd1508207a5209cf8854096202757d9",
    "semantic_title": "optimal transport for treatment effect estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mlxRLIy7kc": {
    "title": "Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment",
    "volume": "poster",
    "abstract": "Recent progress in scaling up large language models has shown impressive capabilities in performing few-shot learning across a wide range of natural language tasks. However, a key limitation is that these language models fundamentally lack grounding to visual perception - a crucial attribute needed to extend to real world tasks such as in visual-question answering and robotics. While prior works have largely connected image to text through pretraining or fine-tuning, learning such alignments are generally costly due to a combination of curating massive datasets and large computational burdens. In order to resolve these limitations, we propose a simple yet effective approach called Language-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to align text-image data in an unsupervised manner by leveraging pretrained language model denoisers (e.g., BERT). Our main idea is to encode images as sequences of text tokens by directly quantizing image embeddings using a pretrained language codebook. We then feed a masked version of the quantized embeddings into a BERT to reconstruct the original input. By doing so, LQAE learns to represent similar images with similar clusters of text tokens, thereby aligning these two modalities without the use of aligned text-image pairs. We show LQAE learns text-aligned image tokens that enable few-shot multi-modal learning with large language models, outperforming baseline methods in tasks such as image classification and VQA while requiring as few as 1-10 image-text pairs",
    "checked": true,
    "id": "d3bc7ba19e274bb6fb5e055a3f1b62924c731432",
    "semantic_title": "language quantized autoencoders: towards unsupervised text-image alignment",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=sIU3WujeSl": {
    "title": "VOCE: Variational Optimization with Conservative Estimation for Offline Safe Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline safe reinforcement learning (RL) algorithms promise to learn policies that satisfy safety constraints directly in offline datasets without interacting with the environment. This arrangement is particularly important in scenarios with high sampling costs and potential dangers, such as autonomous driving and robotics. However, the influence of safety constraints and out-of-distribution (OOD) actions have made it challenging for previous methods to achieve high reward returns while ensuring safety. In this work, we propose a Variational Optimization with Conservative Eestimation algorithm (VOCE) to solve the problem of optimizing safety policies in the offline dataset. Concretely, we reframe the problem of offline safe RL using probabilistic inference, which introduces variational distributions to make the optimization of policies more flexible. Subsequently, we utilize pessimistic estimation methods to estimate the Q-value of cost and reward, which mitigates the extrapolation errors induced by OOD actions. Finally, extensive experiments demonstrate that the VOCE algorithm achieves competitive performance across multiple experimental tasks, particularly outperforming state-of-the-art algorithms in terms of safety",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ntd6X7uWYF": {
    "title": "Blocked Collaborative Bandits: Online Collaborative Filtering with Per-Item Budget Constraints",
    "volume": "poster",
    "abstract": "We consider the problem of \\emph{blocked} collaborative bandits where there are multiple users, each with an associated multi-armed bandit problem. These users are grouped into \\emph{latent} clusters such that the mean reward vectors of users within the same cluster are identical. Our goal is to design algorithms that maximize the cumulative reward accrued by all the users over time, under the \\emph{constraint} that no arm of a user is pulled more than $\\mathsf{B}$ times. This problem has been originally considered by \\cite{Bresler:2014}, and designing regret-optimal algorithms for it has since remained an open problem. In this work, we propose an algorithm called B-LATTICE (Blocked Latent bAndiTs via maTrIx ComplEtion) that collaborates across users, while simultaneously satisfying the budget constraints, to maximize their cumulative rewards. Theoretically, under certain reasonable assumptions on the latent structure, with $\\mathsf{M}$ users, $\\mathsf{N}$ arms, $\\mathsf{T}$ rounds per user, and $\\mathsf{C}=O(1)$ latent clusters, B-LATTICE achieves a per-user regret of $\\widetilde{O}(\\sqrt{\\mathsf{T}(1 + \\mathsf{N}\\mathsf{M}^{-1})})$ under a budget constraint of $\\mathsf{B}=\\Theta(\\log \\mathsf{T})$. These are the first sub-linear regret bounds for this problem, and match the minimax regret bounds when $\\mathsf{B}=\\mathsf{T}$. Empirically, we demonstrate that our algorithm has superior performance over baselines even when $\\mathsf{B}=1$. B-LATTICE is a phased algorithm where in each phase it clusters users into groups and collaborates across users within a group to quickly learn their reward models",
    "checked": true,
    "id": "b468ee222ecc0e7d2101df65312d24346ad0f0ba",
    "semantic_title": "blocked collaborative bandits: online collaborative filtering with per-item budget constraints",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bM6mynsusR": {
    "title": "Function Space Bayesian Pseudocoreset for Bayesian Neural Networks",
    "volume": "poster",
    "abstract": "A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass several challenges that may arise when working on a weight space, including limited scalability and multi-modality issue. Through various experiments, we demonstrate that the Bayesian pseudocoresets constructed from our method enjoys enhanced uncertainty quantification and better robustness across various model architectures",
    "checked": true,
    "id": "a5ba2135a91ebf22dda3886f6dd0929f0829408b",
    "semantic_title": "function space bayesian pseudocoreset for bayesian neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yoZTVn0T50": {
    "title": "CaMP: Causal Multi-policy Planning for Interactive Navigation in Multi-room Scenes",
    "volume": "poster",
    "abstract": "Visual navigation has been widely studied under the assumption that there may be several clear routes to reach the goal. However, in more practical scenarios such as a house with several messy rooms, there may not. Interactive Navigation (InterNav) considers agents navigating to their goals more effectively with object interactions, posing new challenges of learning interaction dynamics and extra action space. Previous works learn single vision-to-action policy with the guidance of designed representations. However, the causality between actions and outcomes is prone to be confounded when the attributes of obstacles are diverse and hard to measure. Learning policy for long-term action planning in complex scenes also leads to extensive inefficient exploration. In this paper, we introduce a causal diagram of InterNav clarifying the confounding bias caused by obstacles. To address the problem, we propose a multi-policy model that enables the exploration of counterfactual interactions as well as reduces unnecessary exploration. We develop a large-scale dataset containing 600k task episodes in 12k multi-room scenes based on the ProcTHOR simulator and showcase the effectiveness of our method with the evaluations on our dataset",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J2Cso0wWZX": {
    "title": "DesCo: Learning Object Recognition with Rich Language Descriptions",
    "volume": "poster",
    "abstract": "Recent development in vision-language approaches has instigated a paradigm shift in learning visual recognition models from language supervision. These approaches align objects with language queries (e.g. \"a photo of a cat\") and thus improve the models' adaptability to novel objects and domains. Recent studies have attempted to query these models with complex language expressions that include specifications of fine-grained details, such as colors, shapes, and relations. However, simply incorporating language descriptions into queries does not guarantee accurate interpretation by the models. In fact, our experiments show that GLIP, a state-of-the-art vision-language model for object detection, often disregards contextual information in the language descriptions and instead relies heavily on detecting objects solely by their names. To tackle the challenge, we propose a new description-conditioned (DesCo) paradigm of learning object recognition models with rich language descriptions consisting of two innovations: 1) we employ a large language model as a commonsense knowledge engine to generate rich language descriptions of objects; 2) we design context-sensitive queries to improve the model's ability in deciphering intricate nuances embedded within descriptions and enforce the model to focus on context rather than object names alone. On two novel object detection benchmarks, LVIS and OminiLabel, under the zero-shot detection setting, our approach achieves 34.8 APr minival (+9.1) and 29.3 AP (+3.6), respectively, surpassing the prior state-of-the-art models, GLIP and FIBER, by a large margin",
    "checked": true,
    "id": "a762954f102a9ece458f02eb955607bf6e456540",
    "semantic_title": "desco: learning object recognition with rich language descriptions",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=l9MbuqzlZt": {
    "title": "Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces",
    "volume": "poster",
    "abstract": "This paper presents a framework for computing the Gromov-Wasserstein problem between two sets of points in low dimensional spaces, where the discrepancy is the squared Euclidean norm. The Gromov-Wasserstein problem is a generalization of the optimal transport problem that finds the assignment between two sets preserving pairwise distances as much as possible. This can be used to quantify the similarity between two formations or shapes, a common problem in AI and machine learning. The problem can be formulated as a Quadratic Assignment Problem (QAP), which is in general computationally intractable even for small problems. Our framework addresses this challenge by reformulating the QAP as an optimization problem with a low-dimensional domain, leveraging the fact that the problem can be expressed as a concave quadratic optimization problem with low rank. The method scales well with the number of points, and it can be used to find the global solution for large-scale problems with thousands of points. We compare the computational complexity of our approach with state-of-the-art methods on synthetic problems and apply it to a near-symmetrical problem which is of particular interest in computational biology",
    "checked": true,
    "id": "c46429f405d0626aa99a3bc23e53b5ef3156b22f",
    "semantic_title": "globally solving the gromov-wasserstein problem for point clouds in low dimensional euclidean spaces",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=CQqBt46FUD": {
    "title": "Unbiased learning of deep generative models with structured discrete representations",
    "volume": "poster",
    "abstract": "By composing graphical models with deep learning architectures, we learn generative models with the strengths of both frameworks. The structured variational autoencoder (SVAE) inherits structure and interpretability from graphical models, and flexible likelihoods for high-dimensional data from deep learning, but poses substantial optimization challenges. We propose novel algorithms for learning SVAEs, and are the first to demonstrate the SVAE's ability to handle multimodal uncertainty when data is missing by incorporating discrete latent variables. Our memory-efficient implicit differentiation scheme makes the SVAE tractable to learn via gradient descent, while demonstrating robustness to incomplete optimization. To more rapidly learn accurate graphical model parameters, we derive a method for computing natural gradients without manual derivations, which avoids biases found in prior work. These optimization innovations enable the first comparisons of the SVAE to state-of-the-art time series models, where the SVAE performs competitively while learning interpretable and structured discrete data representations",
    "checked": true,
    "id": "20014619d1798757da1f76f96c93aeec969a201c",
    "semantic_title": "unbiased learning of deep generative models with structured discrete representations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PLzCXefcpE": {
    "title": "How Re-sampling Helps for Long-Tail Learning?",
    "volume": "poster",
    "abstract": "Long-tail learning has received significant attention in recent years due to the challenge it poses with extremely imbalanced datasets. In these datasets, only a few classes (known as the head classes) have an adequate number of training samples, while the rest of the classes (known as the tail classes) are infrequent in the training data. Re-sampling is a classical and widely used approach for addressing class imbalance issues. Unfortunately, recent studies claim that re-sampling brings negligible performance improvements in modern long-tail learning tasks. This paper aims to investigate this phenomenon systematically. Our research shows that re-sampling can considerably improve generalization when the training images do not contain semantically irrelevant contexts. In other scenarios, however, it can learn unexpected spurious correlations between irrelevant contexts and target labels. We design experiments on two homogeneous datasets, one containing irrelevant context and the other not, to confirm our findings. To prevent the learning of spurious correlations, we propose a new context shift augmentation module that generates diverse training images for the tail class by maintaining a context bank extracted from the head-class images. Experiments demonstrate that our proposed module can boost the generalization and outperform other approaches, including class-balanced re-sampling, decoupled classifier re-training, and data augmentation methods. The source code is available at https://www.lamda.nju.edu.cn/code_CSA.ashx",
    "checked": true,
    "id": "aaee06dcbc926e50392397db650f10cb83e58598",
    "semantic_title": "how re-sampling helps for long-tail learning?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=86dXbqT5Ua": {
    "title": "Geometry-Informed Neural Operator for Large-Scale 3D PDEs",
    "volume": "poster",
    "abstract": "We propose the geometry-informed neural operator (GINO), a highly efficient approach to learning the solution operator of large-scale partial differential equations with varying geometries. GINO uses a signed distance function (SDF) representation of the input shape and neural operators based on graph and Fourier architectures to learn the solution operator. The graph neural operator handles irregular grids and transforms them into and from regular latent grids on which Fourier neural operator can be efficiently applied. We provide an efficient implementation of GINO using an optimized hashing approach, which allows efficient learning in a shared, compressed latent space with reduced computation and memory costs. GINO is discretization-invariant, meaning the trained model can be applied to arbitrary discretizations of the continuous domain and applies to any shape or resolution. To empirically validate the performance of our method on large-scale simulation, we generate the industry-standard aerodynamics dataset of 3D vehicle geometries with Reynolds numbers as high as five million. For this large-scale 3D fluid simulation, numerical methods are expensive to compute surface pressure. We successfully trained GINO to predict the pressure on car surfaces using only five hundred data points. The cost-accuracy experiments show a 26,000x speed-up compared to optimized GPU-based computational fluid dynamics (CFD) simulators on computing the drag coefficient. When tested on new combinations of geometries and boundary conditions (inlet velocities), GINO obtains a one-fourth reduction in error rate compared to deep neural network approaches",
    "checked": true,
    "id": "55a59dfff3e57ec551814db82225a3677411e092",
    "semantic_title": "geometry-informed neural operator for large-scale 3d pdes",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=t9Swbo82dB": {
    "title": "Uncertainty Estimation for Safety-critical Scene Segmentation via Fine-grained Reward Maximization",
    "volume": "poster",
    "abstract": "Uncertainty estimation plays an important role for future reliable deployment of deep segmentation models in safety-critical scenarios such as medical applications. However, existing methods for uncertainty estimation have been limited by the lack of explicit guidance for calibrating the prediction risk and model confidence. In this work, we propose a novel fine-grained reward maximization (FGRM) framework, to address uncertainty estimation by directly utilizing an uncertainty metric related reward function with a reinforcement learning based model tuning algorithm. This would benefit the model uncertainty estimation with direct optimization guidance for model calibration. Specifically, our method designs a new uncertainty estimation reward function using the calibration metric, which is maximized to fine-tune an evidential learning pre-trained segmentation model for calibrating prediction risk. Importantly, we innovate an effective fine-grained parameter update scheme, which imposes fine-grained reward-weighting of each network parameter according to the parameter importance quantified by the fisher information matrix. To the best of our knowledge, this is the first work exploring reward optimization for model uncertainty estimation in safety-critical vision tasks. The effectiveness of our method is demonstrated on two large safety-critical surgical scene segmentation datasets under two different uncertainty estimation settings. With real-time one forward pass at inference, our method outperforms state-of-the-art methods by a clear margin on all the calibration metrics of uncertainty estimation, while maintaining a high task accuracy for the segmentation results. Code is available at https://github.com/med-air/FGRM",
    "checked": true,
    "id": "f638b7109ff3c3c331c1b0007b443f8d8e999a41",
    "semantic_title": "uncertainty estimation for safety-critical scene segmentation via fine-grained reward maximization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9fWKExmKa0": {
    "title": "DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics",
    "volume": "poster",
    "abstract": "Diffusion probabilistic models (DPMs) have exhibited excellent performance for high-fidelity image generation while suffering from inefficient sampling. Recent works accelerate the sampling procedure by proposing fast ODE solvers that leverage the specific ODE form of DPMs. However, they highly rely on specific parameterization during inference (such as noise/data prediction), which might not be the optimal choice. In this work, we propose a novel formulation towards the optimal parameterization during sampling that minimizes the first-order discretization error of the ODE solution. Based on such formulation, we propose \\textit{DPM-Solver-v3}, a new fast ODE solver for DPMs by introducing several coefficients efficiently computed on the pretrained model, which we call \\textit{empirical model statistics}. We further incorporate multistep methods and a predictor-corrector framework, and propose some techniques for improving sample quality at small numbers of function evaluations (NFE) or large guidance scales. Experiments show that DPM-Solver-v3 achieves consistently better or comparable performance in both unconditional and conditional sampling with both pixel-space and latent-space DPMs, especially in 5$\\sim$10 NFEs. We achieve FIDs of 12.21 (5 NFE), 2.51 (10 NFE) on unconditional CIFAR10, and MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable Diffusion, bringing a speed-up of 15\\%$\\sim$30\\% compared to previous state-of-the-art training-free methods. Code is available at \\url{https://github.com/thu-ml/DPM-Solver-v3}",
    "checked": true,
    "id": "d0a1dd918288d445d3e8146a186d5256a2fc5ca3",
    "semantic_title": "dpm-solver-v3: improved diffusion ode solver with empirical model statistics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=30o4ARmfC3": {
    "title": "Evolving Connectivity for Recurrent Spiking Neural Networks",
    "volume": "poster",
    "abstract": "Recurrent spiking neural networks (RSNNs) hold great potential for advancing artificial general intelligence, as they draw inspiration from the biological nervous system and show promise in modeling complex dynamics. However, the widely-used surrogate gradient-based training methods for RSNNs are inherently inaccurate and unfriendly to neuromorphic hardware. To address these limitations, we propose the evolving connectivity (EC) framework, an inference-only method for training RSNNs. The EC framework reformulates weight-tuning as a search into parameterized connection probability distributions, and employs Natural Evolution Strategies (NES) for optimizing these distributions. Our EC framework circumvents the need for gradients and features hardware-friendly characteristics, including sparse boolean connections and high scalability. We evaluate EC on a series of standard robotic locomotion tasks, where it achieves comparable performance with deep neural networks and outperforms gradient-trained RSNNs, even solving the complex 17-DoF humanoid task. Additionally, the EC framework demonstrates a two to three fold speedup in efficiency compared to directly evolving parameters. By providing a performant and hardware-friendly alternative, the EC framework lays the groundwork for further energy-efficient applications of RSNNs and advances the development of neuromorphic devices. Our code is publicly available at https://github.com/imoneoi/EvolvingConnectivity",
    "checked": true,
    "id": "517393c7b3a0730fc73000b9b575fa5756ed589c",
    "semantic_title": "evolving connectivity for recurrent spiking neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QZo1cge4Tc": {
    "title": "Counterfactually Fair Representation",
    "volume": "poster",
    "abstract": "The use of machine learning models in high-stake applications (e.g., healthcare, lending, college admission) has raised growing concerns due to potential biases against protected social groups. Various fairness notions and methods have been proposed to mitigate such biases. In this work, we focus on Counterfactual Fairness (CF), a fairness notion that is dependent on an underlying causal graph and first proposed by Kusner $\\textit{et al.}$; it requires that the outcome an individual perceives is the same in the real world as it would be in a \"counterfactual\" world, in which the individual belongs to another social group. Learning fair models satisfying CF can be challenging. It was shown in (Kusner $\\textit{et al.}$) that a sufficient condition for satisfying CF is to $\\textbf{not}$ use features that are descendants of sensitive attributes in the causal graph. This implies a simple method that learns CF models only using non-descendants of sensitive attributes while eliminating all descendants. Although several subsequent works proposed methods that use all features for training CF models, there is no theoretical guarantee that they can satisfy CF. In contrast, this work proposes a new algorithm that trains models using all the available features. We theoretically and empirically show that models trained with this method can satisfy CF",
    "checked": true,
    "id": "e3b8dc7644db5ac89bf54ba1d957aa3a421a9477",
    "semantic_title": "counterfactually fair representation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tLEDsaKuDh": {
    "title": "Emergent Communication in Interactive Sketch Question Answering",
    "volume": "poster",
    "abstract": "Vision-based emergent communication (EC) aims to learn to communicate through sketches and demystify the evolution of human communication. Ironically, previous works neglect multi-round interaction, which is indispensable in human communication. To fill this gap, we first introduce a novel Interactive Sketch Question Answering (ISQA) task, where two collaborative players are interacting through sketches to answer a question about an image. To accomplish this task, we design a new and efficient interactive EC system, which can achieve an effective balance among three evaluation factors, including the question answering accuracy, drawing complexity and human interpretability. Our experimental results demonstrate that multi-round interactive mechanism facilitates tar- geted and efficient communication between intelligent agents. The code will be released",
    "checked": true,
    "id": "04f21d46f47f65fe7dc6cd3ac2f375c529fe06ce",
    "semantic_title": "emergent communication in interactive sketch question answering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H1a7bVVnPK": {
    "title": "Accelerated Training via Incrementally Growing Neural Networks using Variance Transfer and Learning Rate Adaptation",
    "volume": "poster",
    "abstract": "We develop an approach to efficiently grow neural networks, within which parameterization and optimization strategies are designed by considering their effects on the training dynamics. Unlike existing growing methods, which follow simple replication heuristics or utilize auxiliary gradient-based local optimization, we craft a parameterization scheme which dynamically stabilizes weight, activation, and gradient scaling as the architecture evolves, and maintains the inference functionality of the network. To address the optimization difficulty resulting from imbalanced training effort distributed to subnetworks fading in at different growth phases, we propose a learning rate adaption mechanism that rebalances the gradient contribution of these separate subcomponents. Experiments show that our method achieves comparable or better accuracy than training large fixed-size models, while saving a substantial portion of the original training computation budget. We demonstrate that these gains translate into real wall-clock training speedups",
    "checked": true,
    "id": "bb968f409664bc9122f04647f79ae4b99275ff1d",
    "semantic_title": "accelerated training via incrementally growing neural networks using variance transfer and learning rate adaptation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=BQA7wR2KBF": {
    "title": "Identifiable Contrastive Learning with Automatic Feature Importance Discovery",
    "volume": "poster",
    "abstract": "Existing contrastive learning methods rely on pairwise sample contrast $z_x^\\top z_{x'}$ to learn data representations, but the learned features often lack clear interpretability from a human perspective. Theoretically, it lacks feature identifiability and different initialization may lead to totally different features. In this paper, we study a new method named tri-factor contrastive learning (triCL) that involves a 3-factor contrast in the form of $z_x^\\top S z_{x'}$, where $S=\\text{diag}(s_1,\\dots,s_k)$ is a learnable diagonal matrix that automatically captures the importance of each feature. We show that by this simple extension, triCL can not only obtain identifiable features that eliminate randomness but also obtain more interpretable features that are ordered according to the importance matrix $S$. We show that features with high importance have nice interpretability by capturing common classwise features, and obtain superior performance when evaluated for image retrieval using a few features. The proposed triCL objective is general and can be applied to different contrastive learning methods like SimCLR and CLIP. We believe that it is a better alternative to existing 2-factor contrastive learning by improving its identifiability and interpretability with minimal overhead. Code is available at https://github.com/PKU-ML/Tri-factor-Contrastive-Learning",
    "checked": true,
    "id": "3db89407e3427deba2e728582d85fed38051169a",
    "semantic_title": "identifiable contrastive learning with automatic feature importance discovery",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e2MCL6hObn": {
    "title": "Likelihood-Based Diffusion Language Models",
    "volume": "poster",
    "abstract": "Despite a growing interest in diffusion-based language models, existing work has not shown that these models can attain nontrivial likelihoods on standard language modeling benchmarks. In this work, we take the first steps towards closing the likelihood gap between autoregressive and diffusion-based language models, with the goal of building and releasing a diffusion model which outperforms a small but widely-known autoregressive model. We pursue this goal through algorithmic improvements, scaling laws, and increased compute. On the algorithmic front, we introduce several methodological improvements for the maximum-likelihood training of diffusion language models. We then study scaling laws for our diffusion models and find compute-optimal training regimes which differ substantially from autoregressive models. Using our methods and scaling analysis, we train and release Plaid 1B, a large diffusion language model which outperforms GPT-2 124M in likelihood on benchmark datasets and generates fluent samples in unconditional and zero-shot control settings",
    "checked": true,
    "id": "d9ffb44ee3c8ec0b6692df8a90451384c1edd89b",
    "semantic_title": "likelihood-based diffusion language models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=uoiwugtpCH": {
    "title": "PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning",
    "volume": "poster",
    "abstract": "Hyperparameters of Deep Learning (DL) pipelines are crucial for their downstream performance. While a large number of methods for Hyperparameter Optimization (HPO) have been developed, their incurred costs are often untenable for modern DL. Consequently, manual experimentation is still the most prevalent approach to optimize hyperparameters, relying on the researcher's intuition, domain knowledge, and cheap preliminary explorations. To resolve this misalignment between HPO algorithms and DL researchers, we propose PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs and cheap proxy tasks. Empirically, we demonstrate PriorBand's efficiency across a range of DL benchmarks and show its gains under informative expert input and robustness against poor expert beliefs",
    "checked": true,
    "id": "74dba11830c7521825ff008f394e096efb355d98",
    "semantic_title": "priorband: practical hyperparameter optimization in the age of deep learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=DDkl9vaJyE": {
    "title": "Brant: Foundation Model for Intracranial Neural Signal",
    "volume": "poster",
    "abstract": "We propose a foundation model named Brant for modeling intracranial recordings, which learns powerful representations of intracranial neural signals by pre-training, providing a large-scale, off-the-shelf model for medicine. Brant is the largest model in the field of brain signals and is pre-trained on a large corpus of intracranial data collected by us. The design of Brant is to capture long-term temporal dependency and spatial correlation from neural signals, combining the information in both time and frequency domains. As a foundation model, Brant achieves SOTA performance on various downstream tasks (i.e. neural signal forecasting, frequency-phase forecasting, imputation and seizure detection), showing the generalization ability to a broad range of tasks. The low-resource label analysis and representation visualization further illustrate the effectiveness of our pre-training strategy. In addition, we explore the effect of model size to show that a larger model with a higher capacity can lead to performance improvements on our dataset. The source code and pre-trained weights are available at: https://zju-brainnet.github.io/Brant.github.io/",
    "checked": true,
    "id": "fdbd1c11a0cd390309ad147d0273b5d8721def12",
    "semantic_title": "brant: foundation model for intracranial neural signal",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hiOUySN0ub": {
    "title": "Learning Topology-Agnostic EEG Representations with Geometry-Aware Modeling",
    "volume": "poster",
    "abstract": "Large-scale pre-training has shown great potential to enhance models on downstream tasks in vision and language. Developing similar techniques for scalp electroencephalogram (EEG) is suitable since unlabelled data is plentiful. Meanwhile, various sampling channel selections and inherent structural and spatial information bring challenges and avenues to improve existing pre-training strategies further. In order to break boundaries between different EEG resources and facilitate cross-dataset EEG pre-training, we propose to map all kinds of channel selections to a unified topology. We further introduce MMM, a pre-training framework with Multi-dimensional position encoding, Multi-level channel hierarchy, and Multi-stage pre-training strategy built on the unified topology to obtain topology-agnostic representations. Experiments demonstrate that our approach yields impressive improvements over previous state-of-the-art techniques on emotional recognition benchmark datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QjI36zxjbW": {
    "title": "Neural-Logic Human-Object Interaction Detection",
    "volume": "poster",
    "abstract": "The interaction decoder utilized in prevalent Transformer-based HOI detectors typically accepts pre-composed human-object pairs as inputs. Though achieving remarkable performance, such a paradigm lacks feasibility and cannot explore novel combinations over entities during decoding. We present LogicHOI, a new HOI detector that leverages neural-logic reasoning and Transformer to infer feasible interactions between. entities. Specifically, we modify. self-attention mechanism in the vanilla Transformer, enabling it to reason over the ⟨ human, action, object ⟩ triplet and constitute novel interactions. Meanwhile, such a reasoning process is guided by two crucial properties for understanding HOI: affordances (the potential actions an object can facilitate) and proxemics (the spatial relations between humans and objects). We formulate these two properties in first-order logic and ground them into continuous space to constrain the learning process of our approach, leading to improved performance and zero-shot generalization capabilities. We evaluate L OGIC HOI on V-COCO and HICO-DET under both normal and zero-shot setups, achieving significant improvements over existing methods",
    "checked": true,
    "id": "e1c377356feade5be3bbaaccc9d254582f6056e3",
    "semantic_title": "neural-logic human-object interaction detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y2hnMZvVDm": {
    "title": "Beyond NTK with Vanilla Gradient Descent: A Mean-Field Analysis of Neural Networks with Polynomial Width, Samples, and Time",
    "volume": "poster",
    "abstract": "Despite recent theoretical progress on the non-convex optimization of two-layer neural networks, it is still an open question whether gradient descent on neural networks without unnatural modifications can achieve better sample complexity than kernel methods. This paper provides a clean mean-field analysis of projected gradient flow on polynomial-width two-layer neural networks. Different from prior works, our analysis does not require unnatural modifications of the optimization algorithm. We prove that with sample size $n = O(d^{3.1})$ where $d$ is the dimension of the inputs, the network trained with projected gradient flow converges in polynomial time to a non-trivial error that is not achievable by kernel methods using $n \\ll d^4$ samples, hence demonstrating a clear separation between unmodified gradient descent and NTK. As a corollary, we show that projected gradient descent with a positive learning rate and a polynomial number of iterations converges to low error with the same sample complexity",
    "checked": true,
    "id": "1064a5be52ab4f0ec36790aa2037eb5cc783d513",
    "semantic_title": "beyond ntk with vanilla gradient descent: a mean-field analysis of neural networks with polynomial width, samples, and time",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=zOCIKYVaF5": {
    "title": "Residual Alignment: Uncovering the Mechanisms of Residual Networks",
    "volume": "poster",
    "abstract": "The ResNet architecture has been widely adopted in deep learning due to its significant boost to performance through the use of simple skip connections, yet the underlying mechanisms leading to its success remain largely unknown. In this paper, we conduct a thorough empirical study of the ResNet architecture in classification tasks by linearizing its constituent residual blocks using Residual Jacobians and measuring their singular value decompositions. Our measurements ([code](https://colab.research.google.com/drive/1yKjEg2yF616tnZFAfuN0aQ-E9v3JmyjN?usp=sharing)) reveal a process called Residual Alignment (RA) characterized by four properties: - **(RA1):** intermediate representations of a given input are *equispaced* on a *line*, embedded in high dimensional space, as observed by Gai and Zhang [2021]; - **(RA2):** top left and right singular vectors of Residual Jacobians align with each other and across different depths; - **(RA3):** Residual Jacobians are at most rank $C$ for fully-connected ResNets, where $C$ is the number of classes; and - **(RA4):** top singular values of Residual Jacobians scale inversely with depth. RA consistently occurs in models that generalize well, in both fully-connected and convolutional architectures, across various depths and widths, for varying numbers of classes, on all tested benchmark datasets, but ceases to occur once the skip connections are removed. It also provably occurs in a novel mathematical model we propose. This phenomenon reveals a strong alignment between residual branches of a ResNet (RA2+4), imparting a highly rigid geometric structure to the intermediate representations as they progress *linearly* through the network (RA1) up to the final layer, where they undergo Neural Collapse",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kyXMU3H7RB": {
    "title": "Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL",
    "volume": "poster",
    "abstract": "Offline reinforcement learning (RL) offers an appealing approach to real-world tasks by learning policies from pre-collected datasets without interacting with the environment. However, the performance of existing offline RL algorithms heavily depends on the scale and state-action space coverage of datasets. Real-world data collection is often expensive and uncontrollable, leading to small and narrowly covered datasets and posing significant challenges for practical deployments of offline RL. In this paper, we provide a new insight that leveraging the fundamental symmetry of system dynamics can substantially enhance offline RL performance under small datasets. Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced Dynamics Model (TDM), which establishes consistency between a pair of forward and reverse latent dynamics. TDM provides both well-behaved representations for small datasets and a new reliability measure for OOD samples based on compliance with the T-symmetry. These can be readily used to construct a new offline RL algorithm (TSRL) with less conservative policy constraints and a reliable latent space data augmentation procedure. Based on extensive experiments, we find TSRL achieves great performance on small benchmark datasets with as few as 1% of the original samples, which significantly outperforms the recent offline RL algorithms in terms of data efficiency and generalizability. Code is available at: https://github.com/pcheng2/TSRL",
    "checked": true,
    "id": "157f71d01fbd1799e30e1b1bf68d53a60c2ad107",
    "semantic_title": "look beneath the surface: exploiting fundamental symmetry for sample-efficient offline rl",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qyEm4tF2p1": {
    "title": "Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information",
    "volume": "poster",
    "abstract": "Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning. By learning an optimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience. The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both training and testing. The training is further challenged by sparse gradients of $\\mathbf{g}$, especially for combinatorial solvers. To address these challenges, we propose using a smooth and learnable **Landscape Surrogate** $\\mathcal{M}$ as a replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization. We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems",
    "checked": true,
    "id": "2f7d8963a4981b790be5afde1ddfc567460a38ba",
    "semantic_title": "landscape surrogate: learning decision losses for mathematical optimization under partial information",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=GfZGdJHj27": {
    "title": "Consistent Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent",
    "volume": "poster",
    "abstract": "Imperfect score-matching leads to a shift between the training and the sampling distribution of diffusion models. Due to the recursive nature of the generation process, errors in previous steps yield sampling iterates that drift away from the training distribution. However, the standard training objective via Denoising Score Matching (DSM) is only designed to optimize over non-drifted data. To train on drifted data, we propose to enforce a \\emph{Consistency} property (CP) which states that predictions of the model on its own generated data are consistent across time. Theoretically, we show that the differential equation that describes CP together with the one that describes a conservative vector field, have a unique solution given some initial condition. Consequently, if the score is learned well on non-drifted points via DSM (enforcing the true initial condition) then enforcing CP on drifted points propagates true score values. Empirically, we show that enforcing CP improves the generation quality for conditional and unconditional generation on CIFAR-10, and in AFHQ and FFHQ. We open-source our code and models: https://github.com/giannisdaras/cdm",
    "checked": true,
    "id": "c8abd95ec7dfc6ed81ea27f577d3570c3896bcb1",
    "semantic_title": "consistent diffusion models: mitigating sampling drift by learning to be consistent",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=GWIRpKF6yU": {
    "title": "Structured Neural-PI Control with End-to-End Stability and Output Tracking Guarantees",
    "volume": "poster",
    "abstract": "We study the optimal control of multiple-input and multiple-output dynamical systems via the design of neural network-based controllers with stability and output tracking guarantees. While neural network-based nonlinear controllers have shown superior performance in various applications, their lack of provable guarantees has restricted their adoption in high-stake real-world applications. This paper bridges the gap between neural network-based controllers and the need for stabilization guarantees. Using equilibrium-independent passivity, a property present in a wide range of physical systems, we propose neural Proportional-Integral (PI) controllers that have provable guarantees of stability and zero steady-state output tracking error. The key structure is the strict monotonicity on proportional and integral terms, which is parameterized as gradients of strictly convex neural networks (SCNN). We construct SCNN with tunable softplus-$\\beta$ activations, which yields universal approximation capability and is also useful in incorporating communication constraints. In addition, the SCNNs serve as Lyapunov functions, giving us end-to-end performance guarantees. Experiments on traffic and power networks demonstrate that the proposed approach improves both transient and steady-state performances, while unstructured neural networks lead to unstable behaviors",
    "checked": true,
    "id": "64e73f7f3d887618b5dd52b0698bd4d6bf2e4deb",
    "semantic_title": "structured neural-pi control with end-to-end stability and output tracking guarantees",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XY6BnwIh4q": {
    "title": "Binary Radiance Fields",
    "volume": "poster",
    "abstract": "In this paper, we propose binary radiance fields (BiRF), a storage-efficient radiance field representation employing binary feature encoding that encodes local features using binary encoding parameters in a format of either $+1$ or $-1$. This binarization strategy lets us represent the feature grid with highly compact feature encoding and a dramatic reduction in storage size. Furthermore, our 2D-3D hybrid feature grid design enhances the compactness of feature encoding as the 3D grid includes main components while 2D grids capture details. In our experiments, binary radiance field representation successfully outperforms the reconstruction performance of state-of-the-art (SOTA) efficient radiance field models with lower storage allocation. In particular, our model achieves impressive results in static scene reconstruction, with a PSNR of 32.03 dB for Synthetic-NeRF scenes, 34.48 dB for Synthetic-NSVF scenes, 28.20 dB for Tanks and Temples scenes while only utilizing 0.5 MB of storage space, respectively. We hope the proposed binary radiance field representation will make radiance fields more accessible without a storage bottleneck",
    "checked": true,
    "id": "92676a9a6cc5d2fc88fdded8ff759521adc4f876",
    "semantic_title": "binary radiance fields",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=wBJBLy9kBY": {
    "title": "Ambient Diffusion: Learning Clean Distributions from Corrupted Data",
    "volume": "poster",
    "abstract": "We present the first diffusion-based framework that can learn an unknown distribution using only highly-corrupted samples. This problem arises in scientific applications where access to uncorrupted samples is impossible or expensive to acquire. Another benefit of our approach is the ability to train generative models that are less likely to memorize any individual training sample, since they never observe clean training data. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image. We prove that our method leads to models that learn the conditional expectation of the full uncorrupted image given this additional measurement corruption. This holds for any corruption process that satisfies some technical conditions (and in particular includes inpainting and compressed sensing). We train models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) and show that we can learn the distribution even when all the training samples have 90\\% of their pixels missing. We also show that we can finetune foundation models on small corrupted datasets (e.g. MRI scans with block corruptions) and learn the clean distribution without memorizing the training set",
    "checked": true,
    "id": "fdc04fe7c4a3fb4038d1bbd5f4e2fdf2599566e3",
    "semantic_title": "ambient diffusion: learning clean distributions from corrupted data",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=PdZhf6PiAb": {
    "title": "An Information-Theoretic Evaluation of Generative Models in Learning Multi-modal Distributions",
    "volume": "poster",
    "abstract": "The evaluation of generative models has received significant attention in the machine learning community. When applied to a multi-modal distribution which is common among image datasets, an intuitive evaluation criterion is the number of modes captured by the generative model. While several scores have been proposed to evaluate the quality and diversity of a model's generated data, the correspondence between existing scores and the number of modes in the distribution is unclear. In this work, we propose an information-theoretic diversity evaluation method for multi-modal underlying distributions. We utilize the R\\'enyi Kernel Entropy (RKE) as an evaluation score based on quantum information theory to measure the number of modes in generated samples. To interpret the proposed evaluation method, we show that the RKE score can output the number of modes of a mixture of sub-Gaussian components. We also prove estimation error bounds for estimating the RKE score from limited data, suggesting a fast convergence of the empirical RKE score to the score for the underlying data distribution. Utilizing the RKE score, we conduct an extensive evaluation of state-of-the-art generative models over standard image datasets. The numerical results indicate that while the recent algorithms for training generative models manage to improve the mode-based diversity over the earlier architectures, they remain incapable of capturing the full diversity of real data. Our empirical results provide a ranking of widely-used generative models based on the RKE score of their generated samples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G8nal7MpIQ": {
    "title": "Guide Your Agent with Adaptive Multimodal Rewards",
    "volume": "poster",
    "abstract": "Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning. This work presents Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders. Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal. We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards. Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization. This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies. To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance. Video demonstrations and source code are available on the project website: \\url{https://sites.google.com/view/2023arp}",
    "checked": true,
    "id": "b435bd3fd2c855a755061a5ace42fb444d4f81a7",
    "semantic_title": "guide your agent with adaptive multimodal rewards",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7PJ6LaIOO4": {
    "title": "Statistical and Computational Trade-off in Multi-Agent Multi-Armed Bandits",
    "volume": "poster",
    "abstract": "We study the problem of regret minimization in Multi-Agent Multi-Armed Bandits (MAMABs) where the rewards are defined through a factor graph. We derive an instance-specific regret lower bound and characterize the minimal expected number of times each global action should be explored. Unfortunately, this bound and the corresponding optimal exploration process are obtained by solving a combinatorial optimization problem with a set of variables and constraints exponentially growing with the number of agents. We approximate the regret lower bound problem via Mean Field techniques to reduce the number of variables and constraints. By tuning the latter, we explore the trade-off between achievable regret and complexity. We devise Efficient Sampling for MAMAB (ESM), an algorithm whose regret asymptotically matches the corresponding approximated lower bound. We assess the regret and computational complexity of ESM numerically, using both synthetic and real-world experiments in radio communications networks",
    "checked": false,
    "id": "5aa0a667c9e11a1d9251c5a1fb0d0c1991c64faa",
    "semantic_title": "regret minimization in heavy-tailed bandits",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=2vADOf3K00": {
    "title": "Compressed Video Prompt Tuning",
    "volume": "poster",
    "abstract": "Compressed videos offer a compelling alternative to raw videos, showing the possibility to significantly reduce the on-line computational and storage cost. However, current approaches to compressed video processing generally follow the resource-consuming pre-training and fine-tuning paradigm, which does not fully take advantage of such properties, making them not favorable enough for widespread applications. Inspired by recent successes of prompt tuning techniques in computer vision, this paper presents the first attempt to build a prompt based representation learning framework, which enables effective and efficient adaptation of pre-trained raw video models to compressed video understanding tasks. To this end, we propose a novel prompt tuning approach, namely Compressed Video Prompt Tuning (CVPT), emphatically dealing with the challenging issue caused by the inconsistency between pre-training and downstream data modalities. Specifically, CVPT replaces the learnable prompts with compressed modalities (\\emph{e.g.} Motion Vectors and Residuals) by re-parameterizing them into conditional prompts followed by layer-wise refinement. The conditional prompts exhibit improved adaptability and generalizability to instances compared to conventional individual learnable ones, and the Residual prompts enhance the noisy motion cues in the Motion Vector prompts for further fusion with the visual cues from I-frames. Additionally, we design Selective Cross-modal Complementary Prompt (SCCP) blocks. After inserting them into the backbone, SCCP blocks leverage semantic relations across diverse levels and modalities to improve cross-modal interactions between prompts and input flows. Extensive evaluations on HMDB-51, UCF-101 and Something-Something v2 demonstrate that CVPT remarkably outperforms the state-of-the-art counterparts, delivering a much better balance between accuracy and efficiency",
    "checked": false,
    "id": "a45fd3a9eb9bbd4f265800bb0b46c9ae4bfe3cd7",
    "semantic_title": "vop: text-video co-operative prompt tuning for cross-modal retrieval",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=A7ESFTMJWs": {
    "title": "On Convergence of Polynomial Approximations to the Gaussian Mixture Entropy",
    "volume": "poster",
    "abstract": "Gaussian mixture models (GMMs) are fundamental to machine learning due to their flexibility as approximating densities. However, uncertainty quantification of GMMs remains a challenge as differential entropy lacks a closed form. This paper explores polynomial approximations, specifically Taylor and Legendre, to the GMM entropy from a theoretical and practical perspective. We provide new analysis of a widely used approach due to Huber et al.(2008) and show that the series diverges under simple conditions. Motivated by this divergence we provide a novel Taylor series that is provably convergent to the true entropy of any GMM. We demonstrate a method for selecting a center such that the series converges from below, providing a lower bound on GMM entropy. Furthermore, we demonstrate that orthogonal polynomial series result in more accurate polynomial approximations. Experimental validation supports our theoretical results while showing that our method is comparable in computation to Huber et al. We also show that in application, the use of these polynomial approximations, such as in Nonparametric Variational Inference by Gershamn et al. (2012), rely on the convergence of the methods in computing accurate approximations. This work contributes useful analysis to existing methods while introducing a novel approximation supported by firm theoretical guarantees",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9wrYfqdrwk": {
    "title": "Diversify Your Vision Datasets with Automatic Diffusion-based Augmentation",
    "volume": "poster",
    "abstract": "Many fine-grained classification tasks, like rare animal identification, have limited training data and consequently classifiers trained on these datasets often fail to generalize to variations in the domain like changes in weather or location. As such, we explore how natural language descriptions of the domains seen in training data can be used with large vision models trained on diverse pretraining datasets to generate useful variations of the training data. We introduce ALIA (Automated Language-guided Image Augmentation), a method which utilizes large vision and language models to automatically generate natural language descriptions of a dataset's domains and augment the training data via language-guided image editing. To maintain data integrity, a model trained on the original dataset filters out minimal image edits and those which corrupt class-relevant information. The resulting dataset is visually consistent with the original training data and offers significantly enhanced diversity. We show that ALIA is able to surpasses traditional data augmentation and text-to-image generated data on fine-grained classification tasks, including cases of domain generalization and contextual bias. Code is available at https://github.com/lisadunlap/ALIA",
    "checked": true,
    "id": "c346bfb9b2e2730ee3aa392fd17956416191e38d",
    "semantic_title": "diversify your vision datasets with automatic diffusion-based augmentation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=2C2WZfCfo9": {
    "title": "DOSE: Diffusion Dropout with Adaptive Prior for Speech Enhancement",
    "volume": "poster",
    "abstract": "Speech enhancement (SE) aims to improve the intelligibility and quality of speech in the presence of non-stationary additive noise. Deterministic deep learning models have traditionally been used for SE, but recent studies have shown that generative approaches, such as denoising diffusion probabilistic models (DDPMs), can also be effective. However, incorporating condition information into DDPMs for SE remains a challenge. We propose a model-agnostic method called DOSE that employs two efficient condition-augmentation techniques to address this challenge, based on two key insights: (1) We force the model to prioritize the condition factor when generating samples by training it with dropout operation; (2) We inject the condition information into the sampling process by providing an informative adaptive prior. Experiments demonstrate that our approach yields substantial improvements in high-quality and stable speech generation, consistency with the condition factor, and inference efficiency. Codes are publicly available at https://github.com/ICDM-UESTC/DOSE",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m2WR1yJ8N9": {
    "title": "Better with Less: A Data-Active Perspective on Pre-Training Graph Neural Networks",
    "volume": "poster",
    "abstract": "Pre-training on graph neural networks (GNNs) aims to learn transferable knowledge for downstream tasks with unlabeled data, and it has recently become an active research area. The success of graph pre-training models is often attributed to the massive amount of input data. In this paper, however, we identify the curse of big data phenomenon in graph pre-training: more training data do not necessarily lead to better downstream performance. Motivated by this observation, we propose a better-with-less framework for graph pre-training: fewer, but carefully chosen data are fed into a GNN model to enhance pre-training. The proposed pre-training pipeline is called the data-active graph pre-training (APT) framework, and is composed of a graph selector and a pre-training model. The graph selector chooses the most representative and instructive data points based on the inherent properties of graphs as well as predictive uncertainty. The proposed predictive uncertainty, as feedback from the pre-training model, measures the confidence level of the model in the data. When fed with the chosen data, on the other hand, the pre-training model grasps an initial understanding of the new, unseen data, and at the same time attempts to remember the knowledge learned from previous data. Therefore, the integration and interaction between these two components form a unified framework (APT), in which graph pre-training is performed in a progressive and iterative way. Experiment results show that the proposed APT is able to obtain an efficient pre-training model with fewer training data and better downstream performance",
    "checked": true,
    "id": "4a2a300aee196aff6f490c148a3966eb9a1b20d4",
    "semantic_title": "better with less: a data-active perspective on pre-training graph neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=esy7pkZmKn": {
    "title": "Doubly-Robust Self-Training",
    "volume": "poster",
    "abstract": "Self-training is a well-established technique in semi-supervised learning, which leverages unlabeled data by generating pseudo-labels and incorporating them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly-robust self-training, an innovative semi-supervised algorithm that provably balances between two extremes. When pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly-robust loss over the self-training baseline",
    "checked": false,
    "id": "08af3a441d36a321cb97bb3fbb3fcb7c55c3d390",
    "semantic_title": "doubly robust self-training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rnKgbKmelt": {
    "title": "AdaPlanner: Adaptive Planning from Feedback with Language Models",
    "volume": "poster",
    "abstract": "Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the agent to plan and refine with fewer task demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and 4.11% while utilizing 2x and 600x fewer samples, respectively. The implementation of AdaPlanner is available at https://github.com/haotiansun14/AdaPlanner",
    "checked": true,
    "id": "8e37dc1215681aa153a51c07078ba8befd6a6e01",
    "semantic_title": "adaplanner: adaptive planning from feedback with language models",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=TEpRn67828": {
    "title": "Uniform Convergence with Square-Root Lipschitz Loss",
    "volume": "poster",
    "abstract": "We establish generic uniform convergence guarantees for Gaussian data in terms of the Radamacher complexity of the hypothesis class and the Lipschitz constant of the square root of the scalar loss function. We show how these guarantees substantially generalize previous results based on smoothness (Lipschitz constant of the derivative), and allow us to handle the broader class of square-root-Lipschtz losses, which includes also non-smooth loss functions appropriate for studying phase retrieval and ReLU regression, as well as rederive and better understand \"optimistic rate\" and interpolation learning guarantees",
    "checked": true,
    "id": "2d6e92f0af54559eb7bfbb6fb56196a4acebd8ea",
    "semantic_title": "uniform convergence with square-root lipschitz loss",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=arkmhtYLL6": {
    "title": "Concept Distillation: Leveraging Human-Centered Explanations for Model Improvement",
    "volume": "poster",
    "abstract": "Humans use abstract *concepts* for understanding instead of hard features. Recent interpretability research has focused on human-centered concept explanations of neural networks. Concept Activation Vectors (CAVs) estimate a model's sensitivity and possible biases to a given concept. We extend CAVs from post-hoc analysis to ante-hoc training to reduce model bias through fine-tuning using an additional *Concept Loss*. Concepts are defined on the final layer of the network in the past. We generalize it to intermediate layers, including the last convolution layer. We also introduce *Concept Distillation*, a method to define rich and effective concepts using a pre-trained knowledgeable model as the teacher. Our method can sensitize or desensitize a model towards concepts. We show applications of concept-sensitive training to debias several classification problems. We also show a way to induce prior knowledge into a reconstruction problem. We show that concept-sensitive training can improve model interpretability, reduce biases, and induce prior knowledge",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gd20oaZqqF": {
    "title": "Towards Optimal Caching and Model Selection for Large Model Inference",
    "volume": "poster",
    "abstract": "Large Language Models (LLMs) and other large foundation models have achieved impressive results, but their size exacerbates existing resource consumption and latency challenges. In particular, the large-scale deployment of these models is hindered by the significant resource requirements during inference. In this paper, we study two approaches for mitigating these challenges: employing a cache to store previous queries and learning a model selector to choose from an ensemble of models for query processing. Theoretically, we provide an optimal algorithm for jointly optimizing both approaches to reduce the inference cost in both offline and online tabular settings. By combining a caching algorithm, namely Greedy Dual Size with Frequency (GDSF) or Least Expected Cost (LEC), with a model selector, we achieve optimal rates in both offline and online settings. Empirically, simulations show that our caching and model selection algorithm greatly improves over the baselines, with up to $50\\times$ improvement over the baseline when the ratio between the maximum cost and minimum cost is $100$. Experiments on real datasets show a $4.3\\times$ improvement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a $1.8\\times$ improvement in latency when the ratio for average latency is $1.85$",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l3HUgVHqGQ": {
    "title": "Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer",
    "volume": "poster",
    "abstract": "Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \\emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \\emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends more to distinct key tokens for a specific next token to be predicted, and pays less attention to common key tokens that occur across different next tokens. Among distinct tokens, it progressively drops attention weights, following the order of low to high co-occurrence between the key and the query token in the training set. Interestingly, this procedure does not lead to winner-takes-all, but stops due to a \\emph{phase transition} that is controllable by the learning rate of the decoder layer, leaving (almost) fixed token combination. We verify this \\textbf{\\emph{scan and snap}} dynamics on synthetic and real-world data (WikiText-103)",
    "checked": true,
    "id": "50eb97f832ffcd2114f79957c977215176384e3d",
    "semantic_title": "scan and snap: understanding training dynamics and token composition in 1-layer transformer",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=pVlC0reMKq": {
    "title": "RETVec: Resilient and Efficient Text Vectorizer",
    "volume": "poster",
    "abstract": "This paper describes RETVec, an efficient, resilient, and multilingual text vectorizer designed for neural-based text processing. RETVec combines a novel character encoding with an optional small embedding model to embed words into a 256-dimensional vector space. The RETVec embedding model is pre-trained using pair-wise metric learning to be robust against typos and character-level adversarial attacks. In this paper, we evaluate and compare RETVec to state-of-the-art vectorizers and word embeddings on popular model architectures and datasets. These comparisons demonstrate that RETVec leads to competitive, multilingual models that are significantly more resilient to typos and adversarial text attacks. RETVec is available under the Apache 2 license at https://github.com/google-research/retvec",
    "checked": true,
    "id": "a794a92e1fa516250390514eeeb3c3b3140876a3",
    "semantic_title": "retvec: resilient and efficient text vectorizer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7INd5Yu9ET": {
    "title": "Long-Term Fairness with Unknown Dynamics",
    "volume": "poster",
    "abstract": "While machine learning can myopically reinforce social inequalities, it may also be used to dynamically seek equitable outcomes. In this paper, we formalize long-term fairness as an online reinforcement learning problem for a policy affecting human populations. This formulation accommodates dynamical control objectives, such as achieving equitable population states, that cannot be incorporated into static formulations of fairness. We demonstrate that algorithmic solutions to the proposed fairness problem can adapt to unknown dynamics and, by sacrificing short-term incentives, drive the policy-population system towards more desirable equilibria. For the proposed setting, we develop an algorithm that adapts recent work in online learning and prove that this algorithm achieves simultaneous probabilistic bounds on cumulative loss and cumulative violations of fairness. In the classification setting subject to group fairness, we compare our proposed algorithm to several baselines, including the repeated retraining of myopic or distributionally robust classifiers, and to a deep reinforcement learning algorithm that lacks fairness guarantees. Our experiments model human populations according to evolutionary game theory and integrate real-world datasets",
    "checked": true,
    "id": "41eb61316d3a9aafe92844d222394cd84271d74d",
    "semantic_title": "long-term fairness with unknown dynamics",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=hElNdYMs8Z": {
    "title": "A Finite-Sample Analysis of Payoff-Based Independent Learning in Zero-Sum Stochastic Games",
    "volume": "poster",
    "abstract": "In this work, we study two-player zero-sum stochastic games and develop a variant of the smoothed best-response learning dynamics that combines independent learning dynamics for matrix games with the minimax value iteration for stochastic games. The resulting learning dynamics are payoff-based, convergent, rational, and symmetric between the two players. Our theoretical results present to the best of our knowledge the first last-iterate finite-sample analysis of such independent learning dynamics. To establish the results, we develop a coupled Lyapunov drift approach to capture the evolution of multiple sets of coupled and stochastic iterates, which might be of independent interest",
    "checked": true,
    "id": "e7f3f778dbec99f4e749165aab1a63bbf4d9dfae",
    "semantic_title": "a finite-sample analysis of payoff-based independent learning in zero-sum stochastic games",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FLTg8uA5xI": {
    "title": "Scaling Riemannian Diffusion Models",
    "volume": "poster",
    "abstract": "Riemannian diffusion models draw inspiration from standard Euclidean space diffusion models to learn distributions on general manifolds. Unfortunately, the additional geometric complexity renders the diffusion transition term inexpressible in closed form, so prior methods resort to imprecise approximations of the score matching training objective that degrade performance and preclude applications in high dimensions. In this work, we reexamine these approximations and propose several practical improvements. Our key observation is that most relevant manifolds are symmetric spaces, which are much more amenable to computation. By leveraging and combining various ans\\\"{a}tze, we can quickly compute relevant quantities to high precision. On low dimensional datasets, our correction produces a noticeable improvement and is competitive with other techniques. Additionally, we show that our method enables us to scale to high dimensional tasks on nontrivial manifolds, including $SU(n)$ lattices in the context of lattice quantum chromodynamics (QCD). Finally, we apply our models to contrastively learned hyperspherical embeddings, curbing the representation collapse problem in the projection head and closing the gap between theory and practice",
    "checked": true,
    "id": "ea72fdc4e044278c69bd726a46a126cf7caffe68",
    "semantic_title": "scaling riemannian diffusion models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gVLKXT9JwG": {
    "title": "Global Convergence Analysis of Local SGD for Two-layer Neural Network without Overparameterization",
    "volume": "poster",
    "abstract": "Local SGD, a cornerstone algorithm in federated learning, is widely used in training deep neural networks and shown to have strong empirical performance. A theoretical understanding of such performance on nonconvex loss landscapes is currently lacking. Analysis of the global convergence of SGD is challenging, as the noise depends on the model parameters. Indeed, many works narrow their focus to GD and rely on injecting noise to enable convergence to the local or global optimum. When expanding the focus to local SGD, existing analyses in the nonconvex case can only guarantee finding stationary points or assume the neural network is overparameterized so as to guarantee convergence to the global minimum through neural tangent kernel analysis. In this work, we provide the first global convergence analysis of the vanilla local SGD for two-layer neural networks \\emph{without overparameterization} and \\textit{without injecting noise}, when the input data is Gaussian. The main technical ingredients of our proof are \\textit{a self-correction mechanism} and \\textit{a new exact recursive characterization of the direction of global model parameters}. The self-correction mechanism guarantees the algorithm reaches a good region even if the initialization is in a bad region. A good (bad) region means updating the model by gradient descent will move closer to (away from) the optimal solution. The main difficulty in establishing a self-correction mechanism is to cope with the gradient dependency between two layers. To address this challenge, we divide the landscape of the objective into several regions to carefully control the interference of two layers during the correction process. As a result, we show that local SGD can correct the two layers and enter the good region in polynomial time. After that, we establish a new exact recursive characterization of the direction of global parameters, which is the key to showing convergence to the global minimum with linear speedup in the number of machines and reduced communication rounds. Experiments on synthetic data confirm theoretical results",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qgv56R2YJ7": {
    "title": "Diffusion Self-Guidance for Controllable Image Generation",
    "volume": "poster",
    "abstract": "Large-scale generative models are capable of producing high-quality images from detailed prompts. However, many aspects of an image are difficult or impossible to convey through text. We introduce self-guidance, a method that provides precise control over properties of the generated image by guiding the internal representations of diffusion models. We demonstrate that the size, location, and appearance of objects can be extracted from these representations, and show how to use them to steer the sampling process. Self-guidance operates similarly to standard classifier guidance, but uses signals present in the pretrained model itself, requiring no additional models or training. We demonstrate the flexibility and effectiveness of self-guided generation through a wide range of challenging image manipulations, such as modifying the position or size of a single object (keeping the rest of the image unchanged), merging the appearance of objects in one image with the layout of another, composing objects from multiple images into one, and more. We also propose a new method for reconstruction using self-guidance, which allows extending our approach to editing real images",
    "checked": true,
    "id": "fbebb1a5d72aec2a6b13fc909f781f6ba9b04925",
    "semantic_title": "diffusion self-guidance for controllable image generation",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=G560qr59Gi": {
    "title": "Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data",
    "volume": "poster",
    "abstract": "The implicit bias towards solutions with favorable properties is believed to be a key reason why neural networks trained by gradient-based optimization can generalize well. While the implicit bias of gradient flow has been widely studied for homogeneous neural networks (including ReLU and leaky ReLU networks), the implicit bias of gradient descent is currently only understood for smooth neural networks. Therefore, implicit bias in non-smooth neural networks trained by gradient descent remains an open question. In this paper, we aim to answer this question by studying the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks. We showed that when the training data are nearly-orthogonal, for leaky ReLU activation function, gradient descent will find a network with a stable rank that converges to $1$, whereas for ReLU activation function, gradient descent will find a neural network with a stable rank that is upper bounded by a constant. Additionally, we show that gradient descent will find a neural network such that all the training data points have the same normalized margin asymptotically. Experiments on both synthetic and real data backup our theoretical findings",
    "checked": true,
    "id": "95f5b6d14d5f7f96aa794dd929c5f0d0bf9ec78c",
    "semantic_title": "implicit bias of gradient descent for two-layer relu and leaky relu networks on nearly-orthogonal data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SE73LzWNjr": {
    "title": "Nearly Optimal VC-Dimension and Pseudo-Dimension Bounds for Deep Neural Network Derivatives",
    "volume": "poster",
    "abstract": "This paper addresses the problem of nearly optimal Vapnik--Chervonenkis dimension (VC-dimension) and pseudo-dimension estimations of the derivative functions of deep neural networks (DNNs). Two important applications of these estimations include: 1) Establishing a nearly tight approximation result of DNNs in the Sobolev space; 2) Characterizing the generalization error of machine learning methods with loss functions involving function derivatives. This theoretical investigation fills the gap of learning error estimations for a wide range of physics-informed machine learning models and applications including generative models, solving partial differential equations, operator learning, network compression, distillation, regularization, etc",
    "checked": true,
    "id": "185b4543c0781d4ddf608c282ef5e208dbdb164d",
    "semantic_title": "nearly optimal vc-dimension and pseudo-dimension bounds for deep neural network derivatives",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ZBxycYCuEL": {
    "title": "Stability Guarantees for Feature Attributions with Multiplicative Smoothing",
    "volume": "poster",
    "abstract": "Explanation methods for machine learning models tend not to provide any formal guarantees and may not reflect the underlying decision-making process. In this work, we analyze stability as a property for reliable feature attribution methods. We prove that relaxed variants of stability are guaranteed if the model is sufficiently Lipschitz with respect to the masking of features. We develop a smoothing method called Multiplicative Smoothing (MuS) to achieve such a model. We show that MuS overcomes the theoretical limitations of standard smoothing techniques and can be integrated with any classifier and feature attribution method. We evaluate MuS on vision and language models with various feature attribution methods, such as LIME and SHAP, and demonstrate that MuS endows feature attributions with non-trivial stability guarantees",
    "checked": true,
    "id": "a6874e3652ad75730a5bb6e7554c5e1730095cc4",
    "semantic_title": "stability guarantees for feature attributions with multiplicative smoothing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o6Dnt1uEyZ": {
    "title": "Arbitrarily Scalable Environment Generators via Neural Cellular Automata",
    "volume": "poster",
    "abstract": "We study the problem of generating arbitrarily large environments to improve the throughput of multi-robot systems. Prior work proposes Quality Diversity (QD) algorithms as an effective method for optimizing the environments of automated warehouses. However, these approaches optimize only relatively small environments, falling short when it comes to replicating real-world warehouse sizes. The challenge arises from the exponential increase in the search space as the environment size increases. Additionally, the previous methods have only been tested with up to 350 robots in simulations, while practical warehouses could host thousands of robots. In this paper, instead of optimizing environments, we propose to optimize Neural Cellular Automata (NCA) environment generators via QD algorithms. We train a collection of NCA generators with QD algorithms in small environments and then generate arbitrarily large environments from the generators at test time. We show that NCA environment generators maintain consistent, regularized patterns regardless of environment size, significantly enhancing the scalability of multi-robot systems in two different domains with up to 2,350 robots. Additionally, we demonstrate that our method scales a single-agent reinforcement learning policy to arbitrarily large environments with similar patterns. We include the source code at https://github.com/lunjohnzhang/warehouse_env_gen_nca_public",
    "checked": true,
    "id": "0ed66bbc7c30552b80f1e5fcc76ce74816cba5c6",
    "semantic_title": "arbitrarily scalable environment generators via neural cellular automata",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=INS3ltgjg7": {
    "title": "TopoSRL: Topology preserving self-supervised Simplicial Representation Learning",
    "volume": "poster",
    "abstract": "In this paper, we introduce $\\texttt{TopoSRL}$, a novel self-supervised learning (SSL) method for simplicial complexes to effectively capture higher-order interactions and preserve topology in the learned representations. $\\texttt{TopoSRL}$ addresses the limitations of existing graph-based SSL methods that typically concentrate on pairwise relationships, neglecting long-range dependencies crucial to capture topological information. We propose a new simplicial augmentation technique that generates two views of the simplicial complex that enriches the representations while being efficient. Next, we propose a new simplicial contrastive loss function that contrasts the generated simplices to preserve local and global information present in the simplicial complexes. Extensive experimental results demonstrate the superior performance of $\\texttt{TopoSRL}$ compared to state-of-the-art graph SSL techniques and supervised simplicial neural models across various datasets corroborating the efficacy of $\\texttt{TopoSRL}$ in processing simplicial complex data in a self-supervised setting",
    "checked": false,
    "id": "669825699fb74036aeee78cc2834e04ed0e5d8f1",
    "semantic_title": "scalable self-supervised graph representation learning via enhancing and contrasting subgraphs",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=DVjyq5eCAD": {
    "title": "Chasing Fairness Under Distribution Shift: A Model Weight Perturbation Approach",
    "volume": "poster",
    "abstract": "Fairness in machine learning has attracted increasing attention in recent years. The fairness methods improving algorithmic fairness for in-distribution data may not perform well under distribution shifts. In this paper, we first theoretically demonstrate the inherent connection between distribution shift, data perturbation, and model weight perturbation. Subsequently, we analyze the sufficient conditions to guarantee fairness (i.e., low demographic parity) for the target dataset, including fairness for the source dataset, and low prediction difference between the source and target datasets for each sensitive attribute group. Motivated by these sufficient conditions, we propose robust fairness regularization (RFR) by considering the worst case within the model weight perturbation ball for each sensitive attribute group. We evaluate the effectiveness of our proposed RFR algorithm on synthetic and real distribution shifts across various datasets. Experimental results demonstrate that RFR achieves better fairness-accuracy trade-off performance compared with several baselines. The source code is available at \\url{https://github.com/zhimengj0326/RFR_NeurIPS23}",
    "checked": true,
    "id": "9bb9e291d4329e7370360efa8131df1d0e9493cc",
    "semantic_title": "chasing fairness under distribution shift: a model weight perturbation approach",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Z8TjsPFBSx": {
    "title": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision",
    "volume": "poster",
    "abstract": "Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c8nIdZ5HJJ": {
    "title": "Maximum Average Randomly Sampled: A Scale Free and Non-parametric Algorithm for Stochastic Bandits",
    "volume": "poster",
    "abstract": "Upper Confidence Bound (UCB) methods are one of the most effective methods in dealing with the exploration-exploitation trade-off in online decision-making problems. The confidence bounds utilized in UCB methods tend to be constructed based on concentration equalities which are usually dependent on a parameter of scale (e.g. a bound on the payoffs, a variance, or a subgaussian parameter) that must be known in advance. The necessity of knowing a scale parameter a priori and the fact that the confidence bounds only use the tail information can deteriorate the performance of the UCB methods. Here we propose a data-dependent UCB algorithm called MARS (Maximum Average Randomly Sampled) in a non-parametric setup for multi-armed bandits with symmetric rewards. The algorithm does not depend on any scaling, and the data-dependent upper confidence bound is constructed based on the maximum average of randomly sampled rewards inspired by the work of Hartigan in the 1960s and 70s. A regret bound for the multi-armed bandit problem is derived under the same assumptions as for the $\\psi$-UCB method without incorporating any correction factors. The method is illustrated and compared with baseline algorithms in numerical experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PTvxck0QDE": {
    "title": "Simplicity Bias in 1-Hidden Layer Neural Networks",
    "volume": "poster",
    "abstract": "Recent works have demonstrated that neural networks exhibit extreme *simplicity bias* (SB). That is, they learn *only the simplest* features to solve a task at hand, even in the presence of other, more robust but more complex features. Due to the lack of a general and rigorous definition of *features*, these works showcase SB on *semi-synthetic* datasets such as Color-MNIST , MNIST-CIFAR where defining features is relatively easier. In this work, we rigorously define as well as thoroughly establish SB for *one hidden layer* neural networks in the infinite width regime. More concretely, (i) we define SB as the network essentially being a function of a low dimensional projection of the inputs (ii) theoretically, we show that when the data is linearly separable, the network primarily depends on only the linearly separable ($1$-dimensional) subspace even in the presence of an arbitrarily large number of other, more complex features which could have led to a significantly more robust classifier, (iii) empirically, we show that models trained on *real* datasets such as Imagenet and Waterbirds-Landbirds indeed depend on a low dimensional projection of the inputs, thereby demonstrating SB on these datasets, iv) finally, we present a natural ensemble approach that encourages diversity in models by training successive models on features not used by earlier models, and demonstrate that it yields models that are significantly more robust to Gaussian noise",
    "checked": true,
    "id": "2b7bec81a6ece230ae9361c22336f8a0c70ada5d",
    "semantic_title": "simplicity bias in 1-hidden layer neural networks",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=zUYfbdNl1m": {
    "title": "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
    "volume": "poster",
    "abstract": "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length",
    "checked": false,
    "id": "0423fc7bc1880b850d07aec8ebd9217a70626572",
    "semantic_title": "s3: increasing gpu utilization during generative inference for higher throughput",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B6FihisDBl": {
    "title": "Universal Gradient Descent Ascent Method for Nonconvex-Nonconcave Minimax Optimization",
    "volume": "poster",
    "abstract": "Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Most existing algorithms rely on one-sided information, such as the convexity (resp. concavity) of the primal (resp. dual) functions, or other specific structures, such as the Polyak-Łojasiewicz (PŁ) and Kurdyka-Łojasiewicz (KŁ) conditions. However, verifying these regularity conditions is challenging in practice. To meet this challenge, we propose a novel universally applicable single-loop algorithm, the doubly smoothed gradient descent ascent method (DS-GDA), which naturally balances the primal and dual updates. That is, DS-GDA with the same hyperparameters is able to uniformly solve nonconvex-concave, convex-nonconcave, and nonconvex-nonconcave problems with one-sided KŁ properties, achieving convergence with $\\mathcal{O}(\\epsilon^{-4})$ complexity. Sharper (even optimal) iteration complexity can be obtained when the KŁ exponent is known. Specifically, under the one-sided KŁ condition with exponent $\\theta\\in(0,1)$, DS-GDA converges with an iteration complexity of $\\mathcal{O}(\\epsilon^{-2\\max\\\\{2\\theta,1\\\\}})$. They all match the corresponding best results in the literature. Moreover, we show that DS-GDA is practically applicable to general nonconvex-nonconcave problems even without any regularity conditions, such as the PŁ condition, KŁ condition, or weak Minty variational inequalities condition. For various challenging nonconvex-nonconcave examples in the literature, including *Forsaken*, *Bilinearly-coupled minimax*, *Sixth-order polynomial*, and *PolarGame*, the proposed DS-GDA can all get rid of limit cycles. To the best of our knowledge, this is the first first-order algorithm to achieve convergence on all of these formidable problems",
    "checked": true,
    "id": "86dc30d7345c24b5c6a88266d886a625e940831c",
    "semantic_title": "universal gradient descent ascent method for nonconvex-nonconcave minimax optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zWxKYyW9ik": {
    "title": "Universality and Limitations of Prompt Tuning",
    "volume": "poster",
    "abstract": "Despite the demonstrated empirical efficacy of prompt tuning to adapt a pretrained language model for a new task, the theoretical underpinnings of the difference between \"tuning parameters before the input\" against \"the tuning of model weights\" are limited. We thus take one of the first steps to understand the role of soft-prompt tuning for transformer-based architectures. By considering a general purpose architecture, we analyze prompt tuning from the lens of both: universal approximation and limitations with finite-depth fixed-weight pretrained transformers for continuous-valued functions. Our universality result guarantees the existence of a strong transformer with a prompt to approximate any sequence-to-sequence function in the set of Lipschitz functions. The limitations of prompt tuning for limited-depth transformers are first proved by constructing a set of datasets, that cannot be memorized by a prompt of any length for a given single encoder layer. We also provide a lower bound on the required number of tunable prompt parameters and compare the result with the number of parameters required for a low-rank update (based on LoRA) for a single-layer setting. We finally extend our analysis to multi-layer settings by providing sufficient conditions under which the transformer can at best learn datasets from invertible functions only. Our theoretical claims are also corroborated by empirical results",
    "checked": true,
    "id": "a92f73da79442bc4a5d149a56b97eb46422a0a87",
    "semantic_title": "universality and limitations of prompt tuning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=mYz6ApeU4J": {
    "title": "Class-Conditional Conformal Prediction with Many Classes",
    "volume": "poster",
    "abstract": "Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-specified probability. In many classification problems, we would like to obtain a stronger guarantee--that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. For the latter goal, existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction that clusters together classes having \"similar\" conformal scores and performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set size metrics",
    "checked": true,
    "id": "d98edf182f3a98bd3faf79e85b20c370ea4d5b66",
    "semantic_title": "class-conditional conformal prediction with many classes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=vORUHrVEnH": {
    "title": "Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity",
    "volume": "poster",
    "abstract": "Recent work has revealed many intriguing empirical phenomena in neural network training, despite the poorly understood and highly complex loss landscapes and training dynamics. One of these phenomena, Linear Mode Connectivity (LMC), has gained considerable attention due to the intriguing observation that different solutions can be connected by a linear path in the parameter space while maintaining near-constant training and test losses. In this work, we introduce a stronger notion of linear connectivity, Layerwise Linear Feature Connectivity (LLFC), which says that the feature maps of every layer in different trained networks are also linearly connected. We provide comprehensive empirical evidence for LLFC across a wide range of settings, demonstrating that whenever two trained networks satisfy LMC (via either spawning or permutation methods), they also satisfy LLFC in nearly all the layers. Furthermore, we delve deeper into the underlying factors contributing to LLFC, which reveal new insights into the permutation approaches. The study of LLFC transcends and advances our understanding of LMC by adopting a feature-learning perspective",
    "checked": true,
    "id": "617bf3c2e34f0907fe610d9ced5cf83184fedb1b",
    "semantic_title": "going beyond linear mode connectivity: the layerwise linear feature connectivity",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=aG6xOP9QY7": {
    "title": "Optimal Unbiased Randomizers for Regression with Label Differential Privacy",
    "volume": "poster",
    "abstract": "We propose a new family of label randomizers for training _regression_ models under the constraint of label differential privacy (DP). In particular, we leverage the trade-offs between bias and variance to construct better label randomizers depending on a privately estimated prior distribution over the labels. We demonstrate that these randomizers achieve state-of-the-art privacy-utility trade-offs on several datasets, highlighting the importance of reducing bias when training neural networks with label DP. We also provide theoretical results shedding light on the structural properties of the optimal unbiased randomizers",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6H8Md75kAw": {
    "title": "Certified Minimax Unlearning with Generalization Rates and Deletion Capacity",
    "volume": "poster",
    "abstract": "We study the problem of $(\\epsilon,\\delta)$-certified machine unlearning for minimax models. Most of the existing works focus on unlearning from standard statistical learning models that have a single variable and their unlearning steps hinge on the \\emph{direct Hessian-based conventional Newton} update. We develop a new $(\\epsilon,\\delta)$-certified machine unlearning algorithm for minimax models. It proposes a minimax unlearning step consisting of a \\emph{total-Hessian-based complete Newton} update and the Gaussian mechanism borrowed from differential privacy. To obtain the unlearning certification, our method injects calibrated Gaussian noises by carefully analyzing the ``sensitivity'' of the minimax unlearning step (i.e., the closeness between the minimax unlearning variables and the retraining-from-scratch variables). We derive the generalization rates in terms of population strong and weak primal-dual risk for three different cases of loss functions, i.e., (strongly-)convex-(strongly-)concave losses. We also provide the deletion capacity to guarantee that a desired population risk can be maintained as long as the number of deleted samples does not exceed the derived amount. With training samples $n$ and model dimension $d$, it yields the order $\\mathcal O(n/d^{1/4})$, which shows a strict gap over the baseline method of differentially private minimax learning that has $\\mathcal O(n/d^{1/2})$. In addition, our rates of generalization and deletion capacity match the state-of-the-art rates derived previously for standard statistical learning models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fsCcGr8YFR": {
    "title": "UE4-NeRF:Neural Radiance Field for Real-Time Rendering of Large-Scale Scene",
    "volume": "poster",
    "abstract": "Neural Radiance Fields (NeRF) is a novel implicit 3D reconstruction method that shows immense potential and has been gaining increasing attention. It enables the reconstruction of 3D scenes solely from a set of photographs. However, its real-time rendering capability, especially for interactive real-time rendering of large-scale scenes, still has significant limitations. To address these challenges, in this paper, we propose a novel neural rendering system called UE4-NeRF, specifically designed for real-time rendering of large-scale scenes. We partitioned each large scene into different sub-NeRFs. In order to represent the partitioned independent scene, we initialize polygonal meshes by constructing multiple regular octahedra within the scene and the vertices of the polygonal faces are continuously optimized during the training process. Drawing inspiration from Level of Detail (LOD) techniques, we trained meshes of varying levels of detail for different observation levels. Our approach combines with the rasterization pipeline in Unreal Engine 4 (UE4), achieving real-time rendering of large-scale scenes at 4K resolution with a frame rate of up to 43 FPS. Rendering within UE4 also facilitates scene editing in subsequent stages. Furthermore, through experiments, we have demonstrated that our method achieves rendering quality comparable to state-of-the-art approaches. Project page: https://jamchaos.github.io/UE4-NeRF/",
    "checked": false,
    "id": "28bfafdf04642a74487970e658506c79c91978b1",
    "semantic_title": "ue4-nerf: neural radiance field for real-time rendering of large-scale scene",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=KF4LCXz8Np": {
    "title": "On the Generalization Error of Stochastic Mirror Descent for Quadratically-Bounded Losses: an Improved Analysis",
    "volume": "poster",
    "abstract": "In this work, we revisit the generalization error of stochastic mirror descent for quadratically bounded losses studied in Telgarsky (2022). Quadratically bounded losses is a broad class of loss functions, capturing both Lipschitz and smooth functions, for both regression and classification problems. We study the high probability generalization for this class of losses on linear predictors in both realizable and non-realizable cases when the data are sampled IID or from a Markov chain. The prior work relies on an intricate coupling argument between the iterates of the original problem and those projected onto a bounded domain. This approach enables blackbox application of concentration inequalities, but also leads to suboptimal guarantees due in part to the use of a union bound across all iterations. In this work, we depart significantly from the prior work of Telgarsky (2022), and introduce a novel approach for establishing high probability generalization guarantees. In contrast to the prior work, our work directly analyzes the moment generating function of a novel supermartingale sequence and leverages the structure of stochastic mirror descent. As a result, we obtain improved bounds in all aforementioned settings. Specifically, in the realizable case and non-realizable case with light-tailed sub-Gaussian data, we improve the bounds by a $\\log T$ factor, matching the correct rates of $1/T$ and $1/\\sqrt{T}$, respectively. In the more challenging case of heavy-tailed polynomial data, we improve the existing bound by a $\\mathrm{poly}\\ T$ factor",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zDbsSscmuj": {
    "title": "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning",
    "volume": "poster",
    "abstract": "There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm",
    "checked": true,
    "id": "4f601b4e561557c7a0bd5a741a54cabaec7dc70e",
    "semantic_title": "leveraging pre-trained large language models to construct and utilize world models for model-based task planning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=dCAk9VlegR": {
    "title": "This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations",
    "volume": "poster",
    "abstract": "We present ProtoConcepts, a method for interpretable image classification combining deep learning and case-based reasoning using prototypical parts. Existing work in prototype-based image classification uses a \"this looks like that'' reasoning process, which dissects a test image by finding prototypical parts and combining evidence from these prototypes to make a final classification. However, all of the existing prototypical part-based image classifiers provide only one-to-one comparisons, where a single training image patch serves as a prototype to compare with a part of our test image. With these single-image comparisons, it can often be difficult to identify the underlying concept being compared (e.g., \"is it comparing the color or the shape?''). Our proposed method modifies the architecture of prototype-based networks to instead learn prototypical concepts which are visualized using multiple image patches. Having multiple visualizations of the same prototype allows us to more easily identify the concept captured by that prototype (e.g., \"the test image and the related training patches are all the same shade of blue''), and allows our model to create richer, more interpretable visual explanations. Our experiments show that our ``this looks like those'' reasoning process can be applied as a modification to a wide range of existing prototypical image classification networks while achieving comparable accuracy on benchmark datasets",
    "checked": true,
    "id": "7ddb702da50f1122176612685686661b73da613d",
    "semantic_title": "this looks like those: illuminating prototypical concepts using multiple visualizations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JolrEmMim6": {
    "title": "ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers",
    "volume": "poster",
    "abstract": "Large language models (LLMs) excel at implementing code from functionality descriptions but struggle with algorithmic problems that require not only implementation but also identification of the suitable algorithm. Moreover, LLM-generated programs lack guaranteed correctness and require human verification. To address these challenges, we propose ALGO, a framework that synthesizes Algorithmic programs with LLM-Generated Oracles to guide the generation and verify their correctness. ALGO first generates a reference oracle by prompting an LLM to exhaustively enumerate all the combinations of relevant variables. This oracle is then utilized to guide an arbitrary search strategy in exploring the algorithm space and to verify the synthesized algorithms. Our study shows that the LLM-generated oracles are correct for 88% of the cases. With the oracles as verifiers, ALGO can be integrated with any existing code generation model in a model-agnostic manner to enhance its performance. Experiments show that when equipped with ALGO, we achieve an 8× better one-submission pass rate over the Codex model and a 2.6× better one-submission pass rate over CodeT, the current state-of-the-art model on CodeContests. We can also get 1.3× better pass rate over the ChatGPT Code Interpreter on unseen problems. The problem set we used for testing, the prompts we used, the verifier and solution programs, and the test cases generated by ALGO are available at https://github.com/zkx06111/ALGO",
    "checked": true,
    "id": "2bb4fe9bc10dbf1ea70135e52452f9f63bb10671",
    "semantic_title": "algo: synthesizing algorithmic programs with generated oracle verifiers",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=OeLInnFKUK": {
    "title": "Practical Differentially Private Hyperparameter Tuning with Subsampling",
    "volume": "poster",
    "abstract": "Tuning the hyperparameters of differentially private (DP) machine learning (ML) algorithms often requires use of sensitive data and this may leak private information via hyperparameter values. Recently, Papernot and Steinke (2022) proposed a certain class of DP hyperparameter tuning algorithms, where the number of random search samples is randomized. Commonly, these algorithms still considerably increase the DP privacy parameter $\\varepsilon$ over non-tuned DP ML model training and can be computationally heavy as evaluating each hyperparameter candidate requires a new training run. We focus on lowering both the DP bounds and the compute cost of these methods by using only a random subset of the sensitive data for the hyperparameter tuning and by appropriately extrapolating the optimal values to a larger dataset. We carry out a Rényi differential privacy analysis for the proposed method and experimentally show that it consistently leads to better privacy-utility trade-off than the baseline method by Papernot and Steinke",
    "checked": true,
    "id": "e73c2eb94d146cfc838e733a8c6a3e348479f2f8",
    "semantic_title": "practical differentially private hyperparameter tuning with subsampling",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=qJJmu4qsLO": {
    "title": "Is Heterogeneity Notorious? Taming Heterogeneity to Handle Test-Time Shift in Federated Learning",
    "volume": "poster",
    "abstract": "Federated learning (FL) is an effective machine learning paradigm where multiple clients can train models based on heterogeneous data in a decentralized manner without accessing their private data. However, existing FL systems undergo performance deterioration due to feature-level test-time shifts, which are well investigated in centralized settings but rarely studied in FL. The common non-IID issue in FL usually refers to inter-client heterogeneity during training phase, while the test-time shift refers to the intra-client heterogeneity during test phase. Although the former is always deemed to be notorious for FL, there is still a wealth of useful information delivered by heterogeneous data sources, which may potentially help alleviate the latter issue. To explore the possibility of using inter-client heterogeneity in handling intra-client heterogeneity, we firstly propose a contrastive learning-based FL framework, namely FedICON, to capture invariant knowledge among heterogeneous clients and consistently tune the model to adapt to test data. In FedICON, each client performs sample-wise supervised contrastive learning during the local training phase, which enhances sample-wise invariance encoding ability. Through global aggregation, the invariance extraction ability can be mutually boosted among inter-client heterogeneity. During the test phase, our test-time adaptation procedure leverages unsupervised contrastive learning to guide the model to smoothly generalize to test data under intra-client heterogeneity. Extensive experiments validate the effectiveness of the proposed FedICON in taming heterogeneity to handle test-time shift problems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NYwbmCrrni": {
    "title": "Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning",
    "volume": "poster",
    "abstract": "In many real-world tasks, the concerned objects can be represented as a multi-instance bag associated with a candidate label set, which consists of one ground-truth label and several false positive labels. Multi-instance partial-label learning (MIPL) is a learning paradigm to deal with such tasks and has achieved favorable performances. Existing MIPL approach follows the instance-space paradigm by assigning augmented candidate label sets of bags to each instance and aggregating bag-level labels from instance-level labels. However, this scheme may be suboptimal as global bag-level information is ignored and the predicted labels of bags are sensitive to predictions of negative instances. In this paper, we study an alternative scheme where a multi-instance bag is embedded into a single vector representation. Accordingly, an intuitive algorithm named DEMIPL, i.e., Disambiguated attention Embedding for Multi-Instance Partial-Label learning, is proposed. DEMIPL employs a disambiguation attention mechanism to aggregate a multi-instance bag into a single vector representation, followed by a momentum-based disambiguation strategy to identify the ground-truth label from the candidate label set. Furthermore, we introduce a real-world MIPL dataset for colorectal cancer classification. Experimental results on benchmark and real-world datasets validate the superiority of DEMIPL against the compared MIPL and partial-label learning approaches",
    "checked": true,
    "id": "5f200f0ddef2cabc1354a16f7938419f03fa3d78",
    "semantic_title": "disambiguated attention embedding for multi-instance partial-label learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GGylthmehy": {
    "title": "High dimensional, tabular deep learning with an auxiliary knowledge graph",
    "volume": "poster",
    "abstract": "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high $d$-dimensional features but limited $n$ samples (i.e. $d \\gg n$), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves strong performance on tabular data with $d \\gg n$ by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In PLATO, each input feature corresponds to a node in the auxiliary KG. In the MLP's first layer, each input feature also corresponds to a weight vector. PLATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP's first layer. PLATO captures this inductive bias by inferring the weight vector for each input feature from its corresponding node in the KG via a trainable message-passing function. Across 6 $d \\gg n$ datasets, PLATO outperforms 13 state-of-the-art baselines by up to 10.19%",
    "checked": false,
    "id": "c779710db42fa7dc0ebc6bf98a5d019cb9e8737c",
    "semantic_title": "enabling tabular deep learning when d ≫ n with an auxiliary knowledge graph",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zANxvzflMl": {
    "title": "Towards Foundation Models for Scientific Machine Learning: Characterizing Scaling and Transfer Behavior",
    "volume": "poster",
    "abstract": "Pre-trained machine learning (ML) models have shown great performance for a wide range of applications, in particular in natural language processing (NLP) and computer vision (CV). Here, we study how pre-training could be used for scientific machine learning (SciML) applications, specifically in the context of transfer learning. We study the transfer behavior of these models as (i) the pretrained model size is scaled, (ii) the downstream training dataset size is scaled, (iii) the physics parameters are systematically pushed out of distribution, and (iv) how a single model pre-trained on a mixture of different physics problems can be adapted to various downstream applications. We find that—when fine-tuned appropriately—transfer learning can help reach desired accuracy levels with orders of magnitude fewer downstream examples (across different tasks that can even be out-of-distribution) than training from scratch, with consistent behaviour across a wide range of downstream examples. We also find that fine-tuning these models yields more performance gains as model size increases, compared to training from scratch on new downstream tasks. These results hold for a broad range of PDE learning tasks. All in all, our results demonstrate the potential of the \"pre-train and fine-tune\" paradigm for SciML problems, demonstrating a path towards building SciML foundation models. Our code is available as open-source",
    "checked": true,
    "id": "c8c6408437ac4bce0e00192ff0c339206350f598",
    "semantic_title": "towards foundation models for scientific machine learning: characterizing scaling and transfer behavior",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=lV3LIGlc1w": {
    "title": "Not All Out-of-Distribution Data Are Harmful to Open-Set Active Learning",
    "volume": "poster",
    "abstract": "Active learning (AL) methods have been proven to be an effective way to reduce the labeling effort by intelligently selecting valuable instances for annotation. Despite their great success with in-distribution (ID) scenarios, AL methods suffer from performance degradation in many real-world applications because out-of-distribution (OOD) instances are always inevitably contained in unlabeled data, which may lead to inefficient sampling. Therefore, several attempts have been explored open-set AL by strategically selecting pure ID instances while filtering OOD instances. However, concentrating solely on selecting pseudo-ID instances may cause the training constraint of the ID classifier and OOD detector. To address this issue, we propose a simple yet effective sampling scheme, Progressive Active Learning (PAL), which employs a progressive sampling mechanism to leverage the active selection of valuable OOD instances. The proposed PAL measures unlabeled instances by synergistically evaluating instances' informativeness and representativeness, and thus it can balance the pseudo-ID and pseudo-OOD instances in each round to enhance both the capacity of the ID classifier and the OOD detector. %Meanwhile, PAL measures unlabeled instances by synergistically evaluating instances' informativeness and representativeness, which can more effectively estimate the values of instances. Extensive experiments on various open-set AL scenarios demonstrate the effectiveness of the proposed PAL, compared with the state-of-the-art methods. The code is available at \\url{https://github.com/njustkmg/PAL}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WmqYhqvz5i": {
    "title": "Contextual Bandits and Imitation Learning with Preference-Based Active Queries",
    "volume": "poster",
    "abstract": "We consider the problem of contextual bandits and imitation learning, where the learner lacks direct knowledge of the executed action's reward. Instead, the learner can actively request the expert at each round to compare two actions and receive noisy preference feedback. The learner's objective is two-fold: to minimize regret associated with the executed actions, while simultaneously, minimizing the number of comparison queries made to the expert. In this paper, we assume that the learner has access to a function class that can represent the expert's preference model under appropriate link functions and present an algorithm that leverages an online regression oracle with respect to this function class. For the contextual bandit setting, our algorithm achieves a regret bound that combines the best of both worlds, scaling as $O(\\min\\\\{\\sqrt{T}, d/\\Delta\\\\})$, where $T$ represents the number of interactions, $d$ represents the eluder dimension of the function class, and $\\Delta$ represents the minimum preference of the optimal action over any suboptimal action under all contexts. Our algorithm does not require the knowledge of $\\Delta$, and the obtained regret bound is comparable to what can be achieved in the standard contextual bandits setting where the learner observes reward signals at each round. Additionally, our algorithm makes only $O(\\min\\\\{T, d^2/\\Delta^2\\\\})$ queries to the expert. We then extend our algorithm to the imitation learning setting, where the agent engages with an unknown environment in episodes of length $H$, and provide similar guarantees regarding regret and query complexity. Interestingly, with preference-based feedback, our imitation learning algorithm can learn a policy outperforming a sub-optimal expert, matching the result from interactive imitation learning algorithms [Ross and Bagnell, 2014] that require access to the expert's actions and also reward signals",
    "checked": false,
    "id": "18a387c83289267c79ba4adf6af17c88b73d5180",
    "semantic_title": "contextual bandits and imitation learning via preference-based active queries",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=yyLFUPNEiT": {
    "title": "What Distributions are Robust to Indiscriminate Poisoning Attacks for Linear Learners?",
    "volume": "poster",
    "abstract": "We study indiscriminate poisoning for linear learners where an adversary injects a few crafted examples into the training data with the goal of forcing the induced model to incur higher test error. Inspired by the observation that linear learners on some datasets are able to resist the best known attacks even without any defenses, we further investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners. For theoretical Gaussian distributions, we rigorously characterize the behavior of an optimal poisoning attack, defined as the poisoning strategy that attains the maximum risk of the induced model at a given poisoning budget. Our results prove that linear learners can indeed be robust to indiscriminate poisoning if the class-wise data distributions are well-separated with low variance and the size of the constraint set containing all permissible poisoning points is also small. These findings largely explain the drastic variation in empirical attack performance of the state-of-the-art poisoning attacks on linear learners across benchmark datasets, making an important initial step towards understanding the underlying reasons some learning tasks are vulnerable to data poisoning attacks",
    "checked": true,
    "id": "f63541ae25b88d5b715d64a18a10242c0fd37eb3",
    "semantic_title": "what distributions are robust to indiscriminate poisoning attacks for linear learners?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FV4ngfUlY0": {
    "title": "Non-stationary Experimental Design under Linear Trends",
    "volume": "poster",
    "abstract": "Experimentation has been critical and increasingly popular across various domains, such as clinical trials and online platforms, due to its widely recognized benefits. One of the primary objectives of classical experiments is to estimate the average treatment effect (ATE) to inform future decision-making. However, in healthcare and many other settings, treatment effects may be non-stationary, meaning that they can change over time, rendering the traditional experimental design inadequate and the classical static ATE uninformative. In this work, we address the problem of non-stationary experimental design under linear trends by considering two objectives: estimating the dynamic treatment effect and minimizing welfare loss within the experiment. We propose an efficient design that can be customized for optimal estimation error rate, optimal regret rate, or the Pareto optimal trade-off between the two objectives. We establish information-theoretical lower bounds that highlight the inherent challenge in estimating dynamic treatment effects and minimizing welfare loss, and also statistically reveal the fundamental trade-off between them",
    "checked": false,
    "id": "9a3c98e3f0904922af53e0038099887a0d339f49",
    "semantic_title": "non-stationary experimental design under structured trends",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DCIsNIUCV7": {
    "title": "Payoff-based Learning with Matrix Multiplicative Weights in Quantum Games",
    "volume": "poster",
    "abstract": "In this paper, we study the problem of learning in quantum games - and other classes of semidefinite games - with scalar, payoff-based feedback. For concreteness, we focus on the widely used matrix multiplicative weights (MMW) algorithm and, instead of requiring players to have full knowledge of the game (and/or each other's chosen states), we introduce a suite of minimal-information matrix multiplicative weights (3MW) methods tailored to different information frameworks. The main difficulty to attaining convergence in this setting is that, in contrast to classical finite games, quantum games have an infinite continuum of pure states (the quantum equivalent of pure strategies), so standard importance-weighting techniques for estimating payoff vectors cannot be employed. Instead, we borrow ideas from bandit convex optimization and we design a zeroth-order gradient sampler adapted to the semidefinite geometry of the problem at hand. As a first result, we show that the 3MW method with deterministic payoff feedback retains the $\\mathcal{O}(1/\\sqrt{T})$ convergence rate of the vanilla, full information MMW algorithm in quantum min-max games, even though the players only observe a single scalar. Subsequently, we relax the algorithm's information requirements even further and we provide a 3MW method that only requires players to observe a random realization of their payoff observable, and converges to equilibrium at an $\\mathcal{O}(T^{-1/4})$ rate. Finally, going beyond zero-sum games, we show that a regularized variant of the proposed 3MW method guarantees local convergence with high probability to all equilibria that satisfy a certain first-order stability condition",
    "checked": true,
    "id": "bea06e767b8d8442007c2b905fe7ad6d329ec4d8",
    "semantic_title": "payoff-based learning with matrix multiplicative weights in quantum games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B6qZdrGRpm": {
    "title": "POMDP Planning for Object Search in Partially Unknown Environment",
    "volume": "poster",
    "abstract": "Efficiently searching for target objects in complex environments that contain various types of furniture, such as shelves, tables, and beds, is crucial for mobile robots, but it poses significant challenges due to various factors such as localization errors, limited field of view, and visual occlusion. To address this problem, we propose a Partially Observable Markov Decision Process (POMDP) formulation with a growing state space for object search in a 3D region. We solve this POMDP by carefully designing a perception module and developing a planning algorithm, called Growing Partially Observable Monte-Carlo Planning (GPOMCP), based on online Monte-Carlo tree search and belief tree reuse with a novel upper confidence bound. We have demonstrated that belief tree reuse is reasonable and achieves good performance when the belief differences are limited. Additionally, we introduce a guessed target object with an updating grid world to guide the search in the information-less and reward-less cases, like the absence of any detected objects. We tested our approach using Gazebo simulations on four scenarios of target finding in a realistic indoor living environment with the Fetch robot simulator. Compared to the baseline approaches, which are based on POMCP, our results indicate that our approach enables the robot to find the target object with a higher success rate faster while using the same computational requirements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JTmO2V9Xpz": {
    "title": "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers",
    "volume": "poster",
    "abstract": "Autoregressive transformers are spectacular models for short sequences but scale poorly to long sequences such as high-resolution images, podcasts, code, or books. We proposed Megabyte, a multi-scale decoder architecture that enables end-to-end differentiable modeling of sequences of over one million bytes. Megabyte segments sequences into patches and uses a local submodel within patches and a global model between patches. This enables sub-quadratic self-attention, much larger feedforward layers for the same compute, and improved parallelism during decoding---unlocking better performance at reduced cost for both training and generation. Extensive experiments show that Megabyte allows byte-level models to perform competitively with subword models on long context language modeling, achieve state-of-the-art density estimation on ImageNet, and model audio from raw files. Together, these results establish the viability of tokenization-free autoregressive sequence modeling at scale",
    "checked": true,
    "id": "412e266cddfd87c79087a88ba1e4d11b89a45a13",
    "semantic_title": "megabyte: predicting million-byte sequences with multiscale transformers",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=xx3qRKvG0T": {
    "title": "BasisFormer: Attention-based Time Series Forecasting with Learnable and Interpretable Basis",
    "volume": "poster",
    "abstract": "Bases have become an integral part of modern deep learning-based models for time series forecasting due to their ability to act as feature extractors or future references. To be effective, a basis must be tailored to the specific set of time series data and exhibit distinct correlation with each time series within the set. However, current state-of-the-art methods are limited in their ability to satisfy both of these requirements simultaneously. To address this challenge, we propose BasisFormer, an end-to-end time series forecasting architecture that leverages learnable and interpretable bases. This architecture comprises three components: First, we acquire bases through adaptive self-supervised learning, which treats the historical and future sections of the time series as two distinct views and employs contrastive learning. Next, we design a Coef module that calculates the similarity coefficients between the time series and bases in the historical view via bidirectional cross-attention. Finally, we present a Forecast module that selects and consolidates the bases in the future view based on the similarity coefficients, resulting in accurate future predictions. Through extensive experiments on six datasets, we demonstrate that BasisFormer outperforms previous state-of-the-art methods by 11.04% and 15.78% respectively for univariate and multivariate forecasting tasks. Code is available at: https://github.com/nzl5116190/Basisformer",
    "checked": true,
    "id": "6c3575978251a303595be7ae93a283702acd7db9",
    "semantic_title": "basisformer: attention-based time series forecasting with learnable and interpretable basis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b8xowIlZ7v": {
    "title": "A case for reframing automated medical image classification as segmentation",
    "volume": "poster",
    "abstract": "Image classification and segmentation are common applications of deep learning to radiology. While many tasks can be framed using either classification or segmentation, classification has historically been cheaper to label and more widely used. However, recent work has drastically reduced the cost of training segmentation networks. In light of this recent work, we reexamine the choice of training classification vs. segmentation models. First, we use an information theoretic approach to analyze why segmentation vs. classification models may achieve different performance on the same dataset and overarching task. We then implement multiple methods for using segmentation models to classify medical images, which we call *segmentation-for-classification*, and compare these methods against traditional classification on three retrospective datasets. We use our analysis and experiments to summarize the benefits of switching from segmentation to classification, including: improved sample efficiency, enabling improved performance with fewer labeled images (up to an order of magnitude lower), on low-prevalence classes, and on certain rare subgroups (up to 161.1\\% improved recall); improved robustness to spurious correlations (up to 44.8\\% improved robust AUROC); and improved model interpretability, evaluation, and error analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9eneYFIGKq": {
    "title": "Inner Product-based Neural Network Similarity",
    "volume": "poster",
    "abstract": "Analyzing representational similarity among neural networks (NNs) is essential for interpreting or transferring deep models. In application scenarios where numerous NN models are learned, it becomes crucial to assess model similarities in computationally efficient ways. In this paper, we propose a new paradigm for reducing NN representational similarity to filter subspace distance. Specifically, when convolutional filters are decomposed as a linear combination of a set of filter subspace elements, denoted as filter atoms, and have those decomposed atom coefficients shared across networks, NN representational similarity can be significantly simplified as calculating the cosine distance among respective filter atoms, to achieve millions of times computation reduction over popular probing-based methods. We provide both theoretical and empirical evidence that such simplified filter subspace-based similarity preserves a strong linear correlation with other popular probing-based metrics, while being significantly more efficient to obtain and robust to probing data. We further validate the effectiveness of the proposed method in various application scenarios where numerous models exist, such as federated and continual learning as well as analyzing training dynamics. We hope our findings can help further explorations of real-time large-scale representational similarity analysis in neural networks",
    "checked": false,
    "id": "196d8e4530cf008dcf3256df05e9b785e9d43ce0",
    "semantic_title": "a wavelet-based neural network scheme for supervised and unsupervised learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=xUyBP16Q5J": {
    "title": "Rethinking Incentives in Recommender Systems: Are Monotone Rewards Always Beneficial?",
    "volume": "poster",
    "abstract": "The past decade has witnessed the flourishing of a new profession as media content creators, who rely on revenue streams from online content recommendation platforms. The reward mechanism employed by these platforms creates a competitive environment among creators which affects their production choices and, consequently, content distribution and system welfare. It is thus crucial to design the platform's reward mechanism in order to steer the creators' competition towards a desirable welfare outcome in the long run. This work makes two major contributions in this regard: first, we uncover a fundamental limit about a class of widely adopted mechanisms, coined \\emph{Merit-based Monotone Mechanisms}, by showing that they inevitably lead to a constant fraction loss of the optimal welfare. To circumvent this limitation, we introduce \\emph{Backward Rewarding Mechanisms} (BRMs) and show that the competition game resultant from BRMs possesses a potential game structure. BRMs thus naturally induce strategic creators' collective behaviors towards optimizing the potential function, which can be designed to match any given welfare metric. In addition, the class of BRM can be parameterized so that it allows the platform to directly optimize welfare within the feasible mechanism space even when the welfare metric is not explicitly defined",
    "checked": true,
    "id": "8d22974cc856554d8d3afd780b9bc25f0e30c96e",
    "semantic_title": "rethinking incentives in recommender systems: are monotone rewards always beneficial?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=oDcWnfZyZW": {
    "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective",
    "volume": "poster",
    "abstract": "Off-policy Learning to Rank (LTR) aims to optimize a ranker from data collected by a deployed logging policy. However, existing off-policy learning to rank methods often make strong assumptions about how users generate the click data, i.e., the click model, and hence need to tailor their methods specifically under different click models. In this paper, we unified the ranking process under general stochastic click models as a Markov Decision Process (MDP), and the optimal ranking could be learned with offline reinforcement learning (RL) directly. Building upon this, we leverage offline RL techniques for off-policy LTR and propose the Click Model-Agnostic Unified Off-policy Learning to Rank (CUOLR) method, which could be easily applied to a wide range of click models. Through a dedicated formulation of the MDP, we show that offline RL algorithms can adapt to various click models without complex debiasing techniques and prior knowledge of the model. Results on various large-scale datasets demonstrate that CUOLR consistently outperforms the state-of-the-art off-policy learning to rank algorithms while maintaining consistency and robustness under different click models",
    "checked": true,
    "id": "da25e0c1780d819a9053f38122bd9626dca34655",
    "semantic_title": "unified off-policy learning to rank: a reinforcement learning perspective",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k9zSU3pdi4": {
    "title": "Open Compound Domain Adaptation with Object Style Compensation for Semantic Segmentation",
    "volume": "poster",
    "abstract": "Many methods of semantic image segmentation have borrowed the success of open compound domain adaptation. They minimize the style gap between the images of source and target domains, more easily predicting the accurate pseudo annotations for target domain's images that train segmentation network. The existing methods globally adapt the scene style of the images, whereas the object styles of different categories or instances are adapted improperly. This paper proposes the Object Style Compensation, where we construct the Object-Level Discrepancy Memory with multiple sets of discrepancy features. The discrepancy features in a set capture the style changes of the same category's object instances adapted from target to source domains. We learn the discrepancy features from the images of source and target domains, storing the discrepancy features in memory. With this memory, we select appropriate discrepancy features for compensating the style information of the object instances of various categories, adapting the object styles to a unified style of source domain. Our method enables a more accurate computation of the pseudo annotations for target domain's images, thus yielding state-of-the-art results on different datasets",
    "checked": true,
    "id": "8e879ffbf68681ca65b1e6922ca6066c0086b10f",
    "semantic_title": "open compound domain adaptation with object style compensation for semantic segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2ccH4zjKVs": {
    "title": "Robust Second-Order Nonconvex Optimization and Its Application to Low Rank Matrix Sensing",
    "volume": "poster",
    "abstract": "Finding an approximate second-order stationary point (SOSP) is a well-studied and fundamental problem in stochastic nonconvex optimization with many applications in machine learning. However, this problem is poorly understood in the presence of outliers, limiting the use of existing nonconvex algorithms in adversarial settings. In this paper, we study the problem of finding SOSPs in the strong contamination model, where a constant fraction of datapoints are arbitrarily corrupted. We introduce a general framework for efficiently finding an approximate SOSP with \\emph{dimension-independent} accuracy guarantees, using $\\widetilde{O}({D^2}/{\\epsilon})$ samples where $D$ is the ambient dimension and $\\epsilon$ is the fraction of corrupted datapoints. As a concrete application of our framework, we apply it to the problem of low rank matrix sensing, developing efficient and provably robust algorithms that can tolerate corruptions in both the sensing matrices and the measurements. In addition, we establish a Statistical Query lower bound providing evidence that the quadratic dependence on $D$ in the sample complexity is necessary for computationally efficient algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Drrl2gcjzl": {
    "title": "The Impact of Positional Encoding on Length Generalization in Transformers",
    "volume": "poster",
    "abstract": "Length generalization, the ability to generalize from small training context sizes to larger ones, is a critical challenge in the development of Transformer-based language models. Positional encoding (PE) has been identified as a major factor influencing length generalization, but the exact impact of different PE schemes on extrapolation in downstream tasks remains unclear. In this paper, we conduct a systematic empirical study comparing the length generalization performance of decoder-only Transformers with five different position encoding approaches including Absolute Position Embedding (APE), T5's Relative PE, ALiBi, and Rotary, in addition to Transformers without positional encoding (NoPE). Our evaluation encompasses a battery of reasoning and mathematical tasks. Our findings reveal that the most commonly used positional encoding methods, such as ALiBi, Rotary, and APE, are not well suited for length generalization in downstream tasks. More importantly, NoPE outperforms other explicit positional encoding methods while requiring no additional computation. We theoretically demonstrate that NoPE can represent both absolute and relative PEs, but when trained with SGD, it mostly resembles T5's relative PE attention patterns. Finally, we find that scratchpad is not always helpful to solve length generalization and its format highly impacts the model's performance. Overall, our work suggests that explicit position embeddings are not essential for decoder-only Transformers to generalize well to longer sequences",
    "checked": true,
    "id": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4",
    "semantic_title": "the impact of positional encoding on length generalization in transformers",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=p9k5MS0JAL": {
    "title": "Demystifying the Optimal Performance of Multi-Class Classification",
    "volume": "poster",
    "abstract": "Classification is a fundamental task in science and engineering on which machine learning methods have shown outstanding performances. However, it is challenging to determine whether such methods have achieved the Bayes error rate, that is, the lowest error rate attained by any classifier. This is mainly due to the fact that the Bayes error rate is not known in general and hence, effectively estimating it is paramount. Inspired by the work by Ishida et al. (2023), we propose an estimator for the Bayes error rate of supervised multi-class classification problems. We analyze several theoretical aspects of such estimator, including its consistency, unbiasedness, convergence rate, variance, and robustness. We also propose a denoising method that reduces the noise that potentially corrupts the data labels, and we improve the robustness of the proposed estimator to outliers by incorporating the median-of-means estimator. Our analysis demonstrates the consistency, asymptotic unbiasedness, convergence rate, and robustness of the proposed estimators. Finally, we validate the effectiveness of our theoretical results via experiments both on synthetic data under various noise settings and on real data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=brOMKBEGXP": {
    "title": "Self-Chained Image-Language Model for Video Localization and Question Answering",
    "volume": "poster",
    "abstract": "Recent studies have shown promising results on utilizing large pre-trained image-language models for video question answering. While these image-language models can efficiently bootstrap the representation learning of video-language models, they typically concatenate uniformly sampled video frames as visual inputs without explicit language-aware, temporal modeling. When only a portion of a video input is relevant to the language query, such uniform frame sampling can often lead to missing important visual cues. Although humans often find a video moment to focus on and rewind the moment to answer questions, training a query-aware video moment localizer often requires expensive annotations and high computational costs. To address this issue, we propose Self-Chained Video Localization-Answering (SeViLA), a novel framework that leverages a single image-language model (BLIP- 2) to tackle both temporal keyframe localization and question answering on videos. SeViLA framework consists of two modules: Localizer and Answerer, where both are parameter-efficiently fine-tuned from BLIP-2. We propose two ways of chaining these modules for cascaded inference and self-refinement. First, in the forward chain, the Localizer finds multiple language-aware keyframes in a video, which the Answerer uses to predict the answer. Second, in the reverse chain, the Answerer generates keyframe pseudo-labels to refine the Localizer, alleviating the need for expensive video moment localization annotations. Our SeViLA framework outperforms several strong baselines/previous works on five challenging video question answering and event prediction benchmarks, and achieves the state-of-the-art in both fine-tuning (NExT-QA and STAR) and zero-shot (NExT-QA, STAR, How2QA, and VLEP) settings. We show a comprehensive analysis of our framework, including the impact of Localizer, comparisons of Localizer with other temporal localization models, pre-training/self-refinement of Localizer, and varying the number of keyframes",
    "checked": true,
    "id": "8badb0587fef2ffc078b0cec549eb8ec96ed3ad4",
    "semantic_title": "self-chained image-language model for video localization and question answering",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=RRSltzPc7w": {
    "title": "IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI",
    "volume": "poster",
    "abstract": "Diffusion-based image generation models, such as Stable Diffusion or DALL·E 2, are able to learn from given images and generate high-quality samples following the guidance from prompts. For instance, they can be used to create artistic images that mimic the style of an artist based on his/her original artworks or to maliciously edit the original images for fake content. However, such ability also brings serious ethical issues without proper authorization from the owner of the original images. In response, several attempts have been made to protect the original images from such unauthorized data usage by adding imperceptible perturbations, which are designed to mislead the diffusion model and make it unable to properly generate new samples. In this work, we introduce a perturbation purification platform, named IMPRESS, to evaluate the effectiveness of imperceptible perturbations as a protective measure. IMPRESS is based on the key observation that imperceptible perturbations could lead to a perceptible inconsistency between the original image and the diffusion-reconstructed image, which can be used to devise a new optimization strategy for purifying the image, which may weaken the protection of the original image from unauthorized data usage (e.g., style mimicking, malicious editing). The proposed IMPRESS platform offers a comprehensive evaluation of several contemporary protection methods, and can be used as an evaluation platform for future protection methods",
    "checked": true,
    "id": "c0359ad23c7374bde0a361e01854553f7d73b80e",
    "semantic_title": "impress: evaluating the resilience of imperceptible perturbations against unauthorized data usage in diffusion-based generative ai",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wxkBdtDbmH": {
    "title": "Natural Actor-Critic for Robust Reinforcement Learning with Function Approximation",
    "volume": "poster",
    "abstract": "We study robust reinforcement learning (RL) with the goal of determining a well-performing policy that is robust against model mismatch between the training simulator and the testing environment. Previous policy-based robust RL algorithms mainly focus on the tabular setting under uncertainty sets that facilitate robust policy evaluation, but are no longer tractable when the number of states scales up. To this end, we propose two novel uncertainty set formulations, one based on double sampling and the other on an integral probability metric. Both make large-scale robust RL tractable even when one only has access to a simulator. We propose a robust natural actor-critic (RNAC) approach that incorporates the new uncertainty sets and employs function approximation. We provide finite-time convergence guarantees for the proposed RNAC algorithm to the optimal robust policy within the function approximation error. Finally, we demonstrate the robust performance of the policy learned by our proposed RNAC approach in multiple MuJoCo environments and a real-world TurtleBot navigation task",
    "checked": true,
    "id": "b284d0899d8a1dd31461c81074deadcbcd577be4",
    "semantic_title": "natural actor-critic for robust reinforcement learning with function approximation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WfsWy59bX2": {
    "title": "Anonymous Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization",
    "volume": "poster",
    "abstract": "While personalized recommendations systems have become increasingly popular, ensuring user data protection remains a top concern in the development of these learning systems. A common approach to enhancing privacy involves training models using anonymous data rather than individual data. In this paper, we explore a natural technique called \"look-alike clustering\", which involves replacing sensitive features of individuals with the cluster's average values. We provide a precise analysis of how training models using anonymous cluster centers affects their generalization capabilities. We focus on an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT) and allows us to theoretically understand the role of different model components on the generalization error. In addition, we demonstrate that in certain high-dimensional regimes, training over anonymous cluster centers acts as a regularization and improves generalization error of the trained models. Finally, we corroborate our asymptotic theory with finite-sample numerical experiments where we observe a perfect match when the sample size is only of order of a few hundreds",
    "checked": true,
    "id": "7d52df6b1593a4e9cbb8d084f69be46c5d432220",
    "semantic_title": "anonymous learning via look-alike clustering: a precise analysis of model generalization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u8srPlinoj": {
    "title": "ReDS: Offline RL With Heteroskedastic Datasets via Support Constraints",
    "volume": "poster",
    "abstract": "Offline reinforcement learning (RL) learns policies entirely from static datasets. Practical applications of offline RL will inevitably require learning from datasets where the variability of demonstrated behaviors changes non-uniformly across the state space. For example, at a red light, nearly all human drivers behave similarly by stopping, but when merging onto a highway, some drivers merge quickly, efficiently, and safely, while many hesitate or merge dangerously. Both theoretically and empirically, we show that typical offline RL methods, which are based on distribution constraints fail to learn from data with such non-uniform variability, due to the requirement to stay close to the behavior policy **to the same extent** across the state space. Ideally, the learned policy should be free to choose **per state** how closely to follow the behavior policy to maximize long-term return, as long as the learned policy stays within the support of the behavior policy. To instantiate this principle, we reweight the data distribution in conservative Q-learning (CQL) to obtain an approximate support constraint formulation. The reweighted distribution is a mixture of the current policy and an additional policy trained to mine poor actions that are likely under the behavior policy. Our method, CQL (ReDS), is theoretically motivated, and improves performance across a wide range of offline RL problems in games, navigation, and pixel-based manipulation",
    "checked": false,
    "id": "bacc496fc1adac13c2913638a75448e363a4b258",
    "semantic_title": "offline rl with realistic datasets: heteroskedasticity and support constraints",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=009LK0vLcY": {
    "title": "Finite Population Regression Adjustment and Non-asymptotic Guarantees for Treatment Effect Estimation",
    "volume": "poster",
    "abstract": "The design and analysis of randomized experiments is fundamental to many areas, from the physical and social sciences to industrial settings. Regression adjustment is a popular technique to reduce the variance of estimates obtained from experiments, by utilizing information contained in auxiliary covariates. While there is a large literature within the statistics community studying various approaches to regression adjustment and their asymptotic properties, little focus has been given to approaches in the finite population setting with non-asymptotic accuracy bounds. Further, prior work typically assumes that an entire population is exposed to an experiment, whereas practitioners often seek to minimize the number of subjects exposed to an experiment, for ethical and pragmatic reasons. In this work, we study the problems of estimating the sample mean, individual treatment effects, and average treatment effect with regression adjustment. We propose approaches that use techniques from randomized numerical linear algebra to sample a subset of the population on which to perform an experiment. We give non-asymptotic accuracy bounds for our methods and demonstrate that they compare favorably with prior approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OWELckerm6": {
    "title": "Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions",
    "volume": "poster",
    "abstract": "Recent advances in attention-free sequence models rely on convolutions as alternatives to the attention operator at the core of Transformers. In particular, long convolution sequence models have achieved state-of-the-art performance in many domains, but incur a significant cost during auto-regressive inference workloads -- naively requiring a full pass (or caching of activations) over the input sequence for each generated token -- similarly to attention-based models. In this paper, we seek to enable $\\mathcal O(1)$ compute and memory cost per token in any pre-trained long convolution architecture to reduce memory footprint and increase throughput during generation. Concretely, our methods consist in extracting low-dimensional linear state-space models from each convolution layer, building upon rational interpolation and model-order reduction techniques. We further introduce architectural improvements to convolution-based layers such as Hyena: by weight-tying the filters across channels into heads, we achieve higher pre-training quality and reduce the number of filters to be distilled. The resulting model achieves 10x higher throughput than Transformers and 1.5x higher than Hyena at 1.3B parameters, without any loss in quality after distillation",
    "checked": true,
    "id": "cb0ac335adda4ceef9987cbcbca9129e71c37f0a",
    "semantic_title": "laughing hyena distillery: extracting compact recurrences from convolutions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sdlh4gVOj8": {
    "title": "On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling and Beyond",
    "volume": "poster",
    "abstract": "We seek to understand what facilitates sample-efficient learning from historical datasets for sequential decision-making, a problem that is popularly known as offline reinforcement learning (RL). Further, we are interested in algorithms that enjoy sample efficiency while leveraging (value) function approximation. In this paper, we address these fundamental questions by (i) proposing a notion of data diversity that subsumes the previous notions of coverage measures in offline RL and (ii) using this notion to \\emph{unify} three distinct classes of offline RL algorithms based on version spaces (VS), regularized optimization (RO), and posterior sampling (PS). We establish that VS-based, RO-based, and PS-based algorithms, under standard assumptions, achieve \\emph{comparable} sample efficiency, which recovers the state-of-the-art sub-optimality bounds for finite and linear model classes with the standard assumptions. This result is surprising, given that the prior work suggested an unfavorable sample complexity of the RO-based algorithm compared to the VS-based algorithm, whereas posterior sampling is rarely considered in offline RL due to its explorative nature. Notably, our proposed model-free PS-based algorithm for offline RL is \\emph{novel}, with sub-optimality bounds that are \\emph{frequentist} (i.e., worst-case) in nature",
    "checked": false,
    "id": "5bac7d00035bc1e246a34f9ee3152b290f97bb92",
    "semantic_title": "supervised pretraining can learn in-context reinforcement learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=x6cOcxRnxG": {
    "title": "Neural Ideal Large Eddy Simulation: Modeling Turbulence with Neural Stochastic Differential Equations",
    "volume": "poster",
    "abstract": "We introduce a data-driven learning framework that assimilates two powerful ideas: ideal large eddy simulation (LES) from turbulence closure modeling and neural stochastic differential equations (SDE) for stochastic modeling. The ideal LES models the LES flow by treating each full-order trajectory as a random realization of the underlying dynamics, as such, the effect of small-scales is marginalized to obtain the deterministic evolution of the LES state. However, ideal LES is analytically intractable. In our work, we use a latent neural SDE to model the evolution of the stochastic process and an encoder-decoder pair for transforming between the latent space and the desired ideal flow field. This stands in sharp contrast to other types of neural parameterization of closure models where each trajectory is treated as a deterministic realization of the dynamics. We show the effectiveness of our approach (niLES – neural ideal LES) on two challenging chaotic dynamical systems: Kolmogorov flow at a Reynolds number of 20,000 and flow past a cylinder at Reynolds number 500. Compared to competing methods, our method can handle non-uniform geometries using unstructured meshes seamlessly. In particular, niLES leads to trajectories with more accurate statistics and enhances stability, particularly for long-horizon rollouts. (Source codes and datasets will be made publicly available.)",
    "checked": true,
    "id": "c2a5f24c5802af3c02002d34550a0775349cfe8b",
    "semantic_title": "neural ideal large eddy simulation: modeling turbulence with neural stochastic differential equations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=LloZFVwWvj": {
    "title": "Non-autoregressive Machine Translation with Probabilistic Context-free Grammar",
    "volume": "poster",
    "abstract": "Non-autoregressive Transformer(NAT) significantly accelerates the inference of neural machine translation. However, conventional NAT models suffer from limited expression power and performance degradation compared to autoregressive (AT) models due to the assumption of conditional independence among target tokens. To address these limitations, we propose a novel approach called PCFG-NAT, which leverages a specially designed Probabilistic Context-Free Grammar (PCFG) to enhance the ability of NAT models to capture complex dependencies among output tokens. Experimental results on major machine translation benchmarks demonstrate that PCFG-NAT further narrows the gap in translation quality between NAT and AT models. Moreover, PCFG-NAT facilitates a deeper understanding of the generated sentences, addressing the lack of satisfactory explainability in neural machine translation. Code is publicly available at https://github.com/ictnlp/PCFG-NAT",
    "checked": true,
    "id": "1373e59da4c89c44773173b124cc460f680e9089",
    "semantic_title": "non-autoregressive machine translation with probabilistic context-free grammar",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zAQK5r1enm": {
    "title": "Decision Stacks: Flexible Reinforcement Learning via Modular Generative Models",
    "volume": "poster",
    "abstract": "Reinforcement learning presents an attractive paradigm to reason about several distinct aspects of sequential decision making, such as specifying complex goals, planning future observations and actions, and critiquing their utilities. However, the combined integration of these capabilities poses competing algorithmic challenges in retaining maximal expressivity while allowing for flexibility in modeling choices for efficient learning and inference. We present Decision Stacks, a generative framework that decomposes goal-conditioned policy agents into 3 generative modules. These modules simulate the temporal evolution of observations, rewards, and actions via independent generative models that can be learned in parallel via teacher forcing. Our framework guarantees both expressivity and flexibility in designing individual modules to account for key factors such as architectural bias, optimization objective and dynamics, transferrability across domains, and inference speed. Our empirical results demonstrate the effectiveness of Decision Stacks for offline policy optimization for several MDP and POMDP environments, outperforming existing methods and enabling flexible generative decision making",
    "checked": true,
    "id": "dc0f9a4988fccd8cdd6d64e475306f8a639ac1af",
    "semantic_title": "decision stacks: flexible reinforcement learning via modular generative models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Kvaa3DhvlZ": {
    "title": "Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation",
    "volume": "poster",
    "abstract": "Image captioning aims to describe visual content in natural language. As 'a picture is worth a thousand words', there could be various correct descriptions for an image. However, with maximum likelihood estimation as the training objective, the captioning model is penalized whenever its prediction mismatches with the label. For instance, when the model predicts a word expressing richer semantics than the label, it will be penalized and optimized to prefer more concise expressions, referred to as *conciseness optimization*. In contrast, predictions that are more concise than labels lead to *richness optimization*. Such conflicting optimization directions could eventually result in the model generating general descriptions. In this work, we introduce Semipermeable MaxImum Likelihood Estimation (SMILE), which allows richness optimization while blocking conciseness optimization, thus encouraging the model to generate longer captions with more details. Extensive experiments on two mainstream image captioning datasets MSCOCO and Flickr30K demonstrate that SMILE significantly enhances the descriptiveness of generated captions. We further provide in-depth investigations to facilitate a better understanding of how SMILE works",
    "checked": true,
    "id": "7614d6a5b12aa82f403d5fbfa8b115e571909518",
    "semantic_title": "learning descriptive image captioning via semipermeable maximum likelihood estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3b9sqxCW1x": {
    "title": "A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks",
    "volume": "poster",
    "abstract": "Deep learning models often suffer from forgetting previously learned information when trained on new data. This problem is exacerbated in federated learning (FL), where the data is distributed and can change independently for each user. Many solutions are proposed to resolve this catastrophic forgetting in a centralized setting. However, they do not apply directly to FL because of its unique complexities, such as privacy concerns and resource limitations. To overcome these challenges, this paper presents a framework for \\textbf{federated class incremental learning} that utilizes a generative model to synthesize samples from past distributions. This data can be later exploited alongside the training data to mitigate catastrophic forgetting. To preserve privacy, the generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Moreover, our solution does not demand the users to store old data or models, which gives them the freedom to join/leave the training at any time. Additionally, we introduce SuperImageNet, a new regrouping of the ImageNet dataset specifically tailored for federated continual learning. We demonstrate significant improvements compared to existing baselines through extensive experiments on multiple datasets",
    "checked": true,
    "id": "3993620adc0df18e5f2aa8a0ba2eefbf5667ca7f",
    "semantic_title": "a data-free approach to mitigate catastrophic forgetting in federated class incremental learning for vision tasks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8QGukmdAbh": {
    "title": "New Bounds for Hyperparameter Tuning of Regression Problems Across Instances",
    "volume": "poster",
    "abstract": "The task of tuning regularization coefficients in regularized regression models with provable guarantees across problem instances still poses a significant challenge in the literature. This paper investigates the sample complexity of tuning regularization parameters in linear and logistic regressions under $\\ell_1$ and $\\ell_2$-constraints in the data-driven setting. For the linear regression problem, by more carefully exploiting the structure of the dual function class, we provide a new upper bound for the pseudo-dimension of the validation loss function class, which significantly improves the best-known results on the problem. Remarkably, we also instantiate the first matching lower bound, proving our results are tight. For tuning the regularization parameters of logistic regression, we introduce a new approach to studying the learning guarantee via an approximation of the validation loss function class. We examine the pseudo-dimension of the approximation class and construct a uniform error bound between the validation loss function class and its approximation, which allows us to instantiate the first learning guarantee for the problem of tuning logistic regression regularization coefficients",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EGfYnTyEGv": {
    "title": "A Long $N$-step Surrogate Stage Reward for Deep Reinforcement Learning",
    "volume": "poster",
    "abstract": "We introduce a new stage reward estimator named the long $N$-step surrogate stage (LNSS) reward for deep reinforcement learning (RL). It aims at mitigating the high variance problem, which has shown impeding successful convergence of learning, hurting task performance, and hindering applications of deep RL in continuous control problems. In this paper we show that LNSS, which utilizes a long reward trajectory of rewards of future steps, provides consistent performance improvement measured by average reward, convergence speed, learning success rate,and variance reduction in $Q$ values and rewards. Our evaluations are based on a variety of environments in DeepMind Control Suite and OpenAI Gym by using LNSS in baseline deep RL algorithms such as DDPG, D4PG, and TD3. We show that LNSS reward has enabled good results that have been challenging to obtain by deep RL previously. Our analysis also shows that LNSS exponentially reduces the upper bound on the variances of $Q$ values from respective single-step methods",
    "checked": false,
    "id": "ad55e3eca451705dfe8bb200b9f0f0e199fb1d75",
    "semantic_title": "long n-step surrogate stage reward to reduce variances of deep reinforcement learning in complex problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=559NJBfN20": {
    "title": "Language Models are Weak Learners",
    "volume": "poster",
    "abstract": "A central notion in practical and theoretical machine learning is that of a *weak learner*, classifiers that achieve better-than-random performance (on any given distribution over data), even by a small margin. Such weak learners form the practical basis for canonical machine learning methods such as boosting. In this work, we illustrate that prompt-based large language models can operate effectively as said weak learners. Specifically, we illustrate the use of a large language model (LLM) as a weak learner in a boosting algorithm applied to tabular data. We show that by providing (properly sampled according to the distribution of interest) text descriptions of tabular data samples, LLMs can produce a summary of the samples that serves as a template for classification, and achieves the aim of acting as a weak learner on this task. We incorporate these models into a boosting approach, which in many settings can leverage the knowledge within the LLM to outperform traditional tree-based boosting. The model outperforms both few-shot learning and occasionally even more involved fine-tuning procedures, particularly for some tasks involving small numbers of data points. The results illustrate the potential for prompt-based LLMs to function not just as few-shot learners themselves, but as components of larger machine learning models",
    "checked": true,
    "id": "7d87fbdfbf5038a4e0ff09801b6d3b8a2e0c613a",
    "semantic_title": "language models are weak learners",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B2DEcj4a7i": {
    "title": "Counterfactually Comparing Abstaining Classifiers",
    "volume": "poster",
    "abstract": "Abstaining classifiers have the option to abstain from making predictions on inputs that they are unsure about. These classifiers are becoming increasingly popular in high-stake decision-making problems, as they can withhold uncertain predictions to improve their reliability and safety. When evaluating black-box abstaining classifier(s), however, we lack a principled approach that accounts for what the classifier would have predicted on its abstentions. These missing predictions matter when they can eventually be utilized, either directly or as a backup option in a failure mode. In this paper, we introduce a novel approach and perspective to the problem of evaluating and comparing abstaining classifiers by treating abstentions as missing data. Our evaluation approach is centered around defining the counterfactual score of an abstaining classifier, defined as the expected performance of the classifier had it not been allowed to abstain. We specify the conditions under which the counterfactual score is identifiable: if the abstentions are stochastic, and if the evaluation data is independent of the training data (ensuring that the predictions are missing at random), then the score is identifiable. Note that, if abstentions are deterministic, then the score is unidentifiable because the classifier can perform arbitrarily poorly on its abstentions. Leveraging tools from observational causal inference, we then develop nonparametric and doubly robust methods to efficiently estimate this quantity under identification. Our approach is examined in both simulated and real data experiments",
    "checked": true,
    "id": "bf7af0f9371f19493b5f08a742d9984c0bc3facc",
    "semantic_title": "counterfactually comparing abstaining classifiers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2D7ou48q0E": {
    "title": "Navigating Data Heterogeneity in Federated Learning: A Semi-Supervised Approach for Object Detection",
    "volume": "poster",
    "abstract": "Federated Learning (FL) has emerged as a potent framework for training models across distributed data sources while maintaining data privacy. Nevertheless, it faces challenges with limited high-quality labels and non-IID client data, particularly in applications like autonomous driving. To address these hurdles, we navigate the uncharted waters of Semi-Supervised Federated Object Detection (SSFOD). We present a pioneering SSFOD framework, designed for scenarios where labeled data reside only at the server while clients possess unlabeled data. Notably, our method represents the inaugural implementation of SSFOD for clients with 0% labeled non-IID data, a stark contrast to previous studies that maintain some subset of labels at each client. We propose FedSTO, a two-stage strategy encompassing Selective Training followed by Orthogonally enhanced full-parameter training, to effectively address data shift (e.g. weather conditions) between server and clients. Our contributions include selectively refining the backbone of the detector to avert overfitting, orthogonality regularization to boost representation divergence, and local EMA-driven pseudo label assignment to yield high-quality pseudo labels. Extensive validation on prominent autonomous driving datasets (BDD100K, Cityscapes, and SODA10M) attests to the efficacy of our approach, demonstrating state-of-the-art results. Remarkably, FedSTO, using just 20-30% of labels, performs nearly as well as fully-supervised centralized training methods",
    "checked": false,
    "id": "490b98e44d2e69f1aaabe4dba2c39d170c348b75",
    "semantic_title": "navigating data heterogeneity in federated learning a semi-supervised approach for object detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5zipcfLC2Z": {
    "title": "MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining",
    "volume": "poster",
    "abstract": "Although BERT-style encoder models are heavily used in NLP research, many researchers do not pretrain their own BERTs from scratch due to the high cost of training. In the past half-decade since BERT first rose to prominence, many advances have been made with other transformer architectures and training configurations that have yet to be systematically incorporated into BERT. Here, we introduce MosaicBERT, a BERT-style encoder architecture and training recipe that is empirically optimized for fast pretraining. This efficient architecture incorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear Units (GLU), a module to dynamically remove padded tokens, and low precision LayerNorm into the classic transformer encoder block. The training recipe includes a 30% masking ratio for the Masked Language Modeling (MLM) objective, bfloat16 precision, and vocabulary size optimized for GPU throughput, in addition to best-practices from RoBERTa and other encoder models. When pretrained from scratch on the C4 dataset, this base model achieves a downstream average GLUE score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs at a cost of roughly $20. We plot extensive accuracy vs. pretraining speed Pareto curves and show that MosaicBERT base and large are consistently Pareto optimal when compared to a competitive BERT base and large. This empirical speed up in pretraining enables researchers and engineers to pretrain custom BERT-style models at low cost instead of finetune on existing generic models. We open source our model weights and code",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SLwy8UVS8Y": {
    "title": "PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Model",
    "volume": "poster",
    "abstract": "Autoregressive models for text sometimes generate repetitive and low-quality output because errors accumulate during the steps of generation. This issue is often attributed to exposure bias -- the difference between how a model is trained, and how it is used during inference. Denoising diffusion models provide an alternative approach in which a model can revisit and revise its output. However, they can be computationally expensive and prior efforts on text have led to models that produce less fluent output compared to autoregressive models, especially for longer text and paragraphs. In this paper, we propose PLANNER, a model that combines latent semantic diffusion with autoregressive generation, to generate fluent text while exercising global control over paragraphs. The model achieves this by combining an autoregressive \"decoding\" module with a \"planning\" module that uses latent diffusion to generate semantic paragraph embeddings in a coarse-to-fine manner. The proposed method is evaluated on various conditional generation tasks, and results on semantic generation, text completion and summarization show its effectiveness in generating high-quality long-form text in an efficient manner",
    "checked": true,
    "id": "4c26a1c6e573c772e1634b1747d7e9a3b33dce52",
    "semantic_title": "planner: generating diversified paragraph via latent language diffusion model",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=6Qx7G1xrAk": {
    "title": "ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation",
    "volume": "poster",
    "abstract": "Joint speech-language training is challenging due to the large demand for training data and GPU consumption, as well as the modality gap between speech and language. We present ComSL, a speech-language model built atop a composite architecture of public pre-trained speech-only and language-only models and optimized data-efficiently for spoken language tasks. Particularly, we propose to incorporate cross-modality learning into transfer learning and conduct them simultaneously for downstream tasks in a multi-task learning manner. Our approach has demonstrated effectiveness in end-to-end speech-to-text translation tasks, achieving a new state-of-the-art average BLEU score of 31.5 on the multilingual speech to English text translation task for 21 languages, as measured on the public CoVoST2 evaluation set",
    "checked": true,
    "id": "672bbd982c3fad9af5a42075ec6f50fc6cee425d",
    "semantic_title": "comsl: a composite speech-language model for end-to-end speech-to-text translation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=JZfg6wGi6g": {
    "title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time",
    "volume": "poster",
    "abstract": "Large language models(LLMs) have sparked a new wave of exciting AI applications. Hosting these models at scale requires significant memory resources. One crucial memory bottleneck for the deployment stems from the context window. It is commonly recognized that model weights are memory hungry; however, the size of key-value embedding stored during the generation process (KV cache) can easily surpass the model size. The enormous size of the KV cache puts constraints on the inference batch size, which is crucial for high throughput inference workload. Inspired by an interesting observation of the attention scores, we hypothesize the persistence of importance: only pivotal tokens, which had a substantial influence at one step, will significantly influence future generations. Based on our empirical verification and theoretical analysis around this hypothesis, we propose scissorhands, a system that maintains the memory usage of the KV cache at a fixed budget without finetuning the model. In essence, Scissorhands manages the KV cache by storing the pivotal tokens with a higher probability. We validate that scissorhands reduces the inference memory usage of the KV cache by up to 5$\\times$ without compromising model quality. We further demonstrate that scissorhands can be combined with 4-bit quantization, traditionally used to compress model weights, to achieve up to 20$\\times$ compression",
    "checked": true,
    "id": "d6eeb2898bd9bd34744194ef543062dda6c4531a",
    "semantic_title": "scissorhands: exploiting the persistence of importance hypothesis for llm kv cache compression at test time",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cZVBRg59eb": {
    "title": "Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability",
    "volume": "poster",
    "abstract": "Self-play is a technique for machine learning in multi-agent systems where a learning algorithm learns by interacting with copies of itself. Self-play is useful for generating large quantities of data for learning, but has the drawback that the agents the learner will face post-training may have dramatically different behavior than the learner came to expect by interacting with itself. For the special case of two-player constant-sum games, self-play that reaches Nash equilibrium is guaranteed to produce strategies that perform well against any post-training opponent; however, no such guarantee exists for multiplayer games. We show that in games that approximately decompose into a set of two-player constant-sum games (called constant-sum polymatrix games) where global $\\epsilon$-Nash equilibria are boundedly far from Nash equilibria in each subgame (called subgame stability), any no-external-regret algorithm that learns by self-play will produce a strategy with bounded vulnerability. For the first time, our results identify a structural property of multiplayer games that enable performance guarantees for the strategies produced by a broad class of self-play algorithms. We demonstrate our findings through experiments on Leduc poker",
    "checked": true,
    "id": "003186bc4161c9e7d35f805c5c7d7e1a70320a0f",
    "semantic_title": "guarantees for self-play in multiplayer games via polymatrix decomposability",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GTYaYNsFyv": {
    "title": "ChatGPT-Powered Hierarchical Comparisons for Image Classification",
    "volume": "poster",
    "abstract": "The zero-shot open-vocabulary setting poses challenges for image classification. Fortunately, utilizing a vision-language model like CLIP, pre-trained on image-text pairs, allows for classifying images by comparing embeddings. Leveraging large language models (LLMs) such as ChatGPT can further enhance CLIP's accuracy by incorporating class-specific knowledge in descriptions. However, CLIP still exhibits a bias towards certain classes and generates similar descriptions for similar classes, disregarding their differences. To address this problem, we present a novel image classification framework via hierarchical comparisons. By recursively comparing and grouping classes with LLMs, we construct a class hierarchy. With such a hierarchy, we can classify an image by descending from the top to the bottom of the hierarchy, comparing image and text embeddings at each level. Through extensive experiments and analyses, we demonstrate that our proposed approach is intuitive, effective, and explainable. Code will be released upon publication",
    "checked": true,
    "id": "7c9452ea7d9f19b7f026c68169ced75995ef7268",
    "semantic_title": "chatgpt-powered hierarchical comparisons for image classification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=mOVEJletyD": {
    "title": "Slimmed Asymmetrical Contrastive Learning and Cross Distillation for Lightweight Model Training",
    "volume": "poster",
    "abstract": "Contrastive learning (CL) has been widely investigated with various learning mechanisms and achieves strong capability in learning representations of data in a self-supervised manner using unlabeled data. A common fashion of contrastive learning on this line is employing mega-sized encoders to achieve comparable performance as the supervised learning counterpart. Despite the success of the labelless training, current contrastive learning algorithms *failed* to achieve good performance with lightweight (compact) models, e.g., MobileNet, while the requirements of the heavy encoders impede the energy-efficient computation, especially for resource-constrained AI applications. Motivated by this, we propose a new self-supervised CL scheme, named SACL-XD, consisting of two technical components, **S**limmed **A**symmetrical **C**ontrastive **L**earning (SACL) and **Cross**-**D**istillation (XD), which collectively enable efficient CL with compact models. While relevant prior works employed a strong pre-trained model as the teacher of unsupervised knowledge distillation to a lightweight encoder, our proposed method trains CL models from scratch and outperforms them even without such an expensive requirement. Compared to the SoTA lightweight CL training (distillation) algorithms, SACL-XD achieves 1.79% ImageNet-1K accuracy improvement on MobileNet-V3 with 64$\\times$ training FLOPs reduction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uj9PxVTVqq": {
    "title": "Enhancing Knowledge Transfer for Task Incremental Learning with Data-free Subnetwork",
    "volume": "poster",
    "abstract": "As there exist competitive subnetworks within a dense network in concert with Lottery Ticket Hypothesis, we introduce a novel neuron-wise task incremental learning method, namely Data-free Subnetworks (DSN), which attempts to enhance the elastic knowledge transfer across the tasks that sequentially arrive. Specifically, DSN primarily seeks to transfer knowledge to the new coming task from the learned tasks by selecting the affiliated weights of a small set of neurons to be activated, including the reused neurons from prior tasks via neuron-wise masks. And it also transfers possibly valuable knowledge to the earlier tasks via data-free replay. Especially, DSN inherently relieves the catastrophic forgetting and the unavailability of past data or possible privacy concerns. The comprehensive experiments conducted on four benchmark datasets demonstrate the effectiveness of the proposed DSN in the context of task-incremental learning by comparing it to several state-of-the-art baselines. In particular, DSN enables the knowledge transfer to the earlier tasks, which is often overlooked by prior efforts",
    "checked": false,
    "id": "7e6554dd8c39b6b72385eefe8e5a3e65ab5ef592",
    "semantic_title": "rain: regularization on input and network for black-box domain adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G14N38AjpU": {
    "title": "Evolutionary Neural Architecture Search for Transformer in Knowledge Tracing",
    "volume": "poster",
    "abstract": "Knowledge tracing (KT) aims to trace students' knowledge states by predicting whether students answer correctly on exercises. Despite the excellent performance of existing Transformer-based KT approaches, they are criticized for the manually selected input features for fusion and the defect of single global context modelling to directly capture students' forgetting behavior in KT, when the related records are distant from the current record in terms of time. To address the issues, this paper first considers adding convolution operations to the Transformer to enhance its local context modelling ability used for students' forgetting behavior, then proposes an evolutionary neural architecture search approach to automate the input feature selection and automatically determine where to apply which operation for achieving the balancing of the local/global context modelling. In the search space, the original global path containing the attention module in Transformer is replaced with the sum of a global path and a local path that could contain different convolutions, and the selection of input features is also considered. To search the best architecture, we employ an effective evolutionary algorithm to explore the search space and also suggest a search space reduction strategy to accelerate the convergence of the algorithm. Experimental results on the two largest and most challenging education datasets demonstrate the effectiveness of the architecture found by the proposed approach",
    "checked": true,
    "id": "66efd58b2cbd5dd3b727183a6fe3805ca54f3482",
    "semantic_title": "evolutionary neural architecture search for transformer in knowledge tracing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TZtw5YgxTE": {
    "title": "MIM4DD: Mutual Information Maximization for Dataset Distillation",
    "volume": "poster",
    "abstract": "Dataset distillation (DD) aims to synthesize a small dataset whose test performance is comparable to a full dataset using the same model. State-of-the-art (SoTA) methods optimize synthetic datasets primarily by matching heuristic indicators extracted from two networks: one from real data and one from synthetic data (see Fig.1, Left), such as gradients and training trajectories. DD is essentially a compression problem that emphasizes on maximizing the preservation of information contained in the data. We argue that well-defined metrics which measure the amount of shared information between variables in information theory are necessary for success measurement, but are never considered by previous works. Thus, we introduce mutual information (MI) as the metric to quantify the shared information between the synthetic and the real datasets, and devise MIM4DD numerically maximizing the MI via a newly designed optimizable objective within a contrastive learning framework to update the synthetic dataset. Specifically, we designate the samples in different datasets who share the same labels as positive pairs, and vice versa negative pairs. Then we respectively pull and push those samples in positive and negative pairs into contrastive space via minimizing NCE loss. As a result, the targeted MI can be transformed into a lower bound represented by feature maps of samples, which is numerically feasible. Experiment results show that MIM4DD can be implemented as an add-on module to existing SoTA DD methods",
    "checked": false,
    "id": "5d0b19a76b1da4ce97423f9a6c11d34670bb2697",
    "semantic_title": "using multimodal contrastive knowledge distillation for video-text retrieval",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0ycX03sMAT": {
    "title": "Fine-Grained Theoretical Analysis of Federated Zeroth-Order Optimization",
    "volume": "poster",
    "abstract": "Federated zeroth-order optimization (FedZO) algorithm enjoys the advantages of both zeroth-order optimization and federated learning, and has shown exceptional performance on black-box attack and softmax regression tasks. However, there is no generalization analysis for FedZO, and its analysis on computing convergence rate is slower than the corresponding first-order optimization setting. This paper aims to establish systematic theoretical assessments of FedZO by developing the analysis technique of on-average model stability. We establish the first generalization error bound of FedZO under the Lipschitz continuity and smoothness conditions. Then, refined generalization and optimization bounds are provided by replacing bounded gradient with heavy-tailed gradient noise and utilizing the second-order Taylor expansion for gradient approximation. With the help of a new error decomposition strategy, our theoretical analysis is also extended to the asynchronous case. For FedZO, our fine-grained analysis fills the theoretical gap on the generalization guarantees and polishes the convergence characterization of the computing algorithm",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wzPcffMZ3b": {
    "title": "Searching for Optimal Per-Coordinate Step-sizes with Multidimensional Backtracking",
    "volume": "poster",
    "abstract": "The backtracking line-search is an effective technique to automatically tune the step-size in smooth optimization. It guarantees similar performance to using the theoretically optimal step-size. Many approaches have been developed to instead tune per-coordinate step-sizes, also known as diagonal preconditioners, but none of the existing methods are provably competitive with the optimal per-coordinate step-sizes. We propose multidimensional backtracking, an extension of the backtracking line-search to find good diagonal preconditioners for smooth convex problems. Our key insight is that the gradient with respect to the step-sizes, also known as hyper-gradients, yields separating hyperplanes that let us search for good preconditioners using cutting-plane methods. As black-box cutting-plane approaches like the ellipsoid method are computationally prohibitive, we develop an efficient algorithm tailored to our setting. Multidimensional backtracking is provably competitive with the best diagonal preconditioner and requires no manual tuning",
    "checked": true,
    "id": "e9ab52f657ec4b0775c5b17b670a2b15792c4a4c",
    "semantic_title": "searching for optimal per-coordinate step-sizes with multidimensional backtracking",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=hWPNYWkYPN": {
    "title": "A new perspective on building efficient and expressive 3D equivariant graph neural networks",
    "volume": "poster",
    "abstract": "Geometric deep learning enables the encoding of physical symmetries in modeling 3D objects. Despite rapid progress in encoding 3D symmetries into Graph Neural Networks (GNNs), a comprehensive evaluation of the expressiveness of these network architectures through a local-to-global analysis lacks today. In this paper, we propose a local hierarchy of 3D isomorphism to evaluate the expressive power of equivariant GNNs and investigate the process of representing global geometric information from local patches. Our work leads to two crucial modules for designing expressive and efficient geometric GNNs; namely local substructure encoding (\\textbf{LSE}) and frame transition encoding (\\textbf{FTE}). To demonstrate the applicability of our theory, we propose LEFTNet which effectively implements these modules and achieves state-of-the-art performance on both scalar-valued and vector-valued molecular property prediction tasks. We further point out future design space for 3D equivariant graph neural networks. Our codes are available at \\url{https://github.com/yuanqidu/LeftNet}",
    "checked": true,
    "id": "17a48ebfef2ed820f3529f11b9a5acf48a9a0fe5",
    "semantic_title": "a new perspective on building efficient and expressive 3d equivariant graph neural networks",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=XNBeTgYcAq": {
    "title": "CosNet: A Generalized Spectral Kernel Network",
    "volume": "poster",
    "abstract": "Complex-valued representation exists inherently in the time-sequential data that can be derived from the integration of harmonic waves. The non-stationary spectral kernel, realizing a complex-valued feature mapping, has shown its potential to analyze the time-varying statistical characteristics of the time-sequential data, as a result of the modeling frequency parameters. However, most existing spectral kernel-based methods eliminate the imaginary part, thereby limiting the representation power of the spectral kernel. To tackle this issue, we propose a generalized spectral kernel network, namely, \\underline{Co}mplex-valued \\underline{s}pectral kernel \\underline{Net}work (CosNet), which includes spectral kernel mapping generalization (SKMG) module and complex-valued spectral kernel embedding (CSKE) module. Concretely, the SKMG module is devised to generalize the spectral kernel mapping in the real number domain to the complex number domain, recovering the inherent complex-valued representation for the real-valued data. Then a following CSKE module is further developed to combine the complex-valued spectral kernels and neural networks to effectively capture long-range or periodic relations of the data. Along with the CosNet, we study the effect of the complex-valued spectral kernel mapping via theoretically analyzing the bound of covering number and generalization error. Extensive experiments demonstrate that CosNet performs better than the mainstream kernel methods and complex-valued neural networks",
    "checked": false,
    "id": "821990fd9dda9948e1f6d28159bc33907ea6bf51",
    "semantic_title": "generalization ability of wide neural networks on ℝ",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=SGlrCuwdsB": {
    "title": "Concept Algebra for (Score-Based) Text-Controlled Generative Models",
    "volume": "poster",
    "abstract": "This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. A key property of such models is that they can compose disparate concepts in a 'disentangled' manner.This suggests these models have internal representations that encode concepts in a 'disentangled' manner. Here, we focus on the idea that concepts are encoded as subspaces of some representation space. We formalize what this means, show there's a natural choice for the representation, and develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples using Stable Diffusion",
    "checked": true,
    "id": "574114328240db66ae3f2d689b2fde97ba5d9c6e",
    "semantic_title": "concept algebra for (score-based) text-controlled generative models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=nvX3MiQM0G": {
    "title": "State-Action Similarity-Based Representations for Off-Policy Evaluation",
    "volume": "poster",
    "abstract": "In reinforcement learning, off-policy evaluation (OPE) is the problem of estimating the expected return of an evaluation policy given a fixed dataset that was collected by running one or more different policies. One of the more empirically successful algorithms for OPE has been the fitted q-evaluation (FQE) algorithm that uses temporal difference updates to learn an action-value function, which is then used to estimate the expected return of the evaluation policy. Typically, the original fixed dataset is fed directly into FQE to learn the action-value function of the evaluation policy. Instead, in this paper, we seek to enhance the data-efficiency of FQE by first transforming the fixed dataset using a learned encoder, and then feeding the transformed dataset into FQE. To learn such an encoder, we introduce an OPE-tailored state-action behavioral similarity metric, and use this metric and the fixed dataset to learn an encoder that models this metric. Theoretically, we show that this metric allows us to bound the error in the resulting OPE estimate. Empirically, we show that other state-action similarity metrics lead to representations that cannot represent the action-value function of the evaluation policy, and that our state-action representation method boosts the data-efficiency of FQE and lowers OPE error relative to other OPE-based representation learning methods on challenging OPE tasks. We also empirically show that the learned representations significantly mitigate divergence of FQE under varying distribution shifts. Our code is available here: https://github.com/Badger-RL/ROPE",
    "checked": true,
    "id": "2fd3b48ddcc872c57781f8e0d126eb37108f7c28",
    "semantic_title": "state-action similarity-based representations for off-policy evaluation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uNmKBZrRZC": {
    "title": "Adaptive Linear Estimating Equations",
    "volume": "poster",
    "abstract": "Sequential data collection has emerged as a widely adopted technique for enhancing the efficiency of data gathering processes. Despite its advantages, such data collection mechanism often introduces complexities to the statistical inference procedure. For instance, the ordinary least squares (OLS) estimator in an adaptive linear regression model can exhibit non-normal asymptotic behavior, posing challenges for accurate inference and interpretation. In this paper, we propose a general method for constructing debiased estimator which remedies this issue. It makes use of the idea of adaptive linear estimating equations, and we establish theoretical guarantees of asymptotic normality, supplemented by discussions on achieving near-optimal asymptotic variance. A salient feature of our estimator is that in the context of multi-armed bandits, our estimator retains the non-asymptotic performance of the least square estimator while obtaining asymptotic normality property. Consequently, this work helps connect two fruitful paradigms of adaptive inference: a) non-asymptotic inference using concentration inequalities and b) asymptotic inference via asymptotic normality",
    "checked": true,
    "id": "b70ebd616caf3a1bde711a902b9952c9ea26fb72",
    "semantic_title": "adaptive linear estimating equations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=i6mMWNcTfu": {
    "title": "ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer",
    "volume": "poster",
    "abstract": "Vision Transformers (ViTs) have shown impressive performance and have become a unified backbone for multiple vision tasks. However, both the attention mechanism and multi-layer perceptrons (MLPs) in ViTs are not sufficiently efficient due to dense multiplications, leading to costly training and inference. To this end, we propose to reparameterize pre-trained ViTs with a mixture of multiplication primitives, e.g., bitwise shifts and additions, towards a new type of multiplication-reduced model, dubbed $\\textbf{ShiftAddViT}$, which aims to achieve end-to-end inference speedups on GPUs without requiring training from scratch. Specifically, all $\\texttt{MatMuls}$ among queries, keys, and values are reparameterized using additive kernels, after mapping queries and keys to binary codes in Hamming space. The remaining MLPs or linear layers are then reparameterized with shift kernels. We utilize TVM to implement and optimize those customized kernels for practical hardware deployment on GPUs. We find that such a reparameterization on (quadratic or linear) attention maintains model accuracy, while inevitably leading to accuracy drops when being applied to MLPs. To marry the best of both worlds, we further propose a new mixture of experts (MoE) framework to reparameterize MLPs by taking multiplication or its primitives as experts, e.g., multiplication and shift, and designing a new latency-aware load-balancing loss. Such a loss helps to train a generic router for assigning a dynamic amount of input tokens to different experts according to their latency. In principle, the faster the experts run, the more input tokens they are assigned. Extensive experiments on various 2D/3D Transformer-based vision tasks consistently validate the effectiveness of our proposed ShiftAddViT, achieving up to $\\textbf{5.18$\\times$}$ latency reductions on GPUs and $\\textbf{42.9}$% energy savings, while maintaining a comparable accuracy as original or efficient ViTs. Codes and models are available at https://github.com/GATECH-EIC/ShiftAddViT",
    "checked": true,
    "id": "92a95c5d3ea87e08ac527d8ce25383ff8c1015be",
    "semantic_title": "shiftaddvit: mixture of multiplication primitives towards efficient vision transformer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EE1Uiu3Ryb": {
    "title": "Bandit Task Assignment with Unknown Processing Time",
    "volume": "poster",
    "abstract": "This study considers a novel problem setting, referred to as \\textit{bandit task assignment}, that incorporates the processing time of each task in the bandit setting. In this problem setting, a player sequentially chooses a set of tasks to start so that the set of processing tasks satisfies a given combinatorial constraint. The reward and processing time for each task follow unknown distributions, values of which are revealed only after the task has been completed. The problem generalizes the stochastic combinatorial semi-bandit problem and the budget-constrained bandit problem. For this problem setting, we propose an algorithm based on upper confidence bounds~(UCB) combined with a phased-update approach. The proposed algorithm admits a gap-dependent regret upper bound of $O(MN(1/\\Delta){\\log T})$ and a gap-free regret upper bound of $\\tilde{O}( \\sqrt{MNT} )$, where $N$ is the number of the tasks, $M$ is the maximum number of tasks run at the same time, $T$ is the time horizon, and $\\Delta$ is the gap between expected per-round rewards of the optimal and best suboptimal sets of tasks. These regret bounds nearly match lower bounds",
    "checked": false,
    "id": "41ae33f875d9cf34133e8c295391f031f0b9698d",
    "semantic_title": "experience replay is associated with efficient nonlocal learning",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=ixVAXsdtJO": {
    "title": "Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting",
    "volume": "poster",
    "abstract": "Images contain rich relational knowledge that can help machines understand the world. Existing methods on visual knowledge extraction often rely on the pre-defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation types), restricting the expressiveness of the extracted knowledge. In this work, we take a first exploration to a new paradigm of open visual knowledge extraction. To achieve this, we present OpenVik which consists of an open relational region detector to detect regions potentially containing relational knowledge and a visual knowledge generator that generates format-free knowledge by prompting the large multimodality model with the detected region of interest. We also explore two data enhancement techniques for diversifying the generated format-free visual knowledge. Extensive knowledge quality evaluations highlight the correctness and uniqueness of the extracted open visual knowledge by OpenVik. Moreover, integrating our extracted knowledge across various visual reasoning applications shows consistent improvements, indicating the real-world applicability of OpenVik",
    "checked": true,
    "id": "2b6a3cad4e4cbc2f2ae2a9f2d5b9e349071f24c2",
    "semantic_title": "open visual knowledge extraction via relation-oriented multimodality model prompting",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=UgSSOpqvPI": {
    "title": "DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets",
    "volume": "poster",
    "abstract": "Construction of a universal detector poses a crucial question: How can we most effectively train a model on a large mixture of datasets? The answer lies in learning dataset-specific features and ensembling their knowledge but do all this in a single model. Previous methods achieve this by having separate detection heads on a common backbone but that results in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoE are much more than a scalability tool. We propose Dataset-Aware Mixture-of-Experts, DAMEX where we train the experts to become an `expert' of a dataset by learning to route each dataset tokens to its mapped expert. Experiments on Universal Object-Detection Benchmark show that we outperform the existing state-of-the-art by average +10.2 AP score and improve over our non-MoE baseline by average +2.0 AP score. We also observe consistent gains while mixing datasets with (1) limited availability, (2) disparate domains and (3) divergent label sets. Further, we qualitatively show that DAMEX is robust against expert representation collapse. Code is available at https://github.com/jinga-lala/DAMEX",
    "checked": true,
    "id": "9fb75a6b88122147e21a2d08ae5c04fe9556dd96",
    "semantic_title": "damex: dataset-aware mixture-of-experts for visual understanding of mixture-of-datasets",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hN4qpvGzWn": {
    "title": "Game Solving with Online Fine-Tuning",
    "volume": "poster",
    "abstract": "Game solving is a similar, yet more difficult task than mastering a game. Solving a game typically means to find the game-theoretic value (outcome given optimal play), and optionally a full strategy to follow in order to achieve that outcome. The AlphaZero algorithm has demonstrated super-human level play, and its powerful policy and value predictions have also served as heuristics in game solving. However, to solve a game and obtain a full strategy, a winning response must be found for all possible moves by the losing player. This includes very poor lines of play from the losing side, for which the AlphaZero self-play process will not encounter. AlphaZero-based heuristics can be highly inaccurate when evaluating these out-of-distribution positions, which occur throughout the entire search. To address this issue, this paper investigates applying online fine-tuning while searching and proposes two methods to learn tailor-designed heuristics for game solving. Our experiments show that using online fine-tuning can solve a series of challenging 7x7 Killall-Go problems, using only 23.54\\% of computation time compared to the baseline without online fine-tuning. Results suggest that the savings scale with problem size. Our method can further be extended to any tree search algorithm for problem solving. Our code is available at https://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver",
    "checked": true,
    "id": "1fe3d62a2188392427513b3fa0df06b6e9750999",
    "semantic_title": "game solving with online fine-tuning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B3UDx1rNOy": {
    "title": "Recurrent Temporal Revision Graph Networks",
    "volume": "poster",
    "abstract": "Temporal graphs offer more accurate modeling of many real-world scenarios than static graphs. However, neighbor aggregation, a critical building block of graph networks, for temporal graphs, is currently straightforwardly extended from that of static graphs. It can be computationally expensive when involving all historical neighbors during such aggregation. In practice, typically only a subset of the most recent neighbors are involved. However, such subsampling leads to incomplete and biased neighbor information. To address this limitation, we propose a novel framework for temporal neighbor aggregation that uses the recurrent neural network with node-wise hidden states to integrate information from all historical neighbors for each node to acquire the complete neighbor information. We demonstrate the superior theoretical expressiveness of the proposed framework as well as its state-of-the-art performance in real-world applications. Notably, it achieves a significant +9.4% improvement on averaged precision in a real-world Ecommerce dataset over existing methods on 2-layer models",
    "checked": true,
    "id": "501564e85ff815501265c381e8f94ef787aba784",
    "semantic_title": "recurrent temporal revision graph networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aky0dKv9ip": {
    "title": "Decompose a Task into Generalizable Subtasks in Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "In recent years, Multi-Agent Reinforcement Learning (MARL) techniques have made significant strides in achieving high asymptotic performance in single task. However, there has been limited exploration of model transferability across tasks. Training a model from scratch for each task can be time-consuming and expensive, especially for large-scale Multi-Agent Systems. Therefore, it is crucial to develop methods for generalizing the model across tasks. Considering that there exist task-independent subtasks across MARL tasks, a model that can decompose such subtasks from the source task could generalize to target tasks. However, ensuring true task-independence of subtasks poses a challenge. In this paper, we propose to \\textbf{d}ecompose a \\textbf{t}ask in\\textbf{to} a series of \\textbf{g}eneralizable \\textbf{s}ubtasks (DT2GS), a novel framework that addresses this challenge by utilizing a scalable subtask encoder and an adaptive subtask semantic module. We show that these components endow subtasks with two properties critical for task-independence: avoiding overfitting to the source task and maintaining consistent yet scalable semantics across tasks. Empirical results demonstrate that DT2GS possesses sound zero-shot generalization capability across tasks, exhibits sufficient transferability, and outperforms existing methods in both multi-task and single-task problems",
    "checked": false,
    "id": "46e6ab62d7dd90b7c14281e4b5590731c71c6b0a",
    "semantic_title": "collaborative target search with a visual drone swarm: an adaptive curriculum embedded multi-stage reinforcement learning approach",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=X6TBBsz9qi": {
    "title": "Explain Any Concept: Segment Anything Meets Concept-Based Explanation",
    "volume": "poster",
    "abstract": "EXplainable AI (XAI) is an essential topic to improve human understanding of deep neural networks (DNNs) given their black-box internals. For computer vision tasks, mainstream pixel-based XAI methods explain DNN decisions by identifying important pixels, and emerging concept-based XAI explore forming explanations with concepts (e.g., a head in an image). However, pixels are generally hard to interpret and sensitive to the imprecision of XAI methods, whereas \"concepts\" in prior works require human annotation or are limited to pre-defined concept sets. On the other hand, driven by large-scale pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promotable framework for performing precise and comprehensive instance segmentation, enabling automatic preparation of concept sets from a given image. This paper for the first time explores using SAM to augment concept-based XAI. We offer an effective and flexible concept-based explanation method, namely Explain Any Concept (EAC), which explains DNN decisions with any concept. While SAM is highly effective and offers an \"out-of-the-box\" instance segmentation, it is costly when being integrated into defacto XAI pipelines. We thus propose a lightweight per-input equivalent (PIE) scheme, enabling efficient explanation with a surrogate model. Our evaluation over two popular datasets (ImageNet and COCO) illustrate the highly encouraging performance of EAC over commonly-used XAI methods",
    "checked": true,
    "id": "ede1078e40189190483554f2a84a547e9186872b",
    "semantic_title": "explain any concept: segment anything meets concept-based explanation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ZNBblMEP16": {
    "title": "Depth-discriminative Metric Learning for Monocular 3D Object Detection",
    "volume": "poster",
    "abstract": "Monocular 3D object detection poses a significant challenge due to the lack of depth information in RGB images. Many existing methods strive to enhance the object depth estimation performance by allocating additional parameters for object depth estimation, utilizing extra modules or data. In contrast, we introduce a novel metric learning scheme that encourages the model to extract depth-discriminative features regardless of the visual attributes without increasing inference time and model size. Our method employs the distance-preserving function to organize the feature space manifold in relation to ground-truth object depth. The proposed $(K,B,\\epsilon)$-quasi-isometric loss leverages predetermined pairwise distance restriction as guidance for adjusting the distance among object descriptors without disrupting the non-linearity of the natural feature manifold. Moreover, we introduce an auxiliary head for object-wise depth estimation, which enhances depth quality while maintaining the inference time. The broad applicability of our method is demonstrated through experiments that show improvements in overall performance when integrated into various baselines. The results show that our method consistently improves the performance of various baselines by 23.51\\% and 5.78\\% on average across KITTI and Waymo, respectively",
    "checked": false,
    "id": "7640471b61d2d23c1d2733fa2b8aef6ff415ac65",
    "semantic_title": "learning occupancy for monocular 3d object detection",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=YLOJ4aKAka": {
    "title": "Connecting Pre-trained Language Model and Downstream Task via Properties of Representation",
    "volume": "poster",
    "abstract": "Recently, researchers have found that representations learned by large-scale pre-trained language models are useful in various downstream tasks. However, there is little theoretical understanding of how pre-training performance is related to downstream task performance. In this paper, we analyze how this performance transfer depends on the properties of the downstream task and the structure of the representations. We consider a log-linear model where a word can be predicted from its context through a network having softmax as its last layer. We show that even if the downstream task is highly structured and depends on a simple function of the hidden representation, there are still cases when a low pre-training loss cannot guarantee good performance on the downstream task. On the other hand, we propose and empirically validate the existence of an ``anchor vector'' in the representation space, and show that this assumption, together with properties of the downstream task, guarantees performance transfer",
    "checked": false,
    "id": "8176556a3fefa7c1b16262ba75499a4643682262",
    "semantic_title": "linking emergent and natural languages via corpus transfer",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=vBHKSTgcYQ": {
    "title": "An Exploration-by-Optimization Approach to Best of Both Worlds in Linear Bandits",
    "volume": "poster",
    "abstract": "In this paper, we consider how to construct best-of-both-worlds linear bandit algorithms that achieve nearly optimal performance for both stochastic and adversarial environments. For this purpose, we show that a natural approach referred to as exploration by optimization [Lattimore and Szepesvári, 2020] works well. Specifically, an algorithm constructed using this approach achieves $O(d \\sqrt{ T \\log{T}})$-regret in adversarial environments and $O(\\frac{d^2 \\log T}{\\Delta_{\\min}} )$-regret in stochastic environments. Symbols $d$, $T$ and $\\Delta_{\\min}$ here represent the dimensionality of the action set, the time horizon, and the minimum sub-optimality gap, respectively. We also show that this algorithm has even better theoretical guarantees for important special cases including the multi-armed bandit problem and multitask bandits",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BFGQQKicuu": {
    "title": "Score-based Source Separation with Applications to Digital Communication Signals",
    "volume": "poster",
    "abstract": "We propose a new method for separating superimposed sources using diffusion-based generative models. Our method relies only on separately trained statistical priors of independent sources to establish a new objective function guided by $\\textit{maximum a posteriori}$ estimation with an $\\textit{$\\alpha$-posterior}$, across multiple levels of Gaussian smoothing. Motivated by applications in radio-frequency (RF) systems, we are interested in sources with underlying discrete nature and the recovery of encoded bits from a signal of interest, as measured by the bit error rate (BER). Experimental results with RF mixtures demonstrate that our method results in a BER reduction of 95\\% over classical and existing learning-based methods. Our analysis demonstrates that our proposed method yields solutions that asymptotically approach the modes of an underlying discrete distribution. Furthermore, our method can be viewed as a multi-source extension to the recently proposed score distillation sampling scheme, shedding additional light on its use beyond conditional sampling. The project webpage is available at https://alpha-rgs.github.io",
    "checked": true,
    "id": "760e904afb36e281fe300911e0befeba21a3eef8",
    "semantic_title": "score-based source separation with applications to digital communication signals",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=iohoef1bfM": {
    "title": "Generalized Belief Transport",
    "volume": "poster",
    "abstract": "Human learners have ability to adopt appropriate learning approaches depending on constraints such as prior on the hypothesis, urgency of decision, and drift of the environment. However, existing learning models are typically considered individually rather than in relation to one and other. To build agents that have the ability to move between different modes of learning over time, it is important to understand how learning models are related as points in a broader space of possibilities. We introduce a mathematical framework, Generalized Belief Transport (GBT), that unifies and generalizes prior models, including Bayesian inference, cooperative communication and classification, as parameterizations of three learning constraints within Unbalanced Optimal Transport (UOT). We visualize the space of learning models encoded by GBT as a cube which includes classic learning models as special points. We derive critical properties of this parameterized space including proving continuity and differentiability which is the basis for model interpolation, and study limiting behavior of the parameters, which allows attaching learning models on the boundaries. Moreover, we investigate the long-run behavior of GBT, explore convergence properties of models in GBT mathematical and computationally, document the ability to learn in the presence of distribution drift, and formulate conjectures about general behavior. We conclude with open questions and implications for more unified models of learning",
    "checked": false,
    "id": "f12b5eab0e023cc0ba61af53a7b5e42898d898af",
    "semantic_title": "the generalized maximum belief entropy model",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=DNubFPV5Dy": {
    "title": "Weakly Coupled Deep Q-Networks",
    "volume": "poster",
    "abstract": "We propose weakly coupled deep Q-networks (WCDQN), a novel deep reinforcement learning algorithm that enhances performance in a class of structured problems called weakly coupled Markov decision processes (WCMDP). WCMDPs consist of multiple independent subproblems connected by an action space constraint, which is a structural property that frequently emerges in practice. Despite this appealing structure, WCMDPs quickly become intractable as the number of subproblems grows. WCDQN employs a single network to train multiple DQN ``subagents,'' one for each subproblem, and then combine their solutions to establish an upper bound on the optimal action value. This guides the main DQN agent towards optimality. We show that the tabular version, weakly coupled Q-learning (WCQL), converges almost surely to the optimal action value. Numerical experiments show faster convergence compared to DQN and related techniques in settings with as many as 10 subproblems, $3^{10}$ total actions, and a continuous state space",
    "checked": true,
    "id": "9d5f3fe6495c0aa7a1eb4a49641dfa1ee136419c",
    "semantic_title": "weakly coupled deep q-networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vM5VnNQ4n7": {
    "title": "Exploiting Correlated Auxiliary Feedback in Parameterized Bandits",
    "volume": "poster",
    "abstract": "We study a novel variant of the parameterized bandits problem in which the learner can observe additional auxiliary feedback that is correlated with the observed reward. The auxiliary feedback is readily available in many real-life applications, e.g., an online platform that wants to recommend the best-rated services to its users can observe the user's rating of service (rewards) and collect additional information like service delivery time (auxiliary feedback). In this paper, we first develop a method that exploits auxiliary feedback to build a reward estimator with tight confidence bounds, leading to a smaller regret. We then characterize the regret reduction in terms of the correlation coefficient between reward and its auxiliary feedback. Experimental results in different settings also verify the performance gain achieved by our proposed method",
    "checked": true,
    "id": "14e348995c9557bb5bab7ee30a977e51e3099c36",
    "semantic_title": "exploiting correlated auxiliary feedback in parameterized bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dz5X8hnfJc": {
    "title": "Characterizing Out-of-Distribution Error via Optimal Transport",
    "volume": "poster",
    "abstract": "Out-of-distribution (OOD) data poses serious challenges in deployed machine learning models, so methods of predicting a model's performance on OOD data without labels are important for machine learning safety. While a number of methods have been proposed by prior work, they often underestimate the actual error, sometimes by a large margin, which greatly impacts their applicability to real tasks. In this work, we identify *pseudo-label shift*, or the difference between the predicted and true OOD label distributions, as a key indicator to this underestimation. Based on this observation, we introduce a novel method for estimating model performance by leveraging optimal transport theory, Confidence Optimal Transport (COT), and show that it provably provides more robust error estimates in the presence of pseudo-label shift. Additionally, we introduce an empirically-motivated variant of COT, Confidence Optimal Transport with Thresholding (COTT), which applies thresholding to the individual transport costs and further improves the accuracy of COT's error estimates. We evaluate COT and COTT on a variety of standard benchmarks that induce various types of distribution shift -- synthetic, novel subpopulation, and natural -- and show that our approaches significantly outperform existing state-of-the-art methods with up to 3x lower prediction errorS",
    "checked": true,
    "id": "80e5f8994731103b4ba87bc37676dfd88fb3c2ce",
    "semantic_title": "characterizing out-of-distribution error via optimal transport",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A6PRwRjI8V": {
    "title": "Generalized Semi-Supervised Learning via Self-Supervised Feature Adaptation",
    "volume": "poster",
    "abstract": "Traditional semi-supervised learning (SSL) assumes that the feature distributions of labeled and unlabeled data are consistent which rarely holds in realistic scenarios. In this paper, we propose a novel SSL setting, where unlabeled samples are drawn from a mixed distribution that deviates from the feature distribution of labeled samples. Under this setting, previous SSL methods tend to predict wrong pseudo-labels with the model fitted on labeled data, resulting in noise accumulation. To tackle this issue, we propose \\emph{Self-Supervised Feature Adaptation} (SSFA), a generic framework for improving SSL performance when labeled and unlabeled data come from different distributions. SSFA decouples the prediction of pseudo-labels from the current model to improve the quality of pseudo-labels. Particularly, SSFA incorporates a self-supervised task into the SSL framework and uses it to adapt the feature extractor of the model to the unlabeled data. In this way, the extracted features better fit the distribution of unlabeled data, thereby generating high-quality pseudo-labels. Extensive experiments show that our proposed SSFA is applicable to various pseudo-label-based SSL learners and significantly improves performance in labeled, unlabeled, and even unseen distributions",
    "checked": false,
    "id": "2fb7202bb9750bcb0752e30889098b4ecb964162",
    "semantic_title": "eeg-oriented self-supervised learning and cluster-aware adaptation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=6wBkT2ndDu": {
    "title": "Weitzman's Rule for Pandora's Box with Correlations",
    "volume": "poster",
    "abstract": "Pandora's Box is a central problem in decision making under uncertainty that can model various real life scenarios. In this problem we are given n boxes, each with a fixed opening cost, and an unknown value drawn from a known distribution, only revealed if we pay the opening cost. Our goal is to find a strategy for opening boxes to minimize the sum of the value selected and the opening cost paid. In this work we revisit Pandora's Box when the value distributions are correlated, first studied in [CGT+20]. We show that the optimal algorithm for the independent case, given by Weitzman's rule, directly works for the correlated case. In fact, our algorithm results in significantly improved approximation guarantees compared to the previous work, while also being substantially simpler. We also show how to implement the rule given only sample access to the correlated distribution of values. Specifically, we find that a number of samples that is polynomial in the number of boxes is sufficient for the algorithm to work",
    "checked": true,
    "id": "0a50db847129e907d42d01803231356c606b9cd8",
    "semantic_title": "weitzman's rule for pandora's box with correlations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=K1Uzj8tuwd": {
    "title": "Learning Mask-aware CLIP Representations for Zero-Shot Segmentation",
    "volume": "poster",
    "abstract": "Recently, pre-trained vision-language models have been increasingly used to tackle the challenging zero-shot segmentation task. Typical solutions follow the paradigm of first generating mask proposals and then adopting CLIP to classify them. To maintain the CLIP's zero-shot transferability, previous practices favour to freeze CLIP during training. However, in the paper, we reveal that CLIP is insensitive to different mask proposals and tends to produce similar predictions for various mask proposals of the same image. This insensitivity results in numerous false positives when classifying mask proposals. This issue mainly relates to the fact that CLIP is trained with image-level supervision. To alleviate this issue, we propose a simple yet effective method, named Mask-aware Fine-tuning (MAFT). Specifically, Image-Proposals CLIP Encoder (IP-CLIP Encoder) is proposed to handle arbitrary numbers of image and mask proposals simultaneously. Then, *mask-aware loss* and *self-distillation loss* are designed to fine-tune IP-CLIP Encoder, ensuring CLIP is responsive to different mask proposals while not sacrificing transferability. In this way, mask-aware representations can be easily learned to make the true positives stand out. Notably, our solution can seamlessly plug into most existing methods without introducing any new parameters during the fine-tuning process. We conduct extensive experiments on the popular zero-shot benchmarks. With MAFT, the performance of the state-of-the-art methods is promoted by a large margin: 50.4\\% (+ 8.2\\%) on COCO, 81.8\\% (+ 3.2\\%) on Pascal-VOC, and 8.7\\% (+4.3\\%) on ADE20K in terms of mIoU for unseen classes. Codes will be provided for reproducibility. Code is available at https://github.com/jiaosiyu1999/MAFT.git",
    "checked": true,
    "id": "6a627c258084054b2648058a78c579539d7f7bc3",
    "semantic_title": "learning mask-aware clip representations for zero-shot segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GgdFLb94Ld": {
    "title": "CoDrug: Conformal Drug Property Prediction with Density Estimation under Covariate Shift",
    "volume": "poster",
    "abstract": "In drug discovery, it is vital to confirm the predictions of pharmaceutical properties from computational models using costly wet-lab experiments. Hence, obtaining reliable uncertainty estimates is crucial for prioritizing drug molecules for subsequent experimental validation. Conformal Prediction (CP) is a promising tool for creating such prediction sets for molecular properties with a coverage guarantee. However, the exchangeability assumption of CP is often challenged with covariate shift in drug discovery tasks: Most datasets contain limited labeled data, which may not be representative of the vast chemical space from which molecules are drawn. To address this limitation, we propose a method called CoDrug that employs an energy-based model leveraging both training data and unlabelled data, and Kernel Density Estimation (KDE) to assess the densities of a molecule set. The estimated densities are then used to weigh the molecule samples while building prediction sets and rectifying for distribution shift. In extensive experiments involving realistic distribution drifts in various small-molecule drug discovery tasks, we demonstrate the ability of CoDrug to provide valid prediction sets and its utility in addressing the distribution shift arising from de novo drug design models. On average, using CoDrug can reduce the coverage gap by over 35% when compared to conformal prediction sets not adjusted for covariate shift",
    "checked": false,
    "id": "ccff5545325aaf3868135ce6a70e11391f83d415",
    "semantic_title": "conformal drug property prediction with density estimation under covariate shift",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v8u3EFAyW9": {
    "title": "Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion",
    "volume": "poster",
    "abstract": "Distributional reinforcement learning algorithms have attempted to utilize estimated uncertainty for exploration, such as optimism in the face of uncertainty. However, using the estimated variance for optimistic exploration may cause biased data collection and hinder convergence or performance. In this paper, we present a novel distributional reinforcement learning that selects actions by randomizing risk criterion without losing the risk-neutral objective. We provide a perturbed distributional Bellman optimality operator by distorting the risk measure. Also,we prove the convergence and optimality of the proposed method with the weaker contraction property. Our theoretical results support that the proposed method does not fall into biased exploration and is guaranteed to converge to an optimal return. Finally, we empirically show that our method outperforms other existing distribution-based algorithms in various environments including Atari 55 games",
    "checked": true,
    "id": "034b015f0a8e8f1921e2e4d8c854c939228c4e02",
    "semantic_title": "pitfall of optimism: distributional reinforcement learning by randomizing risk criterion",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RHDXkRPNQa": {
    "title": "Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction",
    "volume": "poster",
    "abstract": "Inductive relation prediction (IRP)---where entities can be different during training and inference---has shown great power for completing evolving knowledge graphs. Existing works mainly focus on using graph neural networks (GNNs) to learn the representation of the subgraph induced from the target link, which can be seen as an implicit rule-mining process to measure the plausibility of the target link. However, these methods are not able to differentiate the target link and other links during message passing, hence the final subgraph representation will contain irrelevant rule information to the target link, which reduces the reasoning performance and severely hinders the applications for real-world scenarios. To tackle this problem, we propose a novel $\\textit{single-source edge-wise}$ GNN model to learn the $\\textbf{R}$ule-induc$\\textbf{E}$d $\\textbf{S}$ubgraph represen$\\textbf{T}$ations $(\\textbf{REST}$), which encodes relevant rules and eliminates irrelevant rules within the subgraph. Specifically, we propose a $\\textit{single-source}$ initialization approach to initialize edge features only for the target link, which guarantees the relevance of mined rules and target link. Then we propose several RNN-based functions for $\\textit{edge-wise}$ message passing to model the sequential property of mined rules. REST is a simple and effective approach with theoretical support to learn the $\\textit{rule-induced subgraph representation}$. Moreover, REST does not need node labeling, which significantly accelerates the subgraph preprocessing time by up to $\\textbf{11.66}\\times$. Experiments on inductive relation prediction benchmarks demonstrate the effectiveness of our REST",
    "checked": false,
    "id": "8884aaa287595ee6fdfff66d2c36594c3f3b7516",
    "semantic_title": "subgraph representation learning with hard negative samples for inductive link prediction",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=PHKkBbuJWM": {
    "title": "An Iterative Self-Learning Framework for Medical Domain Generalization",
    "volume": "poster",
    "abstract": "Deep learning models have been widely used to assist doctors with clinical decision-making. However, these models often encounter a significant performance drop when applied to data that differs from the distribution they were trained on. This challenge is known as the domain shift problem. Existing domain generalization algorithms attempt to address this problem by assuming the availability of domain IDs and training a single model to handle all domains. However, in healthcare settings, patients can be classified into numerous latent domains, where the actual domain categorizations are unknown. Furthermore, each patient domain exhibits distinct clinical characteristics, making it sub-optimal to train a single model for all domains. To overcome these limitations, we propose SLGD, a self-learning framework that iteratively discovers decoupled domains and trains personalized classifiers for each decoupled domain. We evaluate the generalizability of SLGD across spatial and temporal data distribution shifts on two real-world public EHR datasets: eICU and MIMIC-IV. Our results show that SLGD achieves up to 11% improvement in the AUPRC score over the best baseline",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IOuuLBrGJR": {
    "title": "HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text",
    "volume": "poster",
    "abstract": "Black-box hard-label adversarial attack on text is a practical and challenging task, as the text data space is inherently discrete and non-differentiable, and only the predicted label is accessible. Research on this problem is still in the embryonic stage and only a few methods are available. Nevertheless, existing methods rely on the complex heuristic algorithm or unreliable gradient estimation strategy, which probably fall into the local optimum and inevitably consume numerous queries, thus are difficult to craft satisfactory adversarial examples with high semantic similarity and low perturbation rate in a limited query budget. To alleviate above issues, we propose a simple yet effective framework to generate high quality textual adversarial examples under the black-box hard-label attack scenarios, named HQA-Attack. Specifically, after initializing an adversarial example randomly, HQA-attack first constantly substitutes original words back as many as possible, thus shrinking the perturbation rate. Then it leverages the synonym set of the remaining changed words to further optimize the adversarial example with the direction which can improve the semantic similarity and satisfy the adversarial condition simultaneously. In addition, during the optimizing procedure, it searches a transition synonym word for each changed word, thus avoiding traversing the whole synonym set and reducing the query number to some extent. Extensive experimental results on five text classification datasets, three natural language inference datasets and two real-world APIs have shown that the proposed HQA-Attack method outperforms other strong baselines significantly",
    "checked": false,
    "id": "05c286b7d149fd5edd542f5765ca2a66f6219854",
    "semantic_title": "pat: geometry-aware hard-label black-box adversarial attacks on text",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=q4HlFS7B7Y": {
    "title": "Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability",
    "volume": "poster",
    "abstract": "With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by identifying features critical to model predictions; however, prior work has shown that these explanations may not be faithful, in that they incorrectly attribute high importance to features that are unimportant or non-discriminative for the underlying task. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we identify a key reason for the lack of faithfulness of feature attributions: the lack of robustness of the underlying black-box models, especially the erasure of unimportant distractor features in the input. To address this issue, we propose Distractor Erasure Tuning (DiET), a method that adapts black-box models to be robust to distractor erasure, thus providing discriminative and faithful attributions. This strategy naturally combines the ease-of-use of post hoc explanations with the faithfulness of inherently interpretable models. We perform extensive experiments on semi-synthetic and real-world datasets, and show that DiET produces models that (1) closely approximate the original black-box models they are intended to explain, and (2) yield explanations that match approximate ground truths available by construction",
    "checked": false,
    "id": "c271f5d1286bbdc0efd8ed1bc6e9bde028eed725",
    "semantic_title": "verifiable feature attributions: a bridge between post hoc explainability and inherent interpretability",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=c5dRV9tA3K": {
    "title": "EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual Representation Learning",
    "volume": "poster",
    "abstract": "Expressing universal semantics common to all languages is helpful to understand the meanings of complex and culture-specific sentences. The research theme underlying this scenario focuses on learning universal representations across languages with the usage of massive parallel corpora. However, due to the sparsity and scarcity of parallel data, there is still a big challenge in learning authentic ``universals'' for any two languages. In this paper, we propose Emma-X: an EM-like Multilingual pre-training Algorithm, to learn Cross-lingual universals with the aid of excessive multilingual non-parallel data. Emma-X unifies the cross-lingual representation learning task and an extra semantic relation prediction task within an EM framework. Both the extra semantic classifier and the cross-lingual sentence encoder approximate the semantic relation of two sentences, and supervise each other until convergence. To evaluate Emma-X, we conduct experiments on xrete, a newly introduced benchmark containing 12 widely studied cross-lingual tasks that fully depend on sentence-level representations. Results reveal that Emma-X achieves state-of-the-art performance. Further geometric analysis of the built representation space with three requirements demonstrates the superiority of Emma-X over advanced models",
    "checked": true,
    "id": "7cf11e610eb924f83fb3e7816324f0b75c8d12b5",
    "semantic_title": "emma-x: an em-like multilingual pre-training algorithm for cross-lingual representation learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZcJa1R6j3v": {
    "title": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents",
    "volume": "poster",
    "abstract": "Inspired by the insights in cognitive science with respect to human memory and reasoning mechanism, a novel evolvable LLM-based (Large Language Model) agent framework is proposed as Rememberer. By equipping the LLM with a long-term experience memory, Rememberer is capable of exploiting the experiences from the past episodes even for different task goals, which excels an LLM-based agent with fixed exemplars or equipped with a transient working memory. We further introduce **R**einforcement **L**earning with **E**xperience **M**emory (**RLEM**) to update the memory. Thus, the whole system can learn from the experiences of both success and failure, and evolve its capability without fine-tuning the parameters of the LLM. In this way, the proposed Rememberer constitutes a semi-parametric RL agent. Extensive experiments are conducted on two RL task sets to evaluate the proposed framework. The average results with different initialization and training sets exceed the prior SOTA by 4% and 2% for the success rate on two task sets and demonstrate the superiority and robustness of Rememberer",
    "checked": true,
    "id": "60e6e3767c36bf9e16b58b7221c5712b4d3d5293",
    "semantic_title": "large language models are semi-parametric reinforcement learning agents",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=xzmaFfw6oh": {
    "title": "Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D Diffusion",
    "volume": "poster",
    "abstract": "Recently, artificial intelligence for drug discovery has raised increasing interest in both machine learning and chemistry domains. The fundamental building block for drug discovery is molecule geometry and thus, the molecule's geometrical representation is the main bottleneck to better utilize machine learning techniques for drug discovery. In this work, we propose a pretraining method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn both the 2D bond (topology) and 3D conformation (geometry) information, and a diffusion process model is applied to mimic the augmented trajectories of such two modalities, based on which, MoleculeJAE will learn the inherent chemical structure in a self-supervised manner. Thus, the pretrained geometrical representation in MoleculeJAE is expected to benefit downstream geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by reaching state-of-the-art performance on 15 out of 20 tasks by comparing it with 12 competitive baselines",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z3HACY5CMa": {
    "title": "Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization",
    "volume": "poster",
    "abstract": "We tackle the problem of graph out-of-distribution (OOD) generalization. Existing graph OOD algorithms either rely on restricted assumptions or fail to exploit environment information in training data. In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to fully make use of label and environment information, thereby addressing the challenges faced by prior methods on identifying causal and invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for casual subgraph discovery with theoretical guarantees. Extensive experiments and analysis show that LECI significantly outperforms prior methods on both synthetic and real-world datasets, establishing LECI as a practical and effective solution for graph OOD generalization",
    "checked": true,
    "id": "46423fd6c5d0e53c436cc8c1848c815e779937f6",
    "semantic_title": "joint learning of label and environment causal independence for graph out-of-distribution generalization",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=kKXJkiniOx": {
    "title": "ConDaFormer: Disassembled Transformer with Local Structure Enhancement for 3D Point Cloud Understanding",
    "volume": "poster",
    "abstract": "Transformers have been recently explored for 3D point cloud understanding with impressive progress achieved. A large number of points, over 0.1 million, make the global self-attention infeasible for point cloud data. Thus, most methods propose to apply the transformer in a local region, e.g., spherical or cubic window. However, it still contains a large number of Query-Key pairs, which requires high computational costs. In addition, previous methods usually learn the query, key, and value using a linear projection without modeling the local 3D geometric structure. In this paper, we attempt to reduce the costs and model the local geometry prior by developing a new transformer block, named ConDaFormer. Technically, ConDaFormer disassembles the cubic window into three orthogonal 2D planes, leading to fewer points when modeling the attention in a similar range. The disassembling operation is beneficial to enlarging the range of attention without increasing the computational complexity, but ignores some contexts. To provide a remedy, we develop a local structure enhancement strategy that introduces a depth-wise convolution before and after the attention. This scheme can also capture the local geometric information. Taking advantage of these designs, ConDaFormer captures both long-range contextual information and local priors. The effectiveness is demonstrated by experimental results on several 3D point cloud understanding benchmarks. Our code will be available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w3ghbKBJg4": {
    "title": "Minimax Optimal Rate for Parameter Estimation in Multivariate Deviated Models",
    "volume": "poster",
    "abstract": "We study the maximum likelihood estimation (MLE) in the multivariate deviated model where the data are generated from the density function $(1-\\lambda^{\\ast})h_{0}(x)+\\lambda^{\\ast}f(x|\\mu^{\\ast}, \\Sigma^{\\ast})$ in which $h_{0}$ is a known function, $\\lambda^{\\ast} \\in [0,1]$ and $(\\mu^{\\ast}, \\Sigma^{\\ast})$ are unknown parameters to estimate. The main challenges in deriving the convergence rate of the MLE mainly come from two issues: (1) The interaction between the function $h_{0}$ and the density function $f$; (2) The deviated proportion $\\lambda^{\\ast}$ can go to the extreme points of $[0,1]$ as the sample size tends to infinity. To address these challenges, we develop the \\emph{distinguishability condition} to capture the linear independent relation between the function $h_{0}$ and the density function $f$. We then provide comprehensive convergence rates of the MLE via the vanishing rate of $\\lambda^{\\ast}$ to zero as well as the distinguishability of two functions $h_{0}$ and $f$",
    "checked": true,
    "id": "d946b5ccf263ec78cd70c06c3496dd9348f1f6da",
    "semantic_title": "minimax optimal rate for parameter estimation in multivariate deviated models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FmZVRe0gn8": {
    "title": "Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms",
    "volume": "poster",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown promising results across several domains. Despite this promise, MARL policies often lack robustness and are therefore sensitive to small changes in their environment. This presents a serious concern for the real world deployment of MARL algorithms, where the testing environment may slightly differ from the training environment. In this work we show that we can gain robustness by controlling a policy's Lipschitz constant, and under mild conditions, establish the existence of a Lipschitz and close-to-optimal policy. Motivated by these insights, we propose a new robust MARL framework, ERNIE, that promotes the Lipschitz continuity of the policies with respect to the state observations and actions by adversarial regularization. The ERNIE framework provides robustness against noisy observations, changing transition dynamics, and malicious actions of agents. However, ERNIE's adversarial regularization may introduce some training instability. To reduce this instability, we reformulate adversarial regularization as a Stackelberg game. We demonstrate the effectiveness of the proposed framework with extensive experiments in traffic light control and particle environments. In addition, we extend ERNIE to mean-field MARL with a formulation based on distributionally robust optimization that outperforms its non-robust counterpart and is of independent interest. Our code is available at https://github.com/abukharin3/ERNIE",
    "checked": true,
    "id": "f7c0ccef870acfd6090e6de9649abfa1b2b24756",
    "semantic_title": "robust multi-agent reinforcement learning via adversarial regularization: theoretical foundation and stable algorithms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T6iiOqsGOh": {
    "title": "Mass-Producing Failures of Multimodal Systems with Language Models",
    "volume": "poster",
    "abstract": "Deployed multimodal models can fail in ways that evaluators did not anticipate. In order to find these failures before deployment, we introduce MultiMon, a system that automatically identifies systematic failures---generalizable, natural-language descriptions that describe categories of individual failures. To uncover systematic failures, MultiMon scrapes for examples of erroneous agreement: inputs that produce the same output, but should not. It then prompts a language model to identify common categories and describe them in natural language. We use MultiMon to find 14 systematic failures (e.g.\"ignores quantifiers'') of the CLIP text-encoder, each comprising hundreds of distinct inputs (e.g.\"a shelf with a few/many books''). Because CLIP is the backbone for most state-of-the-art multimodal models, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion, and others. MultiMon can also steer towards failures relevant to specific use cases, such as self-driving cars. We see MultiMon as a step towards evaluation that autonomously explores the long-tail of potential system failures",
    "checked": true,
    "id": "0aaee2b99ec6f659657658416e88ad7f4161ac7f",
    "semantic_title": "mass-producing failures of multimodal systems with language models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=EF56cv8B3b": {
    "title": "LayoutPrompter: Awaken the Design Ability of Large Language Models",
    "volume": "poster",
    "abstract": "Conditional graphic layout generation, which automatically maps user constraints to high-quality layouts, has attracted widespread attention today. Although recent works have achieved promising performance, the lack of versatility and data efficiency hinders their practical applications. In this work, we propose LayoutPrompter, which leverages large language models (LLMs) to address the above problems through in-context learning. LayoutPrompter is made up of three key components, namely input-output serialization, dynamic exemplar selection and layout ranking. Specifically, the input-output serialization component meticulously designs the input and output formats for each layout generation task. Dynamic exemplar selection is responsible for selecting the most helpful prompting exemplars for a given input. And a layout ranker is used to pick the highest quality layout from multiple outputs of LLMs. We conduct experiments on all existing layout generation tasks using four public datasets. Despite the simplicity of our approach, experimental results show that LayoutPrompter can compete with or even outperform state-of-the-art approaches on these tasks without any model training or fine-tuning. This demonstrates the effectiveness of this versatile and training-free approach. In addition, the ablation studies show that LayoutPrompter is significantly superior to the training-based baseline in a low-data regime, further indicating the data efficiency of LayoutPrompter. Our project is available at https://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompter",
    "checked": true,
    "id": "1e19a260e771a3d46dfb6a93954071f22b7b564d",
    "semantic_title": "layoutprompter: awaken the design ability of large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X5MH7iut9K": {
    "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly",
    "volume": "poster",
    "abstract": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great attention due to the security risk of applying these models in real-world applications. Based on transferability of adversarial examples, an increasing number of transfer-based methods have been developed to fool black-box DNN models whose architecture and parameters are inaccessible. Although tremendous effort has been exerted, there still lacks a standardized benchmark that could be taken advantage of to compare these methods systematically, fairly, and practically. Our investigation shows that the evaluation of some methods needs to be more reasonable and more thorough to verify their effectiveness, to avoid, for example, unfair comparison and insufficient consideration of possible substitute/victim models. Therefore, we establish a transfer-based attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we evaluate and compare them comprehensively on 10 popular substitute/victim models on ImageNet. New insights about the effectiveness of these methods are gained and guidelines for future evaluations are provided",
    "checked": true,
    "id": "395d9d3b1e2044bb2ce77abb6d6ca121dcc86842",
    "semantic_title": "towards evaluating transfer-based attacks systematically, practically, and fairly",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DBlkX8Nczr": {
    "title": "Brain-like Flexible Visual Inference by Harnessing Feedback Feedforward Alignment",
    "volume": "poster",
    "abstract": "In natural vision, feedback connections support versatile visual inference capabilities such as making sense of the occluded or noisy bottom-up sensory information or mediating pure top-down processes such as imagination. However, the mechanisms by which the feedback pathway learns to give rise to these capabilities flexibly are not clear. We propose that top-down effects emerge through alignment between feedforward and feedback pathways, each optimizing its own objectives. To achieve this co-optimization, we introduce Feedback-Feedforward Alignment (FFA), a learning algorithm that leverages feedback and feedforward pathways as mutual credit assignment computational graphs, enabling alignment. In our study, we demonstrate the effectiveness of FFA in co-optimizing classification and reconstruction tasks on widely used MNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endows feedback connections with emergent visual inference functions, including denoising, resolving occlusions, hallucination, and imagination. Moreover, FFA offers bio-plausibility compared to traditional backpropagation (BP) methods in implementation. By repurposing the computational graph of credit assignment into a goal-driven feedback pathway, FFA alleviates weight transport problems encountered in BP, enhancing the bio-plausibility of the learning algorithm. Our study presents FFA as a promising proof-of-concept for the mechanisms underlying how feedback connections in the visual cortex support flexible visual functions. This work also contributes to the broader field of visual inference underlying perceptual phenomena and has implications for developing more biologically inspired learning algorithms",
    "checked": false,
    "id": "3de480317498e51cc431219c482351c2504d7c93",
    "semantic_title": "brain-like flexible visual inference by harnessing feedback-feedforward alignment",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PRgvdEbhdH": {
    "title": "Policy Space Diversity for Non-Transitive Games",
    "volume": "poster",
    "abstract": "Policy-Space Response Oracles (PSRO) is an influential algorithm framework for approximating a Nash Equilibrium (NE) in multi-agent non-transitive games. Many previous studies have been trying to promote policy diversity in PSRO. A major weakness with existing diversity metrics is that a more diverse (according to their diversity metrics) population does not necessarily mean (as we proved in the paper) a better approximation to a NE. To alleviate this problem, we propose a new diversity metric, the improvement of which guarantees a better approximation to a NE. Meanwhile, we develop a practical and well-justified method to optimize our diversity metric using only state-action samples. By incorporating our diversity regularization into the best response solving of PSRO, we obtain a new PSRO variant, \\textit{Policy Space Diversity} PSRO (PSD-PSRO). We present the convergence property of PSD-PSRO. Empirically, extensive experiments on single-state games, Leduc, and Goofspiel demonstrate that PSD-PSRO is more effective in producing significantly less exploitable policies than state-of-the-art PSRO variants",
    "checked": true,
    "id": "90f47503dc72377e354b69c83befa86819fd0ecb",
    "semantic_title": "policy space diversity for non-transitive games",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XrqqPDAsRE": {
    "title": "A Randomized Approach to Tight Privacy Accounting",
    "volume": "poster",
    "abstract": "Bounding privacy leakage over compositions, i.e., privacy accounting, is a key challenge in differential privacy (DP). However, the privacy parameter ($\\varepsilon$ or $\\delta$) is often easy to estimate but hard to bound. In this paper, we propose a new differential privacy paradigm called estimate-verify-release (EVR), which tackles the challenges of providing a strict upper bound for the privacy parameter in DP compositions by converting an *estimate* of privacy parameter into a formal guarantee. The EVR paradigm first verifies whether the mechanism meets the *estimated* privacy guarantee, and then releases the query output based on the verification result. The core component of the EVR is privacy verification. We develop a randomized privacy verifier using Monte Carlo (MC) technique. Furthermore, we propose an MC-based DP accountant that outperforms existing DP accounting techniques in terms of accuracy and efficiency. MC-based DP verifier and accountant is applicable to an important and commonly used class of DP algorithms, including the famous DP-SGD. An empirical evaluation shows the proposed EVR paradigm improves the utility-privacy tradeoff for privacy-preserving machine learning",
    "checked": false,
    "id": "e231843966472fa60117403f49f2ac5f252ed1d9",
    "semantic_title": "a randomized approach for tight privacy accounting",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=S3Y0VvegGm": {
    "title": "The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning",
    "volume": "poster",
    "abstract": "While distributional reinforcement learning (DistRL) has been empirically effective, the question of when and why it is better than vanilla, non-distributional RL has remained unanswered. This paper explains the benefits of DistRL through the lens of small-loss bounds, which are instance-dependent bounds that scale with optimal achievable cost. Particularly, our bounds converge much faster than those from non-distributional approaches if the optimal cost is small. As warmup, we propose a distributional contextual bandit (DistCB) algorithm, which we show enjoys small-loss regret bounds and empirically outperforms the state-of-the-art on three real-world tasks. In online RL, we propose a DistRL algorithm that constructs confidence sets using maximum likelihood estimation. We prove that our algorithm enjoys novel small-loss PAC bounds in low-rank MDPs. As part of our analysis, we introduce the $\\ell_1$ distributional eluder dimension which may be of independent interest. Then, in offline RL, we show that pessimistic DistRL enjoys small-loss PAC bounds that are novel to the offline setting and are more robust to bad single-policy coverage",
    "checked": true,
    "id": "8d7154a1714f4a076ff211b9a4e0b95429e7a9c1",
    "semantic_title": "the benefits of being distributional: small-loss bounds for reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=dikH9tdPi2": {
    "title": "Improving Adversarial Transferability via Intermediate-level Perturbation Decay",
    "volume": "poster",
    "abstract": "Intermediate-level attacks that attempt to perturb feature representations following an adversarial direction drastically have shown favorable performance in crafting transferable adversarial examples. Existing methods in this category are normally formulated with two separate stages, where a directional guide is required to be determined at first and the scalar projection of the intermediate-level perturbation onto the directional guide is enlarged thereafter. The obtained perturbation deviates from the guide inevitably in the feature space, and it is revealed in this paper that such a deviation may lead to sub-optimal attack. To address this issue, we develop a novel intermediate-level method that crafts adversarial examples within a single stage of optimization. In particular, the proposed method, named intermediate-level perturbation decay (ILPD), encourages the intermediate-level perturbation to be in an effective adversarial direction and to possess a great magnitude simultaneously. In-depth discussion verifies the effectiveness of our method. Experimental results show that it outperforms state-of-the-arts by large margins in attacking various victim models on ImageNet (+10.07% on average) and CIFAR-10 (+3.88% on average). Our code is at https://github.com/qizhangli/ILPD-attack",
    "checked": false,
    "id": "333a8c09fee4dbf8fbd6d9291c9bc6aacd3cf7d9",
    "semantic_title": "improving adversarial transferability by intermediate-level perturbation decay",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JIYdbHDonF": {
    "title": "Simple, Scalable and Effective Clustering via One-Dimensional Projections",
    "volume": "poster",
    "abstract": "Clustering is a fundamental problem in unsupervised machine learning with many applications in data analysis. Popular clustering algorithms such as Lloyd's algorithm and $k$-means++ can take $\\Omega(ndk)$ time when clustering $n$ points in a $d$-dimensional space (represented by an $n\\times d$ matrix $X$) into $k$ clusters. On massive datasets with moderate to large $k$, the multiplicative $k$ factor can become very expensive. We introduce a simple randomized clustering algorithm that provably runs in expected time $O(\\mathsf{nnz}(X) + n\\log n)$ for arbitrary $k$. Here $\\mathsf{nnz}(X)$ is the total number of non-zero entries in the input dataset $X$, which is upper bounded by $nd$ and can be significantly smaller for sparse datasets. We prove that our algorithm achieves approximation ratio $\\widetilde{O}(k^4)$ on any input dataset for the $k$-means objective, and our experiments show that the quality of the clusters found by our algorithm is usually much better than this worst-case bound. We use our algorithm for $k$-means clustering and for coreset construction; our experiments show that it gives a new tradeoff between running time and cluster quality compared to previous state-of-the-art methods for these tasks. Our theoretical analysis is based on novel results of independent interest. We show that the approximation ratio achieved after a random one-dimensional projection can be lifted to the original points and that $k$-means++ seeding can be implemented in expected time $O(n\\log n)$ in one dimension",
    "checked": true,
    "id": "18c7e7a07af7677d910e1f560f9e169357f00d38",
    "semantic_title": "simple, scalable and effective clustering via one-dimensional projections",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bN1ZBSOV2f": {
    "title": "Sequential Predictive Two-Sample and Independence Testing",
    "volume": "poster",
    "abstract": "We study the problems of sequential nonparametric two-sample and independence testing. Sequential tests process data online and allow using observed data to decide whether to stop and reject the null hypothesis or to collect more data, while maintaining type I error control. We build upon the principle of (nonparametric) testing by betting, where a gambler places bets on future observations and their wealth measures evidence against the null hypothesis. While recently developed kernel-based betting strategies often work well on simple distributions, selecting a suitable kernel for high-dimensional or structured data, such as images, is often nontrivial. To address this drawback, we design prediction-based betting strategies that rely on the following fact: if a sequentially updated predictor starts to consistently determine (a) which distribution an instance is drawn from, or (b) whether an instance is drawn from the joint distribution or the product of the marginal distributions (the latter produced by external randomization), it provides evidence against the two-sample or independence nulls respectively. We empirically demonstrate the superiority of our tests over kernel-based approaches under structured settings. Our tests can be applied beyond the case of independent and identically distributed data, remaining valid and powerful even when the data distribution drifts over time",
    "checked": true,
    "id": "7a1f41517e105998f23cd11f64a1addc5a2ae20d",
    "semantic_title": "sequential predictive two-sample and independence testing",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=BJ1vOqh3hJ": {
    "title": "Retaining Beneficial Information from Detrimental Data for Neural Network Repair",
    "volume": "poster",
    "abstract": "The performance of deep learning models heavily relies on the quality of the training data. Inadequacies in the training data, such as corrupt input or noisy labels, can lead to the failure of model generalization. Recent studies propose repairing the model by identifying the training samples that contribute to the failure and removing their influence from the model. However, it is important to note that the identified data may contain both beneficial and detrimental information. Simply erasing the information of the identified data from the model can have a negative impact on its performance, especially when accurate data is mistakenly identified as detrimental and removed. To overcome this challenge, we propose a novel approach that leverages the knowledge obtained from a retained clean set. Our method first identifies harmful data by utilizing the clean set, then separates the beneficial and detrimental information within the identified data. Finally, we utilize the extracted beneficial information to enhance the model's performance. Through empirical evaluations, we demonstrate that our method outperforms baseline approaches in both identifying harmful data and rectifying model failures. Particularly in scenarios where identification is challenging and a significant amount of benign data is involved, our method improves performance while the baselines deteriorate due to the erroneous removal of beneficial information",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8ox2vrQiTF": {
    "title": "Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells",
    "volume": "poster",
    "abstract": "To solve the spatial problems of mapping, localization and navigation, the mammalian lineage has developed striking spatial representations. One important spatial representation is the Nobel-prize winning grid cells: neurons that represent self-location, a local and aperiodic quantity, with seemingly bizarre non-local and spatially periodic activity patterns of a few discrete periods. Why has the mammalian lineage learnt this peculiar grid representation? Mathematical analysis suggests that this multi-periodic representation has excellent properties as an algebraic code with high capacity and intrinsic error-correction, but to date, synthesis of multi-modular grid cells in deep recurrent neural networks remains absent. In this work, we begin by identifying key insights from four families of approaches to answering the grid cell question: dynamical systems, coding theory, function optimization and supervised deep learning. We then leverage our insights to propose a new approach that elegantly combines the strengths of all four approaches. Our approach is a self-supervised learning (SSL) framework - including data, data augmentations, loss functions and a network architecture - motivated from a normative perspective, with no access to supervised position information. Without making assumptions about internal or readout representations, we show that multiple grid cell modules can emerge in networks trained on our SSL framework and that the networks generalize significantly beyond their training distribution. This work contains insights for neuroscientists interested in the origins of grid cells as well as machine learning researchers interested in novel SSL frameworks",
    "checked": true,
    "id": "27bc20a95969cffa29065fcc1beb63ee2386b852",
    "semantic_title": "self-supervised learning of representations for space generates multi-modular grid cells",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ia4dmqst0Z": {
    "title": "ResoNet: Noise-Trained Physics-Informed MRI Off-Resonance Correction",
    "volume": "poster",
    "abstract": "Magnetic Resonance Imaging (MRI) is a powerful medical imaging modality that offers diagnostic information without harmful ionizing radiation. Unlike optical imaging, MRI sequentially samples the spatial Fourier domain (k-space) of the image. Measurements are collected in multiple shots, or readouts, and in each shot, data along a smooth trajectory is sampled. Conventional MRI data acquisition relies on sampling k-space row-by-row in short intervals, which is slow and inefficient. More efficient, non-Cartesian sampling trajectories (e.g., Spirals) use longer data readout intervals, but are more susceptible to magnetic field inhomogeneities, leading to off-resonance artifacts. Spiral trajectories cause off-resonance blurring in the image, and the mathematics of this blurring resembles that of optical blurring, where magnetic field variation corresponds to depth and readout duration to aperture size. Off-resonance blurring is a system issue with a physics-based, accurate forward model. We present a physics-informed deep learning framework for off-resonance correction in MRI, which is trained exclusively on synthetic, noise-like data with representative marginal statistics. Our approach allows for fat/water separation and is compatible with parallel imaging acceleration. Through end-to-end training using synthetic randomized data (i.e., noise-like images, coil sensitivities, field maps), we train the network to reverse off-resonance effects across diverse anatomies and contrasts without retraining. We demonstrate the effectiveness of our approach through results on phantom and in-vivo data. This work has the potential to facilitate the clinical adoption of non-Cartesian sampling trajectories, enabling efficient, rapid, and motion-robust MRI scans. Code is publicly available at: https://github.com/mikgroup/ResoNet",
    "checked": false,
    "id": "1fddeff40140739228e242dcd2da53517dc72668",
    "semantic_title": "resonet: physics informed deep learning based off-resonance correction trained on synthetic data",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=obCNIzeSrg": {
    "title": "SQ Lower Bounds for Learning Mixtures of Linear Classifiers",
    "volume": "poster",
    "abstract": "We study the problem of learning mixtures of linear classifiers under Gaussian covariates. Given sample access to a mixture of $r$ distributions on $\\mathbb{R}^n$ of the form $(\\mathbf{x},y_{\\ell})$, $\\ell \\in [r]$, where $\\mathbf{x}\\sim\\mathcal{N}(0,\\mathbf{I}_n)$ and $y_\\ell=\\mathrm{sign}(\\langle\\mathbf{v}_{\\ell},\\mathbf{x}\\rangle)$ for an unknown unit vector $\\mathbf{v}_{\\ell}$, the goal is to learn the underlying distribution in total variation distance. Our main result is a Statistical Query (SQ) lower bound suggesting that known algorithms for this problem are essentially best possible, even for the special case of uniform mixtures. In particular, we show that the complexity of any SQ algorithm for the problem is $n^{\\mathrm{poly}(1/\\Delta) \\log(r)}$, where $\\Delta$ is a lower bound on the pairwise $\\ell_2$-separation between the $\\mathbf{v}_{\\ell}$'s. The key technical ingredient underlying our result is a new construction of spherical designs on the unit sphere that may be of independent interest",
    "checked": true,
    "id": "5d3ec46e3bae52a04761d0696dfeb01bca6cbe74",
    "semantic_title": "sq lower bounds for learning mixtures of linear classifiers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TfbzX6I14i": {
    "title": "Sparse Modular Activation for Efficient Sequence Modeling",
    "volume": "poster",
    "abstract": "Recent hybrid models combining Linear State Space Models (SSMs) with self-attention mechanisms have demonstrated impressive results across a range of sequence modeling tasks. However, current approaches apply attention modules statically and uniformly to all elements in the input sequences, leading to sub-optimal quality-efficiency trade-offs. To address this limitation, we introduce Sparse Modular Activation (SMA), a general mechanism enabling neural networks to sparsely and dynamically activate sub-modules for sequence elements in a differentiable manner. Through allowing each element to skip non-activated sub-modules, SMA reduces computation and memory consumption of neural networks at both training and inference stages. To validate the effectiveness of SMA on sequence modeling, we design a novel neural architecture, SeqBoat, which employs SMA to sparsely activate a Gated Attention Unit (GAU) based on the state representations learned from an SSM. By constraining the GAU to only conduct local attention on the activated inputs, SeqBoat can achieve linear inference complexity with theoretically infinite attention span, and provide substantially better quality-efficiency trade-off than the chunking-based models. With experiments on a wide range of tasks, including long sequence modeling, speech classification and language modeling, SeqBoat brings new state-of-the-art results among hybrid models with linear complexity, and reveals the amount of attention needed for each task through the learned sparse activation patterns. Our code is publicly available at https://github.com/renll/SeqBoat",
    "checked": true,
    "id": "d2d0371158803df93a249c9f7237ffd79b875816",
    "semantic_title": "sparse modular activation for efficient sequence modeling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qjqJL2lfkH": {
    "title": "Rank-1 Matrix Completion with Gradient Descent and Small Random Initialization",
    "volume": "poster",
    "abstract": "The nonconvex formulation of the matrix completion problem has received significant attention in recent years due to its affordable complexity compared to the convex formulation. Gradient Descent (GD) is a simple yet efficient baseline algorithm for solving nonconvex optimization problems. The success of GD has been witnessed in many different problems in both theory and practice when it is combined with random initialization. However, previous works on matrix completion require either careful initialization or regularizers to prove the convergence of GD. In this paper, we study the rank-1 symmetric matrix completion and prove that GD converges to the ground truth when small random initialization is used. We show that in a logarithmic number of iterations, the trajectory enters the region where local convergence occurs. We provide an upper bound on the initialization size that is sufficient to guarantee the convergence, and show that a larger initialization can be used as more samples are available. We observe that the implicit regularization effect of GD plays a critical role in the analysis, and for the entire trajectory, it prevents each entry from becoming much larger than the others",
    "checked": true,
    "id": "0922c64a10218b234d6b8b926be6aaaab09f6088",
    "semantic_title": "rank-1 matrix completion with gradient descent and small random initialization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=5oEVdOd6TV": {
    "title": "Cross-Scale MAE: A Tale of Multiscale Exploitation in Remote Sensing",
    "volume": "poster",
    "abstract": "Remote sensing images present unique challenges to image analysis due to the extensive geographic coverage, hardware limitations, and misaligned multi-scale images. This paper revisits the classical multi-scale representation learning problem but under the general framework of self-supervised learning for remote sensing image understanding. We present Cross-Scale MAE, a self-supervised model built upon the Masked Auto-Encoder (MAE). During pre-training, Cross-Scale MAE employs scale augmentation techniques and enforces cross-scale consistency constraints through both contrastive and generative losses, to ensure consistent and meaningful representations well-suited for a wide range of downstream tasks. Further, our implementation leverages the xFormers library to accelerate network pre training on a single GPU while maintaining the quality of learned representations. Experimental evaluations demonstrate that Cross-Scale MAE exhibits superior performance compared to standard MAE and other state-of-the-art remote sensing MAE methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OzpTd2EsH1": {
    "title": "Rethinking the Backward Propagation for Adversarial Transferability",
    "volume": "poster",
    "abstract": "Transfer-based attacks generate adversarial examples on the surrogate model, which can mislead other black-box models without access, making it promising to attack real-world applications. Recently, several works have been proposed to boost adversarial transferability, in which the surrogate model is usually overlooked. In this work, we identify that non-linear layers (e.g., ReLU, max-pooling, etc.) truncate the gradient during backward propagation, making the gradient w.r.t. input image imprecise to the loss function. We hypothesize and empirically validate that such truncation undermines the transferability of adversarial examples. Based on these findings, we propose a novel method called Backward Propagation Attack (BPA) to increase the relevance between the gradient w.r.t. input image and loss function so as to generate adversarial examples with higher transferability. Specifically, BPA adopts a non-monotonic function as the derivative of ReLU and incorporates softmax with temperature to smooth the derivative of max-pooling, thereby mitigating the information loss during the backward propagation of gradients. Empirical results on the ImageNet dataset demonstrate that not only does our method substantially boost the adversarial transferability, but it is also general to existing transfer-based attacks. Code is available at https://github.com/Trustworthy-AI-Group/RPA",
    "checked": true,
    "id": "89347e7b42e00e949fd64060136cc64497ab2ef3",
    "semantic_title": "rethinking the backward propagation for adversarial transferability",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=Q3CRHnttxW": {
    "title": "Approximate Allocation Matching for Structural Causal Bandits with Unobserved Confounders",
    "volume": "poster",
    "abstract": "Structural causal bandit provides a framework for online decision-making problems when causal information is available. It models the stochastic environment with a structural causal model (SCM) that governs the causal relations between random variables. In each round, an agent applies an intervention (or no intervention) by setting certain variables to some constants and receives a stochastic reward from a non-manipulable variable. Though the causal structure is given, the observational and interventional distributions of these random variables are unknown beforehand, and they can only be learned through interactions with the environment. Therefore, to maximize the expected cumulative reward, it is critical to balance the explore-versus-exploit tradeoff. We assume each random variable takes a finite number of distinct values, and consider a semi-Markovian setting, where random variables are affected by unobserved confounders. Using the canonical SCM formulation to discretize the domains of unobserved variables, we efficiently integrate samples to reduce model uncertainty. This gives the decision maker a natural advantage over those in a classical multi-armed bandit setup. We provide a logarithmic asymptotic regret lower bound for the structural causal bandit problem. Inspired by the lower bound, we design an algorithm that can utilize the causal structure to accelerate the learning process and take informative and rewarding interventions. We establish that our algorithm achieves a logarithmic regret and demonstrate that it outperforms the existing methods via simulations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nq4OhifyEe": {
    "title": "Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection",
    "volume": "poster",
    "abstract": "We reveal a one-class homophily phenomenon, which is one prevalent property we find empirically in real-world graph anomaly detection (GAD) datasets, i.e., normal nodes tend to have strong connection/affinity with each other, while the homophily in abnormal nodes is significantly weaker than normal nodes. However, this anomaly-discriminative property is ignored by existing GAD methods that are typically built using a conventional anomaly detection objective, such as data reconstruction. In this work, we explore this property to introduce a novel unsupervised anomaly scoring measure for GAD -- local node affinity-- that assigns a larger anomaly score to nodes that are less affiliated with their neighbors, with the affinity defined as similarity on node attributes/representations. We further propose Truncated Affinity Maximization (TAM) that learns tailored node representations for our anomaly measure by maximizing the local affinity of nodes to their neighbors. Optimizing on the original graph structure can be biased by non-homophily edges(i.e., edges connecting normal and abnormal nodes). Thus, TAM is instead optimized on truncated graphs where non-homophily edges are removed iteratively to mitigate this bias. The learned representations result in significantly stronger local affinity for normal nodes than abnormal nodes. Extensive empirical results on 10 real-world GAD datasets show that TAM substantially outperforms seven competing models, achieving over 10% increase in AUROC/AUPRC compared to the best contenders on challenging datasets. Our code is available at https://github.com/mala-lab/TAM-master/",
    "checked": true,
    "id": "4312617b8e7e0bcbf80876ebffddb6bd1d6ea7ac",
    "semantic_title": "truncated affinity maximization: one-class homophily modeling for graph anomaly detection",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=JhQP33aMx2": {
    "title": "Module-wise Adaptive Distillation for Multimodality Foundation Models",
    "volume": "poster",
    "abstract": "Pre-trained multimodal foundation models have demonstrated remarkable generalizability but pose challenges for deployment due to their large sizes. One effective approach to reducing their sizes is layerwise distillation, wherein small student models are trained to match the hidden representations of large teacher models at each layer. Motivated by our observation that certain architecture components, referred to as modules, contribute more significantly to the student's performance than others, we propose to track the contributions of individual modules by recording the loss decrement after distillation each module and choose the module with a greater contribution to distill more frequently. Such an approach can be naturally formulated as a multi-armed bandit (MAB) problem, where modules and loss decrements are considered as arms and rewards, respectively. We then develop a modified-Thompson sampling algorithm named OPTIMA to address the nonstationarity of module contributions resulting from model updating. Specifically, we leverage the observed contributions in recent history to estimate the changing contribution of each module and select modules based on these estimations to maximize the cumulative contribution. We evaluate the effectiveness of OPTIMA through distillation experiments on various multimodal understanding and image captioning tasks, using the CoCa-Large model \\citep{yu2022coca} as the teacher model",
    "checked": true,
    "id": "e2d3f670867a13311a5238a78d98d3c39514a162",
    "semantic_title": "module-wise adaptive distillation for multimodality foundation models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IacxcFpvWQ": {
    "title": "Can Language Models Teach? Teacher Explanations Improve Student Performance via Personalization",
    "volume": "poster",
    "abstract": "A hallmark property of explainable AI models is the ability to teach other agents, communicating knowledge of how to perform a task. While Large Language Models (LLMs) perform complex reasoning by generating explanations for their predictions, it is unclear whether they also make good teachers for weaker agents. To address this, we consider a student-teacher framework between two LLM agents and study if, when, and how the teacher should intervene with natural language explanations to improve the student's performance. Since communication is expensive, we define a budget such that the teacher only communicates explanations for a fraction of the data, after which the student should perform well on its own. We decompose the teaching problem along four axes: (1) if teacher's test time in- tervention improve student predictions, (2) when it is worth explaining a data point, (3) how the teacher should personalize explanations to better teach the student, and (4) if teacher explanations also improve student performance on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next, inspired by the Theory of Mind abilities of effective teachers, we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention, allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions, teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally, we also verify that misaligned teachers can lower student performance to random chance by intentionally misleading them",
    "checked": false,
    "id": "58fce438f817b46d37d072f8af7dfa4fd2dcd866",
    "semantic_title": "can language models teach weaker agents? teacher explanations improve students via personalization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4hYIxI8ds0": {
    "title": "Make the U in UDA Matter: Invariant Consistency Learning for Unsupervised Domain Adaptation",
    "volume": "poster",
    "abstract": "Domain Adaptation (DA) is always challenged by the spurious correlation between the domain-invariant features (e.g., class identity) and the domain-specific ones (e.g., environment) that does not generalize to the target domain. Unfortunately, even enriched with additional unsupervised target domains, existing Unsupervised DA (UDA) methods still suffer from it. This is because the source domain supervision only considers the target domain samples as auxiliary data (e.g., by pseudo-labeling), yet the inherent distribution in the target domain---where the valuable de-correlation clues hide---is disregarded. We propose to make the U in UDA matter by giving equal status to the two domains. Specifically, we learn an invariant classifier whose prediction is simultaneously consistent with the labels in the source domain and clusters in the target domain, hence the spurious correlation inconsistent in the target domain is removed. We dub our approach \"Invariant CONsistency learning\" (ICON). Extensive experiments show that ICON achieves the state-of-the-art performance on the classic UDA benchmarks: Office-Home and VisDA-2017, and outperforms all the conventional methods on the challenging WILDS 2.0 benchmark. Codes are in https://github.com/yue-zhongqi/ICON",
    "checked": true,
    "id": "31496aa700dc812572fc42ce0fffb5a365dc739a",
    "semantic_title": "make the u in uda matter: invariant consistency learning for unsupervised domain adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3ucmcMzCXD": {
    "title": "Estimating Noise Correlations Across Continuous Conditions With Wishart Processes",
    "volume": "poster",
    "abstract": "The signaling capacity of a neural population depends on the scale and orientation of its covariance across trials. Estimating this \"noise\" covariance is challenging and is thought to require a large number of stereotyped trials. New approaches are therefore needed to interrogate the structure of neural noise across rich, naturalistic behaviors and sensory experiences, with few trials per condition. Here, we exploit the fact that conditions are smoothly parameterized in many experiments and leverage Wishart process models to pool statistical power from trials in neighboring conditions. We demonstrate that these models perform favorably on experimental data from the mouse visual cortex and monkey motor cortex relative to standard covariance estimators. Moreover, they produce smooth estimates of covariance as a function of stimulus parameters, enabling estimates of noise correlations in entirely unseen conditions as well as continuous estimates of Fisher information&mdash;a commonly used measure of signal fidelity. Together, our results suggest that Wishart processes are broadly applicable tools for quantification and uncertainty estimation of noise correlations in trial-limited regimes, paving the way toward understanding the role of noise in complex neural computations and behavior",
    "checked": true,
    "id": "b33a8668e479aa41d3cdec397dbd7a9d890784ac",
    "semantic_title": "estimating noise correlations across continuous conditions with wishart processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EfTMRQn00d": {
    "title": "STREAMER: Streaming Representation Learning and Event Segmentation in a Hierarchical Manner",
    "volume": "poster",
    "abstract": "We present a novel self-supervised approach for hierarchical representation learning and segmentation of perceptual inputs in a streaming fashion. Our research addresses how to semantically group streaming inputs into chunks at various levels of a hierarchy while simultaneously learning, for each chunk, robust global representations throughout the domain. To achieve this, we propose STREAMER, an architecture that is trained layer-by-layer, adapting to the complexity of the input domain. In our approach, each layer is trained with two primary objectives: making accurate predictions into the future and providing necessary information to other levels for achieving the same objective. The event hierarchy is constructed by detecting prediction error peaks at different levels, where a detected boundary triggers a bottom-up information flow. At an event boundary, the encoded representation of inputs at one layer becomes the input to a higher-level layer. Additionally, we design a communication module that facilitates top-down and bottom-up exchange of information during the prediction process. Notably, our model is fully self-supervised and trained in a streaming manner, enabling a single pass on the training data. This means that the model encounters each input only once and does not store the data. We evaluate the performance of our model on the egocentric EPIC-KITCHENS dataset, specifically focusing on temporal event segmentation. Furthermore, we conduct event retrieval experiments using the learned representations to demonstrate the high quality of our video event representations. Illustration videos and code are available on our project page: https://ramymounir.com/publications/streamer",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mA7nTGXjD3": {
    "title": "Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games",
    "volume": "poster",
    "abstract": "This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the \\textit{suboptimality gap}, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium (NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the previous best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the same order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds",
    "checked": true,
    "id": "ff11287a7d479d5e4247d7fb0240cb7d36f129de",
    "semantic_title": "provably fast convergence of independent natural policy gradient for markov potential games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bTL5SNOpfa": {
    "title": "Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation",
    "volume": "poster",
    "abstract": "Robustness has been extensively studied in reinforcement learning (RL) to handle various forms of uncertainty such as random perturbations, rare events, and malicious attacks. In this work, we consider one critical type of robustness against spurious correlation, where different portions of the state do not have correlations induced by unobserved confounders. These spurious correlations are ubiquitous in real-world tasks, for instance, a self-driving car usually observes heavy traffic in the daytime and light traffic at night due to unobservable human activity. A model that learns such useless or even harmful correlation could catastrophically fail when the confounder in the test case deviates from the training one. Although motivated, enabling robustness against spurious correlation poses significant challenges since the uncertainty set, shaped by the unobserved confounder and causal structure, is difficult to characterize and identify. Existing robust algorithms that assume simple and unstructured uncertainty sets are therefore inadequate to address this challenge. To solve this issue, we propose Robust State-Confounded Markov Decision Processes (RSC-MDPs) and theoretically demonstrate its superiority in avoiding learning spurious correlations compared with other robust RL counterparts. We also design an empirical algorithm to learn the robust optimal policy for RSC-MDPs, which outperforms all baselines in eight realistic self-driving and manipulation tasks",
    "checked": true,
    "id": "a6ed003703b52aa7de285d19ea2b09326ba04ae4",
    "semantic_title": "seeing is not believing: robust reinforcement learning against spurious correlation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=lnTpBUge5G": {
    "title": "Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms",
    "volume": "poster",
    "abstract": "In stochastic zeroth-order optimization, a problem of practical relevance is understanding how to fully exploit the local geometry of the underlying objective function. We consider a fundamental setting in which the objective function is quadratic, and provide the first tight characterization of the optimal Hessian-dependent sample complexity. Our contribution is twofold. First, from an information-theoretic point of view, we prove tight lower bounds on Hessian-dependent complexities by introducing a concept called \\emph{energy allocation}, which captures the interaction between the searching algorithm and the geometry of objective functions. A matching upper bound is obtained by solving the optimal energy spectrum. Then, algorithmically, we show the existence of a Hessian-independent algorithm that universally achieves the asymptotic optimal sample complexities for all Hessian instances. The optimal sample complexities achieved by our algorithm remain valid for heavy-tailed noise distributions, which are enabled by a truncation method",
    "checked": true,
    "id": "4f91df24fa60e2c481cee9f7a8c5543aefe87c96",
    "semantic_title": "sample complexity for quadratic bandits: hessian dependent bounds and optimal algorithms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1pWNhmbllE": {
    "title": "Uncertainty-Aware Instance Reweighting for Off-Policy Learning",
    "volume": "poster",
    "abstract": "Off-policy learning, referring to the procedure of policy optimization with access only to logged feedback data, has shown importance in various important real-world applications, such as search engines and recommender systems. While the ground-truth logging policy is usually unknown, previous work simply takes its estimated value for the off-policy learning, ignoring the negative impact from both high bias and high variance resulted from such an estimator. And these impact is often magnified on samples with small and inaccurately estimated logging probabilities. The contribution of this work is to explicitly model the uncertainty in the estimated logging policy, and propose an Uncertainty-aware Inverse Propensity Score estimator (UIPS) for improved off-policy learning, with a theoretical convergence guarantee. Experiment results on the synthetic and real-world recommendation datasets demonstrate that UIPS significantly improves the quality of the discovered policy, when compared against an extensive list of state-of-the-art baselines",
    "checked": true,
    "id": "ea30bcd9c2b2d0dbaf63e808c59733b8e4d104a4",
    "semantic_title": "uncertainty-aware instance reweighting for off-policy learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6kINNTYQcm": {
    "title": "Adversarially Robust Distributed Count Tracking via Partial Differential Privacy",
    "volume": "poster",
    "abstract": "We study the distributed tracking model, also known as distributed functional monitoring. This model involves $k$ sites each receiving a stream of items and communicating with the central server. The server's task is to track a function of all items received thus far continuously, with minimum communication cost. For count tracking, it is known that there is a $\\sqrt{k}$ gap in communication between deterministic and randomized algorithms. However, existing randomized algorithms assume an \"oblivious adversary\" who constructs the entire input streams before the algorithm starts. Here we consider adaptive adversaries who can choose new items based on previous answers from the algorithm. Deterministic algorithms are trivially robust to adaptive adversaries, while randomized ones may not. Therefore, we investigate whether the $\\sqrt{k}$ advantage of randomized algorithms is from randomness itself or the oblivious adversary assumption. We provide an affirmative answer to this question by giving a robust algorithm with optimal communication. Existing robustification techniques do not yield optimal bounds due to the inherent challenges of the distributed nature of the problem. To address this, we extend the differential privacy framework by introducing \"partial differential privacy\" and proving a new generalization theorem. This theorem may have broader applications beyond robust count tracking, making it of independent interest",
    "checked": true,
    "id": "edb345fec9e9ce1c9b69c1b4581f3dfbcbfc892e",
    "semantic_title": "adversarially robust distributed count tracking via partial differential privacy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IdF7VT6eEs": {
    "title": "Online Performative Gradient Descent for Learning Nash Equilibria in Decision-Dependent Games",
    "volume": "poster",
    "abstract": "We study the multi-agent game within the innovative framework of decision-dependent games, which establishes a feedback mechanism that population data reacts to agents' actions and further characterizes the strategic interactions between agents. We focus on finding the Nash equilibrium of decision-dependent games in the bandit feedback setting. However, since agents are strategically coupled, traditional gradient-based methods are infeasible without the gradient oracle. To overcome this challenge, we model the strategic interactions by a general parametric model and propose a novel online algorithm, Online Performative Gradient Descent (OPGD), which leverages the ideas of online stochastic approximation and projected gradient descent to learn the Nash equilibrium in the context of function approximation for the unknown gradient. In particular, under mild assumptions on the function classes defined in the parametric model, we prove that OPGD can find the Nash equilibrium efficiently for strongly monotone decision-dependent games. Synthetic numerical experiments validate our theory",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GzlDKZlwie": {
    "title": "Functional Renyi Differential Privacy for Generative Modeling",
    "volume": "poster",
    "abstract": "Differential privacy (DP) has emerged as a rigorous notion to quantify data privacy. Subsequently, Renyi differential privacy (RDP) becomes an alternative to the ordinary DP notion in both theoretical and empirical studies, for its convenient compositional rules and flexibility. However, most mechanisms with DP (RDP) guarantees are essentially based on randomizing a fixed, finite-dimensional vector output. In this work, following Hall et al. (2013) we further extend RDP to functional outputs, where the output space can be infinite-dimensional, and develop all necessary tools, *e.g.*, (subsampled) Gaussian mechanism, composition, and post-processing rules, to facilitate its practical adoption. As an illustration, we apply functional RDP (f-RDP) to functions in the reproducing kernel Hilbert space (RKHS) to develop a differentially private generative model (DPGM), where training can be interpreted as iteratively releasing loss functions (in an RKHS) with DP (RDP) guarantees. Empirically, the new training paradigm achieves a significant improvement in privacy-utility trade-off compared to existing alternatives, especially when $\\epsilon=0.2$. Our code is available at https://github.com/dihjiang/DP-kernel",
    "checked": false,
    "id": "4b32e492828a880b4d2859301a005126312b8e8b",
    "semantic_title": "adam-dpgan: a differential private mechanism for generative adversarial network",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=UK8mA3DRnb": {
    "title": "Simple and Asymmetric Graph Contrastive Learning without Augmentations",
    "volume": "poster",
    "abstract": "Graph Contrastive Learning (GCL) has shown superior performance in representation learning in graph-structured data. Despite their success, most existing GCL methods rely on prefabricated graph augmentation and homophily assumptions. Thus, they fail to generalize well to heterophilic graphs where connected nodes may have different class labels and dissimilar features. In this paper, we study the problem of conducting contrastive learning on homophilic and heterophilic graphs. We find that we can achieve promising performance simply by considering an asymmetric view of the neighboring nodes. The resulting simple algorithm, Asymmetric Contrastive Learning for Graphs (GraphACL), is easy to implement and does not rely on graph augmentations and homophily assumptions. We provide theoretical and empirical evidence that GraphACL can capture one-hop local neighborhood information and two-hop monophily similarity, which are both important for modeling heterophilic graphs. Experimental results show that the simple GraphACL significantly outperforms state-of-the-art graph contrastive learning and self-supervised learning methods on homophilic and heterophilic graphs. The code of GraphACL is available at https://github.com/tengxiao1/GraphACL",
    "checked": true,
    "id": "cb41f8163dd866f51f7e58d9e77f354b11181967",
    "semantic_title": "simple and asymmetric graph contrastive learning without augmentations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S4NN3OOiwP": {
    "title": "Efficient Equivariant Transfer Learning from Pretrained Models",
    "volume": "poster",
    "abstract": "Efficient transfer learning algorithms are key to the success of foundation models on diverse downstream tasks even with limited data. Recent works of Basu et al. (2023) and Kaba et al. (2022) propose group averaging (equitune) and optimization-based methods, respectively, over features from group-transformed inputs to obtain equivariant outputs from non-equivariant neural networks. While Kaba et al. (2022) are only concerned with training from scratch, we find that equitune performs poorly on equivariant zero-shot tasks despite good finetuning results. We hypothesize that this is because pretrained models provide better quality features for certain transformations than others and simply averaging them is deleterious. Hence, we propose λ-equitune that averages the features using importance weights, λs. These weights are learned directly from the data using a small neural network, leading to excellent zero-shot and finetuned results that outperform equitune. Further, we prove that λ-equitune is equivariant and a universal approximator of equivariant functions. Additionally, we show that the method of Kaba et al. (2022) used with appropriate loss functions, which we call equizero, also gives excellent zero-shot and finetuned performance. Both equitune and equizero are special cases of λ- equitune. To show the simplicity and generality of our method, we validate on a wide range of diverse applications and models such as 1) image classification using CLIP, 2) deep Q-learning, 3) fairness in natural language generation (NLG), 4) compositional generalization in languages, and 5) image classification using pretrained CNNs such as Resnet and Alexnet",
    "checked": true,
    "id": "fa69d1a623579e3591045e4615410176e0f55204",
    "semantic_title": "efficient equivariant transfer learning from pretrained models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7ZQiucQu2u": {
    "title": "Bounding the Invertibility of Privacy-preserving Instance Encoding using Fisher Information",
    "volume": "poster",
    "abstract": "Privacy-preserving instance encoding aims to encode raw data into feature vectors without revealing their privacy-sensitive information. When designed properly, these encodings can be used for downstream ML applications such as training and inference with limited privacy risk. However, the vast majority of existing schemes do not theoretically justify that their encoding is non-invertible, and their privacy-enhancing properties are only validated empirically against a limited set of attacks. In this paper, we propose a theoretically-principled measure for the invertibility of instance encoding based on Fisher information that is broadly applicable to a wide range of popular encoders. We show that dFIL can be used to bound the invertibility of encodings both theoretically and empirically, providing an intuitive interpretation of the privacy of instance encoding",
    "checked": true,
    "id": "4668246cb777383beeeb00d8768ced10ef2bf388",
    "semantic_title": "bounding the invertibility of privacy-preserving instance encoding using fisher information",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=VqclD6Nfaj": {
    "title": "Autonomous Capability Assessment of Sequential Decision-Making Systems in Stochastic Settings",
    "volume": "poster",
    "abstract": "It is essential for users to understand what their AI systems can and can't do in order to use them safely. However, the problem of enabling users to assess AI systems with sequential decision-making (SDM) capabilities is relatively understudied. This paper presents a new approach for modeling the capabilities of black-box AI systems that can plan and act, along with the possible effects and requirements for executing those capabilities in stochastic settings. We present an active-learning approach that can effectively interact with a black-box SDM system and learn an interpretable probabilistic model describing its capabilities. Theoretical analysis of the approach identifies the conditions under which the learning process is guaranteed to converge to the correct model of the agent; empirical evaluations on different agents and simulated scenarios show that this approach is few-shot generalizable and can effectively describe the capabilities of arbitrary black-box SDM agents in a sample-efficient manner",
    "checked": false,
    "id": "0eefd63442fac6f74475f7b709d0ad03036d5554",
    "semantic_title": "autonomous capability assessment of sequential decision-making systems in stochastic settings (extended version)",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=JDw50IX4TY": {
    "title": "Partial Multi-Label Learning with Probabilistic Graphical Disambiguation",
    "volume": "poster",
    "abstract": "In partial multi-label learning (PML), each training example is associated with a set of candidate labels, among which only some labels are valid. As a common strategy to tackle PML problem, disambiguation aims to recover the ground-truth labeling information from such inaccurate annotations. However, existing approaches mainly rely on heuristics or ad-hoc rules to disambiguate candidate labels, which may not be universal enough in complicated real-world scenarios. To provide a principled way for disambiguation, we make a first attempt to explore the probabilistic graphical model for PML problem, where a directed graph is tailored to infer latent ground-truth labeling information from the generative process of partial multi-label data. Under the framework of stochastic gradient variational Bayes, a unified variational lower bound is derived for this graphical model, which is further relaxed probabilistically so that the desired prediction model can be induced with simultaneously identified ground-truth labeling information. Comprehensive experiments on multiple synthetic and real-world data sets show that our approach outperforms the state-of-the-art counterparts",
    "checked": false,
    "id": "f9750a5a58af08e4b1e1672ac37926589f973445",
    "semantic_title": "understanding partial multi-label learning via mutual information",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=r9eZH6WNm2": {
    "title": "Learning to Group Auxiliary Datasets for Molecule",
    "volume": "poster",
    "abstract": "The limited availability of annotations in small molecule datasets presents a challenge to machine learning models. To address this, one common strategy is to collaborate with additional auxiliary datasets. However, having more data does not always guarantee improvements. Negative transfer can occur when the knowledge in the target dataset differs or contradicts that of the auxiliary molecule datasets. In light of this, identifying the auxiliary molecule datasets that can benefit the target dataset when jointly trained remains a critical and unresolved problem. Through an empirical analysis, we observe that combining graph structure similarity and task similarity can serve as a more reliable indicator for identifying high-affinity auxiliary datasets. Motivated by this insight, we propose MolGroup, which separates the dataset affinity into task and structure affinity to predict the potential benefits of each auxiliary molecule dataset. MolGroup achieves this by utilizing a routing mechanism optimized through a bi-level optimization framework. Empowered by the meta gradient, the routing mechanism is optimized toward maximizing the target dataset's performance and quantifies the affinity as the gating score. As a result, MolGroup is capable of predicting the optimal combination of auxiliary datasets for each target dataset. Our extensive experiments demonstrate the efficiency and effectiveness of MolGroup, showing an average improvement of 4.41%/3.47% for GIN/Graphormer trained with the group of molecule datasets selected by MolGroup on 11 target molecule datasets",
    "checked": true,
    "id": "8ba3cbc834190274a0af4ccd6b831a9b7c7374c2",
    "semantic_title": "learning to group auxiliary datasets for molecule",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SuvDnzrKCo": {
    "title": "Scaling Up Differentially Private LASSO Regularized Logistic Regression via Faster Frank-Wolfe Iterations",
    "volume": "poster",
    "abstract": "To the best of our knowledge, there are no methods today for training differentially private regression models on sparse input data. To remedy this, we adapt the Frank-Wolfe algorithm for $L_1$ penalized linear regression to be aware of sparse inputs and to use them effectively. In doing so, we reduce the training time of the algorithm from $\\mathcal{O}( T D S + T N S)$ to $\\mathcal{O}(N S + T \\sqrt{D} \\log{D} + T S^2)$, where $T$ is the number of iterations and a sparsity rate $S$ of a dataset with $N$ rows and $D$ features. Our results demonstrate that this procedure can reduce runtime by a factor of up to $2,200\\times$, depending on the value of the privacy parameter $\\epsilon$ and the sparsity of the dataset",
    "checked": true,
    "id": "e49dbd5639cb3ca997754b3aaa00415562a5d3d4",
    "semantic_title": "scaling up differentially private lasso regularized logistic regression via faster frank-wolfe iterations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CrpL8mGa0Q": {
    "title": "On the Relationship Between Relevance and Conflict in Online Social Link Recommendations",
    "volume": "poster",
    "abstract": "In an online social network, link recommendations are a way for users to discover relevant links to people they may know, thereby potentially increasing their engagement on the platform. However, the addition of links to a social network can also have an effect on the level of conflict in the network --- expressed in terms of polarization and disagreement. To date, however, we have very little understanding of how these two implications of link formation relate to each other: are the goals of high relevance and conflict reduction aligned, or are the links that users are most likely to accept fundamentally different from the ones with the greatest potential for reducing conflict? Here we provide the first analysis of this question, using the recently popular Friedkin-Johnsen model of opinion dynamics. We first present a surprising result on how link additions shift the level of opinion conflict, followed by explanation work that relates the amount of shift to structural features of the added links. We then characterize the gap in conflict reduction between the set of links achieving the largest reduction and the set of links achieving the highest relevance. The gap is measured on real-world data, based on instantiations of relevance defined by 13 link recommendation algorithms. We find that some, but not all, of the more accurate algorithms actually lead to better reduction of conflict. Our work suggests that social links recommended for increasing user engagement may not be as conflict-provoking as people might have thought",
    "checked": true,
    "id": "57940f09f8296b813eefaf573cd80e1d58c60191",
    "semantic_title": "on the relationship between relevance and conflict in online social link recommendations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t3vPEjgNtj": {
    "title": "QuadAttac$K$: A Quadratic Programming Approach to Learning Ordered Top-$K$ Adversarial Attacks",
    "volume": "poster",
    "abstract": "The adversarial vulnerability of Deep Neural Networks (DNNs) has been well-known and widely concerned, often under the context of learning top-$1$ attacks (e.g., fooling a DNN to classify a cat image as dog). This paper shows that the concern is much more serious by learning significantly more aggressive ordered top-$K$ clear-box targeted attacks proposed in~\\citep{zhang2020learning}. We propose a novel and rigorous quadratic programming (QP) method of learning ordered top-$K$ attacks with low computing cost, dubbed as \\textbf{QuadAttac$K$}. Our QuadAttac$K$ directly solves the QP to satisfy the attack constraint in the feature embedding space (i.e., the input space to the final linear classifier), which thus exploits the semantics of the feature embedding space (i.e., the principle of class coherence). With the optimized feature embedding vector perturbation, it then computes the adversarial perturbation in the data space via the vanilla one-step back-propagation. In experiments, the proposed QuadAttac$K$ is tested in the ImageNet-1k classification using ResNet-50, DenseNet-121, and Vision Transformers (ViT-B and DEiT-S). It successfully pushes the boundary of successful ordered top-$K$ attacks from $K=10$ up to $K=20$ at a cheap budget ($1\\times 60$) and further improves attack success rates for $K=5$ for all tested models, while retaining the performance for $K=1$",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=93NLxUojvc": {
    "title": "UltraRE: Enhancing RecEraser for Recommendation Unlearning via Error Decomposition",
    "volume": "poster",
    "abstract": "With growing concerns regarding privacy in machine learning models, regulations have committed to granting individuals the right to be forgotten while mandating companies to develop non-discriminatory machine learning systems, thereby fueling the study of the machine unlearning problem. Our attention is directed toward a practical unlearning scenario, i.e., recommendation unlearning. As the state-of-the-art framework, i.e., RecEraser, naturally achieves full unlearning completeness, our objective is to enhance it in terms of model utility and unlearning efficiency. In this paper, we rethink RecEraser from an ensemble-based perspective and focus on its three potential losses, i.e., redundancy, relevance, and combination. Under the theoretical guidance of the above three losses, we propose a new framework named UltraRE, which simplifies and powers RecEraser for recommendation tasks. Specifically, for redundancy loss, we incorporate transport weights in the clustering algorithm to optimize the equilibrium between collaboration and balance while enhancing efficiency; for relevance loss, we ensure that sub-models reach convergence on their respective group data; for combination loss, we simplify the combination estimator without compromising its efficacy. Extensive experiments on three real-world datasets demonstrate the effectiveness of UltraRE",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NibgkUin5n": {
    "title": "Towards Generic Semi-Supervised Framework for Volumetric Medical Image Segmentation",
    "volume": "poster",
    "abstract": "Volume-wise labeling in 3D medical images is a time-consuming task that requires expertise. As a result, there is growing interest in using semi-supervised learning (SSL) techniques to train models with limited labeled data. However, the challenges and practical applications extend beyond SSL to settings such as unsupervised domain adaptation (UDA) and semi-supervised domain generalization (SemiDG). This work aims to develop a generic SSL framework that can handle all three settings. We identify two main obstacles to achieving this goal in the existing SSL framework: 1) the weakness of capturing distribution-invariant features; and 2) the tendency for unlabeled data to be overwhelmed by labeled data, leading to over-fitting to the labeled data during training. To address these issues, we propose an Aggregating & Decoupling framework. The aggregating part consists of a Diffusion encoder that constructs a \"common knowledge set\" by extracting distribution-invariant features from aggregated information from multiple distributions/domains. The decoupling part consists of three decoders that decouple the training process with labeled and unlabeled data, thus avoiding over-fitting to labeled data, specific domains and classes. We evaluate our proposed framework on four benchmark datasets for SSL, Class-imbalanced SSL, UDA and SemiDG. The results showcase notable improvements compared to state-of-the-art methods across all four settings, indicating the potential of our framework to tackle more challenging SSL scenarios. Code and models are available at: https://github.com/xmed-lab/GenericSSL",
    "checked": true,
    "id": "9a768e60bd56c3d8ac2c4a76aac58561d056a786",
    "semantic_title": "towards generic semi-supervised framework for volumetric medical image segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v0GzRLvVp3": {
    "title": "Temporal Continual Learning with Prior Compensation for Human Motion Prediction",
    "volume": "poster",
    "abstract": "Human Motion Prediction (HMP) aims to predict future poses at different moments according to past motion sequences. Previous approaches have treated the prediction of various moments equally, resulting in two main limitations: the learning of short-term predictions is hindered by the focus on long-term predictions, and the incorporation of prior information from past predictions into subsequent predictions is limited. In this paper, we introduce a novel multi-stage training framework called Temporal Continual Learning (TCL) to address the above challenges. To better preserve prior information, we introduce the Prior Compensation Factor (PCF). We incorporate it into the model training to compensate for the lost prior information. Furthermore, we derive a more reasonable optimization objective through theoretical derivation. It is important to note that our TCL framework can be easily integrated with different HMP backbone models and adapted to various datasets and applications. Extensive experiments on four HMP benchmark datasets demonstrate the effectiveness and flexibility of TCL. The code is available at https://github.com/hyqlat/TCL",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZejTutd7VY": {
    "title": "TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models",
    "volume": "poster",
    "abstract": "Large Language Models (LLMs) are progressively being utilized as machine learning services and interface tools for various applications. However, the security implications of LLMs, particularly in relation to adversarial and Trojan attacks, remain insufficiently examined. In this paper, we propose TrojLLM, an automatic and black-box framework to effectively generate universal and stealthy triggers. When these triggers are incorporated into the input data, the LLMs' outputs can be maliciously manipulated. Moreover, the framework also supports embedding Trojans within discrete prompts, enhancing the overall effectiveness and precision of the triggers' attacks. Specifically, we propose a trigger discovery algorithm for generating universal triggers for various inputs by querying victim LLM-based APIs using few-shot data samples. Furthermore, we introduce a novel progressive Trojan poisoning algorithm designed to generate poisoned prompts that retain efficacy and transferability across a diverse range of models. Our experiments and results demonstrate TrojLLM's capacity to effectively insert Trojans into text prompts in real-world black-box LLM APIs including GPT-3.5 and GPT-4, while maintaining exceptional performance on clean test sets. Our work sheds light on the potential security risks in current models and offers a potential defensive approach. The source code of TrojLLM is available at https://github.com/UCF-ML-Research/TrojLLM",
    "checked": true,
    "id": "33e7f54c2b31849ea5f4a36f0a3470ea57857ff6",
    "semantic_title": "trojllm: a black-box trojan prompt attack on large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SxXN3kNTsV": {
    "title": "Offline Reinforcement Learning for Mixture-of-Expert Dialogue Management",
    "volume": "poster",
    "abstract": "Reinforcement learning (RL) has shown great promise for developing agents for dialogue management (DM) that are non-myopic, conduct rich conversations, and maximize overall user satisfaction. Despite the advancements in RL and language models (LMs), employing RL to drive conversational chatbots still poses significant challenges. A primary issue stems from RL's dependency on online exploration for effective learning, a process that can be costly. Moreover, engaging in online interactions with humans during the training phase can raise safety concerns, as the LM can potentially generate unwanted outputs. This issue is exacerbated by the combinatorial action spaces facing these algorithms, as most LM agents generate responses at the word level. We develop various RL algorithms, specialized in dialogue planning, that leverage recent Mixture-of-Expert Language Models (MoE-LMs)---models that capture diverse semantics, generate utterances reflecting different intents, and are amenable for multi-turn DM. By exploiting the MoE-LM structure, our methods significantly reduce the size of the action space and improve the efficacy of RL-based DM. We evaluate our methods in open-domain dialogue to demonstrate their effectiveness with respect to the diversity of intent in generated utterances and overall DM performance",
    "checked": true,
    "id": "d7b704e886fd0f6bd4a0604eb2496f2c25ca5bcf",
    "semantic_title": "offline reinforcement learning for mixture-of-expert dialogue management",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B5LpWAaBVA": {
    "title": "Online Nonstochastic Model-Free Reinforcement Learning",
    "volume": "poster",
    "abstract": "We investigate robust model-free reinforcement learning algorithms designed for environments that may be dynamic or even adversarial. Traditional state-based policies often struggle to accommodate the challenges imposed by the presence of unmodeled disturbances in such settings. Moreover, optimizing linear state-based policies pose an obstacle for efficient optimization, leading to nonconvex objectives, even in benign environments like linear dynamical systems. Drawing inspiration from recent advancements in model-based control, we intro- duce a novel class of policies centered on disturbance signals. We define several categories of these signals, which we term pseudo-disturbances, and develop corresponding policy classes based on them. We provide efficient and practical algorithms for optimizing these policies. Next, we examine the task of online adaptation of reinforcement learning agents in the face of adversarial disturbances. Our methods seamlessly integrate with any black-box model-free approach, yielding provable regret guarantees when dealing with linear dynamics. These regret guarantees unconditionally improve the best-known results for bandit linear control in having no dependence on the state-space dimension. We evaluate our method over various standard RL benchmarks and demonstrate improved robustness",
    "checked": true,
    "id": "4fd3f3b2f0f0a4b4e4a77d356f07dbc2d709b25d",
    "semantic_title": "online nonstochastic model-free reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=hDajsofjRM": {
    "title": "Online Adaptive Policy Selection in Time-Varying Systems: No-Regret via Contractive Perturbations",
    "volume": "poster",
    "abstract": "We study online adaptive policy selection in systems with time-varying costs and dynamics. We develop the Gradient-based Adaptive Policy Selection (GAPS) algorithm together with a general analytical framework for online policy selection via online optimization. Under our proposed notion of contractive policy classes, we show that GAPS approximates the behavior of an ideal online gradient descent algorithm on the policy parameters while requiring less information and computation. When convexity holds, our algorithm is the first to achieve optimal policy regret. When convexity does not hold, we provide the first local regret bound for online policy selection. Our numerical experiments show that GAPS can adapt to changing environments more quickly than existing benchmarks",
    "checked": true,
    "id": "bda76560d337be1cf64c5030295e446235d3e15d",
    "semantic_title": "online adaptive policy selection in time-varying systems: no-regret via contractive perturbations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MCVfX7HgPO": {
    "title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
    "volume": "poster",
    "abstract": "Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity. Recent studies have shown that large language models (LLMs) possess some abstract deductive reasoning ability given chain-of-thought prompts. However, they have primarily been tested on proofs using modus ponens or of a specific size, and from the same distribution as the in-context examples. To measure the general deductive reasoning ability of LLMs, we test on a broad set of deduction rules and measure their ability to generalize to more complex proofs from simpler demonstrations from multiple angles: depth-, width-, and compositional generalization. To facilitate systematic exploration, we construct a new synthetic and programmable reasoning dataset that enables control over deduction rules and proof complexity. Our experiments on four LLMs of various sizes and training objectives show that they are able to generalize to compositional proofs. However, they have difficulty generalizing to longer proofs, and they require explicit demonstrations to produce hypothetical subproofs, specifically in proof by cases and proof by contradiction",
    "checked": true,
    "id": "c58325547156a70cb27c148e5b57738ca9ce79aa",
    "semantic_title": "testing the general deductive reasoning capacity of large language models using ood examples",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=hn1oJO7lg6": {
    "title": "Computing Approximate $\\ell_p$ Sensitivities",
    "volume": "poster",
    "abstract": "Recent works in dimensionality reduction for regression tasks have introduced the notion of sensitivity, an estimate of the importance of a specific datapoint in a dataset, offering provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling. However, fast algorithms for approximating sensitivities, which we show is equivalent to approximate regression, are known for only the $\\ell_2$ setting, in which they are popularly termed leverage scores. In this work, we provide the first efficient algorithms for approximating $\\ell_p$ sensitivities and other summary statistics of a given matrix. In particular, for a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its $\\ell_1$ sensitivities at the cost of $n/\\alpha$ sensitivity computations. For estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$ sensitivities), we provide an algorithm based on importance sampling of $\\ell_p$ Lewis weights, which computes a constant factor approximation at the cost of roughly $\\sqrt{d}$ sensitivity computations, with no polynomial dependence on $n$. Furthermore, we estimate the maximum $\\ell_1$ sensitivity up to a $\\sqrt{d}$ factor in $O(d)$ sensitivity computations. We also generalize these results to $\\ell_p$ norms. Lastly, we experimentally show that for a wide class of structured matrices in real-world datasets, the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have on average low intrinsic effective dimensionality",
    "checked": true,
    "id": "868705ccb31390b87e88fa45fd20200045c2157f",
    "semantic_title": "computing approximate $\\ell_p$ sensitivities",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9Oi3YxIBSa": {
    "title": "Loss Decoupling for Task-Agnostic Continual Learning",
    "volume": "poster",
    "abstract": "Continual learning requires the model to learn multiple tasks in a sequential order. To perform continual learning, the model must possess the abilities to maintain performance on old tasks (stability) and adapt itself to learn new tasks (plasticity). Task-agnostic problem in continual learning is a challenging problem, in which task identities are not available in the inference stage and hence the model must learn to distinguish all the classes in all the tasks. In task-agnostic problem, the model needs to learn two new objectives for learning a new task, including distinguishing new classes from old classes and distinguishing between different new classes. For task-agnostic problem, replay-based methods are commonly used. These methods update the model with both saved old samples and new samples for continual learning. Most existing replay-based methods mix the two objectives in task-agnostic problem together, inhibiting the models from achieving a good trade-off between stability and plasticity. In this paper, we propose a simple yet effective method, called loss decoupling (LODE), for task-agnostic continual learning. LODE separates the two objectives for the new task by decoupling the loss of the new task. As a result, LODE can assign different weights for different objectives, which provides a way to obtain a better trade-off between stability and plasticity than those methods with coupled loss. Experiments show that LODE can outperform existing state-of-the-art replay-based methods on multiple continual learning datasets",
    "checked": false,
    "id": "73156e5126afa180fdfd26d7d51f04cd8a34c500",
    "semantic_title": "tame: task agnostic continual learning using multiple experts",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0eXniewIvr": {
    "title": "Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing",
    "volume": "poster",
    "abstract": "Data over non-Euclidean manifolds, often discretized as surface meshes, naturally arise in computer graphics and biological and physical systems. In particular, solutions to partial differential equations (PDEs) over manifolds depend critically on the underlying geometry. While graph neural networks have been successfully applied to PDEs, they do not incorporate surface geometry and do not consider local gauge symmetries of the manifold. Alternatively, recent works on gauge equivariant convolutional and attentional architectures on meshes leverage the underlying geometry but underperform in modeling surface PDEs with complex nonlinear dynamics. To address these issues, we introduce a new gauge equivariant architecture using nonlinear message passing. Our novel architecture achieves higher performance than either convolutional or attentional networks on domains with highly complex and nonlinear dynamics. However, similar to the non-mesh case, design trade-offs favor convolutional, attentional, or message passing networks for different tasks; we investigate in which circumstances our message passing method provides the most benefit",
    "checked": true,
    "id": "7b0e8c49ea09f3caa9c4c168424c8f100b014116",
    "semantic_title": "modeling dynamics over meshes with gauge equivariant nonlinear message passing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=54hYifmQZU": {
    "title": "Quantifying the Cost of Learning in Queueing Systems",
    "volume": "poster",
    "abstract": "Queueing systems are widely applicable stochastic models with use cases in communication networks, healthcare, service systems, etc. Although their optimal control has been extensively studied, most existing approaches assume perfect knowledge of the system parameters. Of course, this assumption rarely holds in practice where there is parameter uncertainty, thus motivating a recent line of work on bandit learning for queueing systems. This nascent stream of research focuses on the asymptotic performance of the proposed algorithms. In this paper, we argue that an asymptotic metric, which focuses on late-stage performance, is insufficient to capture the intrinsic statistical complexity of learning in queueing systems which typically occurs in the early stage. Instead, we propose the *Cost of Learning in Queueing (CLQ)*, a new metric that quantifies the maximum increase in time-averaged queue length caused by parameter uncertainty. We characterize the CLQ of a single-queue multi-server system, and then extend these results to multi-queue multi-server systems and networks of queues. In establishing our results, we propose a unified analysis framework for CLQ that bridges Lyapunov and bandit analysis, provides guarantees for a wide range of algorithms, and could be of independent interest",
    "checked": true,
    "id": "34986b23a6f96992231c5a0a8545ffce1c68d685",
    "semantic_title": "quantifying the cost of learning in queueing systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=clKbFMt29V": {
    "title": "Self-Supervised Visual Acoustic Matching",
    "volume": "poster",
    "abstract": "Acoustic matching aims to re-synthesize an audio clip to sound as if it were recorded in a target acoustic environment. Existing methods assume access to paired training data, where the audio is observed in both source and target environments, but this limits the diversity of training data or requires the use of simulated data or heuristics to create paired samples. We propose a self-supervised approach to visual acoustic matching where training samples include only the target scene image and audio---without acoustically mismatched source audio for reference. Our approach jointly learns to disentangle room acoustics and re-synthesize audio into the target environment, via a conditional GAN framework and a novel metric that quantifies the level of residual acoustic information in the de-biased audio. Training with either in-the-wild web data or simulated data, we demonstrate it outperforms the state-of-the-art on multiple challenging datasets and a wide variety of real-world audio and environments",
    "checked": true,
    "id": "cc55253297f340c316485b9575d3632302ec8b39",
    "semantic_title": "self-supervised visual acoustic matching",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e7MK5Vq44Q": {
    "title": "DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets",
    "volume": "poster",
    "abstract": "One of the grand challenges of cell biology is inferring the gene regulatory network (GRN) which describes interactions between genes and their products that control gene expression and cellular function. We can treat this as a causal discovery problem but with two non-standard challenges: (1) regulatory networks are inherently cyclic so we should not model a GRN as a directed acyclic graph (DAG), and (2) observations have significant measurement noise so for typical sample sizes, there will always be a large equivalence class of graphs that are likely given the data, and we want methods that capture this uncertainty. Existing methods either focus on challenge (1), identifying cyclic structure from dynamics, or on challenge (2) learning complex Bayesian posteriors over directed acyclic graphs, but not both. In this paper we leverage the fact that it is possible to estimate the ``velocity'' of the expression of a gene with RNA velocity techniques to develop an approach that addresses both challenges. Because we have access to velocity information, we can treat the Bayesian structure learning problem as a problem of sparse identification of a dynamical system, capturing cyclic feedback loops through time. We leverage Generative Flow Networks (GFlowNets) to estimate the posterior distribution over the combinatorial space of possible sparse dependencies. Our results indicate that our method learns posteriors that better encapsulate the distributions of cyclic structures compared to counterpart state-of-the-art Bayesian structure learning approaches",
    "checked": true,
    "id": "aaf644310c370a4f27cbc318ce0fa9d5f76c3833",
    "semantic_title": "dyngfn: towards bayesian inference of gene regulatory networks with gflownets",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=nMB41QjLDY": {
    "title": "Provably Efficient Algorithm for Nonstationary Low-Rank MDPs",
    "volume": "poster",
    "abstract": "Reinforcement learning (RL) under changing environment models many real-world applications via nonstationary Markov Decision Processes (MDPs), and hence gains considerable interest. However, theoretical studies on nonstationary MDPs in the literature have mainly focused on tabular and linear (mixture) MDPs, which do not capture the nature of unknown representation in deep RL. In this paper, we make the first effort to investigate nonstationary RL under episodic low-rank MDPs, where both transition kernels and rewards may vary over time, and the low-rank model contains unknown representation in addition to the linear state embedding function. We first propose a parameter-dependent policy optimization algorithm called PORTAL, and further improve PORTAL to its parameter-free version of Ada-PORTAL, which is able to tune its hyper-parameters adaptively without any prior knowledge of nonstationarity. For both algorithms, we provide upper bounds on the average dynamic suboptimality gap, which show that as long as the nonstationarity is not significantly large, PORTAL and Ada-PORTAL are sample-efficient and can achieve arbitrarily small average dynamic suboptimality gap with polynomial sample complexity",
    "checked": true,
    "id": "6c58a3bfa9b7f882a166cd2ab246285a4e8c6823",
    "semantic_title": "provably efficient algorithm for nonstationary low-rank mdps",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eWKqr1zcRv": {
    "title": "Practical and Asymptotically Exact Conditional Sampling in Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion models have been successful on a range of conditional generation tasks including molecular design and text-to-image generation. However, these achievements have primarily depended on task-specific conditional training or error-prone heuristic approximations. Ideally, a conditional generation method should provide exact samples for a broad range of conditional distributions without requiring taskspecific training. To this end, we introduce the Twisted Diffusion Sampler, or TDS. TDS is a sequential Monte Carlo (SMC) algorithm that targets the conditional distributions of diffusion models. The main idea is to use twisting, an SMC technique that enjoys good computational efficiency, to incorporate heuristic approximations without compromising asymptotic exactness. We first find in simulation and in conditional image generation tasks that TDS provides a computational statistical trade-off, yielding more accurate approximations with many particles but with empirical improvements over heuristics with as few as two particles. We then turn to motif-scaffolding, a core task in protein design, using a TDS extension to Riemannian diffusion models; on benchmark test cases, TDS allows flexible conditioning criteria and often outperforms the state-of-the-art, conditionally trained model",
    "checked": true,
    "id": "79531b47bb27cb18022891eb2ab1fcb41745fca6",
    "semantic_title": "practical and asymptotically exact conditional sampling in diffusion models",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Q25wMXsaeZ": {
    "title": "OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling",
    "volume": "poster",
    "abstract": "Online updating of time series forecasting models aims to address the concept drifting problem by efficiently updating forecasting models based on streaming data. Many algorithms are designed for online time series forecasting, with some exploiting cross-variable dependency while others assume independence among variables. Given every data assumption has its own pros and cons in online time series modeling, we propose **On**line **e**nsembling **Net**work (**OneNet**). It dynamically updates and combines two models, with one focusing on modeling the dependency across the time dimension and the other on cross-variate dependency. Our method incorporates a reinforcement learning-based approach into the traditional online convex programming framework, allowing for the linear combination of the two models with dynamically adjusted weights. OneNet addresses the main shortcoming of classical online learning methods that tend to be slow in adapting to the concept drift. Empirical results show that OneNet reduces online forecasting error by more than $\\mathbf{50}\\\\%$ compared to the State-Of-The-Art (SOTA) method",
    "checked": true,
    "id": "ff84ee4199dd8413601a0b5cc170547266abc522",
    "semantic_title": "onenet: enhancing time series forecasting models under concept drift by online ensembling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C6IIwFHWkF": {
    "title": "Dynamic Sparsity Is Channel-Level Sparsity Learner",
    "volume": "poster",
    "abstract": "Sparse training has received an upsurging interest in machine learning due to its tantalizing saving potential for both the entire training process as well as the inference. Dynamic sparse training (DST) as a leading approach can train deep neural networks at high sparsity from scratch to match the performance of their dense counterparts. However, most if not all DST prior arts demonstrate their effectiveness on unstructured sparsity with highly irregular sparse patterns, which receives limited support in common hardware. This limitation hinders the usage of DST in practice. In this paper, we propose Channel-aware dynamic sparse (Chase), that for the first time seamlessly translates the promise of unstructured dynamic sparsity to GPU-friendly channel-level sparsity (not fine-grained N:M or group sparsity) during one end-to-end training process, without any ad-hoc operations. The resulting small sparse networks can be directly accelerated by commodity hardware, without using any particularly sparsity-aware hardware accelerators. This appealing outcome is partially motivated by a hidden phenomenon of dynamic sparsity: off-the-shelf unstructured DST implicitly involves biased parameter reallocation across channels, with a large fraction of channels (up to 60%) being sparser than others. By progressively identifying and removing these channels during training, our approach transfers unstructured sparsity to channel-wise sparsity. Our experimental results demonstrate that Chase achieves 1.7x inference throughput speedup on common GPU devices without compromising accuracy with ResNet-50 on ImageNet. We release our code in https://github.com/luuyin/chase",
    "checked": true,
    "id": "8f4358ee06b8ecbff57b0c2f08bf801f0836b6e2",
    "semantic_title": "dynamic sparsity is channel-level sparsity learner",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hgLMht2Z3L": {
    "title": "Path following algorithms for $\\ell_2$-regularized $M$-estimation with approximation guarantee",
    "volume": "poster",
    "abstract": "Many modern machine learning algorithms are formulated as regularized M-estimation problems, in which a regularization (tuning) parameter controls a trade-off between model fit to the training data and model complexity. To select the ``best'' tuning parameter value that achieves a good trade-off, an approximated solution path needs to be computed. In practice, this is often done through selecting a grid of tuning parameter values and solving the regularized problem at the selected grid points. However, given any desired level of accuracy, it is often not clear how to choose the grid points and also how accurately one should solve the regularized problems at the selected gird points, both of which can greatly impact the overall amount of computation. In the context of $\\ell_2$-regularized $M$-estimation problem, we propose a novel grid point selection scheme and an adaptive stopping criterion for any given optimization algorithm that produces an approximated solution path with approximation error guarantee. Theoretically, we prove that the proposed solution path can approximate the exact solution path to arbitrary level of accuracy, while saving the overall computation as much as possible. Numerical results also corroborate with our theoretical analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yoAmURKDJi": {
    "title": "TOA: Task-oriented Active VQA",
    "volume": "poster",
    "abstract": "Knowledge-based visual question answering (VQA) requires external knowledge to answer the question about an image. Early methods explicitly retrieve knowledge from external knowledge bases, which often introduce noisy information. Recently large language models like GPT-3 have shown encouraging performance as implicit knowledge source and revealed planning abilities. However, current large language models can not effectively understand image inputs, thus it remains an open problem to extract the image information and input to large language models. Prior works have used image captioning and object descriptions to represent the image. However, they may either drop the essential visual information to answer the question correctly or involve irrelevant objects to the task-of-interest. To address this problem, we propose to let large language models make an initial hypothesis according to their knowledge, then actively collect the visual evidence required to verify the hypothesis. In this way, the model can attend to the essential visual information in a task-oriented manner. We leverage several vision modules from the perspectives of spatial attention (i.e., Where to look) and attribute attention (i.e., What to look), which is similar to human cognition. The experiments show that our proposed method outperforms the baselines on open-ended knowledge-based VQA datasets and presents clear reasoning procedure with better interpretability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dK0Ew3kkVf": {
    "title": "Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation",
    "volume": "poster",
    "abstract": "Pretraining CNN models (i.e., UNet) through self-supervision has become a powerful approach to facilitate medical image segmentation under low annotation regimes. Recent contrastive learning methods encourage similar global representations when the same image undergoes different transformations, or enforce invariance across different image/patch features that are intrinsically correlated. However, CNN-extracted global and local features are limited in capturing long-range spatial dependencies that are essential in biological anatomy. To this end, we present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention. In particular, we augment the CNN feature map at multiple scales by incorporating an additional input that learns long-range spatial self-attention among localized keypoint features. Further, we introduce both global and local self-supervised pretraining for the framework. At the global scale, we obtain global representations from both the bottleneck of the UNet, and by aggregating multiscale keypoint features. These global features are subsequently regularized through image-level contrastive objectives. At the local scale, we define a distance-based criterion to first establish correspondences among keypoints and encourage similarity between their features. Through extensive experiments on both MRI and CT segmentation tasks, we demonstrate the architectural advantages of our proposed method in comparison to both CNN and Transformer-based UNets, when all architectures are trained with randomly initialized weights. With our proposed pretraining strategy, our method further outperforms existing SSL methods by producing more robust self-attention and achieving state-of-the-art segmentation results. The code is available at https://github.com/zshyang/kaf.git",
    "checked": true,
    "id": "2e132b4d0e642a59329a0268170453f358d036fd",
    "semantic_title": "keypoint-augmented self-supervised learning for medical image segmentation with limited annotation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hLPJ7xLbNF": {
    "title": "Self-Supervised Motion Magnification by Backpropagating Through Optical Flow",
    "volume": "poster",
    "abstract": "This paper presents a simple, self-supervised method for magnifying subtle motions in video: given an input video and a magnification factor, we manipulate the video such that its new optical flow is scaled by the desired amount. To train our model, we propose a loss function that estimates the optical flow of the generated video and penalizes how far if deviates from the given magnification factor. Thus, training involves differentiating through a pretrained optical flow network. Since our model is self-supervised, we can further improve its performance through test-time adaptation, by finetuning it on the input video. It can also be easily extended to magnify the motions of only user-selected objects. Our approach avoids the need for synthetic magnification datasets that have been used to train prior learning-based approaches. Instead, it leverages the existing capabilities of off-the-shelf motion estimators. We demonstrate the effectiveness of our method through evaluations of both visual quality and quantitative metrics on a range of real-world and synthetic videos, and we show our method works for both supervised and unsupervised optical flow methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EEtJTfvNZx": {
    "title": "Harnessing the power of choices in decision tree learning",
    "volume": "poster",
    "abstract": "We propose a simple generalization of standard and empirically successful decision tree learning algorithms such as ID3, C4.5, and CART. These algorithms, which have been central to machine learning for decades, are greedy in nature: they grow a decision tree by iteratively splitting on the best attribute. Our algorithm, Top-$k$, considers the $k$ best attributes as possible splits instead of just the single best attribute. We demonstrate, theoretically and empirically, the power of this simple generalization. We first prove a greediness hierarchy theorem showing that for every $k\\in \\mathbb{N}$, Top-$(k+1)$ can be dramatically more powerful than Top-$k$: there are data distributions for which the former achieves accuracy $1-\\epsilon$, whereas the latter only achieves accuracy $\\frac{1}{2}+\\epsilon$. We then show, through extensive experiments, that Top-$k$ outperforms the two main approaches to decision tree learning: classic greedy algorithms and more recent ``optimal decision tree'' algorithms. On one hand, Top-$k$ consistently enjoys significant accuracy gains over greedy algorithms across a wide range of benchmarks. On the other hand, Top-$k$ is markedly more scalable than optimal decision tree algorithms and is able to handle dataset and feature set sizes that remain far beyond the reach of these algorithms. The code to reproduce our results is available at https://github.com/SullivanC19/pydl8.5-topk",
    "checked": true,
    "id": "6e916a4a2e5665a5d37c016b3d755b2b58285f82",
    "semantic_title": "harnessing the power of choices in decision tree learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CzAAbKOHQW": {
    "title": "Exploring and Interacting with the Set of Good Sparse Generalized Additive Models",
    "volume": "poster",
    "abstract": "In real applications, interaction between machine learning models and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present algorithms to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity, direct editing); and (3) investigating sudden changes in the shape functions. Experiments demonstrate the fidelity of the approximated Rashomon set and its effectiveness in solving practical challenges",
    "checked": true,
    "id": "51a000239cda4aece95d79927f67943d819d42cd",
    "semantic_title": "exploring and interacting with the set of good sparse generalized additive models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=q9WMXjUxxT": {
    "title": "Trust Region-Based Safe Distributional Reinforcement Learning for Multiple Constraints",
    "volume": "poster",
    "abstract": "In safety-critical robotic tasks, potential failures must be reduced, and multiple constraints must be met, such as avoiding collisions, limiting energy consumption, and maintaining balance. Thus, applying safe reinforcement learning (RL) in such robotic tasks requires to handle multiple constraints and use risk-averse constraints rather than risk-neutral constraints. To this end, we propose a trust region-based safe RL algorithm for multiple constraints called a safe distributional actor-critic (SDAC). Our main contributions are as follows: 1) introducing a gradient integration method to manage infeasibility issues in multi-constrained problems, ensuring theoretical convergence, and 2) developing a TD($\\lambda$) target distribution to estimate risk-averse constraints with low biases. We evaluate SDAC through extensive experiments involving multi- and single-constrained robotic tasks. While maintaining high scores, SDAC shows 1.93 times fewer steps to satisfy all constraints in multi-constrained tasks and 1.78 times fewer constraint violations in single-constrained tasks compared to safe RL baselines. Code is available at: https://github.com/rllab-snu/Safe-Distributional-Actor-Critic",
    "checked": false,
    "id": "2029600e6c6a6535a48ab84ee0adc33f1234cd83",
    "semantic_title": "efficient trust region-based safe reinforcement learning with low-bias distributional actor-critic",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=afKnrwJBAl": {
    "title": "Cross-Episodic Curriculum for Transformer Agents",
    "volume": "poster",
    "abstract": "We present a new algorithm, Cross-Episodic Curriculum (CEC), to boost the learning efficiency and generalization of Transformer agents. Central to CEC is the placement of cross-episodic experiences into a Transformer's context, which forms the basis of a curriculum. By sequentially structuring online learning trials and mixed-quality demonstrations, CEC constructs curricula that encapsulate learning progression and proficiency increase across episodes. Such synergy combined with the potent pattern recognition capabilities of Transformer models delivers a powerful cross-episodic attention mechanism. The effectiveness of CEC is demonstrated under two representative scenarios: one involving multi-task reinforcement learning with discrete control, such as in DeepMind Lab, where the curriculum captures the learning progression in both individual and progressively complex settings; and the other involving imitation learning with mixed-quality data for continuous control, as seen in RoboMimic, where the curriculum captures the improvement in demonstrators' expertise. In all instances, policies resulting from CEC exhibit superior performance and strong generalization. Code is open-sourced on the project website https://cec-agent.github.io/ to facilitate research on Transformer agent learning",
    "checked": true,
    "id": "a8282d1378cf872817d3291f5e7edb6fbdf0121a",
    "semantic_title": "cross-episodic curriculum for transformer agents",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lM1UnEssuX": {
    "title": "Hypothesis Selection with Memory Constraints",
    "volume": "poster",
    "abstract": "Hypothesis selection is a fundamental problem in learning theory and statistics. Given a dataset and a finite set of candidate distributions, the goal is to select a distribution that matches the data as well as possible. More specifically, suppose we have sample access to an unknown distribution $P$ over a domain $\\mathcal{X}$ that we know is well-approximated by one of a a class of $n$ distributions (a.k.a. hypotheses), $\\mathcal{H} \\coloneqq \\{H_1, H_2, \\ldots, H_n\\}$. The goal is to design an algorithm that outputs a distribution $\\hat{H} \\in \\mathcal{H}$ whose total variation distance from $P$ is nearly minimal. In this work, we study the hypothesis selection problem under memory constraints. We consider a model where samples from $P$ are presented in a stream and we access each sample $x$ via ``PDF-comparison'' queries that allow us to compare the probability densities of any pair of hypotheses at the domain point $x$ (i.e., is $H_i(x) < H_j(x)$?). This model allows us to study how much memory is needed at any point in time to store information about the portion of the stream seen so far. Our main result is an algorithm that achieves a nearly optimal tradeoff between memory usage and the number of samples required. In particular, given $b$ bits of memory (for $b$ roughly between $\\log n$ and $n$), our algorithm solves the hypothesis selection problem with $s$ samples, where $b \\cdot s = O(n \\log n)$. This result is optimal up to an $O(\\log n)$ factor, for all $b$",
    "checked": true,
    "id": "8b0d96121d64652901aa123566141c4a7d0ef245",
    "semantic_title": "hypothesis selection with memory constraints",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zPYeYv6YYs": {
    "title": "Conformal PID Control for Time Series Prediction",
    "volume": "poster",
    "abstract": "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in official CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series)",
    "checked": true,
    "id": "0062fc95d78412b2c5b1b397fe1154abd3ef945c",
    "semantic_title": "conformal pid control for time series prediction",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=MbwVNEx9KS": {
    "title": "Energy Transformer",
    "volume": "poster",
    "abstract": "Our work combines aspects of three promising paradigms in machine learning, namely, attention mechanism, energy-based models, and associative memory. Attention is the power-house driving modern deep learning successes, but it lacks clear theoretical foundations. Energy-based models allow a principled approach to discriminative and generative tasks, but the design of the energy functional is not straightforward. At the same time, Dense Associative Memory models or Modern Hopfield Networks have a well-established theoretical foundation, and allow an intuitive design of the energy function. We propose a novel architecture, called the Energy Transformer (or ET for short), that uses a sequence of attention layers that are purposely designed to minimize a specifically engineered energy function, which is responsible for representing the relationships between the tokens. In this work, we introduce the theoretical foundations of ET, explore its empirical capabilities using the image completion task, and obtain strong quantitative results on the graph anomaly detection and graph classification tasks",
    "checked": true,
    "id": "09ec56d18667455fa86372c0645f331657bc3341",
    "semantic_title": "energy transformer",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=xGz0wAIJrS": {
    "title": "State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding",
    "volume": "poster",
    "abstract": "As more non-AI experts use complex AI systems for daily tasks, there has been an increasing effort to develop methods that produce explanations of AI decision making that are understandable by non-AI experts. Towards this effort, leveraging higher-level concepts and producing concept-based explanations have become a popular method. Most concept-based explanations have been developed for classification techniques, and we posit that the few existing methods for sequential decision making are limited in scope. In this work, we first contribute a desiderata for defining ``concepts'' in sequential decision making settings. Additionally, inspired by the Protege Effect which states explaining knowledge often reinforces one's self-learning, we explore how concept-based explanations of an RL agent's decision making can in turn improve the agent's learning rate, as well as improve end-user understanding of the agent's decision making. To this end, we contribute a unified framework, State2Explanation (S2E), that involves learning a joint embedding model between state-action pairs and concept-based explanations, and leveraging such learned model to both (1) inform reward shaping during an agent's training, and (2) provide explanations to end-users at deployment for improved task performance. Our experimental validations, in Connect 4 and Lunar Lander, demonstrate the success of S2E in providing a dual-benefit, successfully informing reward shaping and improving agent learning rate, as well as significantly improving end user task performance at deployment time",
    "checked": true,
    "id": "024087f125814fa70c6411fba9a4caff75878983",
    "semantic_title": "state2explanation: concept-based explanations to benefit agent learning and user understanding",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=HRGd5dcVfw": {
    "title": "Guiding The Last Layer in Federated Learning with Pre-Trained Models",
    "volume": "poster",
    "abstract": "Federated Learning (FL) is an emerging paradigm that allows a model to be trained across a number of participants without sharing data. Recent works have begun to consider the effects of using pre-trained models as an initialization point for existing FL algorithms; however, these approaches ignore the vast body of efficient transfer learning literature from the centralized learning setting. Here we revisit the problem of FL from a pre-trained model considered in prior work and expand it to a set of computer vision transfer learning problems. We first observe that simply fitting a linear classification head can be efficient in many cases. We then show that in the FL setting, fitting a classifier using the Nearest Class Means (NCM) can be done exactly and orders of magnitude more efficiently than existing proposals, while obtaining strong performance. Finally, we demonstrate that using a two-stage approach of obtaining the classifier and then fine-tuning the model can yield rapid convergence and improved generalization in the federated setting. We demonstrate the potential our method has to reduce communication and compute costs while achieving better model performance",
    "checked": true,
    "id": "1c836a5411e44f4eaaeb69d135546c4eb122662b",
    "semantic_title": "guiding the last layer in federated learning with pre-trained models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iFxWrxDekd": {
    "title": "Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks",
    "volume": "poster",
    "abstract": "In this work, we reveal a strong implicit bias of stochastic gradient descent (SGD) that drives overly expressive networks to much simpler subnetworks, thereby dramatically reducing the number of independent parameters, and improving generalization. To reveal this bias, we identify _invariant sets_, or subsets of parameter space that remain unmodified by SGD. We focus on two classes of invariant sets that correspond to simpler (sparse or low-rank) subnetworks and commonly appear in modern architectures. Our analysis uncovers that SGD exhibits a property of _stochastic attractivity_ towards these simpler invariant sets. We establish a sufficient condition for stochastic attractivity based on a competition between the loss landscape's curvature around the invariant set and the noise introduced by stochastic gradients. Remarkably, we find that an increased level of noise strengthens attractivity, leading to the emergence of attractive invariant sets associated with saddle-points or local maxima of the train loss. We observe empirically the existence of attractive invariant sets in trained deep neural networks, implying that SGD dynamics often collapses to simple subnetworks with either vanishing or redundant neurons. We further demonstrate how this simplifying process of _stochastic collapse_ benefits generalization in a linear teacher-student framework. Finally, through this analysis, we mechanistically explain why early training with large learning rates for extended periods benefits subsequent generalization",
    "checked": true,
    "id": "b488223a9422d43ed8c0e0da04c9c0592eb07829",
    "semantic_title": "stochastic collapse: how gradient noise attracts sgd dynamics towards simpler subnetworks",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=pNtG6NAmx0": {
    "title": "Statistical Knowledge Assessment for Large Language Models",
    "volume": "poster",
    "abstract": "Given varying prompts regarding a factoid question, can a large language model (LLM) reliably generate factually correct answers? Existing LLMs may generate distinct responses for different prompts. In this paper, we study the problem of quantifying knowledge contained in an LLM regarding a given set of facts. We propose KaRR, a statistical approach to assess factual knowledge for LLMs. The main idea is to estimate the ratio of LLM generating text corresponding to the answer entity given diverse prompts of the subject and the querying relation, versus it generating by random chances. Our assessment suite contains a comprehensive set of 994,123 entities and 600 relations, with 1,395,905 text aliases. We use our method to evaluate 20 LLMs of various sizes, including LLaMA, Alpaca, OPT, etc. Experiments show that our results have a strong correlation (0.43 Kendall's $\\tau$) with the results of human assessment on LLMs. Our results reveal that the knowledge in LLMs with the same backbone architecture adheres to the scaling law, while tuning on instruction-following data sometimes compromises the model's capability to generate factually correct text reliably",
    "checked": true,
    "id": "ce994a2e8ece97e3314383c634473da4f90fbdd9",
    "semantic_title": "statistical knowledge assessment for large language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8xx0pyMOW1": {
    "title": "Training neural operators to preserve invariant measures of chaotic attractors",
    "volume": "poster",
    "abstract": "Chaotic systems make long-horizon forecasts difficult because small perturbations in initial conditions cause trajectories to diverge at an exponential rate. In this setting, neural operators trained to minimize squared error losses, while capable of accurate short-term forecasts, often fail to reproduce statistical or structural properties of the dynamics over longer time horizons and can yield degenerate results. In this paper, we propose an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. Specifically, in the multi-environment setting (where each sample trajectory is governed by slightly different dynamics), we consider two novel approaches to training with noisy data. First, we propose a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs. This approach requires expert knowledge of the underlying physics to determine what statistical features should be included in the optimal transport loss. Second, we show that a contrastive learning framework, which does not require any specialized prior knowledge, can preserve statistical properties of the dynamics nearly as well as the optimal transport approach. On a variety of chaotic systems, our method is shown empirically to preserve invariant measures of chaotic attractors",
    "checked": true,
    "id": "d0fa04f18c35d4633e5baea53ad90ed7b25f2271",
    "semantic_title": "training neural operators to preserve invariant measures of chaotic attractors",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=3qHlPqzjM1": {
    "title": "Projection Regret: Reducing Background Bias for Novelty Detection via Diffusion Models",
    "volume": "poster",
    "abstract": "Novelty detection is a fundamental task of machine learning which aims to detect abnormal (*i.e.* out-of-distribution (OOD)) samples. Since diffusion models have recently emerged as the de facto standard generative framework with surprising generation results, novelty detection via diffusion models has also gained much attention. Recent methods have mainly utilized the reconstruction property of in-distribution samples. However, they often suffer from detecting OOD samples that share similar background information to the in-distribution data. Based on our observation that diffusion models can *project* any sample to an in-distribution sample with similar background information, we propose *Projection Regret (PR)*, an efficient novelty detection method that mitigates the bias of non-semantic information. To be specific, PR computes the perceptual distance between the test image and its diffusion-based projection to detect abnormality. Since the perceptual distance often fails to capture semantic changes when the background information is dominant, we cancel out the background bias by comparing it against recursive projections. Extensive experiments demonstrate that PR outperforms the prior art of generative-model-based novelty detection methods by a significant margin",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6gWpJ0IExE": {
    "title": "When is Agnostic Reinforcement Learning Statistically Tractable?",
    "volume": "poster",
    "abstract": "We study the problem of agnostic PAC reinforcement learning (RL): given a policy class $\\Pi$, how many rounds of interaction with an unknown MDP (with a potentially large state and action space) are required to learn an $\\epsilon$-suboptimal policy with respect to \\(\\Pi\\)? Towards that end, we introduce a new complexity measure, called the \\emph{spanning capacity}, that depends solely on the set \\(\\Pi\\) and is independent of the MDP dynamics. With a generative model, we show that the spanning capacity characterizes PAC learnability for every policy class $\\Pi$. However, for online RL, the situation is more subtle. We show there exists a policy class $\\Pi$ with a bounded spanning capacity that requires a superpolynomial number of samples to learn. This reveals a surprising separation for agnostic learnability between generative access and online access models (as well as between deterministic/stochastic MDPs under online access). On the positive side, we identify an additional \\emph{sunflower} structure which in conjunction with bounded spanning capacity enables statistically efficient online RL via a new algorithm called POPLER, which takes inspiration from classical importance sampling methods as well as recent developments for reachable-state identification and policy evaluation in reward-free exploration",
    "checked": true,
    "id": "c9808b9785e51e8ff84abdf2e4d5cdd2adfc3202",
    "semantic_title": "when is agnostic reinforcement learning statistically tractable?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ch1buUOGa3": {
    "title": "Expressive probabilistic sampling in recurrent neural networks",
    "volume": "poster",
    "abstract": "In sampling-based Bayesian models of brain function, neural activities are assumed to be samples from probability distributions that the brain uses for probabilistic computation. However, a comprehensive understanding of how mechanistic models of neural dynamics can sample from arbitrary distributions is still lacking. We use tools from functional analysis and stochastic differential equations to explore the minimum architectural requirements for $\\textit{recurrent}$ neural circuits to sample from complex distributions. We first consider the traditional sampling model consisting of a network of neurons whose outputs directly represent the samples ($\\textit{sampler-only}$ network). We argue that synaptic current and firing-rate dynamics in the traditional model have limited capacity to sample from a complex probability distribution. We show that the firing rate dynamics of a recurrent neural circuit with a separate set of output units can sample from an arbitrary probability distribution. We call such circuits $\\textit{reservoir-sampler networks}$ (RSNs). We propose an efficient training procedure based on denoising score matching that finds recurrent and output weights such that the RSN implements Langevin sampling. We empirically demonstrate our model's ability to sample from several complex data distributions using the proposed neural dynamics and discuss its applicability to developing the next generation of sampling-based Bayesian brain models",
    "checked": true,
    "id": "e5069d753493ed876767f127a197bf6e067bf9c6",
    "semantic_title": "expressive probabilistic sampling in recurrent neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0BwB03qA5T": {
    "title": "Gaussian Process Probes (GPP) for Uncertainty-Aware Probing",
    "volume": "poster",
    "abstract": "Understanding which concepts models can and cannot represent has been fundamental to many tasks: from effective and responsible use of models to detecting out of distribution data. We introduce Gaussian process probes (GPP), a unified and simple framework for probing and measuring uncertainty about concepts represented by models. As a Bayesian extension of linear probing methods, GPP asks what kind of distribution over classifiers (of concepts) is induced by the model. This distribution can be used to measure both what the model represents and how confident the probe is about what the model represents. GPP can be applied to any pre-trained model with vector representations of inputs (e.g., activations). It does not require access to training data, gradients, or the architecture. We validate GPP on datasets containing both synthetic and real images. Our experiments show it can (1) probe a model's representations of concepts even with a very small number of examples, (2) accurately measure both epistemic uncertainty (how confident the probe is) and aleatory uncertainty (how fuzzy the concepts are to the model), and (3) detect out of distribution data using those uncertainty measures as well as classic methods do. By using Gaussian processes to expand what probing can offer, GPP provides a data-efficient, versatile and uncertainty-aware tool for understanding and evaluating the capabilities of machine learning models",
    "checked": true,
    "id": "cd1302b188d687d27afee525b12ec1a0bf526dfc",
    "semantic_title": "gaussian process probes (gpp) for uncertainty-aware probing",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=26qqUHi9XF": {
    "title": "General Munchausen Reinforcement Learning with Tsallis Kullback-Leibler Divergence",
    "volume": "poster",
    "abstract": "Many policy optimization approaches in reinforcement learning incorporate a Kullback-Leilbler (KL) divergence to the previous policy, to prevent the policy from changing too quickly. This idea was initially proposed in a seminal paper on Conservative Policy Iteration, with approximations given by algorithms like TRPO and Munchausen Value Iteration (MVI). We continue this line of work by investigating a generalized KL divergence---called the Tsallis KL divergence. Tsallis KL defined by the $q$-logarithm is a strict generalization, as $q = 1$ corresponds to the standard KL divergence; $q > 1$ provides a range of new options. We characterize the types of policies learned under the Tsallis KL, and motivate when $q >1$ could be beneficial. To obtain a practical algorithm that incorporates Tsallis KL regularization, we extend MVI, which is one of the simplest approaches to incorporate KL regularization. We show that this generalized MVI($q$) obtains significant improvements over the standard MVI($q = 1$) across 35 Atari games",
    "checked": false,
    "id": "a90f49e41a97357fef8f5969972f7359b42cba99",
    "semantic_title": "q-munchausen reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sJDkwMVqb9": {
    "title": "Cross-links Matter for Link Prediction: Rethinking the Debiased GNN from a Data Perspective",
    "volume": "poster",
    "abstract": "Recently, the bias-related issues in GNN-based link prediction have raised widely spread concerns. In this paper, we emphasize the bias on links across different node clusters, which we call cross-links, after considering its significance in both easing information cocoons and preserving graph connectivity. Instead of following the objective-oriented mechanism in prior works with compromised utility, we empirically find that existing GNN models face severe data bias between internal-links (links within the same cluster) and cross-links, and this inspires us to rethink the bias issue on cross-links from a data perspective. Specifically, we design a simple yet effective twin-structure framework, which can be easily applied to most of GNNs to mitigate the bias as well as boost their utility in an end-to-end manner. The basic idea is to generate debiased node embeddings as demonstrations, and fuse them into the embeddings of original GNNs. In particular, we learn debiased node embeddings with the help of augmented supervision signals, and a novel dynamic training strategy is designed to effectively fuse debiased node embeddings with the original node embeddings. Experiments on three datasets with six common GNNs show that our framework can not only alleviate the bias between internal-links and cross-links, but also boost the overall accuracy. Comparisons with other state-of-the-art methods also verify the superiority of our method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aZ44Na3l9p": {
    "title": "Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests",
    "volume": "poster",
    "abstract": "Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a \"bag\" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to \"positive\" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and other works derived from these models will share the same issue. In any context in which these models are being used, this creates the potential for learning incorrect models, which creates risk of operational failure. We identify and demonstrate this problem via a proposed ``algorithmic unit test'', where we create synthetic datasets that can be solved by a MIL respecting model, and which clearly reveal learning that violates MIL assumptions. The five evaluated methods each fail one or more of these tests. This provides a model-agnostic way to identify violations of modeling assumptions, which we hope will be useful for future development and evaluation of MIL models",
    "checked": true,
    "id": "da61e19d9dad09345f30b242161952f938004467",
    "semantic_title": "reproducibility in multiple instance learning: a case for algorithmic unit tests",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8pOBo5NgTQ": {
    "title": "FLSL: Feature-level Self-supervised Learning",
    "volume": "poster",
    "abstract": "Current self-supervised learning (SSL) methods (e.g., SimCLR, DINO, VICReg, MOCOv3) target primarily on representations at instance level and do not generalize well to dense prediction tasks, such as object detection and segmentation. Towards aligning SSL with dense predictions, this paper demonstrates for the first time the underlying mean-shift clustering process of Vision Transformers (ViT), which aligns well with natural image semantics (e.g., a world of objects and stuffs). By employing transformer for joint embedding and clustering, we propose a bi-level feature clustering SSL method, coined Feature-Level Self-supervised Learning (FLSL). We present the formal definition of the FLSL problem and construct the objectives from the mean-shift and k-means perspectives. We show that FLSL promotes remarkable semantic cluster representations and learns an embedding scheme amenable to intra-view and inter-view feature clustering. Experiments show that FLSL yields significant improvements in dense prediction tasks, achieving 44.9 (+2.8)% AP and 46.5% AP in object detection, as well as 40.8 (+2.3)% AP and 42.1% AP in instance segmentation on MS-COCO, using Mask R-CNN with ViT-S/16 and ViT-S/8 as backbone, respectively. FLSL consistently outperforms existing SSL methods across additional benchmarks, including UAV object detection on UAVDT, and video instance segmentation on DAVIS 2017. We conclude by presenting visualization and various ablation studies to better understand the success of FLSL. The source code is available at https://github.com/ISL-CV/FLSL",
    "checked": true,
    "id": "df2117d3f35fe264bd68ea2f805023c888551b03",
    "semantic_title": "flsl: feature-level self-supervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qdsDy0zbn4": {
    "title": "ANTN: Bridging Autoregressive Neural Networks and Tensor Networks for Quantum Many-Body Simulation",
    "volume": "poster",
    "abstract": "Quantum many-body physics simulation has important impacts on understanding fundamental science and has applications to quantum materials design and quantum technology. However, due to the exponentially growing size of the Hilbert space with respect to the particle number, a direct simulation is intractable. While representing quantum states with tensor networks and neural networks are the two state-of-the-art methods for approximate simulations, each has its own limitations in terms of expressivity and inductive bias. To address these challenges, we develop a novel architecture, Autoregressive Neural TensorNet (ANTN), which bridges tensor networks and autoregressive neural networks. We show that Autoregressive Neural TensorNet parameterizes normalized wavefunctions, allows for exact sampling, generalizes the expressivity of tensor networks and autoregressive neural networks, and inherits a variety of symmetries from autoregressive neural networks. We demonstrate our approach on quantum state learning as well as finding the ground state of the challenging 2D $J_1$-$J_2$ Heisenberg model with different systems sizes and coupling parameters, outperforming both tensor networks and autoregressive neural networks. Our work opens up new opportunities for quantum many-body physics simulation, quantum technology design, and generative modeling in artificial intelligence",
    "checked": true,
    "id": "7ac57c5cd8b00f48226f3f2a018a1fa78ff48676",
    "semantic_title": "antn: bridging autoregressive neural networks and tensor networks for quantum many-body simulation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Nd3FennRJZ": {
    "title": "Reward-agnostic Fine-tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning",
    "volume": "poster",
    "abstract": "This paper studies tabular reinforcement learning (RL) in the hybrid setting, which assumes access to both an offline dataset and online interactions with the unknown environment. A central question boils down to how to efficiently utilize online data to strengthen and complement the offline dataset and enable effective policy fine-tuning. Leveraging recent advances in reward-agnostic exploration and offline RL, we design a three-stage hybrid RL algorithm that beats the best of both worlds --- pure offline RL and pure online RL --- in terms of sample complexities. The proposed algorithm does not require any reward information during data collection. Our theory is developed based on a new notion called **single-policy partial concentrability**, which captures the trade-off between distribution mismatch and miscoverage and guides the interplay between offline and online data",
    "checked": true,
    "id": "0f5e5d2e14279137c59cf7a23b3bfed8405bbcda",
    "semantic_title": "reward-agnostic fine-tuning: provable statistical benefits of hybrid reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8VTbfVfAfI": {
    "title": "The Grand Illusion: The Myth of Software Portability and Implications for ML Progress",
    "volume": "poster",
    "abstract": "Pushing the boundaries of machine learning often requires exploring different hardware and software combinations. However, this ability to experiment with different systems can be at odds with the drive for efficiency, which has produced increasingly specialized AI hardware and incentivized consolidation around a narrow set of ML frameworks. Exploratory research can be further restricted if software and hardware are co-evolving, making it even harder to stray away from a given tooling stack. While this friction increasingly impacts the rate of innovation in machine learning, to our knowledge the lack of portability in tooling has not been quantified. In this work we ask: How portable are popular ML software frameworks? We conduct a large scale study of the portability of mainstream ML frameworks across different hardware types. Our findings paint an uncomfortable picture -- frameworks can lose more than 40% of their key functions when ported to other hardware. Worse, even when functions are portable, the slowdown in their performance can be extreme. Collectively, our results reveal how costly straying from a narrow set of hardware-software combinations can be - and thus how specialization incurs an exploration cost that can impede innovation in machine learning research",
    "checked": true,
    "id": "87ed9604338cca1c075b8988b43864781b32a0d0",
    "semantic_title": "the grand illusion: the myth of software portability and implications for ml progress",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ktTSji9ZIs": {
    "title": "Multi-task learning with summary statistics",
    "volume": "poster",
    "abstract": "Multi-task learning has emerged as a powerful machine learning paradigm for integrating data from multiple sources, leveraging similarities between tasks to improve overall model performance. However, the application of multi-task learning to real-world settings is hindered by data-sharing constraints, especially in healthcare settings. To address this challenge, we propose a flexible multi-task learning framework utilizing summary statistics from various sources. Additionally, we present an adaptive parameter selection approach based on a variant of Lepski's method, allowing for data-driven tuning parameter selection when only summary statistics are accessible. Our systematic non-asymptotic analysis characterizes the performance of the proposed methods under various regimes of the source datasets' sample complexity and overlap. We demonstrate our theoretical findings and the performance of the method through extensive simulations. This work offers a more flexible tool for training related models across various domains, with practical implications in genetic risk prediction and many other fields",
    "checked": true,
    "id": "937b6334cebc2ee70f6c4403c85da51d75c8b661",
    "semantic_title": "multi-task learning with summary statistics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5t5u8PQa2T": {
    "title": "StreamNet: Memory-Efficient Streaming Tiny Deep Learning Inference on the Microcontroller",
    "volume": "poster",
    "abstract": "With the emerging Tiny Machine Learning (TinyML) inference applications, there is a growing interest when deploying TinyML models on the low-power Microcontroller Unit (MCU). However, deploying TinyML models on MCUs reveals several challenges due to the MCU's resource constraints, such as small flash memory, tight SRAM memory budget, and slow CPU performance. Unlike typical layer-wise inference, patch-based inference reduces the peak usage of SRAM memory on MCUs by saving small patches rather than the entire tensor in the SRAM memory. However, the processing of patch-based inference tremendously increases the amount of MACs against the layer-wise method. Thus, this notoriously computational overhead makes patch-based inference undesirable on MCUs. This work designs StreamNet that employs the stream buffer to eliminate the redundant computation of patch-based inference. StreamNet uses 1D and 2D streaming processing and provides an parameter selection algorithm that automatically improve the performance of patch-based inference with minimal requirements on the MCU's SRAM memory space. In 10 TinyML models, StreamNet-2D achieves a geometric mean of 7.3X speedup and saves 81\\% of MACs over the state-of-the-art patch-based inference",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FwmvbuDiMk": {
    "title": "Data Quality in Imitation Learning",
    "volume": "poster",
    "abstract": "In supervised learning, the question of data quality and curation has been sidelined in recent years in favor of increasingly more powerful and expressive models that can ingest internet-scale data. However, in offline learning for robotics, we simply lack internet scale data, and so high quality datasets are a necessity. This is especially true in imitation learning (IL), a sample efficient paradigm for robot learning using expert demonstrations. Policies learned through IL suffer from state distribution shift at test time due to compounding errors in action prediction, which leads to unseen states that the policy cannot recover from. Instead of designing new algorithms to address distribution shift, an alternative perspective is to develop new ways of assessing and curating datasets. There is growing evidence that the same IL algorithms can have substantially different performance across different datasets. This calls for a formalism for defining metrics of \"data quality\" that can further be leveraged for data curation. In this work, we take the first step toward formalizing data quality for imitation learning through the lens of distribution shift: a high quality dataset encourages the policy to stay in distribution at test time. We propose two fundamental properties that are necessary for a high quality datasets: i) action divergence: the mismatch between the expert and learned policy at certain states; and ii) transition diversity: the noise present in the system for a given state and action. We investigate the combined effect of these two key properties in imitation learning theoretically, and we empirically analyze models trained on a variety of different data sources. We show that state diversity is not always beneficial, and we demonstrate how action divergence and transition diversity interact in practice",
    "checked": true,
    "id": "a91b821a95ccd417e0f1315247732dd4bcf45991",
    "semantic_title": "data quality in imitation learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=XOCbdqxAR2": {
    "title": "TD Convergence: An Optimization Perspective",
    "volume": "poster",
    "abstract": "We study the convergence behavior of the celebrated temporal-difference (TD) learning algorithm. By looking at the algorithm through the lens of optimization, we first argue that TD can be viewed as an iterative optimization algorithm where the function to be minimized changes per iteration. By carefully investigating the divergence displayed by TD on a classical counter example, we identify two forces that determine the convergent or divergent behavior of the algorithm. We next formalize our discovery in the linear TD setting with quadratic loss and prove that convergence of TD hinges on the interplay between these two forces. We extend this optimization perspective to prove convergence of TD in a much broader setting than just linear approximation and squared loss. Our results provide a theoretical explanation for the successful application of TD in reinforcement learning",
    "checked": true,
    "id": "3b0f83879d421e693fb7c94f7980a99808bdc5eb",
    "semantic_title": "td convergence: an optimization perspective",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WwP2JaXAtB": {
    "title": "Probabilistic Invariant Learning with Randomized Linear Classifiers",
    "volume": "poster",
    "abstract": "Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle",
    "checked": true,
    "id": "9dd99962cc5d8565ed820a67440833101b8f1e2c",
    "semantic_title": "probabilistic invariant learning with randomized linear classifiers",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=tECyQO1QOp": {
    "title": "Doubly Constrained Fair Clustering",
    "volume": "poster",
    "abstract": "The remarkable attention which fair clustering has received in the last few years has resulted in a significant number of different notions of fairness. Despite the fact that these notions are well-justified, they are often motivated and studied in a disjoint manner where one fairness desideratum is considered exclusively in isolation from the others. This leaves the understanding of the relations between different fairness notions as an important open problem in fair clustering. In this paper, we take the first step in this direction. Specifically, we consider the two most prominent demographic representation fairness notions in clustering: (1) Group Fairness ($\\textbf{GF}$), where the different demographic groups are supposed to have close to population-level representation in each cluster and (2) Diversity in Center Selection ($\\textbf{DS}$), where the selected centers are supposed to have close to population-level representation of each group. We show that given a constant approximation algorithm for one constraint ($\\textbf{GF}$ or $\\textbf{DS}$ only) we can obtain a constant approximation solution that satisfies both constraints simultaneously. Interestingly, we prove that any given solution that satisfies the $\\textbf{GF}$ constraint can always be post-processed at a bounded degradation to the clustering cost to additionally satisfy the $\\textbf{DS}$ constraint while the same statement is not true given a solution that satisfies $\\textbf{DS}$ instead. Furthermore, we show that both $\\textbf{GF}$ and $\\textbf{DS}$ are incompatible (having an empty feasibility set in the worst case) with a collection of other distance-based fairness notions. Finally, we carry experiments to validate our theoretical findings",
    "checked": true,
    "id": "b5d521028a9e46af92db3d4ca21a6a0cde52b693",
    "semantic_title": "doubly constrained fair clustering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vzrA6uqOis": {
    "title": "GAUCHE: A Library for Gaussian Processes in Chemistry",
    "volume": "poster",
    "abstract": "We introduce GAUCHE, an open-source library for GAUssian processes in CHEmistry. Gaussian processes have long been a cornerstone of probabilistic machine learning, affording particular advantages for uncertainty quantification and Bayesian optimisation. Extending Gaussian processes to molecular representations, however, necessitates kernels defined over structured inputs such as graphs, strings and bit vectors. By providing such kernels in a modular, robust and easy-to-use framework, we seek to enable expert chemists and materials scientists to make use of state-of-the-art black-box optimization techniques. Motivated by scenarios frequently encountered in practice, we showcase applications for GAUCHE in molecular discovery, chemical reaction optimisation and protein design. The codebase is made available at https://github.com/leojklarner/gauche",
    "checked": true,
    "id": "0d6156d2c20355f60f688b53ef8813cf0114f733",
    "semantic_title": "gauche: a library for gaussian processes in chemistry",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=09bZyE9tfp": {
    "title": "Online Ad Procurement in Non-stationary Autobidding Worlds",
    "volume": "poster",
    "abstract": "Today's online advertisers procure digital ad impressions through interacting with autobidding platforms: advertisers convey high level procurement goals via setting levers such as budget, target return-on-investment, max cost per click, etc.. Then ads platforms subsequently procure impressions on advertisers' behalf, and report final procurement conversions (e.g. click) to advertisers. In practice, advertisers may receive minimal information on platforms' procurement details, and procurement outcomes are subject to non-stationary factors like seasonal patterns, occasional system corruptions, and market trends which make it difficult for advertisers to optimize lever decisions effectively. Motivated by this, we present an online learning framework that helps advertisers dynamically optimize ad platform lever decisions while subject to general long-term constraints in a realistic bandit feedback environment with non-stationary procurement outcomes. In particular, we introduce a primal-dual algorithm for online decision making with multi-dimension decision variables, bandit feedback and long-term uncertain constraints. We show that our algorithm achieves low regret in many worlds when procurement outcomes are generated through procedures that are stochastic, adversarial, adversarially corrupted, periodic, and ergodic, respectively, without having to know which procedure is the ground truth. Finally, we emphasize that our proposed algorithm and theoretical results extend beyond the applications of online advertising",
    "checked": true,
    "id": "ead7a8eb054c731a83ed16b457140e09f7df8dd6",
    "semantic_title": "online ad procurement in non-stationary autobidding worlds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SjiLtmZETc": {
    "title": "Bayesian Risk-Averse Q-Learning with Streaming Observations",
    "volume": "poster",
    "abstract": "We consider a robust reinforcement learning problem, where a learning agent learns from a simulated training environment. To account for the model mis-specification between this training environment and the true environment due to lack of data, we adopt a formulation of Bayesian risk MDP (BRMDP) with infinite horizon, which uses Bayesian posterior to estimate the transition model and impose a risk functional to account for the model uncertainty. Observations from the real environment that is out of the agent's control arrive periodically and are utilized by the agent to update the Bayesian posterior to reduce model uncertainty. We theoretically demonstrate that BRMDP balances the trade-off between robustness and conservativeness, and we further develop a multi-stage Bayesian risk-averse Q-learning algorithm to solve BRMDP with streaming observations from real environment. The proposed algorithm learns a risk-averse yet optimal policy that depends on the availability of real-world observations. We provide a theoretical guarantee of strong convergence for the proposed algorithm",
    "checked": true,
    "id": "b7874dbc796c5bbd5a807b3ca561088507d4cea8",
    "semantic_title": "bayesian risk-averse q-learning with streaming observations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XRTxIBs2eu": {
    "title": "Block-State Transformers",
    "volume": "poster",
    "abstract": "State space models (SSMs) have shown impressive results on tasks that require modeling long-range dependencies and efficiently scale to long sequences owing to their subquadratic runtime complexity. Originally designed for continuous signals, SSMs have shown superior performance on a plethora of tasks, in vision and audio; however, SSMs still lag Transformer performance in Language Modeling tasks. In this work, we propose a hybrid layer named Block-State Transformer (*BST*), that internally combines an SSM sublayer for long-range contextualization, and a Block Transformer sublayer for short-term representation of sequences. We study three different, and completely *parallelizable*, variants that integrate SSMs and block-wise attention. We show that our model outperforms similar Transformer-based architectures on language modeling perplexity and generalizes to longer sequences. In addition, the Block-State Transformer demonstrates a more than *tenfold* increase in speed at the layer level compared to the Block-Recurrent Transformer when model parallelization is employed",
    "checked": true,
    "id": "0a067fab18c67d4a386efa846c080f8afff5e8f3",
    "semantic_title": "block-state transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V5eG47pyVl": {
    "title": "Localized Symbolic Knowledge Distillation for Visual Commonsense Models",
    "volume": "poster",
    "abstract": "Instruction following vision-language (VL) models offer a flexible interface that supports a broad range of multimodal tasks in a zero-shot fashion. However, interfaces that operate on full images do not directly enable the user to \"point to\" and access specific regions within images. This capability is important not only to support reference-grounded VL benchmarks, but also, for practical applications that require precise within-image reasoning. We build Localized Visual Commonsense model which allows users to specify (multiple) regions- as-input. We train our model by sampling localized commonsense knowledge from a large language model (LLM): specifically, we prompt a LLM to collect commonsense knowledge given a global literal image description and a local literal region description automatically generated by a set of VL models. This pipeline is scalable and fully automatic, as no aligned or human-authored image and text pairs are required. With a separately trained critic model that selects high quality examples, we find that training on the localized commonsense corpus expanded solely from images can successfully distill existing VL models to support a reference-as-input interface. Empirical results and human evaluations in zero-shot settings demonstrate that our distillation method results in more precise VL models of reasoning compared to a baseline of passing a generated referring expression",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=waDF0oACu2": {
    "title": "Collaboratively Learning Linear Models with Structured Missing Data",
    "volume": "poster",
    "abstract": "We study the problem of collaboratively learning least squares estimates for $m$ agents. Each agent observes a different subset of the features---e.g., containing data collected from sensors of varying resolution. Our goal is to determine how to coordinate the agents in order to produce the best estimator for each agent. We propose a distributed, semi-supervised algorithm Collab, consisting of three steps: local training, aggregation, and distribution. Our procedure does not require communicating the labeled data, making it communication efficient and useful in settings where the labeled data is inaccessible. Despite this handicap, our procedure is nearly asymptotically, local-minimax optimal---even among estimators allowed to communicate the labeled data such as imputation methods. We test our method on US Census data. We also discuss generalizations of our method to non-Gaussian feature settings, non-linear settings, and Federated Learning",
    "checked": true,
    "id": "b664be3f59679bc5750283ccac7a25f78de84bb1",
    "semantic_title": "collaboratively learning linear models with structured missing data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GiUe0ZFiVe": {
    "title": "Bi-Level Offline Policy Optimization with Limited Exploration",
    "volume": "poster",
    "abstract": "We study offline reinforcement learning (RL) which seeks to learn a good policy based on a fixed, pre-collected dataset. A fundamental challenge behind this task is the distributional shift due to the dataset lacking sufficient exploration, especially under function approximation. To tackle this issue, we propose a bi-level structured policy optimization algorithm that models a hierarchical interaction between the policy (upper-level) and the value function (lower-level). The lower level focuses on constructing a confidence set of value estimates that maintain sufficiently small weighted average Bellman errors, while controlling uncertainty arising from distribution mismatch. Subsequently, at the upper level, the policy aims to maximize a conservative value estimate from the confidence set formed at the lower level. This novel formulation preserves the maximum flexibility of the implicitly induced exploratory data distribution, enabling the power of model extrapolation. In practice, it can be solved through a computationally efficient, penalized adversarial estimation procedure. Our theoretical regret guarantees do not rely on any data-coverage and completeness-type assumptions, only requiring realizability. These guarantees also demonstrate that the learned policy represents the ``best effort'' among all policies, as no other policies can outperform it. We evaluate our model using a blend of synthetic, benchmark, and real-world datasets for offline RL, showing that it performs competitively with state-of-the-art methods",
    "checked": true,
    "id": "89211bbf7616ba8a33e4004dfcbf8cd827f0c2b7",
    "semantic_title": "bi-level offline policy optimization with limited exploration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8F3Lutda7R": {
    "title": "Exploiting Connections between Lipschitz Structures for Certifiably Robust Deep Equilibrium Models",
    "volume": "poster",
    "abstract": "Recently, deep equilibrium models (DEQs) have drawn increasing attention from the machine learning community. However, DEQs are much less understood in terms of certified robustness than their explicit network counterparts. In this paper, we advance the understanding of certified robustness of DEQs via exploiting the connections between various Lipschitz network parameterizations for both explicit and implicit models. Importantly, we show that various popular Lipschitz network structures, including convex potential layers (CPL), SDP-based Lipschitz layers (SLL), almost orthogonal layers (AOL), Sandwich layers, and monotone DEQs (MonDEQ) can all be reparameterized as special cases of the Lipschitz-bounded equilibrium networks (LBEN) without changing the prescribed Lipschitz constant in the original network parameterization. A key feature of our reparameterization technique is that it preserves the Lipschitz prescription used in different structures. This opens the possibility of achieving improved certified robustness of DEQs via a combination of network reparameterization, structure-preserving regularization, and LBEN-based fine-tuning. We also support our theoretical understanding with new empirical results, which show that our proposed method improves the certified robust accuracy of DEQs on classification tasks. All codes and experiments are made available at \\url{https://github.com/AaronHavens/ExploitingLipschitzDEQ}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S8DFqgmEbe": {
    "title": "Learning Nonparametric Latent Causal Graphs with Unknown Interventions",
    "volume": "poster",
    "abstract": "We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in measurement models without parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts---_imaginary subsets_ and _isolated edges_---that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations within the equivalence class of DAGs induced by _unknown_ interventions. These are the first results to characterize the conditions under which causal representations are identifiable without making any parametric assumptions in a general setting with unknown interventions and without faithfulness",
    "checked": true,
    "id": "bf43b2167060739c7a0af93a631e79f1feed3e8d",
    "semantic_title": "learning nonparametric latent causal graphs with unknown interventions",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=eNhW9UnlGG": {
    "title": "Contextual Gaussian Process Bandits with Neural Networks",
    "volume": "poster",
    "abstract": "Contextual decision-making problems have witnessed extensive applications in various fields such as online content recommendation, personalized healthcare, and autonomous vehicles, where a core practical challenge is to select a suitable surrogate model for capturing unknown complicated reward functions. It is often the case that both high approximation accuracy and explicit uncertainty quantification are desired. In this work, we propose a neural network-accompanied Gaussian process (NN-AGP) model, which leverages neural networks to approximate the unknown and potentially complicated reward function regarding the contextual variable, and maintains a Gaussian process surrogate model with respect to the decision variable. Our model is shown to outperform existing approaches by offering better approximation accuracy thanks to the use of neural networks and possessing explicit uncertainty quantification from the Gaussian process. We also analyze the maximum information gain of the NN-AGP model and prove the regret bounds for the corresponding algorithms. Moreover, we conduct the experiments on both synthetic and practical problems, illustrating the effectiveness of our approach",
    "checked": false,
    "id": "9d04207832d24a5a0b675cbc4ce88c847dcfb8e2",
    "semantic_title": "contextual bandit guided data farming for deep neural networks in manufacturing industrial internet",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=58XMiu8kot": {
    "title": "Bayesian Metric Learning for Uncertainty Quantification in Image Retrieval",
    "volume": "poster",
    "abstract": "We propose a Bayesian encoder for metric learning. Rather than relying on neural amortization as done in prior works, we learn a distribution over the network weights with the Laplace Approximation. We first prove that the contrastive loss is a negative log-likelihood on the spherical space. We propose three methods that ensure a positive definite covariance matrix. Lastly, we present a novel decomposition of the Generalized Gauss-Newton approximation. Empirically, we show that our Laplacian Metric Learner (LAM) yields well-calibrated uncertainties, reliably detects out-of-distribution examples, and has state-of-the-art predictive performance",
    "checked": true,
    "id": "be3d114f8383c6c7d95bd059c9c1eebe17ce7472",
    "semantic_title": "bayesian metric learning for uncertainty quantification in image retrieval",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ubp5s2tgXq": {
    "title": "Uncovering Meanings of Embeddings via Partial Orthogonality",
    "volume": "poster",
    "abstract": "Machine learning tools often rely on embedding text as vectors of real numbers. In this paper, we study how the semantic structure of language is encoded in the algebraic structure of such embeddings. Specifically, we look at a notion of \"semantic independence\" capturing the idea that, e.g., \"eggplant\" and \"tomato\" are independent given \"vegetable\". Although such examples are intuitive, it is difficult to formalize such a notion of semantic independence. The key observation here is that any sensible formalization should obey a set of so-called independence axioms, and thus any algebraic encoding of this structure should also obey these axioms. This leads us naturally to use partial orthogonality as the relevant algebraic structure. We develop theory and methods that allow us to demonstrate that partial orthogonality does indeed capture semantic independence. Complementary to this, we also introduce the concept of independence preserving embeddings where embeddings preserve the conditional independence structures of a distribution, and we prove the existence of such embeddings and approximations to them",
    "checked": true,
    "id": "6f2297349ee671c7431cb32a83b3f278f4fc84f0",
    "semantic_title": "uncovering meanings of embeddings via partial orthogonality",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=szFqlNRxeS": {
    "title": "Riemannian Projection-free Online Learning",
    "volume": "poster",
    "abstract": "The projection operation is a critical component in a wide range of optimization algorithms, such as online gradient descent (OGD), for enforcing constraints and achieving optimal regret bounds. However, it suffers from computational complexity limitations in high-dimensional settings or when dealing with ill-conditioned constraint sets. Projection-free algorithms address this issue by replacing the projection oracle with more efficient optimization subroutines. But to date, these methods have been developed primarily in the Euclidean setting, and while there has been growing interest in optimization on Riemannian manifolds, there has been essentially no work in trying to utilize projection-free tools here. An apparent issue is that non-trivial affine functions are generally non-convex in such domains. In this paper, we present methods for obtaining sub-linear regret guarantees in online geodesically convex optimization on curved spaces for two scenarios: when we have access to (a) a separation oracle or (b) a linear optimization oracle. For geodesically convex losses, and when a separation oracle is available, our algorithms achieve $O(T^{\\frac{1}{2}})$, $O(T^{\\frac{3}{4}})$ and $O(T^{\\frac{1}{2}})$ adaptive regret guarantees in the full information setting, the bandit setting with one-point feedback and the bandit setting with two-point feedback, respectively. When a linear optimization oracle is available, we obtain regret rates of $O(T^{\\frac{3}{4}})$ for geodesically convex losses and $O(T^{\\frac{2}{3}}\\log T)$ for strongly geodesically convex losses",
    "checked": false,
    "id": "b3aff0937f221654b0f3f3ad0631bc52fe506e31",
    "semantic_title": "on riemannian projection-free online learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E2TJI6CKm0": {
    "title": "VeriX: Towards Verified Explainability of Deep Neural Networks",
    "volume": "poster",
    "abstract": "We present **VeriX** (**Veri**fied e**X**plainability), a system for producing *optimal robust explanations* and generating *counterfactuals* along decision boundaries of machine learning models. We build such explanations and counterfactuals iteratively using constraint solving techniques and a heuristic based on feature-level sensitivity ranking. We evaluate our method on image recognition benchmarks and a real-world scenario of autonomous aircraft taxiing",
    "checked": true,
    "id": "66ec306659b3c721952d255e2b721613a1764ef7",
    "semantic_title": "verix: towards verified explainability of deep neural networks",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=uzOBDerK1j": {
    "title": "Online robust non-stationary estimation",
    "volume": "poster",
    "abstract": "The real-time estimation of time-varying parameters from high-dimensional, heavy-tailed and corrupted data-streams is a common sub-routine in systems ranging from those for network monitoring and anomaly detection to those for traffic scheduling in data-centers. For estimation tasks that can be cast as minimizing a strongly convex loss function, we prove that an appropriately tuned version of the {\\ttfamily clipped Stochastic Gradient Descent} (SGD) is simultaneously {\\em(i)} adaptive to drift, {\\em (ii)} robust to heavy-tailed inliers and arbitrary corruptions, {\\em(iii)} requires no distributional knowledge and {\\em (iv)} can be implemented in an online streaming fashion. All prior estimation algorithms have only been proven to posses a subset of these practical desiderata. A observation we make is that, neither the $\\mathcal{O}\\left(\\frac{1}{t}\\right)$ learning rate for {\\ttfamily clipped SGD} known to be optimal for strongly convex loss functions of a \\emph{stationary} data-stream, nor the $\\mathcal{O}(1)$ learning rate known to be optimal for being adaptive to drift in a \\emph{noiseless} environment can be used. Instead, a learning rate of $T^{-\\alpha}$ for $ \\alpha < 1$ where $T$ is the stream-length is needed to balance adaptivity to potential drift and to combat noise. We develop a new inductive argument and combine it with a martingale concentration result to derive high-probability under \\emph{any learning rate} on data-streams exhibiting \\emph{arbitrary distribution shift} - a proof strategy that may be of independent interest. Further, using the classical doubling-trick, we relax the knowledge of the stream length $T$. Ours is the first online estimation algorithm that is provably robust to heavy-tails, corruptions and distribution shift simultaneously. We complement our theoretical results empirically on synthetic and real data",
    "checked": false,
    "id": "99e0f5e54794a111be1a339a437c9cd6cd90d548",
    "semantic_title": "outlier-robust sparse estimation via non-convex optimization",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=2W4LxJbgec": {
    "title": "Scaling laws for language encoding models in fMRI",
    "volume": "poster",
    "abstract": "Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language. However, most studies comparing language models to brains have used GPT-2 or similarly sized language models. Here we tested whether larger open-source models such as those from the OPT and LLaMA families are better at predicting brain responses recorded using fMRI. Mirroring scaling results from other contexts, we found that brain prediction performance scales logarithmically with model size from 125M to 30B parameter models, with ~15% increased encoding performance as measured by correlation with a held-out test set across 3 subjects. Similar log-linear behavior was observed when scaling the size of the fMRI training set. We also characterized scaling for acoustic encoding models that use HuBERT, WavLM, and Whisper, and we found comparable improvements with model size. A noise ceiling analysis of these large, high-performance encoding models showed that performance is nearing the theoretical maximum for brain areas such as the precuneus and higher auditory cortex. These results suggest that increasing scale in both models and data will yield incredibly effective models of language processing in the brain, enabling better scientific understanding as well as applications such as decoding",
    "checked": true,
    "id": "8376e50e81329b3db5049a90851cc0418d071e3d",
    "semantic_title": "scaling laws for language encoding models in fmri",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=KBMOKmX2he": {
    "title": "LIMA: Less Is More for Alignment",
    "volume": "poster",
    "abstract": "Large language models are trained in two stages: (1) unsupervised pretraining from raw text, to learn general-purpose representations, and (2) large scale instruction tuning and reinforcement learning, to better align to end tasks and user preferences. We measure the relative importance of these two stages by training LIMA, a 65B parameter LLaMa language model fine-tuned with the standard supervised loss on only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling. LIMA demonstrates remarkably strong performance, learning to follow specific response formats from only a handful of examples in the training data, including complex queries that range from planning trip itineraries to speculating about alternate history. Moreover, the model tends to generalize well to unseen tasks that did not appear in the training data. In a controlled human study, responses from LIMA are either equivalent or strictly preferred to GPT-4 in 43\\% of cases; this statistic is as high as 58\\% when compared to Bard and 65\\% versus DaVinci003, which was trained with human feedback. Taken together, these results strongly suggest that almost all knowledge in large language models is learned during pretraining, and only limited instruction tuning data is necessary to teach models to produce high quality output",
    "checked": true,
    "id": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445",
    "semantic_title": "lima: less is more for alignment",
    "citation_count": 152,
    "authors": []
  },
  "https://openreview.net/forum?id=Fe8PxP2F2p": {
    "title": "Gradient-Based Feature Learning under Structured Data",
    "volume": "poster",
    "abstract": "Recent works have demonstrated that the sample complexity of gradient-based learning of single index models, i.e. functions that depend on a 1-dimensional projection of the input data, is governed by their information exponent. However, these results are only concerned with isotropic data, while in practice the input often contains additional structure which can implicitly guide the algorithm. In this work, we investigate the effect of a spiked covariance structure and reveal several interesting phenomena. First, we show that in the anisotropic setting, the commonly used spherical gradient dynamics may fail to recover the true direction, even when the spike is perfectly aligned with the target direction. Next, we show that appropriate weight normalization that is reminiscent of batch normalization can alleviate this issue. Further, by exploiting the alignment between the (spiked) input covariance and the target, we obtain improved sample complexity compared to the isotropic case. In particular, under the spiked model with a suitably large spike, the sample complexity of gradient-based training can be made independent of the information exponent while also outperforming lower bounds for rotationally invariant kernel methods",
    "checked": true,
    "id": "1a994d5deb2b3ca74e6900a2be04273f89b8c886",
    "semantic_title": "gradient-based feature learning under structured data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zn5ihqknGj": {
    "title": "An Alternating Optimization Method for Bilevel Problems under the Polyak-Łojasiewicz Condition",
    "volume": "poster",
    "abstract": "Bilevel optimization has recently regained interest owing to its applications in emerging machine learning fields such as hyperparameter optimization, meta-learning, and reinforcement learning. Recent results have shown that simple alternating (implicit) gradient-based algorithms can match the convergence rate of single-level gradient descent (GD) when addressing bilevel problems with a strongly convex lower-level objective. However, it remains unclear whether this result can be generalized to bilevel problems beyond this basic setting. In this paper, we first introduce a stationary metric for the considered bilevel problems, which generalizes the existing metric, for a nonconvex lower-level objective that satisfies the Polyak-Łojasiewicz (PL) condition. We then propose a Generalized ALternating mEthod for bilevel opTimization (GALET) tailored to BLO with convex PL LL problem and establish that GALET achieves an $\\epsilon$-stationary point for the considered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which matches the iteration complexity of GD for single-level smooth nonconvex problems",
    "checked": false,
    "id": "26fca75a8072c4f81a9510591079248d247ae085",
    "semantic_title": "a generalized alternating method for bilevel learning under the polyak-łojasiewicz condition",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=kXfrlWXLwH": {
    "title": "DESSERT: An Efficient Algorithm for Vector Set Search with Vector Set Queries",
    "volume": "poster",
    "abstract": "We study the problem of $\\text{\\emph{vector set search}}$ with $\\text{\\emph{vector set queries}}$. This task is analogous to traditional near-neighbor search, with the exception that both the query and each element in the collection are $\\text{\\textit{sets}}$ of vectors. We identify this problem as a core subroutine for semantic search applications and find that existing solutions are unacceptably slow. Towards this end, we present a new approximate search algorithm, DESSERT ($\\text{\\bf D}$ESSERT $\\text{\\bf E}$ffeciently $\\text{\\bf S}$earches $\\text{\\bf S}$ets of $\\text{\\bf E}$mbeddings via $\\text{\\bf R}$etrieval $\\text{\\bf T}$ables). DESSERT is a general tool with strong theoretical guarantees and excellent empirical performance. When we integrate DESSERT into ColBERT, a state-of-the-art semantic search model, we find a 2-5x speedup on the MS MARCO and LoTTE retrieval benchmarks with minimal loss in recall, underscoring the effectiveness and practical applicability of our proposal",
    "checked": true,
    "id": "58ff95eac4b28d6c4852b18e2431d0a7d3ffae78",
    "semantic_title": "dessert: an efficient algorithm for vector set search with vector set queries",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9qlJGjO7bA": {
    "title": "Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "Due to the broad range of applications of multi-agent reinforcement learning (MARL), understanding the effects of adversarial attacks against MARL model is essential for the safe applications of this model. Motivated by this, we investigate the impact of adversarial attacks on MARL. In the considered setup, there is an exogenous attacker who is able to modify the rewards before the agents receive them or manipulate the actions before the environment receives them. The attacker aims to guide each agent into a target policy or maximize the cumulative rewards under some specific reward function chosen by the attacker, while minimizing the amount of the manipulation on feedback and action. We first show the limitations of the action poisoning only attacks and the reward poisoning only attacks. We then introduce a mixed attack strategy with both the action poisoning and reward poisoning. We show that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no prior information about the underlying environment and the agents' algorithms",
    "checked": true,
    "id": "1bed30e9712817f8b750f89fa7046321c5584354",
    "semantic_title": "efficient adversarial attacks on online multi-agent reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=xEhKwsqxMa": {
    "title": "Dissecting Chain-of-Thought: Compositionality through In-Context Filtering and Learning",
    "volume": "poster",
    "abstract": "Chain-of-thought (CoT) is a method that enables language models to handle complex reasoning tasks by decomposing them into simpler steps. Despite its success, the underlying mechanics of CoT are not yet fully understood. In an attempt to shed light on this, our study investigates the impact of CoT on the ability of transformers to in-context learn a simple to study, yet general family of compositional functions: multi-layer perceptrons (MLPs). In this setting, we find that the success of CoT can be attributed to breaking down in-context learning of a compositional function into two distinct phases: focusing on and filtering data related to each step of the composition and in-context learning the single-step composition function. Through both experimental and theoretical evidence, we demonstrate how CoT significantly reduces the sample complexity of in-context learning (ICL) and facilitates the learning of complex functions that non-CoT methods struggle with. Furthermore, we illustrate how transformers can transition from vanilla in-context learning to mastering a compositional function with CoT by simply incorporating additional layers that perform the necessary data-filtering for CoT via the attention mechanism. In addition to these test-time benefits, we show CoT helps accelerate pretraining by learning shortcuts to represent complex functions and filtering plays an important role in this process. These findings collectively provide insights into the mechanics of CoT, inviting further investigation of its role in complex reasoning tasks",
    "checked": true,
    "id": "69bfa665e507fcee4a8d003933998eb89f336c9f",
    "semantic_title": "dissecting chain-of-thought: compositionality through in-context filtering and learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cNObl6QQEH": {
    "title": "PanoGen: Text-Conditioned Panoramic Environment Generation for Vision-and-Language Navigation",
    "volume": "poster",
    "abstract": "Vision-and-Language Navigation requires the agent to follow language instructions to navigate through 3D environments. One main challenge in Vision-and-Language Navigation is the limited availability of photorealistic training environments, which makes it hard to generalize to new and unseen environments. To address this problem, we propose PanoGen, a generation method that can potentially create an infinite number of diverse panoramic environments conditioned on text. Specifically, we collect room descriptions by captioning the room images in existing Matterport3D environments, and leverage a state-of-the-art text-to-image diffusion model to generate the new panoramic environments. We use recursive outpainting over the generated images to create consistent 360-degree panorama views. Our new panoramic environments share similar semantic information with the original environments by conditioning on text descriptions, which ensures the co-occurrence of objects in the panorama follows human intuition, and creates enough diversity in room appearance and layout with image outpainting. Lastly, we explore two ways of utilizing PanoGen in VLN pre-training and fine-tuning. We generate instructions for paths in our PanoGen environments with a speaker built on a pre-trained vision-and-language model for VLN pre-training, and augment the visual observation with our panoramic environments during agents' fine-tuning to avoid overfitting to seen environments. Empirically, learning with our PanoGen environments achieves the new state-of-the-art on the Room-to-Room, Room-for-Room, and CVDN datasets. Besides, we find that pre-training with our PanoGen speaker data is especially effective for CVDN, which has under-specified instructions and needs commonsense knowledge to reach the target. Lastly, we show that the agent can benefit from training with more generated panoramic environments, suggesting promising results for scaling up the PanoGen environments to enhance agents' generalization to unseen environments",
    "checked": true,
    "id": "d7f1a876b7df0e10627bccb0c5b63faf2a1005e4",
    "semantic_title": "panogen: text-conditioned panoramic environment generation for vision-and-language navigation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=UKtjq3dIs0": {
    "title": "The s-value: evaluating stability with respect to distributional shifts",
    "volume": "poster",
    "abstract": "Common statistical measures of uncertainty such as $p$-values and confidence intervals quantify the uncertainty due to sampling, that is, the uncertainty due to not observing the full population. However, sampling is not the only source of uncertainty. In practice, distributions change between locations and across time. This makes it difficult to gather knowledge that transfers across data sets. We propose a measure of instability that quantifies the distributional instability of a statistical parameter with respect to Kullback-Leibler divergence, that is, the sensitivity of the parameter under general distributional perturbations within a Kullback-Leibler divergence ball. In addition, we quantify the instability of parameters with respect to directional or variable-specific shifts. Measuring instability with respect to directional shifts can be used to detect under which kind of distribution shifts a statistical conclusion might be reversed. We discuss how such knowledge can inform data collection for transfer learning of statistical parameters under shifted distributions. We evaluate the performance of the proposed measure on real data and show that it can elucidate the distributional instability of a parameter with respect to certain shifts and can be used to improve estimation accuracy under shifted distributions",
    "checked": false,
    "id": "ae28061cac61f9e12e3abbcd4a3e5abab65e9785",
    "semantic_title": "the $s$-value: evaluating stability with respect to distributional shifts",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=Uczck6TlSZ": {
    "title": "Generating Images with Multimodal Language Models",
    "volume": "poster",
    "abstract": "We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time. This is done with a learnt decision module which conditions on the hidden representations of the LLM. Our model exhibits a wider range of capabilities compared to prior multimodal language models. It can process image-and-text inputs, and produce retrieved images, generated images, and generated text — outperforming non-LLM based generation models across several text-to-image tasks that measure context dependence",
    "checked": true,
    "id": "6fb5c0eff3696ef252aca9638e10176ecce7cecb",
    "semantic_title": "generating images with multimodal language models",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=ohKbQp0jIY": {
    "title": "Successor-Predecessor Intrinsic Exploration",
    "volume": "poster",
    "abstract": "Exploration is essential in reinforcement learning, particularly in environments where external rewards are sparse. Here we focus on exploration with intrinsic rewards, where the agent transiently augments the external rewards with self-generated intrinsic rewards. Although the study of intrinsic rewards has a long history, existing methods focus on composing the intrinsic reward based on measures of future prospects of states, ignoring the information contained in the retrospective structure of transition sequences. Here we argue that the agent can utilise retrospective information to generate explorative behaviour with structure-awareness, facilitating efficient exploration based on global instead of local information. We propose Successor-Predecessor Intrinsic Exploration (SPIE), an exploration algorithm based on a novel intrinsic reward combining prospective and retrospective information. We show that SPIE yields more efficient and ethologically plausible exploratory behaviour in environments with sparse rewards and bottleneck states than competing methods. We also implement SPIE in deep reinforcement learning agents, and show that the resulting agent achieves stronger empirical performance than existing methods on sparse-reward Atari games",
    "checked": true,
    "id": "56ee1a0a195f5a36783c1514f178ca2568cd31f0",
    "semantic_title": "successor-predecessor intrinsic exploration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1JlAV2paGu": {
    "title": "Blurred-Dilated Method for Adversarial Attacks",
    "volume": "poster",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial attacks, which lead to incorrect predictions. In black-box settings, transfer attacks can be conveniently used to generate adversarial examples. However, such examples tend to overfit the specific architecture and feature representations of the source model, resulting in poor attack performance against other target models. To overcome this drawback, we propose a novel model modification-based transfer attack: Blurred-Dilated method (BD) in this paper. In summary, BD works by reducing downsampling while introducing BlurPool and dilated convolutions in the source model. Then BD employs the modified source model to generate adversarial samples. We think that BD can more comprehensively preserve the feature information than the original source model. It thus enables more thorough destruction of the image features, which can improve the transferability of the generated adversarial samples. Extensive experiments on the ImageNet dataset show that adversarial examples generated by BD achieve significantly higher transferability than the state-of-the-art baselines. Besides, BD can be conveniently combined with existing black-box attack techniques to further improve their performance",
    "checked": false,
    "id": "ef2f4ab713ccaf04e1fde0524c1b3428f192ea1b",
    "semantic_title": "deblurred adversarial defence for object tracking",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QRAS5wSgEy": {
    "title": "CADet: Fully Self-Supervised Out-Of-Distribution Detection With Contrastive Learning",
    "volume": "poster",
    "abstract": "Handling out-of-distribution (OOD) samples has become a major stake in the real-world deployment of machine learning systems. This work explores the use of self-supervised contrastive learning to the simultaneous detection of two types of OOD samples: unseen classes and adversarial perturbations. First, we pair self-supervised contrastive learning with the maximum mean discrepancy (MMD) two-sample test. This approach enables us to robustly test whether two independent sets of samples originate from the same distribution, and we demonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1 with higher confidence than previous work. Motivated by this success, we introduce CADet (Contrastive Anomaly Detection), a novel method for OOD detection of single samples. CADet draws inspiration from MMD, but leverages the similarity between contrastive transformations of a same sample. CADet outperforms existing adversarial detection methods in identifying adversarially perturbed samples on ImageNet and achieves comparable performance to unseen label detection methods on two challenging benchmarks: ImageNet-O and iNaturalist. Significantly, CADet is fully self-supervised and requires neither labels for in-distribution samples nor access to OOD examples",
    "checked": true,
    "id": "c9a345151cf666a6d78329012daf1833333a3a5d",
    "semantic_title": "cadet: fully self-supervised out-of-distribution detection with contrastive learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4JCVw8oMlf": {
    "title": "Effectively Learning Initiation Sets in Hierarchical Reinforcement Learning",
    "volume": "poster",
    "abstract": "An agent learning an option in hierarchical reinforcement learning must solve three problems: identify the option's subgoal (termination condition), learn a policy, and learn where that policy will succeed (initiation set). The termination condition is typically identified first, but the option policy and initiation set must be learned simultaneously, which is challenging because the initiation set depends on the option policy, which changes as the agent learns. Consequently, data obtained from option execution becomes invalid over time, leading to an inaccurate initiation set that subsequently harms downstream task performance. We highlight three issues---data non-stationarity, temporal credit assignment, and pessimism---specific to learning initiation sets, and propose to address them using tools from off-policy value estimation and classification. We show that our method learns higher-quality initiation sets faster than existing methods (in MiniGrid and Montezuma's Revenge), can automatically discover promising grasps for robot manipulation (in Robosuite), and improves the performance of a state-of-the-art option discovery method in a challenging maze navigation task in MuJoCo",
    "checked": false,
    "id": "67bf57595409a6a3f2aa50f69490ad5d431d5903",
    "semantic_title": "uav swarm confrontation using hierarchical multiagent reinforcement learning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=2EDqbSCnmF": {
    "title": "Any-to-Any Generation via Composable Diffusion",
    "volume": "poster",
    "abstract": "We present Composable Diffusion (CoDi), a novel generative model capable of generating any combination of output modalities, such as language, image, video, or audio, from any combination of input modalities. Unlike existing generative AI systems, CoDi can generate multiple modalities in parallel and its input is not limited to a subset of modalities like text or image. Despite the absence of training datasets for many combinations of modalities, we propose to align modalities in both the input and output space. This allows CoDi to freely condition on any input combination and generate any group of modalities, even if they are not present in the training data. CoDi employs a novel composable generation strategy which involves building a shared multimodal space by bridging alignment in the diffusion process, enabling the synchronized generation of intertwined modalities, such as temporally aligned video and audio. Highly customizable and flexible, CoDi achieves strong joint-modality generation quality, and outperforms or is on par with the unimodal state-of-the-art for single-modality synthesis",
    "checked": true,
    "id": "9f411fda2ad5b141a3115f707bcf5ee865b3fb94",
    "semantic_title": "any-to-any generation via composable diffusion",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=yjWVd8Fhqt": {
    "title": "OBJECT 3DIT: Language-guided 3D-aware Image Editing",
    "volume": "poster",
    "abstract": "Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected. As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process; such edits break the portrayal of a coherent 3D world. 3D-aware generative models are a promising solution, but currently only succeed on small datasets or at the level of a single object. In this work, we formulate the new task of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction while remaining consistent with the underlying 3D scene. To promote progress towards this goal, we release OBJect: a benchmark dataset of 400K editing examples created from procedurally generated 3D scenes. Each example consists of an input image, editing instruction in language, and the edited image. We also introduce 3DIT: single and multi-task models for four editing tasks. Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations. Surprisingly, training on only synthetic scenes from \\dataset, editing capabilities of 3DIT generalize to real-world images",
    "checked": true,
    "id": "f3ba7153e16a7a56bd0861f58a6bee0244bf5dab",
    "semantic_title": "object 3dit: language-guided 3d-aware image editing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XAyPlfmWpu": {
    "title": "Binarized Neural Machine Translation",
    "volume": "poster",
    "abstract": "The rapid scaling of language models is motivating research using low-bitwidth quantization. In this work, we propose a novel binarization technique for Transformers applied to machine translation (BMT), the first of its kind. We identify and address the problem of inflated dot-product variance when using one-bit weights and activations. Specifically, BMT leverages additional LayerNorms and residual connections to improve binarization quality. Experiments on the WMT dataset show that a one-bit weight-only Transformer can achieve the same quality as a float one, while being 16$\\times$ smaller in size. One-bit activations incur varying degrees of quality drop, but mitigated by the proposed architectural changes. We further conduct a scaling law study using production-scale translation datasets, which shows that one-bit weight Transformers scale and generalize well in both in-domain and out-of-domain settings. Implementation in JAX/Flax will be open sourced",
    "checked": true,
    "id": "101958920c32d67b6509cd849e6644b28d7e473f",
    "semantic_title": "binarized neural machine translation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=66XhNDahk6": {
    "title": "A Competitive Algorithm for Agnostic Active Learning",
    "volume": "poster",
    "abstract": "For some hypothesis classes and input distributions, \\emph{active} agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs. We take a different approach to agnostic active learning, getting an algorithm that is \\emph{competitive} with the optimal algorithm for any binary hypothesis class $H$ and distribution $\\mathcal{D}_X$ over $X$. In particular, if any algorithm can use $m^*$ queries to get $O(\\eta)$ error, then our algorithm uses $O(m^* \\log H)$ queries to get $O(\\eta)$ error. Our algorithm lies in the vein of the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ($\\eta = 0$) setting. We also show that it is NP-hard to do better than our algorithm's $O(\\log H)$ overhead in general",
    "checked": true,
    "id": "991f080fbf252ca874769917e84e80aa3290370d",
    "semantic_title": "a competitive algorithm for agnostic active learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I6aOjhpcNQ": {
    "title": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization",
    "volume": "poster",
    "abstract": "Distributed representations provide a vector space that captures meaningful relationships between data instances. The distributed nature of these representations, however, entangles together multiple attributes or concepts of data instances (e.g., the topic or sentiment of a text, characteristics of the author (age, gender, etc), etc). Recent work has proposed the task of concept erasure, in which rather than making a concept predictable, the goal is to remove an attribute from distributed representations while retaining other information from the original representation space as much as possible. In this paper, we propose a new distance metric learning-based objective, the Kernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure. KRaM fits a transformation of representations to match a specified distance measure (defined by a labeled concept to erase) using a modified rate-distortion function. Specifically, KRaM's objective function aims to make instances with similar concept labels dissimilar in the learned representation space while retaining other information. We find that optimizing KRaM effectively erases various types of concepts—categorical, continuous, and vector-valued variables—from data representations across diverse domains. We also provide a theoretical analysis of several properties of KRaM's objective. To assess the quality of the learned representations, we propose an alignment score to evaluate their similarity with the original representation space. Additionally, we conduct experiments to showcase KRaM's efficacy in various settings, from erasing binary gender variables in word embeddings to vector-valued variables in GPT-3 representations",
    "checked": false,
    "id": "8cde92023b267ed8490ce125795a3979cdfd624f",
    "semantic_title": "program yes workshop 2022 optimal transport, statistics, machine learning and moving in between",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2nTpPxJ5Bs": {
    "title": "Double Auctions with Two-sided Bandit Feedback",
    "volume": "poster",
    "abstract": "Double Auction enables decentralized transfer of goods between multiple buyers and sellers, thus underpinning functioning of many online marketplaces. Buyers and sellers compete in these markets through bidding, but do not often know their own valuation a-priori. As the allocation and pricing happens through bids, the profitability of participants, hence sustainability of such markets, depends crucially on learning respective valuations through repeated interactions. We initiate the study of Double Auction markets under bandit feedback on both buyers' and sellers' side. We show with confidence bound based bidding, and `Average Pricing' there is an efficient price discovery among the participants. In particular, the regret on combined valuation of the buyers and the sellers -- a.k.a. the social regret -- is $O(\\log(T)/\\Delta)$ in $T$ rounds, where $\\Delta$ is the minimum price gap. Moreover, the buyers and sellers exchanging goods attain $O(\\sqrt{T})$ regret, individually. The buyers and sellers who do not benefit from exchange in turn only experience $O(\\log{T}/ \\Delta)$ regret individually in $T$ rounds. We augment our upper bound by showing that $\\omega(\\sqrt{T})$ individual regret, and $\\omega(\\log{T})$ social regret is unattainable in certain Double Auction markets. Our paper is the first to provide decentralized learning algorithms in a two-sided market where \\emph{both sides have uncertain preference} that need to be learned",
    "checked": true,
    "id": "849b5efd0df5e6fffc7f256951cda893d24c23ea",
    "semantic_title": "double auctions with two-sided bandit feedback",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qptO6YDZEP": {
    "title": "Lower Bounds on Adaptive Sensing for Matrix Recovery",
    "volume": "poster",
    "abstract": "We study lower bounds on adaptive sensing algorithms for recovering low rank matrices using linear measurements. Given an $n \\times n$ matrix $A$, a general linear measurement $S(A)$, for an $n \\times n$ matrix $S$, is just the inner product of $S$ and $A$, each treated as $n^2$-dimensional vectors. By performing as few linear measurements as possible on a rank-$r$ matrix $A$, we hope to construct a matrix $\\hat{A}$ that satisfies $|A - \\hat{A}|\\_F^2 \\le c |A|\\_F^2$, for a small constant $c$. Here $|A|\\_F$ denotes the Frobenius norm $(\\sum_{i,j} A_{i,j}^2)^{1/2}$. It is commonly assumed that when measuring $A$ with $S$, the response is corrupted with an independent Gaussian random variable of mean $0$ and variance $\\sigma^2$. Candès and Plan (IEEE Trans. Inform. Theory 2011) study non-adaptive algorithms for low rank matrix recovery using random linear measurements. They use the restricted isometry property (RIP) of Random Gaussian Matrices to give tractable algorithms to estimate $A$ from the measurements. At the edge of the noise level where recovery is information-theoretically feasible, it is known that their non-adaptive algorithms need to perform $\\Omega(n^2)$ measurements, which amounts to reading the entire matrix. An important question is whether adaptivity helps in decreasing the overall number of measurements. While for the related problem of sparse recovery, adaptive algorithms have been extensively studied, as far as we are aware adaptive algorithms and lower bounds on them seem largely unexplored for matrix recovery. We show that any adaptive algorithm that uses $k$ linear measurements in each round and outputs an approximation as in (1) with probability $\\ge 9/10$ must run for $t = \\Omega(\\log(n^2/k)/\\log\\log n)$ rounds. Our lower bound shows that any adaptive algorithm which uses $n^{2-\\beta}$ ($\\beta > 0$ is arbitrary constant) linear measurements in each round must run for $\\Omega(\\log n/\\log\\log n)$ rounds. Our techniques also readily extend to obtain lower bounds on adaptive algorithms for tensor recovery. Our hard distribution also allows us to give a measurement-vs-rounds trade-off for many sensing problems in numerical linear algebra, such as spectral norm low rank approximation, Frobenius norm low rank approximation, singular vector approximation, and more",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x5fs7TXKDc": {
    "title": "FedNAR: Federated Optimization with Normalized Annealing Regularization",
    "volume": "poster",
    "abstract": "Weight decay is a standard technique to improve generalization performance in modern deep neural network optimization, and is also widely adopted in federated learning (FL) to prevent overfitting in local clients. In this paper, we first explore the choices of weight decay and identify that weight decay value appreciably influences the convergence of existing FL algorithms. While preventing overfitting is crucial, weight decay can introduce a different optimization goal towards the global objective, which is further amplified in FL due to multiple local updates and heterogeneous data distribution. To address this challenge, we develop {\\it Federated optimization with Normalized Annealing Regularization} (FedNAR), a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms. Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay. We provide a comprehensive theoretical analysis of FedNAR's convergence rate and conduct extensive experiments on both vision and language datasets with different backbone federated optimization algorithms. Our experimental results consistently demonstrate that incorporating FedNAR into existing FL algorithms leads to accelerated convergence and heightened model accuracy. Moreover, FedNAR exhibits resilience in the face of various hyperparameter configurations. Specifically, FedNAR has the ability to self-adjust the weight decay when the initial specification is not optimal, while the accuracy of traditional FL algorithms would markedly decline. Our codes are released at \\href{https://anonymous.4open.science/r/fednar-BE8F}{https://anonymous.4open.science/r/fednar-BE8F}",
    "checked": true,
    "id": "ab70103b8cc85fd1cd52200aa134c58c7e9c0e03",
    "semantic_title": "fednar: federated optimization with normalized annealing regularization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v7WWesSiOu": {
    "title": "End-To-End Latent Variational Diffusion Models for Inverse Problems in High Energy Physics",
    "volume": "poster",
    "abstract": "High-energy collisions at the Large Hadron Collider (LHC) provide valuable insights into open questions in particle physics. However, detector effects must be corrected before measurements can be compared to certain theoretical predictions or measurements from other detectors. Methods to solve this inverse problem of mapping detector observations to theoretical quantities of the underlying collision are essential parts of many physics analyses at the LHC. We investigate and compare various generative deep learning methods to approximate this inverse mapping. We introduce a novel unified architecture, termed latent variational diffusion models, which combines the latent learning of cutting-edge generative art approaches with an end-to-end variational framework. We demonstrate the effectiveness of this approach for reconstructing global distributions of theoretical kinematic quantities, as well as for ensuring the adherence of the learned posterior distributions to known physics constraints. Our unified approach achieves a distribution-free distance to the truth of over 20 times smaller than non-latent state-of-the-art baseline and 3 times smaller than traditional latent diffusion models",
    "checked": true,
    "id": "f82a3b6ef384804197824c4d31944124eb9670b1",
    "semantic_title": "end-to-end latent variational diffusion models for inverse problems in high energy physics",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=2lWh1G1W1I": {
    "title": "Density of States Prediction of Crystalline Materials via Prompt-guided Multi-Modal Transformer",
    "volume": "poster",
    "abstract": "The density of states (DOS) is a spectral property of crystalline materials, which provides fundamental insights into various characteristics of the materials. While previous works mainly focus on obtaining high-quality representations of crystalline materials for DOS prediction, we focus on predicting the DOS from the obtained representations by reflecting the nature of DOS: DOS determines the general distribution of states as a function of energy. That is, DOS is not solely determined by the crystalline material but also by the energy levels, which has been neglected in previous works. In this paper, we propose to integrate heterogeneous information obtained from the crystalline materials and the energies via a multi-modal transformer, thereby modeling the complex relationships between the atoms in the crystalline materials and various energy levels for DOS prediction. Moreover, we propose to utilize prompts to guide the model to learn the crystal structural system-specific interactions between crystalline materials and energies. Extensive experiments on two types of DOS, i.e., Phonon DOS and Electron DOS, with various real-world scenarios demonstrate the superiority of DOSTransformer. The source code for DOSTransformer is available at https://github.com/HeewoongNoh/DOSTransformer",
    "checked": true,
    "id": "a050013356ca2fe81cd1c46b532a2ac5316a9323",
    "semantic_title": "density of states prediction of crystalline materials via prompt-guided multi-modal transformer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I18BXotQ7j": {
    "title": "GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization",
    "volume": "poster",
    "abstract": "Worldwide Geo-localization aims to pinpoint the precise location of images taken anywhere on Earth. This task has considerable challenges due to the immense variation in geographic landscapes. The image-to-image retrieval-based approaches fail to solve this problem on a global scale as it is not feasible to construct a large gallery of images covering the entire world. Instead, existing approaches divide the globe into discrete geographic cells, transforming the problem into a classification task. However, their performance is limited by the predefined classes and often results in inaccurate localizations when an image's location significantly deviates from its class center. To overcome these limitations, we propose GeoCLIP, a novel CLIP-inspired Image-to-GPS retrieval approach that enforces alignment between the image and its corresponding GPS locations. GeoCLIP's location encoder models the Earth as a continuous function by employing positional encoding through random Fourier features and constructing a hierarchical representation that captures information at varying resolutions to yield a semantically rich high-dimensional feature suitable to use even beyond geo-localization. To the best of our knowledge, this is the first work employing GPS encoding for geo-localization. We demonstrate the efficacy of our method via extensive experiments and ablations on benchmark datasets. We achieve competitive performance with just 20% of training data, highlighting its effectiveness even in limited-data settings. Furthermore, we qualitatively demonstrate geo-localization using a text query by leveraging the CLIP backbone of our image encoder. The project webpage is available at: https://vicentevivan.github.io/GeoCLIP",
    "checked": true,
    "id": "01fc730e06c4d3d02840af2ebae083634998b566",
    "semantic_title": "geoclip: clip-inspired alignment between locations and images for effective worldwide geo-localization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9cQ6kToLnJ": {
    "title": "Learning threshold neurons via edge of stability",
    "volume": "poster",
    "abstract": "Existing analyses of neural network training often operate under the unrealistic assumption of an extremely small learning rate. This lies in stark contrast to practical wisdom and empirical studies, such as the work of J. Cohen et al. (ICLR 2021), which exhibit startling new phenomena (the \"edge of stability\"' or \"unstable convergence\") and potential benefits for generalization in the large learning rate regime. Despite a flurry of recent works on this topic, however, the latter effect is still poorly understood. In this paper, we take a step towards understanding genuinely non-convex training dynamics with large learning rates by performing a detailed analysis of gradient descent for simplified models of two-layer neural networks. For these models, we provably establish the edge of stability phenomenon and discover a sharp phase transition for the step size below which the neural network fails to learn ``threshold-like'' neurons (i.e., neurons with a non-zero first-layer bias). This elucidates one possible mechanism by which the edge of stability can in fact lead to better generalization, as threshold neurons are basic building blocks with useful inductive bias for many tasks",
    "checked": false,
    "id": "273345a0de931b25e62503d0b51c13e4868aab81",
    "semantic_title": "learning threshold neurons via the \"edge of stability",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=bU9hwbsVcy": {
    "title": "The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter",
    "volume": "poster",
    "abstract": "Large pre-trained transformers are $\\textit{show-stealer}$ in modern-day deep learning, and it becomes crucial to comprehend the parsimonious patterns that exist within them as they grow in scale. With exploding parameter counts, Lottery Ticket Hypothesis (LTH) and its variants, have lost their pragmatism in sparsifying them due to high computation and memory bottleneck of repetitive $\\textit{train-prune-retrain}$ routine of iterative magnitude pruning (IMP) which worsens with increasing model size. In this paper, we comprehensively study $\\textit{induced sparse patterns}$ across multiple large pre-trained vision and language transformers. We propose the existence of -- $\\textbf{essential sparsity}$ defined with a $\\textbf{sharp dropping point}$ beyond which the performance declines much faster w.r.t the rise of sparsity level, when we directly remove weights with the smallest magnitudes in $\\textbf{one-shot}$. We also present an intriguing emerging phenomenon of $\\textbf{abrupt sparsification}$ during the pre-training of BERT, i.e., BERT suddenly becomes heavily sparse in pre-training after certain iterations. Moreover, our observations also indicate a $\\textbf{counter-intuitive}$ finding that BERT trained with a larger amount of pre-training data tends to have a better ability to condense knowledge in comparatively relatively fewer parameters. Lastly, we investigate the effect of the pre-training loss on essential sparsity and discover that self-supervised learning (SSL) objectives trigger stronger emergent sparsification properties than supervised learning (SL). All our codes will be publicly available",
    "checked": true,
    "id": "9d460930d9b5d12a65ff2b3efa23047ec75fbca1",
    "semantic_title": "the emergence of essential sparsity in large pre-trained models: the weights that matter",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=XmN7ZNbUAe": {
    "title": "Distributed Inference and Fine-tuning of Large Language Models Over The Internet",
    "volume": "poster",
    "abstract": "Large language models (LLMs) are useful in many NLP tasks and become more capable with size, with the best open-source models having over 50 billion parameters. However, using these 50B+ models requires high-end hardware, making them inaccessible to most researchers. In this work, we investigate methods for cost-efficient inference and fine-tuning of LLMs, comparing local and distributed strategies. We observe that a large enough model (50B+) can run efficiently even on geodistributed devices in a consumer-grade network. This could allow running LLM efficiently by pooling together idle compute resources of multiple research groups and volunteers. We address two open problems: (1) how to perform inference and fine-tuning reliably if any device can disconnect abruptly and (2) how to partition LLMs between devices with uneven hardware, joining and leaving at will. In order to do that, we develop special fault-tolerant inference algorithms and load-balancing protocols that automatically assign devices to maximize the total system throughput. We showcase these algorithms in Petals — a decentralized system that runs Llama 2 (70B) and BLOOM (176B) over the Internet up to $10\\times$ faster than offloading for interactive generation. We evaluate the performance of our system in simulated conditions and a real-world setup spanning two continents",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uhKtQMn21D": {
    "title": "Mechanic: A Learning Rate Tuner",
    "volume": "poster",
    "abstract": "We introduce a technique for tuning the learning rate scale factor of any base optimization algorithm and schedule automatically, which we call Mechanic. Our method provides a practical realization of recent theoretical reductions for accomplishing a similar goal in online convex optimization. We rigorously evaluate Mechanic on a range of large scale deep learning tasks with varying batch sizes, schedules, and base optimization algorithms. These experiments demonstrate that depending on the problem, Mechanic either comes very close to, matches or even improves upon manual tuning of learning rates",
    "checked": true,
    "id": "ad67feae3771220c6a8226da69de3f1795425491",
    "semantic_title": "mechanic: a learning rate tuner",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=pzc6LnUxYN": {
    "title": "StateMask: Explaining Deep Reinforcement Learning through State Mask",
    "volume": "poster",
    "abstract": "Despite the promising performance of deep reinforcement learning (DRL) agents in many challenging scenarios, the black-box nature of these agents greatly limits their applications in critical domains. Prior research has proposed several explanation techniques to understand the deep learning-based policies in RL. Most existing methods explain why an agent takes individual actions rather than pinpointing the critical steps to its final reward. To fill this gap, we propose StateMask, a novel method to identify the states most critical to the agent's final reward. The high-level idea of StateMask is to learn a mask net that blinds a target agent and forces it to take random actions at some steps without compromising the agent's performance. Through careful design, we can theoretically ensure that the masked agent performs similarly to the original agent. We evaluate StateMask in various popular RL environments and show its superiority over existing explainers in explanation fidelity. We also show that StateMask has better utilities, such as launching adversarial attacks and patching policy errors",
    "checked": false,
    "id": "575fe5d006c14d7af94c7aed12be23e94e37997e",
    "semantic_title": "adversarial policy training against deep reinforcement learning",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=QezJbfW01r": {
    "title": "Adaptive Privacy Composition for Accuracy-first Mechanisms",
    "volume": "poster",
    "abstract": "Although there has been work to develop ex-post private mechanisms from Ligett et al. '17 and Whitehouse et al '22 that seeks to provide privacy guarantees subject to a target level of accuracy, there was not a way to use them in conjunction with differentially private mechanisms. Furthermore, there has yet to be work in developing a theory for how these ex-post privacy mechanisms compose, so that we can track the accumulated privacy over several mechanisms. We develop privacy filters that allow an analyst to adaptively switch between differentially private mechanisms and ex-post private mechanisms subject to an overall privacy loss guarantee. We show that using a particular ex-post private mechanism --- noise reduction mechanisms --- can substantially outperform baseline approaches that use existing privacy loss composition bounds. We use the common task of returning as many counts as possible subject to a relative error guarantee and an overall privacy budget as a motivating example",
    "checked": true,
    "id": "c7e452f0d205fa465bc942bd89cf325cd896825a",
    "semantic_title": "adaptive privacy composition for accuracy-first mechanisms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UKd6dpVGdu": {
    "title": "Learning to Tokenize for Generative Retrieval",
    "volume": "poster",
    "abstract": "As a new paradigm in information retrieval, generative retrieval directly generates a ranked list of document identifiers (docids) for a given query using generative language models (LMs). How to assign each document a unique docid (denoted as document tokenization) is a critical problem, because it determines whether the generative retrieval model can precisely retrieve any document by simply decoding its docid. Most existing methods adopt rule-based tokenization, which is ad-hoc and does not generalize well. In contrast, in this paper we propose a novel document tokenization learning method, GenRet, which learns to encode the complete document semantics into docids. GenRet learns to tokenize documents into short discrete representations (i.e., docids) via a discrete auto-encoding approach. We develop a progressive training scheme to capture the autoregressive nature of docids and diverse clustering techniques to stabilize the training process. Based on the semantic-embedded docids of any set of documents, the generative retrieval model can learn to generate the most relevant docid only according to the docids' semantic relevance to the queries. We conduct experiments on the NQ320K, MS MARCO, and BEIR datasets. GenRet establishes the new state-of-the-art on the NQ320K dataset. Compared to generative retrieval baselines, GenRet can achieve significant improvements on unseen documents. Moreover, GenRet can also outperform comparable baselines on MS MARCO and BEIR, demonstrating the method's generalizability",
    "checked": true,
    "id": "d66fe1ade1f2548bdcebd58005cf5fe7153ad9ca",
    "semantic_title": "learning to tokenize for generative retrieval",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=V8GHCGYLkf": {
    "title": "Temporally Disentangled Representation Learning under Unknown Nonstationarity",
    "volume": "poster",
    "abstract": "In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to reconstruct time-delayed latent causal variables and identify their relations from measured sequential data only. Empirical evaluations demonstrated the reliable identification of time-delayed latent causal influences, with our methodology substantially outperforming existing baselines that fail to exploit the nonstationarity adequately and then, consequently, cannot distinguish distribution shifts",
    "checked": true,
    "id": "99dadc987c90626e3c0b0adcf694b6a4b5bd3901",
    "semantic_title": "temporally disentangled representation learning under unknown nonstationarity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0uARg5G04K": {
    "title": "The Adversarial Consistency of Surrogate Risks for Binary Classification",
    "volume": "poster",
    "abstract": "We study the consistency of surrogate risks for robust binary classification. It is common to learn robust classifiers by adversarial training, which seeks to minimize the expected $0$-$1$ loss when each example can be maliciously corrupted within a small ball. We give a simple and complete characterization of the set of surrogate loss functions that are \\emph{consistent}, i.e., that can replace the $0$-$1$ loss without affecting the minimizing sequences of the original adversarial risk, for any data distribution. We also prove a quantitative version of adversarial consistency for the $\\rho$-margin loss. Our results reveal that the class of adversarially consistent surrogates is substantially smaller than in the standard setting, where many common surrogates are known to be consistent",
    "checked": true,
    "id": "13865e2b2c8bbc9d0b04fe657bdea0e891e40415",
    "semantic_title": "the adversarial consistency of surrogate risks for binary classification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=IpUJd3KG3c": {
    "title": "Improving the Privacy and Practicality of Objective Perturbation for Differentially Private Linear Learners",
    "volume": "poster",
    "abstract": "In the arena of privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) has outstripped the objective perturbation mechanism in popularity and interest. Though unrivaled in versatility, DP-SGD requires a non-trivial privacy overhead (for privately tuning the model's hyperparameters) and a computational complexity which might be extravagant for simple models such as linear and logistic regression. This paper revamps the objective perturbation mechanism with tighter privacy analyses and new computational tools that boost it to perform competitively with DP-SGD on unconstrained convex generalized linear problems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EdgPb3ngR4": {
    "title": "Isometric Quotient Variational Auto-Encoders for Structure-Preserving Representation Learning",
    "volume": "poster",
    "abstract": "We study structure-preserving low-dimensional representation of a data manifold embedded in a high-dimensional observation space based on variational auto-encoders (VAEs). We approach this by decomposing the data manifold $\\mathcal{M}$ as $\\mathcal{M} = \\mathcal{M} / G \\times G$, where $G$ and $\\mathcal{M} / G$ are a group of symmetry transformations and a quotient space of $\\mathcal{M}$ up to $G$, respectively. From this perspective, we define the structure-preserving representation of such a manifold as a latent space $\\mathcal{Z}$ which is isometrically isomorphic (i.e., distance-preserving) to the quotient space $\\mathcal{M} / G$ rather $\\mathcal{M}$ (i.e., symmetry-preserving). To this end, we propose a novel auto-encoding framework, named isometric quotient VAEs (IQVAEs), that can extract the quotient space from observations and learn the Riemannian isometry of the extracted quotient in an unsupervised manner. Empirical proof-of-concept experiments reveal that the proposed method can find a meaningful representation of the learned data and outperform other competitors for downstream tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EY7Hpj8Ok6": {
    "title": "Context-lumpable stochastic bandits",
    "volume": "poster",
    "abstract": "We consider a contextual bandit problem with $S $ contexts and $K $ actions. In each round $t=1,2,\\dots$ the learner observes a random context and chooses an action based on its past experience. The learner then observes a random reward whose mean is a function of the context and the action for the round. Under the assumption that the contexts can be lumped into $r\\le \\min(S ,K)$ groups such that the mean reward for the various actions is the same for any two contexts that are in the same group, we give an algorithm that outputs an $\\epsilon$-optimal policy after using at most $\\widetilde O(r (S +K )/\\epsilon^2)$ samples with high probability and provide a matching $\\widetilde\\Omega(r (S +K )/\\epsilon^2)$ lower bound. In the regret minimization setting, we give an algorithm whose cumulative regret up to time $T$ is bounded by $\\widetilde O(\\sqrt{r ^3(S +K )T})$. To the best of our knowledge, we are the first to show the near-optimal sample complexity in the PAC setting and $\\widetilde O{\\sqrt{\\text{poly}(r)(S+K)T}}$ minimax regret in the online setting for this problem. We also show our algorithms can be applied to more general low-rank bandits and get improved regret bounds in some scenarios",
    "checked": true,
    "id": "aa2c567c7c46fe6eec6bb9cfab90304b80b039b7",
    "semantic_title": "context-lumpable stochastic bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=87Nu9SagB7": {
    "title": "Embracing the chaos: analysis and diagnosis of numerical instability in variational flows",
    "volume": "poster",
    "abstract": "In this paper, we investigate the impact of numerical instability on the reliability of sampling, density evaluation, and evidence lower bound (ELBO) estimation in variational flows. We first empirically demonstrate that common flows can exhibit a catastrophic accumulation of error: the numerical flow map deviates significantly from the exact map---which affects sampling---and the numerical inverse flow map does not accurately recover the initial input---which affects density and ELBO computations. Surprisingly though, we find that results produced by flows are often accurate enough for applications despite the presence of serious numerical instability. In this work, we treat variational flows as chaotic dynamical systems, and leverage shadowing theory to elucidate this behavior via theoretical guarantees on the error of sampling, density evaluation, and ELBO estimation. Finally, we develop and empirically test a diagnostic procedure that can be used to validate results produced by numerically unstable flows in practice",
    "checked": true,
    "id": "c0f5d9e904c7a9cb865f94909476d8104cca6bc5",
    "semantic_title": "embracing the chaos: analysis and diagnosis of numerical instability in variational flows",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=MljeRycu9s": {
    "title": "Diverse Conventions for Human-AI Collaboration",
    "volume": "poster",
    "abstract": "Conventions are crucial for strong performance in cooperative multi-agent games, because they allow players to coordinate on a shared strategy without explicit communication. Unfortunately, standard multi-agent reinforcement learning techniques, such as self-play, converge to conventions that are arbitrary and non-diverse, leading to poor generalization when interacting with new partners. In this work, we present a technique for generating diverse conventions by (1) maximizing their rewards during self-play, while (2) minimizing their rewards when playing with previously discovered conventions (cross-play), stimulating conventions to be semantically different. To ensure that learned policies act in good faith despite the adversarial optimization of cross-play, we introduce mixed-play, where an initial state is randomly generated by sampling self-play and cross-play transitions and the player learns to maximize the self-play reward from this initial state. We analyze the benefits of our technique on various multi-agent collaborative games, including Overcooked, and find that our technique can adapt to the conventions of humans, surpassing human-level performance when paired with real users",
    "checked": true,
    "id": "3e126b825d26f1c8c9ce86ab6ede9be11c25c7cd",
    "semantic_title": "diverse conventions for human-ai collaboration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jvEbQBxd8X": {
    "title": "Improving Language Plasticity via Pretraining with Active Forgetting",
    "volume": "poster",
    "abstract": "Pretrained language models (PLMs) are today the primary model for natural language processing. Despite their impressive downstream performance, it can be difficult to apply PLMs to new languages, a barrier to making their capabilities universally accessible. While prior work has shown it possible to address this issue by learning a new embedding layer for the new language, doing so is both data and compute inefficient. We propose to use an active forgetting mechanism during pretraining, as a simple way of creating PLMs that can quickly adapt to new languages. Concretely, by resetting the embedding layer every K updates during pretraining, we encourage the PLM to improve its ability of learning new embeddings within limited number of updates, similar to a meta-learning effect. Experiments with RoBERTa show that models pretrained with our forgetting mechanism not only demonstrate faster convergence during language adaptation, but also outperform standard ones in a low-data regime, particularly for languages that are distant from English. Code will be available at https://github.com/facebookresearch/language-model-plasticity",
    "checked": true,
    "id": "9a2f47777b99a92effb4e998b7082e1e92ae13bc",
    "semantic_title": "improving language plasticity via pretraining with active forgetting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dUAcAtCuKk": {
    "title": "RECKONING: Reasoning through Dynamic Knowledge Encoding",
    "volume": "poster",
    "abstract": "Recent studies on transformer-based language models show that they can answer questions by reasoning over knowledge provided as part of the context (i.e., in-context reasoning). However, since the available knowledge is often not filtered for a particular question, in-context reasoning can be sensitive to distractor facts, additional content that is irrelevant to a question but that may be relevant for a different question (i.e., not necessarily random noise). In these situations, the model fails to distinguish the necessary knowledge to answer the question, leading to spurious reasoning and degraded performance. This reasoning failure contrasts with the model's apparent ability to distinguish its contextual knowledge from all the knowledge it has memorized during pre-training. Following this observation, we propose teaching the model to reason more robustly by folding the provided contextual knowledge into the model's parameters before presenting it with a question. Our method, RECKONING, is a bi-level learning algorithm that teaches language models to reason by updating their parametric knowledge through back-propagation, allowing them to answer questions using the updated parameters. During training, the inner loop rapidly adapts a copy of the model weights to encode contextual knowledge into its parameters. In the outer loop, the model learns to use the updated weights to reproduce and answer reasoning questions about the memorized knowledge. Our experiments on three diverse multi-hop reasoning datasets show that RECKONING's performance improves over the in-context reasoning baseline (by up to 4.5%). We also find that compared to in-context reasoning, RECKONING generalizes better to longer reasoning chains unseen during training, is more robust to distractors in the context, and is computationally more efficient when multiple questions are asked about the same knowledge",
    "checked": true,
    "id": "7805db74210aa113e83f20ffd0ad1ebcbb12ed7a",
    "semantic_title": "reckoning: reasoning through dynamic knowledge encoding",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=gQ4h6WvME0": {
    "title": "Optimistic Rates for Multi-Task Representation Learning",
    "volume": "poster",
    "abstract": "We study the problem of transfer learning via Multi-Task Representation Learning (MTRL), wherein multiple source tasks are used to learn a good common representation, and a predictor is trained on top of it for the target task. Under standard regularity assumptions on the loss function and task diversity, we provide new statistical rates on the excess risk of the target task, which demonstrate the benefit of representation learning. Importantly, our rates are optimistic, i.e., they interpolate between the standard $O(m^{-1/2})$ rate and the fast $O(m^{-1})$ rate, depending on the difficulty of the learning task, where $m$ is the number of samples for the target task. Besides the main result, we make several new contributions, including giving optimistic rates for excess risk of source tasks (multi-task learning (MTL)), a local Rademacher complexity theorem for MTRL and MTL, as well as a chain rule for local Rademacher complexity for composite predictor classes",
    "checked": false,
    "id": "7aea82e390f6c293c1c1cf02c6593c0e062377f8",
    "semantic_title": "active multi-task representation learning",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Cyn1PvuZsB": {
    "title": "Neural Priming for Sample-Efficient Adaptation",
    "volume": "poster",
    "abstract": "We propose Neural Priming, a technique for adapting large pretrained models to distribution shifts and downstream tasks given few or no labeled examples. Presented with class names or unlabeled test samples, Neural Priming enables the model to recall and conditions its parameters on relevant data seen throughout pretraining, thereby priming it for the test distribution. Neural Priming can be performed at test time in even for pretraining datasets as large as LAION-2B. Performing lightweight updates on the recalled data significantly improves accuracy across a variety of distribution shift and transfer learning benchmarks. Concretely, in the zero-shot setting, we see a 2.45% improvement in accuracy on ImageNet and 3.81% accuracy improvement on average across standard transfer learning benchmarks. Further, using our test time inference scheme, we see a 1.41% accuracy improvement on ImageNetV2. These results demonstrate the effectiveness of Neural Priming in addressing the common challenge of limited labeled data and changing distributions. Code and models are open-sourced at [https://www.github.com/RAIVNLab/neural-priming](https://www.github.com/RAIVNLab/neural-priming)",
    "checked": true,
    "id": "20fea2d159b48f049cbbb1ea282536fcb7b403fb",
    "semantic_title": "neural priming for sample-efficient adaptation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XKBFdYwfRo": {
    "title": "Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models",
    "volume": "poster",
    "abstract": "We present the first framework to solve linear inverse problems leveraging pre-trained \\textit{latent} diffusion models. Previously proposed algorithms (such as DPS and DDRM) only apply to \\textit{pixel-space} diffusion models. We theoretically analyze our algorithm showing provable sample recovery in a linear model setting. The algorithmic insight obtained from our analysis extends to more general settings often considered in practice. Experimentally, we outperform previously proposed posterior sampling algorithms in a wide variety of problems including random inpainting, block inpainting, denoising, deblurring, destriping, and super-resolution",
    "checked": true,
    "id": "69295ae728d8e02ef6da80fa9cbc2c613acac6de",
    "semantic_title": "solving linear inverse problems provably via posterior sampling with latent diffusion models",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=qY7UqLoora": {
    "title": "Are GATs Out of Balance?",
    "volume": "poster",
    "abstract": "While the expressive power and computational capabilities of graph neural networks (GNNs) have been theoretically studied, their optimization and learning dynamics, in general, remain largely unexplored. Our study undertakes the Graph Attention Network (GAT), a popular GNN architecture in which a node's neighborhood aggregation is weighted by parameterized attention coefficients. We derive a conservation law of GAT gradient flow dynamics, which explains why a high portion of parameters in GATs with standard initialization struggle to change during training. This effect is amplified in deeper GATs, which perform significantly worse than their shallow counterparts. To alleviate this problem, we devise an initialization scheme that balances the GAT network. Our approach i) allows more effective propagation of gradients and in turn enables trainability of deeper networks, and ii) attains a considerable speedup in training and convergence time in comparison to the standard initialization. Our main theorem serves as a stepping stone to studying the learning dynamics of positive homogeneous models with attention mechanisms",
    "checked": true,
    "id": "79ec215eb5d792e5e74dd9801dfc7d5e2aad5724",
    "semantic_title": "are gats out of balance?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3tbTw2ga8K": {
    "title": "The Quantization Model of Neural Scaling",
    "volume": "poster",
    "abstract": "We propose the Quantization Model of neural scaling laws, explaining both the observed power law dropoff of loss with model and data size, and also the sudden emergence of new capabilities with scale. We derive this model from what we call the Quantization Hypothesis, where network knowledge and skills are \"quantized\" into discrete chunks (quanta). We show that when quanta are learned in order of decreasing use frequency, then a power law in use frequencies explains observed power law scaling of loss. We validate this prediction on toy datasets, then study how scaling curves decompose for large language models. Using language model gradients, we automatically decompose model behavior into a diverse set of skills (quanta). We tentatively find that the frequency at which these quanta are used in the training distribution roughly follows a power law corresponding with the empirical scaling exponent for language models, a prediction of our theory",
    "checked": true,
    "id": "9e4980cb927b803d375c5796f4a2eb3a7fe0555d",
    "semantic_title": "the quantization model of neural scaling",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=DnO6LTQ77U": {
    "title": "Approximation-Generalization Trade-offs under (Approximate) Group Equivariance",
    "volume": "poster",
    "abstract": "The explicit incorporation of task-specific inductive biases through symmetry has emerged as a general design precept in the development of high-performance machine learning models. For example, group equivariant neural networks have demonstrated impressive performance across various domains and applications such as protein and drug design. A prevalent intuition about such models is that the integration of relevant symmetry results in enhanced generalization. Moreover, it is posited that when the data and/or the model exhibits only approximate or partial symmetry, the optimal or best-performing model is one where the model symmetry aligns with the data symmetry. In this paper, we conduct a formal unified investigation of these intuitions. To begin, we present quantitative bounds that demonstrate how models capturing task-specific symmetries lead to improved generalization. Utilizing this quantification, we examine the more general question of dealing with approximate/partial symmetries. We establish, for a given symmetry group, a quantitative comparison between the approximate equivariance of the model and that of the data distribution, precisely connecting model equivariance error and data equivariance error. Our result delineates the conditions under which the model equivariance error is optimal, thereby yielding the best-performing model for the given task and data",
    "checked": true,
    "id": "9e89ec041c4cd1b16958dcf60d6b49e37521f444",
    "semantic_title": "approximation-generalization trade-offs under (approximate) group equivariance",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=kqBUgrkm1c": {
    "title": "Easy Learning from Label Proportions",
    "volume": "poster",
    "abstract": "We consider the problem of Learning from Label Proportions (LLP), a weakly supervised classification setup where instances are grouped into i.i.d. \"bags\", and only the frequency of class labels at each bag is available. Albeit, the objective of the learner is to achieve low task loss at an individual instance level. Here we propose EASYLLP, a flexible and simple-to-implement debiasing approach based on aggregate labels, which operates on arbitrary loss functions. Our technique allows us to accurately estimate the expected loss of an arbitrary model at an individual level. We elucidate the differences between our method and standard methods based on label proportion matching, in terms of applicability and optimality conditions. We showcase the flexibility of our approach compared to alternatives by applying our method to popular learning frameworks, like Empirical Risk Minimization (ERM) and Stochastic Gradient Descent (SGD) with provable guarantees on instance level performance. Finally, we validate our theoretical results on multiple datasets, empirically illustrating the conditions under which our algorithm is expected to perform better or worse than previous LLP approaches",
    "checked": true,
    "id": "34b30c340fd8cbece9705a9aec929df832a2d06c",
    "semantic_title": "easy learning from label proportions",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=DFaGf3O7jf": {
    "title": "Propagating Knowledge Updates to LMs Through Distillation",
    "volume": "poster",
    "abstract": "Modern language models have the capacity to store and use immense amounts of knowledge about real-world entities, but it remains unclear how to update such knowledge stored in model parameters. While prior methods for updating knowledge in LMs successfully inject atomic facts, updated LMs fail to make inferences based on injected facts. In this work, we demonstrate that a context distillation-based approach can both impart knowledge about entities \\emph{and} propagate that knowledge to enable broader inferences. Our approach consists of two stages: transfer set generation and distillation on the transfer set. We first generate a transfer set by prompting a language model to generate continuations from the entity definition. Then, we update the model parameters so that the distribution of the LM (the 'student') matches the distribution of the LM conditioned on the definition (the 'teacher') on the transfer set. Our experiments demonstrate that this approach is more effective at propagating knowledge updates than fine-tuning and other gradient-based knowledge-editing methods. Moreover, it does not compromise performance in other contexts, even when injecting the definitions of up to 150 entities at once",
    "checked": true,
    "id": "a5d3a865b71f3f424ba31e037848028f60161478",
    "semantic_title": "propagating knowledge updates to lms through distillation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=OXhymu6MeN": {
    "title": "Sub-optimality of the Naive Mean Field approximation for proportional high-dimensional Linear Regression",
    "volume": "poster",
    "abstract": "The Naïve Mean Field (NMF) approximation is widely employed in modern Machine Learning due to the huge computational gains it bestows on the statistician. Despite its popularity in practice, theoretical guarantees for high-dimensional problems are only available under strong structural assumptions (e.g. sparsity). Moreover, existing theory often does not explain empirical observations noted in the existing literature. In this paper, we take a step towards addressing these problems by deriving sharp asymptotic characterizations for the NMF approximation in high-dimensional linear regression. Our results apply to a wide class of natural priors and allow for model mismatch (i.e. the underlying statistical model can be different from the fitted model). We work under an iid Gaussian design and the proportional asymptotic regime, where the number of features and number of observations grow at a proportional rate. As a consequence of our asymptotic characterization, we establish two concrete corollaries: (a) we establish the inaccuracy of the NMF approximation for the log-normalizing constant in this regime, and (b) we provide theoretical results backing the empirical observation that the NMF approximation can be overconfident in terms of uncertainty quantification. Our results utilize recent advances in the theory of Gaussian comparison inequalities. To the best of our knowledge, this is the first application of these ideas to the analysis of Bayesian variational inference problems. Our theoretical results are corroborated by numerical experiments. Lastly, we believe our results can be generalized to non-Gaussian designs and provide empirical evidence to support it",
    "checked": true,
    "id": "d25888ad3e09bc0267b89b7edc19936e151fca88",
    "semantic_title": "sub-optimality of the naive mean field approximation for proportional high-dimensional linear regression",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=RkRrPp7GKO": {
    "title": "H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
    "volume": "poster",
    "abstract": "Large Language Models (LLMs), despite their recent impressive accomplishments, are notably cost-prohibitive to deploy, particularly for applications involving long-content generation, such as dialogue systems and story writing. Often, a large amount of transient state information, referred to as the $\\mathsf{KV}$ $\\mathsf{cache}$, is stored in GPU memory in addition to model parameters, scaling linearly with the sequence length and batch size. In this paper, we introduce a novel approach for implementing the $\\mathsf{KV}$ $\\mathsf{cache}$ which significantly reduces its memory footprint. Our approach is based on the noteworthy observation that a small portion of tokens contributes most of the value when computing attention scores. We call these tokens Heavy Hitters ($\\mathsf{H_2}$). Through a comprehensive investigation, we find that ($i$) the emergence of $\\mathsf{H_2}$ is natural and strongly correlates with the frequent co-occurrence of tokens in the text, and ($ii$) removing them results in significant performance degradation. Based on these insights, we propose Heavy Hitter Oracle ($\\mathsf{H_2O}$), a $\\mathsf{KV}$ $\\mathsf{cache}$ eviction policy that dynamically retains a balance of recent and $\\mathsf{H_2}$ tokens. We formulate the $\\mathsf{KV}$ $\\mathsf{cache}$ eviction as a dynamic submodular problem and prove (under mild assumptions) a theoretical guarantee for our novel eviction algorithm which could help guide future work. We validate the accuracy of our algorithm with OPT, LLaMA, and GPT-NeoX across a wide range of tasks. Our implementation of $\\mathsf{H_2O}$ with 20\\% heavy hitters improves the throughput over three leading inference systems DeepSpeed Zero-Inference, Hugging Face Accelerate, and FlexGen by up to $29\\times$, $29\\times$, and $3\\times$ on OPT-6.7B and OPT-30B. With the same batch size, $\\mathsf{H_2O}$ can reduce the latency by up to $1.9\\times$",
    "checked": true,
    "id": "e586a4591ba0303b769f2c07cbddaf1899cb72e4",
    "semantic_title": "h2o: heavy-hitter oracle for efficient generative inference of large language models",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=xXfDB8kJUs": {
    "title": "Learning Curves for Noisy Heterogeneous Feature-Subsampled Ridge Ensembles",
    "volume": "poster",
    "abstract": "Feature bagging is a well-established ensembling method which aims to reduce prediction variance by combining predictions of many estimators trained on subsets or projections of features. Here, we develop a theory of feature-bagging in noisy least-squares ridge ensembles and simplify the resulting learning curves in the special case of equicorrelated data. Using analytical learning curves, we demonstrate that subsampling shifts the double-descent peak of a linear predictor. This leads us to introduce heterogeneous feature ensembling, with estimators built on varying numbers of feature dimensions, as a computationally efficient method to mitigate double-descent. Then, we compare the performance of a feature-subsampling ensemble to a single linear predictor, describing a trade-off between noise amplification due to subsampling and noise reduction due to ensembling. Our qualitative insights carry over to linear classifiers applied to image classification tasks with realistic datasets constructed using a state-of-the-art deep learning feature map",
    "checked": true,
    "id": "c5a30254a1b9545fade4fc32cc1b9475649400b7",
    "semantic_title": "learning curves for noisy heterogeneous feature-subsampled ridge ensembles",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WrRG0C1Vo5": {
    "title": "Distributionally Robust Ensemble of Lottery Tickets Towards Calibrated Sparse Network Training",
    "volume": "poster",
    "abstract": "The recently developed sparse network training methods, such as Lottery Ticket Hypothesis (LTH) and its variants, have shown impressive learning capacity by finding sparse sub-networks from a dense one. While these methods could largely sparsify deep networks, they generally focus more on realizing comparable accuracy to dense counterparts yet neglect network calibration. However, how to achieve calibrated network predictions lies at the core of improving model reliability, especially when it comes to addressing the overconfident issue and out-of-distribution cases. In this study, we propose a novel Distributionally Robust Optimization (DRO) framework to achieve an ensemble of lottery tickets towards calibrated network sparsification. Specifically, the proposed DRO ensemble aims to learn multiple diverse and complementary sparse sub-networks (tickets) with the guidance of uncertainty sets, which encourage tickets to gradually capture different data distributions from easy to hard and naturally complement each other. We theoretically justify the strong calibration performance by showing how the proposed robust training process guarantees to lower the confidence of incorrect predictions. Extensive experimental results on several benchmarks show that our proposed lottery ticket ensemble leads to a clear calibration improvement without sacrificing accuracy and burdening inference costs. Furthermore, experiments on OOD datasets demonstrate the robustness of our approach in the open-set environment",
    "checked": false,
    "id": "c714f39c410eb934565b398a829edac0b6058728",
    "semantic_title": "when layers play the lottery, all tickets win at initialization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=99MHSB98yZ": {
    "title": "Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion",
    "volume": "poster",
    "abstract": "Automated creation of synthetic traffic scenarios is a key part of scaling the safety validation of autonomous vehicles (AVs). In this paper, we propose Scenario Diffusion, a novel diffusion-based architecture for generating traffic scenarios that enables controllable scenario generation. We combine latent diffusion, object detection and trajectory regression to generate distributions of synthetic agent poses, orientations and trajectories simultaneously. This distribution is conditioned on the map and sets of tokens describing the desired scenario to provide additional control over the generated scenario. We show that our approach has sufficient expressive capacity to model diverse traffic patterns and generalizes to different geographical regions",
    "checked": true,
    "id": "59a2aa5efaf04eb3dfb8bbe8499fa4f4a2d2082e",
    "semantic_title": "scenario diffusion: controllable driving scenario generation with diffusion",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=du0hvEpgj8": {
    "title": "Actively Testing Your Model While It Learns: Realizing Label-Efficient Learning in Practice",
    "volume": "poster",
    "abstract": "In active learning (AL), we focus on reducing the data annotation cost from the model training perspective. However, \"testing'', which often refers to the model evaluation process of using empirical risk to estimate the intractable true generalization risk, also requires data annotations. The annotation cost for \"testing'' (model evaluation) is under-explored. Even in works that study active model evaluation or active testing (AT), the learning and testing ends are disconnected. In this paper, we propose a novel active testing while learning (ATL) framework that integrates active learning with active testing. ATL provides an unbiased sample-efficient estimation of the model risk during active learning. It leverages test samples annotated from different periods of a dynamic active learning process to achieve fair model evaluations based on a theoretically guaranteed optimal integration of different test samples. Periodic testing also enables effective early-stopping to further save the total annotation cost. ATL further integrates an \"active feedback'' mechanism, which is inspired by human learning, where the teacher (active tester) provides immediate guidance given by the prior performance of the student (active learner). Our theoretical result reveals that active feedback maintains the label complexity of the integrated learning-testing objective, while improving the model's generalization capability. We study the realistic setting where we maximize the performance gain from choosing \"testing'' samples for feedback without sacrificing the risk estimation accuracy. An agnostic-style analysis and empirical evaluations on real-world datasets demonstrate that the ATL framework can effectively improve the annotation efficiency of both active learning and evaluation tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=77Nq1KjmLl": {
    "title": "Fragment-based Pretraining and Finetuning on Molecular Graphs",
    "volume": "poster",
    "abstract": "Property prediction on molecular graphs is an important application of Graph Neural Networks (GNNs). Recently, unlabeled molecular data has become abundant, which facilitates the rapid development of self-supervised learning for GNNs in the chemical domain. In this work, we propose pretraining GNNs at the fragment level, a promising middle ground to overcome the limitations of node-level and graph-level pretraining. Borrowing techniques from recent work on principal subgraph mining, we obtain a compact vocabulary of prevalent fragments from a large pretraining dataset. From the extracted vocabulary, we introduce several fragment-based contrastive and predictive pretraining tasks. The contrastive learning task jointly pretrains two different GNNs: one on molecular graphs and the other on fragment graphs, which represents higher-order connectivity within molecules. By enforcing consistency between the fragment embedding and the aggregated embedding of the corresponding atoms from the molecular graphs, we ensure that the embeddings capture structural information at multiple resolutions. The structural information of fragment graphs is further exploited to extract auxiliary labels for graph-level predictive pretraining. We employ both the pretrained molecular-based and fragment-based GNNs for downstream prediction, thus utilizing the fragment information during finetuning. Our graph fragment-based pretraining (GraphFP) advances the performances on 5 out of 8 common molecular benchmarks and improves the performances on long-range biological benchmarks by at least 11.5%. Code is available at: https://github.com/lvkd84/GraphFP",
    "checked": true,
    "id": "dc45bc281e3ec50346924ed410bb46370c3ac6ee",
    "semantic_title": "fragment-based pretraining and finetuning on molecular graphs",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7EMphtUgCI": {
    "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent",
    "volume": "poster",
    "abstract": "In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs via tree search, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as \"What event is commemorated by the building depicted in this image?\", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information from the tool outputs, and a working memory component that retains the acquired information throughout the process. The collected user behavior serves as a guide for our system in two key ways. First, we create a transition graph by analyzing the sequence of decisions made by users. This graph delineates distinct states and confines the set of actions available at each state. Second, we use examples of user decision-making to provide our LLM-powered planner and reasoner with relevant contextual instances, enhancing their capacity to make informed decisions. We show that AVIS achieves state-of-the-art results on knowledge-based visual question answering benchmarks such as Infoseek and OK-VQA",
    "checked": false,
    "id": "d98536f24272e258b1d399074b64284d64786099",
    "semantic_title": "avis: autonomous visual information seeking with large language models",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=tP50lLiZIo": {
    "title": "Non-Stationary Bandits with Auto-Regressive Temporal Dependency",
    "volume": "poster",
    "abstract": "Traditional multi-armed bandit (MAB) frameworks, predominantly examined under stochastic or adversarial settings, often overlook the temporal dynamics inherent in many real-world applications such as recommendation systems and online advertising. This paper introduces a novel non-stationary MAB framework that captures the temporal structure of these real-world dynamics through an auto-regressive (AR) reward structure. We propose an algorithm that integrates two key mechanisms: (i) an alternation mechanism adept at leveraging temporal dependencies to dynamically balance exploration and exploitation, and (ii) a restarting mechanism designed to discard out-of-date information. Our algorithm achieves a regret upper bound that nearly matches the lower bound, with regret measured against a robust dynamic benchmark. Finally, via a real-world case study on tourism demand prediction, we demonstrate both the efficacy of our algorithm and the broader applicability of our techniques to more complex, rapidly evolving time series",
    "checked": false,
    "id": "ec1cbde3d064f9039b2fb1a45e8a2b76981c3052",
    "semantic_title": "dynamic bandits with an auto-regressive temporal structure",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=AnFUgNC3Yc": {
    "title": "Resetting the Optimizer in Deep RL: An Empirical Study",
    "volume": "poster",
    "abstract": "We focus on the task of approximating the optimal value function in deep reinforcement learning. This iterative process is comprised of solving a sequence of optimization problems where the loss function changes per iteration. The common approach to solving this sequence of problems is to employ modern variants of the stochastic gradient descent algorithm such as Adam. These optimizers maintain their own internal parameters such as estimates of the first-order and the second-order moments of the gradient, and update them over time. Therefore, information obtained in previous iterations is used to solve the optimization problem in the current iteration. We demonstrate that this can contaminate the moment estimates because the optimization landscape can change arbitrarily from one iteration to the next one. To hedge against this negative effect, a simple idea is to reset the internal parameters of the optimizer when starting a new iteration. We empirically investigate this resetting idea by employing various optimizers in conjunction with the Rainbow algorithm. We demonstrate that this simple modification significantly improves the performance of deep RL on the Atari benchmark",
    "checked": true,
    "id": "d0eac1da5d54638fd3dc41cd1e477d804dc4d806",
    "semantic_title": "resetting the optimizer in deep rl: an empirical study",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=jS4DUGOtBD": {
    "title": "When are ensembles really effective?",
    "volume": "poster",
    "abstract": "Ensembling has a long history in statistical data analysis, with many impactful applications. However, in many modern machine learning settings, the benefits of ensembling are less ubiquitous and less obvious. We study, both theoretically and empirically, the fundamental question of when ensembling yields significant performance improvements in classification tasks. Theoretically, we prove new results relating the \\emph{ensemble improvement rate} (a measure of how much ensembling decreases the error rate versus a single model, on a relative scale) to the \\emph{disagreement-error ratio}. We show that ensembling improves performance significantly whenever the disagreement rate is large relative to the average error rate; and that, conversely, one classifier is often enough whenever the disagreement rate is low relative to the average error rate. On the way to proving these results, we derive, under a mild condition called \\emph{competence}, improved upper and lower bounds on the average test error rate of the majority vote classifier. To complement this theory, we study ensembling empirically in a variety of settings, verifying the predictions made by our theory, and identifying practical scenarios where ensembling does and does not result in large performance improvements. Perhaps most notably, we demonstrate a distinct difference in behavior between interpolating models (popular in current practice) and non-interpolating models (such as tree-based methods, where ensembling is popular), demonstrating that ensembling helps considerably more in the latter case than in the former",
    "checked": true,
    "id": "26f4ac43e9586c110cb40b8dfc6820346375bf9b",
    "semantic_title": "when are ensembles really effective?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jCPRG3FuHV": {
    "title": "Learning Repeatable Speech Embeddings Using An Intra-class Correlation Regularizer",
    "volume": "poster",
    "abstract": "A good supervised embedding for a specific machine learning task is only sensitive to changes in the label of interest and is invariant to other confounding factors. We leverage the concept of repeatability from measurement theory to describe this property and propose to use the intra-class correlation coefficient (ICC) to evaluate the repeatability of embeddings. We then propose a novel regularizer, the ICC regularizer, as a complementary component for contrastive losses to guide deep neural networks to produce embeddings with higher repeatability. We use simulated data to explain why the ICC regularizer works better on minimizing the intra-class variance than the contrastive loss alone. We implement the ICC regularizer and apply it to three speech tasks: speaker verification, voice style conversion, and a clinical application for detecting dysphonic voice. The experimental results demonstrate that adding an ICC regularizer can improve the repeatability of learned embeddings compared to only using the contrastive loss; further, these embeddings lead to improved performance in these downstream tasks",
    "checked": true,
    "id": "5c1235069150752adc87e537a40863138abbfdb8",
    "semantic_title": "learning repeatable speech embeddings using an intra-class correlation regularizer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RhE01dqo8u": {
    "title": "Feature Selection in the Contrastive Analysis Setting",
    "volume": "poster",
    "abstract": "Contrastive analysis (CA) refers to the exploration of variations uniquely enriched in a _target_ dataset as compared to a corresponding _background_ dataset generated from sources of variation that are irrelevant to a given task. For example, a biomedical data analyst may wish to find a small set of genes to use as a proxy for variations in genomic data only present among patients with a given disease (target) as opposed to healthy control subjects (background). However, as of yet the problem of feature selection in the CA setting has received little attention from the machine learning community. In this work we present contrastive feature selection (CFS), a method for performing feature selection in the CA setting. We motivate our approach with a novel information-theoretic analysis of representation learning in the CA setting, and we empirically validate CFS on a semi-synthetic dataset and four real-world biomedical datasets. We find that our method consistently outperforms previously proposed state-of-the-art supervised and fully unsupervised feature selection methods not designed for the CA setting. An open-source implementation of our method is available at https://github.com/suinleelab/CFS",
    "checked": true,
    "id": "bdd78f42f230e591a3d8c854c0a5cf85d28c5219",
    "semantic_title": "feature selection in the contrastive analysis setting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=L9nTuSbAws": {
    "title": "GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients",
    "volume": "poster",
    "abstract": "Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of \\textbf{most important parameters} of the pre-trained network over In-Distribution data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on \\textit{the subspaces considered \\textbf{important} for the in-distribution data}. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the in-distribution (ID) data. This simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate at a 95\\% true positive rate (FPR95) of up to 8\\% when compared to the current state-of-the-art methods",
    "checked": true,
    "id": "6db1cc71f6cfad8d7a9e09882711c722766562b6",
    "semantic_title": "gradorth: a simple yet efficient out-of-distribution detection with orthogonal projection of gradients",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Nr1XSeDzpn": {
    "title": "On the Convergence to a Global Solution of Shuffling-Type Gradient Algorithms",
    "volume": "poster",
    "abstract": "Stochastic gradient descent (SGD) algorithm is the method of choice in many machine learning tasks thanks to its scalability and efficiency in dealing with large-scale problems. In this paper, we focus on the shuffling version of SGD which matches the mainstream practical heuristics. We show the convergence to a global solution of shuffling SGD for a class of non-convex functions under over-parameterized settings. Our analysis employs more relaxed non-convex assumptions than previous literature. Nevertheless, we maintain the desired computational complexity as shuffling SGD has achieved in the general convex setting",
    "checked": true,
    "id": "b142814c2ef07f8ad60364840b2c53d06ae6f776",
    "semantic_title": "on the convergence to a global solution of shuffling-type gradient algorithms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zEm6hF97Pz": {
    "title": "(Amplified) Banded Matrix Factorization: A unified approach to private training",
    "volume": "poster",
    "abstract": "Matrix factorization (MF) mechanisms for differential privacy (DP) have substantially improved the state-of-the-art in privacy-utility-computation tradeoffs for ML applications in a variety of scenarios, but in both the centralized and federated settings there remain instances where either MF cannot be easily applied, or other algorithms provide better tradeoffs (typically, as $\\epsilon$ becomes small). In this work, we show how MF can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. The key technique throughout is the construction of MF mechanisms with banded matrices (lower-triangular matrices with at most $\\hat{b}$ nonzero bands including the main diagonal). For cross-device federated learning (FL), this enables multiple-participations with a relaxed device participation schema compatible with practical FL infrastructure (as demonstrated by a production deployment). In the centralized setting, we prove that banded matrices enjoy the same privacy amplification results as the ubiquitous DP-SGD algorithm, but can provide strictly better performance in most scenarios---this lets us always at least match DP-SGD, and often outperform it",
    "checked": true,
    "id": "fdefa635f2a399a75a04f3ee78391e1a90e51c75",
    "semantic_title": "(amplified) banded matrix factorization: a unified approach to private training",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=1h7Uh9zUXc": {
    "title": "Reliable learning in challenging environments",
    "volume": "poster",
    "abstract": "The problem of designing learners that provide guarantees that their predictions are provably correct is of increasing importance in machine learning. However, learning theoretic guarantees have only been considered in very specific settings. In this work, we consider the design and analysis of reliable learners in challenging test-time environments as encountered in modern machine learning problems: namely adversarial test-time attacks (in several variations) and natural distribution shifts. In this work, we provide a reliable learner with provably optimal guarantees in such settings. We discuss computationally feasible implementations of the learner and further show that our algorithm achieves strong positive performance guarantees on several natural examples: for example, linear separators under log-concave distributions or smooth boundary classifiers under smooth probability distributions",
    "checked": true,
    "id": "8b8baff695364de1f06789bcfae81afa12402ddc",
    "semantic_title": "reliable learning in challenging environments",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZFwNdsDCRL": {
    "title": "Learning to Reason and Memorize with Self-Notes",
    "volume": "poster",
    "abstract": "Large language models have been shown to struggle with multi-step reasoning, and do not retain previous reasoning steps for future use. We propose a simple method for solving both of these problems by allowing the model to take Self-Notes. Unlike recent chain-of-thought or scratchpad approaches, the model can deviate from the input context at any time to explicitly think and write down its thoughts. This allows the model to perform reasoning on the fly as it reads the context and even integrate previous reasoning steps, thus enhancing its memory with useful information and enabling multi-step reasoning. Experiments across a wide variety of tasks demonstrate that our method can outperform chain-of-thought and scratchpad methods by taking Self-Notes that interleave the input text",
    "checked": true,
    "id": "1db6836f61695e558608bb57166feca6876edabf",
    "semantic_title": "learning to reason and memorize with self-notes",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=P3n4wFJGs5": {
    "title": "Window-Based Distribution Shift Detection for Deep Neural Networks",
    "volume": "poster",
    "abstract": "To deploy and operate deep neural models in production, the quality of their predictions, which might be contaminated benignly or manipulated maliciously by input distributional deviations, must be monitored and assessed. Specifically, we study the case of monitoring the healthy operation of a deep neural network (DNN) receiving a stream of data, with the aim of detecting input distributional deviations over which the quality of the network's predictions is potentially damaged. Using selective prediction principles, we propose a distribution deviation detection method for DNNs. The proposed method is derived from a tight coverage generalization bound computed over a sample of instances drawn from the true underlying distribution. Based on this bound, our detector continuously monitors the operation of the network over a test window and fires off an alarm whenever a deviation is detected. Our novel detection method performs on-par or better than the state-of-the-art, while consuming substantially lower computation time (five orders of magnitude reduction) and space complexity. Unlike previous methods, which require at least linear dependence on the size of the source distribution for each detection, rendering them inapplicable to ``Google-Scale'' datasets, our approach eliminates this dependence, making it suitable for real-world applications. Code is available at [https://github.com/BarSGuy/Window-Based-Distribution-Shift-Detection](https://github.com/BarSGuy/Window-Based-Distribution-Shift-Detection)",
    "checked": true,
    "id": "11462c53277ae86727ed34d2987b9433ab6d51e7",
    "semantic_title": "window-based distribution shift detection for deep neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o778eWSr1S": {
    "title": "Label-Retrieval-Augmented Diffusion Models for Learning from Noisy Labels",
    "volume": "poster",
    "abstract": "Learning from noisy labels is an important and long-standing problem in machine learning for real applications. One of the main research lines focuses on learning a label corrector to purify potential noisy labels. However, these methods typically rely on strict assumptions and are limited to certain types of label noise. In this paper, we reformulate the label-noise problem from a generative-model perspective, *i.e.*, labels are generated by gradually refining an initial random guess. This new perspective immediately enables existing powerful diffusion models to seamlessly learn the stochastic generative process. Once the generative uncertainty is modeled, we can perform classification inference using maximum likelihood estimation of labels. To mitigate the impact of noisy labels, we propose the **L**abel-**R**etrieval-**A**ugmented (LRA) diffusion model, which leverages neighbor consistency to effectively construct pseudo-clean labels for diffusion training. Our model is flexible and general, allowing easy incorporation of different types of conditional information, *e.g.*, use of pre-trained models, to further boost model performance. Extensive experiments are conducted for evaluation. Our model achieves new state-of-the-art (SOTA) results on all the standard real-world benchmark datasets. Remarkably, by incorporating conditional information from the powerful CLIP model, our method can boost the current SOTA accuracy by 10-20 absolute points in many cases. Code is available: https://anonymous.4open.science/r/LRA-diffusion-5F2F",
    "checked": true,
    "id": "c92bca32e8244dfb394c2defa85f93380fb59928",
    "semantic_title": "label-retrieval-augmented diffusion models for learning from noisy labels",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9S8oVumknA": {
    "title": "Intervention Generalization: A View from Factor Graph Models",
    "volume": "poster",
    "abstract": "One of the goals of causal inference is to generalize from past experiments and observational data to novel conditions. While it is in principle possible to eventually learn a mapping from a novel experimental condition to an outcome of interest, provided a sufficient variety of experiments is available in the training data, coping with a large combinatorial space of possible interventions is hard. Under a typical sparse experimental design, this mapping is ill-posed without relying on heavy regularization or prior distributions. Such assumptions may or may not be reliable, and can be hard to defend or test. In this paper, we take a close look at how to warrant a leap from past experiments to novel conditions based on minimal assumptions about the factorization of the distribution of the manipulated system, communicated in the well-understood language of factor graph models. A postulated interventional factor model (IFM) may not always be informative, but it conveniently abstracts away a need for explicitly modeling unmeasured confounding and feedback mechanisms, leading to directly testable claims. Given an IFM and datasets from a collection of experimental regimes, we derive conditions for identifiability of the expected outcomes of new regimes never observed in these training data. We implement our framework using several efficient algorithms, and apply them on a range of semi-synthetic experiments",
    "checked": true,
    "id": "3b1bff79a0dd9babe86e7897a065a1e12f1635e1",
    "semantic_title": "intervention generalization: a view from factor graph models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7rm3OcASkg": {
    "title": "DP-Mix: Mixup-based Data Augmentation for Differentially Private Learning",
    "volume": "poster",
    "abstract": "Data augmentation techniques, such as simple image transformations and combinations, are highly effective at improving the generalization of computer vision models, especially when training data is limited. However, such techniques are fundamentally incompatible with differentially private learning approaches, due to the latter's built-in assumption that each training image's contribution to the learned model is bounded. In this paper, we investigate why naive applications of multi-sample data augmentation techniques, such as mixup, fail to achieve good performance and propose two novel data augmentation techniques specifically designed for the constraints of differentially private learning. Our first technique, DP-Mix_Self, achieves SoTA classification performance across a range of datasets and settings by performing mixup on self-augmented data. Our second technique, DP-Mix_Diff, further improves performance by incorporating synthetic data from a pre-trained diffusion model into the mixup process. We open-source the code at https://github.com/wenxuan-Bao/DP-Mix",
    "checked": true,
    "id": "985b98d742e5938909985789cbe531e3bb284ed8",
    "semantic_title": "dp-mix: mixup-based data augmentation for differentially private learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p53QDxSIc5": {
    "title": "DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction",
    "volume": "poster",
    "abstract": "There is currently a significant gap between the performance of fine-tuned models and prompting approaches using Large Language Models (LLMs) on the challenging task of text-to-SQL, as evaluated on datasets such as Spider. To improve the performance of LLMs in the reasoning process, we study how decomposing the task into smaller sub-tasks can be effective. In particular, we show that breaking down the generation problem into sub-problems and feeding the solutions of those sub-problems into LLMs can be an effective approach for significantly improving their performance. Our experiments with three LLMs show that this approach consistently improves their simple few-shot performance by roughly 10%, pushing the accuracy of LLMs towards SOTA or surpassing it. On the holdout test set of Spider, the SOTA, in terms of execution accuracy, was 79.9 and the new SOTA at the time of this writing using our approach is 85.3. Our approach with in-context learning beats many heavily fine-tuned models by at least 5%. Additionally, when evaluated on the BIRD benchmark, our approach achieved an execution accuracy of 55.9%, setting a new SOTA on its holdout test set",
    "checked": true,
    "id": "cc0f0cb09a73f82ed44d900f5ca710bec784acc1",
    "semantic_title": "din-sql: decomposed in-context learning of text-to-sql with self-correction",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=XPWEtXzlLy": {
    "title": "Mirror Diffusion Models for Constrained and Watermarked Generation",
    "volume": "poster",
    "abstract": "Modern successes of diffusion models in learning complex, high-dimensional data distributions are attributed, in part, to their capability to construct diffusion processes with analytic transition kernels and score functions. The tractability results in a simulation-free framework with stable regression losses, from which reversed, generative processes can be learned at scale. However, when data is confined to a constrained set as opposed to a standard Euclidean space, these desirable characteristics appear to be lost based on prior attempts. In this work, we propose Mirror Diffusion Models (MDM), a new class of diffusion models that generate data on convex constrained sets without losing any tractability. This is achieved by learning diffusion processes in a dual space constructed from a mirror map, which, crucially, is a standard Euclidean space. We derive efficient computation of mirror maps for popular constrained sets, such as simplices and $\\ell_2$-balls, showing significantly improved performance of MDM over existing methods. For safety and privacy purposes, we also explore constrained sets as a new mechanism to embed invisible but quantitative information (i.e., watermarks) in generated data, for which MDM serves as a compelling approach. Our work brings new algorithmic opportunities for learning tractable diffusion on complex domains",
    "checked": true,
    "id": "79c95a0f90dd6d20bc038338861850a27e862f93",
    "semantic_title": "mirror diffusion models for constrained and watermarked generation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XlvsieCnAX": {
    "title": "Exact Representation of Sparse Networks with Symmetric Nonnegative Embeddings",
    "volume": "poster",
    "abstract": "Graph models based on factorization of the adjacency matrix often fail to capture network structures related to links between dissimilar nodes (heterophily). We introduce a novel graph factorization model that leverages two nonnegative vectors per node to interpretably account for links between both similar and dissimilar nodes. We prove that our model can exactly represent any graph with low *arboricity*, a property that many real-world networks satisfy; our proof also applies to related models but has much greater scope than the closest prior bound, which is based on low *max degree*. Our factorization also has compelling properties besides expressiveness: due to its symmetric structure and nonnegativity, fitting the model inherently finds node communities, and the model's link predictions can be interpreted in terms of these communities. In experiments on real-world networks, we demonstrate our factorization's effectiveness on a variety of tasks, including community detection and link prediction",
    "checked": true,
    "id": "ddc08e96d4d52c34bc9f9e61a77b7c59be179a21",
    "semantic_title": "exact representation of sparse networks with symmetric nonnegative embeddings",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1EYKYJeZtR": {
    "title": "Large language models transition from integrating across position-yoked, exponential windows to structure-yoked, power-law windows",
    "volume": "poster",
    "abstract": "Modern language models excel at integrating across long temporal scales needed to encode linguistic meaning and show non-trivial similarities to biological neural systems. Prior work suggests that human brain responses to language exhibit hierarchically organized \"integration windows\" that substantially constrain the overall influence of an input token (e.g., a word) on the neural response. However, little prior work has attempted to use integration windows to characterize computations in large language models (LLMs). We developed a simple word-swap procedure for estimating integration windows from black-box language models that does not depend on access to gradients or knowledge of the model architecture (e.g., attention weights). Using this method, we show that trained LLMs exhibit stereotyped integration windows that are well-fit by a convex combination of an exponential and a power-law function, with a partial transition from exponential to power-law dynamics across network layers. We then introduce a metric for quantifying the extent to which these integration windows vary with structural boundaries (e.g., sentence boundaries), and using this metric, we show that integration windows become increasingly yoked to structure at later network layers. None of these findings were observed in an untrained model, which as expected integrated uniformly across its input. These results suggest that LLMs learn to integrate information in natural language using a stereotyped pattern: integrating across position-yoked, exponential windows at early layers, followed by structure-yoked, power-law windows at later layers. The methods we describe in this paper provide a general-purpose toolkit for understanding temporal integration in language models, facilitating cross-disciplinary research at the intersection of biological and artificial intelligence",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bAI21VEMvM": {
    "title": "Marich: A Query-efficient Distributionally Equivalent Model Extraction Attack",
    "volume": "poster",
    "abstract": "We study design of black-box model extraction attacks that can *send minimal number of queries from* a *publicly available dataset* to a target ML model through a predictive API with an aim *to create an informative and distributionally equivalent replica* of the target. First, we define *distributionally equivalent* and *Max-Information model extraction* attacks, and reduce them into a variational optimisation problem. The attacker sequentially solves this optimisation problem to select the most informative queries that simultaneously maximise the entropy and reduce the mismatch between the target and the stolen models. This leads to *an active sampling-based query selection algorithm*, Marich, which is *model-oblivious*. Then, we evaluate Marich on different text and image data sets, and different models, including CNNs and BERT. Marich extracts models that achieve $\\sim 60-95\\%$ of true model's accuracy and uses $\\sim 1,000 - 8,500$ queries from the publicly available datasets, which are different from the private training datasets. Models extracted by Marich yield prediction distributions, which are $\\sim2-4\\times$ closer to the target's distribution in comparison to the existing active sampling-based attacks. The extracted models also lead to 84-96$\\%$ accuracy under membership inference attacks. Experimental results validate that Marich is *query-efficient*, and capable of performing task-accurate, high-fidelity, and informative model extraction",
    "checked": false,
    "id": "b885e291f660df34d9f22777dc0678bdf8e0860d",
    "semantic_title": "marich: a query-efficient distributionally equivalent model extraction attack using public data",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=fmJv8Hj0yo": {
    "title": "Are Diffusion Models Vision-And-Language Reasoners?",
    "volume": "poster",
    "abstract": "Text-conditioned image generation models have recently shown immense qualitative success using denoising diffusion processes. However, unlike discriminative vision-and-language models, it is a non-trivial task to subject these diffusion-based generative models to automatic fine-grained quantitative evaluation of high-level phenomena such as compositionality. Towards this goal, we perform two innovations. First, we transform diffusion-based models (in our case, Stable Diffusion) for any image-text matching (ITM) task using a novel method called DiffusionITM. Second, we introduce the Generative-Discriminative Evaluation Benchmark (GDBench) benchmark with 7 complex vision-and-language tasks, bias evaluation and detailed analysis. We find that Stable Diffusion + DiffusionITM is competitive on many tasks and outperforms CLIP on compositional tasks like like CLEVR and Winoground. We further boost its compositional performance with a transfer setup by fine-tuning on MS-COCO while retaining generative capabilities. We also measure the stereotypical bias in diffusion models, and find that Stable Diffusion 2.1 is, for the most part, less biased than Stable Diffusion 1.5. Overall, our results point in an exciting direction bringing discriminative and generative model evaluation closer. We will release code and benchmark setup soon",
    "checked": true,
    "id": "14cb918ee6b9aab981c7b01c2c4db3ee4016abae",
    "semantic_title": "are diffusion models vision-and-language reasoners?",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=zMeemcUeXL": {
    "title": "FAMO: Fast Adaptive Multitask Optimization",
    "volume": "poster",
    "abstract": "One of the grand enduring goals of AI is to create generalist agents that can learn multiple different tasks from diverse data via multitask learning (MTL). However, in practice, applying gradient descent (GD) on the average loss across all tasks may yield poor multitask performance due to severe under-optimization of certain tasks. Previous approaches that manipulate task gradients for a more balanced loss decrease require storing and computing all task gradients ($\\mathcal{O}(k)$ space and time where $k$ is the number of tasks), limiting their use in large-scale scenarios. In this work, we introduce Fast Adaptive Multitask Optimization (FAMO), a dynamic weighting method that decreases task losses in a balanced way using $\\mathcal{O}(1)$ space and time. We conduct an extensive set of experiments covering multi-task supervised and reinforcement learning problems. Our results indicate that FAMO achieves comparable or superior performance to state-of-the-art gradient manipulation techniques while offering significant improvements in space and computational efficiency. Code is available at \\url{https://github.com/Cranial-XIX/FAMO}",
    "checked": true,
    "id": "ed71aa500f70a254bbf14a90d5ea7d927be12df9",
    "semantic_title": "famo: fast adaptive multitask optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gUTVpByfVX": {
    "title": "Test-time Adaptation of Discriminative Models via Diffusion Generative Feedback",
    "volume": "poster",
    "abstract": "The advancements in generative modeling, particularly the advent of diffusion models, have sparked a fundamental question: how can these models be effectively used for discriminative tasks? In this work, we find that generative models can be great test-time adapters for discriminative models. Our method, Diffusion-TTA, adapts pre-trained discriminative models such as image classifiers, segmenters and depth predictors, to each unlabelled example in the test set using generative feedback from a diffusion model. We achieve this by modulating the conditioning of the diffusion model using the output of the discriminative model. We then maximize the image likelihood objective by backpropagating the gradients to discriminative model's parameters. We show Diffusion-TTA significantly enhances the accuracy of various large-scale pre-trained discriminative models, such as, ImageNet classifiers, CLIP models, image pixel labellers and image depth predictors. Diffusion-TTA outperforms existing test-time adaptation methods, including TTT-MAE and TENT, and particularly shines in online adaptation setups, where the discriminative model is continually adapted to each example in the test set. We provide access to code, results, and visualizations on our website: https://diffusion-tta.github.io/",
    "checked": true,
    "id": "591f08f6252f2f5a894d3370b9c4d9458288d827",
    "semantic_title": "test-time adaptation of discriminative models via diffusion generative feedback",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7JuReDmGSL": {
    "title": "Adaptive Contextual Perception: How To Generalize To New Backgrounds and Ambiguous Objects",
    "volume": "poster",
    "abstract": "Biological vision systems make adaptive use of context to recognize objects in new settings with novel contexts as well as occluded or blurry objects in familiar settings. In this paper, we investigate how vision models adaptively use context for out-of-distribution (OOD) generalization and leverage our analysis results to improve model OOD generalization. First, we formulate two distinct OOD settings where the contexts are either beneficial Object-Disambiguation or irrelevant Background-Invariance, reflecting the diverse contextual challenges faced in biological vision. We then analyze model performance in these two different OOD settings and demonstrate that models that excel in one setting tend to struggle in the other. Notably, prior works on learning causal features improve on one setting but hurt on the other. This underscores the importance of generalizing across both OOD settings, as this ability is crucial for both human cognition and robust AI systems. Next, to better understand the model properties contributing to OOD generalization, we use representational geometry analysis and our own probing methods to examine a population of models, and we discover that those with more factorized representations and appropriate feature weighting are more successful in handling Object-Disambiguation and Background-Invariance tests. We further validate these findings through causal intervention, manipulating representation factorization and feature weighting to demonstrate their causal effect on performance. Motivated by our analysis results, we propose new augmentation methods aimed at enhancing model generalization. The proposed methods outperform strong baselines, yielding improvements in both in-distribution and OOD tests. We conclude that, in order to replicate the generalization abilities of biological vision, computer vision models must have factorized object vs. background representations and appropriately weigh both kinds of features",
    "checked": true,
    "id": "89fda53715e67259a95104b7e58bfd0782d12a47",
    "semantic_title": "adaptive contextual perception: how to generalize to new backgrounds and ambiguous objects",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yGs9vTRjaE": {
    "title": "What Can We Learn from Unlearnable Datasets?",
    "volume": "poster",
    "abstract": "In an era of widespread web scraping, unlearnable dataset methods have the potential to protect data privacy by preventing deep neural networks from generalizing. But in addition to a number of practical limitations that make their use unlikely, we make a number of findings that call into question their ability to safeguard data. First, it is widely believed that neural networks trained on unlearnable datasets only learn shortcuts, simpler rules that are not useful for generalization. In contrast, we find that networks actually can learn useful features that can be reweighed for high test performance, suggesting that image protection is not assured. Unlearnable datasets are also believed to induce learning shortcuts through linear separability of added perturbations. We provide a counterexample, demonstrating that linear separability of perturbations is not a necessary condition. To emphasize why linearly separable perturbations should not be relied upon, we propose an orthogonal projection attack which allows learning from unlearnable datasets published in ICML 2021 and ICLR 2023. Our proposed attack is significantly less complex than recently proposed techniques",
    "checked": true,
    "id": "160f49ae4999c3e37967f6b698bf1d0dfa828db5",
    "semantic_title": "what can we learn from unlearnable datasets?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kPfd3pcwHV": {
    "title": "Online Ad Allocation with Predictions",
    "volume": "poster",
    "abstract": "Display Ads and the generalized assignment problem are two well-studied online packing problems with important applications in ad allocation and other areas. In both problems, ad impressions arrive online and have to be allocated immediately to budget-constrained advertisers. Worst-case algorithms that achieve the ideal competitive ratio are known for both problems, but might act overly conservative given the predictable and usually tame nature of real-world input. Given this discrepancy, we develop an algorithm for both problems that incorporate machine-learned predictions and can thus improve the performance beyond the worst-case. Our algorithm is based on the work of Feldman et al. (2009) and similar in nature to Mahdian et al. (2007) who were the first to develop a learning-augmented algorithm for the related, but more structured Ad Words problem. We use a novel analysis to show that our algorithm is able to capitalize on a good prediction, while being robust against poor predictions. We experimentally evaluate our algorithm on synthetic and real-world data on a wide range of predictions. Our algorithm is consistently outperforming the worst-case algorithm without predictions",
    "checked": true,
    "id": "0a8a7deaeb94c32967e89e97afd45151c73816c8",
    "semantic_title": "online ad allocation with predictions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PYASzxr2OP": {
    "title": "Eliciting User Preferences for Personalized Multi-Objective Decision Making through Comparative Feedback",
    "volume": "poster",
    "abstract": "In this work, we propose a multi-objective decision making framework that accommodates different user preferences over objectives, where preferences are learned via policy comparisons. Our model consists of a known Markov decision process with a vector-valued reward function, with each user having an unknown preference vector that expresses the relative importance of each objective. The goal is to efficiently compute a near-optimal policy for a given user. We consider two user feedback models. We first address the case where a user is provided with two policies and returns their preferred policy as feedback. We then move to a different user feedback model, where a user is instead provided with two small weighted sets of representative trajectories and selects the preferred one. In both cases, we suggest an algorithm that finds a nearly optimal policy for the user using a number of comparison queries that scales quasilinearly in the number of objectives",
    "checked": true,
    "id": "9001e28c3c1bf4a575d7765168e9c3baea2de0c8",
    "semantic_title": "eliciting user preferences for personalized multi-objective decision making through comparative feedback",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N6FhEMnxCU": {
    "title": "Label Robust and Differentially Private Linear Regression: Computational and Statistical Efficiency",
    "volume": "poster",
    "abstract": "We study the canonical problem of linear regression under $(\\varepsilon,\\delta)$-differential privacy when the datapoints are sampled i.i.d.~from a distribution and a fraction of response variables are adversarially corrupted. We provide the first provably efficient -- both computationally and statistically -- method for this problem, assuming standard assumptions on the data distribution. Our algorithm is a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two key innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. Our method requires only linear time in input size, and still matches the information theoretical optimal sample complexity up to a data distribution dependent condition number factor. Interestingly, the same algorithm, when applied to a setting where there is no adversarial corruption, still improves upon the existing state-of-the-art and achieves a near optimal sample complexity",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G3aubF5Wnw": {
    "title": "On the Sublinear Regret of GP-UCB",
    "volume": "poster",
    "abstract": "In the kernelized bandit problem, a learner aims to sequentially compute the optimum of a function lying in a reproducing kernel Hilbert space given only noisy evaluations at sequentially chosen points. In particular, the learner aims to minimize regret, which is a measure of the suboptimality of the choices made. Arguably the most popular algorithm is the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, which involves acting based on a simple linear estimator of the unknown function. Despite its popularity, existing analyses of GP-UCB give a suboptimal regret rate, which fails to be sublinear for many commonly used kernels such as the Matern kernel. This has led to a longstanding open question: are existing regret analyses for GP-UCB tight, or can bounds be improved by using more sophisticated analytical techniques? In this work, we resolve this open question and show that GP-UCB enjoys nearly optimal regret. In particular, our results yield sublinear regret rates for the Matern kernel, improving over the state-of-the-art analyses and partially resolving a COLT open problem posed by Vakili et al. Our improvements rely on a key technical contribution --- regularizing kernel ridge estimators in proportion to the smoothness of the underlying kernel $k$. Applying this key idea together with a largely overlooked concentration result in separable Hilbert spaces (for which we provide an independent, simplified derivation), we are able to provide a tighter analysis of the GP-UCB algorithm",
    "checked": true,
    "id": "6cc825b25d30c01264783e4fba8ce5aedfa032a5",
    "semantic_title": "on the sublinear regret of gp-ucb",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=RPFd3D3P3L": {
    "title": "On Imitation in Mean-field Games",
    "volume": "poster",
    "abstract": "We explore the problem of imitation learning (IL) in the context of mean-field games (MFGs), where the goal is to imitate the behavior of a population of agents following a Nash equilibrium policy according to some unknown payoff function. IL in MFGs presents new challenges compared to single-agent IL, particularly when both the reward function and the transition kernel depend on the population distribution. In this paper, departing from the existing literature on IL for MFGs, we introduce a new solution concept called the Nash imitation gap. Then we show that when only the reward depends on the population distribution, IL in MFGs can be reduced to single-agent IL with similar guarantees. However, when the dynamics is population-dependent, we provide a novel upper-bound that suggests IL is harder in this setting. To address this issue, we propose a new adversarial formulation where the reinforcement learning problem is replaced by a mean-field control (MFC) problem, suggesting progress in IL within MFGs may have to build upon MFC",
    "checked": true,
    "id": "3e41362120a618396209f87a615a8f33c36d2a35",
    "semantic_title": "on imitation in mean-field games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sf17j2pkCU": {
    "title": "Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates",
    "volume": "poster",
    "abstract": "There has been an increasing interest in using symbolic models along with reinforcement learning (RL) problems, where these coarser abstract models are used as a way to provide RL agents with higher level guidance. However, most of these works are inherently limited by their assumption of having an access to a symbolic approximation of the underlying problem. To address this issue, we introduce a new method for learning optimistic symbolic approximations of the underlying world model. We will see how these representations, coupled with fast diverse planners developed by the automated planning community, provide us with a new paradigm for optimistic exploration in sparse reward settings. We investigate the possibility of speeding up the learning process by generalizing learned model dynamics across similar actions with minimal human input. Finally, we evaluate the method, by testing it on multiple benchmark domains and compare it with other RL strategies",
    "checked": false,
    "id": "e66d55565f6cd6336f92be01b4efc7e6a1eb2381",
    "semantic_title": "optimistic active exploration of dynamical systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6cJKcIxPck": {
    "title": "Strategic Classification under Unknown Personalized Manipulation",
    "volume": "poster",
    "abstract": "We study the fundamental mistake bound and sample complexity in the strategic classification, where agents can strategically manipulate their feature vector up to an extent in order to be predicted as positive. For example, given a classifier determining college admission, student candidates may try to take easier classes to improve their GPA, retake SAT and change schools in an effort to fool the classifier. *Ball manipulations* are a widely studied class of manipulations in the literature, where agents can modify their feature vector within a bounded radius ball. Unlike most prior work, our work consider manipulations to be *personalized*, meaning that agents can have different levels of manipulation abilities (e.g., varying radii for ball manipulations), and *unknown* to the learner. We formalize the learning problem in an interaction model where the learner first deploys a classifier and the agent manipulates the feature vector within their manipulation set to game the deployed classifier. We investigate various scenarios in terms of the information available to the learner during the interaction, such as observing the original feature vector before or after deployment, observing the manipulated feature vector, or not seeing either the original or the manipulated feature vector. We begin by providing online mistake bounds and PAC sample complexity in these scenarios for ball manipulations. We also explore non-ball manipulations and show that, even in the simplest scenario where both the original and the manipulated feature vectors are revealed, the mistake bounds and sample complexity are lower bounded by $\\Omega(|\\mathcal H|)$ when the target function belongs to a known class $\\mathcal H$",
    "checked": true,
    "id": "af269ebec60237ecf1420055f10d74255fd9cda3",
    "semantic_title": "strategic classification under unknown personalized manipulation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=UzUhiKACmS": {
    "title": "$k$-Means Clustering with Distance-Based Privacy",
    "volume": "poster",
    "abstract": "In this paper, we initiate the study of Euclidean clustering with Distance-based privacy. Distance-based privacy is motivated by the fact that it is often only needed to protect the privacy of exact, rather than approximate, locations. We provide constant-approximate algorithms for $k$-means and $k$-median clustering, with additive error depending only on the attacker's precision bound $\\rho$, rather than the radius $\\Lambda$ of the space. In addition, we empirically demonstrate that our algorithm performs significantly better than previous differentially private clustering algorithms, as well as naive distance-based private clustering baselines",
    "checked": false,
    "id": "f8dfc8a4ce50d4a2be8d7b2bda75897a381cc350",
    "semantic_title": "fuzzy k-means clustering with discriminative embedding",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=DVlawv2rSI": {
    "title": "RoboCLIP: One Demonstration is Enough to Learn Robot Policies",
    "volume": "poster",
    "abstract": "Reward specification is a notoriously difficult problem in reinforcement learning, requiring extensive expert supervision to design robust reward functions. Imitation learning (IL) methods attempt to circumvent these problems by utilizing expert demonstrations instead of using an extrinsic reward function but typically require a large number of in-domain expert demonstrations. Inspired by advances in the field of Video-and-Language Models (VLMs), we present RoboCLIP, an online imitation learning method that uses a single demonstration (overcoming the large data requirement) in the form of a video demonstration or a textual description of the task to generate rewards without manual reward function design. Additionally, RoboCLIP can also utilize out-of-domain demonstrations, like videos of humans solving the task for reward generation, circumventing the need to have the same demonstration and deployment domains. RoboCLIP utilizes pretrained VLMs without any finetuning for reward generation. Reinforcement learning agents trained with RoboCLIP rewards demonstrate 2-3 times higher zero-shot performance than competing imitation learning methods on downstream robot manipulation tasks, doing so using only one video/text demonstration. Visit our website at https://sites.google.com/view/roboclip/home for experiment videos",
    "checked": true,
    "id": "8c9e95f32982ca21a7e4ef9c986aaa934cb11293",
    "semantic_title": "roboclip: one demonstration is enough to learn robot policies",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GGIA1p9fDT": {
    "title": "CORNN: Convex optimization of recurrent neural networks for rapid inference of neural dynamics",
    "volume": "poster",
    "abstract": "Advances in optical and electrophysiological recording technologies have made it possible to record the dynamics of thousands of neurons, opening up new possibilities for interpreting and controlling large neural populations in behaving animals. A promising way to extract computational principles from these large datasets is to train data-constrained recurrent neural networks (dRNNs). Performing this training in real-time could open doors for research techniques and medical applications to model and control interventions at single-cell resolution and drive desired forms of animal behavior. However, existing training algorithms for dRNNs are inefficient and have limited scalability, making it a challenge to analyze large neural recordings even in offline scenarios. To address these issues, we introduce a training method termed Convex Optimization of Recurrent Neural Networks (CORNN). In studies of simulated recordings, CORNN attained training speeds $\\sim$100-fold faster than traditional optimization approaches while maintaining or enhancing modeling accuracy. We further validated CORNN on simulations with thousands of cells that performed simple computations such as those of a 3-bit flip-flop or the execution of a timed response. Finally, we showed that CORNN can robustly reproduce network dynamics and underlying attractor structures despite mismatches between generator and inference models, severe subsampling of observed neurons, or mismatches in neural time-scales. Overall, by training dRNNs with millions of parameters in subminute processing times on a standard computer, CORNN constitutes a first step towards real-time network reproduction constrained on large-scale neural recordings and a powerful computational tool for advancing the understanding of neural computation",
    "checked": true,
    "id": "fa360f5c6aeb7fb7e88f89252bae855f1033e520",
    "semantic_title": "cornn: convex optimization of recurrent neural networks for rapid inference of neural dynamics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hz10oiVMNE": {
    "title": "CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss",
    "volume": "poster",
    "abstract": "This paper considers contrastive training for cross-modal 0-shot transfer wherein a pre-trained model in one modality is used for representation learning in another domain using pairwise data. The learnt models in the latter domain can then be used for a diverse set of tasks in a 0-shot way, similar to Contrastive Language-Image Pre-training (CLIP) and Locked-image Tuning (LiT) that have recently gained considerable attention. Classical contrastive training employs sets of positive and negative examples to align similar and repel dissimilar training data samples. However, similarity amongst training examples has a more continuous nature, thus calling for a more `non-binary' treatment. To address this, we propose a new contrastive loss function called Continuously Weighted Contrastive Loss (CWCL) that employs a continuous measure of similarity. With CWCL, we seek to transfer the structure of the embedding space from one modality to another. Owing to the continuous nature of similarity in the proposed loss function, these models outperform existing methods for 0-shot transfer across multiple models, datasets and modalities. By using publicly available datasets, we achieve 5-8% (absolute) improvement over previous state-of-the-art methods in 0-shot image classification and 20-30% (absolute) improvement in 0-shot speech-to-intent classification and keyword classification",
    "checked": true,
    "id": "4c6fe77be1787d76ef3a5337759ecdcccae122c1",
    "semantic_title": "cwcl: cross-modal transfer with continuously weighted contrastive loss",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8OTPepXzeh": {
    "title": "Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models",
    "volume": "poster",
    "abstract": "Learning from human feedback has been shown to improve text-to-image models. These techniques first learn a reward function that captures what humans care about in the task and then improve the models based on the learned reward function. Even though relatively simple approaches (e.g., rejection sampling based on reward scores) have been investigated, fine-tuning text-to-image models with the reward function remains challenging. In this work, we propose using online reinforcement learning (RL) to fine-tune text-to-image models. We focus on diffusion models, defining the fine-tuning task as an RL problem, and updating the pre-trained text-to-image diffusion models using policy gradient to maximize the feedback-trained reward. Our approach, coined DPOK, integrates policy optimization with KL regularization. We conduct an analysis of KL regularization for both RL fine-tuning and supervised fine-tuning. In our experiments, we show that DPOK is generally superior to supervised fine-tuning with respect to both image-text alignment and image quality. Our code is available at https://github.com/google-research/google-research/tree/master/dpok",
    "checked": false,
    "id": "a553bf27d801d09f667fe121c0ba9632257f364b",
    "semantic_title": "dpok: reinforcement learning for fine-tuning text-to-image diffusion models",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=lT9n36RH1w": {
    "title": "Unconstrained Dynamic Regret via Sparse Coding",
    "volume": "poster",
    "abstract": "Motivated by the challenge of nonstationarity in sequential decision making, we study Online Convex Optimization (OCO) under the coupling of two problem structures: the domain is unbounded, and the comparator sequence $u_1,\\ldots,u_T$ is arbitrarily time-varying. As no algorithm can guarantee low regret simultaneously against all comparator sequences, handling this setting requires moving from minimax optimality to comparator adaptivity. That is, sensible regret bounds should depend on certain complexity measures of the comparator relative to one's prior knowledge. This paper achieves a new type of such adaptive regret bounds leveraging a sparse coding framework. The complexity of the comparator is measured by its energy and its sparsity on a user-specified dictionary, which offers considerable versatility. For example, equipped with a wavelet dictionary, our framework improves the state-of-the-art bound (Jacobsen & Cutkosky, 2022) by adapting to both ($i$) the magnitude of the comparator average $||\\bar u||=||\\sum_{t=1}^Tu_t/T||$, rather than the maximum $\\max_t||u_t||$; and ($ii$) the comparator variability $\\sum_{t=1}^T||u_t-\\bar u||$, rather than the uncentered sum $\\sum_{t=1}^T||u_t||$. Furthermore, our proof is simpler due to decoupling function approximation from regret minimization",
    "checked": true,
    "id": "efa164de424f51168c0258ced4c93ab7f9ff6bea",
    "semantic_title": "unconstrained dynamic regret via sparse coding",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=KMxRQO7P98": {
    "title": "One-Pass Distribution Sketch for Measuring Data Heterogeneity in Federated Learning",
    "volume": "poster",
    "abstract": "Federated learning (FL) is a machine learning paradigm where multiple client devices train models collaboratively without data exchange. Data heterogeneity problem is naturally inherited in FL since data in different clients follow diverse distributions. To mitigate the negative influence of data heterogeneity, we need to start by measuring it across clients. However, the efficient measurement between distributions is a challenging problem, especially in high dimensionality. In this paper, we propose a one-pass distribution sketch to represent the client data distribution. Our sketching algorithm only requires a single pass of the client data, which is efficient in terms of time and memory. Moreover, we show in both theory and practice that the distance between two distribution sketches represents the divergence between their corresponding distributions. Furthermore, we demonstrate with extensive experiments that our distribution sketch improves the client selection in the FL training. We also showcase that our distribution sketch is an efficient solution to the cold start problem in FL for new clients with unlabeled data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LTdfYIvbHc": {
    "title": "Feature-Learning Networks Are Consistent Across Widths At Realistic Scales",
    "volume": "poster",
    "abstract": "We study the effect of width on the dynamics of feature-learning neural networks across a variety of architectures and datasets. Early in training, wide neural networks trained on online data have not only identical loss curves but also agree in their point-wise test predictions throughout training. For simple tasks such as CIFAR-5m this holds throughout training for networks of realistic widths. We also show that structural properties of the models, including internal representations, preactivation distributions, edge of stability phenomena, and large learning rate effects are consistent across large widths. This motivates the hypothesis that phenomena seen in realistic models can be captured by infinite-width, feature-learning limits. For harder tasks (such as ImageNet and language modeling), and later training times, finite-width deviations grow systematically. Two distinct effects cause these deviations across widths. First, the network output has an initialization-dependent variance scaling inversely with width, which can be removed by ensembling networks. We observe, however, that ensembles of narrower networks perform worse than a single wide network. We call this the bias of narrower width. We conclude with a spectral perspective on the origin of this finite-width bias",
    "checked": true,
    "id": "5875e7cc6d8941f078e32b51b8d36fc08f9c1774",
    "semantic_title": "feature-learning networks are consistent across widths at realistic scales",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Z1Aj59LoZD": {
    "title": "Path Regularization: A Convexity and Sparsity Inducing Regularization for Parallel ReLU Networks",
    "volume": "poster",
    "abstract": "Understanding the fundamental principles behind the success of deep neural networks is one of the most important open questions in the current literature. To this end, we study the training problem of deep neural networks and introduce an analytic approach to unveil hidden convexity in the optimization landscape. We consider a deep parallel ReLU network architecture, which also includes standard deep networks and ResNets as its special cases. We then show that pathwise regularized training problems can be represented as an exact convex optimization problem. We further prove that the equivalent convex problem is regularized via a group sparsity inducing norm. Thus, a path regularized parallel ReLU network can be viewed as a parsimonious convex model in high dimensions. More importantly, since the original training problem may not be trainable in polynomial-time, we propose an approximate algorithm with a fully polynomial-time complexity in all data dimensions. Then, we prove strong global optimality guarantees for this algorithm. We also provide experiments corroborating our theory",
    "checked": true,
    "id": "16f19c934025341a38370cc48a9613178845b027",
    "semantic_title": "path regularization: a convexity and sparsity inducing regularization for parallel relu networks",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=rpuEARqB54": {
    "title": "On the Role of Noise in the Sample Complexity of Learning Recurrent Neural Networks: Exponential Gaps for Long Sequences",
    "volume": "poster",
    "abstract": "We consider the class of noisy multi-layered sigmoid recurrent neural networks with $w$ (unbounded) weights for classification of sequences of length $T$, where independent noise distributed according to $\\mathcal{N}(0,\\sigma^2)$ is added to the output of each neuron in the network. Our main result shows that the sample complexity of PAC learning this class can be bounded by $O (w\\log(T/\\sigma))$. For the non-noisy version of the same class (i.e., $\\sigma=0$), we prove a lower bound of $\\Omega (wT)$ for the sample complexity. Our results indicate an exponential gap in the dependence of sample complexity on $T$ for noisy versus non-noisy networks. Moreover, given the mild logarithmic dependence of the upper bound on $1/\\sigma$, this gap still holds even for numerically negligible values of $\\sigma$",
    "checked": true,
    "id": "98c4b544247f74e4b53e756a054e5692bc24b8a8",
    "semantic_title": "on the role of noise in the sample complexity of learning recurrent neural networks: exponential gaps for long sequences",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YifKp5b15e": {
    "title": "Near-Optimal Bounds for Learning Gaussian Halfspaces with Random Classification Noise",
    "volume": "poster",
    "abstract": "We study the problem of learning general (i.e., not necessarily homogeneous) halfspaces with Random Classification Noise under the Gaussian distribution. We establish nearly-matching algorithmic and Statistical Query (SQ) lower bound results revealing a surprising information-computation gap for this basic problem. Specifically, the sample complexity of this learning problem is $\\widetilde{\\Theta}(d/\\epsilon)$, where $d$ is the dimension and $\\epsilon$ is the excess error. Our positive result is a computationally efficient learning algorithm with sample complexity $\\tilde{O}(d/\\epsilon + d/\\max(p, \\epsilon))^2)$, where $p$ quantifies the bias of the target halfspace. On the lower bound side, we show that any efficient SQ algorithm (or low-degree test) for the problem requires sample complexity at least $\\Omega(d^{1/2}/(\\max(p, \\epsilon))^2)$. Our lower bound suggests that this quadratic dependence on $1/\\epsilon$ is inherent for efficient algorithms",
    "checked": true,
    "id": "6523426e8b5eebd191f7ade203871f6d90b64fff",
    "semantic_title": "near-optimal bounds for learning gaussian halfspaces with random classification noise",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=frSfSaRGXY": {
    "title": "Meek Separators and Their Applications in Targeted Causal Discovery",
    "volume": "poster",
    "abstract": "Learning causal structures from interventional data is a fundamental problem with broad applications across various fields. While many previous works have focused on recovering the entire causal graph, in practice, there are scenarios where learning only part of the causal graph suffices. This is called \\emph{targeted} causal discovery. In our work, we focus on two such well-motivated problems: subset search and causal matching. We aim to minimize the number of interventions in both cases. Towards this, we introduce the \\emph{Meek separator}, which is a subset of vertices that, when intervened, decomposes the remaining unoriented edges into smaller connected components. We then present an efficient algorithm to find Meek separators that are of small sizes. Such a procedure is helpful in designing various divide-and-conquer-based approaches. In particular, we propose two randomized algorithms that achieve logarithmic approximation for subset search and causal matching, respectively. Our results provide the first known average-case provable guarantees for both problems. We believe that this opens up possibilities to design near-optimal methods for many other targeted causal structure learning problems arising from various applications",
    "checked": true,
    "id": "9833089702faf7579facefe280c03f3d354ac27c",
    "semantic_title": "meek separators and their applications in targeted causal discovery",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zq4vFneRiA": {
    "title": "The Crucial Role of Normalization in Sharpness-Aware Minimization",
    "volume": "poster",
    "abstract": "Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based optimizer (Foret et al., ICLR 2021) that greatly improves the prediction performance of deep neural networks. Consequently, there has been a surge of interest in explaining its empirical success. We focus, in particular, on understanding ***the role played by normalization***, a key component of the SAM updates. We theoretically and empirically study the effect of normalization in SAM for both convex and non-convex functions, revealing two key roles played by normalization: i) it helps in stabilizing the algorithm; and ii) it enables the algorithm to drift along a continuum (manifold) of minima -- a property identified by recent theoretical works that is the key to better performance. We further argue that these two properties of normalization make SAM robust against the choice of hyper-parameters, supporting the practicality of SAM. Our conclusions are backed by various experiments",
    "checked": true,
    "id": "169ead48300d7d775fdb0fcb88005c02720a5efb",
    "semantic_title": "the crucial role of normalization in sharpness-aware minimization",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=X3IeHRD0zf": {
    "title": "Causal Imitability Under Context-Specific Independence Relations",
    "volume": "poster",
    "abstract": "Drawbacks of ignoring the causal mechanisms when performing imitation learning have recently been acknowledged. Several approaches both to assess the feasibility of imitation and to circumvent causal confounding and causal misspecifications have been proposed in the literature. However, the potential benefits of the incorporation of additional information about the underlying causal structure are left unexplored. An example of such overlooked information is context-specific independence (CSI), i.e., independence that holds only in certain contexts. We consider the problem of causal imitation learning when CSI relations are known. We prove that the decision problem pertaining to the feasibility of imitation in this setting is NP-hard. Further, we provide a necessary graphical criterion for imitation learning under CSI and show that under a structural assumption, this criterion is also sufficient. Finally, we propose a sound algorithmic approach for causal imitation learning which takes both CSI relations and data into account",
    "checked": true,
    "id": "00fe94a6d7097b860a33ec0c1c85eba2e2e74f14",
    "semantic_title": "causal imitability under context-specific independence relations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o16sYKHk3S": {
    "title": "Identifiability Guarantees for Causal Disentanglement from Soft Interventions",
    "volume": "poster",
    "abstract": "Causal disentanglement aims to uncover a representation of data using latent variables that are interrelated through a causal model. Such a representation is identifiable if the latent model that explains the data is unique. In this paper, we focus on the scenario where unpaired observational and interventional data are available, with each intervention changing the mechanism of a latent variable. When the causal variables are fully observed, statistically consistent algorithms have been developed to identify the causal model under faithfulness assumptions. We here show that identifiability can still be achieved with unobserved causal variables, given a generalized notion of faithfulness. Our results guarantee that we can recover the latent causal model up to an equivalence class and predict the effect of unseen combinations of interventions, in the limit of infinite data. We implement our causal disentanglement framework by developing an autoencoding variational Bayes algorithm and apply it to the problem of predicting combinatorial perturbation effects in genomics",
    "checked": true,
    "id": "ce7fc001e17d5a062d1ea062e29b899c03d61727",
    "semantic_title": "identifiability guarantees for causal disentanglement from soft interventions",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=S37hOerQLB": {
    "title": "Self-Refine: Iterative Refinement with Self-Feedback",
    "volume": "poster",
    "abstract": "Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides *feedback* for its output and uses it to *refine* itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner and the feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by $\\sim$20\\% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test-time using our simple, standalone approach",
    "checked": true,
    "id": "3aaf6a2cbad5850ad81ab5c163599cb3d523436f",
    "semantic_title": "self-refine: iterative refinement with self-feedback",
    "citation_count": 247,
    "authors": []
  },
  "https://openreview.net/forum?id=1vvsIJtnnr": {
    "title": "Boosting with Tempered Exponential Measures",
    "volume": "poster",
    "abstract": "One of the most popular ML algorithms, AdaBoost, can be derived from the dual of a relative entropy minimization problem subject to the fact that the positive weights on the examples sum to one. Essentially, harder examples receive higher probabilities. We generalize this setup to the recently introduced *tempered exponential measure*s (TEMs) where normalization is enforced on a specific power of the measure and not the measure itself. TEMs are indexed by a parameter $t$ and generalize exponential families ($t=1$). Our algorithm, $t$-AdaBoost, recovers AdaBoost as a special case ($t=1$). We show that $t$-AdaBoost retains AdaBoost's celebrated exponential convergence rate when $t\\in [0,1)$ while allowing a slight improvement of the rate's hidden constant compared to $t=1$. $t$-AdaBoost partially computes on a generalization of classical arithmetic over the reals and brings notable properties like guaranteed bounded leveraging coefficients for $t\\in [0,1)$. From the loss that $t$-AdaBoost minimizes (a generalization of the exponential loss), we show how to derive a new family of *tempered* losses for the induction of domain-partitioning classifiers like decision trees. Crucially, strict properness is ensured for all while their boosting rates span the full known spectrum. Experiments using $t$-AdaBoost+trees display that significant leverage can be achieved by tuning $t$",
    "checked": true,
    "id": "14242f41992cb473da3876b7c27bb7fac56e8258",
    "semantic_title": "boosting with tempered exponential measures",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=OzjBohmLvE": {
    "title": "Achieving $\\mathcal{O}(\\epsilon^{-1.5})$ Complexity in Hessian/Jacobian-free Stochastic Bilevel Optimization",
    "volume": "poster",
    "abstract": "In this paper, we revisit the bilevel optimization problem, in which the upper-level objective function is generally nonconvex and the lower-level objective function is strongly convex. Although this type of problem has been studied extensively, it still remains an open question how to achieve an $\\mathcal{O}(\\epsilon^{-1.5})$ sample complexity of $\\mathcal{O}(\\epsilon^{-1.5})$ in Hessian/Jacobian-free stochastic bilevel optimization without any second-order derivative computation. To fill this gap, we propose a novel Hessian/Jacobian-free bilevel optimizer named FdeHBO, which features a simple fully single-loop structure, a projection-aided finite-difference Hessian/Jacobian-vector approximation, and momentum-based updates. Theoretically, we show that FdeHBO requires $\\mathcal{O}(\\epsilon^{-1.5})$ iterations (each using $\\mathcal{O}(1)$ samples and only first-order gradient information) to find an $\\epsilon$-accurate stationary point. As far as we know, this is the first Hessian/Jacobian-free method with an $\\mathcal{O}(\\epsilon^{-1.5})$ sample complexity for nonconvex-strongly-convex stochastic bilevel optimization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZXbgVm3PSt": {
    "title": "TART: A plug-and-play Transformer module for task-agnostic reasoning",
    "volume": "poster",
    "abstract": "Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our experiments actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and, as a proof of concept, propose TART which generically improves an LLM's reasoning abilities using a synthetically trained reasoning module. TART trains this Transformer-based reasoning module in a task-agnostic manner using only synthetic logistic regression tasks and composes it with an arbitrary real-world pre-trained model without any additional training. With a single inference module, TART improves performance across different model families (GPT-Neo, Pythia, Bloom), model sizes (100M - 6B), tasks (14 NLP classification tasks), and even across different modalities (audio and vision). On the RAFT Benchmark, TART improves GPT-Neo (125M)'s performance such that it outperforms Bloom (176B), and is within $4$% of GPT-3",
    "checked": true,
    "id": "014c00319cb23c6322ea5218049661a4ce222946",
    "semantic_title": "tart: a plug-and-play transformer module for task-agnostic reasoning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=58HwnnEdtF": {
    "title": "Reward-Directed Conditional Diffusion: Provable Distribution Estimation and Reward Improvement",
    "volume": "poster",
    "abstract": "We explore the methodology and theory of reward-directed generation via conditional diffusion models. Directed generation aims to generate samples with desired properties as measured by a reward function, which has broad applications in generative AI, reinforcement learning, and computational biology. We consider the common learning scenario where the dataset consists of majorly unlabeled data and a small set of data with noisy reward labels. Our approach leverages a learned reward function on the smaller data set as a pseudolabeler to label the unlabelled data. After pseudo-labelling, a conditional diffusion model (CDM) is trained on the data and samples are generated by setting a target value $a$ as the condition in CDM. From a theoretical standpoint, we show that this directed generator can effectively learn and sample from the reward-conditioned data distribution: 1. our model is capable of recovering the data's latent subspace representation. 2. the model generates samples moving closer to the user-specified target. The improvement in rewards of samples is influenced by a interplay between the strength of the reward signal, the distribution shift, and the cost of off-support extrapolation. We provide empirical results to validate our theory and highlight the relationship between the strength of extrapolation and the quality of generated samples",
    "checked": true,
    "id": "9d24424dcddf836870b74293ac1222cb6a371bd9",
    "semantic_title": "reward-directed conditional diffusion: provable distribution estimation and reward improvement",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ftPoVcm821": {
    "title": "Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought",
    "volume": "poster",
    "abstract": "Language instructions and demonstrations are two natural ways for users to teach robots personalized tasks. Recent progress in Large Language Models (LLMs) has shown impressive performance in translating language instructions into code for robotic tasks. However, translating demonstrations into task code continues to be a challenge due to the length and complexity of both demonstrations and code, making learning a direct mapping intractable. This paper presents Demo2Code, a novel framework that generates robot task code from demonstrations via an extended chain-of-thought and defines a common latent specification to connect the two. Our framework employs a robust two-stage process: (1) a recursive summarization technique that condenses demonstrations into concise specifications, and (2) a code synthesis approach that expands each function recursively from the generated specifications. We conduct extensive evaluation on various robot task benchmarks, including a novel game benchmark Robotouille, designed to simulate diverse cooking tasks in a kitchen environment",
    "checked": true,
    "id": "9dee1aceb09f7d4c22fdbaf49d238e1502effd1b",
    "semantic_title": "demo2code: from summarizing demonstrations to synthesizing code via extended chain-of-thought",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=Dx99y3okbL": {
    "title": "Distribution Learnability and Robustness",
    "volume": "poster",
    "abstract": "We examine the relationship between learnability and robust learnability for the problem of distribution learning. We show that learnability implies robust learnability if the adversary can only perform additive contamination (and consequently, under Huber contamination), but not if the adversary is allowed to perform subtractive contamination. Thus, contrary to other learning settings (e.g., PAC learning of function classes), realizable learnability does not imply agnostic learnability. We also explore related implications in the context of compression schemes and differentially private learnability",
    "checked": false,
    "id": "6f9918ad83b2e6058acfc15ed66601879b855494",
    "semantic_title": "distributional robustness loss for long-tail learning",
    "citation_count": 63,
    "authors": []
  },
  "https://openreview.net/forum?id=PaSpImjKm2": {
    "title": "Performance Bounds for Policy-Based Average Reward Reinforcement Learning Algorithms",
    "volume": "poster",
    "abstract": "Many policy-based reinforcement learning (RL) algorithms can be viewed as instantiations of approximate policy iteration (PI), i.e., where policy improvement and policy evaluation are both performed approximately. In applications where the average reward objective is the meaningful performance metric, often discounted reward formulations are used with the discount factor being close to $1,$ which is equivalent to making the expected horizon very large. However, the corresponding theoretical bounds for error performance scale with the square of the horizon. Thus, even after dividing the total reward by the length of the horizon, the corresponding performance bounds for average reward problems go to infinity. Therefore, an open problem has been to obtain meaningful performance bounds for approximate PI and RL algorithms for the average-reward setting. In this paper, we solve this open problem by obtaining the first non-trivial finite time error bounds for average-reward MDPs which go to zero in the limit as policy evaluation and policy improvement errors go to zero",
    "checked": true,
    "id": "36f23ead10acc50f47824fd9b082118c98eb0263",
    "semantic_title": "performance bounds for policy-based average reward reinforcement learning algorithms",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=iwp3H8uSeK": {
    "title": "Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models",
    "volume": "poster",
    "abstract": "We propose a conceptually simple and lightweight framework for improving the robustness of vision models through the combination of knowledge distillation and data augmentation. We address the conjecture that larger models do not make for better teachers by showing strong gains in out-of-distribution robustness when distilling from pretrained foundation models. Following this finding, we propose Discrete Adversarial Distillation (DAD), which leverages a robust teacher to generate adversarial examples and a VQGAN to discretize them, creating more informative samples than standard data augmentation techniques. We provide a theoretical framework for the use of a robust teacher in the knowledge distillation with data augmentation setting and demonstrate strong gains in out-of-distribution robustness and clean accuracy across different student architectures. Notably, our method adds minor computational overhead compared to similar techniques and can be easily combined with other data augmentations for further improvements",
    "checked": true,
    "id": "f71ee484b9182cfe00ed260ae0c70014cabf9f59",
    "semantic_title": "distilling out-of-distribution robustness from vision-language foundation models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OLk3F64eSg": {
    "title": "An $\\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence and Beyond",
    "volume": "poster",
    "abstract": "We propose EB-TC$\\varepsilon$, a novel sampling rule for $\\varepsilon$-best arm identification in stochastic bandits. It is the first instance of Top Two algorithm analyzed for approximate best arm identification. EB-TC$\\varepsilon$ is an *anytime* sampling rule that can therefore be employed without modification for fixed confidence or fixed budget identification (without prior knowledge of the budget). We provide three types of theoretical guarantees for EB-TC$\\varepsilon$. First, we prove bounds on its expected sample complexity in the fixed confidence setting, notably showing its asymptotic optimality in combination with an adaptive tuning of its exploration parameter. We complement these findings with upper bounds on its probability of error at any time and for any slack parameter, which further yield upper bounds on its simple regret at any time. Finally, we show through numerical simulations that EB-TC$\\varepsilon$ performs favorably compared to existing algorithms for different approximate best arm identification tasks",
    "checked": true,
    "id": "0705c91bf2a26d12abcb7f320bb1b61085570eab",
    "semantic_title": "an $\\varepsilon$-best-arm identification algorithm for fixed-confidence and beyond",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZmeAoWQqe0": {
    "title": "Time Series as Images: Vision Transformer for Irregularly Sampled Time Series",
    "volume": "poster",
    "abstract": "Irregularly sampled time series are increasingly prevalent, particularly in medical domains. While various specialized methods have been developed to handle these irregularities, effectively modeling their complex dynamics and pronounced sparsity remains a challenge. This paper introduces a novel perspective by converting irregularly sampled time series into line graph images, then utilizing powerful pre-trained vision transformers for time series classification in the same way as image classification. This method not only largely simplifies specialized algorithm designs but also presents the potential to serve as a universal framework for time series modeling. Remarkably, despite its simplicity, our approach outperforms state-of-the-art specialized algorithms on several popular healthcare and human activity datasets. Especially in the rigorous leave-sensors-out setting where a portion of variables is omitted during testing, our method exhibits strong robustness against varying degrees of missing observations, achieving an impressive improvement of 42.8% in absolute F1 score points over leading specialized baselines even with half the variables masked. Code and data are available at https://github.com/Leezekun/ViTST",
    "checked": true,
    "id": "3f4bd6e35eca865b0226f1bc0da9fc5f0dc948a8",
    "semantic_title": "time series as images: vision transformer for irregularly sampled time series",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YSMLVffl5u": {
    "title": "CELLE-2: Translating Proteins to Pictures and Back with a Bidirectional Text-to-Image Transformer",
    "volume": "poster",
    "abstract": "We present CELL-E 2, a novel bidirectional transformer that can generate images depicting protein subcellular localization from the amino acid sequences (and vice versa). Protein localization is a challenging problem that requires integrating sequence and image information, which most existing methods ignore. CELL-E 2 extends the work of CELL-E, not only capturing the spatial complexity of protein localization and produce probability estimates of localization atop a nucleus image, but also being able to generate sequences from images, enabling de novo protein design. We train and finetune CELL-E 2 on two large-scale datasets of human proteins. We also demonstrate how to use CELL-E 2 to create hundreds of novel nuclear localization signals (NLS). Results and interactive demos are featured at https://bohuanglab.github.io/CELL-E_2/",
    "checked": false,
    "id": "f6d79996a9d24daa572e4ffc91abd8420cd53fad",
    "semantic_title": "cell-e 2: translating proteins to pictures and back with a bidirectional text-to-image transformer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6rabAZhCRS": {
    "title": "Explaining Predictive Uncertainty with Information Theoretic Shapley Values",
    "volume": "poster",
    "abstract": "Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement efficient algorithms that perform well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection, active learning, feature selection, and active feature-value acquisition",
    "checked": true,
    "id": "31aaa0dc9dd433e9e33f799b143cb8d3ee53b27e",
    "semantic_title": "explaining predictive uncertainty with information theoretic shapley values",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Of0GBzow8P": {
    "title": "The Transient Nature of Emergent In-Context Learning in Transformers",
    "volume": "poster",
    "abstract": "Transformer neural networks can exhibit a surprising capacity for in-context learning (ICL), despite not being explicitly trained for it. Prior work has provided a deeper understanding of how ICL emerges in transformers, e.g., through the lens of mechanistic interpretability, Bayesian inference, or by examining the distributional properties of training data. However, in each of these cases, ICL is treated largely as a persistent phenomenon; namely, once ICL emerges, it is assumed to persist asymptotically. Here, we show that the emergence of ICL during transformer training is, in fact, often transient. We train transformers on synthetic data designed so that both ICL or in-weights learning (IWL) strategies can lead to correct predictions. We find that ICL first emerges, then disappears and gives way to IWL, all while the training loss decreases, indicating an asymptotic preference for IWL. The transient nature of ICL is observed in transformers across a range of model sizes and datasets, raising the question of how much to \"overtrain\" transformers when seeking compact, cheaper-to-run models. We find that L2 regularization may offer a path to more persistent ICL that removes the need for early stopping based on ICL-style validation tasks",
    "checked": true,
    "id": "50714ad97ae3a65ff15771b8ec89de47aa8311ab",
    "semantic_title": "the transient nature of emergent in-context learning in transformers",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=38o372YoYt": {
    "title": "Im-Promptu: In-Context Composition from Image Prompts",
    "volume": "poster",
    "abstract": "Large language models are few-shot learners that can solve diverse tasks from a handful of demonstrations. This implicit understanding of tasks suggests that the attention mechanisms over word tokens may play a role in analogical reasoning. In this work, we investigate whether analogical reasoning can enable in-context composition over composable elements of visual stimuli. First, we introduce a suite of three benchmarks to test the generalization properties of a visual in-context learner. We formalize the notion of an analogy-based in-context learner and use it to design a meta-learning framework called Im-Promptu. Whereas the requisite token granularity for language is well established, the appropriate compositional granularity for enabling in-context generalization in visual stimuli is usually unspecified. To this end, we use Im-Promptu to train multiple agents with different levels of compositionality, including vector representations, patch representations, and object slots. Our experiments reveal tradeoffs between extrapolation abilities and the degree of compositionality, with non-compositional representations extending learned composition rules to unseen domains but performing poorly on combinatorial tasks. Patch-based representations require patches to contain entire objects for robust extrapolation. At the same time, object-centric tokenizers coupled with a cross-attention module generate consistent and high-fidelity solutions, with these inductive biases being particularly crucial for compositional generalization. Lastly, we demonstrate a use case of Im-Promptu as an intuitive programming interface for image generation",
    "checked": true,
    "id": "1cd9ac9051a874a84957910acea944af88135621",
    "semantic_title": "im-promptu: in-context composition from image prompts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t3WCiGjHqd": {
    "title": "Scalable Membership Inference Attacks via Quantile Regression",
    "volume": "poster",
    "abstract": "Membership inference attacks are designed to determine, using black box access to trained models, whether a particular example was used in training or not. Membership inference can be formalized as a hypothesis testing problem. The most effective existing attacks estimate the distribution of some test statistic (usually the model's confidence on the true label) on points that were (and were not) used in training by training many \\emph{shadow models}---i.e. models of the same architecture as the model being attacked, trained on a random subsample of data. While effective, these attacks are extremely computationally expensive, especially when the model under attack is large. \\footnotetext[0]{ Martin and Shuai are the lead authors, and other authors are ordered alphabetically. \\{maberlop,shuat\\}@amazon.com} We introduce a new class of attacks based on performing quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training. We show that our method is competitive with state-of-the-art shadow model attacks, while requiring substantially less compute because our attack requires training only a single model. Moreover, unlike shadow model attacks, our proposed attack does not require any knowledge of the architecture of the model under attack and is therefore truly ``black-box\". We show the efficacy of this approach in an extensive series of experiments on various datasets and model architectures. Our code is available at \\href{https://github.com/amazon-science/quantile-mia}{github.com/amazon-science/quantile-mia.}",
    "checked": true,
    "id": "85b6d229b5ee21840116d9b0520ede1e73c25174",
    "semantic_title": "scalable membership inference attacks via quantile regression",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=BryMFPQ4L6": {
    "title": "Augmenting Language Models with Long-Term Memory",
    "volume": "poster",
    "abstract": "Existing large language models (LLMs) can only afford fix-sized inputs due to the input length limit, preventing them from utilizing rich long-context information from past inputs. To address this, we propose a framework, Language Models Augmented with Long-Term Memory (LongMem), which enables LLMs to memorize long history. We design a novel decoupled network architecture with the original backbone LLM frozen as a memory encoder and an adaptive residual side-network as a memory retriever and reader. Such a decoupled memory design can easily cache and update long-term past contexts for memory retrieval without suffering from memory staleness. Enhanced with memory-augmented adaptation training, LongMem can thus memorize long past context and use long-term memory for language modeling. The proposed memory retrieval module can handle unlimited-length context in its memory bank to benefit various downstream tasks. Typically, LongMem can enlarge the long-form memory to 65k tokens and thus cache many-shot extra demonstration examples as long-form memory for in-context learning. Experiments show that our method outperforms strong long-context models on ChapterBreak, a challenging long-context modeling benchmark, and achieves remarkable improvements on memory-augmented in-context learning over LLMs. The results demonstrate that the proposed method is effective in helping language models to memorize and utilize long-form contents",
    "checked": true,
    "id": "80980cd10d19f021c14a6b7eee871b6a5d328024",
    "semantic_title": "augmenting language models with long-term memory",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=KQ25VgEvOJ": {
    "title": "Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments",
    "volume": "poster",
    "abstract": "Continual semantic segmentation aims to learn new classes while maintaining the information from the previous classes. Although prior studies have shown impressive progress in recent years, the fairness concern in the continual semantic segmentation needs to be better addressed. Meanwhile, fairness is one of the most vital factors in deploying the deep learning model, especially in human-related or safety applications. In this paper, we present a novel Fairness Continual Learning approach to the semantic segmentation problem. In particular, under the fairness objective, a new fairness continual learning framework is proposed based on class distributions. Then, a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning, i.e., catastrophic forgetting and background shift. Our proposed loss has also been proven as a novel, generalized learning paradigm of knowledge distillation commonly used in continual learning. Moreover, the proposed Conditional Structural Consistency loss further regularized the structural constraint of the predicted segmentation. Our proposed approach has achieved State-of-the-Art performance on three standard scene understanding benchmarks, i.e., ADE20K, Cityscapes, and Pascal VOC, and promoted the fairness of the segmentation model",
    "checked": true,
    "id": "ac856b6b7b3f32fb34320b7170526d3ab15ba5f3",
    "semantic_title": "fairness continual learning approach to semantic scene understanding in open-world environments",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=EjG2G1PT2v": {
    "title": "Information-guided Planning: An Online Approach for Partially Observable Problems",
    "volume": "poster",
    "abstract": "This paper presents IB-POMCP, a novel algorithm for online planning under partial observability. Our approach enhances the decision-making process by using estimations of the world belief's entropy to guide a tree search process and surpass the limitations of planning in scenarios with sparse reward configurations. By performing what we denominate as an *information-guided planning process*, the algorithm, which incorporates a novel I-UCB function, shows significant improvements in reward and reasoning time compared to state-of-the-art baselines in several benchmark scenarios, along with theoretical convergence guarantees",
    "checked": false,
    "id": "d46af7ca575cdb5e172d48aadff83b4d3736d72f",
    "semantic_title": "multiagent path finding using deep reinforcement learning coupled with hot supervision contrastive loss",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=V5cQH7JbGo": {
    "title": "Lockdown: Backdoor Defense for Federated Learning with Isolated Subspace Training",
    "volume": "poster",
    "abstract": "Federated learning (FL) is vulnerable to backdoor attacks due to its distributed computing nature. Existing defense solution usually requires larger amount of computation in either the training or testing phase, which limits their practicality in the resource-constrain scenarios. A more practical defense, i.e., neural network (NN) pruning based defense has been proposed in centralized backdoor setting. However, our empirical study shows that traditional pruning-based solution suffers \\textit{poison-coupling} effect in FL, which significantly degrades the defense performance.This paper presents Lockdown, an isolated subspace training method to mitigate the poison-coupling effect. Lockdown follows three key procedures. First, it modifies the training protocol by isolating the training subspaces for different clients. Second, it utilizes randomness in initializing isolated subspacess, and performs subspace pruning and subspace recovery to segregate the subspaces between malicious and benign clients. Third, it introduces quorum consensus to cure the global model by purging malicious/dummy parameters. Empirical results show that Lockdown achieves \\textit{superior} and \\textit{consistent} defense performance compared to existing representative approaches against backdoor attacks. Another value-added property of Lockdown is the communication-efficiency and model complexity reduction, which are both critical for resource-constrain FL scenario. Our code is available at \\url{https://github.com/git-disl/Lockdown}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uR8TtWCIsr": {
    "title": "A Logic for Expressing Log-Precision Transformers",
    "volume": "poster",
    "abstract": "One way to interpret the reasoning power of transformer-based language models is to describe the types of logical rules they can resolve over some input text. Recently, Chiang et al. (2023) showed that finite-precision transformer classifiers can be equivalently expressed in a generalization of first-order logic. However, finite-precision transformers are a weak transformer variant because, as we show, a single head can only attend to a constant number of tokens and, in particular, cannot represent uniform attention. Since attending broadly is a core capability for transformers, we ask whether a minimally more expressive model that can attend universally can also be characterized in logic. To this end, we analyze transformers whose forward pass is computed in $\\log n$ precision on contexts of length $n$. We prove any log-precision transformer classifier can be equivalently expressed as a first-order logic sentence that, in addition to standard universal and existential quantifiers, may also contain majority-vote quantifiers. This is the tightest known upper bound and first logical characterization of log-precision transformers",
    "checked": true,
    "id": "a85a0f91474c8848e81393627912341993f6f1d7",
    "semantic_title": "a logic for expressing log-precision transformers",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=1qFnxhdbxg": {
    "title": "Energy Discrepancies: A Score-Independent Loss for Energy-Based Models",
    "volume": "poster",
    "abstract": "Energy-based models are a simple yet powerful class of probabilistic models, but their widespread adoption has been limited by the computational burden of training them. We propose a novel loss function called Energy Discrepancy (ED) which does not rely on the computation of scores or expensive Markov chain Monte Carlo. We show that energy discrepancy approaches the explicit score matching and negative log-likelihood loss under different limits, effectively interpolating between both. Consequently, minimum energy discrepancy estimation overcomes the problem of nearsightedness encountered in score-based estimation methods, while also enjoying theoretical guarantees. Through numerical experiments, we demonstrate that ED learns low-dimensional data distributions faster and more accurately than explicit score matching or contrastive divergence. For high-dimensional image data, we describe how the manifold hypothesis puts limitations on our approach and demonstrate the effectiveness of energy discrepancy by training the energy-based model as a prior of a variational decoder model",
    "checked": true,
    "id": "16cd5b774f3a39d98404c727b652eef7f857677a",
    "semantic_title": "energy discrepancies: a score-independent loss for energy-based models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=K3JgUvDSYX": {
    "title": "Fast Optimal Locally Private Mean Estimation via Random Projections",
    "volume": "poster",
    "abstract": "We study the problem of locally private mean estimation of high-dimensional vectors in the Euclidean ball. Existing algorithms for this problem either incur sub-optimal error or have high communication and/or run-time complexity. We propose a new algorithmic framework, namely ProjUnit, for private mean estimation that yields algorithms that are computationally efficient, have low communication complexity, and incur optimal error up to a $1+o(1)$-factor. Our framework is deceptively simple: each randomizer projects its input to a random low-dimensional subspace and then runs an optimal algorithm such a PrivUnitG in the lower dimensional space. We analyze the error of the algorithm in terms of properties of the random projection ensemble, and study two instantiations. We conduct several experiments for private mean estimation and private federated learning which demonstrate that our algorithms obtain nearly the same utility as optimal algorithms while having significantly lower communication and computational cost",
    "checked": true,
    "id": "48f4873d8c7aa2b393118cc8a4118ee1e3cd739a",
    "semantic_title": "fast optimal locally private mean estimation via random projections",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=rY4sA9qYKy": {
    "title": "On the impact of activation and normalization in obtaining isometric embeddings at initialization",
    "volume": "poster",
    "abstract": "In this paper, we explore the structure of the penultimate Gram matrix in deep neural networks, which contains the pairwise inner products of outputs corresponding to a batch of inputs. In several architectures it has been observed that this Gram matrix becomes degenerate with depth at initialization, which dramatically slows training. Normalization layers, such as batch or layer normalization, play a pivotal role in preventing the rank collapse issue. Despite promising advances, the existing theoretical results do not extend to layer normalization, which is widely used in transformers, and can not quantitatively characterize the role of non-linear activations. To bridge this gap, we prove that layer normalization, in conjunction with activation layers, biases the Gram matrix of a multilayer perceptron towards the identity matrix at an exponential rate with depth at initialization. We quantify this rate using the Hermite expansion of the activation function",
    "checked": true,
    "id": "f9e1cf92a56898e9378b9019669e6de62bb7066a",
    "semantic_title": "on the impact of activation and normalization in obtaining isometric embeddings at initialization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=nX0zYBGEka": {
    "title": "FedGame: A Game-Theoretic Defense against Backdoor Attacks in Federated Learning",
    "volume": "poster",
    "abstract": "Federated learning (FL) provides a distributed training paradigm where multiple clients can jointly train a global model without sharing their local data. However, recent studies have shown that FL offers an additional surface for backdoor attacks. For instance, an attacker can compromise a subset of clients and thus corrupt the global model to misclassify an input with a backdoor trigger as the adversarial target. Existing defenses for FL against backdoor attacks usually detect and exclude the corrupted information from the compromised clients based on a static attacker model. However, such defenses are inadequate against dynamic attackers who strategically adapt their attack strategies. To bridge this gap, we model the strategic interactions between the defender and dynamic attackers as a minimax game. Based on the analysis of the game, we design an interactive defense mechanism FedGame. We prove that under mild assumptions, the global model trained with FedGame under backdoor attacks is close to that trained without attacks. Empirically, we compare FedGame with multiple state-of-the-art baselines on several benchmark datasets under various attacks. We show that FedGame can effectively defend against strategic attackers and achieves significantly higher robustness than baselines. Our code is available at: https://github.com/AI-secure/FedGame",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DGmxTUCHYs": {
    "title": "Zero-One Laws of Graph Neural Networks",
    "volume": "poster",
    "abstract": "Graph neural networks (GNNs) are the de facto standard deep learning architectures for machine learning on graphs. This has led to a large body of work analyzing the capabilities and limitations of these models, particularly pertaining to their representation and extrapolation capacity. We offer a novel theoretical perspective on the representation and extrapolation capacity of GNNs, by answering the question: how do GNNs behave as the number of graph nodes become very large? Under mild assumptions, we show that when we draw graphs of increasing size from the Erdős–Rényi model, the probability that such graphs are mapped to a particular output by a class of GNN classifiers tends to either zero or one. This class includes the popular graph convolutional network architecture. The result establishes `zero-one laws' for these GNNs, and analogously to other convergence laws, entails theoretical limitations on their capacity. We empirically verify our results, observing that the theoretical asymptotic limits are evident already on relatively small graphs",
    "checked": true,
    "id": "bf217e7afa10c7c736ee4d28b523603eff35ba95",
    "semantic_title": "zero-one laws of graph neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Lg1ODJGGiI": {
    "title": "Deep Stochastic Processes via Functional Markov Transition Operators",
    "volume": "poster",
    "abstract": "We introduce Markov Neural Processes (MNPs), a new class of Stochastic Processes (SPs) which are constructed by stacking sequences of neural parameterised Markov transition operators in function space. We prove that these Markov transition operators can preserve the exchangeability and consistency of SPs. Therefore, the proposed iterative construction adds substantial flexibility and expressivity to the original framework of Neural Processes (NPs) without compromising consistency or adding restrictions. Our experiments demonstrate clear advantages of MNPs over baseline models on a variety of tasks",
    "checked": true,
    "id": "c24d25b33e5f7ee566f080b57410c49ffefbea52",
    "semantic_title": "deep stochastic processes via functional markov transition operators",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9QEVJ9qm46": {
    "title": "Robust Learning with Progressive Data Expansion Against Spurious Correlation",
    "volume": "poster",
    "abstract": "While deep learning models have shown remarkable performance in various tasks, they are susceptible to learning non-generalizable _spurious features_ rather than the core features that are genuinely correlated to the true label. In this paper, beyond existing analyses of linear models, we theoretically examine the learning process of a two-layer nonlinear convolutional neural network in the presence of spurious features. Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process. In light of this, we propose a new training algorithm called **PDE** that efficiently enhances the model's robustness for a better worst-group performance. PDE begins with a group-balanced subset of training data and progressively expands it to facilitate the learning of the core features. Experiments on synthetic and real-world benchmark datasets confirm the superior performance of our method on models such as ResNets and Transformers. On average, our method achieves a $2.8$ \\% improvement in worst-group accuracy compared with the state-of-the-art method, while enjoying up to $10\\times$ faster training efficiency",
    "checked": true,
    "id": "ea68c705715b610b5f4750217a934f8d1666d30d",
    "semantic_title": "robust learning with progressive data expansion against spurious correlation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=x7q7w07r6Y": {
    "title": "Lending Interaction Wings to Recommender Systems with Conversational Agents",
    "volume": "poster",
    "abstract": "An intelligent conversational agent (a.k.a., chat-bot) could embrace conversational technologies to obtain user preferences online, to overcome inherent limitations of recommender systems trained over the offline historical user behaviors. In this paper, we propose CORE, a new offline-training and online-checking framework to plug a COnversational agent into REcommender systems. Unlike most prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, CORE bridges the conversational agent and recommender system through a unified uncertainty minimization framework, which can be easily applied to any existing recommendation approach. Concretely, CORE treats a recommender system as an offline estimator to produce an estimated relevance score for each item, while CORE regards a conversational agent as an online checker that checks these estimated scores in each online session. We define uncertainty as the sum of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Towards uncertainty minimization, we derive the certainty gain of querying each attribute and item, and develop a novel online decision tree algorithm to decide what to query at each turn. Our theoretical analysis reveals the bound of the expected number of turns of CORE in a cold-start setting. Experimental results demonstrate that CORE can be seamlessly employed on a variety of recommendation approaches, and can consistently bring significant improvements in both hot-start and cold-start settings",
    "checked": true,
    "id": "e04c1ccf87d16fcf361ee3810dedca951d4589e6",
    "semantic_title": "lending interaction wings to recommender systems with conversational agents",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=wX8GuzDSJR": {
    "title": "What can a Single Attention Layer Learn? A Study Through the Random Features Lens",
    "volume": "poster",
    "abstract": "Attention layers---which map a sequence of inputs to a sequence of outputs---are core building blocks of the Transformer architecture which has achieved significant breakthroughs in modern artificial intelligence. This paper presents a rigorous theoretical study on the learning and generalization of a single multi-head attention layer, with a sequence of key vectors and a separate query vector as input. We consider the random feature setting where the attention layer has a large number of heads, with randomly sampled frozen query and key matrices, and trainable value matrices. We show that such a random-feature attention layer can express a broad class of target functions that are permutation invariant to the key vectors. We further provide quantitative excess risk bounds for learning these target functions from finite samples, using random feature attention with finitely many heads. Our results feature several implications unique to the attention structure compared with existing random features theory for neural networks, such as (1) Advantages in the sample complexity over standard two-layer random-feature networks; (2) Concrete and natural classes of functions that can be learned efficiently by a random-feature attention layer; and (3) The effect of the sampling distribution of the query-key weight matrix (the product of the query and key matrix), where Gaussian random weights with a non-zero mean result in better sample complexities over the zero-mean counterpart for learning certain natural target functions. Experiments on simulated data corroborate our theoretical findings and further illustrate the interplay between the sample size and the complexity of the target function",
    "checked": true,
    "id": "b978428a41d4051f0fd744845a4bce0523dbee85",
    "semantic_title": "what can a single attention layer learn? a study through the random features lens",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=RiwPYAMLur": {
    "title": "Active representation learning for general task space with applications in robotics",
    "volume": "poster",
    "abstract": "Representation learning based on multi-task pretraining has become a powerful approach in many domains. In particular, task-aware representation learning aims to learn an optimal representation for a specific target task by sampling data from a set of source tasks, while task-agnostic representation learning seeks to learn a universal representation for a class of tasks. In this paper, we propose a general and versatile algorithmic and theoretic framework for \\emph{active representation learning}, where the learner optimally chooses which source tasks to sample from. This framework, along with a tractable meta algorithm, allows most arbitrary target and source task spaces (from discrete to continuous), covers both task-aware and task-agnostic settings, and is compatible with deep representation learning practices. We provide several instantiations under this framework, from bilinear and feature-based nonlinear to general nonlinear cases. In the bilinear case, by leveraging the non-uniform spectrum of the task representation and the calibrated source-target relevance, we prove that the sample complexity to achieve $\\varepsilon$-excess risk on target scales with $(k^*)^2 ||v^*||_2^2 \\varepsilon^{-2}$ where $k^*$ is the effective dimension of the target and $||v^*||_2^2 \\in (0,1]$ represents the connection between source and target space. Compared to the passive one, this can save up to $\\frac{1}{d_W}$ of sample complexity, where $d_W$ is the task space dimension. Finally, we demonstrate different instantiations of our meta algorithm in synthetic datasets and robotics problems, from pendulum simulations to real-world drone flight datasets. On average, our algorithms outperform baselines by 20%-70%",
    "checked": true,
    "id": "fc8823cc12fe97f261764d1731ae4be021b3c7fb",
    "semantic_title": "active representation learning for general task space with applications in robotics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hwjmEZ8561": {
    "title": "Analyzing Vision Transformers for Image Classification in Class Embedding Space",
    "volume": "poster",
    "abstract": "Despite the growing use of transformer models in computer vision, a mechanistic understanding of these networks is still needed. This work introduces a method to reverse-engineer Vision Transformers trained to solve image classification tasks. Inspired by previous research in NLP, we demonstrate how the inner representations at any level of the hierarchy can be projected onto the learned class embedding space to uncover how these networks build categorical representations for their predictions. We use our framework to show how image tokens develop class-specific representations that depend on attention mechanisms and contextual information, and give insights on how self-attention and MLP layers differentially contribute to this categorical composition. We additionally demonstrate that this method (1) can be used to determine the parts of an image that would be important for detecting the class of interest, and (2) exhibits significant advantages over traditional linear probing approaches. Taken together, our results position our proposed framework as a powerful tool for mechanistic interpretability and explainability research",
    "checked": true,
    "id": "7c57530318ae6c6e49c835f23e75affd9cf0827d",
    "semantic_title": "analyzing vision transformers for image classification in class embedding space",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BHHrX3CRE1": {
    "title": "Regularity as Intrinsic Reward for Free Play",
    "volume": "poster",
    "abstract": "We propose regularity as a novel reward signal for intrinsically-motivated reinforcement learning. Taking inspiration from child development, we postulate that striving for structure and order helps guide exploration towards a subspace of tasks that are not favored by naive uncertainty-based intrinsic rewards. Our generalized formulation of Regularity as Intrinsic Reward (RaIR) allows us to operationalize it within model-based reinforcement learning. In a synthetic environment, we showcase the plethora of structured patterns that can emerge from pursuing this regularity objective. We also demonstrate the strength of our method in a multi-object robotic manipulation environment. We incorporate RaIR into free play and use it to complement the model's epistemic uncertainty as an intrinsic reward. Doing so, we witness the autonomous construction of towers and other regular structures during free play, which leads to a substantial improvement in zero-shot downstream task performance on assembly tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v6jIxRRDyD": {
    "title": "Adaptive Algorithms for Relaxed Pareto Set Identification",
    "volume": "poster",
    "abstract": "In this paper we revisit the fixed-confidence identification of the Pareto optimal set in a multi-objective multi-armed bandit model. As the sample complexity to identify the exact Pareto set can be very large, a relaxation allowing to output some additional near-optimal arms has been studied. In this work we also tackle alternative relaxations that allow instead to identify a relevant \\emph{subset} of the Pareto set. Notably, we propose a single sampling strategy, called Adaptive Pareto Exploration, that can be used in conjunction with different stopping rules to take into account different relaxations of the Pareto Set Identification problem. We analyze the sample complexity of these different combinations, quantifying in particular the reduction in sample complexity that occurs when one seeks to identify at most $k$ Pareto optimal arms. We showcase the good practical performance of Adaptive Pareto Exploration on a real-world scenario, in which we adaptively explore several vaccination strategies against Covid-19 in order to find the optimal ones when multiple immunogenicity criteria are taken into account",
    "checked": true,
    "id": "8601d8dd272343add81f489c0a1338f7e85ee195",
    "semantic_title": "adaptive algorithms for relaxed pareto set identification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=xo2lbfQE8I": {
    "title": "Fitting trees to $\\ell_1$-hyperbolic distances",
    "volume": "poster",
    "abstract": "Building trees to represent or to fit distances is a critical component of phylogenetic analysis, metric embeddings, approximation algorithms, geometric graph neural nets, and the analysis of hierarchical data. Much of the previous algorithmic work, however, has focused on generic metric spaces (i.e., those with no \\emph{a priori} constraints). Leveraging several ideas from the mathematical analysis of hyperbolic geometry and geometric group theory, we study the tree fitting problem as finding the relation between the hyperbolicity (ultrametricity) vector and the error of tree (ultrametric) embedding. That is, we define a vector of hyperbolicity (ultrametric) values over all triples of points and compare the $\\ell_p$ norms of this vector with the $\\ell_q$ norm of the distortion of the best tree fit to the distances. This formulation allows us to define the average hyperbolicity (ultrametricity) in terms of a normalized $\\ell_1$ norm of the hyperbolicity vector. Furthermore, we can interpret the classical tree fitting result of Gromov as a $p = q = \\infty$ result. We present an algorithm \\textsc{HCCRootedTreeFit} such that the $\\ell_1$ error of the output embedding is analytically bounded in terms of the $\\ell_1$-norm of the hyperbolicity vector (i.e., $p = q = 1$) and that this result is tight. Furthermore, this algorithm has significantly different theoretical and empirical performance as compared to Gromov's result and related algorithms. Finally, we show using \\textsc{HCCRootedTreeFit} and related tree fitting algorithms, that supposedly standard data sets for hierarchical data analysis and geometric graph neural networks have radically different tree fits than those of synthetic, truly tree-like data sets, suggesting that a much more refined analysis of these standard data sets is called for",
    "checked": false,
    "id": "ebde5d6d3862ffe5ecbd91e5d4bdc51e28dd895b",
    "semantic_title": "hyperaid: denoising in hyperbolic spaces for tree-fitting and hierarchical clustering",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=rGN3X9jnEg": {
    "title": "Formalizing locality for normative synaptic plasticity models",
    "volume": "poster",
    "abstract": "In recent years, many researchers have proposed new models for synaptic plasticity in the brain based on principles of machine learning. The central motivation has been the development of learning algorithms that are able to learn difficult tasks while qualifying as \"biologically plausible\". However, the concept of a biologically plausible learning algorithm is only heuristically defined as an algorithm that is potentially implementable by biological neural networks. Further, claims that neural circuits could implement any given algorithm typically rest on an amorphous concept of \"locality\" (both in space and time). As a result, it is unclear what many proposed local learning algorithms actually predict biologically, and which of these are consequently good candidates for experimental investigation. Here, we address this lack of clarity by proposing formal and operational definitions of locality. Specifically, we define different classes of locality, each of which makes clear what quantities cannot be included in a learning rule if an algorithm is to qualify as local with respect to a given (biological) constraint. We subsequently use this framework to distill testable predictions from various classes of biologically plausible synaptic plasticity models that are robust to arbitrary choices about neural network architecture. Therefore, our framework can be used to guide claims of biological plausibility and to identify potential means of experimentally falsifying a proposed learning algorithm for the brain",
    "checked": true,
    "id": "0459f71fca3b443eff059118f7d35f80c9a160e1",
    "semantic_title": "formalizing locality for normative synaptic plasticity models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z2BHMLA8pM": {
    "title": "Thin and deep Gaussian processes",
    "volume": "poster",
    "abstract": "Gaussian processes (GPs) can provide a principled approach to uncertainty quantification with easy-to-interpret kernel hyperparameters, such as the lengthscale, which controls the correlation distance of function values.However, selecting an appropriate kernel can be challenging. Deep GPs avoid manual kernel engineering by successively parameterizing kernels with GP layers, allowing them to learn low-dimensional embeddings of the inputs that explain the output data. Following the architecture of deep neural networks, the most common deep GPs warp the input space layer-by-layer but lose all the interpretability of shallow GPs. An alternative construction is to successively parameterize the lengthscale of a kernel, improving the interpretability but ultimately giving away the notion of learning lower-dimensional embeddings. Unfortunately, both methods are susceptible to particular pathologies which may hinder fitting and limit their interpretability. This work proposes a novel synthesis of both previous approaches: {Thin and Deep GP} (TDGP). Each TDGP layer defines locally linear transformations of the original input data maintaining the concept of latent embeddings while also retaining the interpretation of lengthscales of a kernel. Moreover, unlike the prior solutions, TDGP induces non-pathological manifolds that admit learning lower-dimensional representations. We show with theoretical and experimental results that i) TDGP is, unlike previous models, tailored to specifically discover lower-dimensional manifolds in the input data, ii) TDGP behaves well when increasing the number of layers, and iii) TDGP performs well in standard benchmark datasets",
    "checked": true,
    "id": "d3e3ea946403a17c3579e44fdebc4ec9bb28230f",
    "semantic_title": "thin and deep gaussian processes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7R8noSP4vL": {
    "title": "Tempo Adaptation in Non-stationary Reinforcement Learning",
    "volume": "poster",
    "abstract": "We first raise and tackle a ``time synchronization'' issue between the agent and the environment in non-stationary reinforcement learning (RL), a crucial factor hindering its real-world applications. In reality, environmental changes occur over wall-clock time ($t$) rather than episode progress ($k$), where wall-clock time signifies the actual elapsed time within the fixed duration $t \\in [0, T]$. In existing works, at episode $k$, the agent rolls a trajectory and trains a policy before transitioning to episode $k+1$. In the context of the time-desynchronized environment, however, the agent at time $t_{k}$ allocates $\\Delta t$ for trajectory generation and training, subsequently moves to the next episode at $t_{k+1}=t_{k}+\\Delta t$. Despite a fixed total number of episodes ($K$), the agent accumulates different trajectories influenced by the choice of interaction times ($t_1,t_2,...,t_K$), significantly impacting the suboptimality gap of the policy. We propose a Proactively Synchronizing Tempo ($\\texttt{ProST}$) framework that computes a suboptimal sequence {$t_1,t_2,...,t_K$} (= { $t_{1:K}$}) by minimizing an upper bound on its performance measure, i.e., the dynamic regret. Our main contribution is that we show that a suboptimal {$t_{1:K}$} trades-off between the policy training time (agent tempo) and how fast the environment changes (environment tempo). Theoretically, this work develops a suboptimal {$t_{1:K}$} as a function of the degree of the environment's non-stationarity while also achieving a sublinear dynamic regret. Our experimental evaluation on various high-dimensional non-stationary environments shows that the $\\texttt{ProST}$ framework achieves a higher online return at suboptimal {$t_{1:K}$} than the existing methods",
    "checked": true,
    "id": "b8e843d199ab6807eb8d7758fc44e430a08e9837",
    "semantic_title": "tempo adaptation in non-stationary reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EoDpq18R30": {
    "title": "Reconciling Competing Sampling Strategies of Network Embedding",
    "volume": "poster",
    "abstract": "Network embedding plays a significant role in a variety of applications. To capture the topology of the network, most of the existing network embedding algorithms follow a sampling training procedure, which maximizes the similarity (e.g., embedding vectors' dot product) between positively sampled node pairs and minimizes the similarity between negatively sampled node pairs in the embedding space. Typically, close node pairs function as positive samples while distant node pairs are usually considered as negative samples. However, under different or even competing sampling strategies, some methods champion sampling distant node pairs as positive samples to encapsulate longer distance information in link prediction, whereas others advocate adding close nodes into the negative sample set to boost the performance of node recommendation. In this paper, we seek to understand the intrinsic relationships between these competing strategies. To this end, we identify two properties (discrimination and monotonicity) that given any node pair proximity distribution, node embeddings should embrace. Moreover, we quantify the empirical error of the trained similarity score w.r.t. the sampling strategy, which leads to an important finding that the discrimination property and the monotonicity property for all node pairs can not be satisfied simultaneously in real-world applications. Guided by such analysis, a simple yet novel model (SENSEI) is proposed, which seamlessly fulfills the discrimination property and the partial monotonicity within the top-$K$ ranking list. Extensive experiments show that SENSEI outperforms the state-of-the-arts in plain network embedding",
    "checked": false,
    "id": "e1968076e618e9d7b9a0e689d177eb01fc01859f",
    "semantic_title": "operationalizing the just city",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QlfGOVD5PO": {
    "title": "Convergence of Actor-Critic with Multi-Layer Neural Networks",
    "volume": "poster",
    "abstract": "The early theory of actor-critic methods considered convergence using linear function approximators for the policy and value functions. Recent work has established convergence using neural network approximators with a single hidden layer. In this work we are taking the natural next step and establish convergence using deep neural networks with an arbitrary number of hidden layers, thus closing a gap between theory and practice. We show that actor-critic updates projected on a ball around the initial condition will converge to a neighborhood where the average of the squared gradients is $\\tilde{O} \\left( 1/\\sqrt{m} \\right) + O \\left( \\epsilon \\right)$, with $m$ being the width of the neural network and $\\epsilon$ the approximation quality of the best critic neural network over the projected set",
    "checked": false,
    "id": "9d27941df4c6bd3d1413161827165dd72e8e6106",
    "semantic_title": "optimal tracking of nonlinear discrete-time systems using zero-sum game formulation and hybrid learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hCUG1MCFk5": {
    "title": "On the Generalization Properties of Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish the theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., independent of the data dimension) when *early-stopped*. Furthermore, we extend our quantitative analysis to a *data-dependent* scenario, wherein target distributions are portrayed as a succession of densities with progressively increasing distances between modes. This precisely elucidates the *adverse* effect of \"*modes shift*'' in ground truths on the model generalization. Furthermore, these estimates are not solely theoretical constructs but have also been confirmed through numerical simulations. Our findings contribute to the rigorous understanding of diffusion models' generalization properties and provide insights that may guide practical applications",
    "checked": true,
    "id": "a3eff696eef2d9cf155a4433f8a4e77c78229373",
    "semantic_title": "on the generalization properties of diffusion models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=TyLjNSbSOe": {
    "title": "An Efficient Doubly-Robust Test for the Kernel Treatment Effect",
    "volume": "poster",
    "abstract": "The average treatment effect, which is the difference in expectation of the counterfactuals, is probably the most popular target effect in causal inference with binary treatments. However, treatments may have effects beyond the mean, for instance decreasing or increasing the variance. We propose a new kernel-based test for distributional effects of the treatment. It is, to the best of our knowledge, the first kernel-based, doubly-robust test with provably valid type-I error. Furthermore, our proposed algorithm is computationally efficient, avoiding the use of permutations",
    "checked": true,
    "id": "b5bda12b16209d77a0ede563fc1fb81422471820",
    "semantic_title": "an efficient doubly-robust test for the kernel treatment effect",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=g2ROKOASiv": {
    "title": "Incentivizing Honesty among Competitors in Collaborative Learning and Optimization",
    "volume": "poster",
    "abstract": "Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the effectiveness of our incentive scheme on a standard non-convex federated learning benchmark. Our work shows that explicitly modeling the incentives and actions of dishonest clients, rather than assuming them malicious, can enable strong robustness guarantees for collaborative learning",
    "checked": true,
    "id": "4d6be45a51f2ab33329fe5c08939591e52dc6e6d",
    "semantic_title": "incentivizing honesty among competitors in collaborative learning and optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p8lowHbuv8": {
    "title": "From Trainable Negative Depth to Edge Heterophily in Graphs",
    "volume": "poster",
    "abstract": "Finding the proper depth $d$ of a graph convolutional network (GCN) that provides strong representation ability has drawn significant attention, yet nonetheless largely remains an open problem for the graph learning community. Although noteworthy progress has been made, the depth or the number of layers of a corresponding GCN is realized by a series of graph convolution operations, which naturally makes $d$ a positive integer ($d \\in \\mathbb{N}+$). An interesting question is whether breaking the constraint of $\\mathbb{N}+$ by making $d$ a real number ($d \\in \\mathbb{R}$) can bring new insights into graph learning mechanisms. In this work, by redefining GCN's depth $d$ as a trainable parameter continuously adjustable within $(-\\infty,+\\infty)$, we open a new door of controlling its signal processing capability to model graph homophily/heterophily (nodes with similar/dissimilar labels/attributes tend to be inter-connected). A simple and powerful GCN model TEDGCN, is proposed to retain the simplicity of GCN and meanwhile automatically search for the optimal $d$ without the prior knowledge regarding whether the input graph is homophilic or heterophilic. Negative-valued $d$ intrinsically enables high-pass frequency filtering functionality via augmented topology for graph heterophily. Extensive experiments demonstrate the superiority of TEDGCN on node classification tasks for a variety of homophilic and heterophilic graphs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1CJ8D7P8RZ": {
    "title": "PoET: A generative model of protein families as sequences-of-sequences",
    "volume": "poster",
    "abstract": "Generative protein language models are a natural way to design new proteins with desired functions. However, current models are either difficult to direct to produce a protein from a specific family of interest, or must be trained on a large multiple sequence alignment (MSA) from the specific family of interest, making them unable to benefit from transfer learning across families. To address this, we propose **P**r**o**tein **E**volutionary **T**ransformer (PoET), an autoregressive generative model of whole protein families that learns to generate sets of related proteins as sequences-of-sequences across tens of millions of natural protein sequence clusters. PoET can be used as a retrieval-augmented language model to generate and score arbitrary modifications conditioned on any protein family of interest, and can extrapolate from short context lengths to generalize well even for small families. This is enabled by a unique Transformer layer; we model tokens sequentially within sequences while attending between sequences order invariantly, allowing PoET to scale to context lengths beyond those used during training. In extensive experiments on deep mutational scanning datasets, we show that PoET outperforms existing protein language models and evolutionary sequence models for variant function prediction across proteins of all MSA depths. We also demonstrate PoET's ability to controllably generate new protein sequences",
    "checked": true,
    "id": "b7737ab9c95eb357faa1d5636acadda0fcdcb401",
    "semantic_title": "poet: a generative model of protein families as sequences-of-sequences",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VeO03T59Sh": {
    "title": "Conformal Prediction for Uncertainty-Aware Planning with Diffusion Dynamics Model",
    "volume": "poster",
    "abstract": "Robotic applications often involve working in environments that are uncertain, dynamic, and partially observable. Recently, diffusion models have been proposed for learning trajectory prediction models trained from expert demonstrations, which can be used for planning in robot tasks. Such models have demonstrated a strong ability to overcome challenges such as multi-modal action distributions, high-dimensional output spaces, and training instability. It is crucial to quantify the uncertainty of these dynamics models when using them for planning. In this paper, we quantify the uncertainty of diffusion dynamics models using Conformal Prediction (CP). Given a finite number of exchangeable expert trajectory examples (called the \"calibration set\"), we use CP to obtain a set in the trajectory space (called the \"coverage region\") that is guaranteed to contain the output of the diffusion model with a user-defined probability (called the \"coverage level\"). In PlanCP, inspired by concepts from conformal prediction, we modify the loss function for training the diffusion model to include a quantile term to encourage more robust performance across the variety of training examples. At test time, we then calibrate PlanCP with a conformal prediction process to obtain coverage sets for the trajectory prediction with guaranteed coverage level. We evaluate our algorithm on various planning tasks and model-based offline reinforcement learning tasks and show that it reduces the uncertainty of the learned trajectory prediction model. As a by-product, our algorithm PlanCP outperforms prior algorithms on existing offline RL benchmarks and challenging continuous planning tasks. Our method can be combined with most model-based planning approaches to produce uncertainty estimates of the closed-loop system",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=roGYQvarnC": {
    "title": "ConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image",
    "volume": "poster",
    "abstract": "We present a novel method for reconstructing 3D objects from a single RGB image. Our method leverages the latest image generation models to infer the hidden 3D structure while remaining faithful to the input image. While existing methods obtain impressive results in generating 3D models from text prompts, they do not provide an easy approach for conditioning on input RGB data. Naive extensions of these methods often lead to improper alignment in appearance between the input image and the 3D reconstructions. We address these challenges by introducing Image Constrained Radiance Fields (ConRad), a novel variant of neural radiance fields. ConRad is an efficient 3D representation that explicitly captures the appearance of an input image in one viewpoint. We propose a training algorithm that leverages the single RGB image in conjunction with pretrained Diffusion Models to optimize the parameters of a ConRad representation. Extensive experiments show that ConRad representations can simplify preservation of image details while producing a realistic 3D reconstruction. Compared to existing state-of-the-art baselines, we show that our 3D reconstructions remain more faithful to the input and produce more consistent 3D models while demonstrating significantly improved quantitative performance on a ShapeNet object benchmark",
    "checked": true,
    "id": "f7b841060aac8b9f1c39597686325103a2266921",
    "semantic_title": "conrad: image constrained radiance fields for 3d generation from a single image",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=i2H2sEiq2T": {
    "title": "A Unified Fast Gradient Clipping Framework for DP-SGD",
    "volume": "poster",
    "abstract": "A well-known numerical bottleneck in the differentially-private stochastic gradient descent (DP-SGD) algorithm is the computation of the gradient norm for each example in a large input batch. When the loss function in DP-SGD is consists of an intermediate linear operation, existing methods in the literature have proposed decompositions of gradients that are amenable to fast norm computations. In this paper, we present a framework that generalizes the above approach to arbitrary (possibly nonlinear) intermediate operations. Moreover, we show that for certain operations, such as fully-connected and embedding layer computations, further improvements to the runtime and storage costs of existing decompositions can be deduced using certain components of our framework. Finally, preliminary numerical experiments are given to demonstrate the substantial effects of the aforementioned improvements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g27BggUT3L": {
    "title": "LART: Neural Correspondence Learning with Latent Regularization Transformer for 3D Motion Transfer",
    "volume": "poster",
    "abstract": "3D motion transfer aims at transferring the motion from a dynamic input sequence to a static 3D object and outputs an identical motion of the target with high-fidelity and realistic visual effects. In this work, we propose a novel 3D Transformer framework called LART for 3D motion transfer. With carefully-designed architectures, LART is able to implicitly learn the correspondence via a flexible geometry perception. Thus, unlike other existing methods, LART does not require any key point annotations or pre-defined correspondence between the motion source and target meshes and can also handle large-size full-detailed unseen 3D targets. Besides, we introduce a novel latent metric regularization on the Transformer for better motion generation. Our rationale lies in the observation that the decoded motions can be approximately expressed as linearly geometric distortion at the frame level. The metric preservation of motions could be translated to the formation of linear paths in the underlying latent space as a rigorous constraint to control the synthetic motions occurring in the construction of the latent space. The proposed LART shows a high learning efficiency with the need for a few samples from the AMASS dataset to generate motions with plausible visual effects. The experimental results verify the potential of our generative model in applications of motion transfer, content generation, temporal interpolation, and motion denoising. The code is made available: https://github.com/mikecheninoulu/LART",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CBBtMnlTGq": {
    "title": "Neural Data Transformer 2: Multi-context Pretraining for Neural Spiking Activity",
    "volume": "poster",
    "abstract": "The neural population spiking activity recorded by intracortical brain-computer interfaces (iBCIs) contain rich structure. Current models of such spiking activity are largely prepared for individual experimental contexts, restricting data volume to that collectable within a single session and limiting the effectiveness of deep neural networks (DNNs). The purported challenge in aggregating neural spiking data is the pervasiveness of context-dependent shifts in the neural data distributions. However, large scale unsupervised pretraining by nature spans heterogeneous data, and has proven to be a fundamental recipe for successful representation learning across deep learning. We thus develop Neural Data Transformer 2 (NDT2), a spatiotemporal Transformer for neural spiking activity, and demonstrate that pretraining can leverage motor BCI datasets that span sessions, subjects, and experimental tasks. NDT2 enables rapid adaptation to novel contexts in downstream decoding tasks and opens the path to deployment of pretrained DNNs for iBCI control. Code: https://github.com/joel99/context_general_bci",
    "checked": true,
    "id": "3f1b5af721e7085ccedc4a27e1272d412e396ee8",
    "semantic_title": "neural data transformer 2: multi-context pretraining for neural spiking activity",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eXubleMT0q": {
    "title": "Penguin: Parallel-Packed Homomorphic Encryption for Fast Graph Convolutional Network Inference",
    "volume": "poster",
    "abstract": "The marriage of Graph Convolutional Network (GCN) and Homomorphic Encryption (HE) enables the inference of graph data on the cloud with significantly enhanced client data privacy. However, the tremendous computation and memory overhead associated with HE operations challenges the practicality of HE-based GCN inference. GCN inference involves a sequence of expensive matrix-matrix multiplications, and we observe that directly applying the state-of-the-art HE-based secure matrix-matrix multiplication solutions to accelerate HE-GCN inference is far less efficient as it does not exploit the unique aggregation mechanism of two-dimension graph node-features in GCN layer computation. As a result, in this paper, we propose a novel HE-based ciphertext packing technique, i.e., Penguin, that can take advantage of the unique computation pattern during the HE-GCN inference to significantly reduce the computation and memory overhead associated with HE operations. Specifically, Penguin employs (i) an effective two-dimension parallel packing technique for feature ciphertext with optimal graph node partitioning and graph feature interleaving, and (ii) an interleaved assembly technique that can effectively make use of the blank slots to merge ciphertexts after feature reduction and significantly reduce the costly rotation operation. We provide theoretical analysis and experimental validation to demonstrate the speedup achieved by Penguin in accelerating GCN inference using popular GCN models and datasets. Our results show that Penguin can achieve up to $\\sim10\\times$ speedup and around $\\sim79$% reduction in computational memory overhead, significantly outperforming state-of-the-art solutions. To the best of our knowledge, this is the first work that can ensure the protection of both graph structure and features when accelerating HE-GCN inference on encrypted data. Our code is publicly available at https://github.com/ranran0523/Penguin",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SquMNyrk1O": {
    "title": "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
    "volume": "poster",
    "abstract": "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. Previous works usually focus on reducing the number of trainable parameters in the network. While the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. Notably, machine learning models are typically trained using stochastic gradient descent. We argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance. Following this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. Our work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones. By replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size. Under the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes. The code is available at https://anonymous.4open.science/r/WTACRS-A5C5/",
    "checked": true,
    "id": "6d31db7c53853de62cacec26facdb4300d6b5092",
    "semantic_title": "winner-take-all column row sampling for memory efficient adaptation of language model",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=IobxuwPnWt": {
    "title": "SLM: A Smoothed First-Order Lagrangian Method for Structured Constrained Nonconvex Optimization",
    "volume": "poster",
    "abstract": "Functional constrained optimization (FCO) has emerged as a powerful tool for solving various machine learning problems. However, with the rapid increase in applications of neural networks in recent years, it has become apparent that both the objective and constraints often involve nonconvex functions, which poses significant challenges in obtaining high-quality solutions. In this work, we focus on a class of nonconvex FCO problems with nonconvex constraints, where the two optimization variables are nonlinearly coupled in the inequality constraint. Leveraging the primal-dual optimization framework, we propose a smoothed first-order Lagrangian method (SLM) for solving this class of problems. We establish the theoretical convergence guarantees of SLM to the Karush-Kuhn-Tucker (KKT) solutions through quantifying dual error bounds. By establishing connections between this structured FCO and equilibrium-constrained nonconvex problems (also known as bilevel optimization), we apply the proposed SLM to tackle bilevel optimization oriented problems where the lower-level problem is nonconvex. Numerical results obtained from both toy examples and hyper-data cleaning problems demonstrate the superiority of SLM compared to benchmark methods",
    "checked": false,
    "id": "cb100f740cb52abad66028526ba532d60b012949",
    "semantic_title": "level constrained first order methods for function constrained optimization",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=4JB42GBxGs": {
    "title": "Neural approximation of Wasserstein distance via a universal architecture for symmetric and factorwise group invariant functions",
    "volume": "poster",
    "abstract": "Learning distance functions between complex objects, such as the Wasserstein distance to compare point sets, is a common goal in machine learning applications. However, functions on such complex objects (e.g., point sets and graphs) are often required to be invariant to a wide variety of group actions e.g. permutation or rigid transformation. Therefore, continuous and symmetric *product* functions (such as distance functions) on such complex objects must also be invariant to the *product* of such group actions. We call these functions symmetric and factor-wise group invariant functions (or SGFI functions} in short). In this paper, we first present a general neural network architecture for approximating SFGI functions. The main contribution of this paper combines this general NN with a sketching idea in order to develop a specific and efficient neural network which can approximate the $p$-th Wasserstein distance between point sets. Very importantly, the required model complexity is *independent* of the sizes of input point sets. On the theoretical front, to the best of our knowledge, this is the first result showing that there exists a neural network with the capacity to approximate Wasserstein distance with bounded model complexity. Our work provides an interesting integration of sketching ideas for geometric problems with universal approximation of symmetric functions. On the empirical front, we present a range of results showing that our newly proposed neural network architecture performs comparatively or better than other models (including a SOTA Siamese Autoencoder based approach). In particular, our NN generalizes significantly better and trains much faster than the SOTA Siamese AE. Finally, this line of investigation could be useful in exploring effective neural network design for solving a broad range of geometric optimization problems (e.g., $k$-means in a metric space)",
    "checked": true,
    "id": "b7e6ac97498338e1917aea70e2fafdc94a007e38",
    "semantic_title": "neural approximation of wasserstein distance via a universal architecture for symmetric and factorwise group invariant functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w6krZiUa7t": {
    "title": "Hyper-HMM: aligning human brains and semantic features in a common latent event space",
    "volume": "poster",
    "abstract": "Naturalistic stimuli evoke complex neural responses with spatial and temporal properties that differ across individuals. Current alignment methods focus on either spatial hyperalignment (assuming exact temporal correspondence) or temporal alignment (assuming exact spatial correspondence). Here, we propose a hybrid model, the Hyper-HMM, that simultaneously aligns both temporal and spatial features across brains. The model learns to linearly project voxels to a reduced-dimension latent space, in which timecourses are segmented into corresponding temporal events. This approach allows tracking of each individual's mental trajectory through an event sequence, and also allows for alignment with other feature spaces such as stimulus content. Using an fMRI dataset in which students watch videos of class lectures, we demonstrate that the Hyper-HMM can be used to map all participants and the semantic content of the videos into a common low-dimensional space, and that these mappings generalize to held-out data. Our model provides a new window into individual cognitive dynamics evoked by complex naturalistic stimuli",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rDiMgZulwi": {
    "title": "Learning better with Dale's Law: A Spectral Perspective",
    "volume": "poster",
    "abstract": "Most recurrent neural networks (RNNs) do not include a fundamental constraint of real neural circuits: Dale's Law, which implies that neurons must be excitatory (E) or inhibitory (I). Dale's Law is generally absent from RNNs because simply partitioning a standard network's units into E and I populations impairs learning. However, here we extend a recent feedforward bio-inspired EI network architecture, named Dale's ANNs, to recurrent networks, and demonstrate that good performance is possible while respecting Dale's Law. This begs the question: What makes some forms of EI network learn poorly and others learn well? And, why does the simple approach of incorporating Dale's Law impair learning? Historically the answer was thought to be the sign constraints on EI network parameters, and this was a motivation behind Dale's ANNs. However, here we show the spectral properties of the recurrent weight matrix at initialisation are more impactful on network performance than sign constraints. We find that simple EI partitioning results in a singular value distribution that is multimodal and dispersed, whereas standard RNNs have an unimodal, more clustered singular value distribution, as do recurrent Dale's ANNs. We also show that the spectral properties and performance of partitioned EI networks are worse for small networks with fewer I units, and we present normalised SVD entropy as a measure of spectrum pathology that correlates with performance. Overall, this work sheds light on a long-standing mystery in neuroscience-inspired AI and computational neuroscience, paving the way for greater alignment between neural networks and biology",
    "checked": true,
    "id": "c7c58af22c4b387379f49993b53ccece7b8ddd73",
    "semantic_title": "learning better with dale's law: a spectral perspective",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Tz2uONpgpy": {
    "title": "Long Sequence Hopfield Memory",
    "volume": "poster",
    "abstract": "Sequence memory is an essential attribute of natural and artificial intelligence that enables agents to encode, store, and retrieve complex sequences of stimuli and actions. Computational models of sequence memory have been proposed where recurrent Hopfield-like neural networks are trained with temporally asymmetric Hebbian rules. However, these networks suffer from limited sequence capacity (maximal length of the stored sequence) due to interference between the memories. Inspired by recent work on Dense Associative Memories, we expand the sequence capacity of these models by introducing a nonlinear interaction term, enhancing separation between the patterns. We derive novel scaling laws for sequence capacity with respect to network size, significantly outperforming existing scaling laws for models based on traditional Hopfield networks, and verify these theoretical results with numerical simulation. Moreover, we introduce a generalized pseudoinverse rule to recall sequences of highly correlated patterns. Finally, we extend this model to store sequences with variable timing between states' transitions and describe a biologically-plausible implementation, with connections to motor neuroscience",
    "checked": true,
    "id": "fb6dde045c52fe46b409e221e7ef5dc139756d55",
    "semantic_title": "long sequence hopfield memory",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=MlrFYNo1yc": {
    "title": "Minimum norm interpolation by perceptra: Explicit regularization and implicit bias",
    "volume": "poster",
    "abstract": "We investigate how shallow ReLU networks interpolate between known regions. Our analysis shows that empirical risk minimizers converge to a minimum norm interpolant as the number of data points and parameters tends to infinity when a weight decay regularizer is penalized with a coefficient which vanishes at a precise rate as the network width and the number of data points grow. With and without explicit regularization, we numerically study the implicit bias of common optimization algorithms towards known minimum norm interpolants",
    "checked": true,
    "id": "b1c94d76c8772c656bc8fa2944747e277c4b1a2e",
    "semantic_title": "minimum norm interpolation by perceptra: explicit regularization and implicit bias",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=08zf7kTOoh": {
    "title": "Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models",
    "volume": "poster",
    "abstract": "We systematically study a wide variety of generative models spanning semantically-diverse image datasets to understand and improve the feature extractors and metrics used to evaluate them. Using best practices in psychophysics, we measure human perception of image realism for generated samples by conducting the largest experiment evaluating generative models to date, and find that no existing metric strongly correlates with human evaluations. Comparing to 17 modern metrics for evaluating the overall performance, fidelity, diversity, rarity, and memorization of generative models, we find that the state-of-the-art perceptual realism of diffusion models as judged by humans is not reflected in commonly reported metrics such as FID. This discrepancy is not explained by diversity in generated samples, though one cause is over-reliance on Inception-V3. We address these flaws through a study of alternative self-supervised feature extractors, find that the semantic information encoded by individual networks strongly depends on their training procedure, and show that DINOv2-ViT-L/14 allows for much richer evaluation of generative models. Next, we investigate data memorization, and find that generative models do memorize training examples on simple, smaller datasets like CIFAR10, but not necessarily on more complex datasets like ImageNet. However, our experiments show that current metrics do not properly detect memorization: none in the literature is able to separate memorization from other phenomena such as underfitting or mode shrinkage. To facilitate further development of generative models and their evaluation we release all generated image datasets, human evaluation data, and a modular library to compute 17 common metrics for 9 different encoders at https://github.com/layer6ai-labs/dgm-eval",
    "checked": true,
    "id": "caf6ca4ccfabf903003cdf927fb7e883342fdcad",
    "semantic_title": "exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=1ZzG6td0el": {
    "title": "Unified Lower Bounds for Interactive High-dimensional Estimation under Information Constraints",
    "volume": "poster",
    "abstract": "We consider distributed parameter estimation using interactive protocols subject to local information constraints such as bandwidth limitations, local differential privacy, and restricted measurements. We provide a unified framework enabling us to derive a variety of (tight) minimax lower bounds for different parametric families of distributions, both continuous and discrete, under any $\\ell_p$ loss. Our lower bound framework is versatile and yields \"plug-and-play\" bounds that are widely applicable to a large range of estimation problems, and, for the prototypical case of the Gaussian family, circumvents limitations of previous techniques. In particular, our approach recovers bounds obtained using data processing inequalities and Cramér–Rao bounds, two other alternative approaches for proving lower bounds in our setting of interest. Further, for the families considered, we complement our lower bounds with matching upper bounds",
    "checked": false,
    "id": "eb1caf23ffd7068413743d4d15623b82b330ad13",
    "semantic_title": "pointwise bounds for distribution estimation under communication constraints",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=qumBHr77ht": {
    "title": "On the Robustness of Mechanism Design under Total Variation Distance",
    "volume": "poster",
    "abstract": "We study the problem of designing mechanisms when agents' valuation functions are drawn from unknown and correlated prior distributions. In particular, we are given a prior distribution $D$, and we are interested in designing a (truthful) mechanism that has good performance for all \"true distributions\" that are close to $D$ in Total Variation (TV) distance. We show that DSIC and BIC mechanisms in this setting are strongly robust with respect to TV distance, for any bounded objective function $\\mathcal{O}$, extending a recent result of Brustle et al. ([BCD20], EC 2020). At the heart of our result is a fundamental duality property of total variation distance. As direct applications of our result, we (i) demonstrate how to find approximately revenue-optimal and approximately BIC mechanisms for weakly dependent prior distributions; (ii) show how to find correlation-robust mechanisms when only ``noisy'' versions of marginals are accessible, extending recent results of Bei et. al. ([BGLT19], SODA 2019); (iii) prove that prophet-inequality type guarantees are preserved for correlated priors, recovering a variant of a result of D{\\\"u}tting and Kesselheim ([DK19], EC 2019) as a special case; (iv) give a new necessary condition for a correlated distribution to witness an infinite separation in revenue between simple and optimal mechanisms, complementing recent results of Psomas et al. ([PSCW22], NeurIPS 2022); (v) give a new condition for simple mechanisms to approximate revenue-optimal mechanisms for the case of a single agent whose type is drawn from a correlated distribution that can be captured by a Markov Random Field, complementing recent results of Cai and Oikonomou ([CO21], EC 2021)",
    "checked": true,
    "id": "547535539b74ba97e8de7a1e1d665f72a8c3a88d",
    "semantic_title": "on the robustness of mechanism design under total variation distance",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yaJ4vZPnHX": {
    "title": "Complexity of Derivative-Free Policy Optimization for Structured $\\mathcal{H}_\\infty$ Control",
    "volume": "poster",
    "abstract": "The applications of direct policy search in reinforcement learning and continuous control have received increasing attention. In this work, we present novel theoretical results on the complexity of derivative-free policy optimization on an important class of robust control tasks, namely the structured $H_\\infty$ synthesis with static output feedback. Optimal $H_\\infty$ synthesis under structural constraints leads to a constrained nonconvex nonsmooth problem and is typically addressed using subgradient-based policy search techniques that are built upon the concept of Goldstein subdifferential or other notions of enlarged subdifferential. In this paper, we study the complexity of finding $(\\delta,\\epsilon)$-stationary points for such nonsmooth robust control design tasks using policy optimization methods which can only access the zeroth-order oracle (i.e. the $H_\\infty$ norm of the closed-loop system). First, we study the exact oracle setting and identify the coerciveness of the cost function to prove high-probability feasibility/complexity bounds for derivative-free policy optimization on this problem. Next, we derive a sample complexity result for the multi-input multi-output (MIMO) $H_\\infty$-norm estimation. We combine this with our analysis to obtain the first sample complexity of model-free, trajectory-based, zeroth-order policy optimization on finding $(\\delta,\\epsilon)$-stationary points for structured $H_\\infty$ control. Numerical results are also provided to demonstrate our theory",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fU9U7OYxfE": {
    "title": "Asynchronous Proportional Response Dynamics: Convergence in Markets with Adversarial Scheduling",
    "volume": "poster",
    "abstract": "We study Proportional Response Dynamics (PRD) in linear Fisher markets, where participants act asynchronously. We model this scenario as a sequential process in which at each step, an adversary selects a subset of the players to update their bids, subject to liveness constraints. We show that if every bidder individually applies the PRD update rule whenever they are included in the group of bidders selected by the adversary, then, in the generic case, the entire dynamic converges to a competitive equilibrium of the market. Our proof technique reveals additional properties of linear Fisher markets, such as the uniqueness of the market equilibrium for generic parameters and the convergence of associated no swap regret dynamics and best response dynamics under certain conditions",
    "checked": false,
    "id": "a693518831be43a5cc53e79663fa6cb3550281b3",
    "semantic_title": "asynchronous proportional response dynamics in markets with adversarial scheduling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3Wrolscjbx": {
    "title": "Learning via Wasserstein-Based High Probability Generalisation Bounds",
    "volume": "poster",
    "abstract": "Minimising upper bounds on the population risk or the generalisation gap has been widely used in structural risk minimisation (SRM) -- this is in particular at the core of PAC-Bayesian learning. Despite its successes and unfailing surge of interest in recent years, a limitation of the PAC-Bayesian framework is that most bounds involve a Kullback-Leibler (KL) divergence term (or its variations), which might exhibit erratic behavior and fail to capture the underlying geometric structure of the learning problem -- hence restricting its use in practical applications. As a remedy, recent studies have attempted to replace the KL divergence in the PAC-Bayesian bounds with the Wasserstein distance. Even though these bounds alleviated the aforementioned issues to a certain extent, they either hold in expectation, are for bounded losses, or are nontrivial to minimize in an SRM framework. In this work, we contribute to this line of research and prove novel Wasserstein distance-based PAC-Bayesian generalisation bounds for both batch learning with independent and identically distributed (i.i.d.) data, and online learning with potentially non-i.i.d. data. Contrary to previous art, our bounds are stronger in the sense that (i) they hold with high probability, (ii) they apply to unbounded (potentially heavy-tailed) losses, and (iii) they lead to optimizable training objectives that can be used in SRM. As a result we derive novel Wasserstein-based PAC-Bayesian learning algorithms and we illustrate their empirical advantage on a variety of experiments",
    "checked": true,
    "id": "b5e2277d953a319313240cc9a61290edc46f989a",
    "semantic_title": "learning via wasserstein-based high probability generalisation bounds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f6rQJ83ycb": {
    "title": "Reward Finetuning for Faster and More Accurate Unsupervised Object Discovery",
    "volume": "poster",
    "abstract": "Recent advances in machine learning have shown that Reinforcement Learning from Human Feedback (RLHF) can improve machine learning models and align them with human preferences. Although very successful for Large Language Models (LLMs), these advancements have not had a comparable impact in research for autonomous vehicles—where alignment with human expectations can be imperative. In this paper, we propose to adapt similar RL-based methods to unsupervised object discovery, i.e. learning to detect objects from LiDAR points without any training labels. Instead of labels, we use simple heuristics to mimic human feedback. More explicitly, we combine multiple heuristics into a simple reward function that positively correlates its score with bounding box accuracy, i.e., boxes containing objects are scored higher than those without. We start from the detector's own predictions to explore the space and reinforce boxes with high rewards through gradient updates. Empirically, we demonstrate that our approach is not only more accurate, but also orders of magnitudes faster to train compared to prior works on object discovery. Code is available at https://github.com/katieluo88/DRIFT",
    "checked": true,
    "id": "229b546f24fe6487b62b53fb9d4cb327f736e31e",
    "semantic_title": "reward finetuning for faster and more accurate unsupervised object discovery",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rZqRu8e4uc": {
    "title": "Swarm Reinforcement Learning for Adaptive Mesh Refinement",
    "volume": "poster",
    "abstract": "The Finite Element Method, an important technique in engineering, is aided by Adaptive Mesh Refinement (AMR), which dynamically refines mesh regions to allow for a favorable trade-off between computational speed and simulation accuracy. Classical methods for AMR depend on task-specific heuristics or expensive error estimators, hindering their use for complex simulations. Recent learned AMR methods tackle these problems, but so far scale only to simple toy examples. We formulate AMR as a novel Adaptive Swarm Markov Decision Process in which a mesh is modeled as a system of simple collaborating agents that may split into multiple new agents. This framework allows for a spatial reward formulation that simplifies the credit assignment problem, which we combine with Message Passing Networks to propagate information between neighboring mesh elements. We experimentally validate the effectiveness of our approach, Adaptive Swarm Mesh Refinement (ASMR), showing that it learns reliable, scalable, and efficient refinement strategies on a set of challenging problems. Our approach significantly speeds up computation, achieving up to 30-fold improvement compared to uniform refinements in complex simulations. Additionally, we outperform learned baselines and achieve a refinement quality that is on par with a traditional error-based AMR strategy without expensive oracle information about the error signal",
    "checked": true,
    "id": "dd97122422463898e45e4649a59f625d67452c6f",
    "semantic_title": "swarm reinforcement learning for adaptive mesh refinement",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Pl416tPkNv": {
    "title": "Taking the neural sampling code very seriously: A data-driven approach for evaluating generative models of the visual system",
    "volume": "poster",
    "abstract": "Prevailing theories of perception hypothesize that the brain implements perception via Bayesian inference in a generative model of the world. One prominent theory, the Neural Sampling Code (NSC), posits that neuronal responses to a stimulus represent samples from the posterior distribution over latent world state variables that cause the stimulus. Although theoretically elegant, NSC does not specify the exact form of the generative model or prescribe how to link the theory to recorded neuronal activity. Previous works assume simple generative models and test their qualitative agreement with neurophysiological data. Currently, there is no precise alignment of the normative theory with neuronal recordings, especially in response to natural stimuli, and a quantitative, experimental evaluation of models under NSC has been lacking. Here, we propose a novel formalization of NSC, that (a) allows us to directly fit NSC generative models to recorded neuronal activity in response to natural images, (b) formulate richer and more flexible generative models, and (c) employ standard metrics to quantitatively evaluate different generative models under NSC. Furthermore, we derive a stimulus-conditioned predictive model of neuronal responses from the trained generative model using our formalization that we compare to neural system identification models. We demonstrate our approach by fitting and comparing classical- and flexible deep learning-based generative models on population recordings from the macaque primary visual cortex (V1) to natural images, and show that the flexible models outperform classical models in both their generative- and predictive-model performance. Overall, our work is an important step towards a quantitative evaluation of NSC. It provides a framework that lets us \\textit{learn} the generative model directly from neuronal population recordings, paving the way for an experimentally-informed understanding of probabilistic computational principles underlying perception and behavior",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4mXYJzoPhf": {
    "title": "Online Pricing for Multi-User Multi-Item Markets",
    "volume": "poster",
    "abstract": "Online pricing has been the focus of extensive research in recent years, particularly in the context of selling an item to sequentially arriving users. However, what if a provider wants to maximize revenue by selling multiple items to multiple users in each round? This presents a complex problem, as the provider must intelligently offer the items to those users who value them the most without exceeding their highest acceptable prices. In this study, we tackle this challenge by designing online algorithms that can efficiently offer and price items while learning user valuations from accept/reject feedback. We focus on three user valuation models (fixed valuations, random experiences, and random valuations) and provide algorithms with nearly-optimal revenue regret guarantees. In particular, for any market setting with $N$ users, $M$ items, and load $L$ (which roughly corresponds to the maximum number of simultaneous allocations possible), our algorithms achieve regret of order $O(NM\\log\\log(LT))$ under fixed valuations model, $\\widetilde{O}(\\sqrt{NMLT})$ under random experiences model and $\\widetilde{O}(\\sqrt{NMLT})$ under random valuations model in $T$ rounds",
    "checked": false,
    "id": "9a8b698f0d51f875765f245ee0009ba7842c0b18",
    "semantic_title": "interactive recommendations for optimal allocations in markets with constraints",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=YWsPN0EMZr": {
    "title": "Fixing the NTK: From Neural Network Linearizations to Exact Convex Programs",
    "volume": "poster",
    "abstract": "Recently, theoretical analyses of deep neural networks have broadly focused on two directions: 1) Providing insight into neural network training by SGD in the limit of infinite hidden-layer width and infinitesimally small learning rate (also known as gradient flow) via the Neural Tangent Kernel (NTK), and 2) Globally optimizing the regularized training objective via cone-constrained convex reformulations of ReLU networks. The latter research direction also yielded an alternative formulation of the ReLU network, called a gated ReLU network, that is globally optimizable via efficient unconstrained convex programs. In this work, we interpret the convex program for this gated ReLU network as a Multiple Kernel Learning (MKL) model with a weighted data masking feature map and establish a connection to the NTK. Specifically, we show that for a particular choice of mask weights that do not depend on the learning targets, this kernel is equivalent to the NTK of the gated ReLU network on the training data. A consequence of this lack of dependence on the targets is that the NTK cannot perform better than the optimal MKL kernel on the training set. By using iterative reweighting, we improve the weights induced by the NTK to obtain the optimal MKL kernel which is equivalent to the solution of the exact convex reformulation of the gated ReLU network. We also provide several numerical simulations corroborating our theory. Additionally, we provide an analysis of the prediction error of the resulting optimal kernel via consistency results for the group lasso",
    "checked": true,
    "id": "646090314325c23059daa217c0be9f1efb8b14c0",
    "semantic_title": "fixing the ntk: from neural network linearizations to exact convex programs",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8JCZe7QrPy": {
    "title": "Systematic Visual Reasoning through Object-Centric Relational Abstraction",
    "volume": "poster",
    "abstract": "Human visual reasoning is characterized by an ability to identify abstract patterns from only a small number of examples, and to systematically generalize those patterns to novel inputs. This capacity depends in large part on our ability to represent complex visual inputs in terms of both objects and relations. Recent work in computer vision has introduced models with the capacity to extract object-centric representations, leading to the ability to process multi-object visual inputs, but falling short of the systematic generalization displayed by human reasoning. Other recent models have employed inductive biases for relational abstraction to achieve systematic generalization of learned abstract rules, but have generally assumed the presence of object-focused inputs. Here, we combine these two approaches, introducing Object-Centric Relational Abstraction (OCRA), a model that extracts explicit representations of both objects and abstract relations, and achieves strong systematic generalization in tasks (including a novel dataset, CLEVR-ART, with greater visual complexity) involving complex visual displays",
    "checked": true,
    "id": "fc1774419f418fb79451c0bde5d64ae4ce8d5b31",
    "semantic_title": "systematic visual reasoning through object-centric relational abstraction",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=PcKHQFsvel": {
    "title": "On the Statistical Consistency of Risk-Sensitive Bayesian Decision-Making",
    "volume": "poster",
    "abstract": "We study data-driven decision-making problems in the Bayesian framework, where the expectation in the Bayes risk is replaced by a risk-sensitive entropic risk measure with respect to the posterior distribution. We focus on problems where calculating the posterior distribution is intractable, a typical situation in modern applications with large datasets and complex data generating models. We leverage a dual representation of the entropic risk measure to introduce a novel risk-sensitive variational Bayesian (RSVB) framework for jointly computing a risk-sensitive posterior approximation and the corresponding decision rule. Our general framework includes \\textit{loss-calibrated} VB (Lacoste-Julien et al. [2011] ) as a special case. We also study the impact of these computational approximations on the predictive performance of the inferred decision rules. We compute the convergence rates of the RSVB approximate posterior and the corresponding optimal value. We illustrate our theoretical findings in parametric and nonparametric settings with the help of three examples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ezCsMOy1w9": {
    "title": "$\\texttt{TACO}$: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning",
    "volume": "poster",
    "abstract": "Despite recent progress in reinforcement learning (RL) from raw pixel data, sample inefficiency continues to present a substantial obstacle. Prior works have attempted to address this challenge by creating self-supervised auxiliary tasks, aiming to enrich the agent's learned representations with control-relevant information for future state prediction. However, these objectives are often insufficient to learn representations that can represent the optimal policy or value function, and they often consider tasks with small, abstract discrete action spaces and thus overlook the importance of action representation learning in continuous control. In this paper, we introduce $\\texttt{TACO}$: $\\textbf{T}$emporal $\\textbf{A}$ction-driven $\\textbf{CO}$ntrastive Learning, a simple yet powerful temporal contrastive learning approach that facilitates the concurrent acquisition of latent state and action representations for agents. $\\texttt{TACO}$ simultaneously learns a state and an action representation by optimizing the mutual information between representations of current states paired with action sequences and representations of the corresponding future states. Theoretically, $\\texttt{TACO}$ can be shown to learn state and action representations that encompass sufficient information for control, thereby improving sample efficiency. For online RL, $\\texttt{TACO}$ achieves 40% performance boost after one million environment interaction steps on average across nine challenging visual continuous control tasks from Deepmind Control Suite. In addition, we show that $\\texttt{TACO}$ can also serve as a plug-and-play module adding to existing offline visual RL methods to establish the new state-of-the-art performance for offline visual RL across offline datasets with varying quality",
    "checked": false,
    "id": "9b0e89b3770005ad1f79b0d95f951f442f83de23",
    "semantic_title": "taco: temporal latent action-driven contrastive loss for visual reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NKdtztladR": {
    "title": "Latent Diffusion for Language Generation",
    "volume": "poster",
    "abstract": "Diffusion models have achieved great success in modeling continuous data modalities such as images, audio, and video, but have seen limited use in discrete domains such as language. Recent attempts to adapt diffusion to language have presented diffusion as an alternative to existing pretrained language models. We view diffusion and existing language models as complementary. We demonstrate that encoder-decoder language models can be utilized to efficiently learn high-quality language autoencoders. We then demonstrate that continuous diffusion models can be learned in the latent space of the language autoencoder, enabling us to sample continuous latent representations that can be decoded into natural language with the pretrained decoder. We validate the effectiveness of our approach for unconditional, class-conditional, and sequence-to-sequence language generation. We demonstrate across multiple diverse data sets that our latent language diffusion models are significantly more effective than previous diffusion language models. Our code is available at \\url{https://github.com/justinlovelace/latent-diffusion-for-language}",
    "checked": true,
    "id": "23b7cde603b5ec8d5d13d46e1c453dc52d7c3f6c",
    "semantic_title": "latent diffusion for language generation",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=hiQG8qGxso": {
    "title": "Test-Time Amendment with a Coarse Classifier for Fine-Grained Classification",
    "volume": "poster",
    "abstract": "We investigate the problem of reducing mistake severity for fine-grained classification. Fine-grained classification can be challenging, mainly due to the requirement of knowledge or domain expertise for accurate annotation. However, humans are particularly adept at performing coarse classification as it requires relatively low levels of expertise. To this end, we present a novel approach for Post-Hoc Correction called Hierarchical Ensembles (HiE) that utilizes label hierarchy to improve the performance of fine-grained classification at test-time using the coarse-grained predictions. By only requiring the parents of leaf nodes, our method significantly reduces avg. mistake severity while improving top-1 accuracy on the iNaturalist-19 and tieredImageNet-H datasets, achieving a new state-of-the-art on both benchmarks. We also investigate the efficacy of our approach in the semi-supervised setting. Our approach brings notable gains in top-1 accuracy while significantly decreasing the severity of mistakes as training data decreases for the fine-grained classes. The simplicity and post-hoc nature of HiE renders it practical to be used with any off-the-shelf trained model to improve its predictions further",
    "checked": true,
    "id": "af09477e8ecaf750b8730042799fdcadf9a490b7",
    "semantic_title": "test-time amendment with a coarse classifier for fine-grained classification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=6AAbWSF6Qg": {
    "title": "Causal Fairness for Outcome Control",
    "volume": "poster",
    "abstract": "As society transitions towards an AI-based decision-making infrastructure, an ever-increasing number of decisions once under control of humans are now delegated to automated systems. Even though such developments make various parts of society more efficient, a large body of evidence suggests that a great deal of care needs to be taken to make such automated decision-making systems fair and equitable, namely, taking into account sensitive attributes such as gender, race, and religion. In this paper, we study a specific decision-making task called outcome control in which an automated system aims to optimize an outcome variable $Y$ while being fair and equitable. The interest in such a setting ranges from interventions related to criminal justice and welfare, all the way to clinical decision-making and public health. In this paper, we first analyze through causal lenses the notion of benefit, which captures how much a specific individual would benefit from a positive decision, counterfactually speaking, when contrasted with an alternative, negative one. We introduce the notion of benefit fairness, which can be seen as the minimal fairness requirement in decision-making, and develop an algorithm for satisfying it. We then note that the benefit itself may be influenced by the protected attribute, and propose causal tools which can be used to analyze this. Finally, if some of the variations of the protected attribute in the benefit are considered as discriminatory, the notion of benefit fairness may need to be strengthened, which leads us to articulating a notion of causal benefit fairness. Using this notion, we develop a new optimization procedure capable of maximizing $Y$ while ascertaining causal fairness in the decision process",
    "checked": true,
    "id": "6c76d356de2e56dc2a1fd5e3ecd9e573dc231dab",
    "semantic_title": "causal fairness for outcome control",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=izNfcaHJk0": {
    "title": "Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation",
    "volume": "poster",
    "abstract": "Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA). We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and $(\\varepsilon, \\delta)$-differential privacy (DP) constraints. We consider both the central and the multi-message shuffled DP models. We show that in order to achieve the optimal $\\ell_2$ error under $(\\varepsilon, \\delta)$-DP, it is sufficient for each client to send $\\Theta\\left( n \\min\\left(\\varepsilon, \\varepsilon^2\\right)\\right)$ bits for FL %{\\color{blue}(assuming the dimension $d \\gg n \\min\\left(\\varepsilon, \\varepsilon^2\\right)$)} and $\\Theta\\left(\\log\\left( n\\min\\left(\\varepsilon, \\varepsilon^2\\right) \\right)\\right)$ bits for FA to the server, where $n$ is the number of participating clients. Without compression, each client needs $O(d)$ bits and $O\\left(\\log d\\right)$ bits for the mean and frequency estimation problems respectively (where $d$ corresponds to the number of trainable parameters in FL or the domain size in FA), meaning that we can get significant savings in the regime $ n \\min\\left(\\varepsilon, \\varepsilon^2\\right) = o(d)$, which is often the relevant regime in practice. We propose two different ways to leverage compression for privacy amplification and achieve the optimal privacy-communication-accuracy trade-offs. In both cases, each client communicates only partial information about its sample and we show that privacy is amplified by randomly selecting the part contributed by each client. In the first method, the random selection is revealed to the server, which results in a central DP guarantee with optimal privacy-communication-accuracy trade-offs. In the second method, the random data parts from the clients are shuffled by a secure shuffler resulting in a multi-message shuffling scheme with the same optimal trade-offs. As a result, we establish the optimal three-way trade-offs between privacy, communication, and accuracy for both the central DP and multi-message shuffling frameworks",
    "checked": true,
    "id": "b8aee0129293c419a7b0d50b342789a4c38f9623",
    "semantic_title": "privacy amplification via compression: achieving the optimal privacy-accuracy-communication trade-off in distributed mean estimation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=7LSEkvEGCM": {
    "title": "Representation Equivalent Neural Operators: a Framework for Alias-free Operator Learning",
    "volume": "poster",
    "abstract": "Recently, operator learning, or learning mappings between infinite-dimensional function spaces, has garnered significant attention, notably in relation to learning partial differential equations from data. Conceptually clear when outlined on paper, neural operators necessitate discretization in the transition to computer implementations. This step can compromise their integrity, often causing them to deviate from the underlying operators. This research offers a fresh take on neural operators with a framework Representation equivalent Neural Operators (ReNO) designed to address these issues. At its core is the concept of operator aliasing, which measures inconsistency between neural operators and their discrete representations. We explore this for widely-used operator learning techniques. Our findings detail how aliasing introduces errors when handling different discretizations and grids and loss of crucial continuous structures. More generally, this framework not only sheds light on existing challenges but, given its constructive and broad nature, also potentially offers tools for developing new neural operators",
    "checked": true,
    "id": "580b113c16e30818cb2d4e821ea12360fc34915a",
    "semantic_title": "representation equivalent neural operators: a framework for alias-free operator learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=lAEc7aIW20": {
    "title": "Unsupervised Learning for Solving the Travelling Salesman Problem",
    "volume": "poster",
    "abstract": "We propose UTSP, an Unsupervised Learning (UL) framework for solving the Travelling Salesman Problem (TSP). We train a Graph Neural Network (GNN) using a surrogate loss. The GNN outputs a heat map representing the probability for each edge to be part of the optimal path. We then apply local search to generate our final prediction based on the heat map. Our loss function consists of two parts: one pushes the model to find the shortest path and the other serves as a surrogate for the constraint that the route should form a Hamiltonian Cycle. Experimental results show that UTSP outperforms the existing data-driven TSP heuristics. Our approach is parameter efficient as well as data efficient: the model takes $\\sim$ 10\\% of the number of parameters and $\\sim$ 0.2\\% of training samples compared with Reinforcement Learning or Supervised Learning methods",
    "checked": true,
    "id": "9b69a9c46d7261fee37c26ce84c9bfd16e8101eb",
    "semantic_title": "unsupervised learning for solving the travelling salesman problem",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u2RJ0I3o3j": {
    "title": "PlanE: Representation Learning over Planar Graphs",
    "volume": "poster",
    "abstract": "Graph neural networks are prominent models for representation learning over graphs, where the idea is to iteratively compute representations of nodes of an input graph through a series of transformations in such a way that the learned graph function is isomorphism-invariant on graphs, which makes the learned representations graph invariants. On the other hand, it is well-known that graph invariants learned by these class of models are incomplete: there are pairs of non-isomorphic graphs which cannot be distinguished by standard graph neural networks. This is unsurprising given the computational difficulty of graph isomorphism testing on general graphs, but the situation begs to differ for special graph classes, for which efficient graph isomorphism testing algorithms are known, such as planar graphs. The goal of this work is to design architectures for efficiently learning complete invariants of planar graphs. Inspired by the classical planar graph isomorphism algorithm of Hopcroft and Tarjan, we propose PlanE as a framework for planar representation learning. PlanE includes architectures which can learn complete invariants over planar graphs while remaining practically scalable. We empirically validate the strong performance of the resulting model architectures on well-known planar graph benchmarks, achieving multiple state-of-the-art results",
    "checked": true,
    "id": "a9927a4e1c0da6bf5446e3ba93e5c395b3bbd1bf",
    "semantic_title": "plane: representation learning over planar graphs",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5loV5tVzsY": {
    "title": "LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference",
    "volume": "poster",
    "abstract": "The growth of Graph Convolution Network (GCN) model sizes has revolutionized numerous applications, surpassing human performance in areas such as personal healthcare and financial systems. The deployment of GCNs in the cloud raises privacy concerns due to potential adversarial attacks on client data. To address security concerns, Privacy-Preserving Machine Learning (PPML) using Homomorphic Encryption (HE) secures sensitive client data. However, it introduces substantial computational overhead in practical applications. To tackle those challenges, we present LinGCN, a framework designed to reduce multiplication depth and optimize the performance of HE based GCN inference. LinGCN is structured around three key elements: (1) A differentiable structural linearization algorithm, complemented by a parameterized discrete indicator function, co-trained with model weights to meet the optimization goal. This strategy promotes fine-grained node-level non-linear location selection, resulting in a model with minimized multiplication depth. (2) A compact node-wise polynomial replacement policy with a second-order trainable activation function, steered towards superior convergence by a two-level distillation approach from an all-ReLU based teacher model. (3) an enhanced HE solution that enables finer-grained operator fusion for node-wise activation functions, further reducing multiplication level consumption in HE-based inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that LinGCN excels in latency, accuracy, and scalability for homomorphically encrypted inference, outperforming solutions such as CryptoGCN. Remarkably, LinGCN achieves a 14.2× latency speedup relative to CryptoGCN, while preserving an inference accuracy of ~75\\% and notably reducing multiplication depth. Additionally, LinGCN proves scalable for larger models, delivering a substantial 85.78\\% accuracy with 6371s latency, a 10.47\\% accuracy improvement over CryptoGCN",
    "checked": true,
    "id": "b787f4c24bd7b8296bb3837321c25e523f7e0043",
    "semantic_title": "lingcn: structural linearized graph convolutional network for homomorphically encrypted inference",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Zi1KKzh5Aj": {
    "title": "Collapsed Inference for Bayesian Deep Learning",
    "volume": "poster",
    "abstract": "Bayesian neural networks (BNNs) provide a formalism to quantify and calibrate uncertainty in deep learning. Current inference approaches for BNNs often resort to few-sample estimation for scalability, which can harm predictive performance, while its alternatives tend to be computationally prohibitively expensive. We tackle this challenge by revealing a previously unseen connection between inference on BNNs and volume computation problems. With this observation, we introduce a novel collapsed inference scheme that performs Bayesian model averaging using collapsed samples. It improves over a Monte-Carlo sample by limiting sampling to a subset of the network weights while pairing it with some closed-form conditional distribution over the rest. A collapsed sample represents uncountably many models drawn from the approximate posterior and thus yields higher sample efficiency. Further, we show that the marginalization of a collapsed sample can be solved analytically and efficiently despite the non-linearity of neural networks by leveraging existing volume computation solvers. Our proposed use of collapsed samples achieves a balance between scalability and accuracy. On various regression and classification tasks, our collapsed Bayesian deep learning approach demonstrates significant improvements over existing methods and sets a new state of the art in terms of uncertainty estimation as well as predictive performance",
    "checked": true,
    "id": "48d4fa3f664f399a5fcbd70093fcbc0956fa15a4",
    "semantic_title": "collapsed inference for bayesian deep learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=nUbdkXqC8R": {
    "title": "RegBN: Batch Normalization of Multimodal Data with Regularization",
    "volume": "poster",
    "abstract": "Recent years have witnessed a surge of interest in integrating high-dimensional data captured by multisource sensors, driven by the impressive success of neural networks in integrating multimodal data. However, the integration of heterogeneous multimodal data poses a significant challenge, as confounding effects and dependencies among such heterogeneous data sources introduce unwanted variability and bias, leading to suboptimal performance of multimodal models. Therefore, it becomes crucial to normalize the low- or high-level features extracted from data modalities before their fusion takes place. This paper introduces RegBN, a novel approach for multimodal Batch Normalization with REGularization. RegBN uses the Frobenius norm as a regularizer term to address the side effects of confounders and underlying dependencies among different data sources. The proposed method generalizes well across multiple modalities and eliminates the need for learnable parameters, simplifying training and inference. We validate the effectiveness of RegBN on eight databases from five research areas, encompassing diverse modalities such as language, audio, image, video, depth, tabular, and 3D MRI. The proposed method demonstrates broad applicability across different architectures such as multilayer perceptrons, convolutional neural networks, and vision transformers, enabling effective normalization of both low- and high-level features in multimodal neural networks. RegBN is available at https://mogvision.github.io/RegBN",
    "checked": true,
    "id": "ab8f8c7c62a9c1ab2bf18b6afe074d87a2206e2d",
    "semantic_title": "regbn: batch normalization of multimodal data with regularization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rfcak9EV99": {
    "title": "Policy Optimization for Continuous Reinforcement Learning",
    "volume": "poster",
    "abstract": "We study reinforcement learning (RL) in the setting of continuous time and space, for an infinite horizon with a discounted objective and the underlying dynamics driven by a stochastic differential equation. Built upon recent advances in the continuous approach to RL, we develop a notion of occupation time (specifically for a discounted objective), and show how it can be effectively used to derive performance difference and local approximation formulas. We further extend these results to illustrate their applications in the PG (policy gradient) and TRPO/PPO (trust region policy optimization/ proximal policy optimization) methods, which have been familiar and powerful tools in the discrete RL setting but under-developed in continuous RL. Through numerical experiments, we demonstrate the effectiveness and advantages of our approach",
    "checked": true,
    "id": "5b84f988ba68559a6580ffcfafc93fc09d53ae96",
    "semantic_title": "policy optimization for continuous reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=mm9svgvwvk": {
    "title": "A Causal Framework for Decomposing Spurious Variations",
    "volume": "poster",
    "abstract": "One of the fundamental challenges found throughout the data sciences is to explain why things happen in specific ways, or through which mechanisms a certain variable $X$ exerts influences over another variable $Y$. In statistics and machine learning, significant efforts have been put into developing machinery to estimate correlations across variables efficiently. In causal inference, a large body of literature is concerned with the decomposition of causal effects under the rubric of mediation analysis. However, many variations are spurious in nature, including different phenomena throughout the applied sciences. Despite the statistical power to estimate correlations and the identification power to decompose causal effects, there is still little understanding of the properties of spurious associations and how they can be decomposed in terms of the underlying causal mechanisms. In this manuscript, we develop formal tools for decomposing spurious variations in both Markovian and Semi-Markovian models. We prove the first results that allow a non-parametric decomposition of spurious effects and provide sufficient conditions for the identification of such decompositions. The described approach has several applications, ranging from explainable and fair AI to questions in epidemiology and medicine, and we empirically demonstrate its use on a real-world dataset",
    "checked": true,
    "id": "46d1820bfd416887cdfef804a259d09e47188606",
    "semantic_title": "a causal framework for decomposing spurious variations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VAC7aB6qSG": {
    "title": "Video-Mined Task Graphs for Keystep Recognition in Instructional Videos",
    "volume": "poster",
    "abstract": "Procedural activity understanding requires perceiving human actions in terms of a broader task, where multiple keysteps are performed in sequence across a long video to reach a final goal state---such as the steps of a recipe or the steps of a DIY fix-it task. Prior work largely treats keystep recognition in isolation of this broader structure, or else rigidly confines keysteps to align with a particular sequential script. We propose discovering a task graph automatically from how-to videos to represent probabilistically how people tend to execute keysteps, then leverage this graph to regularize keystep recognition in novel videos. On multiple datasets of real-world instructional video, we show the impact: more reliable zero-shot keystep localization and improved video representation learning, exceeding the state of the art",
    "checked": true,
    "id": "6d7b3f5d39b940f8f857470edb26dc87fb213001",
    "semantic_title": "video-mined task graphs for keystep recognition in instructional videos",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=zrUEHZ6s9C": {
    "title": "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
    "volume": "poster",
    "abstract": "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR",
    "checked": true,
    "id": "b732e65c2d5c0bbe868430873ad7f1a682cf2232",
    "semantic_title": "algorithm selection for deep active learning with imbalanced datasets",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PnbCA4ylIc": {
    "title": "Goal Driven Discovery of Distributional Differences via Language Descriptions",
    "volume": "poster",
    "abstract": "Exploring large corpora can generate useful discoveries but is time-consuming for humans. We formulate a new task, D5, that automatically discovers differences between two large corpora in a goal-driven way. The task input is a problem comprising a user-specified research goal (\"*comparing the side effects of drug A and drug*\") and a corpus pair (two large collections of patients' self-reported reactions after taking each drug). The output is a goal-related description (discovery) of how these corpora differ (patients taking drug A \"*mention feelings of paranoia*\" more often). We build a D5 system, and to quantitatively evaluate its performance, we 1) build a diagnostic benchmark, SynD5, to test whether it can recover known differences between two synthetic corpora, and 2) contribute a meta-dataset, OpenD5, aggregating 675 open-ended problems ranging across business, social sciences, humanities, machine learning, and health. With both synthetic and real datasets, we confirm that language models can leverage the user-specified goals to propose more relevant candidate discoveries, and they sometimes produce discoveries previously unknown to the authors, including demographic differences in discussion topics, political stances in speech, insights in commercial reviews, and error patterns in NLP models. Finally, we discuss the limitations of the current D5 system, which discovers correlation rather than causation and has the potential to reinforce societal biases when misused; therefore, practitioners should treat the outputs of our system with caution",
    "checked": true,
    "id": "6aceefb7b260a4797986a5f42bfd474904af3124",
    "semantic_title": "goal driven discovery of distributional differences via language descriptions",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=14ZM7FfPx8": {
    "title": "Towards Understanding the Dynamics of Gaussian-Stein Variational Gradient Descent",
    "volume": "poster",
    "abstract": "Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based deterministic sampling algorithm. Despite its wide usage, understanding the theoretical properties of SVGD has remained a challenging problem. For sampling from a Gaussian target, the SVGD dynamics with a bilinear kernel will remain Gaussian as long as the initializer is Gaussian. Inspired by this fact, we undertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD projected to the family of Gaussian distributions via the bilinear kernel, or equivalently Gaussian variational inference (GVI) with SVGD. We present a complete picture by considering both the mean-field PDE and discrete particle systems. When the target is strongly log-concave, the mean-field Gaussian-SVGD dynamics is proven to converge linearly to the Gaussian distribution closest to the target in KL divergence. In the finite-particle setting, there is both uniform in time convergence to the mean-field limit and linear convergence in time to the equilibrium if the target is Gaussian. In the general case, we propose a density-based and a particle-based implementation of the Gaussian-SVGD, and show that several recent algorithms for GVI, proposed from different perspectives, emerge as special cases of our unified framework. Interestingly, one of the new particle-based instance from this framework empirically outperforms existing approaches. Our results make concrete contributions towards obtaining a deeper understanding of both SVGD and GVI",
    "checked": true,
    "id": "dfa36be09f44496c3b4411a763f7b60df98255b0",
    "semantic_title": "towards understanding the dynamics of gaussian-stein variational gradient descent",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Tj0eXVPnRX": {
    "title": "Loss Dynamics of Temporal Difference Reinforcement Learning",
    "volume": "poster",
    "abstract": "Reinforcement learning has been successful across several applications in which agents have to learn to act in environments with sparse feedback. However, despite this empirical success there is still a lack of theoretical understanding of how the parameters of reinforcement learning models and the features used to represent states interact to control the dynamics of learning. In this work, we use concepts from statistical physics, to study the typical case learning curves for temporal difference learning of a value function with linear function approximators. Our theory is derived under a Gaussian equivalence hypothesis where averages over the random trajectories are replaced with temporally correlated Gaussian feature averages and we validate our assumptions on small scale Markov Decision Processes. We find that the stochastic semi-gradient noise due to subsampling the space of possible episodes leads to significant plateaus in the value error, unlike in traditional gradient descent dynamics. We study how learning dynamics and plateaus depend on feature structure, learning rate, discount factor, and reward function. We then analyze how strategies like learning rate annealing and reward shaping can favorably alter learning dynamics and plateaus. To conclude, our work introduces new tools to open a new direction towards developing a theory of learning dynamics in reinforcement learning",
    "checked": true,
    "id": "15fff00f7ceb51dbe9cbdf26d86907ac1f6ec99f",
    "semantic_title": "loss dynamics of temporal difference reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kJmYu3Ti2z": {
    "title": "When Do Graph Neural Networks Help with Node Classification? Investigating the Homophily Principle on Node Distinguishability",
    "volume": "poster",
    "abstract": "Homophily principle, i.e., nodes with the same labels are more likely to be connected, has been believed to be the main reason for the performance superiority of Graph Neural Networks (GNNs) over Neural Networks on node classification tasks. Recent research suggests that, even in the absence of homophily, the advantage of GNNs still exists as long as nodes from the same class share similar neighborhood patterns. However, this argument only considers intra-class Node Distinguishability (ND) but neglects inter-class ND, which provides incomplete understanding of homophily on GNNs. In this paper, we first demonstrate such deficiency with examples and argue that an ideal situation for ND is to have smaller intra-class ND than inter-class ND. To formulate this idea and study ND deeply, we propose Contextual Stochastic Block Model for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error (PBE) and negative generalized Jeffreys divergence, to quantify ND. With the metrics, we visualize and analyze how graph filters, node degree distributions and class variances influence ND, and investigate the combined effect of intra- and inter-class ND. Besides, we discovered the mid-homophily pitfall, which occurs widely in graph datasets. Furthermore, we verified that, in real-work tasks, the superiority of GNNs is indeed closely related to both intra- and inter-class ND regardless of homophily levels. Grounded in this observation, we propose a new hypothesis-testing based performance metric beyond homophily, which is non-linear, feature-based and can provide statistical threshold value for GNNs' the superiority. Experiments indicate that it is significantly more effective than the existing homophily metrics on revealing the advantage and disadvantage of graph-aware modes on both synthetic and benchmark real-world datasets",
    "checked": false,
    "id": "d6b5fa7e88c0740654529362695612a797df4b5a",
    "semantic_title": "when do graph neural networks help with node classification: investigating the homophily principle on node distinguishability",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=qBAED3u1XZ": {
    "title": "VLATTACK: Multimodal Adversarial Attacks on Vision-Language Tasks via Pre-trained Models",
    "volume": "poster",
    "abstract": "Vision-Language (VL) pre-trained models have shown their superiority on many multimodal tasks. However, the adversarial robustness of such models has not been fully explored. Existing approaches mainly focus on exploring the adversarial robustness under the white-box setting, which is unrealistic. In this paper, we aim to investigate a new yet practical task to craft image and text perturbations using pre-trained VL models to attack black-box fine-tuned models on different downstream tasks. Towards this end, we propose VLATTACK to generate adversarial samples by fusing perturbations of images and texts from both single-modal and multi-modal levels. At the single-modal level, we propose a new block-wise similarity attack (BSA) strategy to learn image perturbations for disrupting universal representations. Besides, we adopt an existing text attack strategy to generate text perturbations independent of the image-modal attack. At the multi-modal level, we design a novel iterative cross-search attack (ICSA) method to update adversarial image-text pairs periodically, starting with the outputs from the single-modal level. We conduct extensive experiments to attack three widely-used VL pretrained models for six tasks on eight datasets. Experimental results show that the proposed VLATTACK framework achieves the highest attack success rates on all tasks compared with state-of-the-art baselines, which reveals a significant blind spot in the deployment of pre-trained VL models",
    "checked": true,
    "id": "8dd9605fbc9702f08a295cba5ae263f625781856",
    "semantic_title": "vlattack: multimodal adversarial attacks on vision-language tasks via pre-trained models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uRHpgo6TMR": {
    "title": "Sampling weights of deep neural networks",
    "volume": "poster",
    "abstract": "We introduce a probability distribution, combined with an efficient sampling algorithm, for weights and biases of fully-connected neural networks. In a supervised learning context, no iterative optimization or gradient computations of internal network parameters are needed to obtain a trained network. The sampling is based on the idea of random feature models. However, instead of a data-agnostic distribution, e.g., a normal distribution, we use both the input and the output training data to sample shallow and deep networks. We prove that sampled networks are universal approximators. For Barron functions, we show that the $L^2$-approximation error of sampled shallow networks decreases with the square root of the number of neurons. Our sampling scheme is invariant to rigid body transformations and scaling of the input data, which implies many popular pre-processing techniques are not required. In numerical experiments, we demonstrate that sampled networks achieve accuracy comparable to iteratively trained ones, but can be constructed orders of magnitude faster. Our test cases involve a classification benchmark from OpenML, sampling of neural operators to represent maps in function spaces, and transfer learning using well-known architectures",
    "checked": true,
    "id": "d896a21150b56027ffa39c7da8390328e36ca196",
    "semantic_title": "sampling weights of deep neural networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=IKjOMA8olL": {
    "title": "Towards Label Position Bias in Graph Neural Networks",
    "volume": "poster",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for semi-supervised node classification tasks. However, recent studies have revealed various biases in GNNs stemming from both node features and graph topology. In this work, we uncover a new bias - label position bias, which indicates that the node closer to the labeled nodes tends to perform better. We introduce a new metric, the Label Proximity Score, to quantify this bias, and find that it is closely related to performance disparities. To address the label position bias, we propose a novel optimization framework for learning a label position unbiased graph structure, which can be applied to existing GNNs. Extensive experiments demonstrate that our proposed method not only outperforms backbone methods but also significantly mitigates the issue of label position bias in GNNs",
    "checked": true,
    "id": "fcf1badf515d74d8ee40fa8e6c64f5464da90c74",
    "semantic_title": "towards label position bias in graph neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o0ggjFD24U": {
    "title": "Active Observing in Continuous-time Control",
    "volume": "poster",
    "abstract": "The control of continuous-time environments while actively deciding when to take costly observations in time is a crucial yet unexplored problem, particularly relevant to real-world scenarios such as medicine, low-power systems, and resource management. Existing approaches either rely on continuous-time control methods that take regular, expensive observations in time or discrete-time control with costly observation methods, which are inapplicable to continuous-time settings due to the compounding discretization errors introduced by time discretization. In this work, we are the first to formalize the continuous-time control problem with costly observations. Our key theoretical contribution shows that observing at regular time intervals is not optimal in certain environments, while irregular observation policies yield higher expected utility. This perspective paves the way for the development of novel methods that can take irregular observations in continuous-time control with costly observations. We empirically validate our theoretical findings in various continuous-time environments, including a cancer simulation, by constructing a simple initial method to solve this new problem, with a heuristic threshold on the variance of reward rollouts in an offline continuous-time model-based model predictive control (MPC) planner. Although determining the optimal method remains an open problem, our work offers valuable insights and understanding of this unique problem, laying the foundation for future research in this area",
    "checked": false,
    "id": "8d12f5f3c4ca261f8dc440a1b9f0beae291acdd4",
    "semantic_title": "design architecture for continuous-time control of dual active bridge converter",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=FxRfAIj4s2": {
    "title": "Neural Image Compression: Generalization, Robustness, and Spectral Biases",
    "volume": "poster",
    "abstract": "Recent advances in neural image compression (NIC) have produced models that are starting to outperform classic codecs. While this has led to growing excitement about using NIC in real-world applications, the successful adoption of any machine learning system in the wild requires it to generalize (and be robust) to unseen distribution shifts at deployment. Unfortunately, current research lacks comprehensive datasets and informative tools to evaluate and understand NIC performance in real-world settings. To bridge this crucial gap, first, this paper presents a comprehensive benchmark suite to evaluate the out-of-distribution (OOD) performance of image compression methods. Specifically, we provide CLIC-C and Kodak-C by introducing 15 corruptions to the popular CLIC and Kodak benchmarks. Next, we propose spectrally-inspired inspection tools to gain deeper insight into errors introduced by image compression methods as well as their OOD performance. We then carry out a detailed performance comparison of several classic codecs and NIC variants, revealing intriguing findings that challenge our current understanding of the strengths and limitations of NIC. Finally, we corroborate our empirical findings with theoretical analysis, providing an in-depth view of the OOD performance of NIC and its dependence on the spectral properties of the data. Our benchmarks, spectral inspection tools, and findings provide a crucial bridge to the real-world adoption of NIC. We hope that our work will propel future efforts in designing robust and generalizable NIC methods. Code and data will be made available at https://github.com/klieberman/ood_nic",
    "checked": true,
    "id": "a68dc1dd73c3f78eae4853fdda23333e69c801a6",
    "semantic_title": "neural image compression: generalization, robustness, and spectral biases",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yPkbdJxQ0o": {
    "title": "Three-Way Trade-Off in Multi-Objective Learning: Optimization, Generalization and Conflict-Avoidance",
    "volume": "poster",
    "abstract": "Multi-objective learning (MOL) often arises in emerging machine learning problems when multiple learning criteria or tasks need to be addressed. Recent works have developed various _dynamic weighting_ algorithms for MOL, including MGDA and its variants, whose central idea is to find an update direction that _avoids conflicts_ among objectives. Albeit its appealing intuition, empirical studies show that dynamic weighting methods may not always outperform static alternatives. To bridge this gap between theory and practice, we focus on a new variant of stochastic MGDA - the Multi-objective gradient with Double sampling (MoDo) algorithm and study its generalization performance and the interplay with optimization through the lens of algorithm stability. We find that the rationale behind MGDA -- updating along conflict-avoidant direction - may \\emph{impede} dynamic weighting algorithms from achieving the optimal ${\\cal O}(1/\\sqrt{n})$ population risk, where $n$ is the number of training samples. We further highlight the variability of dynamic weights and their impact on the three-way trade-off among optimization, generalization, and conflict avoidance that is unique in MOL. Code is available at https://github.com/heshandevaka/Trade-Off-MOL",
    "checked": true,
    "id": "ba1c8e1d51dc8a2685d2f0ddc146c54ef7d61d23",
    "semantic_title": "three-way trade-off in multi-objective learning: optimization, generalization and conflict-avoidance",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=gIG8LvTLuc": {
    "title": "How Does Adaptive Optimization Impact Local Neural Network Geometry?",
    "volume": "poster",
    "abstract": "Adaptive optimization methods are well known to achieve superior convergence relative to vanilla gradient methods. The traditional viewpoint in optimization, particularly in convex optimization, explains this improved performance by arguing that, unlike vanilla gradient schemes, adaptive algorithms mimic the behavior of a second-order method by adapting to the *global* geometry of the loss function. We argue that in the context of neural network optimization, this traditional viewpoint is insufficient. Instead, we advocate for a *local* trajectory analysis. For iterate trajectories produced by running a generic optimization algorithm OPT, we introduce $R^{\\text{OPT}}\\_{\\text{med}}$, a statistic that is analogous to the condition number of the loss Hessian evaluated at the iterates. Through extensive experiments on language models where adaptive algorithms converge faster than vanilla gradient methods like SGD, we show that adaptive methods such as Adam bias the trajectories towards regions where $R^{\\text{Adam}}_{\\text{med}}$ is small, where one might expect faster optimization. By contrast, SGD (with momentum) biases the trajectories towards regions where $R^{\\text{SGD}}\\_{\\text{med}}$ is comparatively large. We complement these empirical observations with a theoretical result that provably demonstrates this phenomenon in the simplified setting of a two-layer linear network. We view our findings as evidence for the need of a new explanation of the success of adaptive methods, one that is different than the conventional wisdom",
    "checked": true,
    "id": "3b823616b94475a07fb646c9387cb0bb924edd91",
    "semantic_title": "how does adaptive optimization impact local neural network geometry?",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=iyweRIXAeH": {
    "title": "Near-Optimal Algorithms for Gaussians with Huber Contamination: Mean Estimation and Linear Regression",
    "volume": "poster",
    "abstract": "We study the fundamental problems of Gaussian mean estimation and linear regression with Gaussian covariates in the presence of Huber contamination. Our main contribution is the design of the first sample near-optimal and almost linear-time algorithms with optimal error guarantees for both these problems. Specifically, for Gaussian robust mean estimation on $\\mathbb R^d$ with contamination parameter $\\epsilon \\in (0, \\epsilon_0)$ for a small absolute constant $\\epsilon_0$, we give an algorithm with sample complexity $n = \\tilde{O}(d/\\epsilon^2)$ and almost linear runtime that approximates the target mean within $\\ell_2$-error $O(\\epsilon)$. This improves on prior work that achieved this error guarantee with polynomially suboptimal sample and time complexity. For robust linear regression, we give the first algorithm with sample complexity $n = \\tilde{O}(d/\\epsilon^2)$ and almost linear runtime that approximates the target regressor within $\\ell_2$-error $O(\\epsilon)$. This is the first polynomial sample and time algorithm achieving the optimal error guarantee, answering an open question in the literature. At the technical level, we develop a methodology that yields almost-linear time algorithms for multi-directional filtering that may be of broader interest",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fPAAgjISu0": {
    "title": "In Defense of Softmax Parametrization for Calibrated and Consistent Learning to Defer",
    "volume": "poster",
    "abstract": "Enabling machine learning classifiers to defer their decision to a downstream expert when the expert is more accurate will ensure improved safety and performance. This objective can be achieved with the learning-to-defer framework which aims to jointly learn how to classify and how to defer to the expert. In recent studies, it has been theoretically shown that popular estimators for learning to defer parameterized with softmax provide unbounded estimates for the likelihood of deferring which makes them uncalibrated. However, it remains unknown whether this is due to the widely used softmax parameterization and if we can find a softmax-based estimator that is both statistically consistent and possesses a valid probability estimator. In this work, we first show that the cause of the miscalibrated and unbounded estimator in prior literature is due to the symmetric nature of the surrogate losses used and not due to softmax. We then propose a novel statistically consistent asymmetric softmax-based surrogate loss that can produce valid estimates without the issue of unboundedness. We further analyze the non-asymptotic properties of our proposed method and empirically validate its performance and calibration on benchmark datasets",
    "checked": true,
    "id": "7dd83c0d4bc97c4153ccfd387420a63094720df1",
    "semantic_title": "in defense of softmax parametrization for calibrated and consistent learning to defer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k4ZCORSFEd": {
    "title": "Streaming Algorithms and Lower Bounds for Estimating Correlation Clustering Cost",
    "volume": "poster",
    "abstract": "Correlation clustering is a fundamental optimization problem at the intersection of machine learning and theoretical computer science. Motivated by applications to big data processing, recent years have witnessed a flurry of results on this problem in the streaming model. In this model, the algorithm needs to process the input $n$-vertex graph by making one or few passes over the stream of its edges and using a limited memory, much smaller than the input size. All previous work on streaming correlation clustering have focused on semi-streaming algorithms with $\\Omega(n)$ memory, whereas in this work, we study streaming algorithms with much smaller memory requirement of only $\\text{polylog}{(n)}$ bits. This stringent memory requirement is in the same spirit of classical streaming algorithms that instead of recovering a full solution to the problem---which can be prohibitively large with such small memory as is the case in our problem---, aimed to learn certain statistical properties of their inputs. In our case, this translates to determining the ``(correlation) clusterability'' of input graphs, or more precisely, estimating the cost of the optimal correlation clustering solution. As our main result, we present two novel algorithms that in only $\\text{polylog}{(n)}$ space are able to estimate the optimal correlation clustering cost up to some constant multiplicative factor plus some extra additive error. One of the algorithms outputs a $3$-multiplicative approximation plus $o(n^2)$ additive approximation, and the other one improves the additive error further down at the cost of increasing the multiplicative factor to some large constant. We then present new lower bounds that justify this mix of both multiplicative and additive error approximation in our algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DrIZZwEZtM": {
    "title": "Gaussian Differential Privacy on Riemannian Manifolds",
    "volume": "poster",
    "abstract": "We develop an advanced approach for extending Gaussian Differential Privacy (GDP) to general Riemannian manifolds. The concept of GDP stands out as a prominent privacy definition that strongly warrants extension to manifold settings, due to its central limit properties. By harnessing the power of the renowned Bishop-Gromov theorem in geometric analysis, we propose a Riemannian Gaussian distribution that integrates the Riemannian distance, allowing us to achieve GDP in Riemannian manifolds with bounded Ricci curvature. To the best of our knowledge, this work marks the first instance of extending the GDP framework to accommodate general Riemannian manifolds, encompassing curved spaces, and circumventing the reliance on tangent space summaries. We provide a simple algorithm to evaluate the privacy budget $\\mu$ on any one-dimensional manifold and introduce a versatile Markov Chain Monte Carlo (MCMC)-based algorithm to calculate $\\mu$ on any Riemannian manifold with constant curvature. Through simulations on one of the most prevalent manifolds in statistics, the unit sphere $S^d$, we demonstrate the superior utility of our Riemannian Gaussian mechanism in comparison to the previously proposed Riemannian Laplace mechanism for implementing GDP",
    "checked": true,
    "id": "fae7be79e900dfbc17348912e3d8c863c7fe816f",
    "semantic_title": "gaussian differential privacy on riemannian manifolds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dcw7qRUuD8": {
    "title": "Deep Gaussian Markov Random Fields for Graph-Structured Dynamical Systems",
    "volume": "poster",
    "abstract": "Probabilistic inference in high-dimensional state-space models is computationally challenging. For many spatiotemporal systems, however, prior knowledge about the dependency structure of state variables is available. We leverage this structure to develop a computationally efficient approach to state estimation and learning in graph-structured state-space models with (partially) unknown dynamics and limited historical data. Building on recent methods that combine ideas from deep learning with principled inference in Gaussian Markov random fields (GMRF), we reformulate graph-structured state-space models as Deep GMRFs defined by simple spatial and temporal graph layers. This results in a flexible spatiotemporal prior that can be learned efficiently from a single time sequence via variational inference. Under linear Gaussian assumptions, we retain a closed-form posterior, which can be sampled efficiently using the conjugate gradient method, scaling favourably compared to classical Kalman filter based approaches",
    "checked": true,
    "id": "66173ff04bc062987a4395181001bf9b7c3eb21b",
    "semantic_title": "deep gaussian markov random fields for graph-structured dynamical systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=COPzNA10hZ": {
    "title": "Norm-based Generalization Bounds for Sparse Neural Networks",
    "volume": "poster",
    "abstract": "In this paper, we derive norm-based generalization bounds for sparse ReLU neural networks, including convolutional neural networks. These bounds differ from previous ones because they consider the sparse structure of the neural network architecture and the norms of the convolutional filters, rather than the norms of the (Toeplitz) matrices associated with the convolutional layers. Theoretically, we demonstrate that these bounds are significantly tighter than standard norm-based generalization bounds. Empirically, they offer relatively tight estimations of generalization for various simple classification problems. Collectively, these findings suggest that the sparsity of the underlying target function and the model's architecture plays a crucial role in the success of deep learning",
    "checked": false,
    "id": "658fbf9874c35b442ca67e3d0077682064808cbf",
    "semantic_title": "norm-based generalization bounds for compositionally sparse neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=tBwRbgsol1": {
    "title": "Replicable Reinforcement Learning",
    "volume": "poster",
    "abstract": "The replicability crisis in the social, behavioral, and data sciences has led to the formulation of algorithm frameworks for replicability --- i.e., a requirement that an algorithm produce identical outputs (with high probability) when run on two different samples from the same underlying distribution. While still in its infancy, provably replicable algorithms have been developed for many fundamental tasks in machine learning and statistics, including statistical query learning, the heavy hitters problem, and distribution testing. In this work we initiate the study of replicable reinforcement learning, providing a provably replicable algorithm for parallel value iteration, and a provably replicable version of R-Max in the episodic setting. These are the first formal replicability results for control problems, which present different challenges for replication than batch learning settings",
    "checked": true,
    "id": "475b6130dcaef639dfd4a2540cd8d85842c854c8",
    "semantic_title": "replicable reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=pTCZWSDltG": {
    "title": "CorresNeRF: Image Correspondence Priors for Neural Radiance Fields",
    "volume": "poster",
    "abstract": "Neural implicit representations in Neural Radiance Fields (NeRF) have achieved impressive results in novel view synthesis and surface reconstruction tasks. However, their performance suffers under challenging scenarios with sparse input views. We present CorresNeRF, a method to leverage image correspondence priors computed by off-the-shelf methods to supervise the training of NeRF. These correspondence priors are first augmented and filtered with our adaptive algorithm. Then they are injected into the training process by adding loss terms on the reprojection error and depth error of the correspondence points. We evaluate our methods on novel view synthesis and surface reconstruction tasks with density-based and SDF-based neural implicit representations across different datasets. We show that this simple yet effective technique can be applied as a plug-and-play module to improve the performance of NeRF under sparse-view settings across different NeRF variants. Our experiments show that we outperform previous methods in both photometric and geometric metrics. The source code is available at https://github.com/yxlao/corres-nerf",
    "checked": false,
    "id": "e52c7512bdcaff569a2e00844089cf59ceb401a1",
    "semantic_title": "explicit correspondence matching for generalizable neural radiance fields",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=xPqINp0Eu1": {
    "title": "Stability of Random Forests and Coverage of Random-Forest Prediction Intervals",
    "volume": "poster",
    "abstract": "We establish stability of random forests under the mild condition that the squared response ($Y^2$) does not have a heavy tail. In particular, our analysis holds for the practical version of random forests that is implemented in popular packages like \\texttt{randomForest} in \\texttt{R}. Empirical results show that stability may persist even beyond our assumption and hold for heavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. With another mild condition that is typically satisfied when $Y$ is continuous, we also establish a complementary upper bound, which can be similarly established for the jackknife prediction interval constructed from an arbitrary stable algorithm. We also discuss the asymptotic coverage probability under assumptions weaker than those considered in previous literature. Our work implies that random forests, with its stability property, is an effective machine learning method that can provide not only satisfactory point prediction but also justified interval prediction at almost no extra computational cost",
    "checked": true,
    "id": "e3597414d6cc5f741636f98eb0181ba7616c7762",
    "semantic_title": "stability of random forests and coverage of random-forest prediction intervals",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=igE3Zbxvws": {
    "title": "Maximum Independent Set: Self-Training through Dynamic Programming",
    "volume": "poster",
    "abstract": "This work presents a graph neural network (GNN) framework for solving the maximum independent set (MIS) problem, inspired by dynamic programming (DP). Specifically, given a graph, we propose a DP-like recursive algorithm based on GNNs that firstly constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call. To train our algorithm, we require annotated comparisons of different graphs concerning their MIS size. Annotating the comparisons with the output of our algorithm leads to a self-training process that results in more accurate self-annotation of the comparisons and vice versa. We provide numerical evidence showing the superiority of our method vs prior methods in multiple synthetic and real-world datasets",
    "checked": true,
    "id": "786ded7849e7b358cefda0fc3f0b8d2a3236b536",
    "semantic_title": "maximum independent set: self-training through dynamic programming",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fTyGT5fulj": {
    "title": "Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First",
    "volume": "poster",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs",
    "checked": true,
    "id": "e45031dc8bac71d86206a6b4b8ad9891b3c43dac",
    "semantic_title": "curriculum learning for graph neural networks: which edges should we learn first",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y5duN2j9s6": {
    "title": "On the Importance of Exploration for Generalization in Reinforcement Learning",
    "volume": "poster",
    "abstract": "Existing approaches for improving generalization in deep reinforcement learning (RL) have mostly focused on representation learning, neglecting RL-specific aspects such as exploration. We hypothesize that the agent's exploration strategy plays a key role in its ability to generalize to new environments. Through a series of experiments in a tabular contextual MDP, we show that exploration is helpful not only for efficiently finding the optimal policy for the training environments but also for acquiring knowledge that helps decision making in unseen environments. Based on these observations, we propose EDE: Exploration via Distributional Ensemble, a method that encourages the exploration of states with high epistemic uncertainty through an ensemble of Q-value distributions. The proposed algorithm is the first value-based approach to achieve strong performance on both Procgen and Crafter, two benchmarks for generalization in RL with high-dimensional observations. The open-sourced implementation can be found at https://github.com/facebookresearch/ede",
    "checked": true,
    "id": "1a73038804052a40c12aae696848ece2168f6da7",
    "semantic_title": "on the importance of exploration for generalization in reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=IyAHCbMq3a": {
    "title": "A Unified Approach to Count-Based Weakly Supervised Learning",
    "volume": "poster",
    "abstract": "High-quality labels are often very scarce, whereas unlabeled data with inferred weak labels occurs more naturally. In many cases, these weak labels dictate the frequency of each respective class over a set of instances. In this paper, we develop a unified approach to learning from such weakly-labeled data, which we call *count-based weakly-supervised learning*. At the heart of our approach is the ability to compute the probability of exactly $k$ out of $n$ outputs being set to true. This computation is differentiable, exact, and efficient. Building upon the previous computation, we derive a *count loss* penalizing the model for deviations in its distribution from an arithmetic constraint defined over label counts",
    "checked": false,
    "id": "2a3757c03859e7be0554b148f922e66948c8f48f",
    "semantic_title": "a unified approach to count-based weakly-supervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VpGFHmI7e5": {
    "title": "Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution",
    "volume": "poster",
    "abstract": "The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged. However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths. We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios. Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining. NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks. At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off. We believe that NaViTmarks a departure from the standard, CNN-designed, input and modelling pipeline used by most computer vision models, and represents a promising direction for ViTs",
    "checked": true,
    "id": "918617dbc02fa4df1999599bcf967acd2ea84d71",
    "semantic_title": "patch n' pack: navit, a vision transformer for any aspect ratio and resolution",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=JkmvrheMe7": {
    "title": "On Single-Index Models beyond Gaussian Data",
    "volume": "poster",
    "abstract": "Sparse high-dimensional functions have arisen as a rich framework to study the behavior of gradient-descent methods using shallow neural networks, and showcasing its ability to perform feature learning beyond linear models. Amongst those functions, the simplest are single-index models $f(x) = \\phi( x \\cdot \\theta^*)$, where the labels are generated by an arbitrary non-linear link function $\\phi$ of an unknown one-dimensional projection $\\theta^*$ of the input data. By focusing on Gaussian data, several recent works have built a remarkable picture, where the so-called information exponent (related to the regularity of the link function) controls the required sample complexity. In essence, these tools exploit the stability and spherical symmetry of Gaussian distributions. In this work, we explore extensions of this picture beyond the Gaussian setting, where both stability or symmetry might be violated. Focusing on the planted setting where $\\phi$ is known, our main results establish that Stochastic Gradient Descent recovers the unknown direction $\\theta^*$ with constant probability in the high-dimensional regime, under mild assumptions that significantly extend ~[Yehudai and Shamir,20]",
    "checked": false,
    "id": "c23d85e038718bd1ff0ada71df70ab1d934800be",
    "semantic_title": "on single index models beyond gaussian data",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=zjpjsJeVJZ": {
    "title": "Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions",
    "volume": "poster",
    "abstract": "Similarity functions measure how comparable pairs of elements are, and play a key role in a wide variety of applications, e.g., notions of Individual Fairness abiding by the seminal paradigm of Dwork et al., as well as Clustering problems. However, access to an accurate similarity function should not always be considered guaranteed, and this point was even raised by Dwork et al. For instance, it is reasonable to assume that when the elements to be compared are produced by different distributions, or in other words belong to different ``demographic'' groups, knowledge of their true similarity might be very difficult to obtain. In this work, we present an efficient sampling framework that learns these across-groups similarity functions, using only a limited amount of experts' feedback. We show analytical results with rigorous theoretical bounds, and empirically validate our algorithms via a large suite of experiments",
    "checked": true,
    "id": "b97145f180fe7f90999bab18528b72f7476690a2",
    "semantic_title": "comparing apples to oranges: learning similarity functions for data produced by different distributions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9B9J8X23LK": {
    "title": "Accelerating Motion Planning via Optimal Transport",
    "volume": "poster",
    "abstract": "Motion planning is still an open problem for many disciplines, e.g., robotics, autonomous driving, due to their need for high computational resources that hinder real-time, efficient decision-making. A class of methods striving to provide smooth solutions is gradient-based trajectory optimization. However, those methods usually suffer from bad local minima, while for many settings, they may be inapplicable due to the absence of easy-to-access gradients of the optimization objectives. In response to these issues, we introduce Motion Planning via Optimal Transport (MPOT)---a \\textit{gradient-free} method that optimizes a batch of smooth trajectories over highly nonlinear costs, even for high-dimensional tasks, while imposing smoothness through a Gaussian Process dynamics prior via the planning-as-inference perspective. To facilitate batch trajectory optimization, we introduce an original zero-order and highly-parallelizable update rule----the Sinkhorn Step, which uses the regular polytope family for its search directions. Each regular polytope, centered on trajectory waypoints, serves as a local cost-probing neighborhood, acting as a \\textit{trust region} where the Sinkhorn Step ``transports'' local waypoints toward low-cost regions. We theoretically show that Sinkhorn Step guides the optimizing parameters toward local minima regions of non-convex objective functions. We then show the efficiency of MPOT in a range of problems from low-dimensional point-mass navigation to high-dimensional whole-body robot motion planning, evincing its superiority compared to popular motion planners, paving the way for new applications of optimal transport in motion planning",
    "checked": true,
    "id": "13de3992d1ff9629cf95910292a7534d77fd6b1e",
    "semantic_title": "accelerating motion planning via optimal transport",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=llP6lmMiXE": {
    "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks",
    "volume": "poster",
    "abstract": "We introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), which we call the $G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the triple-correlation on groups, which is the unique, lowest-degree polynomial invariant map that is also \\textit{complete}. Many commonly used invariant maps\\textemdash such as the \\texttt{max}\\textemdash are incomplete: they remove both group and signal structure. A complete invariant, by contrast, removes only the variation due to the actions of the group, while preserving all information about the structure of the signal. The completeness of the triple correlation endows the $G$-TC layer with strong robustness, which can be observed in its resistance to invariance-based adversarial attacks. In addition, we observe that it yields measurable improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures. We provide a general and efficient implementation of the method for any discretized group, which requires only a table defining the group's product structure. We demonstrate the benefits of this method for $G$-CNNs defined on both commutative and non-commutative groups\\textemdash $SO(2)$, $O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$, chiral octahedral $O$ and full octahedral $O_h$ groups)\\textemdash acting on $\\mathbb{R}^2$ and $\\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10 datasets",
    "checked": true,
    "id": "cffc2d96e015828848409d257f22eeefb7148bb7",
    "semantic_title": "a general framework for robust g-invariance in g-equivariant networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OitmaxSAUu": {
    "title": "Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars",
    "volume": "poster",
    "abstract": "Transformer interpretability aims to understand the algorithm implemented by a learned Transformer by examining various aspects of the model, such as the weight matrices or the attention patterns. In this work, through a combination of theoretical results and carefully controlled experiments on synthetic data, we take a critical view of methods that exclusively focus on individual parts of the model, rather than consider the network as a whole. We consider a simple synthetic setup of learning a (bounded) Dyck language. Theoretically, we show that the set of models that (exactly or approximately) solve this task satisfy a structural characterization derived from ideas in formal languages (the pumping lemma). We use this characterization to show that the set of optima is qualitatively rich; in particular, the attention pattern of a single layer can be \"nearly randomized\", while preserving the functionality of the network. We also show via extensive experiments that these constructions are not merely a theoretical artifact: even with severe constraints to the architecture of the model, vastly different solutions can be reached via standard training. Thus, interpretability claims based on inspecting individual heads or weight matrices in the Transformer can be misleading",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zpVCITHknd": {
    "title": "Towards Personalized Federated Learning via Heterogeneous Model Reassembly",
    "volume": "poster",
    "abstract": "This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner",
    "checked": true,
    "id": "99a0f0f6ada73216389307133e04e9468639fbb2",
    "semantic_title": "towards personalized federated learning via heterogeneous model reassembly",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=AWpWaub6nf": {
    "title": "Every Parameter Matters: Ensuring the Convergence of Federated Learning with Dynamic Heterogeneous Models Reduction",
    "volume": "poster",
    "abstract": "Cross-device Federated Learning (FL) faces significant challenges where low-end clients that could potentially make unique contributions are excluded from training large models due to their resource bottlenecks. Recent research efforts have focused on model-heterogeneous FL, by extracting reduced-size models from the global model and applying them to local clients accordingly. Despite the empirical success, general theoretical guarantees of convergence on this method remain an open question. This paper presents a unifying framework for heterogeneous FL algorithms with online model extraction and provides a general convergence analysis for the first time. In particular, we prove that under certain sufficient conditions and for both IID and non-IID data, these algorithms converge to a stationary point of standard FL for general smooth cost functions. Moreover, we introduce the concept of minimum coverage index, together with model reduction noise, which will determine the convergence of heterogeneous federated learning, and therefore we advocate for a holistic approach that considers both factors to enhance the efficiency of heterogeneous federated learning",
    "checked": true,
    "id": "56a868d761bb8cc35625d354df427aa1a625cd92",
    "semantic_title": "every parameter matters: ensuring the convergence of federated learning with dynamic heterogeneous models reduction",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=OfjVAKx44G": {
    "title": "EgoDistill: Egocentric Head Motion Distillation for Efficient Video Understanding",
    "volume": "poster",
    "abstract": "Recent advances in egocentric video understanding models are promising, but their heavy computational expense is a barrier for many real-world applications. To address this challenge, we propose EgoDistill, a distillation-based approach that learns to reconstruct heavy ego-centric video clip features by combining the semantics from a sparse set of video frames with head motion from lightweight IMU readings. We further devise a novel IMU-based self-supervised pretraining strategy. Our method leads to significant improvements in efficiency, requiring 200× fewer GFLOPs than equivalent video models. We demonstrate its effectiveness on the Ego4D and EPIC- Kitchens datasets, where our method outperforms state-of-the-art efficient video understanding methods",
    "checked": true,
    "id": "6f83eb44dbfbc2ff55c66d40c2a94e8729aa0e85",
    "semantic_title": "egodistill: egocentric head motion distillation for efficient video understanding",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=sxao2udWXi": {
    "title": "A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks",
    "volume": "poster",
    "abstract": "Graph neural networks (GNNs) have become increasingly popular for classification tasks on graph-structured data. Yet, the interplay between graph topology and feature evolution in GNNs is not well understood. In this paper, we focus on node-wise classification, illustrated with community detection on stochastic block model graphs, and explore the feature evolution through the lens of the \"Neural Collapse\" (NC) phenomenon. When training instance-wise deep classifiers (e.g. for image classification) beyond the zero training error point, NC demonstrates a reduction in the deepest features' within-class variability and an increased alignment of their class means to certain symmetric structures. We start with an empirical study that shows that a decrease in within-class variability is also prevalent in the node-wise classification setting, however, not to the extent observed in the instance-wise case. Then, we theoretically study this distinction. Specifically, we show that even an \"optimistic\" mathematical model requires that the graphs obey a strict structural condition in order to possess a minimizer with exact collapse. Furthermore, by studying the gradient dynamics of this model, we provide reasoning for the partial collapse observed empirically. Finally, we present a study on the evolution of within- and between-class feature variability across layers of a well-trained GNN and contrast the behavior with spectral methods",
    "checked": true,
    "id": "278a5e27f70347c78d5ff6131a276883a9e5a42e",
    "semantic_title": "a neural collapse perspective on feature evolution in graph neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=apFDDJOYf5": {
    "title": "FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow",
    "volume": "poster",
    "abstract": "Reconstruction of 3D neural fields from posed images has emerged as a promising method for self-supervised representation learning. The key challenge preventing the deployment of these 3D scene learners on large-scale video data is their dependence on precise camera poses from structure-from-motion, which is prohibitively expensive to run at scale. We propose a method that jointly reconstructs camera poses and 3D neural scene representations online and in a single forward pass. We estimate poses by first lifting frame-to-frame optical flow to 3D scene flow via differentiable rendering, preserving locality and shift-equivariance of the image processing backbone. SE(3) camera pose estimation is then performed via a weighted least-squares fit to the scene flow field. This formulation enables us to jointly supervise pose estimation and a generalizable neural scene representation via re-rendering the input video, and thus, train end-to-end and fully self-supervised on real-world video datasets. We demonstrate that our method performs robustly on diverse, real-world video, notably on sequences traditionally challenging to optimization-based pose estimation techniques",
    "checked": true,
    "id": "fe0c14242aa048354b1e08de068f64200531caf1",
    "semantic_title": "flowcam: training generalizable 3d radiance fields without camera poses via pixel-aligned scene flow",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=qS9aHF8bXz": {
    "title": "Provably Efficient Offline Goal-Conditioned Reinforcement Learning with General Function Approximation and Single-Policy Concentrability",
    "volume": "poster",
    "abstract": "Goal-conditioned reinforcement learning (GCRL) refers to learning general-purpose skills that aim to reach diverse goals. In particular, offline GCRL only requires purely pre-collected datasets to perform training tasks without additional interactions with the environment. Although offline GCRL has become increasingly prevalent and many previous works have demonstrated its empirical success, the theoretical understanding of efficient offline GCRL algorithms is not well established, especially when the state space is huge and the offline dataset only covers the policy we aim to learn. In this paper, we provide a rigorous theoretical analysis of an existing empirically successful offline GCRL algorithm. We prove that under slight modification, this algorithm enjoys an $\\tilde{O}(\\text{poly}(1/\\epsilon))$ sample complexity (where $\\epsilon$ is the desired suboptimality of the learned policy) with general function approximation thanks to the property of (semi-)strong convexity of the objective functions. We only require nearly minimal assumptions on the dataset (single-policy concentrability) and the function class (realizability). Moreover, this algorithm consists of two uninterleaved optimization steps, which we refer to as $V$-learning and policy learning, and is computationally stable since it does not involve minimax optimization. We also empirically validate our theory by showing that the modified algorithm outperforms the previous algorithm in various real-world environments. To the best of our knowledge, this is the first algorithm that is both provably efficient with general function approximation and single-policy concentrability, and empirically successful without requiring solving minimax optimization problems",
    "checked": true,
    "id": "cf8626c23d1d22405b9cc8061044ce7d8f8adf77",
    "semantic_title": "provably efficient offline goal-conditioned reinforcement learning with general function approximation and single-policy concentrability",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=MH7E7AME1r": {
    "title": "Debiasing Conditional Stochastic Optimization",
    "volume": "poster",
    "abstract": "In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure, and therefore requires a high sample complexity for convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than the existing bounds. Additionally, we develop new algorithms for the finite-sum variant of the CSO problem that also significantly improve upon existing results. Finally, we believe that our debiasing technique has the potential to be a useful tool for addressing similar challenges in other stochastic optimization problems",
    "checked": true,
    "id": "c2c5e98cf8b2cab673e3c5db80a374ed2efb0669",
    "semantic_title": "debiasing conditional stochastic optimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hkPn7M9k1W": {
    "title": "Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training",
    "volume": "poster",
    "abstract": "Dynamic Sparse Training (DST) is a rapidly evolving area of research that seeks to optimize the sparse initialization of a neural network by adapting its topology during training. It has been shown that under specific conditions, DST is able to outperform dense models. The key components of this framework are the pruning and growing criteria, which are repeatedly applied during the training process to adjust the network's sparse connectivity. While the growing criterion's impact on DST performance is relatively well studied, the influence of the pruning criterion remains overlooked. To address this issue, we design and perform an extensive empirical analysis of various pruning criteria to better understand their impact on the dynamics of DST solutions. Surprisingly, we find that most of the studied methods yield similar results. The differences become more significant in the low-density regime, where the best performance is predominantly given by the simplest technique: magnitude-based pruning",
    "checked": true,
    "id": "70be7596d63efc18ec7ec9e0613a6136efe8c299",
    "semantic_title": "fantastic weights and how to find them: where to prune in dynamic sparse training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TXq8PCRSoY": {
    "title": "A Variational Perspective on High-Resolution ODEs",
    "volume": "poster",
    "abstract": "We consider unconstrained minimization of smooth convex functions. We propose a novel variational perspective using forced Euler-Lagrange equation that allows for studying high-resolution ODEs. Through this, we obtain a faster convergence rate for gradient norm minimization using Nesterov's accelerated gradient method. Additionally, we show that Nesterov's method can be interpreted as a rate-matching discretization of an appropriately chosen high-resolution ODE. Finally, using the results from the new variational perspective, we propose a stochastic method for noisy gradients. Several numerical experiments compare and illustrate our stochastic algorithm with state of the art methods",
    "checked": true,
    "id": "990ab230ef148700681b6462d1ff2cebec848364",
    "semantic_title": "a variational perspective on high-resolution odes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eU6P4aUdCA": {
    "title": "Algorithmic Regularization in Tensor Optimization: Towards a Lifted Approach in Matrix Sensing",
    "volume": "poster",
    "abstract": "Gradient descent (GD) is crucial for generalization in machine learning models, as it induces implicit regularization, promoting compact representations. In this work, we examine the role of GD in inducing implicit regularization for tensor optimization, particularly within the context of the lifted matrix sensing framework. This framework has been recently proposed to address the non-convex matrix sensing problem by transforming spurious solutions into strict saddles when optimizing over symmetric, rank-1 tensors. We show that, with sufficiently small initialization scale, GD applied to this lifted problem results in approximate rank-1 tensors and critical points with escape directions. Our findings underscore the significance of the tensor parametrization of matrix sensing, in combination with first-order methods, in achieving global optimality in such problems",
    "checked": true,
    "id": "874d0a5969943084c3709cca4ac44136ce4033b6",
    "semantic_title": "algorithmic regularization in tensor optimization: towards a lifted approach in matrix sensing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1GxKVprbwM": {
    "title": "On Computing Pairwise Statistics with Local Differential Privacy",
    "volume": "poster",
    "abstract": "We study the problem of computing pairwise statistics, i.e., ones of the form $\\binom{n}{2}^{-1} \\sum_{i \\ne j} f(x_i, x_j)$, where $x_i$ denotes the input to the $i$th user, with differential privacy (DP) in the local model. This formulation captures important metrics such as Kendall's $\\tau$ coefficient, Area Under Curve, Gini's mean difference, Gini's entropy, etc. We give several novel and generic algorithms for the problem, leveraging techniques from DP algorithms for linear queries",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7Fb2lCwS76": {
    "title": "Change point detection and inference in multivariate non-parametric models under mixing conditions",
    "volume": "poster",
    "abstract": "This paper addresses the problem of localizing and inferring multiple change points, in non-parametric multivariate time series settings. Specifically, we consider a multivariate time series with potentially short-range dependence, whose underlying distributions have Hölder smooth densities and can change over time in a piecewise-constant manner. The change points, which correspond to the times when the distribution changes, are unknown. We present the limiting distributions of the change point estimators under the scenarios where the minimal jump size vanishes or remains constant. Such results have not been revealed in the literature in non-parametric change point settings. As byproducts, we develop a sharp estimator that can accurately localize the change points in multivariate non-parametric time series, and a consistent block-type long-run variance estimator. Numerical studies are provided to complement our theoretical findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UPefaFqjNQ": {
    "title": "Brain encoding models based on multimodal transformers can transfer across language and vision",
    "volume": "poster",
    "abstract": "Encoding models have been used to assess how the human brain represents concepts in language and vision. While language and vision rely on similar concept representations, current encoding models are typically trained and tested on brain responses to each modality in isolation. Recent advances in multimodal pretraining have produced transformers that can extract aligned representations of concepts in language and vision. In this work, we used representations from multimodal transformers to train encoding models that can transfer across fMRI responses to stories and movies. We found that encoding models trained on brain responses to one modality can successfully predict brain responses to the other modality, particularly in cortical regions that represent conceptual meaning. Further analysis of these encoding models revealed shared semantic dimensions that underlie concept representations in language and vision. Comparing encoding models trained using representations from multimodal and unimodal transformers, we found that multimodal transformers learn more aligned representations of concepts in language and vision. Our results demonstrate how multimodal transformers can provide insights into the brain's capacity for multimodal processing",
    "checked": true,
    "id": "32d0ad59162b07bf469b6889930ef1d10e66f7f8",
    "semantic_title": "brain encoding models based on multimodal transformers can transfer across language and vision",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=kJIibP5bq2": {
    "title": "On the Identifiability of Sparse ICA without Assuming Non-Gaussianity",
    "volume": "poster",
    "abstract": "Independent component analysis (ICA) is a fundamental statistical tool used to reveal hidden generative processes from observed data. However, traditional ICA approaches struggle with the rotational invariance inherent in Gaussian distributions, often necessitating the assumption of non-Gaussianity in the underlying sources. This may limit their applicability in broader contexts. To accommodate Gaussian sources, we develop an identifiability theory that relies on second-order statistics without imposing further preconditions on the distribution of sources, by introducing novel assumptions on the connective structure from sources to observed variables. Different from recent work that focuses on potentially restrictive connective structures, our proposed assumption of structural variability is both considerably less restrictive and provably necessary. Furthermore, we propose two estimation methods based on second-order statistics and sparsity constraint. Experimental results are provided to validate our identifiability theory and estimation methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X0CIxqYc4Z": {
    "title": "Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning",
    "volume": "poster",
    "abstract": "Many real-world domains require safe decision making in uncertain environments. In this work, we introduce a deep reinforcement learning framework for approaching this important problem. We consider a distribution over transition models, and apply a risk-averse perspective towards model uncertainty through the use of coherent distortion risk measures. We provide robustness guarantees for this framework by showing it is equivalent to a specific class of distributionally robust safe reinforcement learning problems. Unlike existing approaches to robustness in deep reinforcement learning, however, our formulation does not involve minimax optimization. This leads to an efficient, model-free implementation of our approach that only requires standard data collection from a single training environment. In experiments on continuous control tasks with safety constraints, we demonstrate that our framework produces robust performance and safety at deployment time across a range of perturbed test environments",
    "checked": true,
    "id": "67ce63f8399c3b63da8f8746f312a3f57232edc4",
    "semantic_title": "risk-averse model uncertainty for distributionally robust safe reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=VgQw8zXrH8": {
    "title": "Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models",
    "volume": "poster",
    "abstract": "Text-to-Image diffusion models have made tremendous progress over the past two years, enabling the generation of highly realistic images based on open-domain text descriptions. However, despite their success, text descriptions often struggle to adequately convey detailed controls, even when composed of long and complex texts. Moreover, recent studies have also shown that these models face challenges in understanding such complex texts and generating the corresponding images. Therefore, there is a growing need to enable more control modes beyond text description. In this paper, we introduce Uni-ControlNet, a unified framework that allows for the simultaneous utilization of different local controls (e.g., edge maps, depth map, segmentation masks) and global controls (e.g., CLIP image embeddings) in a flexible and composable manner within one single model. Unlike existing methods, Uni-ControlNet only requires the fine-tuning of two additional adapters upon frozen pre-trained text-to-image diffusion models, eliminating the huge cost of training from scratch. Moreover, thanks to some dedicated adapter designs, Uni-ControlNet only necessitates a constant number (i.e., 2) of adapters, regardless of the number of local or global controls used. This not only reduces the fine-tuning costs and model size, making it more suitable for real-world deployment, but also facilitate composability of different conditions. Through both quantitative and qualitative comparisons, Uni-ControlNet demonstrates its superiority over existing methods in terms of controllability, generation quality and composability. Code is available at https://github.com/ShihaoZhaoZSH/Uni-ControlNet",
    "checked": true,
    "id": "a483ff9557f29d21fe780b3dd969a037a3ffc3ed",
    "semantic_title": "uni-controlnet: all-in-one control to text-to-image diffusion models",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=d2WsCmoITF": {
    "title": "Unbalanced Low-rank Optimal Transport Solvers",
    "volume": "poster",
    "abstract": "The relevance of optimal transport methods to machine learning has long been hindered by two salient limitations. First, the $O(n^3)$ computational cost of standard sample-based solvers (when used on batches of $n$ samples) is prohibitive. Second, the mass conservation constraint makes OT solvers too rigid in practice: because they must match \\textit{all} points from both measures, their output can be heavily influenced by outliers. A flurry of recent works in OT has addressed these computational and modelling limitations, but has resulted in two separate strains of methods: While the computational outlook was much improved by entropic regularization, more recent $O(n)$ linear-time \\textit{low-rank} solvers hold the promise to scale up OT further. On the other hand, modelling rigidities have been eased owing to unbalanced variants of OT, that rely on penalization terms to promote, rather than impose, mass conservation. The goal of this paper is to merge these two strains, to achieve the promise of \\textit{both} versatile/scalable unbalanced/low-rank OT solvers. We propose custom algorithms to implement these extensions for the linear OT problem and its Fused-Gromov-Wasserstein generalization, and demonstrate their practical relevance to challenging spatial transcriptomics matching problems",
    "checked": true,
    "id": "04b067014849852f1ffd8ca240436522e202c0af",
    "semantic_title": "unbalanced low-rank optimal transport solvers",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=kshC3NOP6h": {
    "title": "Towards Last-layer Retraining for Group Robustness with Fewer Annotations",
    "volume": "poster",
    "abstract": "Empirical risk minimization (ERM) of neural networks is prone to over-reliance on spurious correlations and poor generalization on minority groups. The recent deep feature reweighting (DFR) technique achieves state-of-the-art group robustness via simple last-layer retraining, but it requires held-out group and class annotations to construct a group-balanced reweighting dataset. In this work, we examine this impractical requirement and find that last-layer retraining can be surprisingly effective with no group annotations (other than for model selection) and only a handful of class annotations. We first show that last-layer retraining can greatly improve worst-group accuracy even when the reweighting dataset has only a small proportion of worst-group data. This implies a \"free lunch\" where holding out a subset of training data to retrain the last layer can substantially outperform ERM on the entire dataset with no additional data, annotations, or computation for training. To further improve group robustness, we introduce a lightweight method called selective last-layer finetuning (SELF), which constructs the reweighting dataset using misclassifications or disagreements. Our experiments present the first evidence that model disagreement upsamples worst-group data, enabling SELF to nearly match DFR on four well-established benchmarks across vision and language tasks with no group annotations and less than 3% of the held-out class annotations",
    "checked": true,
    "id": "2d14697232f03661cb86246df46e52816694a97f",
    "semantic_title": "towards last-layer retraining for group robustness with fewer annotations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=AQyqxXctsN": {
    "title": "Differentiable Sampling of Categorical Distributions Using the CatLog-Derivative Trick",
    "volume": "poster",
    "abstract": "Categorical random variables can faithfully represent the discrete and uncertain aspects of data as part of a discrete latent variable model. Learning in such models necessitates taking gradients with respect to the parameters of the categorical probability distributions, which is often intractable due to their combinatorial nature. A popular technique to estimate these otherwise intractable gradients is the Log-Derivative trick. This trick forms the basis of the well-known REINFORCE gradient estimator and its many extensions. While the Log-Derivative trick allows us to differentiate through samples drawn from categorical distributions, it does not take into account the discrete nature of the distribution itself. Our first contribution addresses this shortcoming by introducing the CatLog-Derivative trick -- a variation of the Log-Derivative trick tailored towards categorical distributions. Secondly, we use the CatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient estimator for the important case of products of independent categorical distributions with provably lower variance than REINFORCE. Thirdly, we empirically show that IndeCateR can be efficiently implemented and that its gradient estimates have significantly lower bias and variance for the same number of samples compared to the state of the art",
    "checked": true,
    "id": "db5463470183203d89f35983bd56ff265344538c",
    "semantic_title": "differentiable sampling of categorical distributions using the catlog-derivative trick",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4e0NJbkkd8": {
    "title": "Importance Weighted Actor-Critic for Optimal Conservative Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "We propose A-Crab (Actor-Critic Regularized by Average Bellman error), a new practical algorithm for offline reinforcement learning (RL) in complex environments with insufficient data coverage. Our algorithm combines the marginalized importance sampling framework with the actor-critic paradigm, where the critic returns evaluations of the actor (policy) that are pessimistic relative to the offline data and have a small average (importance-weighted) Bellman error. Compared to existing methods, our algorithm simultaneously offers a number of advantages: (1) It achieves the optimal statistical rate of $1/\\sqrt{N}$---where $N$ is the size of offline dataset---in converging to the best policy covered in the offline dataset, even when combined with general function approximators. (2) It relies on a weaker \\textit{average} notion of policy coverage (compared to the $\\ell_\\infty$ single-policy concentrability) that exploits the structure of policy visitations. (3) It outperforms the data-collection behavior policy over a wide range of specific hyperparameters. We provide both theoretical analysis and experimental results to validate the effectiveness of our proposed algorithm. The code is available at https://github.com/zhuhl98/ACrab",
    "checked": true,
    "id": "b47e3d1cebb549d4ed9f420fc2ebadabc8997a9c",
    "semantic_title": "importance weighted actor-critic for optimal conservative offline reinforcement learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=CEk6JK71Mb": {
    "title": "Meet in the Middle: A New Pre-training Paradigm",
    "volume": "poster",
    "abstract": "Most language models (LMs) are trained and applied in an autoregressive left-to-right fashion, predicting the next token from the preceding ones. However, this ignores that the full sequence is available during training. In this paper, we introduce ``Meet in the Middle'' (MIM) a new pre-training paradigm that improves data efficiency by training in two directions, left-to-right and right-to-left, and encouraging the respective models to agree on their token distribution for each position. While the primary outcome is an improved left-to-right LM, we also obtain secondary benefits in the infilling task. There, we leverage the two pre-trained directions to propose an infilling procedure that builds the completion simultaneously from both sides. We conduct extensive experiments on both programming and natural languages and show that MIM significantly surpasses existing pre-training paradigms, in both left-to-right generation as well as infilling. Code and models available at https://github.com/microsoft/Meet-in-the-Middle",
    "checked": true,
    "id": "fbdd496c421e050a47c4fb2e0019635d2f4b97e7",
    "semantic_title": "meet in the middle: a new pre-training paradigm",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=hSkEcIFi3o": {
    "title": "Adversarial Examples Are Not Real Features",
    "volume": "poster",
    "abstract": "The existence of adversarial examples has been a mystery for years and attracted much interest. A well-known theory by \\citet{ilyas2019adversarial} explains adversarial vulnerability from a data perspective by showing that one can extract non-robust features from adversarial examples and these features alone are useful for classification. However, the explanation remains quite counter-intuitive since non-robust features are mostly noise features to humans. In this paper, we re-examine the theory from a larger context by incorporating multiple learning paradigms. Notably, we find that contrary to their good usefulness under supervised learning, non-robust features attain poor usefulness when transferred to other self-supervised learning paradigms, such as contrastive learning, masked image modeling, and diffusion models. It reveals that non-robust features are not really as useful as robust or natural features that enjoy good transferability between these paradigms. Meanwhile, for robustness, we also show that naturally trained encoders from robust features are largely non-robust under AutoAttack. Our cross-paradigm examination suggests that the non-robust features are not really useful but more like paradigm-wise shortcuts, and robust features alone might be insufficient to attain reliable model robustness. Code is available at \\url{https://github.com/PKU-ML/AdvNotRealFeatures}",
    "checked": true,
    "id": "8889c5a2326b137fd544ec933c1136e9e38eca27",
    "semantic_title": "adversarial examples are not real features",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Iq7v0sZw2H": {
    "title": "Debiasing Pretrained Generative Models by Uniformly Sampling Semantic Attributes",
    "volume": "poster",
    "abstract": "Generative models are being increasingly used in science and industry applications. Unfortunately, they often perpetuate the biases present in their training sets, such as societal biases causing certain groups to be underrepresented in the data. For instance, image generators may overwhelmingly produce images of white people due to few non-white samples in their training data. It is imperative to debias generative models so they synthesize an equal number of instances for each group, while not requiring retraining of the model to avoid prohibitive expense. We thus propose a *distribution mapping module* that produces samples from a *fair noise distribution*, such that the pretrained generative model produces *semantically uniform* outputs - an equal number of instances for each group - when conditioned on these samples. This does *not* involve retraining the generator, nor does it require *any* real training data. Experiments on debiasing generators trained on popular real-world datasets show that our method outperforms existing approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A5yMv7XPuA": {
    "title": "Combinatorial Group Testing with Selfish Agents",
    "volume": "poster",
    "abstract": "We study the Combinatorial Group Testing (CGT) problem in a novel game-theoretic framework, with a solution concept of Adversarial Equilibrium (AE). In this new framework, we have $n$ selfish agents corresponding to the elements of the universe $[n] =\\{0,1,\\ldots,n-1\\}$ and a hidden set $K \\subseteq [n]$ of active agents of size $|K| = k \\ll n$. In each round of the game, each active agent decides if it is present in a query $Q \\subseteq [n]$, and all agents receive feedback on $Q \\cap K$. The goal of each active agent is to assure that its id could be learned from the feedback as early as possible. We present a comprehensive set of results in this new game, where we design and analyze adaptive algorithmic strategies of agents which are AE's. In particular, if $k$ is known to the agents, then we design adaptive AE strategies with provably near optimal learning time of $O(k \\log(n/k))$. In the case of unknown $k$, we design an adaptive AE strategies with learning time of order $n^k$, and we prove a lower bound of $\\Omega(n)$ on the learning time of any such algorithmic strategies. This shows a strong separations between the two models of known and unknown $k$, as well as between the classic CGT, i.e., without selfish agents, and our game theoretic CGT model",
    "checked": false,
    "id": "13775e7d59aedcfe993d86f68ea2f644aadecaa7",
    "semantic_title": "piecewise-stationary combinatorial semi-bandit with causally related rewards",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J0RD92Tmfc": {
    "title": "A graphon-signal analysis of graph neural networks",
    "volume": "poster",
    "abstract": "We present an approach for analyzing message passing graph neural networks (MPNNs) based on an extension of graphon analysis to a so called graphon-signal analysis. A MPNN is a function that takes a graph and a signal on the graph (a graph-signal) and returns some value. Since the input space of MPNNs is non-Euclidean, i.e., graphs can be of any size and topology, properties such as generalization are less well understood for MPNNs than for Euclidean neural networks. We claim that one important missing ingredient in past work is a meaningful notion of graph-signal similarity measure, that endows the space of inputs to MPNNs with a regular structure. We present such a similarity measure, called the graphon-signal cut distance, which makes the space of all graph-signals a dense subset of a compact metric space -- the graphon-signal space. Informally, two deterministic graph-signals are close in cut-distance if they ``look like'' they were sampled from the same random graph-signal model. Hence, our cut distance is a natural notion of graph-signal similarity, which allows comparing any pair of graph-signals of any size and topology. We prove that MPNNs are Lipschitz continuous functions over the graphon-signal metric space. We then give two applications of this result: 1) a generalization bound for MPNNs, and, 2) the stability of MPNNs to subsampling of graph-signals. Our results apply to any regular enough MPNN on any distribution of graph-signals, making the analysis rather universal",
    "checked": true,
    "id": "f42898181e56cb6fee860143c96663ed361449e0",
    "semantic_title": "a graphon-signal analysis of graph neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=EWNtYvepJh": {
    "title": "Generative Neural Fields by Mixtures of Neural Implicit Functions",
    "volume": "poster",
    "abstract": "We propose a novel approach to learning the generative neural fields represented by linear combinations of implicit basis networks. Our algorithm learns basis networks in the form of implicit neural representations and their coefficients in a latent space by either conducting meta-learning or adopting auto-decoding paradigms. The proposed method easily enlarges the capacity of generative neural fields by increasing the number of basis networks while maintaining the size of a network for inference to be small through their weighted model averaging. Consequently, sampling instances using the model is efficient in terms of latency and memory footprint. Moreover, we customize denoising diffusion probabilistic model for a target task to sample latent mixture coefficients, which allows our final model to generate unseen data effectively. Experiments show that our approach achieves competitive generation performance on diverse benchmarks for images, voxel data, and NeRF scenes without sophisticated designs for specific modalities and domains",
    "checked": true,
    "id": "6ff14e75df375f7888aa9a0727f6bf8c456911d0",
    "semantic_title": "generative neural fields by mixtures of neural implicit functions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=YcmGuwdLoU": {
    "title": "Real-Time Motion Prediction via Heterogeneous Polyline Transformer with Relative Pose Encoding",
    "volume": "poster",
    "abstract": "The real-world deployment of an autonomous driving system requires its components to run on-board and in real-time, including the motion prediction module that predicts the future trajectories of surrounding traffic participants. Existing agent-centric methods have demonstrated outstanding performance on public benchmarks. However, they suffer from high computational overhead and poor scalability as the number of agents to be predicted increases. To address this problem, we introduce the K-nearest neighbor attention with relative pose encoding (KNARPE), a novel attention mechanism allowing the pairwise-relative representation to be used by Transformers. Then, based on KNARPE we present the Heterogeneous Polyline Transformer with Relative pose encoding (HPTR), a hierarchical framework enabling asynchronous token update during the online inference. By sharing contexts among agents and reusing the unchanged contexts, our approach is as efficient as scene-centric methods, while performing on par with state-of-the-art agent-centric methods. Experiments on Waymo and Argoverse-2 datasets show that HPTR achieves superior performance among end-to-end methods that do not apply expensive post-processing or model ensembling. The code is available at https://github.com/zhejz/HPTR",
    "checked": true,
    "id": "a03f5b8d293fdb0e56b178cfaa01788a9c5a8458",
    "semantic_title": "real-time motion prediction via heterogeneous polyline transformer with relative pose encoding",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mlbes5TAAg": {
    "title": "Unleashing the Power of Randomization in Auditing Differentially Private ML",
    "volume": "poster",
    "abstract": "We present a rigorous methodology for auditing differentially private machine learning by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with $K$ canaries versus $K-1$ canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both theoretically and empirically, using synthetic and real data. Further, recent advances in designing stronger canaries can be readily incorporated in the new framework",
    "checked": true,
    "id": "2691f426b7dcc242f8f4c268a6fc8c3fc524b822",
    "semantic_title": "unleashing the power of randomization in auditing differentially private ml",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=bprclnHNvm": {
    "title": "SyncTREE: Fast Timing Analysis for Integrated Circuit Design through a Physics-informed Tree-based Graph Neural Network",
    "volume": "poster",
    "abstract": "Nowadays integrated circuits (ICs) are underpinning all major information technology innovations including the current trends of artificial intelligence (AI). Modern IC designs often involve analyses of complex phenomena (such as timing, noise, and power etc.) for tens of billions of electronic components, like resistance (R), capacitance (C), transistors and gates, interconnected in various complex structures. Those analyses often need to strike a balance between accuracy and speed as those analyses need to be carried out many times throughout the entire IC design cycles. With the advancement of AI, researchers also start to explore news ways in leveraging AI to improve those analyses. This paper focuses on one of the most important analyses, timing analysis for interconnects. Since IC interconnects can be represented as an RC-tree, a specialized graph as tree, we design a novel tree-based graph neural network, SyncTREE, to speed up the timing analysis by incorporating both the structural and physical properties of electronic circuits. Our major innovations include (1) a two-pass message-passing (bottom-up and top-down) for graph embedding, (2) a tree contrastive loss to guide learning, and (3) a closed formular-based approach to conduct fast timing. Our experiments show that, compared to conventional GNN models, SyncTREE achieves the best timing prediction in terms of both delays and slews, all in reference to the industry golden numerical analyses results on real IC design data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A86JTXllHa": {
    "title": "On the Importance of Feature Separability in Predicting Out-Of-Distribution Error",
    "volume": "poster",
    "abstract": "Estimating the generalization performance is practically challenging on out-of-distribution (OOD) data without ground-truth labels. While previous methods emphasize the connection between distribution difference and OOD accuracy, we show that a large domain gap not necessarily leads to a low test accuracy. In this paper, we investigate this problem from the perspective of feature separability empirically and theoretically. Specifically, we propose a dataset-level score based upon feature dispersion to estimate the test accuracy under distribution shift. Our method is inspired by desirable properties of features in representation learning: high inter-class dispersion and high intra-class compactness. Our analysis shows that inter-class dispersion is strongly correlated with the model accuracy, while intra-class compactness does not reflect the generalization performance on OOD data. Extensive experiments demonstrate the superiority of our method in both prediction performance and computational efficiency",
    "checked": true,
    "id": "13bfdd929b91164c32643bddb566bcce02ccf6b5",
    "semantic_title": "on the importance of feature separability in predicting out-of-distribution error",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NG4DaApavi": {
    "title": "Monte Carlo Tree Search with Boltzmann Exploration",
    "volume": "poster",
    "abstract": "Monte-Carlo Tree Search (MCTS) methods, such as Upper Confidence Bound applied to Trees (UCT), are instrumental to automated planning techniques. However, UCT can be slow to explore an optimal action when it initially appears inferior to other actions. Maximum ENtropy Tree-Search (MENTS) incorporates the maximum entropy principle into an MCTS approach, utilising Boltzmann policies to sample actions, naturally encouraging more exploration. In this paper, we highlight a major limitation of MENTS: optimal actions for the maximum entropy objective do not necessarily correspond to optimal actions for the original objective. We introduce two algorithms, Boltzmann Tree Search (BTS) and Decaying ENtropy Tree-Search (DENTS), that address these limitations and preserve the benefits of Boltzmann policies, such as allowing actions to be sampled faster by using the Alias method. Our empirical analysis shows that our algorithms show consistent high performance across several benchmark domains, including the game of Go",
    "checked": false,
    "id": "d1774dde042125083613cbdeef2eb5e5a68255d2",
    "semantic_title": "on using monte-carlo tree search to solve puzzles",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=z9d9DsjAPH": {
    "title": "CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation",
    "volume": "poster",
    "abstract": "Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual prompt. Cyclenet is a practical framework, which is robust even with very limited training data (around 2k) and requires minimal computational resources (1 GPU) to train. Project homepage: https://cyclenetweb.github.io/",
    "checked": true,
    "id": "2d895c3153a80d281428a14d14ae121536fe790d",
    "semantic_title": "cyclenet: rethinking cycle consistency in text-guided diffusion for image manipulation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Fqg9vGWy4k": {
    "title": "Faster approximate subgraph counts with privacy",
    "volume": "poster",
    "abstract": "One of the most common problems studied in the context of differential privacy for graph data is counting the number of non-induced embeddings of a subgraph in a given graph. These counts have very high global sensitivity. Therefore, adding noise based on powerful alternative techniques, such as smooth sensitivity and higher-order local sensitivity have been shown to give significantly better accuracy. However, all these alternatives to global sensitivity become computationally very expensive, and to date efficient polynomial time algorithms are known only for few selected subgraphs, such as triangles, $k$-triangles, and $k$-stars. In this paper, we show that good approximations to these sensitivity metrics can be still used to get private algorithms. Using this approach, we show the first quasilinear time and parallel algorithms for privately counting the number of triangles. We also give a private polynomial time algorithm for counting any constant size subgraph using less noise than the global sensitivity; we show this can be improved significantly for counting paths in special classes of graphs",
    "checked": false,
    "id": "063cd28574c4e592c8730266e7dab4dff24384bd",
    "semantic_title": "efficiently counting substructures by subgraph gnns without running gnn on subgraphs",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=eqyhjLG5Nr": {
    "title": "Supply-Side Equilibria in Recommender Systems",
    "volume": "poster",
    "abstract": "Algorithmic recommender systems such as Spotify and Netflix affect not only consumer behavior but also *producer incentives*. Producers seek to create content that will be shown by the recommendation algorithm, which can impact both the diversity and quality of their content. In this work, we investigate the resulting supply-side equilibria in personalized content recommender systems. We model the decisions of producers as choosing *multi-dimensional* content vectors and users as having *heterogenous* preferences, which contrasts with classical low-dimensional models. Multi-dimensionality and heterogeneity creates the potential for *specialization*, where different producers create different types of content at equilibrium. Using a duality argument, we derive necessary and sufficient conditions for whether specialization occurs. Then, we characterize the distribution of content at equilibrium in concrete settings with two populations of users. Lastly, we show that specialization can enable producers to achieve *positive profit at equilibrium*, which means that specialization can reduce the competitiveness of the marketplace. At a conceptual level, our analysis of supply-side competition takes a step towards elucidating how personalized recommendations shape the marketplace of digital goods",
    "checked": true,
    "id": "2839009c867435ebcf117d341a28f1534382a02b",
    "semantic_title": "supply-side equilibria in recommender systems",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=CXrRMfs5eY": {
    "title": "PETAL: Physics Emulation Through Averaged Linearizations for Solving Inverse Problems",
    "volume": "poster",
    "abstract": "Inverse problems describe the task of recovering an underlying signal of interest given observables. Typically, the observables are related via some non-linear forward model applied to the underlying unknown signal. Inverting the non-linear forward model can be computationally expensive, as it often involves computing and inverting a linearization at a series of estimates. Rather than inverting the physics-based model, we instead train a surrogate forward model (emulator) and leverage modern auto-grad libraries to solve for the input within a classical optimization framework. Current methods to train emulators are done in a black box supervised machine learning fashion and fail to take advantage of any existing knowledge of the forward model. In this article, we propose a simple learned weighted average model that embeds linearizations of the forward model around various reference points into the model itself, explicitly incorporating known physics. Grounding the learned model with physics based linearizations improves the forward modeling accuracy and provides richer physics based gradient information during the inversion process leading to more accurate signal recovery. We demonstrate the efficacy on an ocean acoustic tomography (OAT) example that aims to recover ocean sound speed profile (SSP) variations from acoustic observations (e.g. eigenray arrival times) within simulation of ocean dynamics in the Gulf of Mexico",
    "checked": true,
    "id": "43f1925c9bb4c8a1d74bd997530d695ff515447f",
    "semantic_title": "petal: physics emulation through averaged linearizations for solving inverse problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ONwL9ucoYG": {
    "title": "Robust Contrastive Language-Image Pretraining against Data Poisoning and Backdoor Attacks",
    "volume": "poster",
    "abstract": "Contrastive vision-language representation learning has achieved state-of-the-art performance for zero-shot classification, by learning from millions of image-caption pairs crawled from the internet. However, the massive data that powers large multimodal models such as CLIP, makes them extremely vulnerable to various types of targeted data poisoning and backdoor attacks. Despite this vulnerability, robust contrastive vision-language pre-training against such attacks has remained unaddressed. In this work, we propose RoCLIP, the first effective method for robust pre-training multimodal vision-language models against targeted data poisoning and backdoor attacks. RoCLIP effectively breaks the association between poisoned image-caption pairs by considering a relatively large and varying pool of random captions, and matching every image with the text that is most similar to it in the pool instead of its own caption, every few epochs.It also leverages image and text augmentations to further strengthen the defense and improve the performance of the model. Our extensive experiments show that RoCLIP renders state-of-the-art targeted data poisoning and backdoor attacks ineffective during pre-training CLIP models. In particular, RoCLIP decreases the success rate for targeted data poisoning attacks from 93.75% to 12.5% and that of backdoor attacks down to 0%, while improving the model's linear probe performance by 10% and maintains a similar zero shot performance compared to CLIP. By increasing the frequency of matching, RoCLIP is able to defend strong attacks, which add up to 1% poisoned examples to the data, and successfully maintain a low attack success rate of 12.5%, while trading off the performance on some tasks",
    "checked": false,
    "id": "4a27c16e24429d557205a0403e01490619ad8035",
    "semantic_title": "robust contrastive language-image pretraining against adversarial attacks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=H1CQZqpgdQ": {
    "title": "CBD: A Certified Backdoor Detector Based on Local Dominant Probability",
    "volume": "poster",
    "abstract": "Backdoor attack is a common threat to deep neural networks. During testing, samples embedded with a backdoor trigger will be misclassified as an adversarial target by a backdoored model, while samples without the backdoor trigger will be correctly classified. In this paper, we present the first certified backdoor detector (CBD), which is based on a novel, adjustable conformal prediction scheme based on our proposed statistic local dominant probability. For any classifier under inspection, CBD provides 1) a detection inference, 2) the condition under which the attacks are guaranteed to be detectable for the same classification domain, and 3) a probabilistic upper bound for the false positive rate. Our theoretical results show that attacks with triggers that are more resilient to test-time noise and have smaller perturbation magnitudes are more likely to be detected with guarantees. Moreover, we conduct extensive experiments on four benchmark datasets considering various backdoor types, such as BadNet, CB, and Blend. CBD achieves comparable or even higher detection accuracy than state-of-the-art detectors, and it in addition provides detection certification. Notably, for backdoor attacks with random perturbation triggers bounded by $\\ell_2\\leq0.75$ which achieves more than 90\\% attack success rate, CBD achieves 100\\% (98\\%), 100\\% (84\\%), 98\\% (98\\%), and 72\\% (40\\%) empirical (certified) detection true positive rates on the four benchmark datasets GTSRB, SVHN, CIFAR-10, and TinyImageNet, respectively, with low false positive rates",
    "checked": true,
    "id": "7f02e286cc15bf58ed305cd9c5ad558b30d0a47f",
    "semantic_title": "cbd: a certified backdoor detector based on local dominant probability",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5yZiP9fZNv": {
    "title": "Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs",
    "volume": "poster",
    "abstract": "We consider the problem of inferring latent stochastic differential equations (SDEs) with a time and memory cost that scales independently with the amount of data, the total length of the time series, and the stiffness of the approximate differential equations. This is in stark contrast to typical methods for inferring latent differential equations which, despite their constant memory cost, have a time complexity that is heavily dependent on the stiffness of the approximate differential equation. We achieve this computational advancement by removing the need to solve differential equations when approximating gradients using a novel amortization strategy coupled with a recently derived reparametrization of expectations under linear SDEs. We show that, in practice, this allows us to achieve similar performance to methods based on adjoint sensitivities with more than an order of magnitude fewer evaluations of the model in training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nRfcVBsF9n": {
    "title": "Differentiable Clustering with Perturbed Spanning Forests",
    "volume": "poster",
    "abstract": "We introduce a differentiable clustering method based on stochastic perturbations of minimum-weight spanning forests. This allows us to include clustering in end-to-end trainable pipelines, with efficient gradients. We show that our method performs well even in difficult settings, such as data sets with high noise and challenging geometries. We also formulate an ad hoc loss to efficiently learn from partial clustering data using this operation. We demonstrate its performance on several data sets for supervised and semi-supervised tasks",
    "checked": true,
    "id": "56750799e0f0fe956b63554a53993a7aa7960351",
    "semantic_title": "differentiable clustering with perturbed spanning forests",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=scaKiAtbI3": {
    "title": "Retrieval-Augmented Multiple Instance Learning",
    "volume": "poster",
    "abstract": "Multiple Instance Learning (MIL) is a crucial weakly supervised learning method applied across various domains, e.g., medical diagnosis based on whole slide images (WSIs). Recent advancements in MIL algorithms have yielded exceptional performance when the training and test data originate from the same domain, such as WSIs obtained from the same hospital. However, this paper reveals a performance deterioration of MIL models when tested on an out-of-domain test set, exemplified by WSIs sourced from a novel hospital. To address this challenge, this paper introduces the Retrieval-AugMented MIL (RAM-MIL) framework, which integrates Optimal Transport (OT) as the distance metric for nearest neighbor retrieval. The development of RAM-MIL is driven by two key insights. First, a theoretical discovery indicates that reducing the input's intrinsic dimension can minimize the approximation error in attention-based MIL. Second, previous studies highlight a link between input intrinsic dimension and the feature merging process with the retrieved data. Empirical evaluations conducted on WSI classification demonstrate that the proposed RAM-MIL framework achieves state-of-the-art performance in both in-domain scenarios, where the training and retrieval data are in the same domain, and more crucially, in out-of-domain scenarios, where the (unlabeled) retrieval data originates from a different domain. Furthermore, the use of the transportation matrix derived from OT renders the retrieval results interpretable at the instance level, in contrast to the vanilla $l_2$ distance, and allows for visualization for human experts. *Code can be found at \\url{https://github.com/ralphc1212/ram-mil*",
    "checked": false,
    "id": "d780adb1df97c647fc65bb9d5139af88cf89215d",
    "semantic_title": "a comprehensive review on multiple instance learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IltQ87ZdT6": {
    "title": "Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition",
    "volume": "poster",
    "abstract": "As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At a conceptual level, our work suggests that favorable scaling trends for individual model-providers need not translate to downstream improvements in social welfare in marketplaces with multiple model providers",
    "checked": true,
    "id": "06a69a5ffbc9b28d268bc50c1ccc7a1ed6c22dfb",
    "semantic_title": "improved bayes risk can yield reduced social welfare under competition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MRiitgpcUy": {
    "title": "On the Exploration of Local Significant Differences For Two-Sample Test",
    "volume": "poster",
    "abstract": "Recent years have witnessed increasing attentions on two-sample test with diverse real applications, while this work takes one more step on the exploration of local significant differences for two-sample test. We propose the ME$_\\text{MaBiD}$, an effective test for two-sample testing, and the basic idea is to exploit local information by multiple Mahalanobis kernels and introduce bi-directional hypothesis for testing. On the exploration of local significant differences, we first partition the embedding space into several rectangle regions via a new splitting criterion, which is relevant to test power and data correlation. We then explore local significant differences based on our bi-directional masked $p$-value together with the ME$_\\text{MaBiD}$ test. Theoretically, we present the asymptotic distribution and lower bounds of test power for our ME$_\\text{MaBiD}$ test, and control the familywise error rate on the exploration of local significant differences. We finally conduct extensive experiments to validate the effectiveness of our proposed methods on two-sample test and the exploration of local significant differences",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z2L7F0nekb": {
    "title": "Meta-Learning with Neural Bandit Scheduler",
    "volume": "poster",
    "abstract": "Meta-learning has been proven an effective learning paradigm for training machine learning models with good generalization ability. Apart from the common practice of uniformly sampling the meta-training tasks, existing methods working on task scheduling strategies are mainly based on pre-defined sampling protocols or the assumed task-model correlations, and greedily make scheduling decisions, which can lead to sub-optimal performance bottlenecks of the meta-model. In this paper, we propose a novel task scheduling framework under Contextual Bandits settings, named BASS, which directly optimizes the task scheduling strategy based on the status of the meta-model. By balancing the exploitation and exploration in meta-learning task scheduling, BASS can help tackle the challenge of limited knowledge about the task distribution during the early stage of meta-training, while simultaneously exploring potential benefits for forthcoming meta-training iterations through an adaptive exploration strategy. Theoretical analysis and extensive experiments are presented to show the effectiveness of our proposed framework",
    "checked": false,
    "id": "f2693c6c9a601d5a40a57db2d2e67aebf4b73b87",
    "semantic_title": "meta-learning with an adaptive task scheduler",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=y0OlQSZsyp": {
    "title": "Learning Causal Models under Independent Changes",
    "volume": "poster",
    "abstract": "In many scientific applications, we observe a system in different conditions in which its components may change, rather than in isolation. In our work, we are interested in explaining the generating process of such a multi-context system using a finite mixture of causal mechanisms. Recent work shows that this causal model is identifiable from data, but is limited to settings where the sparse mechanism shift hypothesis holds and only a subset of the causal conditionals change. As this assumption is not easily verifiable in practice, we study the more general principle that mechanism shifts are independent, which we formalize using the algorithmic notion of independence. We introduce an approach for causal discovery beyond partially directed graphs using Gaussian Process models, and give conditions under which we provably identify the correct causal model. In our experiments, we show that our method performs well in a range of synthetic settings, on realistic gene expression simulations, as well as on real-world cell signaling data",
    "checked": false,
    "id": "f8ae681d9e345a7581ab04665ce9f97fa12cbdc2",
    "semantic_title": "learning causal explanations for recommendation",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=RBI4oAbdpm": {
    "title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization",
    "volume": "poster",
    "abstract": "Neural combinatorial optimization (NCO) is a promising learning-based approach for solving challenging combinatorial optimization problems without specialized algorithm design by experts. However, most constructive NCO methods cannot solve problems with large-scale instance sizes, which significantly diminishes their usefulness for real-world applications. In this work, we propose a novel Light Encoder and Heavy Decoder (LEHD) model with a strong generalization ability to address this critical issue. The LEHD model can learn to dynamically capture the relationships between all available nodes of varying sizes, which is beneficial for model generalization to problems of various scales. Moreover, we develop a data-efficient training scheme and a flexible solution construction mechanism for the proposed LEHD model. By training on small-scale problem instances, the LEHD model can generate nearly optimal solutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 1000 nodes, and also generalizes well to solve real-world TSPLib and CVRPLib problems. These results confirm our proposed LEHD model can significantly improve the state-of-the-art performance for constructive NCO",
    "checked": true,
    "id": "3c2f14a28ba5e826c63c294f4cca01a8217a217e",
    "semantic_title": "neural combinatorial optimization with heavy decoder: toward large scale generalization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=gJLAfO4KUq": {
    "title": "Pengi: An Audio Language Model for Audio Tasks",
    "volume": "poster",
    "abstract": "In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 21 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding",
    "checked": true,
    "id": "ad22af138fa1d1490cda0301abf8159a7c30c5a2",
    "semantic_title": "pengi: an audio language model for audio tasks",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=sla7V80uWA": {
    "title": "Beyond MLE: Convex Learning for Text Generation",
    "volume": "poster",
    "abstract": "Maximum likelihood estimation (MLE) is a statistical method used to estimate the parameters of a probability distribution that best explain the observed data. In the context of text generation, MLE is often used to train generative language models, which can then be used to generate new text. However, we argue that MLE is not always necessary and optimal, especially for closed-ended text generation tasks like machine translation. In these tasks, the goal of model is to generate the most appropriate response, which does not necessarily require it to estimate the entire data distribution with MLE. To this end, we propose a novel class of training objectives based on convex functions, which enables text generation models to focus on highly probable outputs without having to estimate the entire data distribution. We investigate the theoretical properties of the optimal predicted distribution when applying convex functions to the loss, demonstrating that convex functions can sharpen the optimal distribution, thereby enabling the model to better capture outputs with high probabilities. Experiments on various text generation tasks and models show the effectiveness of our approach. It enables autoregressive models to bridge the gap between greedy and beam search, and facilitates the learning of non-autoregressive models with a maximum improvement of 9+ BLEU points. Moreover, our approach also exhibits significant impact on large language models (LLMs), substantially enhancing their generative capability on various tasks. Source code is available at \\url{https://github.com/ictnlp/Convex-Learning}",
    "checked": true,
    "id": "02929c69092989315fd4afca9670f98137648878",
    "semantic_title": "beyond mle: convex learning for text generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FCIj5KMn2m": {
    "title": "Cognitive Steering in Deep Neural Networks via Long-Range Modulatory Feedback Connections",
    "volume": "poster",
    "abstract": "Given the rich visual information available in each glance, humans can internally direct their visual attention to enhance goal-relevant information---a capacity often absent in standard vision models. Here we introduce cognitively and biologically-inspired long-range modulatory pathways to enable `cognitive steering' in vision models. First, we show that models equipped with these feedback pathways naturally show improved image recognition, adversarial robustness, and increased brain alignment, relative to baseline models. Further, these feedback projections from the final layer of the vision backbone provide a meaningful steering interface, where goals can be specified as vectors in the output space. We show that there are effective ways to steer the model that dramatically improve recognition of categories in composite images of multiple categories, succeeding where baseline feed-forward models without flexible steering fail. And, our multiplicative modulatory motif prevents rampant hallucination of the top-down goal category, dissociating what the model is looking for, from what it is looking at. Thus, these long-range modulatory pathways enable new behavioral capacities for goal-directed visual encoding, offering a flexible communication interface between cognitive and visual systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NWrN6cMG2x": {
    "title": "Moment Matching Denoising Gibbs Sampling",
    "volume": "poster",
    "abstract": "Energy-Based Models (EBMs) offer a versatile framework for modelling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a noisy data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a noisy model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets",
    "checked": true,
    "id": "9c94d99eb07d398ce9bf4232983fc540e48d9ee1",
    "semantic_title": "moment matching denoising gibbs sampling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ah2Q8mLH96": {
    "title": "Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-Norm Linear Regression",
    "volume": "poster",
    "abstract": "We study the performance of empirical risk minimization on the $p$-norm linear regression problem for $p \\in (1, \\infty)$. We show that, in the realizable case, under no moment assumptions, and up to a distribution-dependent constant, $O(d)$ samples are enough to exactly recover the target. Otherwise, for $p \\in [2, \\infty)$, and under weak moment assumptions on the target and the covariates, we prove a high probability excess risk bound on the empirical risk minimizer whose leading term matches, up to a constant that depends only on $p$, the asymptotically exact rate. We extend this result to the case $p \\in (1, 2)$ under mild assumptions that guarantee the existence of the Hessian of the risk at its minimizer",
    "checked": true,
    "id": "4db9e23a1460f7a3555a696ac1ce6330f8ebabf5",
    "semantic_title": "optimal excess risk bounds for empirical risk minimization on $p$-norm linear regression",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xtaX3WyCj1": {
    "title": "TIES-Merging: Resolving Interference When Merging Models",
    "volume": "poster",
    "abstract": "Transfer learning – i.e., further fine-tuning a pre-trained model on a downstream task – can confer significant advantages, including improved downstream performance, faster convergence, and better sample efficiency. These advantages have led to a proliferation of task-specific fine-tuned models, which typically can only perform a single task and do not benefit from one another. Recently, model merging techniques have emerged as a solution to combine multiple task-specific models into a single multitask model without performing additional training. However, existing merging methods often ignore the interference between parameters of different models, resulting in large performance drops when merging multiple models. In this paper, we demonstrate that prior merging techniques inadvertently lose valuable information due to two major sources of interference: (a) interference due to redundant parameter values and (b) disagreement on the sign of a given parameter's values across models. To address this, we propose our method, TrIm, Elect Sign & Merge (TIES-Merging), which introduces three novel steps when merging models: (1) resetting parameters that only changed a small amount during fine-tuning, (2) resolving sign conflicts, and (3) merging only the parameters that are in alignment with the final agreed-upon sign. We find that TIES-Merging outperforms existing methods in diverse settings covering a range of modalities, domains, number of tasks, model sizes, architectures, and fine-tuning settings. We further analyze the impact of different types of interference on model parameters, highlight the importance of signs, and show that estimating the signs using the validation data could further improve performance",
    "checked": true,
    "id": "2651f0179874bd010f58d2c9fa7d118807c80977",
    "semantic_title": "ties-merging: resolving interference when merging models",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=7WeCyYy9TL": {
    "title": "Joint processing of linguistic properties in brains and language models",
    "volume": "poster",
    "abstract": "Language models have been shown to be very effective in predicting brain recordings of subjects experiencing complex language stimuli. For a deeper understanding of this alignment, it is important to understand the correspondence between the detailed processing of linguistic information by the human brain versus language models. We investigate this correspondence via a direct approach, in which we eliminate information related to specific linguistic properties in the language model representations and observe how this intervention affects the alignment with fMRI brain recordings obtained while participants listened to a story. We investigate a range of linguistic properties (surface, syntactic, and semantic) and find that the elimination of each one results in a significant decrease in brain alignment. Specifically, we find that syntactic properties (i.e. Top Constituents and Tree Depth) have the largest effect on the trend of brain alignment across model layers. These findings provide clear evidence for the role of specific linguistic information in the alignment between brain and language models, and open new avenues for mapping the joint information processing in both systems. We make the code publicly available [https://github.com/subbareddy248/linguistic-properties-brain-alignment]",
    "checked": true,
    "id": "a103da21d92a715cdb0e7f42eb90d505e2a81986",
    "semantic_title": "joint processing of linguistic properties in brains and language models",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=dX9MjUtP1A": {
    "title": "Self-Correcting Bayesian Optimization through Bayesian Active Learning",
    "volume": "poster",
    "abstract": "Gaussian processes are the model of choice in Bayesian optimization and active learning. Yet, they are highly dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding good hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize hyperparameter learning. Statistical distance-based Active Learning (SAL) considers the average disagreement between samples from the posterior, as measured by a statistical distance. SAL outperforms the state-of-the-art in Bayesian active learning on several test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization methods on traditional benchmarks. Moreover, we demonstrate the importance of self-correction on atypical Bayesian optimization tasks",
    "checked": true,
    "id": "54d2ad98be9f89359e0b523121d5cc028cc79099",
    "semantic_title": "self-correcting bayesian optimization through bayesian active learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=DeZst6dKyi": {
    "title": "Sketchy: Memory-efficient Adaptive Regularization with Frequent Directions",
    "volume": "poster",
    "abstract": "Adaptive regularization methods that exploit more than the diagonal entries exhibit state of the art performance for many tasks, but can be prohibitive in terms of memory and running time. We find the spectra of the Kronecker-factored gradient covariance matrix in deep learning (DL) training tasks are concentrated on a small leading eigenspace that changes throughout training, motivating a low-rank sketching approach. We describe a generic method for reducing memory and compute requirements of maintaining a matrix preconditioner using the Frequent Directions (FD) sketch. While previous approaches have explored applying FD for second-order optimization, we present a novel analysis which allows efficient interpolation between resource requirements and the degradation in regret guarantees with rank $k$: in the online convex optimization (OCO) setting over dimension $d$, we match full-matrix $d^2$ memory regret using only $dk$ memory up to additive error in the bottom $d-k$ eigenvalues of the gradient covariance. Further, we show extensions of our work to Shampoo, resulting in a method competitive in quality with Shampoo and Adam, yet requiring only sub-linear memory for tracking second moments",
    "checked": true,
    "id": "dde69c0eb38e0e12bf19032c8815f3291dcd23ea",
    "semantic_title": "sketchy: memory-efficient adaptive regularization with frequent directions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TBOfDCX4Gz": {
    "title": "GEQ: Gaussian Kernel Inspired Equilibrium Models",
    "volume": "poster",
    "abstract": "Despite the connection established by optimization-induced deep equilibrium models (OptEqs) between their output and the underlying hidden optimization problems, the performance of it along with its related works is still not good enough especially when compared to deep networks. One key factor responsible for this performance limitation is the use of linear kernels to extract features in these models. To address this issue, we propose a novel approach by replacing its linear kernel with a new function that can readily capture nonlinear feature dependencies in the input data. Drawing inspiration from classical machine learning algorithms, we introduce Gaussian kernels as the alternative function and then propose our new equilibrium model, which we refer to as GEQ. By leveraging Gaussian kernels, GEQ can effectively extract the nonlinear information embedded within the input features, surpassing the performance of the original OptEqs. Moreover, GEQ can be perceived as a weight-tied neural network with infinite width and depth. GEQ also enjoys better theoretical properties and improved overall performance. Additionally, our GEQ exhibits enhanced stability when confronted with various samples. We further substantiate the effectiveness and stability of GEQ through a series of comprehensive experiments",
    "checked": false,
    "id": "2b6239d13d54f7caa3e5f68631fa26ce7825ca64",
    "semantic_title": "wide neural networks as gaussian processes: lessons from deep equilibrium models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A383wMho4h": {
    "title": "Oracle Complexity of Single-Loop Switching Subgradient Methods for Non-Smooth Weakly Convex Functional Constrained Optimization",
    "volume": "poster",
    "abstract": "We consider a non-convex constrained optimization problem, where the objective function is weakly convex and the constraint function is either convex or weakly convex. To solve this problem, we consider the classical switching subgradient method, which is an intuitive and easily implementable first-order method whose oracle complexity was only known for convex problems. This paper provides the first analysis on the oracle complexity of the switching subgradient method for finding a nearly stationary point of non-convex problems. Our results are derived separately for convex and weakly convex constraints. Compared to existing approaches, especially the double-loop methods, the switching gradient method can be applied to non-smooth problems and achieves the same complexity using only a single loop, which saves the effort on tuning the number of inner iterations",
    "checked": true,
    "id": "999d09054e0097dfb1f381f6a92826cf80bc0572",
    "semantic_title": "oracle complexity of single-loop switching subgradient methods for non-smooth weakly convex functional constrained optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=uoRiO855Sj": {
    "title": "Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees",
    "volume": "poster",
    "abstract": "For a sequence of classification tasks that arrive over time, it is common that tasks are evolving in the sense that consecutive tasks often have a higher similarity. The incremental learning of a growing sequence of tasks holds promise to enable accurate classification even with few samples per task by leveraging information from all the tasks in the sequence (forward and backward learning). However, existing techniques developed for continual learning and concept drift adaptation are either designed for tasks with time-independent similarities or only aim to learn the last task in the sequence. This paper presents incremental minimax risk classifiers (IMRCs) that effectively exploit forward and backward learning and account for evolving tasks. In addition, we analytically characterize the performance improvement provided by forward and backward learning in terms of the tasks' expected quadratic change and the number of tasks. The experimental evaluation shows that IMRCs can result in a significant performance improvement, especially for reduced sample sizes",
    "checked": true,
    "id": "041e1ebcfa042515e915231c26689da093142949",
    "semantic_title": "minimax forward and backward learning of evolving tasks with performance guarantees",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gjBk6IQofa": {
    "title": "Creating Multi-Level Skill Hierarchies in Reinforcement Learning",
    "volume": "poster",
    "abstract": "What is a useful skill hierarchy for an autonomous agent? We propose an answer based on a graphical representation of how the interaction between an agent and its environment may unfold. Our approach uses modularity maximisation as a central organising principle to expose the structure of the interaction graph at multiple levels of abstraction. The result is a collection of skills that operate at varying time scales, organised into a hierarchy, where skills that operate over longer time scales are composed of skills that operate over shorter time scales. The entire skill hierarchy is generated automatically, with no human input, including the skills themselves (their behaviour, when they can be called, and when they terminate) as well as the dependency structure between them. In a wide range of environments, this approach generates skill hierarchies that are intuitively appealing and that considerably improve the learning performance of the agent",
    "checked": true,
    "id": "d0bed3f76f187cba083fda0188b0b0e094e6ddda",
    "semantic_title": "creating multi-level skill hierarchies in reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UHIDdtxmVS": {
    "title": "Asynchrony-Robust Collaborative Perception via Bird's Eye View Flow",
    "volume": "poster",
    "abstract": "Collaborative perception can substantially boost each agent's perception ability by facilitating communication among multiple agents. However, temporal asynchrony among agents is inevitable in the real world due to communication delays, interruptions, and clock misalignments. This issue causes information mismatch during multi-agent fusion, seriously shaking the foundation of collaboration. To address this issue, we propose CoBEVFlow, an asynchrony-robust collaborative perception system based on bird's eye view (BEV) flow. The key intuition of CoBEVFlow is to compensate motions to align asynchronous collaboration messages sent by multiple agents. To model the motion in a scene, we propose BEV flow, which is a collection of the motion vector corresponding to each spatial location. Based on BEV flow, asynchronous perceptual features can be reassigned to appropriate positions, mitigating the impact of asynchrony. CoBEVFlow has two advantages: (i) CoBEVFlow can handle asynchronous collaboration messages sent at irregular, continuous time stamps without discretization; and (ii) with BEV flow, CoBEVFlow only transports the original perceptual features, instead of generating new perceptual features, avoiding additional noises. To validate CoBEVFlow's efficacy, we create IRregular V2V(IRV2V), the first synthetic collaborative perception dataset with various temporal asynchronies that simulate different real-world scenarios. Extensive experiments conducted on both IRV2V and the real-world dataset DAIR-V2X show that CoBEVFlow consistently outperforms other baselines and is robust in extremely asynchronous settings. The code is available at https://github.com/MediaBrain-SJTU/CoBEVFlow",
    "checked": true,
    "id": "e4797aee1f423b449cdccf90cbd9c67b42b2202d",
    "semantic_title": "asynchrony-robust collaborative perception via bird's eye view flow",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0gvtoxhvMY": {
    "title": "Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition",
    "volume": "poster",
    "abstract": "This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs",
    "checked": true,
    "id": "091a1eb4e38911ce97dee2c88e5fbe18f42da6b8",
    "semantic_title": "rethinking semi-supervised imbalanced node classification from bias-variance decomposition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EfMyf9MC3t": {
    "title": "Speculative Decoding with Big Little Decoder",
    "volume": "poster",
    "abstract": "The recent emergence of Large Language Models based on the Transformer architecture has enabled dramatic advancements in the field of Natural Language Processing. However, these models have long inference latency, which limits their deployment and makes them prohibitively expensive for various real-time applications. The inference latency is further exacerbated by autoregressive generative tasks, as models need to run iteratively to generate tokens sequentially without leveraging token-level parallelization. To address this, we propose Big Little Decoder (BiLD), a framework that can improve inference efficiency and latency for a wide range of text generation applications. The BiLD framework contains two models with different sizes that collaboratively generate text. The small model runs autoregressively to generate text with a low inference cost, and the large model is only invoked occasionally to refine the small model's inaccurate predictions in a non-autoregressive manner. To coordinate the small and large models, BiLD introduces two simple yet effective policies: (1) the fallback policy that determines when to hand control over to the large model; and (2) the rollback policy that determines when the large model needs to correct the small model's inaccurate predictions. To evaluate our framework across different tasks and models, we apply BiLD to various text generation scenarios encompassing machine translation on IWSLT 2017 De-En and WMT 2014 De-En, and summarization on XSUM and CNN/DailyMail. On an NVIDIA T4 GPU, our framework achieves a speedup of up to 2.12x speedup with minimal generation quality degradation. Furthermore, our framework is fully plug-and-play and can be applied without any modifications in the training process or model architecture. Our code is open-sourced",
    "checked": true,
    "id": "b7d12aec8a0152ec4921dfa43ab525a63b334385",
    "semantic_title": "speculative decoding with big little decoder",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=JVzeOYEx6d": {
    "title": "ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation",
    "volume": "poster",
    "abstract": "We present a comprehensive solution to learn and improve text-to-image models from human preference feedback. To begin with, we build ImageReward---the first general-purpose text-to-image human preference reward model---to effectively encode human preferences. Its training is based on our systematic annotation pipeline including rating and ranking, which collects 137k expert comparisons to date. In human evaluation, ImageReward outperforms existing scoring models and metrics, making it a promising automatic metric for evaluating text-to-image synthesis. On top of it, we propose Reward Feedback Learning (ReFL), a direct tuning algorithm to optimize diffusion models against a scorer. Both automatic and human evaluation support ReFL's advantages over compared methods. All code and datasets are provided at \\url{https://github.com/THUDM/ImageReward}",
    "checked": true,
    "id": "1b2355c3c674b26a977768a91a164384ad51bbb1",
    "semantic_title": "imagereward: learning and evaluating human preferences for text-to-image generation",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=1B6YKnHYBb": {
    "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
    "volume": "poster",
    "abstract": "*De novo* drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT",
    "checked": false,
    "id": "006f26974d2db9fe7d5bc6365cb74dc2e3afaef0",
    "semantic_title": "de novo drug design by iterative multiobjective deep reinforcement learning with graph-based molecular quality assessment",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tFeaLw9AWn": {
    "title": "Single-Call Stochastic Extragradient Methods for Structured Non-monotone Variational Inequalities: Improved Analysis under Weaker Conditions",
    "volume": "poster",
    "abstract": "Single-call stochastic extragradient methods, like stochastic past extragradient (SPEG) and stochastic optimistic gradient (SOG), have gained a lot of interest in recent years and are one of the most efficient algorithms for solving large-scale min-max optimization and variational inequalities problems (VIP) appearing in various machine learning tasks. However, despite their undoubted popularity, current convergence analyses of SPEG and SOG require strong assumptions like bounded variance or growth conditions. In addition, several important questions regarding the convergence properties of these methods are still open, including mini-batching, efficient step-size selection, and convergence guarantees under different sampling strategies. In this work, we address these questions and provide convergence guarantees for two large classes of structured non-monotone VIPs: (i) quasi-strongly monotone problems (a generalization of strongly monotone problems) and (ii) weak Minty variational inequalities (a generalization of monotone and Minty VIPs). We introduce the expected residual condition, explain its benefits, and show how it allows us to obtain a strictly weaker bound than previously used growth conditions, expected co-coercivity, or bounded variance assumptions. Finally, our convergence analysis holds under the arbitrary sampling paradigm, which includes importance sampling and various mini-batching strategies as special cases",
    "checked": true,
    "id": "0baa8a43b6aa3b575dae240b505a8630935a7980",
    "semantic_title": "single-call stochastic extragradient methods for structured non-monotone variational inequalities: improved analysis under weaker conditions",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=hz33V7Tb2O": {
    "title": "CLeAR: Continual Learning on Algorithmic Reasoning for Human-like Intelligence",
    "volume": "poster",
    "abstract": "Continual learning (CL) aims to incrementally learn multiple tasks that are presented sequentially. The significance of CL lies not only in the practical importance but also in studying the learning mechanisms of humans who are excellent continual learners. While most research on CL has been done on structured data such as images, there is a lack of research on CL for abstract logical concepts such as counting, sorting, and arithmetic, which humans learn gradually over time in the real world. In this work, for the first time, we introduce novel algorithmic reasoning (AR) methodology for continual tasks of abstract concepts: CLeAR. Our methodology proposes a one-to-many mapping of input distribution to a shared mapping space, which allows the alignment of various tasks of different dimensions and shared semantics. Our tasks of abstract logical concepts, in the form of formal language, can be classified into Chomsky hierarchies based on their difficulty. In this study, we conducted extensive experiments consisting of 15 tasks with various levels of Chomsky hierarchy, ranging from in-hierarchy to inter-hierarchy scenarios. CLeAR not only achieved near zero forgetting but also improved accuracy during following tasks, a phenomenon known as backward transfer, while previous CL methods designed for image classification drastically failed",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dd3KNayGFz": {
    "title": "Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection",
    "volume": "poster",
    "abstract": "Graph Neural Networks (GNNs) have proven to be highly effective in solving real-world learning problems that involve graph-structured data. However, GNNs can also inadvertently expose sensitive user information and interactions through their model predictions. To address these privacy concerns, Differential Privacy (DP) protocols are employed to control the trade-off between provable privacy protection and model utility. Applying standard DP approaches to GNNs directly is not advisable due to two main reasons. First, the prediction of node labels, which relies on neighboring node attributes through graph convolutions, can lead to privacy leakage. Second, in practical applications, the privacy requirements for node attributes and graph topology may differ. In the latter setting, existing DP-GNN models fail to provide multigranular trade-offs between graph topology privacy, node attribute privacy, and GNN utility. To address both limitations, we propose a new framework termed Graph Differential Privacy (GDP), specifically tailored to graph learning. GDP ensures both provably private model parameters as well as private predictions. Additionally, we describe a novel unified notion of graph dataset adjacency to analyze the properties of GDP for different levels of graph topology privacy. Our findings reveal that DP-GNNs, which rely on graph convolutions, not only fail to meet the requirements for multigranular graph topology privacy but also necessitate the injection of DP noise that scales at least linearly with the maximum node degree. In contrast, our proposed Differentially Private Decoupled Graph Convolutions (DPDGCs) represent a more flexible and efficient alternative to graph convolutions that still provides the necessary guarantees of GDP. To validate our approach, we conducted extensive experiments on seven node classification benchmarking and illustrative synthetic datasets. The results demonstrate that DPDGCs significantly outperform existing DP-GNNs in terms of privacy-utility trade-offs",
    "checked": true,
    "id": "41c8a2a6ca140eeb9da52cb852e49d5ce7ffa162",
    "semantic_title": "differentially private decoupled graph convolutions for multigranular topology protection",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=CCVsGbhFdj": {
    "title": "Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics",
    "volume": "poster",
    "abstract": "Neural networks are emerging as a tool for scalable data-driven simulation of high-dimensional dynamical systems, especially in settings where numerical methods are infeasible or computationally expensive. Notably, it has been shown that incorporating domain symmetries in deterministic neural simulators can substantially improve their accuracy, sample efficiency, and parameter efficiency. However, to incorporate symmetries in probabilistic neural simulators that can simulate stochastic phenomena, we need a model that produces equivariant distributions over trajectories, rather than equivariant function approximations. In this paper, we propose Equivariant Probabilistic Neural Simulation (EPNS), a framework for autoregressive probabilistic modeling of equivariant distributions over system evolutions. We use EPNS to design models for a stochastic n-body system and stochastic cellular dynamics. Our results show that EPNS considerably outperforms existing neural network-based methods for probabilistic simulation. More specifically, we demonstrate that incorporating equivariance in EPNS improves simulation quality, data efficiency, rollout stability, and uncertainty quantification. We conclude that EPNS is a promising method for efficient and effective data-driven probabilistic simulation in a diverse range of domains",
    "checked": true,
    "id": "2c540d472a38baea5363f4c139783f70db384086",
    "semantic_title": "equivariant neural simulators for stochastic spatiotemporal dynamics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xw6Szwu4xz": {
    "title": "Personalized Dictionary Learning for Heterogeneous Datasets",
    "volume": "poster",
    "abstract": "We introduce a relevant yet challenging problem named Personalized Dictionary Learning (PerDL), where the goal is to learn sparse linear representations from heterogeneous datasets that share some commonality. In PerDL, we model each dataset's shared and unique features as global and local dictionaries. Challenges for PerDL not only are inherited from classical dictionary learning(DL), but also arise due to the unknown nature of the shared and unique features. In this paper, we rigorously formulate this problem and provide conditions under which the global and local dictionaries can be provably disentangled. Under these conditions, we provide a meta-algorithm called Personalized Matching and Averaging (PerMA) that can recover both global and local dictionaries from heterogeneous datasets. PerMA is highly efficient; it converges to the ground truth at a linear rate under suitable conditions. Moreover, it automatically borrows strength from strong learners to improve the prediction of weak learners. As a general framework for extracting global and local dictionaries, we show the application of PerDL in different learning tasks, such as training with imbalanced datasets and video surveillance",
    "checked": true,
    "id": "74b12e16922ff1410d7f4665177a7815f38d0446",
    "semantic_title": "personalized dictionary learning for heterogeneous datasets",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y2VQWfi7Vc": {
    "title": "Expert load matters: operating networks at high accuracy and low manual effort",
    "volume": "poster",
    "abstract": "In human-AI collaboration systems for critical applications, in order to ensure minimal error, users should set an operating point based on model confidence to determine when the decision should be delegated to human experts. Samples for which model confidence is lower than the operating point would be manually analysed by experts to avoid mistakes. Such systems can become truly useful only if they consider two aspects: models should be confident only for samples for which they are accurate, and the number of samples delegated to experts should be minimized. The latter aspect is especially crucial for applications where available expert time is limited and expensive, such as healthcare. The trade-off between the model accuracy and the number of samples delegated to experts can be represented by a curve that is similar to an ROC curve, which we refer to as confidence operating characteristic (COC) curve. In this paper, we argue that deep neural networks should be trained by taking into account both accuracy and expert load and, to that end, propose a new complementary loss function for classification that maximizes the area under this COC curve. This promotes simultaneously the increase in network accuracy and the reduction in number of samples delegated to humans. We perform experiments on multiple computer vision and medical image datasets for classification. Our results demonstrate that the proposed loss improves classification accuracy and delegates less number of decisions to experts, achieves better out-of-distribution samples detection and on par calibration performance compared to existing loss functions",
    "checked": true,
    "id": "707ee57ec048eb55fe2fa8b383747a589e2c7af9",
    "semantic_title": "expert load matters: operating networks at high accuracy and low manual effort",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2YtdxqvdjX": {
    "title": "Implicit Convolutional Kernels for Steerable CNNs",
    "volume": "poster",
    "abstract": "Steerable convolutional neural networks (CNNs) provide a general framework for building neural networks equivariant to translations and transformations of an origin-preserving group $G$, such as reflections and rotations. They rely on standard convolutions with $G$-steerable kernels obtained by analytically solving the group-specific equivariance constraint imposed onto the kernel space. As the solution is tailored to a particular group $G$, implementing a kernel basis does not generalize to other symmetry transformations, complicating the development of general group equivariant models. We propose using implicit neural representation via multi-layer perceptrons (MLPs) to parameterize $G$-steerable kernels. The resulting framework offers a simple and flexible way to implement Steerable CNNs and generalizes to any group $G$ for which a $G$-equivariant MLP can be built. We prove the effectiveness of our method on multiple tasks, including N-body simulations, point cloud classification and molecular property prediction",
    "checked": true,
    "id": "ae9d5ae9f7ab573499f9864d9dec267e46a1d1a3",
    "semantic_title": "implicit convolutional kernels for steerable cnns",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7f6vH3mmhr": {
    "title": "Multi-Agent Learning with Heterogeneous Linear Contextual Bandits",
    "volume": "poster",
    "abstract": "As trained intelligent systems become increasingly pervasive, multiagent learning has emerged as a popular framework for studying complex interactions between autonomous agents. Yet, a formal understanding of how and when learners in heterogeneous environments benefit from sharing their respective experiences is far from complete. In this paper, we seek answers to these questions in the context of linear contextual bandits. We present a novel distributed learning algorithm based on the upper confidence bound (UCB) algorithm, which we refer to as H-LINUCB, wherein agents cooperatively minimize the group regret under the coordination of a central server. In the setting where the level of heterogeneity or dissimilarity across the environments is known to the agents, we show that H-LINUCB is provably optimal in regimes where the tasks are highly similar or highly dissimilar",
    "checked": false,
    "id": "f1477777f1f25bb5bc3f5a0f7457aaede2568400",
    "semantic_title": "multi-agent heterogeneous stochastic linear bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=icWwBKyVMs": {
    "title": "Interpretable Prototype-based Graph Information Bottleneck",
    "volume": "poster",
    "abstract": "The success of Graph Neural Networks (GNNs) has led to a need for understanding their decision-making process and providing explanations for their predictions, which has given rise to explainable AI (XAI) that offers transparent explanations for black-box models. Recently, the use of prototypes has successfully improved the explainability of models by learning prototypes to imply training graphs that affect the prediction. However, these approaches tend to provide prototypes with excessive information from the entire graph, leading to the exclusion of key substructures or the inclusion of irrelevant substructures, which can limit both the interpretability and the performance of the model in downstream tasks. In this work, we propose a novel framework of explainable GNNs, called interpretable Prototype-based Graph Information Bottleneck (PGIB) that incorporates prototype learning within the information bottleneck framework to provide prototypes with the key subgraph from the input graph that is important for the model prediction. This is the first work that incorporates prototype learning into the process of identifying the key subgraphs that have a critical impact on the prediction performance. Extensive experiments, including qualitative analysis, demonstrate that PGIB outperforms state-of-the-art methods in terms of both prediction performance and explainability",
    "checked": true,
    "id": "cebd5b9f659d1f93d95524158e104e6b7c330bfc",
    "semantic_title": "interpretable prototype-based graph information bottleneck",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2dx5MNs2Ip": {
    "title": "Probabilistic Exponential Integrators",
    "volume": "poster",
    "abstract": "Probabilistic solvers provide a flexible and efficient framework for simulation, uncertainty quantification, and inference in dynamical systems. However, like standard solvers, they suffer performance penalties for certain stiff systems, where small steps are required not for reasons of numerical accuracy but for the sake of stability. This issue is greatly alleviated in semi-linear problems by the probabilistic exponential integrators developed in this paper. By including the fast, linear dynamics in the prior, we arrive at a class of probabilistic integrators with favorable properties. Namely, they are proven to be L-stable, and in a certain case reduce to a classic exponential integrator---with the added benefit of providing a probabilistic account of the numerical error. The method is also generalized to arbitrary non-linear systems by imposing piece-wise semi-linearity on the prior via Jacobians of the vector field at the previous estimates, resulting in probabilistic exponential Rosenbrock methods. We evaluate the proposed methods on multiple stiff differential equations and demonstrate their improved stability and efficiency over established probabilistic solvers. The present contribution thus expands the range of problems that can be effectively tackled within probabilistic numerics",
    "checked": true,
    "id": "f79b25d173013ff9ef03f2589f39e326184c306d",
    "semantic_title": "probabilistic exponential integrators",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cr99foBDPV": {
    "title": "Back-Modality: Leveraging Modal Transformation for Data Augmentation",
    "volume": "poster",
    "abstract": "We introduce Back-Modality, a novel data augmentation schema predicated on modal transformation. Data from an initial modality undergoes transformation to an intermediate modality, followed by a reverse transformation. This framework serves dual roles. On one hand, it operates as a general data augmentation strategy. On the other hand, it allows for other augmentation techniques, suitable for the intermediate modality, to enhance the initial modality. For instance, data augmentation methods applicable to pure text can be employed to augment images, thereby facilitating the cross-modality of data augmentation techniques. To validate the viability and efficacy of our framework, we proffer three instantiations of Back-Modality: back-captioning, back-imagination, and back-speech. Comprehensive evaluations across tasks such as image classification, sentiment classification, and textual entailment demonstrate that our methods consistently enhance performance under data-scarce circumstances",
    "checked": false,
    "id": "a0708cf6a1c2987633a15e64fea6b67cdea1b2be",
    "semantic_title": "btdnet: a multi-modal approach for brain tumor radiogenomic classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Af5GvIj3T5": {
    "title": "To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis",
    "volume": "poster",
    "abstract": "Recent research has highlighted the importance of dataset size in scaling language models. However, large language models (LLMs) are notoriously token-hungry during pre-training, and high-quality text data on the web is likely to be approaching its scaling limit for LLMs. To further enhance LLMs, a straightforward approach is to repeat the pre-training data for additional epochs. In this study, we empirically investigate three key aspects under this approach. First, we explore the consequences of repeating pre-training data, revealing that the model is susceptible to overfitting, leading to multi-epoch degradation. Second, we examine the key factors contributing to multi-epoch degradation, finding that significant factors include dataset size, model parameters, and training objectives, while less influential factors consist of dataset quality and model FLOPs. Finally, we explore whether widely used regularization can alleviate multi-epoch degradation. Most regularization techniques do not yield significant improvements, except for dropout, which demonstrates remarkable effectiveness but requires careful tuning when scaling up the model size. Additionally, we discover that leveraging mixture-of-experts (MoE) enables cost-effective and efficient hyper-parameter tuning for computationally intensive dense LLMs with comparable trainable parameters, potentially impacting efficient LLM development on a broader scale",
    "checked": true,
    "id": "7c217cc7524251f42887438834912e06129c3299",
    "semantic_title": "to repeat or not to repeat: insights from scaling llm under token-crisis",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=zGRWp7yRqd": {
    "title": "Multi-Swap k-Means++",
    "volume": "poster",
    "abstract": "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost",
    "checked": true,
    "id": "4d19140e0da85728bb9d6b91da2287a0618c4843",
    "semantic_title": "multi-swap k-means++",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wbg4JEM5Jp": {
    "title": "Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms",
    "volume": "poster",
    "abstract": "We study the problem of designing adaptive multi-armed bandit algorithms that perform optimally in both the stochastic setting and the adversarial setting simultaneously (often known as a best-of-both-world guarantee). A line of recent works shows that when configured and analyzed properly, the Follow-the-Regularized-Leader (FTRL) algorithm, originally designed for the adversarial setting, can in fact optimally adapt to the stochastic setting as well. Such results, however, critically rely on an assumption that there exists one unique optimal arm. Recently, Ito [2021] took the first step to remove such an undesirable uniqueness assumption for one particular FTRL algorithm with the 1/2-Tsallis entropy regularizer. In this work, we significantly improve and generalize this result, showing that uniqueness is unnecessary for FTRL with a broad family of regularizers and a new learning rate schedule. For some regularizers, our regret bounds also improve upon prior results even when uniqueness holds. We further provide an application of our results to the decoupled exploration and exploitation problem, demonstrating that our techniques are broadly applicable",
    "checked": true,
    "id": "165bf26ca3c0c05f5b24d711c36afa03b89be4ec",
    "semantic_title": "improved best-of-both-worlds guarantees for multi-armed bandits: ftrl with general regularizers and multiple optimal arms",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=3H9QH1v6U9": {
    "title": "DFRD: Data-Free Robustness Distillation for Heterogeneous Federated Learning",
    "volume": "poster",
    "abstract": "Federated Learning (FL) is a privacy-constrained decentralized machine learning paradigm in which clients enable collaborative training without compromising private data. However, how to learn a robust global model in the data-heterogeneous and model-heterogeneous FL scenarios is challenging. To address it, we resort to data-free knowledge distillation to propose a new FL method (namely DFRD). DFRD equips a conditional generator on the server to approximate the training space of the local models uploaded by clients, and systematically investigates its training in terms of fidelity, transferability and diversity. To overcome the catastrophic forgetting of the global model caused by the distribution shifts of the generator across communication rounds, we maintain an exponential moving average copy of the generator on the server. Additionally, we propose dynamic weighting and label sampling to accurately extract knowledge from local models. Finally, our extensive experiments on various image classification tasks illustrate that DFRD achieves significant performance gains compared to SOTA baselines",
    "checked": true,
    "id": "6104bdd786836ae05a575eac50694160e6c388a2",
    "semantic_title": "dfrd: data-free robustness distillation for heterogeneous federated learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K7u3RkoBP9": {
    "title": "Neural Modulation for Flash Memory: An Unsupervised Learning Framework for Improved Reliability",
    "volume": "poster",
    "abstract": "Recent years have witnessed a significant increase in the storage density of NAND flash memory, making it a critical component in modern electronic devices. However, with the rise in storage capacity comes an increased likelihood of errors in data storage and retrieval. The growing number of errors poses ongoing challenges for system designers and engineers, in terms of the characterization, modeling, and optimization of NAND-based systems. We present a novel approach for modeling and preventing errors by utilizing the capabilities of generative and unsupervised machine learning methods. As part of our research, we constructed and trained a neural modulator that translates information bits into programming operations on each memory cell in NAND devices. Our modulator, tailored explicitly for flash memory channels, provides a smart writing scheme that reduces programming errors as well as compensates for data degradation over time. Specifically, the modulator is based on an auto-encoder architecture with an additional channel model embedded between the encoder and the decoder. A conditional generative adversarial network (cGAN) was used to construct the channel model. Optimized for the end-of-life work-point, the learned memory system outperforms the prior art by up to 56\\% in raw bit error rate (RBER) and extends the lifetime of the flash memory block by up to 25\\%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2EiqizElGO": {
    "title": "ViSt3D: Video Stylization with 3D CNN",
    "volume": "poster",
    "abstract": "Visual stylization has been a very popular research area in recent times. While image stylization has seen a rapid advancement in the recent past, video stylization, while being more challenging, is relatively less explored. The immediate method of stylizing videos by stylizing each frame independently has been tried with some success. To the best of our knowledge, we present the first approach to video stylization using 3D CNN directly, building upon insights from 2D image stylization. Stylizing video is highly challenging, as the appearance and video motion, which includes both camera and subject motions, are inherently entangled in the representations learnt by a 3D CNN. Hence, a naive extension of 2D CNN stylization methods to 3D CNN does not work. To perform stylization with 3D CNN, we propose to explicitly disentangle motion and appearance, stylize the appearance part, and then add back the motion component and decode the final stylized video. In addition, we propose a dataset, curated from existing datasets, to train video stylization networks. We also provide an independently collected test set to study the generalization of video stylization methods. We provide results on this test dataset comparing the proposed method with 2D stylization methods applied frame by frame. We show successful stylization with 3D CNN for the first time, and obtain better stylization in terms of texture cf.\\ the existing 2D methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f2U4HCY8bg": {
    "title": "Iterative Reachability Estimation for Safe Reinforcement Learning",
    "volume": "poster",
    "abstract": "Ensuring safety is important for the practical deployment of reinforcement learning (RL). Various challenges must be addressed, such as handling stochasticity in the environments, providing rigorous guarantees of persistent state-wise safety satisfaction, and avoiding overly conservative behaviors that sacrifice performance. We propose a new framework, Reachability Estimation for Safe Policy Optimization (RESPO), for safety-constrained RL in general stochastic settings. In the feasible set where there exist violation-free policies, we optimize for rewards while maintaining persistent safety. Outside this feasible set, our optimization produces the safest behavior by guaranteeing entrance into the feasible set whenever possible with the least cumulative discounted violations. We introduce a class of algorithms using our novel reachability estimation function to optimize in our proposed framework and in similar frameworks such as those concurrently handling multiple hard and soft constraints. We theoretically establish that our algorithms almost surely converge to locally optimal policies of our safe optimization framework. We evaluate the proposed methods on a diverse suite of safe RL environments from Safety Gym, PyBullet, and MuJoCo, and show the benefits in improving both reward performance and safety compared with state-of-the-art baselines",
    "checked": true,
    "id": "8da73e2e0d6ff6d7ebc912605d50f54eb6d3736a",
    "semantic_title": "iterative reachability estimation for safe reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5hVXbiEGXB": {
    "title": "Evolving Standardization for Continual Domain Generalization over Temporal Drift",
    "volume": "poster",
    "abstract": "The capability of generalizing to out-of-distribution data is crucial for the deployment of machine learning models in the real world. Existing domain generalization (DG) mainly embarks on offline and discrete scenarios, where multiple source domains are simultaneously accessible and the distribution shift among domains is abrupt and violent. Nevertheless, such setting may not be universally applicable to all real-world applications, as there are cases where the data distribution gradually changes over time due to various factors, e.g., the process of aging. Additionally, as the domain constantly evolves, new domains will continually emerge. Re-training and updating models with both new and previous domains using existing DG methods can be resource-intensive and inefficient. Therefore, in this paper, we present a problem formulation for Continual Domain Generalization over Temporal Drift (CDGTD). CDGTD addresses the challenge of gradually shifting data distributions over time, where domains arrive sequentially and models can only access the data of the current domain. The goal is to generalize to unseen domains that are not too far into the future. To this end, we propose an Evolving Standardization (EvoS) method, which characterizes the evolving pattern of feature distribution and mitigates the distribution shift by standardizing features with generated statistics of corresponding domain. Specifically, inspired by the powerful ability of transformers to model sequence relations, we design a multi-scale attention module (MSAM) to learn the evolving pattern under sliding time windows of different lengths. MSAM can generate statistics of current domain based on the statistics of previous domains and the learned evolving pattern. Experiments on multiple real-world datasets including images and texts validate the efficacy of our EvoS",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cxazQGSsQa": {
    "title": "Efficient Neural Music Generation",
    "volume": "poster",
    "abstract": "Recent progress in music generation has been remarkably advanced by the state-of-the-art MusicLM, which comprises a hierarchy of three LMs, respectively, for semantic, coarse acoustic, and fine acoustic modelings. Yet, sampling with the MusicLM requires processing through these LMs one by one to obtain the fine-grained acoustic tokens, making it computationally expensive and prohibitive for a real-time generation. Efficient music generation with a quality on par with MusicLM remains a significant challenge. In this paper, we present **M**e**L**o**D**y (**M** for music; **L** for LM; **D** for diffusion), an LM-guided diffusion model that generates music audios of state-of-the-art quality meanwhile reducing 95.7\\% to 99.6\\% forward passes in MusicLM, respectively, for sampling 10s to 30s music. MeLoDy inherits the highest-level LM from MusicLM for semantic modeling, and applies a novel dual-path diffusion (DPD) model and an audio VAE-GAN to efficiently decode the conditioning semantic tokens into waveform. DPD is proposed to simultaneously model the coarse and fine acoustics by incorporating the semantic information into segments of latents effectively via cross-attention at each denoising step. Our experimental results suggest the superiority of MeLoDy, not only in its practical advantages on sampling speed and infinitely continuable generation, but also in its state-of-the-art musicality, audio quality, and text correlation. Our samples are available at https://Efficient-MeLoDy.github.io/",
    "checked": true,
    "id": "38b93d01e08ab19ada89a40051a1ed4309fbe834",
    "semantic_title": "efficient neural music generation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=7LZ4tZrYlx": {
    "title": "Bounding training data reconstruction in DP-SGD",
    "volume": "poster",
    "abstract": "Differentially private training offers a protection which is usually interpreted as a guarantee against membership inference attacks. By proxy, this guarantee extends to other threats like reconstruction attacks attempting to extract complete training examples. Recent works provide evidence that if one does not need to protect against membership attacks but instead only wants to protect against a training data reconstruction, then utility of private models can be improved because less noise is required to protect against these more ambitious attacks. We investigate this question further in the context of DP-SGD, a standard algorithm for private deep learning, and provide an upper bound on the success of any reconstruction attack against DP-SGD together with an attack that empirically matches the predictions of our bound. Together, these two results open the door to fine-grained investigations on how to set the privacy parameters of DP-SGD in practice to protect against reconstruction attacks. Finally, we use our methods to demonstrate that different settings of the DP-SGD parameters leading to same DP guarantees can results in significantly different success rates for reconstruction, indicating that the DP guarantee alone might not be a good proxy for controlling the protection against reconstruction attacks",
    "checked": true,
    "id": "671ce139cdc68544ac8142d0f2046f1ce6073a0e",
    "semantic_title": "bounding training data reconstruction in dp-sgd",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=cd5D1DD923": {
    "title": "DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization",
    "volume": "poster",
    "abstract": "Ant Colony Optimization (ACO) is a meta-heuristic algorithm that has been successfully applied to various Combinatorial Optimization Problems (COPs). Traditionally, customizing ACO for a specific problem requires the expert design of knowledge-driven heuristics. In this paper, we propose DeepACO, a generic framework that leverages deep reinforcement learning to automate heuristic designs. DeepACO serves to strengthen the heuristic measures of existing ACO algorithms and dispense with laborious manual design in future ACO applications. As a neural-enhanced meta-heuristic, DeepACO consistently outperforms its ACO counterparts on eight COPs using a single neural model and a single set of hyperparameters. As a Neural Combinatorial Optimization method, DeepACO performs better than or on par with problem-specific methods on canonical routing problems. Our code is publicly available at https://github.com/henry-yeh/DeepACO",
    "checked": true,
    "id": "fd016671555b3eb1e417f0a645e1268922e3c081",
    "semantic_title": "deepaco: neural-enhanced ant systems for combinatorial optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f8zIs2IB6Q": {
    "title": "Sequential Memory with Temporal Predictive Coding",
    "volume": "poster",
    "abstract": "Forming accurate memory of sequential stimuli is a fundamental function of biological agents. However, the computational mechanism underlying sequential memory in the brain remains unclear. Inspired by neuroscience theories and recent successes in applying predictive coding (PC) to \\emph{static} memory tasks, in this work we propose a novel PC-based model for \\emph{sequential} memory, called \\emph{temporal predictive coding} (tPC). We show that our tPC models can memorize and retrieve sequential inputs accurately with a biologically plausible neural implementation. Importantly, our analytical study reveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN) with an implicit statistical whitening process, which leads to more stable performance in sequential memory tasks of structured inputs. Moreover, we find that tPC exhibits properties consistent with behavioral observations and theories in neuroscience, thereby strengthening its biological relevance. Our work establishes a possible computational mechanism underlying sequential memory in the brain that can also be theoretically interpreted using existing memory model frameworks",
    "checked": true,
    "id": "8a8f7953894fef09d32c5f35fd79cfbff025e56f",
    "semantic_title": "sequential memory with temporal predictive coding",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NJPSvv0u3R": {
    "title": "Robust low-rank training via approximate orthonormal constraints",
    "volume": "poster",
    "abstract": "With the growth of model and data sizes, a broad effort has been made to design pruning techniques that reduce the resource demand of deep learning pipelines, while retaining model performance. In order to reduce both inference and training costs, a prominent line of work uses low-rank matrix factorizations to represent the network weights. Although able to retain accuracy, we observe that low-rank methods tend to compromise model robustness against adversarial perturbations. By modeling robustness in terms of the condition number of the neural network, we argue that this loss of robustness is due to the exploding singular values of the low-rank weight matrices. Thus, we introduce a robust low-rank training algorithm that maintains the network's weights on the low-rank matrix manifold while simultaneously enforcing approximate orthonormal constraints. The resulting model reduces both training and inference costs while ensuring well-conditioning and thus better adversarial robustness, without compromising model accuracy. This is shown by extensive numerical evidence and by our main approximation theorem that shows the computed robust low-rank network well-approximates the ideal full model, provided a highly performing low-rank sub-network exists",
    "checked": true,
    "id": "1b88ff25523e21628672e6e0d77b4f2aede14bbc",
    "semantic_title": "robust low-rank training via approximate orthonormal constraints",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hLoanbRrjM": {
    "title": "Parts of Speech–Grounded Subspaces in Vision-Language Models",
    "volume": "poster",
    "abstract": "Latent image representations arising from vision-language models have proved immensely useful for a variety of downstream tasks. However, their utility is limited by their entanglement with respect to different visual attributes. For instance, recent work has shown that CLIP image representations are often biased toward specific visual properties (such as objects or actions) in an unpredictable manner. In this paper, we propose to separate representations of the different visual modalities in CLIP's joint vision-language space by leveraging the association between parts of speech and specific visual modes of variation (e.g. nouns relate to objects, adjectives describe appearance). This is achieved by formulating an appropriate component analysis model that learns subspaces capturing variability corresponding to a specific part of speech, while jointly minimising variability to the rest. Such a subspace yields disentangled representations of the different visual properties of an image or text in closed form while respecting the underlying geometry of the manifold on which the representations lie. What's more, we show the proposed model additionally facilitates learning subspaces corresponding to specific visual appearances (e.g. artists' painting styles), which enables the selective removal of entire visual themes from CLIP-based text-to-image synthesis. We validate the model both qualitatively, by visualising the subspace projections with a text-to-image model and by preventing the imitation of artists' styles, and quantitatively, through class invariance metrics and improvements to baseline zero-shot classification",
    "checked": false,
    "id": "470e12281fde486f2872f825528198384ff76702",
    "semantic_title": "parts of speech-grounded subspaces in vision-language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=CQ38aC92WY": {
    "title": "Counting Distinct Elements in the Turnstile Model with Differential Privacy under Continual Observation",
    "volume": "poster",
    "abstract": "Privacy is a central challenge for systems that learn from sensitive data sets, especially when a system's outputs must be continuously updated to reflect changing data. We consider the achievable error for differentially private continual release of a basic statistic---the number of distinct items---in a stream where items may be both inserted and deleted (the turnstile model). With only insertions, existing algorithms have additive error just polylogarithmic in the length of the stream $T$. We uncover a much richer landscape in the turnstile model, even without considering memory restrictions. We show that every differentially private mechanism that handles insertions and deletions has worst-case additive error at least $T^{1/4}$ even under a relatively weak, event-level privacy definition. Then, we identify a parameter of the input stream, its maximum flippancy, that is low for natural data streams and for which we give tight parameterized error guarantees. Specifically, the maximum flippancy is the largest number of times that the contribution of a single item to the distinct elements count changes over the course of the stream. We present an item-level differentially private mechanism that, for all turnstile streams with maximum flippancy $w$, continually outputs the number of distinct elements with an $O(\\sqrt{w} \\cdot \\mathsf{poly}\\log T)$ additive error, without requiring prior knowledge of $w$. We prove that this is the best achievable error bound that depends only on $w$, for a large range of values of $w$. When $w$ is small, the error of our mechanism is similar to the polylogarithmic in $T$ error in the insertion-only setting, bypassing the hardness in the turnstile model",
    "checked": true,
    "id": "61febc71dfeeed80f57d6d4c581750cbb083bb4e",
    "semantic_title": "counting distinct elements in the turnstile model with differential privacy under continual observation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=xz8j3r3oUA": {
    "title": "Color Equivariant Convolutional Networks",
    "volume": "poster",
    "abstract": "Color is a crucial visual cue readily exploited by Convolutional Neural Networks (CNNs) for object recognition. However, CNNs struggle if there is data imbalance between color variations introduced by accidental recording conditions. Color invariance addresses this issue but does so at the cost of removing all color information, which sacrifices discriminative power. In this paper, we propose Color Equivariant Convolutions (CEConvs), a novel deep learning building block that enables shape feature sharing across the color spectrum while retaining important color information. We extend the notion of equivariance from geometric to photometric transformations by incorporating parameter sharing over hue-shifts in a neural network. We demonstrate the benefits of CEConvs in terms of downstream performance to various tasks and improved robustness to color changes, including train-test distribution shifts. Our approach can be seamlessly integrated into existing architectures, such as ResNets, and offers a promising solution for addressing color-based domain shifts in CNNs",
    "checked": true,
    "id": "7aa596994ab0c70f3a5f816e8afb01038dd0afe6",
    "semantic_title": "color equivariant convolutional networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MGPST5I9DO": {
    "title": "Learning Efficient Surrogate Dynamic Models with Graph Spline Networks",
    "volume": "poster",
    "abstract": "While complex simulations of physical systems have been widely used in engineering and scientific computing, lowering their often prohibitive computational requirements has only recently been tackled by deep learning approaches. In this paper, we present GraphSplineNets, a novel deep-learning method to speed up the forecasting of physical systems by reducing the grid size and number of iteration steps of deep surrogate models. Our method uses two differentiable orthogonal spline collocation methods to efficiently predict response at any location in time and space. Additionally, we introduce an adaptive collocation strategy in space to prioritize sampling from the most important regions. GraphSplineNets improve the accuracy-speedup tradeoff in forecasting various dynamical systems with increasing complexity, including the heat equation, damped wave propagation, Navier-Stokes equations, and real-world ocean currents in both regular and irregular domains",
    "checked": true,
    "id": "cdab8be20b89f6f6127ed3145d2bff97581842fa",
    "semantic_title": "learning efficient surrogate dynamic models with graph spline networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B7QkdEnjL9": {
    "title": "Optimization and Bayes: A Trade-off for Overparameterized Neural Networks",
    "volume": "poster",
    "abstract": "This paper proposes a novel algorithm, Transformative Bayesian Learning (TansBL), which bridges the gap between empirical risk minimization (ERM) and Bayesian learning for neural networks. We compare ERM, which uses gradient descent to optimize, and Bayesian learning with importance sampling for their generalization and computational complexity. We derive the first algorithm-dependent PAC-Bayesian generalization bound for infinitely wide networks based on an exact KL divergence between the trained posterior distribution obtained by infinitesimal step size gradient descent and a Gaussian prior. Moreover, we show how to transform gradient-based optimization into importance sampling by incorporating a weight. While Bayesian learning has better generalization, it suffers from low sampling efficiency. Optimization methods, on the other hand, have good sampling efficiency but poor generalization. Our proposed algorithm TansBL enables a trade-off between generalization and sampling efficiency",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AYiRHZirD2": {
    "title": "A Unified Solution for Privacy and Communication Efficiency in Vertical Federated Learning",
    "volume": "poster",
    "abstract": "Vertical Federated Learning (VFL) is a collaborative machine learning paradigm that enables multiple participants to jointly train a model on their private data without sharing it. To make VFL practical, privacy security and communication efficiency should both be satisfied. Recent research has shown that Zero-Order Optimization (ZOO) in VFL can effectively conceal the internal information of the model without adding costly privacy protective add-ons, making it a promising approach for privacy and efficiency. However, there are still two key problems that have yet to be resolved. First, the convergence rate of ZOO-based VFL is significantly slower compared to gradient-based VFL, resulting in low efficiency in model training and more communication round, which hinders its application on large neural networks. Second, although ZOO-based VFL has demonstrated resistance to state-of-the-art (SOTA) attacks, its privacy guarantee lacks a theoretical explanation. To address these challenges, we propose a novel cascaded hybrid optimization approach that employs a zeroth-order (ZO) gradient on the most critical output layer of the clients, with other parts utilizing the first-order (FO) gradient. This approach preserves the privacy protection of ZOO while significantly enhancing convergence. Moreover, we theoretically prove that applying ZOO to the VFL is equivalent to adding Gaussian Mechanism to the gradient information, which offers an implicit differential privacy guarantee. Experimental results demonstrate that our proposed framework achieves similar utility as the Gaussian mechanism under the same privacy budget, while also having significantly lower communication costs compared with SOTA communication-efficient VFL frameworks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CswEebv5Hn": {
    "title": "Imitation Learning from Vague Feedback",
    "volume": "poster",
    "abstract": "Imitation learning from human feedback studies how to train well-performed imitation agents with an annotator's relative comparison of two demonstrations (one demonstration is better/worse than the other), which is usually easier to collect than the perfect expert data required by traditional imitation learning. However, in many real-world applications, it is still expensive or even impossible to provide a clear pairwise comparison between two demonstrations with similar quality. This motivates us to study the problem of imitation learning with vague feedback, where the data annotator can only distinguish the paired demonstrations correctly when their quality differs significantly, i.e., one from the expert and another from the non-expert. By modeling the underlying demonstration pool as a mixture of expert and non-expert data, we show that the expert policy distribution can be recovered when the proportion $\\alpha$ of expert data is known. We also propose a mixture proportion estimation method for the unknown $\\alpha$ case. Then, we integrate the recovered expert policy distribution with generative adversarial imitation learning to form an end-to-end algorithm. Experiments show that our methods outperform standard and preference-based imitation learning methods on various tasks",
    "checked": false,
    "id": "89200d67ab3dd3b1dad7dc544abb3cc6cbff5e3c",
    "semantic_title": "the minerl basalt competition on learning from human feedback",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=uWGH6jDTVv": {
    "title": "Complementary Benefits of Contrastive Learning and Self-Training Under Distribution Shift",
    "volume": "poster",
    "abstract": "Self-training and contrastive learning have emerged as leading techniques for incorporating unlabeled data, both under distribution shift (unsupervised domain adaptation) and when it is absent (semi-supervised learning). However, despite the popularity and compatibility of these techniques, their efficacy in combination remains surprisingly unexplored. In this paper, we first undertake a systematic empirical investigation of this combination, finding (i) that in domain adaptation settings, self-training and contrastive learning offer significant complementary gains; and (ii) that in semi-supervised learning settings, surprisingly, the benefits are not synergistic. Across eight distribution shift datasets (e.g., BREEDs, WILDS), we demonstrate that the combined method obtains 3--8\\% higher accuracy than either approach independently. Finally, we theoretically analyze these techniques in a simplified model of distribution shift demonstrating scenarios under which the features produced by contrastive learning can yield a good initialization for self-training to further amplify gains and achieve optimal performance, even when either method alone would fail",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1ihGy9vAIg": {
    "title": "Towards Efficient Image Compression Without Autoregressive Models",
    "volume": "poster",
    "abstract": "Recently, learned image compression (LIC) has garnered increasing interest with its rapidly improving performance surpassing conventional codecs. A key ingredient of LIC is a hyperprior-based entropy model, where the underlying joint probability of the latent image features is modeled as a product of Gaussian distributions from each latent element. Since latents from the actual images are not spatially independent, autoregressive (AR) context based entropy models were proposed to handle the discrepancy between the assumed distribution and the actual distribution. Though the AR-based models have proven effective, the computational complexity is significantly increased due to the inherent sequential nature of the algorithm. In this paper, we present a novel alternative to the AR-based approach that can provide a significantly better trade-off between performance and complexity. To minimize the discrepancy, we introduce a correlation loss that forces the latents to be spatially decorrelated and better fitted to the independent probability model. Our correlation loss is proved to act as a general plug-in for the hyperprior (HP) based learned image compression methods. The performance gain from our correlation loss is ‘free' in terms of computation complexity for both inference time and decoding time. To our knowledge, our method gives the best trade-off between the complexity and performance: combined with the Checkerboard-CM, it attains **90%** and when combined with ChARM-CM, it attains **98%** of the AR-based BD-Rate gains yet is around **50 times** and **30 times** faster than AR-based methods respectively",
    "checked": false,
    "id": "de510b4bcb62b6006d31f74ecd6a445818100949",
    "semantic_title": "towards learning-based image compression for storage on dna support",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WVmus8NWE8": {
    "title": "Mixture Weight Estimation and Model Prediction in Multi-source Multi-target Domain Adaptation",
    "volume": "poster",
    "abstract": "We consider a problem of learning a model from multiple sources with the goal to perform well on a new target distribution. Such problem arises in learning with data collected from multiple sources (e.g. crowdsourcing) or learning in distributed systems, where the data can be highly heterogeneous. The goal of learner is to mix these data sources in a target-distribution aware way and simultaneously minimize the empirical risk on the mixed source. The literature has made some tangible advancements in establishing theory of learning on mixture domain. However, there are still two unsolved problems. Firstly, how to estimate the optimal mixture of sources, given a target domain; Secondly, when there are numerous target domains, we have to solve empirical risk minimization for each target on possibly unique mixed source data , which is computationally expensive. In this paper we address both problems efficiently and with guarantees. We cast the first problem, mixture weight estimation as convex-nonconcave compositional minimax, and propose an efficient stochastic algorithm with provable stationarity guarantees. Next, for the second problem, we identify that for certain regime, solving ERM for each target domain individually can be avoided, and instead parameters for a target optimal model can be viewed as a non-linear function on a space of the mixture coefficients. To this end, we show that in offline setting, a GD-trained overparameterized neural network can provably learn such function. Finally, we also consider an online setting and propose an label efficient online algorithm, which predicts parameters for new models given arbitrary sequence of mixing coefficients, while enjoying optimal regret",
    "checked": true,
    "id": "30104cbea097437807d31b34eff4ebbabdce98c6",
    "semantic_title": "mixture weight estimation and model prediction in multi-source multi-target domain adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oqDSDKLd3S": {
    "title": "Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic Generalization Bounds",
    "volume": "poster",
    "abstract": "We present new information-theoretic generalization guarantees through the a novel construction of the \"neighboring-hypothesis\" matrix and a new family of stability notions termed sample-conditioned hypothesis (SCH) stability. Our approach yields sharper bounds that improve upon previous information-theoretic bounds in various learning scenarios. Notably, these bounds address the limitations of existing information-theoretic bounds in the context of stochastic convex optimization (SCO) problems, as explored in the recent work by Haghifam et al. (2023)",
    "checked": true,
    "id": "c4d7c145d31fba96d4868225ba7b4b9370155852",
    "semantic_title": "sample-conditioned hypothesis stability sharpens information-theoretic generalization bounds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nSr2epejn2": {
    "title": "Robust Matrix Sensing in the Semi-Random Model",
    "volume": "poster",
    "abstract": "Low-rank matrix recovery is a fundamental problem in machine learning with numerous applications. In practice, the problem can be solved by convex optimization namely nuclear norm minimization, or by non-convex optimization as it is well-known that for low-rank matrix problems like matrix sensing and matrix completion, all local optima of the natural non-convex objectives are also globally optimal under certain ideal assumptions. In this paper, we study new approaches for matrix sensing in a semi-random model where an adversary can add any number of arbitrary sensing matrices. More precisely, the problem is to recover a low-rank matrix $X^\\star$ from linear measurements $b_i = \\langle A_i, X^\\star \\rangle$, where an unknown subset of the sensing matrices satisfies the Restricted Isometry Property (RIP) and the rest of the $A_i$'s are chosen adversarially. It is known that in the semi-random model, existing non-convex objectives can have bad local optima. To fix this, we present a descent-style algorithm that provably recovers the ground-truth matrix $X^\\star$. For the closely-related problem of semi-random matrix completion, prior work [CG18] showed that all bad local optima can be eliminated by reweighting the input data. However, the analogous approach for matrix sensing requires reweighting a set of matrices to satisfy RIP, which is a condition that is NP-hard to check. Instead, we build on the framework proposed in [KLL$^+$23] for semi-random sparse linear regression, where the algorithm in each iteration reweights the input based on the current solution, and then takes a weighted gradient step that is guaranteed to work well locally. Our analysis crucially exploits the connection between sparsity in vector problems and low-rankness in matrix problems, which may have other applications in obtaining robust algorithms for sparse and low-rank problems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bGs1qWQ1Fx": {
    "title": "FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective",
    "volume": "poster",
    "abstract": "Multivariate time series (MTS) forecasting has shown great importance in numerous industries. Current state-of-the-art graph neural network (GNN)-based forecasting methods usually require both graph networks (e.g., GCN) and temporal networks (e.g., LSTM) to capture inter-series (spatial) dynamics and intra-series (temporal) dependencies, respectively. However, the uncertain compatibility of the two networks puts an extra burden on handcrafted model designs. Moreover, the separate spatial and temporal modeling naturally violates the unified spatiotemporal inter-dependencies in real world, which largely hinders the forecasting performance. To overcome these problems, we explore an interesting direction of directly applying graph networks and rethink MTS forecasting from a pure graph perspective. We first define a novel data structure, hypervariate graph, which regards each series value (regardless of variates or timestamps) as a graph node, and represents sliding windows as space-time fully-connected graphs. This perspective considers spatiotemporal dynamics unitedly and reformulates classic MTS forecasting into the predictions on hypervariate graphs. Then, we propose a novel architecture Fourier Graph Neural Network (FourierGNN) by stacking our proposed Fourier Graph Operator (FGO) to perform matrix multiplications in Fourier space. FourierGNN accommodates adequate expressiveness and achieves much lower complexity, which can effectively and efficiently accomplish {the forecasting}. Besides, our theoretical analysis reveals FGO's equivalence to graph convolutions in the time domain, which further verifies the validity of FourierGNN. Extensive experiments on seven datasets have demonstrated our superior performance with higher efficiency and fewer parameters compared with state-of-the-art methods. Code is available at this repository: https://github.com/aikunyi/FourierGNN",
    "checked": true,
    "id": "9dbcb0893d05e6176353eee401afa4929b570cf6",
    "semantic_title": "fouriergnn: rethinking multivariate time series forecasting from a pure graph perspective",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kAU6Cdq1gV": {
    "title": "Discovering General Reinforcement Learning Algorithms with Adversarial Environment Design",
    "volume": "poster",
    "abstract": "The past decade has seen vast progress in deep reinforcement learning (RL) on the back of algorithms manually designed by human researchers. Recently, it has been shown that it is possible to meta-learn update rules, with the hope of discovering algorithms that can perform well on a wide range of RL tasks. Despite impressive initial results from algorithms such as Learned Policy Gradient (LPG), there remains a generalization gap when these algorithms are applied to unseen environments. In this work, we examine how characteristics of the meta-training distribution impact the generalization performance of these algorithms. Motivated by this analysis and building on ideas from Unsupervised Environment Design (UED), we propose a novel approach for automatically generating curricula to maximize the regret of a meta-learned optimizer, in addition to a novel approximation of regret, which we name algorithmic regret (AR). The result is our method, General RL Optimizers Obtained Via Environment Design (GROOVE). In a series of experiments, we show that GROOVE achieves superior generalization to LPG, and evaluate AR against baseline metrics from UED, identifying it as a critical component of environment design in this setting. We believe this approach is a step towards the discovery of truly general RL algorithms, capable of solving a wide range of real-world environments",
    "checked": true,
    "id": "7afb8a00b808d6dc43cef350450f46e443329e67",
    "semantic_title": "discovering general reinforcement learning algorithms with adversarial environment design",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WcoX8eJJjI": {
    "title": "Low Tensor Rank Learning of Neural Dynamics",
    "volume": "poster",
    "abstract": "Learning relies on coordinated synaptic changes in recurrently connected populations of neurons. Therefore, understanding the collective evolution of synaptic connectivity over learning is a key challenge in neuroscience and machine learning. In particular, recent work has shown that the weight matrices of task-trained RNNs are typically low rank, but how this low rank structure unfolds over learning is unknown. To address this, we investigate the rank of the 3-tensor formed by the weight matrices throughout learning. By fitting RNNs of varying rank to large-scale neural recordings during a motor learning task, we find that the inferred weights are low-tensor-rank and therefore evolve over a fixed low-dimensional subspace throughout the entire course of learning. We next validate the observation of low-tensor-rank learning on an RNN trained to solve the same task. Finally, we present a set of mathematical results bounding the matrix and tensor ranks of gradient descent learning dynamics which show that low-tensor-rank weights emerge naturally in RNNs trained to solve low-dimensional tasks. Taken together, our findings provide insight on the evolution of population connectivity over learning in both biological and artificial neural networks, and enable reverse engineering of learning-induced changes in recurrent dynamics from large-scale neural recordings",
    "checked": true,
    "id": "49d720873b5f793a13564a5777ab88152febb9f1",
    "semantic_title": "low tensor rank learning of neural dynamics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CJWQGDwa6u": {
    "title": "Differentiable Random Partition Models",
    "volume": "poster",
    "abstract": "Partitioning a set of elements into an unknown number of mutually exclusive subsets is essential in many machine learning problems. However, assigning elements, such as samples in a dataset or neurons in a network layer, to an unknown and discrete number of subsets is inherently non-differentiable, prohibiting end-to-end gradient-based optimization of parameters. We overcome this limitation by proposing a novel two-step method for inferring partitions, which allows its usage in variational inference tasks. This new approach enables reparameterized gradients with respect to the parameters of the new random partition model. Our method works by inferring the number of elements per subset and, second, by filling these subsets in a learned order. We highlight the versatility of our general-purpose approach on three different challenging experiments: variational clustering, inference of shared and independent generative factors under weak supervision, and multitask learning",
    "checked": true,
    "id": "d4c4c023006c88eda322abfd3e28352a71a4535b",
    "semantic_title": "differentiable random partition models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SQP1H9Jy8W": {
    "title": "Leveraging Locality and Robustness to Achieve Massively Scalable Gaussian Process Regression",
    "volume": "poster",
    "abstract": "The accurate predictions and principled uncertainty measures provided by GP regression incur $O(n^3)$ cost which is prohibitive for modern-day large-scale applications. This has motivated extensive work on computationally efficient approximations. We introduce a new perspective by exploring robustness properties and limiting behaviour of GP nearest-neighbour (GPnn) prediction. We demonstrate through theory and simulation that as the data-size $n$ increases, accuracy of estimated parameters and GP model assumptions become increasingly irrelevant to GPnn predictive accuracy. Consequently, it is sufficient to spend small amounts of work on parameter estimation in order to achieve high MSE accuracy, even in the presence of gross misspecification. In contrast, as $n \\rightarrow \\infty$, uncertainty calibration and NLL are shown to remain sensitive to just one parameter, the additive noise-variance; but we show that this source of inaccuracy can be corrected for, thereby achieving both well-calibrated uncertainty measures and accurate predictions at remarkably low computational cost. We exhibit a very simple GPnn regression algorithm with stand-out performance compared to other state-of-the-art GP approximations as measured on large UCI datasets. It operates at a small fraction of those other methods' training costs, for example on a basic laptop taking about 30 seconds to train on a dataset of size $n = 1.6 \\times 10^6$",
    "checked": true,
    "id": "8b3450a8bbfb19bd7f489b86da7b2f9890db44ec",
    "semantic_title": "leveraging locality and robustness to achieve massively scalable gaussian process regression",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9yhYcjsdab": {
    "title": "Three Iterations of (d − 1)-WL Test Distinguish Non Isometric Clouds of d-dimensional Points",
    "volume": "poster",
    "abstract": "The Weisfeiler-Lehman (WL) test is a fundamental iterative algorithm for checking the isomorphism of graphs. It has also been observed that it underlies the design of several graph neural network architectures, whose capabilities and performance can be understood in terms of the expressive power of this test. Motivated by recent developments in machine learning applications to datasets involving three-dimensional objects, we study when the WL test is {\\em complete} for clouds of Euclidean points represented by complete distance graphs, i.e., when it can distinguish, up to isometry, any arbitrary such cloud. Our main result states that the $(d-1)$-dimensional WL test is complete for point clouds in $d$-dimensional Euclidean space, for any $d\\ge 2$, and only three iterations of the test suffice. Our result is tight for $d = 2, 3$. We also observe that the $d$-dimensional WL test only requires one iteration to achieve completeness",
    "checked": false,
    "id": "7de523207140a88ab7e5f0d2960f55d1b40ddb86",
    "semantic_title": "three iterations of $(d-1)$-wl test distinguish non isometric clouds of $d$-dimensional points",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=iif9mGCTfy": {
    "title": "Frequency-domain MLPs are More Effective Learners in Time Series Forecasting",
    "volume": "poster",
    "abstract": "Time series forecasting has played the key role in different industrial, including finance, traffic, energy, and healthcare domains. While existing literatures have designed many sophisticated architectures based on RNNs, GNNs, or Transformers, another kind of approaches based on multi-layer perceptrons (MLPs) are proposed with simple structure, low complexity, and superior performance. However, most MLP-based forecasting methods suffer from the point-wise mappings and information bottleneck, which largely hinders the forecasting performance. To overcome this problem, we explore a novel direction of applying MLPs in the frequency domain for time series forecasting. We investigate the learned patterns of frequency-domain MLPs and discover their two inherent characteristic benefiting forecasting, (i) global view: frequency spectrum makes MLPs own a complete view for signals and learn global dependencies more easily, and (ii) energy compaction: frequency-domain MLPs concentrate on smaller key part of frequency components with compact signal energy. Then, we propose FreTS, a simple yet effective architecture built upon Frequency-domain MLPs for Time Series forecasting. FreTS mainly involves two stages, (i) Domain Conversion, that transforms time-domain signals into complex numbers of frequency domain; (ii) Frequency Learning, that performs our redesigned MLPs for the learning of real and imaginary part of frequency components. The above stages operated on both inter-series and intra-series scales further contribute to channel-wise and time-wise dependency learning. Extensive experiments on 13 real-world benchmarks (including 7 benchmarks for short-term forecasting and 6 benchmarks for long-term forecasting) demonstrate our consistent superiority over state-of-the-art methods. Code is available at this repository: https://github.com/aikunyi/FreTS",
    "checked": true,
    "id": "9297502c3b1eaa528e8a8fb85a83842d0577fdc6",
    "semantic_title": "frequency-domain mlps are more effective learners in time series forecasting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0e4eiXoUn5": {
    "title": "SAMoSSA: Multivariate Singular Spectrum Analysis with Stochastic Autoregressive Noise",
    "volume": "poster",
    "abstract": "The well-established practice of time series analysis involves estimating deterministic, non-stationary trend and seasonality components followed by learning the residual stochastic, stationary components. Recently, it has been shown that one can learn the deterministic non-stationary components accurately using multivariate Singular Spectrum Analysis (mSSA) in the absence of a correlated stationary component; meanwhile, in the absence of deterministic non-stationary components, the Autoregressive (AR) stationary component can also be learnt readily, e.g. via Ordinary Least Squares (OLS). However, a theoretical underpinning of multi-stage learning algorithms involving both deterministic and stationary components has been absent in the literature despite its pervasiveness. We resolve this open question by establishing desirable theoretical guarantees for a natural two-stage algorithm, where mSSA is first applied to estimate the non-stationary components despite the presence of a correlated stationary AR component, which is subsequently learned from the residual time series. We provide a finite-sample forecasting consistency bound for the proposed algorithm, SAMoSSA, which is data-driven and thus requires minimal parameter tuning. To establish theoretical guarantees, we overcome three hurdles: (i) we characterize the spectra of Page matrices of stable AR processes, thus extending the analysis of mSSA; (ii) we extend the analysis of AR process identification in the presence of arbitrary bounded perturbations; (iii) we characterize the out-of-sample or forecasting error, as opposed to solely considering model identification. Through representative empirical studies, we validate the superior performance of SAMoSSA compared to existing baselines. Notably, SAMoSSA's ability to account for AR noise structure yields improvements ranging from 5% to 37% across various benchmark datasets",
    "checked": true,
    "id": "af0348256beec50cb4cca32a66c359ae68945430",
    "semantic_title": "samossa: multivariate singular spectrum analysis with stochastic autoregressive noise",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LyAuNoZkGP": {
    "title": "Diffused Redundancy in Pre-trained Representations",
    "volume": "poster",
    "abstract": "Representations learned by pre-training a neural network on a large dataset are increasingly used successfully to perform a variety of downstream tasks. In this work, we take a closer look at how features are encoded in such pre-trained representations. We find that learned representations in a given layer exhibit a degree of diffuse redundancy, ie, any randomly chosen subset of neurons in the layer that is larger than a threshold size shares a large degree of similarity with the full layer and is able to perform similarly as the whole layer on a variety of downstream tasks. For example, a linear probe trained on $20\\%$ of randomly picked neurons from the penultimate layer of a ResNet50 pre-trained on ImageNet1k achieves an accuracy within $5\\%$ of a linear probe trained on the full layer of neurons for downstream CIFAR10 classification. We conduct experiments on different neural architectures (including CNNs and Transformers) pre-trained on both ImageNet1k and ImageNet21k and evaluate a variety of downstream tasks taken from the VTAB benchmark. We find that the loss \\& dataset used during pre-training largely govern the degree of diffuse redundancy and the \"critical mass\" of neurons needed often depends on the downstream task, suggesting that there is a task-inherent redundancy-performance Pareto frontier. Our findings shed light on the nature of representations learned by pre-trained deep neural networks and suggest that entire layers might not be necessary to perform many downstream tasks. We investigate the potential for exploiting this redundancy to achieve efficient generalization for downstream tasks and also draw caution to certain possible unintended consequences. Our code is available at \\url{https://github.com/nvedant07/diffused-redundancy}",
    "checked": true,
    "id": "32658cbc2e3435b3df667cb494e527a5955d0cde",
    "semantic_title": "diffused redundancy in pre-trained representations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LUVqEs90mq": {
    "title": "Stochastic Optimal Control for Collective Variable Free Sampling of Molecular Transition Paths",
    "volume": "poster",
    "abstract": "We consider the problem of sampling transition paths between two given metastable states of a molecular system, eg. a folded and unfolded protein or products and reactants of a chemical reaction. Due to the existence of high energy barriers separating the states, these transition paths are unlikely to be sampled with standard Molecular Dynamics (MD) simulation. Traditional methods to augment MD with a bias potential to increase the probability of the transition rely on a dimensionality reduction step based on Collective Variables (CVs). Unfortunately, selecting appropriate CVs requires chemical intuition and traditional methods are therefore not always applicable to larger systems. Additionally, when incorrect CVs are used, the bias potential might not be minimal and bias the system along dimensions irrelevant to the transition. Showing a formal relation between the problem of sampling molecular transition paths, the Schrodinger bridge problem and stochastic optimal control with neural network policies, we propose a machine learning method for sampling said transitions. Unlike previous non-machine learning approaches our method, named PIPS, does not depend on CVs. We show that our method successful generates low energy transitions for Alanine Dipeptide as well as the larger Polyproline and Chignolin proteins",
    "checked": true,
    "id": "fe3f15ae7a953eae5ac4e8d7670765116d838ce9",
    "semantic_title": "stochastic optimal control for collective variable free sampling of molecular transition paths",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=RrdBNXBUIF": {
    "title": "Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering",
    "volume": "poster",
    "abstract": "Despite the empirical success and practical significance of (relational) knowledge distillation that matches (the relations of) features between teacher and student models, the corresponding theoretical interpretations remain limited for various knowledge distillation paradigms. In this work, we take an initial step toward a theoretical understanding of relational knowledge distillation (RKD), with a focus on semi-supervised classification problems. We start by casting RKD as spectral clustering on a population-induced graph unveiled by a teacher model. Via a notion of clustering error that quantifies the discrepancy between the predicted and ground truth clusterings, we illustrate that RKD over the population provably leads to low clustering error. Moreover, we provide a sample complexity bound for RKD with limited unlabeled samples. For semi-supervised learning, we further demonstrate the label efficiency of RKD through a general framework of cluster-aware semi-supervised learning that assumes low clustering errors. Finally, by unifying data augmentation consistency regularization into this cluster-aware framework, we show that despite the common effect of learning accurate clusterings, RKD facilitates a \"global\" perspective through spectral clustering, whereas consistency regularization focuses on a \"local\" perspective via expansion",
    "checked": true,
    "id": "138ad85ac351cf8cca2bb3a5defed58707eb72c6",
    "semantic_title": "cluster-aware semi-supervised learning: relational knowledge distillation provably learns clustering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZGElmTRk3w": {
    "title": "On kernel-based statistical learning theory in the mean field limit",
    "volume": "poster",
    "abstract": "In many applications of machine learning, a large number of variables are considered. Motivated by machine learning of interacting particle systems, we consider the situation when the number of input variables goes to infinity. First, we continue the recent investigation of the mean field limit of kernels and their reproducing kernel Hilbert spaces, completing the existing theory. Next, we provide results relevant for approximation with such kernels in the mean field limit, including a representer theorem. Finally, we use these kernels in the context of statistical learning in the mean field limit, focusing on Support Vector Machines. In particular, we show mean field convergence of empirical and infinite-sample solutions as well as the convergence of the corresponding risks. On the one hand, our results establish rigorous mean field limits in the context of kernel methods, providing new theoretical tools and insights for large-scale problems. On the other hand, our setting corresponds to a new form of limit of learning problems, which seems to have not been investigated yet in the statistical learning theory literature",
    "checked": false,
    "id": "4feb49424f0a7d4aa1433ac7440b7354d3b623b8",
    "semantic_title": "on kernel-based statistical learning in the mean field limit",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1mdTYi1jAW": {
    "title": "Adjustable Robust Reinforcement Learning for Online 3D Bin Packing",
    "volume": "poster",
    "abstract": "Designing effective policies for the online 3D bin packing problem (3D-BPP) has been a long-standing challenge, primarily due to the unpredictable nature of incoming box sequences and stringent physical constraints. While current deep reinforcement learning (DRL) methods for online 3D-BPP have shown promising results in optimizing average performance over an underlying box sequence distribution, they often fail in real-world settings where some worst-case scenarios can materialize. Standard robust DRL algorithms tend to overly prioritize optimizing the worst-case performance at the expense of performance under normal problem instance distribution. To address these issues, we first introduce a permutation-based attacker to investigate the practical robustness of both DRL-based and heuristic methods proposed for solving online 3D-BPP. Then, we propose an adjustable robust reinforcement learning (AR2L) framework that allows efficient adjustment of robustness weights to achieve the desired balance of the policy's performance in average and worst-case environments. Specifically, we formulate the objective function as a weighted sum of expected and worst-case returns, and derive the lower performance bound by relating to the return under a mixture dynamics. To realize this lower bound, we adopt an iterative procedure that searches for the associated mixture dynamics and improves the corresponding policy. We integrate this procedure into two popular robust adversarial algorithms to develop the exact and approximate AR2L algorithms. Experiments demonstrate that AR2L is versatile in the sense that it improves policy robustness while maintaining an acceptable level of performance for the nominal case",
    "checked": true,
    "id": "37ae5464f493148e1eb06ca949bf0ffc6813a109",
    "semantic_title": "adjustable robust reinforcement learning for online 3d bin packing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xW0ayZxPWs": {
    "title": "Fair Graph Distillation",
    "volume": "poster",
    "abstract": "As graph neural networks (GNNs) struggle with large-scale graphs due to high computational demands, data distillation for graph data promises to alleviate this issue by distilling a large real graph into a smaller distilled graph while maintaining comparable prediction performance for GNNs trained on both graphs. However, we observe that GNNs trained on distilled graphs may exhibit more severe group fairness problems than those trained on real graphs. Motivated by this observation, we propose \\textit{fair graph distillation} (\\Algnameabbr), an approach for generating small distilled \\textit{fair and informative} graphs based on the graph distillation method. The challenge lies in the deficiency of sensitive attributes for nodes in the distilled graph, making most debiasing methods (e.g., regularization and adversarial debiasing) intractable for distilled graphs. We develop a simple yet effective bias metric, called coherence, for distilled graphs. Based on the proposed coherence metric, we introduce a framework for fair graph distillation using a bi-level optimization algorithm. Extensive experiments demonstrate that the proposed algorithm can achieve better prediction performance-fairness trade-offs across various datasets and GNN architectures",
    "checked": false,
    "id": "9361dfb0f38d80dadf373b6cda02d44b8ce43867",
    "semantic_title": "fair graph mining",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=6qLzQeFGio": {
    "title": "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?",
    "volume": "poster",
    "abstract": "We present the largest and most comprehensive empirical study of pre-trained visual representations (PVRs) or visual ‘foundation models' for Embodied AI. First, we curate CortexBench, consisting of 17 different tasks spanning locomotion, navigation, dexterous, and mobile manipulation. Next, we systematically evaluate existing PVRs and find that none are universally dominant. To study the effect of pre-training data size and diversity, we combine over 4,000 hours of egocentric videos from 7 different sources (over 4.3M images) and ImageNet to train different-sized vision transformers using Masked Auto-Encoding (MAE) on slices of this data. Contrary to inferences from prior work, we find that scaling dataset size and diversity does not improve performance universally (but does so on average). Our largest model, named VC-1, outperforms all prior PVRs on average but does not universally dominate either. Next, we show that task- or domain-specific adaptation of VC-1 leads to substantial gains, with VC-1 (adapted) achieving competitive or superior performance than the best known results on all of the benchmarks in CortexBench. Finally, we present real-world hardware experiments, in which VC-1 and VC-1 (adapted) outperform the strongest pre-existing PVR. Overall, this paper presents no new techniques but a rigorous systematic evaluation, a broad set of findings about PVRs (that in some cases, refute those made in narrow domains in prior work), and open-sourced code and models (that required over 10,000 GPU-hours to train) for the benefit of the research community",
    "checked": true,
    "id": "326f6a8011e43322c433751b9cc31fd56564621c",
    "semantic_title": "where are we in the search for an artificial visual cortex for embodied intelligence?",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=jYIknUIgkd": {
    "title": "Moral Responsibility for AI Systems",
    "volume": "poster",
    "abstract": "As more and more decisions that have a significant ethical dimension are being outsourced to AI systems, it is important to have a definition of _moral responsibility_ that can be applied to AI systems. Moral responsibility for an outcome of an agent who performs some action is commonly taken to involve both a _causal condition_ and an _epistemic condition_: the action should cause the outcome, and the agent should have been aware - in some form or other - of the possible moral consequences of their action. This paper presents a formal definition of both conditions within the framework of causal models. I compare my approach to the existing approaches of Braham and van Hees (BvH) and of Halpern and Kleiman-Weiner (HK). I then generalize my definition into a _degree of responsibility_",
    "checked": true,
    "id": "dbe09be3d8721bd0bd62150b3c8d9c6765f678d3",
    "semantic_title": "moral responsibility for ai systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kjMGHTo8Cs": {
    "title": "Inverse Dynamics Pretraining Learns Good Representations for Multitask Imitation",
    "volume": "poster",
    "abstract": "In recent years, domains such as natural language processing and image recognition have popularized the paradigm of using large datasets to pretrain representations that can be effectively transferred to downstream tasks. In this work we evaluate how such a paradigm should be done in imitation learning, where both pretraining and finetuning data are trajectories collected by experts interacting with an unknown environment. Namely, we consider a setting where the pretraining corpus consists of multitask demonstrations and the task for each demonstration is set by an unobserved latent context variable. The goal is to use the pretraining corpus to learn a low dimensional representation of the high dimensional (e.g., visual) observation space which can be transferred to a novel context for finetuning on a limited dataset of demonstrations. Among a variety of possible pretraining objectives, we argue that inverse dynamics modeling -- i.e., predicting an action given the observations appearing before and after it in the demonstration -- is well-suited to this setting. We provide empirical evidence of this claim through evaluations on a variety of simulated visuomotor manipulation problems. While previous work has attempted various theoretical explanations regarding the benefit of inverse dynamics modeling, we find that these arguments are insufficient to explain the empirical advantages often observed in our settings, and so we derive a novel analysis using a simple but general environment model",
    "checked": true,
    "id": "64a98f9c40ef559117324e6d92417e8f5173b694",
    "semantic_title": "inverse dynamics pretraining learns good representations for multitask imitation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Qv7rWR9JWa": {
    "title": "Sorting with Predictions",
    "volume": "poster",
    "abstract": "We explore the fundamental problem of sorting through the lens of learning-augmented algorithms, where algorithms can leverage possibly erroneous predictions to improve their efficiency. We consider two different settings: In the first setting, each item is provided a prediction of its position in the sorted list. In the second setting, we assume there is a ``quick-and-dirty'' way of comparing items, in addition to slow-and-exact comparisons. For both settings, we design new and simple algorithms using only $O(\\sum_i \\log \\eta_i)$ exact comparisons, where $\\eta_i$ is a suitably defined prediction error for the $i$th element. In particular, as the quality of predictions deteriorates, the number of comparisons degrades smoothly from $O(n)$ to $O(n\\log n)$. We prove that this comparison complexity is theoretically optimal with respect to the examined error measures. An experimental evaluation against existing adaptive and non-adaptive sorting algorithms demonstrates the potential of applying learning-augmented algorithms in sorting tasks",
    "checked": true,
    "id": "15f8b247570b9381aa2b38c4360d02ae81834517",
    "semantic_title": "sorting with predictions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=497CevPdOg": {
    "title": "Direct Diffusion Bridge using Data Consistency for Inverse Problems",
    "volume": "poster",
    "abstract": "Diffusion model-based inverse problem solvers have shown impressive performance, but are limited in speed, mostly as they require reverse diffusion sampling starting from noise. Several recent works have tried to alleviate this problem by building a diffusion process, directly bridging the clean and the corrupted for specific inverse problems. In this paper, we first unify these existing works under the name Direct Diffusion Bridges (DDB), showing that while motivated by different theories, the resulting algorithms only differ in the choice of parameters. Then, we highlight a critical limitation of the current DDB framework, namely that it does not ensure data consistency. To address this problem, we propose a modified inference procedure that imposes data consistency without the need for fine-tuning. We term the resulting method data Consistent DDB (CDDB), which outperforms its inconsistent counterpart in terms of both perception and distortion metrics, thereby effectively pushing the Pareto-frontier toward the optimum. Our proposed method achieves state-of-the-art results on both evaluation criteria, showcasing its superiority over existing methods. Code is open-sourced [here](https://github.com/HJ-harry/CDDB)",
    "checked": true,
    "id": "403d5853984300565714ef446bc5da0b80479b37",
    "semantic_title": "direct diffusion bridge using data consistency for inverse problems",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=yBVLXvJ1sb": {
    "title": "Error Discovery By Clustering Influence Embeddings",
    "volume": "poster",
    "abstract": "We present a method for identifying groups of test examples---slices---on which a model under-performs, a task now known as slice discovery. We formalize coherence---a requirement that erroneous predictions, within a slice, should be wrong for the same reason---as a key property that any slice discovery method should satisfy. We then use influence functions to derive a new slice discovery method, InfEmbed, which satisfies coherence by returning slices whose examples are influenced similarly by the training data. InfEmbed is simple, and consists of applying K-Means clustering to a novel representation we deem influence embeddings. We show InfEmbed outperforms current state-of-the-art methods on 2 benchmarks, and is effective for model debugging across several case studies",
    "checked": false,
    "id": "147475ad48f26f76c8862e6980917d78110982f0",
    "semantic_title": "coin: co-cluster infomax for bipartite graphs",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=0WLMVDdvDF": {
    "title": "No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions",
    "volume": "poster",
    "abstract": "Existing online learning algorithms for adversarial Markov Decision Processes achieve $\\mathcal{O}(\\sqrt{T})$ regret after $T$ rounds of interactions even if the loss functions are chosen arbitrarily by an adversary, with the caveat that the transition function has to be fixed. This is because it has been shown that adversarial transition functions make no-regret learning impossible. Despite such impossibility results, in this work, we develop algorithms that can handle both adversarial losses and adversarial transitions, with regret increasing smoothly in the degree of maliciousness of the adversary. More concretely, we first propose an algorithm that enjoys $\\widetilde{\\mathcal{O}}(\\sqrt{T} + C^{P})$ regret where $C^{P}$ measures how adversarial the transition functions are and can be at most $\\mathcal{O}(T)$. While this algorithm itself requires knowledge of $C^{P}$, we further develop a black-box reduction approach that removes this requirement. Moreover, we also show that further refinements of the algorithm not only maintains the same regret bound, but also simultaneously adapts to easier environments (where losses are generated in a certain stochastically constrained manner as in [Jin et al. 2021]) and achieves $\\widetilde{\\mathcal{O}}(U + \\sqrt{UC^{L}} + C^{P})$ regret, where $U$ is some standard gap-dependent coefficient and $C^{L}$ is the amount of corruption on losses",
    "checked": true,
    "id": "4e54d1731c089aa617880b916844e3912dbb538f",
    "semantic_title": "no-regret online reinforcement learning with adversarial losses and transitions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=4Ks8RPcXd9": {
    "title": "Direction-oriented Multi-objective Learning: Simple and Provable Stochastic Algorithms",
    "volume": "poster",
    "abstract": "Multi-objective optimization (MOO) has become an influential framework in many machine learning problems with multiple objectives such as learning with multiple criteria and multi-task learning (MTL). In this paper, we propose a new direction-oriented multi-objective formulation by regularizing the common descent direction within a neighborhood of a direction that optimizes a linear combination of objectives such as the average loss in MTL or a weighted loss that places higher emphasis on some tasks than the others. This formulation includes GD and MGDA as special cases, enjoys the direction-oriented benefit as in CAGrad, and facilitates the design of stochastic algorithms. To solve this problem, we propose Stochastic Direction-oriented Multi-objective Gradient descent (SDMGrad) with simple SGD type of updates, and its variant SDMGrad-OS with an efficient objective sampling. We develop a comprehensive convergence analysis for the proposed methods with different loop sizes and regularization coefficients. We show that both SDMGrad and SDMGrad-OS achieve improved sample complexities to find an $\\epsilon$-accurate Pareto stationary point while achieving a small $\\epsilon$-level distance toward a conflict-avoidant (CA) direction. For a constant-level CA distance, their sample complexities match the best known $\\mathcal{O}(\\epsilon^{-2})$ without bounded function value assumption. Extensive experiments show that our methods achieve competitive or improved performance compared to existing gradient manipulation approaches in a series of tasks on multi-task supervised learning and reinforcement learning. Code is available at https://github.com/ml-opt-lab/sdmgrad",
    "checked": true,
    "id": "60ad0e8febb6930f2c0b94955514ea0cebbf58b4",
    "semantic_title": "direction-oriented multi-objective learning: simple and provable stochastic algorithms",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=gsglrhvQxX": {
    "title": "Flow-Based Feature Fusion for Vehicle-Infrastructure Cooperative 3D Object Detection",
    "volume": "poster",
    "abstract": "Cooperatively utilizing both ego-vehicle and infrastructure sensor data can significantly enhance autonomous driving perception abilities. However, the uncertain temporal asynchrony and limited communication conditions that are present in traffic environments can lead to fusion misalignment and constrain the exploitation of infrastructure data. To address these issues in vehicle-infrastructure cooperative 3D (VIC3D) object detection, we propose the Feature Flow Net (FFNet), a novel cooperative detection framework. FFNet is a flow-based feature fusion framework that uses a feature flow prediction module to predict future features and compensate for asynchrony. Instead of transmitting feature maps extracted from still-images, FFNet transmits feature flow, leveraging the temporal coherence of sequential infrastructure frames. Furthermore, we introduce a self-supervised training approach that enables FFNet to generate feature flow with feature prediction ability from raw infrastructure sequences. Experimental results demonstrate that our proposed method outperforms existing cooperative detection methods while only requiring about 1/100 of the transmission cost of raw data and covers all latency in one model on the DAIR-V2X dataset. The code is available https://github.com/haibao-yu/FFNet-VIC3D",
    "checked": true,
    "id": "b015c405a15b44f6edab3abad796813c67d67078",
    "semantic_title": "flow-based feature fusion for vehicle-infrastructure cooperative 3d object detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IcIQbCWoFj": {
    "title": "Stochastic Approximation Approaches to Group Distributionally Robust Optimization",
    "volume": "poster",
    "abstract": "This paper investigates group distributionally robust optimization (GDRO), with the purpose to learn a model that performs well over $m$ different distributions. First, we formulate GDRO as a stochastic convex-concave saddle-point problem, and demonstrate that stochastic mirror descent (SMD), using $m$ samples in each iteration, achieves an $O(m (\\log m)/\\epsilon^2)$ sample complexity for finding an $\\epsilon$-optimal solution, which matches the $\\Omega(m/\\epsilon^2)$ lower bound up to a logarithmic factor. Then, we make use of techniques from online learning to reduce the number of samples required in each round from $m$ to $1$, keeping the same sample complexity. Specifically, we cast GDRO as a two-players game where one player simply performs SMD and the other executes an online algorithm for non-oblivious multi-armed bandits. Next, we consider a more practical scenario where the number of samples that can be drawn from each distribution is different, and propose a novel formulation of weighted GDRO, which allows us to derive distribution-dependent convergence rates. Denote by $n_i$ the sample budget for the $i$-th distribution, and assume $n_1 \\geq n_2 \\geq \\cdots \\geq n_m$. In the first approach, we incorporate non-uniform sampling into SMD such that the sample budget is satisfied in expectation, and prove that the excess risk of the $i$-th distribution decreases at an $O(\\sqrt{n_1 \\log m}/n_i)$ rate. In the second approach, we use mini-batches to meet the budget exactly and also reduce the variance in stochastic gradients, and then leverage stochastic mirror-prox algorithm, which can exploit small variances, to optimize a carefully designed weighted GDRO problem. Under appropriate conditions, it attains an $O((\\log m)/\\sqrt{n_i})$ convergence rate, which almost matches the optimal $O(\\sqrt{1/n_i})$ rate of only learning from the $i$-th distribution with $n_i$ samples",
    "checked": true,
    "id": "ffb355d49e686ba3c7871aee9928e314e63b6a78",
    "semantic_title": "stochastic approximation approaches to group distributionally robust optimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=YJDz4F2AZu": {
    "title": "ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling",
    "volume": "poster",
    "abstract": "Modeling continuous-time dynamics on irregular time series is critical to account for data evolution and correlations that occur continuously. Traditional methods including recurrent neural networks or Transformer models leverage inductive bias via powerful neural architectures to capture complex patterns. However, due to their discrete characteristic, they have limitations in generalizing to continuous-time data paradigms. Though neural ordinary differential equations (Neural ODEs) and their variants have shown promising results in dealing with irregular time series, they often fail to capture the intricate correlations within these sequences. It is challenging yet demanding to concurrently model the relationship between input data points and capture the dynamic changes of the continuous-time system. To tackle this problem, we propose ContiFormer that extends the relation modeling of vanilla Transformer to the continuous-time domain, which explicitly incorporates the modeling abilities of continuous dynamics of Neural ODEs with the attention mechanism of Transformers. We mathematically characterize the expressive power of ContiFormer and illustrate that, by curated designs of function hypothesis, many Transformer variants specialized in irregular time series modeling can be covered as a special case of ContiFormer. A wide range of experiments on both synthetic and real-world datasets have illustrated the superior modeling capacities and prediction performance of ContiFormer on irregular time series data. The project link is https://seqml.github.io/contiformer/",
    "checked": false,
    "id": "7c2a345df687cc54044d04a7e214e9d391dbadcb",
    "semantic_title": "self-supervised transformer for multivariate clinical time-series with missing values",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=mgNu8nDFwa": {
    "title": "Beyond Average Return in Markov Decision Processes",
    "volume": "poster",
    "abstract": "What are the functionals of the reward that can be computed and optimized exactly in Markov Decision Processes? In the finite-horizon, undiscounted setting, Dynamic Programming (DP) can only handle these operations efficiently for certain classes of statistics. We summarize the characterization of these classes for policy evaluation, and give a new answer for the planning problem. Interestingly, we prove that only generalized means can be optimized exactly, even in the more general framework of Distributional Reinforcement Learning (DistRL). DistRL permits, however, to evaluate other functionals approximately. We provide error bounds on the resulting estimators, and discuss the potential of this approach as well as its limitations. These results contribute to advancing the theory of Markov Decision Processes by examining overall characteristics of the return, and particularly risk-conscious strategies",
    "checked": true,
    "id": "fb879e7c74ef352a4e61a36174230551d0cde12e",
    "semantic_title": "beyond average return in markov decision processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e2aCgjtjMR": {
    "title": "Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors",
    "volume": "poster",
    "abstract": "As the use of machine learning models in real world high-stakes decision settings continues to grow, it is highly important that we are able to audit and control for any potential fairness violations these models may exhibit towards certain groups. To do so, one naturally requires access to sensitive attributes, such as demographics, biological sex, or other potentially sensitive features that determine group membership. Unfortunately, in many settings, this information is often unavailable. In this work we study the well known equalized odds (EOD) definition of fairness. In a setting without sensitive attributes, we first provide tight and computable upper bounds for the EOD violation of a predictor. These bounds precisely reflect the worst possible EOD violation. Second, we demonstrate how one can provably control the worst-case EOD by a new post-processing correction method. Our results characterize when directly controlling for EOD with respect to the predicted sensitive attributes is -- and when is not -- optimal when it comes to controlling worst-case EOD. Our results hold under assumptions that are milder than previous works, and we illustrate these results with experiments on synthetic and real datasets",
    "checked": true,
    "id": "fb30199d753b923d880746f998d19704afcc77d1",
    "semantic_title": "estimating and controlling for equalized odds via sensitive attribute predictors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZIfhYAE2xg": {
    "title": "Sparse Parameterization for Epitomic Dataset Distillation",
    "volume": "poster",
    "abstract": "The success of deep learning relies heavily on large and diverse datasets, but the storage, preprocessing, and training of such data present significant challenges. To address these challenges, dataset distillation techniques have been proposed to obtain smaller synthetic datasets that capture the essential information of the originals. In this paper, we introduce a Sparse Parameterization for Epitomic datasEt Distillation (SPEED) framework, which leverages the concept of dictionary learning and sparse coding to distill epitomes that represent pivotal information of the dataset. SPEED prioritizes proper parameterization of the synthetic dataset and introduces techniques to capture spatial redundancy within and between synthetic images. We propose Spatial-Agnostic Epitomic Tokens (SAETs) and Sparse Coding Matrices (SCMs) to efficiently represent and select significant features. Additionally, we build a Feature-Recurrent Network (FReeNet) to generate hierarchical features with high compression and storage efficiency. Experimental results demonstrate the superiority of SPEED in handling high-resolution datasets, achieving state-of-the-art performance on multiple benchmarks and downstream applications. Our framework is compatible with a variety of dataset matching approaches, generally enhancing their performance. This work highlights the importance of proper parameterization in epitomic dataset distillation and opens avenues for efficient representation learning. Source code is available at https://github.com/MIV-XJTU/SPEED",
    "checked": false,
    "id": "a30454327c13d7b93ad52a52e940294d356c6de6",
    "semantic_title": "representation disparity-aware distillation for 3d object detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pvgxecj5aS": {
    "title": "Understanding Few-Shot Learning: Measuring Task Relatedness and Adaptation Difficulty via Attributes",
    "volume": "poster",
    "abstract": "Few-shot learning (FSL) aims to learn novel tasks with very few labeled samples by leveraging experience from \\emph{related} training tasks. In this paper, we try to understand FSL by exploring two key questions: (1) How to quantify the relationship between \\emph{ training} and \\emph{novel} tasks? (2) How does the relationship affect the \\emph{adaptation difficulty} on novel tasks for different models? To answer the first question, we propose Task Attribute Distance (TAD) as a metric to quantify the task relatedness via attributes. Unlike other metrics, TAD is independent of models, making it applicable to different FSL models. To address the second question, we utilize TAD metric to establish a theoretical connection between task relatedness and task adaptation difficulty. By deriving the generalization error bound on a novel task, we discover how TAD measures the adaptation difficulty on novel tasks for different models. To validate our theoretical results, we conduct experiments on three benchmarks. Our experimental results confirm that TAD metric effectively quantifies the task relatedness and reflects the adaptation difficulty on novel tasks for various FSL methods, even if some of them do not learn attributes explicitly or human-annotated attributes are not provided. Our code is available at \\href{https://github.com/hu-my/TaskAttributeDistance}{https://github.com/hu-my/TaskAttributeDistance}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3n8PNUdvSg": {
    "title": "RECESS Vaccine for Federated Learning: Proactive Defense Against Model Poisoning Attacks",
    "volume": "poster",
    "abstract": "Model poisoning attacks greatly jeopardize the application of federated learning (FL). The effectiveness of existing defenses is susceptible to the latest model poisoning attacks, leading to a decrease in prediction accuracy. Besides, these defenses are intractable to distinguish benign outliers from malicious gradients, which further compromises the model generalization. In this work, we propose a novel defense including detection and aggregation, named RECESS, to serve as a \"vaccine\" for FL against model poisoning attacks. Different from the passive analysis in previous defenses, RECESS proactively queries each participating client with a delicately constructed aggregation gradient, accompanied by the detection of malicious clients according to their responses with higher accuracy. Further, RECESS adopts a newly proposed trust scoring based mechanism to robustly aggregate gradients. Rather than previous methods of scoring in each iteration, RECESS takes into account the correlation of clients' performance over multiple iterations to estimate the trust score, bringing in a significant increase in detection fault tolerance. Finally, we extensively evaluate RECESS on typical model architectures and four datasets under various settings including white/black-box, cross-silo/device FL, etc. Experimental results show the superiority of RECESS in terms of reducing accuracy loss caused by the latest model poisoning attacks over five classic and two state-of-the-art defenses",
    "checked": true,
    "id": "947573bcd83fe6985749e08e15402f37f5d69136",
    "semantic_title": "recess vaccine for federated learning: proactive defense against model poisoning attacks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CxzCoFDeQf": {
    "title": "SALSA VERDE: a machine learning attack on LWE with sparse small secrets",
    "volume": "poster",
    "abstract": "Learning with Errors (LWE) is a hard math problem used in post-quantum cryptography. Homomorphic Encryption (HE) schemes rely on the hardness of the LWE problem for their security, and two LWE-based cryptosystems were recently standardized by NIST for digital signatures and key exchange (KEM). Thus, it is critical to continue assessing the security of LWE and specific parameter choices. For example, HE uses secrets with small entries, and the HE community has considered standardizing small sparse secrets to improve efficiency and functionality. However, prior work, SALSA and PICANTE, showed that ML attacks can recover sparse binary secrets. Building on these, we propose VERDE, an improved ML attack that can recover sparse binary, ternary, and narrow Gaussian secrets. Using improved preprocessing and secret recovery techniques, VERDE can attack LWE with larger dimensions ($n=512$) and smaller moduli ($\\log_2 q=12$ for $n=256$), using less time and power. We propose novel architectures for scaling. Finally, we develop a theory that explains the success of ML LWE attacks",
    "checked": false,
    "id": "75a50217c31dbc0bcddcc5c2a1af690e4f61e8a9",
    "semantic_title": "salsa verde: a machine learning attack on learning with errors with sparse small secrets",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=wwmKVO8bsR": {
    "title": "Federated Learning with Bilateral Curation for Partially Class-Disjoint Data",
    "volume": "poster",
    "abstract": "Partially class-disjoint data (PCDD), a common yet under-explored data formation where each client contributes a part of classes (instead of all classes) of samples, severely challenges the performance of federated algorithms. Without full classes, the local objective will contradict the global objective, yielding the angle collapse problem for locally missing classes and the space waste problem for locally existing classes. As far as we know, none of the existing methods can intrinsically mitigate PCDD challenges to achieve holistic improvement in the bilateral views (both global view and local view) of federated learning. To address this dilemma, we are inspired by the strong generalization of simplex Equiangular Tight Frame (ETF) on the imbalanced data, and propose a novel approach called FedGELA where the classifier is globally fixed as a simplex ETF while locally adapted to the personal distributions. Globally, FedGELA provides fair and equal discrimination for all classes and avoids inaccurate updates of the classifier, while locally it utilizes the space of locally missing classes for locally existing classes. We conduct extensive experiments on a range of datasets to demonstrate that our FedGELA achieves promising performance (averaged improvement of 3.9% to FedAvg and 1.5% to best baselines) and provide both local and global convergence guarantees",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iVYInarGXg": {
    "title": "On the Identifiability and Interpretability of Gaussian Process Models",
    "volume": "poster",
    "abstract": "In this paper, we critically examine the prevalent practice of using additive mixtures of Mat\\'ern kernels in single-output Gaussian process (GP) models and explore the properties of multiplicative mixtures of Mat\\'ern kernels for multi-output GP models. For the single-output case, we derive a series of theoretical results showing that the smoothness of a mixture of Mat\\'ern kernels is determined by the least smooth component and that a GP with such a kernel is effectively equivalent to the least smooth kernel component. Furthermore, we demonstrate that none of the mixing weights or parameters within individual kernel components are identifiable. We then turn our attention to multi-output GP models and analyze the identifiability of the covariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where $K_0$ is a standard single output kernel such as Mat\\'ern. We show that $A$ is identifiable up to a multiplicative constant, suggesting that multiplicative mixtures are well suited for multi-output tasks. Our findings are supported by extensive simulations and real applications for both single- and multi-output settings. This work provides insight into kernel selection and interpretation for GP models, emphasizing the importance of choosing appropriate kernel structures for different tasks",
    "checked": true,
    "id": "c5a797c3dc6184ed3c35a869efecad064a19188e",
    "semantic_title": "on the identifiability and interpretability of gaussian process models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U4WTG06Yu3": {
    "title": "Towards Efficient and Accurate Winograd Convolution via Full Quantization",
    "volume": "poster",
    "abstract": "The Winograd algorithm is an efficient convolution implementation, which performs calculations in the transformed domain. To further improve the computation efficiency, recent works propose to combine it with model quantization. Although Post-Training Quantization has the advantage of low computational cost and has been successfully applied in many other scenarios, a severe accuracy drop exists when utilizing it in Winograd convolution. Besides, despite the Winograd algorithm consisting of four stages, most existing methods only quantize the element-wise multiplication stage, leaving a considerable portion of calculations in full precision. In this paper, observing the inconsistency among different transformation procedures, we present PTQ-Aware Winograd (PAW) to optimize them collaboratively under a unified objective function. Moreover, we explore the full quantization of faster Winograd (tile size $\\geq4$) for the first time. We further propose a hardware-friendly method called Factorized Scale Quantization (FSQ), which can effectively balance the significant range differences in the Winograd domain. Experiments demonstrate the effectiveness of our method, e.g., with 8-bit quantization and a tile size of 6, our method outperforms the previous Winograd PTQ method by 8.27\\% and 5.38\\% in terms of the top-1 accuracy on ResNet-18 and ResNet-34, respectively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8SUtvEZCF2": {
    "title": "Semantic segmentation of sparse irregular point clouds for leaf/wood discrimination",
    "volume": "poster",
    "abstract": "Lidar (Light Detection and Ranging) has become an essential part of the remote sensing toolbox used for biosphere monitoring. In particular, Lidar provides the opportunity to map forest leaf area with unprecedented accuracy, while leaf area has remained an important source of uncertainty affecting models of gas exchanges between the vegetation and the atmosphere. Unmanned Aerial Vehicles (UAV) are easy to mobilize and therefore allow frequent revisits to track the response of vegetation to climate change. However, miniature sensors embarked on UAVs usually provide point clouds of limited density, which are further affected by a strong decrease in density from top to bottom of the canopy due to progressively stronger occlusion. In such a context, discriminating leaf points from wood points presents a significant challenge due in particular to strong class imbalance and spatially irregular sampling intensity. Here we introduce a neural network model based on the Pointnet ++ architecture which makes use of point geometry only (excluding any spectral information). To cope with local data sparsity, we propose an innovative sampling scheme which strives to preserve local important geometric information. We also propose a loss function adapted to the severe class imbalance. We show that our model outperforms state-of-the-art alternatives on UAV point clouds. We discuss future possible improvements, particularly regarding much denser point clouds acquired from below the canopy",
    "checked": true,
    "id": "65a896606b8f318eea0a466cbb74d0d2b871047b",
    "semantic_title": "semantic segmentation of sparse irregular point clouds for leaf/wood discrimination",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9AcG3Tsyoq": {
    "title": "AmadeusGPT: a natural language interface for interactive animal behavioral analysis",
    "volume": "poster",
    "abstract": "The process of quantifying and analyzing animal behavior involves translating the naturally occurring descriptive language of their actions into machine-readable code. Yet, codifying behavior analysis is often challenging without deep understanding of animal behavior and technical machine learning knowledge. To limit this gap, we introduce AmadeusGPT: a natural language interface that turns natural language descriptions of behaviors into machine-executable code. Large-language models (LLMs) such as GPT3.5 and GPT4 allow for interactive language-based queries that are potentially well suited for making interactive behavior analysis. However, the comprehension capability of these LLMs is limited by the context window size, which prevents it from remembering distant conversations. To overcome the context window limitation, we implement a novel dual-memory mechanism to allow communication between short-term and long-term memory using symbols as context pointers for retrieval and saving. Concretely, users directly use language-based definitions of behavior and our augmented GPT develops code based on the core AmadeusGPT API, which contains machine learning, computer vision, spatio-temporal reasoning, and visualization modules. Users then can interactively refine results, and seamlessly add new behavioral modules as needed. We used the MABe 2022 behavior challenge tasks to benchmark AmadeusGPT and show excellent performance. Note, an end-user would not need to write any code to achieve this. Thus, collectively AmadeusGPT presents a novel way to merge deep biological knowledge, large-language models, and core computer vision modules into a more naturally intelligent system. Code and demos can be found at: https://github.com/AdaptiveMotorControlLab/AmadeusGPT",
    "checked": true,
    "id": "ec592e12f45e20819afe203164bbbd0de8990510",
    "semantic_title": "amadeusgpt: a natural language interface for interactive animal behavioral analysis",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=BA7NHAzbpO": {
    "title": "Sampling from Structured Log-Concave Distributions via a Soft-Threshold Dikin Walk",
    "volume": "poster",
    "abstract": "Given a Lipschitz or smooth convex function $f:K \\to \\mathbb{R}^d$ for a bounded polytope $K:=${ $\\theta \\in \\mathbb{R}^d: A\\theta \\leq b$}, where $A\\in \\mathbb{R}^{m\\times d}$ and $b \\in \\mathbb{R}^m$, we consider the problem of sampling from the log-concave distribution $\\pi(\\theta) \\propto e^{-f(\\theta)}$ constrained to $K$. Interest in this problem derives from its applications to Bayesian inference and differential privacy. We present a generalization of the Dikin walk to this setting that requires at most $O((md + d L^2 R^2) \\times md^{\\omega-1} \\log(\\frac{w}{\\delta}))$ arithmetic operations to sample from $\\pi$ within error $\\delta>0$ in the total variation distance from a $w$-warm start. Here $L$ is the Lipschitz constant of $f$, $K$ is contained in a ball of radius $R$ and contains a ball of smaller radius $r$, and $\\omega \\approx 2.37$ is the matrix-multiplication constant. This improves on the running time of prior works for a range of structured settings important for the aforementioned inference and privacy applications. Technically, we depart from previous Dikin walks by adding a soft-threshold regularizer derived from the Lipschitz or smoothness properties of $f$ to a barrier function for $K$ that allows our version of the Dikin walk to propose updates that have a high Metropolis acceptance ratio for $f$, while at the same time remaining inside the polytope $K$",
    "checked": false,
    "id": "3d8f8bd7ea0440ded36ecb73a925b62ff18049d1",
    "semantic_title": "sampling from log-concave distributions over polytopes via a soft-threshold dikin walk",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VkhvDfY2dB": {
    "title": "Efficient Exploration in Continuous-time Model-based Reinforcement Learning",
    "volume": "poster",
    "abstract": "Reinforcement learning algorithms typically consider discrete-time dynamics, even though the underlying systems are often continuous in time. In this paper, we introduce a model-based reinforcement learning algorithm that represents continuous-time dynamics using nonlinear ordinary differential equations (ODEs). We capture epistemic uncertainty using well-calibrated probabilistic models, and use the optimistic principle for exploration. Our regret bounds surface the importance of the measurement selection strategy (MSS), since in continuous time we not only must decide how to explore, but also when to observe the underlying system. Our analysis demonstrates that the regret is sublinear when modeling ODEs with Gaussian Processes (GP) for common choices of MSS, such as equidistant sampling. Additionally, we propose an adaptive, data-dependent, practical MSS that, when combined with GP dynamics, also achieves sublinear regret with significantly fewer samples. We showcase the benefits of continuous-time modeling over its discrete-time counterpart, as well as our proposed adaptive MSS over standard baselines, on several applications",
    "checked": true,
    "id": "8356fd79b3dbbf35c8dfabc014a510f8d45fb21f",
    "semantic_title": "efficient exploration in continuous-time model-based reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tC0r8duG9z": {
    "title": "On the Power of SVD in the Stochastic Block Model",
    "volume": "poster",
    "abstract": "A popular heuristic method for improving clustering results is to apply dimensionality reduction before running clustering algorithms. It has been observed that spectral-based dimensionality reduction tools, such as PCA or SVD, improve the performance of clustering algorithms in many applications. This phenomenon indicates that spectral method not only serves as a dimensionality reduction tool, but also contributes to the clustering procedure in some sense. It is an interesting question to understand the behavior of spectral steps in clustering problems. As an initial step in this direction, this paper studies the power of vanilla-SVD algorithm in the stochastic block model (SBM). We show that, in the symmetric setting, vanilla-SVD algorithm recovers all clusters correctly. This result answers an open question posed by Van Vu (Combinatorics Probability and Computing, 2018) in the symmetric setting",
    "checked": true,
    "id": "e71ddcfb8661a03c86a0b0107d55518eb5f427e9",
    "semantic_title": "on the power of svd in the stochastic block model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LUT4b9gOtS": {
    "title": "Learning Visual Prior via Generative Pre-Training",
    "volume": "poster",
    "abstract": "Various stuff and things in visual data possess specific traits, which can be learned by deep neural networks and are implicitly represented as the visual prior, e.g., object location and shape, in the model. Such prior potentially impacts many vision tasks. For example, in conditional image synthesis, spatial conditions failing to adhere to the prior can result in visually inaccurate synthetic results. This work aims to explicitly learn the visual prior and enable the customization of sampling. Inspired by advances in language modeling, we propose to learn Visual prior via Generative Pre-Training, dubbed VisorGPT. By discretizing visual locations, e.g., bounding boxes, human pose, and instance masks, into sequences, VisorGPT can model visual prior through likelihood maximization. Besides, prompt engineering is investigated to unify various visual locations and enable customized sampling of sequential outputs from the learned prior. Experimental results demonstrate the effectiveness of VisorGPT in modeling visual prior and extrapolating to novel scenes, potentially motivating that discrete visual locations can be integrated into the learning paradigm of current language models to further perceive visual world. Code is available at https://sierkinhane.github.io/visor-gpt",
    "checked": false,
    "id": "0a61802b71aa044cf1fe0e81befec148e0d5001b",
    "semantic_title": "visorgpt: learning visual prior via generative pre-training",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hVAla2O73O": {
    "title": "A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints",
    "volume": "poster",
    "abstract": "Neuro-symbolic AI bridges the gap between purely symbolic and neural approaches to learning. This often requires maximizing the likelihood of a symbolic constraint w.r.t the neural network's output distribution. Such output distributions are typically assumed to be fully-factorized. This limits the applicability of neuro-symbolic learning to the more expressive auto-regressive distributions, e.g., transformers. Under such distributions, computing the likelihood of even simple constraints is #P-hard. Instead of attempting to enforce the constraint on the entire likelihood distribution, we propose to do so on a random, local approximation thereof. More precisely, we approximate the likelihood of the constraint with the pseudolikelihood of the constraint centered around a model sample. Our approach is factorizable, allowing us to reuse solutions to sub-problems---a main tenet for the efficient computation of neuro-symbolic losses. It also provides a local, high fidelity approximation of the likelihood: it exhibits low entropy and KL-divergence around the model sample. We tested our approach on Sudoku and shortest-path prediction cast as auto-regressive generation, and observe that we greatly improve upon the base model's ability to predict logically-consistent outputs. We also tested our approach on the task of detoxifying large language models. We observe that using a simple constraint disallowing a list of toxic words, we are able to steer the model's outputs away from toxic generations, achieving SoTA compared to previous approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kS7ED7eE74": {
    "title": "A Fractional Graph Laplacian Approach to Oversmoothing",
    "volume": "poster",
    "abstract": "Graph neural networks (GNNs) have shown state-of-the-art performances in various applications. However, GNNs often struggle to capture long-range dependencies in graphs due to oversmoothing. In this paper, we generalize the concept of oversmoothing from undirected to directed graphs. To this aim, we extend the notion of Dirichlet energy by considering a directed symmetrically normalized Laplacian. As vanilla graph convolutional networks are prone to oversmooth, we adopt a neural graph ODE framework. Specifically, we propose fractional graph Laplacian neural ODEs, which describe non-local dynamics. We prove that our approach allows propagating information between distant nodes while maintaining a low probability of long-distance jumps. Moreover, we show that our method is more flexible with respect to the convergence of the graph's Dirichlet energy, thereby mitigating oversmoothing. We conduct extensive experiments on synthetic and real-world graphs, both directed and undirected, demonstrating our method's versatility across diverse graph homophily levels. Our code is available at https://github.com/RPaolino/fLode",
    "checked": true,
    "id": "2f2d4ce7ca8ed125e3ee5ecd97bd638eabadd2e1",
    "semantic_title": "a fractional graph laplacian approach to oversmoothing",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=XF923QPCGw": {
    "title": "Learning Regularized Monotone Graphon Mean-Field Games",
    "volume": "poster",
    "abstract": "This paper studies two fundamental problems in regularized Graphon Mean-Field Games (GMFGs). First, we establish the existence of a Nash Equilibrium (NE) of any $\\lambda$-regularized GMFG (for $\\lambda\\geq 0$). This result relies on weaker conditions than previous works analyzing both unregularized GMFGs ($\\lambda=0$) and $\\lambda$-regularized MFGs, which are special cases of GMFGs. Second, we propose provably efficient algorithms to learn the NE in weakly monotone GMFGs, motivated by Lasry and Lions (2007). Previous literature either only analyzed continuous-time algorithms or required extra conditions to analyze discrete-time algorithms. In contrast, we design a discrete-time algorithm and derive its convergence rate solely under weakly monotone conditions. Furthermore, we develop and analyze the action-value function estimation procedure during the online learning process, which is absent from algorithms for monotone GMFGs. This serves as a sub-module in our optimization algorithm. The efficiency of the designed algorithm is corroborated by empirical evaluations",
    "checked": true,
    "id": "7d5c1808cef30e747b35bb1a3e4628c66da6100b",
    "semantic_title": "learning regularized monotone graphon mean-field games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gevmGxsTSI": {
    "title": "Learning From Biased Soft Labels",
    "volume": "poster",
    "abstract": "Since the advent of knowledge distillation, many researchers have been intrigued by the $\\textit{dark knowledge}$ hidden in the soft labels generated by the teacher model. This prompts us to scrutinize the circumstances under which these soft labels are effective. Predominant existing theories implicitly require that the soft labels are close to the ground-truth labels. In this paper, however, we investigate whether biased soft labels are still effective. Here, bias refers to the discrepancy between the soft labels and the ground-truth labels. We present two indicators to measure the effectiveness of the soft labels. Based on the two indicators, we propose moderate conditions to ensure that, the biased soft label learning problem is both $\\textit{classifier-consistent}$ and $\\textit{Empirical Risk Minimization}$ (ERM) $\\textit{learnable}$, which can be applicable even for large-biased soft labels. We further design a heuristic method to train Skillful but Bad Teachers (SBTs), and these teachers with accuracy less than 30\\% can teach students to achieve accuracy over 90\\% on CIFAR-10, which is comparable to models trained on the original data. The proposed indicators adequately measure the effectiveness of the soft labels generated in this process. Moreover, our theoretical framework can be adapted to elucidate the effectiveness of soft labels in three weakly-supervised learning paradigms, namely incomplete supervision, partial label learning and learning with additive noise. Experimental results demonstrate that our indicators can measure the effectiveness of biased soft labels generated by teachers or in these weakly-supervised learning paradigms",
    "checked": true,
    "id": "ff253cd29f4996f5e4be6cfa3fa7f2855b7041ae",
    "semantic_title": "learning from biased soft labels",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=EqpR9Vtt13": {
    "title": "Does Invariant Graph Learning via Environment Augmentation Learn Invariance?",
    "volume": "poster",
    "abstract": "Invariant graph representation learning aims to learn the invariance among data from different environments for out-of-distribution generalization on graphs. As the graph environment partitions are usually expensive to obtain, augmenting the environment information has become the de facto approach. However, the usefulness of the augmented environment information has never been verified. In this work, we find that it is fundamentally impossible to learn invariant graph representations via environment augmentation without additional assumptions. Therefore, we develop a set of minimal assumptions, including variation sufficiency and variation consistency, for feasible invariant graph learning. We then propose a new framework Graph invAriant Learning Assistant (GALA). GALA incorporates an assistant model that needs to be sensitive to graph environment changes or distribution shifts. The correctness of the proxy predictions by the assistant model hence can differentiate the variations in spurious subgraphs. We show that extracting the maximally invariant subgraph to the proxy predictions provably identifies the underlying invariant subgraph for successful OOD generalization under the established minimal assumptions. Extensive experiments on datasets including DrugOOD with various graph distribution shifts confirm the effectiveness of GALA",
    "checked": true,
    "id": "3c637c287a97ebf8810634a47e1ac03846bc2f7a",
    "semantic_title": "does invariant graph learning via environment augmentation learn invariance?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=h3lTrt4Ftb": {
    "title": "Large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language",
    "volume": "poster",
    "abstract": "Predicting upcoming events is critical to our ability to effectively interact with our environment and conspecifics. In natural language processing, transformer models, which are trained on next-word prediction, appear to construct a general-purpose representation of language that can support diverse downstream tasks. However, we still lack an understanding of how a predictive objective shapes such representations. Inspired by recent work in vision neuroscience Hénaff et al. (2019), here we test a hypothesis about predictive representations of autoregressive transformer models. In particular, we test whether the neural trajectory of a sequence of words in a sentence becomes progressively more straight as it passes through the layers of the network. The key insight behind this hypothesis is that straighter trajectories should facilitate prediction via linear extrapolation. We quantify straightness using a 1- dimensional curvature metric, and present four findings in support of the trajectory straightening hypothesis: i) In trained models, the curvature progressively decreases from the first to the middle layers of the network. ii) Models that perform better on the next-word prediction objective, including larger models and models trained on larger datasets, exhibit greater decreases in curvature, suggesting that this improved ability to straighten sentence neural trajectories may be the underlying driver of better language modeling performance. iii) Given the same linguistic context, the sequences that are generated by the model have lower curvature than the ground truth (the actual continuations observed in a language corpus), suggesting that the model favors straighter trajectories for making predictions. iv) A consistent relationship holds between the average curvature and the average surprisal of sentences in the middle layers of models, such that sentences with straighter neural trajectories also have lower surprisal. Importantly, untrained models don't exhibit these behaviors. In tandem, these results support the trajectory straightening hypothesis and provide a possible mechanism for how the geometry of the internal representations of autoregressive models supports next word prediction",
    "checked": true,
    "id": "04d0b1977e01ab69c03c8c7c5a6673e621eb5c52",
    "semantic_title": "large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gmVoaAxB1R": {
    "title": "Structure of universal formulas",
    "volume": "poster",
    "abstract": "By universal formulas we understand parameterized analytic expressions that have a fixed complexity, but nevertheless can approximate any continuous function on a compact set. There exist various examples of such formulas, including some in the form of neural networks. In this paper we analyze the essential structural elements of these highly expressive models. We introduce a hierarchy of expressiveness classes connecting the global approximability property to the weaker property of infinite VC dimension, and prove a series of classification results for several increasingly complex functional families. In particular, we introduce a general family of polynomially-exponentially-algebraic functions that, as we prove, is subject to polynomial constraints. As a consequence, we show that fixed-size neural networks with not more than one layer of neurons having transcendental activations (e.g., sine or standard sigmoid) cannot in general approximate functions on arbitrary finite sets. On the other hand, we give examples of functional families, including two-hidden-layer neural networks, that approximate functions on arbitrary finite sets, but fail to do that on the whole domain of definition",
    "checked": true,
    "id": "991d5d254678b59beca705d904ef23c704304b8a",
    "semantic_title": "structure of universal formulas",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XGXL1E8Yyo": {
    "title": "DreamWaltz: Make a Scene with Complex 3D Animatable Avatars",
    "volume": "poster",
    "abstract": "We present DreamWaltz, a novel framework for generating and animating complex 3D avatars given text guidance and parametric human body prior. While recent methods have shown encouraging results for text-to-3D generation of common objects, creating high-quality and animatable 3D avatars remains challenging. To create high-quality 3D avatars, DreamWaltz proposes 3D-consistent occlusion-aware Score Distillation Sampling (SDS) to optimize implicit neural representations with canonical poses. It provides view-aligned supervision via 3D-aware skeleton conditioning which enables complex avatar generation without artifacts and multiple faces. For animation, our method learns an animatable 3D avatar representation from abundant image priors of diffusion model conditioned on various poses, which could animate complex non-rigged avatars given arbitrary poses without retraining. Extensive evaluations demonstrate that DreamWaltz is an effective and robust approach for creating 3D avatars that can take on complex shapes and appearances as well as novel poses for animation. The proposed framework further enables the creation of complex scenes with diverse compositions, including avatar-avatar, avatar-object and avatar-scene interactions. See https://dreamwaltz3d.github.io/ for more vivid 3D avatar and animation results",
    "checked": true,
    "id": "7316596b1f02f288e3b76546d90646524e35fd40",
    "semantic_title": "dreamwaltz: make a scene with complex 3d animatable avatars",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=U6fp6IUBdr": {
    "title": "Understanding Neural Network Binarization with Forward and Backward Proximal Quantizers",
    "volume": "poster",
    "abstract": "In neural network binarization, BinaryConnect (BC) and its variants are considered the standard. These methods apply the sign function in their forward pass and their respective gradients are backpropagated to update the weights. However, the derivative of the sign function is zero whenever defined, which consequently freezes training. Therefore, implementations of BC (e.g., BNN) usually replace the derivative of sign in the backward computation with identity or other approximate gradient alternatives. Although such practice works well empirically, it is largely a heuristic or ``training trick.'' We aim at shedding some light on these training tricks from the optimization perspective. Building from existing theory on ProxConnect (PC, a generalization of BC), we (1) equip PC with different forward-backward quantizers and obtain ProxConnect++ (PC++) that includes existing binarization techniques as special cases; (2) derive a principled way to synthesize forward-backward quantizers with automatic theoretical guarantees; (3) illustrate our theory by proposing an enhanced binarization algorithm BNN++; (4) conduct image classification experiments on CNNs and vision transformers, and empirically verify that BNN++ generally achieves competitive results on binarizing these models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=27CRbwewyb": {
    "title": "Noether Embedding: Efficient Learning of Temporal Regularities",
    "volume": "poster",
    "abstract": "Learning to detect and encode temporal regularities (TRs) in events is a prerequisite for human-like intelligence. These regularities should be formed from limited event samples and stored as easily retrievable representations. Existing event embeddings, however, cannot effectively decode TR validity with well-trained vectors, let alone satisfy the efficiency requirements. We develop Noether Embedding (NE) as the first efficient TR learner with event embeddings. Specifically, NE possesses the intrinsic time-translation symmetries of TRs indicated as conserved local energies in the embedding space. This structural bias reduces the calculation of each TR validity to embedding each event sample, enabling NE to achieve data-efficient TR formation insensitive to sample size and time-efficient TR retrieval in constant time complexity. To comprehensively evaluate the TR learning capability of embedding models, we define complementary tasks of TR detection and TR query, formulate their evaluation metrics, and assess embeddings on classic ICEWS14, ICEWS18, and GDELT datasets. Our experiments demonstrate that NE consistently achieves about double the F1 scores for detecting valid TRs compared to classic embeddings, and it provides over ten times higher confidence scores for querying TR intervals. Additionally, we showcase NE's potential applications in social event prediction, personal decision-making, and memory-constrained scenarios",
    "checked": false,
    "id": "01ee1aca8a01e6cb0e4cd69bae9bff70e89ecaf6",
    "semantic_title": "nodesense2vec: spatiotemporal context-aware network embedding for heterogeneous urban mobility data",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ztDxO15N7f": {
    "title": "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
    "volume": "poster",
    "abstract": "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel \"role-infused partition benchmark\", a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way",
    "checked": true,
    "id": "a3ffa9d19ba88d1734d1caccf4f71a94727f4d56",
    "semantic_title": "an optimization-based approach to node role discovery in networks: approximating equitable partitions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eozEoAtjG8": {
    "title": "Understanding and Improving Feature Learning for Out-of-Distribution Generalization",
    "volume": "poster",
    "abstract": "A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. Despite the contradictions at first glance, we theoretically show that ERM essentially learns both spurious and invariant features, while ERM tends to learn spurious features faster if the spurious correlation is stronger. Moreover, when fed the ERM learned features to the OOD objectives, the invariant feature learning quality significantly affects the final OOD performance, as OOD objectives rarely learn new features. Therefore, ERM feature learning can be a bottleneck to OOD generalization. To alleviate the reliance, we propose Feature Augmented Training (FeAT), to enforce the model to learn richer features ready for OOD generalization. FeAT iteratively augments the model to learn new features while retaining the already learned features. In each round, the retention and augmentation operations are performed on different subsets of the training data that capture distinct features. Extensive experiments show that FeAT effectively learns richer features thus boosting the performance of various OOD objectives",
    "checked": true,
    "id": "e8e60bdc6004bb7506708e4a1260779f06de369e",
    "semantic_title": "understanding and improving feature learning for out-of-distribution generalization",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=xQOHOpe1Fv": {
    "title": "The Tunnel Effect: Building Data Representations in Deep Neural Networks",
    "volume": "poster",
    "abstract": "Deep neural networks are widely known for their remarkable effectiveness across various tasks, with the consensus that deeper networks implicitly learn more complex data representations. This paper shows that sufficiently deep networks trained for supervised image classification split into two distinct parts that contribute to the resulting data representations differently. The initial layers create linearly-separable representations, while the subsequent layers, which we refer to as \\textit{the tunnel}, compress these representations and have a minimal impact on the overall performance. We explore the tunnel's behavior through comprehensive empirical studies, highlighting that it emerges early in the training process. Its depth depends on the relation between the network's capacity and task complexity. Furthermore, we show that the tunnel degrades out-of-distribution generalization and discuss its implications for continual learning",
    "checked": true,
    "id": "f574f4e4f94c0268014d8c10dd85d5df34a46561",
    "semantic_title": "the tunnel effect: building data representations in deep neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SCsJFNcSHQ": {
    "title": "Structure Learning with Adaptive Random Neighborhood Informed MCMC",
    "volume": "poster",
    "abstract": "In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a fully-Bayesian approach to the problem of structure learning under observational data. Under the assumption of causal sufficiency, the algorithm allows for approximate sampling directly from the posterior distribution on Directed Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs via locally informed, adaptive random neighborhood proposal that results in better mixing properties. In addition, to ensure better scalability with the number of nodes, we couple PARNI-DAG with a pre-tuning procedure of the sampler's parameters that exploits a skeleton graph derived through some constraint-based or scoring-based algorithms. Thanks to these novel features, PARNI-DAG quickly converges to high-probability regions and is less likely to get stuck in local modes in the presence of high correlation between nodes in high-dimensional settings. After introducing the technical novelties in PARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in learning DAG structures on a variety of experiments",
    "checked": true,
    "id": "a321ff82aba369548ad6a4b9c4fd08b3b4c26e0b",
    "semantic_title": "structure learning with adaptive random neighborhood informed mcmc",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QUkYZNhfc6": {
    "title": "FaceDNeRF: Semantics-Driven Face Reconstruction, Prompt Editing and Relighting with Diffusion Models",
    "volume": "poster",
    "abstract": "The ability to create high-quality 3D faces from a single image has become increasingly important with wide applications in video conferencing, AR/VR, and advanced video editing in movie industries. In this paper, we propose Face Diffusion NeRF (FaceDNeRF), a new generative method to reconstruct high-quality Face NeRFs from single images, complete with semantic editing and relighting capabilities. FaceDNeRF utilizes high-resolution 3D GAN inversion and expertly trained 2D latent-diffusion model, allowing users to manipulate and construct Face NeRFs in zero-shot learning without the need for explicit 3D data. With carefully designed illumination and identity preserving loss, as well as multi-modal pre-training, FaceDNeRF offers users unparalleled control over the editing process enabling them to create and edit face NeRFs using just single-view images, text prompts, and explicit target lighting. The advanced features of FaceDNeRF have been designed to produce more impressive results than existing 2D editing approaches that rely on 2D segmentation maps for editable attributes. Experiments show that our FaceDNeRF achieves exceptionally realistic results and unprecedented flexibility in editing compared with state-of-the-art 3D face reconstruction and editing methods. Our code will be available at https://github.com/BillyXYB/FaceDNeRF",
    "checked": false,
    "id": "6613a8eb62126426401e49ec0b6d4fceb7a9a15f",
    "semantic_title": "fdnerf: semantics-driven face reconstruction, prompt editing and relighting with diffusion models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vnTUuecp2v": {
    "title": "Higher-Order Uncoupled Dynamics Do Not Lead to Nash Equilibrium - Except When They Do",
    "volume": "poster",
    "abstract": "The framework of multi-agent learning explores the dynamics of how an agent's strategies evolve in response to the evolving strategies of other agents. Of particular interest is whether or not agent strategies converge to well known solution concepts such as Nash Equilibrium (NE). In \"higher order'' learning, agent dynamics include auxiliary states that can capture phenomena such as path dependencies. We introduce higher-order gradient play dynamics that resemble projected gradient ascent with auxiliary states. The dynamics are \"payoff based'' and \"uncoupled'' in that each agent's dynamics depend on its own evolving payoff and has no explicit dependence on the utilities of other agents. We first show that for any specific game with an isolated completely mixed-strategy NE, there exist higher-order gradient play dynamics that lead (locally) to that NE, both for the specific game and nearby games with perturbed utility functions. Conversely, we show that for any higher-order gradient play dynamics, there exists a game with a unique isolated completely mixed-strategy NE for which the dynamics do not lead to NE. Finally, we show that convergence to the mixed-strategy equilibrium in coordination games, comes at the expense of the dynamics being inherently internally unstable",
    "checked": true,
    "id": "9215c3a3cc22e79c2351e262431159571a6e0e83",
    "semantic_title": "higher-order uncoupled dynamics do not lead to nash equilibrium - except when they do",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UZlAjSnmvB": {
    "title": "Model-enhanced Vector Index",
    "volume": "poster",
    "abstract": "Embedding-based retrieval methods construct vector indices to search for document representations that are most similar to the query representations. They are widely used in document retrieval due to low latency and decent recall performance. Recent research indicates that deep retrieval solutions offer better model quality, but are hindered by unacceptable serving latency and the inability to support document updates. In this paper, we aim to enhance the vector index with end-to-end deep generative models, leveraging the differentiable advantages of deep retrieval models while maintaining desirable serving efficiency. We propose Model-enhanced Vector Index (MEVI), a differentiable model-enhanced index empowered by a twin-tower representation model. MEVI leverages a Residual Quantization (RQ) codebook to bridge the sequence-to-sequence deep retrieval and embedding-based models. To substantially reduce the inference time, instead of decoding the unique document ids in long sequential steps, we first generate some semantic virtual cluster ids of candidate documents in a small number of steps, and then leverage the well-adapted embedding vectors to further perform a fine-grained search for the relevant documents in the candidate virtual clusters. We empirically show that our model achieves better performance on the commonly used academic benchmarks MSMARCO Passage and Natural Questions, with comparable serving latency to dense retrieval solutions",
    "checked": true,
    "id": "21f0efaa9df627e180571f457386c87be7dcd299",
    "semantic_title": "model-enhanced vector index",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yT0f93CeTw": {
    "title": "Fast Conditional Mixing of MCMC Algorithms for Non-log-concave Distributions",
    "volume": "poster",
    "abstract": "MCMC algorithms offer empirically efficient tools for sampling from a target distribution $\\pi(x) \\propto \\exp(-V(x))$. However, on the theory side, MCMC algorithms suffer from slow mixing rate when $\\pi(x)$ is non-log-concave. Our work examines this gap and shows that when Poincar\\'e-style inequality holds on a subset $\\mathcal{X}$ of the state space, the conditional distribution of MCMC iterates over $\\mathcal{X}$ mixes fast to the true conditional distribution. This fast mixing guarantee can hold in cases when global mixing is provably slow. We formalize the statement and quantify the conditional mixing rate. We further show that conditional mixing can have interesting implications for sampling from mixtures of Gaussians, parameter estimation for Gaussian mixture models, and Gibbs-sampling with well-connected local minima",
    "checked": true,
    "id": "baccde19ffdea057508c675b12abbf29178b826e",
    "semantic_title": "fast conditional mixing of mcmc algorithms for non-log-concave distributions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=exPzwOhBgx": {
    "title": "Learning Dictionary for Visual Attention",
    "volume": "poster",
    "abstract": "Recently, the attention mechanism has shown outstanding competence in capturing global structure information and long-range relationships within data, thus enhancing the performance of deep vision models on various computer vision tasks. In this work, we propose a novel dictionary learning-based attention (\\textit{Dic-Attn}) module, which models this issue as a decomposition and reconstruction problem with the sparsity prior, inspired by sparse coding in the human visual perception system. The proposed \\textit{Dic-Attn} module decomposes the input into a dictionary and corresponding sparse representations, allowing for the disentanglement of underlying nonlinear structural information in visual data and the reconstruction of an attention embedding. By applying transformation operations in the spatial and channel domains, the module dynamically selects the dictionary's atoms and sparse representations. Finally, the updated dictionary and sparse representations capture the global contextual information and reconstruct the attention maps. The proposed \\textit{Dic-Attn} module is designed with plug-and-play compatibility, allowing for integration into deep attention encoders. Our approach offers an intuitive and elegant means to exploit the discriminative information from data, promoting visual attention construction. Extensive experimental results on various computer vision tasks, e.g., image and point cloud classification, validate that our method achieves promising performance, and shows a strong competitive comparison with state-of-the-art attention methods",
    "checked": false,
    "id": "e1242b25091c2ec5dea3f248882b46c5090d57d3",
    "semantic_title": "learning to recognize actions on objects in egocentric video with attention dictionaries",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=tLrkjK128n": {
    "title": "Optimistic Active Exploration of Dynamical Systems",
    "volume": "poster",
    "abstract": "Reinforcement learning algorithms commonly seek to optimize policies for solving one particular task. How should we explore an unknown dynamical system such that the estimated model allows us to solve multiple downstream tasks in a zero-shot manner? In this paper, we address this challenge, by developing an algorithm -- OPAX -- for active exploration. OPAX uses well-calibrated probabilistic models to quantify the epistemic uncertainty about the unknown dynamics. It optimistically---w.r.t. to plausible dynamics---maximizes the information gain between the unknown dynamics and state observations. We show how the resulting optimization problem can be reduced to an optimal control problem that can be solved at each episode using standard approaches. We analyze our algorithm for general models, and, in the case of Gaussian process dynamics, we give a sample complexity bound and show that the epistemic uncertainty converges to zero. In our experiments, we compare OPAX with other heuristic active exploration approaches on several environments. Our experiments show that OPAX is not only theoretically sound but also performs well for zero-shot planning on novel downstream tasks",
    "checked": true,
    "id": "e66d55565f6cd6336f92be01b4efc7e6a1eb2381",
    "semantic_title": "optimistic active exploration of dynamical systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nFEQNYsjQO": {
    "title": "Label Correction of Crowdsourced Noisy Annotations with an Instance-Dependent Noise Transition Model",
    "volume": "poster",
    "abstract": "The predictive ability of supervised learning algorithms hinges on the quality of annotated examples, whose labels often come from multiple crowdsourced annotators with diverse expertise. To aggregate noisy crowdsourced annotations, many existing methods employ an annotator-specific instance-independent noise transition matrix to characterize the labeling skills of each annotator. Learning an instance-dependent noise transition model, however, is challenging and remains relatively less explored. To address this problem, in this paper, we formulate the noise transition model in a Bayesian framework and subsequently design a new label correction algorithm. Specifically, we approximate the instance-dependent noise transition matrices using a Bayesian network with a hierarchical spike and slab prior. To theoretically characterize the distance between the noise transition model and the true instance-dependent noise transition matrix, we provide a posterior-concentration theorem that ensures the posterior consistency in terms of the Hellinger distance. We further formulate the label correction process as a hypothesis testing problem and propose a novel algorithm to infer the true label from the noisy annotations based on the pairwise likelihood ratio test. Moreover, we establish an information-theoretic bound on the Bayes error for the proposed method. We validate the effectiveness of our approach through experiments on benchmark and real-world datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dFtpRphNb3": {
    "title": "Cookie Consent Has Disparate Impact on Estimation Accuracy",
    "volume": "poster",
    "abstract": "Cookies are designed to enable more accurate identification and tracking of user behavior, in turn allowing for more personalized ads and better performing ad campaigns. Given the additional information that is recorded, questions related to privacy and fairness naturally arise. How does a user's consent decision influence how much the system can learn about their demographic and tastes? Is the impact of a user's consent decision on the recommender system's ability to learn about their latent attributes uniform across demographics? We investigate these questions in the context of an engagement-driven recommender system using simulation. We empirically demonstrate that when consent rates exhibit demographic-dependence, user consent has a disparate impact on the recommender agent's ability to estimate users' latent attributes. In particular, we find that when consent rates are demographic-dependent, a user disagreeing to share their cookie may counter-intuitively cause the recommender agent to know more about the user than if the user agreed to share their cookie. Furthermore, the gap in base consent rates across demographics serves as an amplifier: users from the lower consent rate demographic who agree to cookie sharing generally experience higher estimation errors than the same users from the higher consent rate demographic, and conversely for users who choose to disagree to cookie sharing, with these differences increasing in consent rate gap. We discuss the need for new notions of fairness that encourage consistency between a user's privacy decisions and the system's ability to estimate their latent attributes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QGmNMtK3pQ": {
    "title": "Learning Large-scale Neural Fields via Context Pruned Meta-Learning",
    "volume": "poster",
    "abstract": "We introduce an efficient optimization-based meta-learning technique for large-scale neural field training by realizing significant memory savings through automated online context point selection. This is achieved by focusing each learning step on the subset of data with the highest expected immediate improvement in model quality, resulting in the almost instantaneous modeling of global structure and subsequent refinement of high-frequency details. We further improve the quality of our meta-learned initialization by introducing a bootstrap correction resulting in the minimization of any error introduced by reduced context sets while simultaneously mitigating the well-known myopia of optimization-based meta-learning. Finally, we show how gradient re-scaling at meta-test time allows the learning of extremely high-quality neural fields in significantly shortened optimization procedures. Our framework is model-agnostic, intuitive, straightforward to implement, and shows significant reconstruction improvements for a wide range of signals. We provide an extensive empirical evaluation on nine datasets across multiple multiple modalities, demonstrating state-of-the-art results while providing additional insight through careful analysis of the algorithmic components constituting our method. Code is available at https://github.com/jihoontack/GradNCP",
    "checked": true,
    "id": "0eabdfafa75f65dd24ebc7abc191aa2415a10dce",
    "semantic_title": "learning large-scale neural fields via context pruned meta-learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=xgzkuTGBTx": {
    "title": "Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression",
    "volume": "poster",
    "abstract": "In this paper we compare and contrast the behavior of the posterior predictive distribution to the risk of the the maximum a posteriori estimator for the random features regression model in the overparameterized regime. We will focus on the variance of the posterior predictive distribution (Bayesian model average) and compare its asymptotics to that of the risk of the MAP estimator. In the regime where the model dimensions grow faster than any constant multiple of the number of samples, asymptotic agreement between these two quantities is governed by the phase transition in the signal-to-noise ratio. They also asymptotically agree with each other when the number of samples grow faster than any constant multiple of model dimensions. Numerical simulations illustrate finer distributional properties of the two quantities for finite dimensions. We conjecture they have Gaussian fluctuations and exhibit similar properties as found by previous authors in a Gaussian sequence model, this is of independent theoretical interest",
    "checked": true,
    "id": "0a5194c057dd099a86b4795ac1f7a8a5a7899ee7",
    "semantic_title": "asymptotics of bayesian uncertainty estimation in random features regression",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KfOUAlraMP": {
    "title": "Wasserstein distributional robustness of neural networks",
    "volume": "poster",
    "abstract": "Deep neural networks are known to be vulnerable to adversarial attacks (AA). For an image recognition task, this means that a small perturbation of the original can result in the image being misclassified. Design of such attacks as well as methods of adversarial training against them are subject of intense research. We re-cast the problem using techniques of Wasserstein distributionally robust optimization (DRO) and obtain novel contributions leveraging recent insights from DRO sensitivity analysis. We consider a set of distributional threat models. Unlike the traditional pointwise attacks, which assume a uniform bound on perturbation of each input data point, distributional threat models allow attackers to perturb inputs in a non-uniform way. We link these more general attacks with questions of out-of-sample performance and Knightian uncertainty. To evaluate the distributional robustness of neural networks, we propose a first-order AA algorithm and its multistep version. Our attack algorithms include Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) as special cases. Furthermore, we provide a new asymptotic estimate of the adversarial accuracy against distributional threat models. The bound is fast to compute and first-order accurate, offering new insights even for the pointwise AA. It also naturally yields out-of-sample performance guarantees. We conduct numerical experiments on CIFAR-10, CIFAR-100, ImageNet datasets using DNNs on RobustBench to illustrate our theoretical results. Our code is available at https://github.com/JanObloj/W-DRO-Adversarial-Methods",
    "checked": true,
    "id": "63c24262fc0741179d9d4e002d8eebbb764cc3d5",
    "semantic_title": "wasserstein distributional robustness of neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pefAAzu8an": {
    "title": "Recurrent Hypernetworks are Surprisingly Strong in Meta-RL",
    "volume": "poster",
    "abstract": "Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually achieve the strongest performance of all methods evaluated",
    "checked": true,
    "id": "d7a64f08f559b5199b72e5525a92c66f534d749f",
    "semantic_title": "recurrent hypernetworks are surprisingly strong in meta-rl",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=en4LGxpd9E": {
    "title": "Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design",
    "volume": "poster",
    "abstract": "Scaling laws have been recently employed to derive compute-optimal model size (number of parameters) for a given compute duration. We advance and refine such methods to infer compute-optimal model shapes, such as width and depth, and successfully implement this in vision transformers. Our shape-optimized vision transformer, SoViT, achieves results competitive with models that exceed twice its size, despite being pre-trained with an equivalent amount of compute. For example, SoViT-400m/14 achieves 90.3% fine-tuning accuracy on ILSRCV2012, surpassing the much larger ViT-g/14 and approaching ViT-G/14 under identical settings, with also less than half the inference cost. We conduct a thorough evaluation across multiple tasks, such as image classification, captioning, VQA and zero-shot transfer, demonstrating the effectiveness of our model across a broad range of domains and identifying limitations. Overall, our findings challenge the prevailing approach of blindly scaling up vision models and pave a path for a more informed scaling",
    "checked": true,
    "id": "16b4620b59bfef414d702214a717856c943db7fb",
    "semantic_title": "getting vit in shape: scaling laws for compute-optimal model design",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=vKpVJxplmB": {
    "title": "Transformer as a hippocampal memory consolidation model based on NMDAR-inspired nonlinearity",
    "volume": "poster",
    "abstract": "The hippocampus plays a critical role in learning, memory, and spatial representation, processes that depend on the NMDA receptor (NMDAR). Inspired by recent findings that compare deep learning models to the hippocampus, we propose a new nonlinear activation function that mimics NMDAR dynamics. NMDAR-like nonlinearity has a beneficial role in shifting short-term working memory into long-term reference memory in transformers, thus enhancing a process that is similar to memory consolidation in the mammalian brain. We design a navigation task assessing these two memory functions and show that manipulating the activation function (i.e., mimicking the Mg$^{2+}$-gating of NMDAR) disrupts long-term memory processes. Our experiments suggest that place cell-like functions and reference memory reside in the feed-forward network layer of transformers and that nonlinearity drives these processes. We discuss the role of NMDAR-like nonlinearity in establishing this striking resemblance between transformer architecture and hippocampal spatial representation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sx0xpaO0za": {
    "title": "Meta-in-context learning in large language models",
    "volume": "poster",
    "abstract": "Large language models have shown tremendous performance in a variety of tasks. In-context learning -- the ability to improve at a task after being provided with a number of demonstrations -- is seen as one of the main contributors to their success. In the present paper, we demonstrate that the in-context learning abilities of large language models can be recursively improved via in-context learning itself. We coin this phenomenon meta-in-context learning. Looking at two idealized domains, a one-dimensional regression task and a two-armed bandit task, we show that meta-in-context learning adaptively reshapes a large language model's priors over expected tasks. Furthermore, we find that meta-in-context learning modifies the in-context learning strategies of such models. Finally, we broaden the scope of our investigation to encompass two diverse benchmarks: one focusing on real-world regression problems and the other encompassing multiple NLP tasks. In both cases, we observe competitive performance comparable to that of traditional learning algorithms. Taken together, our work improves our understanding of in-context learning and paves the way toward adapting large language models to the environment they are applied purely through meta-in-context learning rather than traditional finetuning",
    "checked": true,
    "id": "286c3587f2616839286748461cbc90261ea49caf",
    "semantic_title": "meta-in-context learning in large language models",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=GjJRbEZ1dc": {
    "title": "Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning",
    "volume": "poster",
    "abstract": "Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel confidence intervals for multitask regression in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data",
    "checked": true,
    "id": "b1271b0e0bb342f6a373bbe84d1f2396a7ebda06",
    "semantic_title": "multitask learning with no regret: from improved confidence bounds to active learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GtgFo5lmOB": {
    "title": "Joint Data-Task Generation for Auxiliary Learning",
    "volume": "poster",
    "abstract": "Current auxiliary learning methods mainly adopt the methodology of reweighing losses for the manually collected auxiliary data and tasks. However, these methods heavily rely on domain knowledge during data collection, which may be hardly available in reality. Therefore, current methods will become less effective and even do harm to the primary task when unhelpful auxiliary data and tasks are employed. To tackle the problem, we propose a joint data-task generation framework for auxiliary learning (DTG-AuxL), which can bring benefits to the primary task by generating the new auxiliary data and task in a joint manner. The proposed DTG-AuxL framework contains a joint generator and a bi-level optimization strategy. Specifically, the joint generator contains a feature generator and a label generator, which are designed to be applicable and expressive for various auxiliary learning scenarios. The bi-level optimization strategy optimizes the joint generator and the task learning model, where the joint generator is effectively optimized in the upper level via the implicit gradient from the primary loss and the explicit gradient of our proposed instance regularization, while the task learning model is optimized in the lower level by the generated data and task. Extensive experiments show that our proposed DTG-AuxL framework consistently outperforms existing methods in various auxiliary learning scenarios, particularly when the manually collected auxiliary data and tasks are unhelpful",
    "checked": false,
    "id": "7dbb2d81343fb30792b2a9850e6fd35e75e18b80",
    "semantic_title": "private image generation with dual-purpose auxiliary classifier",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uFpjPJMkv6": {
    "title": "FairLISA: Fair User Modeling with Limited Sensitive Attributes Information",
    "volume": "poster",
    "abstract": "User modeling techniques profile users' latent characteristics (e.g., preference) from their observed behaviors, and play a crucial role in decision-making. Unfortunately, traditional user models may unconsciously capture biases related to sensitive attributes (e.g., gender) from behavior data, even when this sensitive information is not explicitly provided. This can lead to unfair issues and discrimination against certain groups based on these sensitive attributes. Recent studies have been proposed to improve fairness by explicitly decorrelating user modeling results and sensitive attributes. However, most existing approaches assume that fully sensitive attribute labels are available in the training set, which is unrealistic due to collection limitations like privacy concerns, and hence bear the limitation of performance. In this paper, we focus on a practical situation with limited sensitive data and propose a novel FairLISA framework, which can efficiently utilize data with known and unknown sensitive attributes to facilitate fair model training. We first propose a novel theoretical perspective to build the relationship between data with both known and unknown sensitive attributes with the fairness objective. Then, based on this, we provide a general adversarial framework to effectively leverage the whole user data for fair user modeling. We conduct experiments on representative user modeling tasks including recommender system and cognitive diagnosis. The results demonstrate that our FairLISA can effectively improve fairness while retaining high accuracy in scenarios with different ratios of missing sensitive attributes",
    "checked": false,
    "id": "c342e5ba8d81da016455a8cd37b3634f7ab0ae04",
    "semantic_title": "learning fair graph neural networks with limited and private sensitive attribute information",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=RgNXKIrWyU": {
    "title": "Reusing Pretrained Models by Multi-linear Operators for Efficient Training",
    "volume": "poster",
    "abstract": "Training large models from scratch usually costs a substantial amount of resources. Towards this problem, recent studies such as bert2BERT and LiGO have reused small pretrained models to initialize a large model (termed the ``target model''), leading to a considerable acceleration in training. Despite the successes of these previous studies, they grew pretrained models by mapping partial weights only, ignoring potential correlations across the entire model. As we show in this paper, there are inter- and intra-interactions among the weights of both the pretrained and the target models. As a result, the partial mapping may not capture the complete information and lead to inadequate growth. In this paper, we propose a method that linearly correlates each weight of the target model to all the weights of the pretrained model to further enhance acceleration ability. We utilize multi-linear operators to reduce computational and spacial complexity, enabling acceptable resource requirements. Experiments demonstrate that our method can save 76\\% computational costs on DeiT-base transferred from DeiT-small, which outperforms bert2BERT by +12\\% and LiGO by +21\\%, respectively",
    "checked": true,
    "id": "317bad11d7207183c1538db511c3592297e364e5",
    "semantic_title": "reusing pretrained models by multi-linear operators for efficient training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GGbBXSkX3r": {
    "title": "Domain Adaptive Imitation Learning with Visual Observation",
    "volume": "poster",
    "abstract": "In this paper, we consider domain-adaptive imitation learning with visual observation, where an agent in a target domain learns to perform a task by observing expert demonstrations in a source domain. Domain adaptive imitation learning arises in practical scenarios where a robot, receiving visual sensory data, needs to mimic movements by visually observing other robots from different angles or observing robots of different shapes. To overcome the domain shift in cross-domain imitation learning with visual observation, we propose a novel framework for extracting domain-independent behavioral features from input observations that can be used to train the learner, based on dual feature extraction and image reconstruction. Empirical results demonstrate that our approach outperforms previous algorithms for imitation learning from visual observation with domain shift",
    "checked": false,
    "id": "3e5279bc0f471cfd4f14ad50c722d800fc53d420",
    "semantic_title": "one-shot domain-adaptive imitation learning via progressive learning",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=LIsJHQHi4z": {
    "title": "Variational Weighting for Kernel Density Ratios",
    "volume": "poster",
    "abstract": "Kernel density estimation (KDE) is integral to a range of generative and discriminative tasks in machine learning. Drawing upon tools from the multidimensional calculus of variations, we derive an optimal weight function that reduces bias in standard kernel density estimates for density ratios, leading to improved estimates of prediction posteriors and information-theoretic measures. In the process, we shed light on some fundamental aspects of density estimation, particularly from the perspective of algorithms that employ KDEs as their main building blocks",
    "checked": true,
    "id": "483c4f2069e60d86ad18393987b8d75cf2034fdd",
    "semantic_title": "variational weighting for kernel density ratios",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x2PH6q32LR": {
    "title": "Taming Local Effects in Graph-based Spatiotemporal Forecasting",
    "volume": "poster",
    "abstract": "Spatiotemporal graph neural networks have shown to be effective in time series forecasting applications, achieving better performance than standard univariate predictors in several settings. These architectures take advantage of a graph structure and relational inductive biases to learn a single (global) inductive model to predict any number of the input time series, each associated with a graph node. Despite the gain achieved in computational and data efficiency w.r.t. fitting a set of local models, relying on a single global model can be a limitation whenever some of the time series are generated by a different spatiotemporal stochastic process. The main objective of this paper is to understand the interplay between globality and locality in graph-based spatiotemporal forecasting, while contextually proposing a methodological framework to rationalize the practice of including trainable node embeddings in such architectures. We ascribe to trainable node embeddings the role of amortizing the learning of specialized components. Moreover, embeddings allow for 1) effectively combining the advantages of shared message-passing layers with node-specific parameters and 2) efficiently transferring the learned model to new node sets. Supported by strong empirical evidence, we provide insights and guidelines for specializing graph-based models to the dynamics of each time series and show how this aspect plays a crucial role in obtaining accurate predictions",
    "checked": true,
    "id": "e2a83369383aff37224170c1ae3d3870d5d9e419",
    "semantic_title": "taming local effects in graph-based spatiotemporal forecasting",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=kj33zJ9Vue": {
    "title": "On permutation symmetries in Bayesian neural network posteriors: a variational perspective",
    "volume": "poster",
    "abstract": "The elusive nature of gradient-based optimization in neural networks is tied to their loss landscape geometry, which is poorly understood. However recent work has brought solid evidence that there is essentially no loss barrier between the local solutions of gradient descent, once accounting for weight-permutations that leave the network's computation unchanged. This raises questions for approximate inference in Bayesian neural networks (BNNs), where we are interested in marginalizing over multiple points in the loss landscape. In this work, we first extend the formalism of marginalized loss barrier and solution interpolation to BNNs, before proposing a matching algorithm to search for linearly connected solutions. This is achieved by aligning the distributions of two independent approximate Bayesian solutions with respect to permutation matrices. Building on the work of Ainsworth et al. (2023), we frame the problem as a combinatorial optimization one, using an approximation to the sum of bilinear assignment problem. We then experiment on a variety of architectures and datasets, finding nearly zero marginalized loss barriers for linearly connected solutions",
    "checked": true,
    "id": "5ebc3cba36b949676a5d79a2120cb93de3d3092a",
    "semantic_title": "on permutation symmetries in bayesian neural network posteriors: a variational perspective",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gzCS252hCO": {
    "title": "Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale",
    "volume": "poster",
    "abstract": "Large-scale generative models such as GPT and DALL-E have revolutionized the research community. These models not only generate high fidelity outputs, but are also generalists which can solve tasks not explicitly taught. In contrast, speech generative models are still primitive in terms of scale and task generalization. In this paper, we present Voicebox, the most versatile text-guided generative model for speech at scale. Voicebox is a non-autoregressive flow-matching model trained to infill speech, given audio context and text, trained on over 50K hours of speech that are not filtered or enhanced. Similar to GPT, Voicebox can perform many different tasks through in-context learning, but is more flexible as it can also condition on future context. Voicebox can be used for mono or cross-lingual zero-shot text-to-speech synthesis, noise removal, content editing, style conversion, and diverse sample generation. In particular, Voicebox outperforms the state-of-the-art zero-shot TTS model VALL-E on both intelligibility (5.9\\% vs 1.9\\% word error rates) and audio similarity (0.580 vs 0.681) while being up to 20 times faster. Audio samples can be found in \\url{https://voicebox.metademolab.com}",
    "checked": true,
    "id": "a9e00c216ce69325a15fd139da0624978e54058a",
    "semantic_title": "voicebox: text-guided multilingual universal speech generation at scale",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=bBIHqoZ3OR": {
    "title": "A Bayesian Take on Gaussian Process Networks",
    "volume": "poster",
    "abstract": "Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows the description of continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features. Simulation studies show that our method outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its posterior distribution",
    "checked": true,
    "id": "85b07fa29727664cc08414afbcb7c7753fd9f16d",
    "semantic_title": "a bayesian take on gaussian process networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZeRiLBvIps": {
    "title": "Local Convergence of Gradient Methods for Min-Max Games: Partial Curvature Generically Suffices",
    "volume": "poster",
    "abstract": "We study the convergence to local Nash equilibria of gradient methods for two-player zero-sum differentiable games. It is well-known that, in the continuous-time setting, such dynamics converge locally when $S \\succ 0$ and may diverge when $S=0$, where $S\\succeq 0$ is the symmetric part of the Jacobian at equilibrium that accounts for the \"potential\" component of the game. We show that these dynamics also converge as soon as $S$ is nonzero (*partial curvature*) and the eigenvectors of the antisymmetric part $A$ are in general position with respect to the kernel of $S$. We then study the convergence rate when $S \\ll A$ and prove that it typically depends on the *average* of the eigenvalues of $S$, instead of the minimum as an analogy with minimization problems would suggest. To illustrate our results, we consider the problem of computing mixed Nash equilibria of continuous games. We show that, thanks to partial curvature, conic particle methods -- which optimize over both weights and supports of the mixed strategies -- generically converge faster than fixed-support methods. For min-max games, it is thus beneficial to add degrees of freedom \"with curvature\": this can be interpreted as yet another benefit of over-parameterization",
    "checked": true,
    "id": "ae115ee72cc3d05b3fbe6fca70c9a3d3642a9d20",
    "semantic_title": "local convergence of gradient methods for min-max games: partial curvature generically suffices",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wqIm0Qsgy0": {
    "title": "Granger Components Analysis: Unsupervised learning of latent temporal dependencies",
    "volume": "poster",
    "abstract": "A new technique for unsupervised learning of time series data based on the notion of Granger causality is presented. The technique learns pairs of projections of a multivariate data set such that the resulting components -- \"driving\" and \"driven\" -- maximize the strength of the Granger causality between the latent time series (how strongly the past of the driving signal predicts the present of the driven signal). A coordinate descent algorithm that learns pairs of coefficient vectors in an alternating fashion is developed and shown to blindly identify the underlying sources (up to scale) on simulated vector autoregressive (VAR) data. The technique is tested on scalp electroencephalography (EEG) data from a motor imagery experiment where the resulting components lateralize with the side of the cued hand, and also on functional magnetic resonance imaging (fMRI) data, where the recovered components express previously reported resting-state networks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dqn715Txgl": {
    "title": "Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment",
    "volume": "poster",
    "abstract": "Active Learning (AL) aims to reduce the labeling burden by interactively selecting the most informative samples from a pool of unlabeled data. While there has been extensive research on improving AL query methods in recent years, some studies have questioned the effectiveness of AL compared to emerging paradigms such as semi-supervised (Semi-SL) and self-supervised learning (Self-SL), or a simple optimization of classifier configurations. Thus, today's AL literature presents an inconsistent and contradictory landscape, leaving practitioners uncertain about whether and how to use AL in their tasks. In this work, we make the case that this inconsistency arises from a lack of systematic and realistic evaluation of AL methods. Specifically, we identify five key pitfalls in the current literature that reflect the delicate considerations required for AL evaluation. Further, we present an evaluation framework that overcomes these pitfalls and thus enables meaningful statements about the performance of AL methods. To demonstrate the relevance of our protocol, we present a large-scale empirical study and benchmark for image classification spanning various data sets, query methods, AL settings, and training paradigms. Our findings clarify the inconsistent picture in the literature and enable us to give hands-on recommendations for practitioners. The benchmark is hosted at https://github.com/IML-DKFZ/realistic-al",
    "checked": true,
    "id": "bf88d88e712fc626cdc8e010b5d0db7e9c471645",
    "semantic_title": "navigating the pitfalls of active learning evaluation: a systematic framework for meaningful performance assessment",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=u6BYyPuD29": {
    "title": "MADG: Margin-based Adversarial Learning for Domain Generalization",
    "volume": "poster",
    "abstract": "Domain Generalization (DG) techniques have emerged as a popular approach to address the challenges of domain shift in Deep Learning (DL), with the goal of generalizing well to the target domain unseen during the training. In recent years, numerous methods have been proposed to address the DG setting, among which one popular approach is the adversarial learning-based methodology. The main idea behind adversarial DG methods is to learn domain-invariant features by minimizing a discrepancy metric. However, most adversarial DG methods use 0-1 loss based $\\mathcal{H}\\Delta\\mathcal{H}$ divergence metric. In contrast, the margin loss-based discrepancy metric has the following advantages: more informative, tighter, practical, and efficiently optimizable. To mitigate this gap, this work proposes a novel adversarial learning DG algorithm, $\\textbf{MADG}$, motivated by a margin loss-based discrepancy metric. The proposed $\\textbf{MADG}$ model learns domain-invariant features across all source domains and uses adversarial training to generalize well to the unseen target domain. We also provide a theoretical analysis of the proposed $\\textbf{MADG}$ model based on the unseen target error bound. Specifically, we construct the link between the source and unseen domains in the real-valued hypothesis space and derive the generalization bound using margin loss and Rademacher complexity. We extensively experiment with the $\\textbf{MADG}$ model on popular real-world DG datasets, VLCS, PACS, OfficeHome, DomainNet, and TerraIncognita. We evaluate the proposed algorithm on DomainBed's benchmark and observe consistent performance across all the datasets",
    "checked": true,
    "id": "8d590a7c196b32fe936f944e5975ea7c7001c640",
    "semantic_title": "madg: margin-based adversarial learning for domain generalization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FdtdjQpAwJ": {
    "title": "Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning",
    "volume": "poster",
    "abstract": "Safe reinforcement learning (RL) focuses on training reward-maximizing agents subject to pre-defined safety constraints. Yet, learning versatile safe policies that can adapt to varying safety constraint requirements during deployment without retraining remains a largely unexplored and challenging area. In this work, we formulate the versatile safe RL problem and consider two primary requirements: training efficiency and zero-shot adaptation capability. To address them, we introduce the Conditioned Constrained Policy Optimization (CCPO) framework, consisting of two key modules: (1) Versatile Value Estimation (VVE) for approximating value functions under unseen threshold conditions, and (2) Conditioned Variational Inference (CVI) for encoding arbitrary constraint thresholds during policy optimization. Our extensive experiments demonstrate that CCPO outperforms the baselines in terms of safety and task performance while preserving zero-shot adaptation capabilities to different constraint thresholds data-efficiently. This makes our approach suitable for real-world dynamic applications",
    "checked": true,
    "id": "b9dff780b3cbe81adca8f063a1fdcc699db0f79f",
    "semantic_title": "constraint-conditioned policy optimization for versatile safe reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XjOj3ZmWEl": {
    "title": "ASIF: Coupled Data Turns Unimodal Models to Multimodal without Training",
    "volume": "poster",
    "abstract": "CLIP proved that aligning visual and language spaces is key to solving many vision tasks without explicit training, but required to train image and text encoders from scratch on a huge dataset. LiT improved this by only training the text encoder and using a pre-trained vision network. In this paper, we show that a common space can be created without any training at all, using single-domain encoders (trained with or without supervision) and a much smaller amount of image-text pairs. Furthermore, our model has unique properties. Most notably, deploying a new version with updated training samples can be done in a matter of seconds. Additionally, the representations in the common space are easily interpretable as every dimension corresponds to the similarity of the input to a unique entry in the multimodal dataset. Experiments on standard zero-shot visual benchmarks demonstrate the typical transfer ability of image-text models. Overall, our method represents a simple yet surprisingly strong baseline for foundation multi-modal models, raising important questions on their data efficiency and on the role of retrieval in machine learning",
    "checked": true,
    "id": "81e4973ba9c1f3aa72dd12f059617c9e64b2ae9a",
    "semantic_title": "asif: coupled data turns unimodal models to multimodal without training",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=8muKbaAgsh": {
    "title": "Towards Stable Backdoor Purification through Feature Shift Tuning",
    "volume": "poster",
    "abstract": "It has been widely observed that deep neural networks (DNN) are vulnerable to backdoor attacks where attackers could manipulate the model behavior maliciously by tampering with a small set of training samples. Although a line of defense methods is proposed to mitigate this threat, they either require complicated modifications to the training process or heavily rely on the specific model architecture, which makes them hard to deploy into real-world applications. Therefore, in this paper, we instead start with fine-tuning, one of the most common and easy-to-deploy backdoor defenses, through comprehensive evaluations against diverse attack scenarios. Observations made through initial experiments show that in contrast to the promising defensive results on high poisoning rates, vanilla tuning methods completely fail at low poisoning rate scenarios. Our analysis shows that with the low poisoning rate, the entanglement between backdoor and clean features undermines the effect of tuning-based defenses. Therefore, it is necessary to disentangle the backdoor and clean features in order to improve backdoor purification. To address this, we introduce Feature Shift Tuning (FST), a method for tuning-based backdoor purification. Specifically, FST encourages feature shifts by actively deviating the classifier weights from the originally compromised weights. Extensive experiments demonstrate that our FST provides consistently stable performance under different attack settings. Without complex parameter adjustments, FST also achieves much lower tuning costs, only $10$ epochs. Our codes are available at https://github.com/AISafety-HKUST/stable_backdoor_purification",
    "checked": true,
    "id": "a879e226e34f40840128f675b2f53ee6043183e0",
    "semantic_title": "towards stable backdoor purification through feature shift tuning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MCkUS1P3Sh": {
    "title": "Nash Regret Guarantees for Linear Bandits",
    "volume": "poster",
    "abstract": "We obtain essentially tight upper bounds for a strengthened notion of regret in the stochastic linear bandits framework. The strengthening---referred to as Nash regret---is defined as the difference between the (a priori unknown) optimum and the geometric mean of expected rewards accumulated by the linear bandit algorithm. Since the geometric mean corresponds to the well-studied Nash social welfare (NSW) function, this formulation quantifies the performance of a bandit algorithm as the collective welfare it generates across rounds. NSW is known to satisfy fairness axioms and, hence, an upper bound on Nash regret provides a principled fairness guarantee. We consider the stochastic linear bandits problem over a horizon of $\\mathsf{T}$ rounds and with a set of arms ${\\cal X}$ in ambient dimension $d$. Furthermore, we focus on settings in which the stochastic reward---associated with each arm in ${\\cal X}$---is a non-negative, sub-Poisson random variable. For this setting, we develop an algorithm that achieves a Nash regret of $O\\left( \\sqrt{\\frac{d}{\\mathsf{T}}} \\log(\\mathsf{T} |{\\cal X}|)\\right)$. In addition, addressing linear bandit instances in which the set of arms ${\\cal X}$ is not necessarily finite, we obtain a Nash regret upper bound of $O\\left( \\frac{d^\\frac{5}{4}}{\\sqrt{\\mathsf{T}}} \\log(\\mathsf{T})\\right)$. Since bounded random variables are sub-Poisson, these results hold for bounded, non-negative rewards. Our linear bandit algorithm is built upon the successive elimination method with novel technical insights, including tailored concentration bounds and the use of sampling via John ellipsoid in conjunction with the Kiefer–Wolfowitz optimal design",
    "checked": true,
    "id": "7a9a2460079ab272a91da5f93c4dc83fa5156705",
    "semantic_title": "nash regret guarantees for linear bandits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yq6GKgN3RC": {
    "title": "Federated Learning with Client Subsampling, Data Heterogeneity, and Unbounded Smoothness: A New Algorithm and Lower Bounds",
    "volume": "poster",
    "abstract": "We study the problem of Federated Learning (FL) under client subsampling and data heterogeneity with an objective function that has potentially unbounded smoothness. This problem is motivated by empirical evidence that the class of relaxed smooth functions, where the Lipschitz constant of the gradient scales linearly with the gradient norm, closely resembles the loss functions of certain neural networks such as recurrent neural networks (RNNs) with possibly exploding gradient. We introduce EPISODE++, the first algorithm to solve this problem. It maintains historical statistics for each client to construct control variates and decide clipping behavior for sampled clients in the current round. We prove that EPISODE++ achieves linear speedup in the number of participating clients, reduced communication rounds, and resilience to data heterogeneity. Our upper bound proof relies on novel techniques of recursively bounding the client updates under unbounded smoothness and client subsampling, together with a refined high probability analysis. In addition, we prove a lower bound showing that the convergence rate of a special case of clipped minibatch SGD (without randomness in the stochastic gradient and with randomness in client subsampling) suffers from an explicit dependence on the maximum gradient norm of the objective in a sublevel set, which may be large. This effectively demonstrates that applying gradient clipping to minibatch SGD in our setting does not eliminate the problem of exploding gradients. Our lower bound is based on new constructions of hard instances tailored to client subsampling and a novel analysis of the trajectory of the algorithm in the presence of clipping. Lastly, we provide an experimental evaluation of EPISODE++ when training RNNs on federated text classification tasks, demonstrating that EPISODE++ outperforms strong baselines in FL. The code is available at https://github.com/MingruiLiu-ML-Lab/episode_plusplus",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xq2s5yxzd2": {
    "title": "Multi-Prompt Alignment for Multi-Source Unsupervised Domain Adaptation",
    "volume": "poster",
    "abstract": "Most existing methods for unsupervised domain adaptation (UDA) rely on a shared network to extract domain-invariant features. However, when facing multiple source domains, optimizing such a network involves updating the parameters of the entire network, making it both computationally expensive and challenging, particularly when coupled with min-max objectives. Inspired by recent advances in prompt learning that adapts high-capacity models for downstream tasks in a computationally economic way, we introduce Multi-Prompt Alignment (MPA), a simple yet efficient framework for multi-source UDA. Given a source and target domain pair, MPA first trains an individual prompt to minimize the domain gap through a contrastive loss. Then, MPA denoises the learned prompts through an auto-encoding process and aligns them by maximizing the agreement of all the reconstructed prompts. Moreover, we show that the resulting subspace acquired from the auto-encoding process can easily generalize to a streamlined set of target domains, making our method more efficient for practical usage. Extensive experiments show that MPA achieves state-of-the-art results on three popular datasets with an impressive average accuracy of 54.1% on DomainNet",
    "checked": true,
    "id": "0106d45b55fd6af1d00cce8ef0b7b451e4b5a314",
    "semantic_title": "multi-prompt alignment for multi-source unsupervised domain adaptation",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=awbWWO0nb6": {
    "title": "Characterization of Overfitting in Robust Multiclass Classification",
    "volume": "poster",
    "abstract": "This paper considers the following question: Given the number of classes m, the number of robust accuracy queries k, and the number of test examples in the dataset n, how much can adaptive algorithms robustly overfit the test dataset? We solve this problem by equivalently giving near-matching upper and lower bounds of the robust overfitting bias in multiclass classification problems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J3taqrzyyA": {
    "title": "Stability-penalty-adaptive follow-the-regularized-leader: Sparsity, game-dependency, and best-of-both-worlds",
    "volume": "poster",
    "abstract": "Adaptivity to the difficulties of a problem is a key property in sequential decision-making problems to broaden the applicability of algorithms. Follow-the-regularized-leader (FTRL) has recently emerged as one of the most promising approaches for obtaining various types of adaptivity in bandit problems. Aiming to further generalize this adaptivity, we develop a generic adaptive learning rate, called stability-penalty-adaptive (SPA) learning rate for FTRL. This learning rate yields a regret bound jointly depending on stability and penalty of the algorithm, into which the regret of FTRL is typically decomposed. With this result, we establish several algorithms with three types of adaptivity: sparsity, game-dependency, and best-of-both-worlds (BOBW). Despite the fact that sparsity appears frequently in real problems, existing sparse multi-armed bandit algorithms with $k$-arms assume that the sparsity level $s \\leq k$ is known in advance, which is often not the case in real-world scenarios. To address this issue, we first establish $s$-agnostic algorithms with regret bounds of $\\tilde{O}(\\sqrt{sT})$ in the adversarial regime for $T$ rounds, which matches the existing lower bound up to a logarithmic factor. Meanwhile, BOBW algorithms aim to achieve a near-optimal regret in both the stochastic and adversarial regimes. Leveraging the SPA learning rate and the technique for $s$-agnostic algorithms combined with a new analysis to bound the variation in FTRL output in response to changes in a regularizer, we establish the first BOBW algorithm with a sparsity-dependent bound. Additionally, we explore partial monitoring and demonstrate that the proposed SPA learning rate framework allows us to achieve a game-dependent bound and the BOBW simultaneously",
    "checked": true,
    "id": "7097ce178f82a052f1bf1a708e3c44d6eac5a0e4",
    "semantic_title": "stability-penalty-adaptive follow-the-regularized-leader: sparsity, game-dependency, and best-of-both-worlds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kupNhxLc6k": {
    "title": "Computing Optimal Nash Equilibria in Multiplayer Games",
    "volume": "poster",
    "abstract": "Designing efficient algorithms to compute a Nash Equilibrium (NE) in multiplayer games is still an open challenge. In this paper, we focus on computing an NE that optimizes a given objective function. For example, when there is a team of players independently playing against an adversary in a game (e.g., several groups in a forest trying to interdict illegal loggers in green security games), these team members may need to find an NE minimizing the adversary's utility. Finding an optimal NE in multiplayer games can be formulated as a mixed-integer bilinear program by introducing auxiliary variables to represent bilinear terms, leading to a huge number of bilinear terms, making it hard to solve. To overcome this challenge, we first propose a general framework for this formulation based on a set of correlation plans. We then develop a novel algorithm called CRM based on this framework, which uses correlation plans with their relations to strictly reduce the feasible solution space after the convex relaxation of bilinear terms while minimizing the number of correlation plans to significantly reduce the number of bilinear terms. We show that our techniques can significantly reduce the time complexity and CRM can be several orders of magnitude faster than the state-of-the-art baseline",
    "checked": false,
    "id": "bab867036406188208bea54f7c0a0a3e31ca97e2",
    "semantic_title": "finding optimal nash equilibria in multiplayer games via correlation plans",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xDHzQQ4lnC": {
    "title": "Probabilistic inverse optimal control for non-linear partially observable systems disentangles perceptual uncertainty and behavioral costs",
    "volume": "poster",
    "abstract": "Inverse optimal control can be used to characterize behavior in sequential decision-making tasks. Most existing work, however, is limited to fully observable or linear systems, or requires the action signals to be known. Here, we introduce a probabilistic approach to inverse optimal control for partially observable stochastic non-linear systems with unobserved action signals, which unifies previous approaches to inverse optimal control with maximum causal entropy formulations. Using an explicit model of the noise characteristics of the sensory and motor systems of the agent in conjunction with local linearization techniques, we derive an approximate likelihood function for the model parameters, which can be computed within a single forward pass. We present quantitative evaluations on stochastic and partially observable versions of two classic control tasks and two human behavioral tasks. Importantly, we show that our method can disentangle perceptual factors and behavioral costs despite the fact that epistemic and pragmatic actions are intertwined in sequential decision-making under uncertainty, such as in active sensing and active learning. The proposed method has broad applicability, ranging from imitation learning to sensorimotor neuroscience",
    "checked": true,
    "id": "23a7b62a8a85d26f0e3dc1140aec0adfa539c556",
    "semantic_title": "probabilistic inverse optimal control for non-linear partially observable systems disentangles perceptual uncertainty and behavioral costs",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SfdkS6tt81": {
    "title": "An Optimal Structured Zeroth-order Algorithm for Non-smooth Optimization",
    "volume": "poster",
    "abstract": "Finite-difference methods are a class of algorithms designed to solve black-box optimization problems by approximating a gradient of the target function on a set of directions. In black-box optimization, the non-smooth setting is particularly relevant since, in practice, differentiability and smoothness assumptions cannot be verified. To cope with nonsmoothness, several authors use a smooth approximation of the target function and show that finite difference methods approximate its gradient. Recently, it has been proved that imposing a structure in the directions allows improving performance. However, only the smooth setting was considered. To close this gap, we introduce and analyze O-ZD, the first structured finite-difference algorithm for non-smooth black-box optimization. Our method exploits a smooth approximation of the target function and we prove that it approximates its gradient on a subset of random {\\em orthogonal} directions. We analyze the convergence of O-ZD under different assumptions. For non-smooth convex functions, we obtain the optimal complexity. In the non-smooth non-convex setting, we characterize the number of iterations needed to bound the expected norm of the smoothed gradient. For smooth functions, our analysis recovers existing results for structured zeroth-order methods for the convex case and extends them to the non-convex setting. We conclude with numerical simulations where assumptions are satisfied, observing that our algorithm has very good practical performances",
    "checked": true,
    "id": "048d457ec432ecfcbc090a1d92478410e7be9fe5",
    "semantic_title": "an optimal structured zeroth-order algorithm for non-smooth optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=w7TyuWhGZP": {
    "title": "Interpretable Reward Redistribution in Reinforcement Learning: A Causal Approach",
    "volume": "poster",
    "abstract": "A major challenge in reinforcement learning is to determine which state-action pairs are responsible for future rewards that are delayed. Reward redistribution serves as a solution to re-assign credits for each time step from observed sequences. While the majority of current approaches construct the reward redistribution in an uninterpretable manner, we propose to explicitly model the contributions of state and action from a causal perspective, resulting in an interpretable reward redistribution and preserving policy invariance. In this paper, we start by studying the role of causal generative models in reward redistribution by characterizing the generation of Markovian rewards and trajectory-wise long-term return and further propose a framework, called Generative Return Decomposition (GRD), for policy optimization in delayed reward scenarios. Specifically, GRD first identifies the unobservable Markovian rewards and causal relations in the generative process. Then, GRD makes use of the identified causal generative model to form a compact representation to train policy over the most favorable subspace of the state space of the agent. Theoretically, we show that the unobservable Markovian reward function is identifiable, as well as the underlying causal structure and causal models. Experimental results show that our method outperforms state-of-the-art methods and the provided visualization further demonstrates the interpretability of our method. The project page is located at [https://reedzyd.github.io/GenerativeReturnDecomposition/](https://reedzyd.github.io/GenerativeReturnDecomposition/)",
    "checked": true,
    "id": "1f56856748285c3fdbd0e8ee97d678123b9f17d5",
    "semantic_title": "interpretable reward redistribution in reinforcement learning: a causal approach",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N0KwVdaaaJ": {
    "title": "Theoretical Analysis of the Inductive Biases in Deep Convolutional Networks",
    "volume": "poster",
    "abstract": "In this paper, we provide a theoretical analysis of the inductive biases in convolutional neural networks (CNNs). We start by examining the universality of CNNs, i.e., the ability to approximate any continuous functions. We prove that a depth of $\\mathcal{O}(\\log d)$ suffices for deep CNNs to achieve this universality, where $d$ in the input dimension. Additionally, we establish that learning sparse functions with CNNs requires only $\\widetilde{\\mathcal{O}}(\\log^2d)$ samples, indicating that deep CNNs can efficiently capture {\\em long-range} sparse correlations. These results are made possible through a novel combination of the multichanneling and downsampling when increasing the network depth. We also delve into the distinct roles of weight sharing and locality in CNNs. To this end, we compare the performance of CNNs, locally-connected networks (LCNs), and fully-connected networks (FCNs) on a simple regression task, where LCNs can be viewed as CNNs without weight sharing. On the one hand, we prove that LCNs require ${\\Omega}(d)$ samples while CNNs need only $\\widetilde{\\mathcal{O}}(\\log^2d)$ samples, highlighting the critical role of weight sharing. On the other hand, we prove that FCNs require $\\Omega(d^2)$ samples, whereas LCNs need only $\\widetilde{\\mathcal{O}}(d)$ samples, underscoring the importance of locality. These provable separations quantify the difference between the two biases, and the major observation behind our proof is that weight sharing and locality break different symmetries in the learning process",
    "checked": false,
    "id": "e5fa12f6876baa9498a3bdab0edc640225c19c5c",
    "semantic_title": "theoretical analysis of inductive biases in deep convolutional networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lXOoR4KYcJ": {
    "title": "Entropy-based Training Methods for Scalable Neural Implicit Samplers",
    "volume": "poster",
    "abstract": "Efficiently sampling from un-normalized target distributions is a fundamental problem in scientific computing and machine learning. Traditional approaches such as Markov Chain Monte Carlo (MCMC) guarantee asymptotically unbiased samples from such distributions but suffer from computational inefficiency, particularly when dealing with high-dimensional targets, as they require numerous iterations to generate a batch of samples. In this paper, we introduce an efficient and scalable neural implicit sampler that overcomes these limitations. The implicit sampler can generate large batches of samples with low computational costs by leveraging a neural transformation that directly maps easily sampled latent vectors to target samples without the need for iterative procedures. To train the neural implicit samplers, we introduce two novel methods: the KL training method and the Fisher training method. The former method minimizes the Kullback-Leibler divergence, while the latter minimizes the Fisher divergence between the sampler and the target distributions. By employing the two training methods, we effectively optimize the neural implicit samplers to learn and generate from the desired target distribution. To demonstrate the effectiveness, efficiency, and scalability of our proposed samplers, we evaluate them on three sampling benchmarks with different scales. These benchmarks include sampling from 2D targets, Bayesian inference, and sampling from high-dimensional energy-based models (EBMs). Notably, in the experiment involving high-dimensional EBMs, our sampler produces samples that are comparable to those generated by MCMC-based methods while being more than 100 times more efficient, showcasing the efficiency of our neural sampler. Besides the theoretical contributions and strong empirical performances, the proposed neural samplers and corresponding training methods will shed light on further research on developing efficient samplers for various applications beyond the ones explored in this study",
    "checked": false,
    "id": "5834ecf432389445812c318ce20d1f9095ab647c",
    "semantic_title": "entropy-based training methods for scalable neural implicit sampler",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZPtzwr2SwJ": {
    "title": "Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback",
    "volume": "poster",
    "abstract": "In this work, we study the low-rank MDPs with adversarially changed losses in the full-information feedback setting. In particular, the unknown transition probability kernel admits a low-rank matrix decomposition \\citep{REPUCB22}, and the loss functions may change adversarially but are revealed to the learner at the end of each episode. We propose a policy optimization-based algorithm POLO, and we prove that it attains the $\\widetilde{O}(dA^{\\frac{1}{2}}K^{\\frac{3}{4}}\\ln^{\\frac{1}{4}}M/(1-\\gamma)^2)$ regret guarantee, where $d$ is rank of the transition kernel (and hence the dimension of the unknown representations), $A$ is the cardinality of the action space, $M$ is the cardinality of the model class, and $\\gamma$ is the discounted factor. Notably, our algorithm is oracle-efficient and has a regret guarantee with no dependence on the size of potentially arbitrarily large state space. Furthermore, we also prove an $\\Omega(\\frac{\\gamma^2}{1-\\gamma} \\sqrt{d A K})$ regret lower bound for this problem, showing that low-rank MDPs are statistically more difficult to learn than linear MDPs in the regret minimization setting. To the best of our knowledge, we present the first algorithm that interleaves representation learning, exploration, and exploitation to achieve the sublinear regret guarantee for RL with nonlinear function approximation and adversarial losses",
    "checked": true,
    "id": "fa9dd03d976a5ad4462143c2b0ab5ff13676724f",
    "semantic_title": "learning adversarial low-rank markov decision processes with unknown transition and full-information feedback",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XUu2GloTXb": {
    "title": "Implicit Contrastive Representation Learning with Guided Stop-gradient",
    "volume": "poster",
    "abstract": "In self-supervised representation learning, Siamese networks are a natural architecture for learning transformation-invariance by bringing representations of positive pairs closer together. But it is prone to collapse into a degenerate solution. To address the issue, in contrastive learning, a contrastive loss is used to prevent collapse by moving representations of negative pairs away from each other. But it is known that algorithms with negative sampling are not robust to a reduction in the number of negative samples. So, on the other hand, there are algorithms that do not use negative pairs. Many positive-only algorithms adopt asymmetric network architecture consisting of source and target encoders as a key factor in coping with collapse. By exploiting the asymmetric architecture, we introduce a methodology to implicitly incorporate the idea of contrastive learning. As its implementation, we present a novel method guided stop-gradient. We apply our method to benchmark algorithms SimSiam and BYOL and show that our method stabilizes training and boosts performance. We also show that the algorithms with our method work well with small batch sizes and do not collapse even when there is no predictor. The code is available in the supplementary material",
    "checked": false,
    "id": "fccada3fc530ea98d612126399f13ecb0844fc21",
    "semantic_title": "contrast with reconstruct: contrastive 3d representation learning guided by generative pretraining",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=JTwxylP6U9": {
    "title": "Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability",
    "volume": "poster",
    "abstract": "Neural networks are known to be susceptible to adversarial samples: small variations of natural examples crafted to deliberately mislead the models. While they can be easily generated using gradient-based techniques in digital and physical scenarios, they often differ greatly from the actual data distribution of natural images, resulting in a trade-off between strength and stealthiness. In this paper, we propose a novel framework dubbed Diffusion-Based Projected Gradient Descent (Diff-PGD) for generating realistic adversarial samples. By exploiting a gradient guided by a diffusion model, Diff-PGD ensures that adversarial samples remain close to the original data distribution while maintaining their effectiveness. Moreover, our framework can be easily customized for specific tasks such as digital attacks, physical-world attacks, and style-based attacks. Compared with existing methods for generating natural-style adversarial samples, our framework enables the separation of optimizing adversarial loss from other surrogate losses (e.g. content/smoothness/style loss), making it more stable and controllable. Finally, we demonstrate that the samples generated using Diff-PGD have better transferability and anti-purification power than traditional gradient-based methods",
    "checked": true,
    "id": "fcd9a82decb020e946e9adde4fab9ba055e8396b",
    "semantic_title": "diffusion-based adversarial sample generation for improved stealthiness and controllability",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=6e86TccKyQ": {
    "title": "Balancing Risk and Reward: A Batched-Bandit Strategy for Automated Phased Release",
    "volume": "poster",
    "abstract": "Phased releases are a common strategy in the technology industry for gradually releasing new products or updates through a sequence of A/B tests in which the number of treated units gradually grows until full deployment or deprecation. Performing phased releases in a principled way requires selecting the proportion of units assigned to the new release in a way that balances the risk of an adverse effect with the need to iterate and learn from the experiment rapidly. In this paper, we formalize this problem and propose an algorithm that automatically determines the release percentage at each stage in the schedule, balancing the need to control risk while maximizing ramp-up speed. Our framework models the challenge as a constrained batched bandit problem that ensures that our pre-specified experimental budget is not depleted with high probability. Our proposed algorithm leverages an adaptive Bayesian approach in which the maximal number of units assigned to the treatment is determined by the posterior distribution, ensuring that the probability of depleting the remaining budget is low. Notably, our approach analytically solves the ramp sizes by inverting probability bounds, eliminating the need for challenging rare-event Monte Carlo simulation. It only requires computing means and variances of outcome subsets, making it highly efficient and parallelizable",
    "checked": false,
    "id": "6b56fe36dcc68baafca624bb9de5eb2cbff3ba76",
    "semantic_title": "balancing risk and reward: an automated phased release strategy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tzxP9Rx0LV": {
    "title": "Knowledge Distillation Performs Partial Variance Reduction",
    "volume": "poster",
    "abstract": "Knowledge distillation is a popular approach for enhancing the performance of \"student\" models, with lower representational capacity, by taking advantage of more powerful \"teacher\" models. Despite its apparent simplicity, the underlying mechanics behind knowledge distillation (KD) are not yet fully understood. In this work, we shed new light on the inner workings of this method, by examining it from an optimization perspective. Specifically, we show that, in the context of linear and deep linear models, KD can be interpreted as a novel type of stochastic variance reduction mechanism. We provide a detailed convergence analysis of the resulting dynamics, which hold under standard assumptions for both strongly-convex and non-convex losses, showing that KD acts as a form of \\emph{partial variance reduction}, which can reduce the stochastic gradient noise, but may not eliminate it completely, depending on the properties of the ``teacher'' model. Our analysis puts further emphasis on the need for careful parametrization of KD, in particular w.r.t. the weighting of the distillation loss, and is validated empirically on both linear models and deep neural networks",
    "checked": true,
    "id": "9d4a352743790cb15725e1bdd903c5f558b63dd0",
    "semantic_title": "knowledge distillation performs partial variance reduction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Fp5uC6YHwe": {
    "title": "3D-IntPhys: Towards More Generalized 3D-grounded Visual Intuitive Physics under Challenging Scenes",
    "volume": "poster",
    "abstract": "Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models from videos of complex scenes with fluids. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, using which we can impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks acquired using color prior. This enables the proposed model to handle scenarios where accurate point estimation and tracking are hard or impossible. We generate datasets including three challenging scenarios involving fluid, granular materials, and rigid objects in the simulation. The datasets do not include any dense particle information so most previous 3D-based intuitive physics pipelines can barely deal with that. We show our model can make long-horizon future predictions by learning from raw images and significantly outperforms models that do not employ an explicit 3D representation space. We also show that once trained, our model can achieve strong generalization in complex scenarios under extrapolate settings",
    "checked": true,
    "id": "f3f1592ff282fbf58864c243510eb4a425f3fc70",
    "semantic_title": "3d-intphys: towards more generalized 3d-grounded visual intuitive physics under challenging scenes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9cF6RUwMe7": {
    "title": "Learning Space-Time Continuous Latent Neural PDEs from Partially Observed States",
    "volume": "poster",
    "abstract": "We introduce a novel grid-independent model for learning partial differential equations (PDEs) from noisy and partial observations on irregular spatiotemporal grids. We propose a space-time continuous latent neural PDE model with an efficient probabilistic framework and a novel encoder design for improved data efficiency and grid independence. The latent state dynamics are governed by a PDE model that combines the collocation method and the method of lines. We employ amortized variational inference for approximate posterior estimation and utilize a multiple shooting technique for enhanced training speed and stability. Our model demonstrates state-of-the-art performance on complex synthetic and real-world datasets, overcoming limitations of previous approaches and effectively handling partially-observed data. The proposed model outperforms recent methods, showing its potential to advance data-driven PDE modeling and enabling robust, grid-independent modeling of complex partially-observed dynamic processes across various domains",
    "checked": false,
    "id": "18fc14bf5e659e56f4c5cc3ccd593462dd28c383",
    "semantic_title": "learning space-time continuous neural pdes from partially observed states",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TAIYBdRb3C": {
    "title": "Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models",
    "volume": "poster",
    "abstract": "Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity — i.e., (possibly non-linear) dependencies between the features — has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that concurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and reducing variance in the feature importances",
    "checked": true,
    "id": "15118e8f0a09f4ed275e3cdae5968f1c93c37186",
    "semantic_title": "curve your enthusiasm: concurvity regularization in differentiable generalized additive models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K9M7XNS9BX": {
    "title": "Corruption-Robust Offline Reinforcement Learning with General Function Approximation",
    "volume": "poster",
    "abstract": "We investigate the problem of corruption robustness in offline reinforcement learning (RL) with general function approximation, where an adversary can corrupt each sample in the offline dataset, and the corruption level $\\zeta\\geq0$ quantifies the cumulative corruption amount over $n$ episodes and $H$ steps. Our goal is to find a policy that is robust to such corruption and minimizes the suboptimality gap with respect to the optimal policy for the uncorrupted Markov decision processes (MDPs). Drawing inspiration from the uncertainty-weighting technique from the robust online RL setting \\citep{he2022nearly,ye2022corruptionrobust}, we design a new uncertainty weight iteration procedure to efficiently compute on batched samples and propose a corruption-robust algorithm for offline RL. Notably, under the assumption of single policy coverage and the knowledge of $\\zeta$, our proposed algorithm achieves a suboptimality bound that is worsened by an additive factor of $\\mathcal O(\\zeta \\cdot (\\text CC(\\lambda,\\hat{\\mathcal F},\\mathcal Z_n^H))^{1/2} (C(\\hat{\\mathcal F},\\mu))^{-1/2} n^{-1})$ due to the corruption. Here $\\text CC(\\lambda,\\hat{\\mathcal F},\\mathcal Z_n^H)$ is the coverage coefficient that depends on the regularization parameter $\\lambda$, the confidence set $\\hat{\\mathcal F}$, and the dataset $\\mathcal Z_n^H$, and $C(\\hat{\\mathcal F},\\mu)$ is a coefficient that depends on $\\hat{\\mathcal F}$ and the underlying data distribution $\\mu$. When specialized to linear MDPs, the corruption-dependent error term reduces to $\\mathcal O(\\zeta d n^{-1})$ with $d$ being the dimension of the feature map, which matches the existing lower bound for corrupted linear MDPs. This suggests that our analysis is tight in terms of the corruption-dependent term",
    "checked": true,
    "id": "a1dea7d843d369d6317e8ce5783c0011943c4c99",
    "semantic_title": "corruption-robust offline reinforcement learning with general function approximation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NaYAsbv2jF": {
    "title": "Geometric Neural Diffusion Processes",
    "volume": "poster",
    "abstract": "Denoising diffusion models have proven to be a flexible and effective paradigm for generative modelling. Their recent extension to infinite dimensional Euclidean spaces has allowed for the modelling of stochastic processes. However, many problems in the natural sciences incorporate symmetries and involve data living in non-Euclidean spaces. In this work, we extend the framework of diffusion models to incorporate a series of geometric priors in infinite-dimension modelling. We do so by a) constructing a noising process which admits, as limiting distribution, a geometric Gaussian process that transforms under the symmetry group of interest, and b) approximating the score with a neural network that is equivariant w.r.t. this group. We show that with these conditions, the generative functional model admits the same symmetry. We demonstrate scalability and capacity of the model, using a novel Langevin-based conditional sampler, to fit complex scalar and vector fields, with Euclidean and spherical codomain, on synthetic and real-world weather data",
    "checked": true,
    "id": "f617ea37ed8955dfc8299876f4a490d39ad16225",
    "semantic_title": "geometric neural diffusion processes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=BGP5Vjt93A": {
    "title": "Predicting mutational effects on protein-protein binding via a side-chain diffusion probabilistic model",
    "volume": "poster",
    "abstract": "Many crucial biological processes rely on networks of protein-protein interactions. Predicting the effect of amino acid mutations on protein-protein binding is important in protein engineering, including therapeutic discovery. However, the scarcity of annotated experimental data on binding energy poses a significant challenge for developing computational approaches, particularly deep learning-based methods. In this work, we propose SidechainDiff, a novel representation learning-based approach that leverages unlabelled experimental protein structures. SidechainDiff utilizes a Riemannian diffusion model to learn the generative process of side-chain conformations and can also give the structural context representations of mutations on the protein-protein interface. Leveraging the learned representations, we achieve state-of-the-art performance in predicting the mutational effects on protein-protein binding. Furthermore, SidechainDiff is the first diffusion-based generative model for side-chains, distinguishing it from prior efforts that have predominantly focused on the generation of protein backbone structures",
    "checked": true,
    "id": "dfd128998d8f69beb10efe0ea2ecdc7aa8819551",
    "semantic_title": "predicting mutational effects on protein-protein binding via a side-chain diffusion probabilistic model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2NUFe4TZMS": {
    "title": "Gaussian Membership Inference Privacy",
    "volume": "poster",
    "abstract": "We propose a novel and practical privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. Consequently, $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). In particular, we derive a parametric family of $f$-MIP guarantees that we refer to as $\\mu$-Gaussian Membership Inference Privacy ($\\mu$-GMIP) by theoretically analyzing likelihood ratio-based membership inference attacks on stochastic gradient descent (SGD). Our analysis highlights that models trained with standard SGD already offer an elementary level of MIP. Additionally, we show how $f$-MIP can be amplified by adding noise to gradient updates. Our analysis further yields an analytical membership inference attack that offers two distinct advantages over previous approaches. First, unlike existing state-of-the-art attacks that require training hundreds of shadow models, our attack does not require any shadow model. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, we quantify how various hyperparameters (e.g., batch size, number of model parameters) and specific data characteristics determine an attacker's ability to accurately infer a point's membership in the training set. We demonstrate the effectiveness of our method on models trained on vision and tabular datasets",
    "checked": true,
    "id": "e33ae42f40196754c0189cd6e30c4c246da012df",
    "semantic_title": "gaussian membership inference privacy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wLFXTAWa5V": {
    "title": "An Efficient and Robust Framework for Approximate Nearest Neighbor Search with Attribute Constraint",
    "volume": "poster",
    "abstract": "This paper introduces an efficient and robust framework for hybrid query (HQ) processing, which combines approximate nearest neighbor search (ANNS) with attribute constraint. HQ aims to find objects that are similar to a feature vector and match some structured attributes. Existing methods handle ANNS and attribute filtering separately, leading to inefficiency and inaccuracy. Our framework, called native hybrid query (NHQ), builds a composite index based on proximity graph (PG) and applies joint pruning for HQ. We can easily adapt existing PGs to this framework for efficient HQ processing. We also propose two new navigable PGs (NPGs) with optimized edge selection and routing, which improve the overall ANNS performance. We implement five HQ methods based on the proposed NPGs and existing PGs in NHQ, and show that they outperform the state-of-the-art methods on 10 real-world datasets (up to 315$\\times$ faster with the same accuracy)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TOxpAwp0VE": {
    "title": "Multi-task Graph Neural Architecture Search with Task-aware Collaboration and Curriculum",
    "volume": "poster",
    "abstract": "Graph neural architecture search (GraphNAS) has shown great potential for automatically designing graph neural architectures for graph related tasks. However, multi-task GraphNAS capable of handling multiple tasks simultaneously has been largely unexplored in literature, posing great challenges to capture the complex relations and influences among different tasks. To tackle this problem, we propose a novel multi-task graph neural architecture search with task-aware collaboration and curriculum (MTGC3), which is able to simultaneously discover optimal architectures for different tasks and learn the collaborative relationships among different tasks in a joint manner. Specifically, we design the layer-wise disentangled supernet capable of managing multiple architectures in a unified framework, which combines with our proposed soft task-collaborative module to learn the transferability relationships between tasks. We further develop the task-wise curriculum training strategy to improve the architecture search procedure via reweighing the influence of different tasks based on task difficulties. Extensive experiments show that our proposed MTGC3 model achieves state-of-the-art performance against several baselines in multi-task scenarios, demonstrating its ability to discover effective architectures and capture the collaborative relationships for multiple tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3G2ec833mW": {
    "title": "Addressing Negative Transfer in Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion-based generative models have achieved remarkable success in various domains. It trains a shared model on denoising tasks that encompass different noise levels simultaneously, representing a form of multi-task learning (MTL). However, analyzing and improving diffusion models from an MTL perspective remains under-explored. In particular, MTL can sometimes lead to the well-known phenomenon of \\textit{negative transfer}, which results in the performance degradation of certain tasks due to conflicts between tasks. In this paper, we first aim to analyze diffusion training from an MTL standpoint, presenting two key observations: \\textbf{(O1)} the task affinity between denoising tasks diminishes as the gap between noise levels widens, and \\textbf{(O2)} negative transfer can arise even in diffusion training. Building upon these observations, we aim to enhance diffusion training by mitigating negative transfer. To achieve this, we propose leveraging existing MTL methods, but the presence of a huge number of denoising tasks makes this computationally expensive to calculate the necessary per-task loss or gradient. To address this challenge, we propose clustering the denoising tasks into small task clusters and applying MTL methods to them. Specifically, based on \\textbf{(O2)}, we employ interval clustering to enforce temporal proximity among denoising tasks within clusters. We show that interval clustering can be solved using dynamic programming, utilizing signal-to-noise ratio, timestep, and task affinity for clustering objectives. Through this, our approach addresses the issue of negative transfer in diffusion models by allowing for efficient computation of MTL methods. We validate the proposed clustering and its integration with MTL methods through various experiments, demonstrating improved sample quality of diffusion models. Our project page is available at https://gohyojun15.github.io/ANT_diffusion",
    "checked": true,
    "id": "121b3e27f81004451e399cf6177cb03347d7976d",
    "semantic_title": "addressing negative transfer in diffusion models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=UqYrYB3dp5": {
    "title": "Polynomially Over-Parameterized Convolutional Neural Networks Contain Structured Strong Winning Lottery Tickets",
    "volume": "poster",
    "abstract": "The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialised neural networks likely contain subnetworks that perform well without any training. Although unstructured pruning has been extensively studied in this context, its structured counterpart, which can deliver significant computational and memory efficiency gains, has been largely unexplored. One of the main reasons for this gap is the limitations of the underlying mathematical tools used in formal analyses of the SLTH. In this paper, we overcome these limitations: we leverage recent advances in the multidimensional generalisation of the Random Subset-Sum Problem and obtain a variant that admits the stochastic dependencies that arise when addressing structured pruning in the SLTH. We apply this result to prove, for a wide class of random Convolutional Neural Networks, the existence of structured subnetworks that can approximate any sufficiently smaller network. This result provides the first sub-exponential bound around the SLTH for structured pruning, opening up new avenues for further research on the hypothesis and contributing to the understanding of the role of over-parameterization in deep learning",
    "checked": true,
    "id": "b6bc1e5cf7589abc259e9eb18597564121b41364",
    "semantic_title": "polynomially over-parameterized convolutional neural networks contain structured strong winning lottery tickets",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MLIs5iRq4w": {
    "title": "Diff-Instruct: A Universal Approach for Transferring Knowledge From Pre-trained Diffusion Models",
    "volume": "poster",
    "abstract": "Due to the ease of training, ability to scale, and high sample quality, diffusion models (DMs) have become the preferred option for generative modeling, with numerous pre-trained models available for a wide variety of datasets. Containing intricate information about data distributions, pre-trained DMs are valuable assets for downstream applications. In this work, we consider learning from pre-trained DMs and transferring their knowledge to other generative models in a data-free fashion. Specifically, we propose a general framework called Diff-Instruct to instruct the training of arbitrary generative models as long as the generated samples are differentiable with respect to the model parameters. Our proposed Diff-Instruct is built on a rigorous mathematical foundation where the instruction process directly corresponds to minimizing a novel divergence we call Integral Kullback-Leibler (IKL) divergence. IKL is tailored for DMs by calculating the integral of the KL divergence along a diffusion process, which we show to be more robust in comparing distributions with misaligned supports. We also reveal non-trivial connections of our method to existing works such as DreamFusion, and generative adversarial training. To demonstrate the effectiveness and universality of Diff-Instruct, we consider two scenarios: distilling pre-trained diffusion models and refining existing GAN models. The experiments on distilling pre-trained diffusion models show that Diff-Instruct results in state-of-the-art single-step diffusion-based models. The experiments on refining GAN models show that the Diff-Instruct can consistently improve the pre-trained generators of GAN models across various settings",
    "checked": true,
    "id": "946fa1978b570407e082c61ed8334822f3da1740",
    "semantic_title": "diff-instruct: a universal approach for transferring knowledge from pre-trained diffusion models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=QrB38MAAEP": {
    "title": "Towards a Unified Framework of Contrastive Learning for Disentangled Representations",
    "volume": "poster",
    "abstract": "Contrastive learning has recently emerged as a promising approach for learning data representations that discover and disentangle the explanatory factors of the data. Previous analyses of such approaches have largely focused on individual contrastive losses, such as noise-contrastive estimation (NCE) and InfoNCE, and rely on specific assumptions about the data generating process. This paper extends the theoretical guarantees for disentanglement to a broader family of contrastive methods, while also relaxing the assumptions about the data distribution. Specifically, we prove identifiability of the true latents for four contrastive losses studied in this paper, without imposing common independence assumptions. The theoretical findings are validated on several benchmark datasets. Finally, practical limitations of these methods are also investigated",
    "checked": true,
    "id": "1d3ae620721e26ea8eeed833f64a6a5d6ca99689",
    "semantic_title": "towards a unified framework of contrastive learning for disentangled representations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CJY7NEXVwC": {
    "title": "A Theory of Transfer-Based Black-Box Attacks: Explanation and Implications",
    "volume": "poster",
    "abstract": "Transfer-based attacks are a practical method of black-box adversarial attacks, in which the attacker aims to craft adversarial examples from a source (surrogate) model that is transferable to the target model. A wide range of empirical works has tried to explain the transferability of adversarial examples from different angles. However, these works only provide ad hoc explanations without quantitative analyses. The theory behind transfer-based attacks remains a mystery. This paper studies transfer-based attacks under a unified theoretical framework. We propose an explanatory model, called the manifold attack model, that formalizes popular beliefs and explains the existing empirical results. Our model explains why adversarial examples are transferable even when the source model is inaccurate. Moreover, our model implies that the existence of transferable adversarial examples depends on the \"curvature\" of the data manifold, which quantitatively explains why the success rates of transfer-based attacks are hard to improve. We also discuss the expressive power and the possible extensions of our model in general applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CuHymkHRus": {
    "title": "Convolution Monge Mapping Normalization for learning on sleep data",
    "volume": "poster",
    "abstract": "In many machine learning applications on signals and biomedical data, especially electroencephalogram (EEG), one major challenge is the variability of the data across subjects, sessions, and hardware devices. In this work, we propose a new method called Convolutional Monge Mapping Normalization ($\\texttt{CMMN}$), which consists in filtering the signals in order to adapt their power spectrum density (PSD) to a Wasserstein barycenter estimated on training data. $\\texttt{CMMN}$ relies on novel closed-form solutions for optimal transport mappings and barycenters and provides individual test time adaptation to new data without needing to retrain a prediction model. Numerical experiments on sleep EEG data show that $\\texttt{CMMN}$ leads to significant and consistent performance gains independent from the neural network architecture when adapting between subjects, sessions, and even datasets collected with different hardware. Notably our performance gain is on par with much more numerically intensive Domain Adaptation (DA) methods and can be used in conjunction with those for even better performances",
    "checked": false,
    "id": "de16813dba47cb4b9a1ca61ad0f45bb304a86963",
    "semantic_title": "convolutional monge mapping normalization for learning on sleep data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=etd0ebzGOG": {
    "title": "VPP: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation",
    "volume": "poster",
    "abstract": "Conditional 3D generation is undergoing a significant advancement, enabling the free creation of 3D content from inputs such as text or 2D images. However, previous approaches have suffered from low inference efficiency, limited generation categories, and restricted downstream applications. In this work, we revisit the impact of different 3D representations on generation quality and efficiency. We propose a progressive generation method through Voxel-Point Progressive Representation (VPP). VPP leverages structured voxel representation in the proposed Voxel Semantic Generator and the sparsity of unstructured point representation in the Point Upsampler, enabling efficient generation of multi-category objects. VPP can generate high-quality 8K point clouds within 0.2 seconds. Additionally, the masked generation Transformer allows for various 3D downstream tasks, such as generation, editing, completion, and pre-training. Extensive experiments demonstrate that VPP efficiently generates high-fidelity and diverse 3D shapes across different categories, while also exhibiting excellent representation transfer performance. Codes will be released at https://github.com/qizekun/VPP",
    "checked": true,
    "id": "7da6bec621f443d33ba1ef7625cd8abb57d35629",
    "semantic_title": "vpp: efficient conditional 3d generation via voxel-point progressive representation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=gLwjBDsE3G": {
    "title": "Triangulation Residual Loss for Data-efficient 3D Pose Estimation",
    "volume": "poster",
    "abstract": "This paper presents Triangulation Residual loss (TR loss) for multiview 3D pose estimation in a data-efficient manner. Existing 3D supervised models usually require large-scale 3D annotated datasets, but the amount of existing data is still insufficient to train supervised models to achieve ideal performance, especially for animal pose estimation. To employ unlabeled multiview data for training, previous epipolar-based consistency provides a self-supervised loss that considers only the local consistency in pairwise views, resulting in limited performance and heavy calculations. In contrast, TR loss enables self-supervision with global multiview geometric consistency. Starting from initial 2D keypoint estimates, the TR loss can fine-tune the corresponding 2D detector without 3D supervision by simply minimizing the smallest singular value of the triangulation matrix in an end-to-end fashion. Our method achieves the state-of-the-art 25.8mm MPJPE and competitive 28.7mm MPJPE with only 5\\% 2D labeled training data on the Human3.6M dataset. Experiments on animals such as mice demonstrate our TR loss's data-efficient training ability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UBBeUjTja8": {
    "title": "Cross-modal Active Complementary Learning with Self-refining Correspondence",
    "volume": "poster",
    "abstract": "Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities. However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop. Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise. To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods. Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous supervision, leading to theoretically and experimentally demonstrated robustness against NC. SCC utilizes multiple self-refining processes with momentum correction to enlarge the receptive field for correcting correspondences, thereby alleviating error accumulation and achieving accurate and stable corrections. We carry out extensive experiments on three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify the superior robustness of our CRCL against synthetic and real-world noisy correspondences",
    "checked": true,
    "id": "85b4a40642184b060e2116eec78add8dd27727ec",
    "semantic_title": "cross-modal active complementary learning with self-refining correspondence",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=37cADkATD0": {
    "title": "Explore to Generalize in Zero-Shot RL",
    "volume": "poster",
    "abstract": "We study zero-shot generalization in reinforcement learning - optimizing a policy on a set of training tasks to perform well on a similar but unseen test task. To mitigate overfitting, previous work explored different notions of invariance to the task. However, on problems such as the ProcGen Maze, an adequate solution that is invariant to the task visualization does not exist, and therefore invariance-based approaches fail. Our insight is that learning a policy that effectively $\\textit{explores}$ the domain is harder to memorize than a policy that maximizes reward for a specific task, and therefore we expect such learned behavior to generalize well; we indeed demonstrate this empirically on several domains that are difficult for invariance-based approaches. Our $\\textit{Explore to Generalize}$ algorithm (ExpGen) builds on this insight: we train an additional ensemble of agents that optimize reward. At test time, either the ensemble agrees on an action, and we generalize well, or we take exploratory actions, which generalize well and drive us to a novel part of the state space, where the ensemble may potentially agree again. We show that our approach is the state-of-the-art on tasks of the ProcGen challenge that have thus far eluded effective generalization, yielding a success rate of 83% on the Maze task and 74% on Heist with $200$ training levels. ExpGen can also be combined with an invariance based approach to gain the best of both worlds, setting new state-of-the-art results on ProcGen. Code available at [https://github.com/EvZissel/expgen](https://github.com/EvZissel/expgen)",
    "checked": true,
    "id": "39550f6205931166a913489336fb35530fb81b0a",
    "semantic_title": "explore to generalize in zero-shot rl",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xMgO04HDOS": {
    "title": "Hierarchical Multi-Agent Skill Discovery",
    "volume": "poster",
    "abstract": "Skill discovery has shown significant progress in unsupervised reinforcement learning. This approach enables the discovery of a wide range of skills without any extrinsic reward, which can be effectively combined to tackle complex tasks. However, such unsupervised skill learning has not been well applied to multi-agent reinforcement learning (MARL) due to two primary challenges. One is how to learn skills not only for the individual agents but also for the entire team, and the other is how to coordinate the skills of different agents to accomplish multi-agent tasks. To address these challenges, we present Hierarchical Multi-Agent Skill Discovery (HMASD), a two-level hierarchical algorithm for discovering both team and individual skills in MARL. The high-level policy employs a transformer structure to realize sequential skill assignment, while the low-level policy learns to discover valuable team and individual skills. We evaluate HMASD on sparse reward multi-agent benchmarks, and the results show that HMASD achieves significant performance improvements compared to strong MARL baselines",
    "checked": false,
    "id": "be51afa5ab8ba4aaad43ac1c31691b3fb05937aa",
    "semantic_title": "multi-agent deep covering skill discovery",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VzLBMkc7tB": {
    "title": "Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage",
    "volume": "poster",
    "abstract": "We study distributionally robust offline reinforcement learning (RL), which seeks to find an optimal robust policy purely from an offline dataset that can perform well in perturbed environments. We propose a generic algorithm framework Doubly Pessimistic Model-based Policy Optimization ($\\texttt{P}^2\\texttt{MPO}$) for robust offline RL, which features a novel combination of a flexible model estimation subroutine and a doubly pessimistic policy optimization step. Here the double pessimism principle is crucial to overcome the distribution shift incurred by i) the mismatch between behavior policy and the family of target policies; and ii) the perturbation of the nominal model. Under certain accuracy assumptions on the model estimation subroutine, we show that $\\texttt{P}^2\\texttt{MPO}$ is provably sample-efficient with robust partial coverage data, which means that the offline dataset has good coverage of the distributions induced by the optimal robust policy and perturbed models around the nominal model. By tailoring specific model estimation subroutines for concrete examples including tabular Robust Markov Decision Process (RMDP), factored RMDP, and RMDP with kernel and neural function approximations, we show that $\\texttt{P}^2\\texttt{MPO}$ enjoys a $\\tilde{\\mathcal{O}}(n^{-1/2})$ convergence rate, where $n$ is the number of trajectories in the offline dataset. Notably, these models, except for the tabular case, are first identified and proven tractable by this paper. To the best of our knowledge, we first propose a general learning principle --- double pessimism --- for robust offline RL and show that it is provably efficient in the context of general function approximations",
    "checked": true,
    "id": "db9bc8e393c5f49c04af7d9cac7a6ff6435d8587",
    "semantic_title": "double pessimism is provably efficient for distributionally robust offline reinforcement learning: generic algorithm and robust partial coverage",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=jhs8F63xI6": {
    "title": "Adaptive Online Replanning with Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion models have risen a promising approach to data-driven planning, and have demonstrated impressive robotic control, reinforcement learning, and video planning performance. Given an effective planner, an important question to consider is replanning -- when given plans should be regenerated due to both action execution error and external environment changes. Direct plan execution, without replanning, is problematic as errors from individual actions rapidly accumulate and environments are partially observable and stochastic. Simultaneously, replanning at each timestep incurs a substantial computational cost, and may prevent successful task execution, as different generated plans prevent consistent progress to any particular goal. In this paper, we explore how we may effectively replan with diffusion models. We propose a principled approach to determine when to replan, based on the diffusion model's estimated likelihood of existing generated plans. We further present an approach to replan existing trajectories to ensure that new plans follow the same goal state as the original trajectory, which may efficiently bootstrap off previously generated plans. We illustrate how a combination of our proposed additions significantly improves the performance of diffusion planners leading to 38\\% gains over past diffusion planning approaches on Maze2D and further enables handling of stochastic and long-horizon robotic control tasks",
    "checked": true,
    "id": "481aabfd4a0c07c1e6be75c332e17b64896fb5c1",
    "semantic_title": "adaptive online replanning with diffusion models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WIrZh2XxLT": {
    "title": "Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning",
    "volume": "poster",
    "abstract": "In the field of multi-task reinforcement learning, the modular principle, which involves specializing functionalities into different modules and combining them appropriately, has been widely adopted as a promising approach to prevent the negative transfer problem that performance degradation due to conflicts between tasks. However, most of the existing multi-task RL methods only combine shared modules at the task level, ignoring that there may be conflicts within the task. In addition, these methods do not take into account that without constraints, some modules may learn similar functions, resulting in restricting the model's expressiveness and generalization capability of modular methods. In this paper, we propose the Contrastive Modules with Temporal Attention(CMTA) method to address these limitations. CMTA constrains the modules to be different from each other by contrastive learning and combining shared modules at a finer granularity than the task level with temporal attention, alleviating the negative transfer within the task and improving the generalization ability and the performance for multi-task RL. We conducted the experiment on Meta-World, a multi-task RL benchmark containing various robotics manipulation tasks. Experimental results show that CMTA outperforms learning each task individually for the first time and achieves substantial performance improvements over the baselines",
    "checked": true,
    "id": "3dcfce427f3ab192cb8667c73e11ec4e7a403b62",
    "semantic_title": "contrastive modules with temporal attention for multi-task reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H5pwAeYAun": {
    "title": "Failure-Aware Gaussian Process Optimization with Regret Bounds",
    "volume": "poster",
    "abstract": "Real-world optimization problems often require black-box optimization with observation failure, where we can obtain the objective function value if we succeed, otherwise, we can only obtain a fact of failure. Moreover, this failure region can be complex by several latent constraints, whose number is also unknown. For this problem, we propose a failure-aware Gaussian process upper confidence bound (F-GP-UCB), which only requires a mild assumption for the observation failure that an optimal solution lies on an interior of a feasible region. Furthermore, we show that the number of successful observations grows linearly, by which we provide the first regret upper bounds and the convergence of F-GP-UCB. We demonstrate the effectiveness of F-GP-UCB in several benchmark functions, including the simulation function motivated by material synthesis experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1bTG4sJ7tN": {
    "title": "A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes",
    "volume": "poster",
    "abstract": "The proximal policy optimization (PPO) algorithm stands as one of the most prosperous methods in the field of reinforcement learning (RL). Despite its success, the theoretical understanding of PPO remains deficient. Specifically, it is unclear whether PPO or its optimistic variants can effectively solve linear Markov decision processes (MDPs), which are arguably the simplest models in RL with function approximation. To bridge this gap, we propose an optimistic variant of PPO for episodic adversarial linear MDPs with full-information feedback, and establish a $\\tilde{\\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for it. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each episode, and $K$ is the number of episodes. Compared with existing policy-based algorithms, we achieve the state-of-the-art regret bound in both stochastic linear MDPs and adversarial linear MDPs with full information. Additionally, our algorithm design features a novel multi-batched updating mechanism and the theoretical analysis utilizes a new covering number argument of value and policy classes, which might be of independent interest",
    "checked": true,
    "id": "bfce86bcdce722c175cd07c8cb0203a7bb0b5711",
    "semantic_title": "a theoretical analysis of optimistic proximal policy optimization in linear markov decision processes",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=UgomCjCWjC": {
    "title": "Multi-Agent First Order Constrained Optimization in Policy Space",
    "volume": "poster",
    "abstract": "In the realm of multi-agent reinforcement learning (MARL), achieving high performance is crucial for a successful multi-agent system. Meanwhile, the ability to avoid unsafe actions is becoming an urgent and imperative problem to solve for real-life applications. Whereas, it is still challenging to develop a safety-aware method for multi-agent systems in MARL. In this work, we introduce a novel approach called Multi-Agent First Order Constrained Optimization in Policy Space (MAFOCOPS), which effectively addresses the dual objectives of attaining satisfactory performance and enforcing safety constraints. Using data generated from the current policy, MAFOCOPS first finds the optimal update policy by solving a constrained optimization problem in the nonparameterized policy space. Then, the update policy is projected back into the parametric policy space to achieve a feasible policy. Notably, our method is first-order in nature, ensuring the ease of implementation, and exhibits an approximate upper bound on the worst-case constraint violation. Empirical results show that our approach achieves remarkable performance while satisfying safe constraints on several safe MARL benchmarks",
    "checked": false,
    "id": "0600045b540747f135d1c7cde6cf511e4aea086a",
    "semantic_title": "sample-efficient multi-agent rl: an optimization perspective",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AGMVzMGcGP": {
    "title": "Active Bipartite Ranking",
    "volume": "poster",
    "abstract": "In this paper, we develop an active learning framework for the bipartite ranking problem. Motivated by numerous applications, ranging from supervised anomaly detection to credit-scoring through the design of medical diagnosis support systems, and usually formulated as the problem of optimizing (a scalar summary of) the ROC curve, bipartite ranking has been the subject of much attention in the passive context. Various dedicated algorithms have been recently proposed and studied by the machine-learning community. In contrast, active bipartite ranking rule is poorly documented in the literature. Due to its global nature, a strategy for labeling sequentially data points that are difficult to rank w.r.t. to the others is required. This learning task is much more complex than binary classification, for which many active algorithms have been designed. It is the goal of this article to provide a rigorous formulation of such a selective sampling approach. We propose a dedicated algorithm, referred to as active-rank, which aims to minimise the distance between the ROC curve of the ranking function built and the optimal one, w.r.t. the sup norm. We show that, for a fixed confidence level $\\epsilon$ and probability $\\delta$, active-rank is PAC$(\\epsilon,\\delta)$. In addition, we provide a problem dependent upper bound on the expected sampling time of active-rank and also demonstrate a problem dependent lower bound on the expected sampling time of any PAC$(\\epsilon,\\delta)$ algorithm. Beyond the theoretical analysis carried out, numerical results are presented, providing strong empirical evidence of the performance of the algorithm proposed, which compares favorably with more naive approaches",
    "checked": false,
    "id": "8dfd28d9cdccab6c2b1e095d644fbf3ce28d962c",
    "semantic_title": "fast neural ranking on bipartite graph indices",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=MOAHXRzHhm": {
    "title": "Enhancing Adversarial Robustness via Score-Based Optimization",
    "volume": "poster",
    "abstract": "Adversarial attacks have the potential to mislead deep neural network classifiers by introducing slight perturbations. Developing algorithms that can mitigate the effects of these attacks is crucial for ensuring the safe use of artificial intelligence. Recent studies have suggested that score-based diffusion models are effective in adversarial defenses. However, existing diffusion-based defenses rely on the sequential simulation of the reversed stochastic differential equations of diffusion models, which are computationally inefficient and yield suboptimal results. In this paper, we introduce a novel adversarial defense scheme named ScoreOpt, which optimizes adversarial samples at test-time, towards original clean data in the direction guided by score-based priors. We conduct comprehensive experiments on multiple datasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results demonstrate that our approach outperforms existing adversarial defenses in terms of both robustness performance and inference speed",
    "checked": true,
    "id": "c2a4a145bb5a17113756dd737322de652d64edc0",
    "semantic_title": "enhancing adversarial robustness via score-based optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vHSQTEIFkp": {
    "title": "Accelerated Zeroth-order Method for Non-Smooth Stochastic Convex Optimization Problem with Infinite Variance",
    "volume": "poster",
    "abstract": "In this paper, we consider non-smooth stochastic convex optimization with two function evaluations per round under infinite noise variance. In the classical setting when noise has finite variance, an optimal algorithm, built upon the batched accelerated gradient method, was proposed in (Gasnikov et. al., 2022). This optimality is defined in terms of iteration and oracle complexity, as well as the maximal admissible level of adversarial noise. However, the assumption of finite variance is burdensome and it might not hold in many practical scenarios. To address this, we demonstrate how to adapt a refined clipped version of the accelerated gradient (Stochastic Similar Triangles) method from (Sadiev et al., 2023) for a two-point zero-order oracle. This adaptation entails extending the batching technique to accommodate infinite variance — a non-trivial task that stands as a distinct contribution of this paper",
    "checked": true,
    "id": "c439fe3afcd9cf8a5ed946583dbc8a378a2308d3",
    "semantic_title": "accelerated zeroth-order method for non-smooth stochastic convex optimization problem with infinite variance",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=crZlhMnfeO": {
    "title": "RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency",
    "volume": "poster",
    "abstract": "In this paper, we study the problem of continuous 3D shape representations. The majority of existing successful methods are coordinate-based implicit neural representations. However, they are inefficient to render novel views or recover explicit surface points. A few works start to formulate 3D shapes as ray-based neural functions, but the learned structures are inferior due to the lack of multi-view geometry consistency. To tackle these challenges, we propose a new framework called RayDF. It consists of three major components: 1) the simple ray-surface distance field, 2) the novel dual-ray visibility classifier, and 3) a multi-view consistency optimization module to drive the learned ray-surface distances to be multi-view geometry consistent. We extensively evaluate our method on three public datasets, demonstrating remarkable performance in 3D surface point reconstruction on both synthetic and challenging real-world 3D scenes, clearly surpassing existing coordinate-based and ray-based baselines. Most notably, our method achieves a 1000x faster speed than coordinate-based methods to render an 800x800 depth image, showing the superiority of our method for 3D shape representation. Our code and data are available at https://github.com/vLAR-group/RayDF",
    "checked": true,
    "id": "b17f5381d09444f15a9740cd4ed28dc9c329cfec",
    "semantic_title": "raydf: neural ray-surface distance fields with multi-view consistency",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UOB1UgPjuG": {
    "title": "Class-Distribution-Aware Pseudo-Labeling for Semi-Supervised Multi-Label Learning",
    "volume": "poster",
    "abstract": "Pseudo-labeling has emerged as a popular and effective approach for utilizing unlabeled data. However, in the context of semi-supervised multi-label learning (SSMLL), conventional pseudo-labeling methods encounter difficulties when dealing with instances associated with multiple labels and an unknown label count. These limitations often result in the introduction of false positive labels or the neglect of true positive ones. To overcome these challenges, this paper proposes a novel solution called Class-Aware Pseudo-Labeling (CAP) that performs pseudo-labeling in a class-aware manner. The proposed approach introduces a regularized learning framework incorporating class-aware thresholds, which effectively control the assignment of positive and negative pseudo-labels for each class. Notably, even with a small proportion of labeled examples, our observations demonstrate that the estimated class distribution serves as a reliable approximation. Motivated by this finding, we develop a class-distribution-aware thresholding strategy to ensure the alignment of pseudo-label distribution with the true distribution. The correctness of the estimated class distribution is theoretically verified, and a generalization error bound is provided for our proposed method. Extensive experiments on multiple benchmark datasets confirm the efficacy of CAP in addressing the challenges of SSMLL problems",
    "checked": false,
    "id": "8140e51258eb15c52a328689cec1318d00e5209e",
    "semantic_title": "class-distribution-aware pseudo labeling for semi-supervised multi-label learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6ljXBlojde": {
    "title": "Mask Propagation for Efficient Video Semantic Segmentation",
    "volume": "poster",
    "abstract": "Video Semantic Segmentation (VSS) involves assigning a semantic label to each pixel in a video sequence. Prior work in this field has demonstrated promising results by extending image semantic segmentation models to exploit temporal relationships across video frames; however, these approaches often incur significant computational costs. In this paper, we propose an efficient mask propagation framework for VSS, called MPVSS. Our approach first employs a strong query-based image segmentor on sparse key frames to generate accurate binary masks and class predictions. We then design a flow estimation module utilizing the learned queries to generate a set of segment-aware flow maps, each associated with a mask prediction from the key frame. Finally, the mask-flow pairs are warped to serve as the mask predictions for the non-key frames. By reusing predictions from key frames, we circumvent the need to process a large volume of video frames individually with resource-intensive segmentors, alleviating temporal redundancy and significantly reducing computational costs. Extensive experiments on VSPW and Cityscapes demonstrate that our mask propagation framework achieves SOTA accuracy and efficiency trade-offs. For instance, our best model with Swin-L backbone outperforms the SOTA MRCFA using MiT-B5 by 4.0% mIoU, requiring only 26% FLOPs on the VSPW dataset. Moreover, our framework reduces up to 4× FLOPs compared to the per-frame Mask2Former baseline with only up to 2% mIoU degradation on the Cityscapes validation set. Code is available at https://github.com/ziplab/MPVSS",
    "checked": true,
    "id": "fdc2c8da623008528a5b21fc18442a614135d73e",
    "semantic_title": "mask propagation for efficient video semantic segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AGVBqJuL0T": {
    "title": "Fantastic Robustness Measures: The Secrets of Robust Generalization",
    "volume": "poster",
    "abstract": "Adversarial training has become the de-facto standard method for improving the robustness of models against adversarial examples. However, robust overfitting remains a significant challenge, leading to a large gap between the robustness on the training and test datasets. To understand and improve robust generalization, various measures have been developed, including margin, smoothness, and flatness-based measures. In this study, we present a large-scale analysis of robust generalization to empirically verify whether the relationship between these measures and robust generalization remains valid in diverse settings. We demonstrate when and how these measures effectively capture the robust generalization gap by comparing over 1,300 models trained on CIFAR-10 under the $L_\\infty$ norm and further validate our findings through an evaluation of more than 100 models from RobustBench across CIFAR-10, CIFAR-100, and ImageNet. We hope this work can help the community better understand adversarial robustness and motivate the development of more robust defense methods against adversarial attacks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cCYvakU5Ek": {
    "title": "The geometry of hidden representations of large transformer models",
    "volume": "poster",
    "abstract": "Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language taskand image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be observed across many models trained on diverse datasets. Based on our findings, we point out an explicit strategy to identify, without supervision, the layers that maximize semantic content: representations at intermediate layers corresponding to a relative minimum of the ID profile are more suitable for downstream learning tasks",
    "checked": true,
    "id": "43d8ef2c8d361aaec01131104a287fcc45ccab55",
    "semantic_title": "the geometry of hidden representations of large transformer models",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=AYLlZMmUbo": {
    "title": "Two Heads are Better Than One: A Simple Exploration Framework for Efficient Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "Exploration strategy plays an important role in reinforcement learning, especially in sparse-reward tasks. In cooperative multi-agent reinforcement learning~(MARL), designing a suitable exploration strategy is much more challenging due to the large state space and the complex interaction among agents. Currently, mainstream exploration methods in MARL either contribute to exploring the unfamiliar states which are large and sparse, or measuring the interaction among agents with high computational costs. We found an interesting phenomenon that different kinds of exploration plays a different role in different MARL scenarios, and choosing a suitable one is often more effective than designing an exquisite algorithm. In this paper, we propose a exploration method that incorporate the \\underline{C}uri\\underline{O}sity-based and \\underline{IN}fluence-based exploration~(COIN) which is simple but effective in various situations. First, COIN measures the influence of each agent on the other agents based on mutual information theory and designs it as intrinsic rewards which are applied to each individual value function. Moreover, COIN computes the curiosity-based intrinsic rewards via prediction errors which are added to the extrinsic reward. For integrating the two kinds of intrinsic rewards, COIN utilizes a novel framework in which they complement each other and lead to a sufficient and effective exploration on cooperative MARL tasks. We perform extensive experiments on different challenging benchmarks, and results across different scenarios show the superiority of our method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bTidcHIK2t": {
    "title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents",
    "volume": "poster",
    "abstract": "Deep reinforcement learning (RL) has achieved remarkable success in solving complex tasks through its integration with deep neural networks (DNNs) as function approximators. However, the reliance on DNNs has introduced a new challenge called primacy bias, whereby these function approximators tend to prioritize early experiences, leading to overfitting. To alleviate this bias, a reset method has been proposed, which involves periodic resets of a portion or the entirety of a deep RL agent while preserving the replay buffer. However, the use of this method can result in performance collapses after executing the reset, raising concerns from the perspective of safe RL and regret minimization. In this paper, we propose a novel reset-based method that leverages deep ensemble learning to address the limitations of the vanilla reset method and enhance sample efficiency. The effectiveness of the proposed method is validated through various experiments including those in the domain of safe RL. Numerical results demonstrate its potential for real-world applications requiring high sample efficiency and safety considerations",
    "checked": true,
    "id": "638c99c1cc5da348239a6e5f90bb212e8b154bb4",
    "semantic_title": "sample-efficient and safe deep reinforcement learning via reset deep ensemble agents",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yhBFG9Y85R": {
    "title": "Visual Programming for Step-by-Step Text-to-Image Generation and Evaluation",
    "volume": "poster",
    "abstract": "As large language models have demonstrated impressive performance in many domains, recent works have adopted language models (LMs) as controllers of visual modules for vision-and-language tasks. While existing work focuses on equipping LMs with visual understanding, we propose two novel interpretable/explainable visual programming frameworks for text-to-image (T2I) generation and evaluation. First, we introduce VPGen, an interpretable step-by-step T2I generation framework that decomposes T2I generation into three steps: object/count generation, layout generation, and image generation. We employ an LM to handle the first two steps (object/count generation and layout generation), by finetuning it on text-layout pairs. Our step-by-step T2I generation framework provides stronger spatial control than end-to-end models, the dominant approach for this task. Furthermore, we leverage the world knowledge of pretrained LMs, overcoming the limitation of previous layout-guided T2I works that can only handle predefined object classes. We demonstrate that our VPGen has improved control in counts/spatial relations/scales of objects than state-of-the-art T2I generation models. Second, we introduce VPEval, an interpretable and explainable evaluation framework for T2I generation based on visual programming. Unlike previous T2I evaluations with a single scoring model that is accurate in some skills but unreliable in others, VPEval produces evaluation programs that invoke a set of visual modules that are experts in different skills, and also provides visual+textual explanations of the evaluation results. Our analysis shows that VPEval provides a more human-correlated evaluation for skill-specific and open-ended prompts than widely used single model-based evaluation. We hope that our work encourages future progress on interpretable/explainable generation and evaluation for T2I models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=prIwYTU9PV": {
    "title": "Distributional Pareto-Optimal Multi-Objective Reinforcement Learning",
    "volume": "poster",
    "abstract": "Multi-objective reinforcement learning (MORL) has been proposed to learn control policies over multiple competing objectives with each possible preference over returns. However, current MORL algorithms fail to account for distributional preferences over the multi-variate returns, which are particularly important in real-world scenarios such as autonomous driving. To address this issue, we extend the concept of Pareto-optimality in MORL into distributional Pareto-optimality, which captures the optimality of return distributions, rather than the expectations. Our proposed method, called Distributional Pareto-Optimal Multi-Objective Reinforcement Learning~(DPMORL), is capable of learning distributional Pareto-optimal policies that balance multiple objectives while considering the return uncertainty. We evaluated our method on several benchmark problems and demonstrated its effectiveness in discovering distributional Pareto-optimal policies and satisfying diverse distributional preferences compared to existing MORL methods",
    "checked": true,
    "id": "bd74dff05ea32996c8be5ca7ff516fe6999c2b88",
    "semantic_title": "distributional pareto-optimal multi-objective reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=muVKSb8gi5": {
    "title": "Reliable Off-Policy Learning for Dosage Combinations",
    "volume": "poster",
    "abstract": "Decision-making in personalized medicine such as cancer therapy or critical care must often make choices for dosage combinations, i.e., multiple continuous treatments. Existing work for this task has modeled the effect of multiple treatments independently, while estimating the joint effect has received little attention but comes with non-trivial challenges. In this paper, we propose a novel method for reliable off-policy learning for dosage combinations. Our method proceeds along three steps: (1) We develop a tailored neural network that estimates the individualized dose-response function while accounting for the joint effect of multiple dependent dosages. (2) We estimate the generalized propensity score using conditional normalizing flows in order to detect regions with limited overlap in the shared covariate-treatment space. (3) We present a gradient-based learning algorithm to find the optimal, individualized dosage combinations. Here, we ensure reliable estimation of the policy value by avoiding regions with limited overlap. We finally perform an extensive evaluation of our method to show its effectiveness. To the best of our knowledge, ours is the first work to provide a method for reliable off-policy learning for optimal dosage combinations",
    "checked": true,
    "id": "a8d9620ed4f4fe26ca5bafc5110feabd73f8cc36",
    "semantic_title": "reliable off-policy learning for dosage combinations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=TVD3wNVH9A": {
    "title": "Bounce: Reliable High-Dimensional Bayesian Optimization for Combinatorial and Mixed Spaces",
    "volume": "poster",
    "abstract": "Impactful applications such as materials discovery, hardware design, neural architecture search, or portfolio optimization require optimizing high-dimensional black-box functions with mixed and combinatorial input spaces. While Bayesian optimization has recently made significant progress in solving such problems, an in-depth analysis reveals that the current state-of-the-art methods are not reliable. Their performances degrade substantially when the unknown optima of the function do not have a certain structure. To fill the need for a reliable algorithm for combinatorial and mixed spaces, this paper proposes Bounce that relies on a novel map of various variable types into nested embeddings of increasing dimensionality. Comprehensive experiments show that Bounce reliably achieves and often even improves upon state-of-the-art performance on a variety of high-dimensional problems",
    "checked": false,
    "id": "b886db66e0b1a138923434657b82f0fd8a17275d",
    "semantic_title": "bounce: a reliable bayesian optimization algorithm for combinatorial and mixed spaces",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9cQzO3rXgR": {
    "title": "Diffusion Representation for Asymmetric Kernels via Magnetic Transform",
    "volume": "poster",
    "abstract": "As a nonlinear dimension reduction technique, the diffusion map (DM) has been widely used. In DM, kernels play an important role for capturing the nonlinear relationship of data. However, only symmetric kernels can be used now, which prevents the use of DM in directed graphs, trophic networks, and other real-world scenarios where the intrinsic and extrinsic geometries in data are asymmetric. A promising technique is the magnetic transform which converts an asymmetric matrix to a Hermitian one. However, we are facing essential problems, including how diffusion distance could be preserved and how divergence could be avoided during diffusion process. Via theoretical proof, we successfully establish a diffusion representation framework with the magnetic transform, named MagDM. The effectiveness and robustness for dealing data endowed with asymmetric proximity are demonstrated on three synthetic datasets and two trophic networks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TStMZH3Xqx": {
    "title": "Context Shift Reduction for Offline Meta-Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline datasets to enhance the agent's generalization ability on unseen tasks. However, the context shift problem arises due to the distribution discrepancy between the contexts used for training (from the behavior policy) and testing (from the exploration policy). The context shift problem leads to incorrect task inference and further deteriorates the generalization ability of the meta-policy. Existing OMRL methods either overlook this problem or attempt to mitigate it with additional information. In this paper, we propose a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem with only offline datasets. The key insight of CSRO is to minimize the influence of policy in context during both the meta-training and meta-test phases. During meta-training, we design a max-min mutual information representation learning mechanism to diminish the impact of the behavior policy on task representation. In the meta-test phase, we introduce the non-prior context collection strategy to reduce the effect of the exploration policy. Experimental results demonstrate that CSRO significantly reduces the context shift and improves the generalization ability, surpassing previous methods across various challenging domains",
    "checked": true,
    "id": "8f9c2761662a3fab59fed11f22d3b2cfe5cd7f8e",
    "semantic_title": "context shift reduction for offline meta-reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tn9Dldam9L": {
    "title": "Add and Thin: Diffusion for Temporal Point Processes",
    "volume": "poster",
    "abstract": "Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive ADD-THIN, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting",
    "checked": true,
    "id": "eddcc9f77bde8be2cc4d23e7a8282b619b3cbd26",
    "semantic_title": "add and thin: diffusion for temporal point processes",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0P6uJtndWu": {
    "title": "Efficient Diffusion Policies For Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline reinforcement learning (RL) aims to learn optimal policies from offline datasets, where the parameterization of policies is crucial but often overlooked. Recently, Diffsuion-QL significantly boosts the performance of offline RL by representing a policy with a diffusion model, whose success relies on a parametrized Markov Chain with hundreds of steps for sampling. However, Diffusion-QL suffers from two critical limitations. 1) It is computationally inefficient to forward and backward through the whole Markov chain during training. 2) It is incompatible with maximum likelihood-based RL algorithms (e.g., policy gradient methods) as the likelihood of diffusion models is intractable. Therefore, we propose efficient diffusion policy (EDP) to overcome these two challenges. EDP approximately constructs actions from corrupted ones at training to avoid running the sampling chain. We conduct extensive experiments on the D4RL benchmark. The results show that EDP can reduce the diffusion policy training time from 5 days to 5 hours on gym-locomotion tasks. Moreover, we show that EDP is compatible with various offline RL algorithms (TD3, CRR, and IQL) and achieves new state-of-the-art on D4RL by large margins over previous methods",
    "checked": true,
    "id": "2aae2dd79ef30022da59d8c33f0b3afa55d9c20d",
    "semantic_title": "efficient diffusion policies for offline reinforcement learning",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=lHa7gFbmvS": {
    "title": "The CLIP Model is Secretly an Image-to-Prompt Converter",
    "volume": "poster",
    "abstract": "The Stable Diffusion model is a prominent text-to-image generation model that relies on a text prompt as its input, which is encoded using the Contrastive Language-Image Pre-Training (CLIP). However, text prompts have limitations when it comes to incorporating implicit information from reference images. Existing methods have attempted to address this limitation by employing expensive training procedures involving millions of training samples for image-to-image generation. In contrast, this paper demonstrates that the CLIP model, as utilized in Stable Diffusion, inherently possesses the ability to instantaneously convert images into text prompts. Such an image-to-prompt conversion can be achieved by utilizing a linear projection matrix that is calculated in a closed form. Moreover, the paper showcases that this capability can be further enhanced by either utilizing a small amount of similar-domain training data (approximately 100 images) or incorporating several online training steps (around 30 iterations) on the reference images. By leveraging these approaches, the proposed method offers a simple and flexible solution to bridge the gap between images and text prompts. This methodology can be applied to various tasks such as image variation and image editing, facilitating more effective and seamless interaction between images and textual prompts",
    "checked": true,
    "id": "454b4c46461a245efa1462d9f4fd6ea8be958ec7",
    "semantic_title": "the clip model is secretly an image-to-prompt converter",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uotGmrcooz": {
    "title": "Optimal approximation using complex-valued neural networks",
    "volume": "poster",
    "abstract": "Complex-valued neural networks (CVNNs) have recently shown promising empirical success, for instance for increasing the stability of recurrent neural networks and for improving the performance in tasks with complex-valued inputs, such as MRI fingerprinting. While the overwhelming success of Deep Learning in the real-valued case is supported by a growing mathematical foundation, such a foundation is still largely lacking in the complex-valued case. We thus analyze the expressivity of CVNNs by studying their approximation properties. Our results yield the first quantitative approximation bounds for CVNNs that apply to a wide class of activation functions including the popular modReLU and complex cardioid activation functions. Precisely, our results apply to any activation function that is smooth but not polyharmonic on some non-empty open set; this is the natural generalization of the class of smooth and non-polynomial activation functions to the complex setting. Our main result shows that the approximation error scales as $m^{-k/(2n)}$ for $m \\to \\infty$ where $m$ is the number of neurons, $k$ the smoothness of the target function and $n$ is the (complex) input dimension. Under a natural continuity assumption, we show that this rate is optimal; we further discuss the optimality when dropping this assumption. Moreover, we prove that the problem of approximating $C^k$-functions using continuous approximation methods unavoidably suffers from the curse of dimensionality",
    "checked": true,
    "id": "cb4e0788b9e95c445fe580d8b17931ea8c35ae4b",
    "semantic_title": "optimal approximation using complex-valued neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=HPrd17Qvbp": {
    "title": "Learning Dense Flow Field for Highly-accurate Cross-view Camera Localization",
    "volume": "poster",
    "abstract": "This paper addresses the problem of estimating the 3-DoF camera pose for a ground-level image with respect to a satellite image that encompasses the local surroundings. We propose a novel end-to-end approach that leverages the learning of dense pixel-wise flow fields in pairs of ground and satellite images to calculate the camera pose. Our approach differs from existing methods by constructing the feature metric at the pixel level, enabling full-image supervision for learning distinctive geometric configurations and visual appearances across views. Specifically, our method employs two distinct convolution networks for ground and satellite feature extraction. Then, we project the ground feature map to the bird's eye view (BEV) using a fixed camera height assumption to achieve preliminary geometric alignment. To further establish the content association between the BEV and satellite features, we introduce a residual convolution block to refine the projected BEV feature. Optical flow estimation is performed on the refined BEV feature map and the satellite feature map using flow decoder networks based on RAFT. After obtaining dense flow correspondences, we apply the least square method to filter matching inliers and regress the ground camera pose. Extensive experiments demonstrate significant improvements compared to state-of-the-art methods. Notably, our approach reduces the median localization error by 89\\%, 19\\%, 80\\%, and 35\\% on the KITTI, Ford multi-AV, VIGOR, and Oxford RobotCar datasets, respectively",
    "checked": true,
    "id": "6876f4ad4934979de70975d56e48fafafbec497c",
    "semantic_title": "learning dense flow field for highly-accurate cross-view camera localization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ca78M3awPw": {
    "title": "MMGP: a Mesh Morphing Gaussian Process-based machine learning method for regression of physical problems under nonparametrized geometrical variability",
    "volume": "poster",
    "abstract": "When learning simulations for modeling physical phenomena in industrial designs, geometrical variabilities are of prime interest. While classical regression techniques prove effective for parameterized geometries, practical scenarios often involve the absence of shape parametrization during the inference stage, leaving us with only mesh discretizations as available data. Learning simulations from such mesh-based representations poses significant challenges, with recent advances relying heavily on deep graph neural networks to overcome the limitations of conventional machine learning approaches. Despite their promising results, graph neural networks exhibit certain drawbacks, including their dependency on extensive datasets and limitations in providing built-in predictive uncertainties or handling large meshes. In this work, we propose a machine learning method that do not rely on graph neural networks. Complex geometrical shapes and variations with fixed topology are dealt with using well-known mesh morphing onto a common support, combined with classical dimensionality reduction techniques and Gaussian processes. The proposed methodology can easily deal with large meshes without the need for explicit shape parameterization and provides crucial predictive uncertainties, which are essential for informed decision-making. In the considered numerical experiments, the proposed method is competitive with respect to existing graph neural networks, regarding training efficiency and accuracy of the predictions",
    "checked": false,
    "id": "76671cfc37ec9c41366c73e481a4d5fa93b3461d",
    "semantic_title": "mmgp: a mesh morphing gaussian process-based machine learning method for regression of physical problems under non-parameterized geometrical variability",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=txv7TnPvOi": {
    "title": "InstanT: Semi-supervised Learning with Instance-dependent Thresholds",
    "volume": "poster",
    "abstract": "Semi-supervised learning (SSL) has been a fundamental challenge in machine learning for decades. The primary family of SSL algorithms, known as pseudo-labeling, involves assigning pseudo-labels to confident unlabeled instances and incorporating them into the training set. Therefore, the selection criteria of confident instances are crucial to the success of SSL. Recently, there has been growing interest in the development of SSL methods that use dynamic or adaptive thresholds. Yet, these methods typically apply the same threshold to all samples, or use class-dependent thresholds for instances belonging to a certain class, while neglecting instance-level information. In this paper, we propose the study of instance-dependent thresholds, which has the highest degree of freedom compared with existing methods. Specifically, we devise a novel instance-dependent threshold function for all unlabeled instances by utilizing their instance-level ambiguity and the instance-dependent error rates of pseudo-labels, so instances that are more likely to have incorrect pseudo-labels will have higher thresholds. Furthermore, we demonstrate that our instance-dependent threshold function provides a bounded probabilistic guarantee for the correctness of the pseudo-labels it assigns",
    "checked": true,
    "id": "e9ca3a5f33ab79bf96ad347b4162d24a0484389d",
    "semantic_title": "instant: semi-supervised learning with instance-dependent thresholds",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eDDZh8C4W4": {
    "title": "How to Select Which Active Learning Strategy is Best Suited for Your Specific Problem and Budget",
    "volume": "poster",
    "abstract": "In the domain of Active Learning (AL), a learner actively selects which unlabeled examples to seek labels from an oracle, while operating within predefined budget constraints. Importantly, it has been recently shown that distinct query strategies are better suited for different conditions and budgetary constraints. In practice, the determination of the most appropriate AL strategy for a given situation remains an open problem. To tackle this challenge, we propose a practical derivative-based method that dynamically identifies the best strategy for a given budget. Intuitive motivation for our approach is provided by the theoretical analysis of a simplified scenario. We then introduce a method to dynamically select an AL strategy, which takes into account the unique characteristics of the problem and the available budget. Empirical results showcase the effectiveness of our approach across diverse budgets and computer vision tasks",
    "checked": true,
    "id": "b6261ab0a8ee31fcab0e2675280aa95521586894",
    "semantic_title": "how to select which active learning strategy is best suited for your specific problem and budget",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ny3GcHLyzj": {
    "title": "Efficient Policy Adaptation with Contrastive Prompt Ensemble for Embodied Agents",
    "volume": "poster",
    "abstract": "For embodied reinforcement learning (RL) agents interacting with the environment, it is desirable to have rapid policy adaptation to unseen visual observations, but achieving zero-shot adaptation capability is considered as a challenging problem in the RL context. To address the problem, we present a novel contrastive prompt ensemble (ConPE) framework which utilizes a pretrained vision-language model and a set of visual prompts, thus enables efficient policy learning and adaptation upon a wide range of environmental and physical changes encountered by embodied agents. Specifically, we devise a guided-attention-based ensemble approach with multiple visual prompts on the vision-language model to construct robust state representations. Each prompt is contrastively learned in terms of an individual domain factors that significantly affects the agent's egocentric perception and observation. For a given task, the attention-based ensemble and policy are jointly learned so that the resulting state representations not only generalize to various domains but are also optimized for learning the task. Through experiments, we show that ConPE outperforms other state-of-the-art algorithms for several embodied agent tasks including navigation in AI2THOR, manipulation in Metaworld, and autonomous driving in CARLA, while also improving the sample efficiency of policy learning and adaptation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2gn9WFlqJ4": {
    "title": "Mode Connectivity in Auction Design",
    "volume": "poster",
    "abstract": "Optimal auction design is a fundamental problem in algorithmic game theory. This problem is notoriously difficult already in very simple settings. Recent work in differentiable economics showed that neural networks can efficiently learn known optimal auction mechanisms and discover interesting new ones. In an attempt to theoretically justify their empirical success, we focus on one of the first such networks, RochetNet, and a generalized version for affine maximizer auctions. We prove that they satisfy mode connectivity, i.e., locally optimal solutions are connected by a simple, piecewise linear path such that every solution on the path is almost as good as one of the two local optima. Mode connectivity has been recently investigated as an intriguing empirical and theoretically justifiable property of neural networks used for prediction problems. Our results give the first such analysis in the context of differentiable economics, where neural networks are used directly for solving non-convex optimization problems",
    "checked": true,
    "id": "0ce4f232b2cb12d48414332b6a07aa5d094d1b87",
    "semantic_title": "mode connectivity in auction design",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8NAxGDdf7H": {
    "title": "Few-Shot Class-Incremental Learning via Training-Free Prototype Calibration",
    "volume": "poster",
    "abstract": "Real-world scenarios are usually accompanied by continuously appearing classes with scare labeled samples, which require the machine learning model to incrementally learn new classes and maintain the knowledge of base classes. In this Few-Shot Class-Incremental Learning (FSCIL) scenario, existing methods either introduce extra learnable components or rely on a frozen feature extractor to mitigate catastrophic forgetting and overfitting problems. However, we find a tendency for existing methods to misclassify the samples of new classes into base classes, which leads to the poor performance of new classes. In other words, the strong discriminability of base classes distracts the classification of new classes. To figure out this intriguing phenomenon, we observe that although the feature extractor is only trained on base classes, it can surprisingly represent the *semantic similarity* between the base and *unseen* new classes. Building upon these analyses, we propose a *simple yet effective* Training-frEE calibratioN (TEEN) strategy to enhance the discriminability of new classes by fusing the new prototypes (i.e., mean features of a class) with weighted base prototypes. In addition to standard benchmarks in FSCIL, TEEN demonstrates remarkable performance and consistent improvements over baseline methods in the few-shot learning scenario. Code is available at: https://github.com/wangkiw/TEEN",
    "checked": false,
    "id": "f3fdc05ae21e48b98f7a4881fc3433fb70b494f5",
    "semantic_title": "few shot class incremental learning via efficient prototype replay and calibration",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qZjl2TKvUY": {
    "title": "One Risk to Rule Them All: A Risk-Sensitive Perspective on Model-Based Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline reinforcement learning (RL) is suitable for safety-critical domains where online exploration is not feasible. In such domains, decision-making should take into consideration the risk of catastrophic outcomes. In other words, decision-making should be *risk-averse*. An additional challenge of offline RL is avoiding *distributional shift*, i.e. ensuring that state-action pairs visited by the policy remain near those in the dataset. Previous offline RL algorithms that consider risk combine offline RL techniques (to avoid distributional shift), with risk-sensitive RL algorithms (to achieve risk-aversion). In this work, we propose risk-aversion as a mechanism to jointly address *both* of these issues. We propose a model-based approach, and use an ensemble of models to estimate epistemic uncertainty, in addition to aleatoric uncertainty. We train a policy that is risk-averse, and avoids high uncertainty actions. Risk-aversion to epistemic uncertainty prevents distributional shift, as areas not covered by the dataset have high epistemic uncertainty. Risk-aversion to aleatoric uncertainty discourages actions that are risky due to environment stochasticity. Thus, by considering epistemic uncertainty via a model ensemble and introducing risk-aversion, our algorithm (1R2R) avoids distributional shift in addition to achieving risk-aversion to aleatoric risk. Our experiments show that 1R2R achieves strong performance on deterministic benchmarks, and outperforms existing approaches for risk-sensitive objectives in stochastic domains",
    "checked": true,
    "id": "2f130f118ee696d6a97cf22b2e02738d550c52e8",
    "semantic_title": "one risk to rule them all: a risk-sensitive perspective on model-based offline reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=tEmFyqjaJh": {
    "title": "PPi: Pretraining Brain Signal Model for Patient-independent Seizure Detection",
    "volume": "poster",
    "abstract": "Automated seizure detection is of great importance to epilepsy diagnosis and treatment. An emerging method used in seizure detection, stereoelectroencephalography (SEEG), can provide detailed and stereoscopic brainwave information. However, modeling SEEG in clinical scenarios will face challenges like huge domain shift between different patients and dramatic pattern evolution among different brain areas. In this study, we propose a Pretraining-based model for Patient-independent seizure detection (PPi) to address these challenges. Firstly, we design two novel self-supervised tasks which can extract rich information from abundant SEEG data while preserving the unique characteristics between brain signals recorded from different brain areas. Then two techniques channel background subtraction and brain region enhancement are proposed to effectively tackle the domain shift problem. Extensive experiments show that PPi outperforms the SOTA baselines on two public datasets and a real-world clinical dataset collected by ourselves, which demonstrates the effectiveness and practicability of PPi. Finally, visualization analysis illustrates the rationality of the two domain generalization techniques",
    "checked": true,
    "id": "f7595c49efbe2a16d950f3b974b1408e9e45f9f1",
    "semantic_title": "ppi: pretraining brain signal model for patient-independent seizure detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LAbxkhkjbD": {
    "title": "Trial matching: capturing variability with data-constrained spiking neural networks",
    "volume": "poster",
    "abstract": "Simultaneous behavioral and electrophysiological recordings call for new methods to reveal the interactions between neural activity and behavior. A milestone would be an interpretable model of the co-variability of spiking activity and behavior across trials. Here, we model a mouse cortical sensory-motor pathway in a tactile detection task reported by licking with a large recurrent spiking neural network (RSNN), fitted to the recordings via gradient-based optimization. We focus specifically on the difficulty to match the trial-to-trial variability in the data. Our solution relies on optimal transport to define a distance between the distributions of generated and recorded trials. The technique is applied to artificial data and neural recordings covering six cortical areas. We find that the resulting RSNN can generate realistic cortical activity and predict jaw movements across the main modes of trial-to-trial variability. Our analysis also identifies an unexpected mode of variability in the data corresponding to task-irrelevant movements of the mouse",
    "checked": true,
    "id": "63981254f02c3298aa83b7055a16722b14b9df26",
    "semantic_title": "trial matching: capturing variability with data-constrained spiking neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NnIaEaBfXD": {
    "title": "Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models",
    "volume": "poster",
    "abstract": "Public large-scale text-to-image diffusion models, such as Stable Diffusion, have gained significant attention from the community. These models can be easily customized for new concepts using low-rank adaptations (LoRAs). However, the utilization of multiple-concept LoRAs to jointly support multiple customized concepts presents a challenge. We refer to this scenario as decentralized multi-concept customization, which involves single-client concept tuning and center-node concept fusion. In this paper, we propose a new framework called Mix-of-Show that addresses the challenges of decentralized multi-concept customization, including concept conflicts resulting from existing single-client LoRA tuning and identity loss during model fusion. Mix-of-Show adopts an embedding-decomposed LoRA (ED-LoRA) for single-client tuning and gradient fusion for the center node to preserve the in-domain essence of single concepts and support theoretically limitless concept fusion. Additionally, we introduce regionally controllable sampling, which extends spatially controllable sampling (e.g., ControlNet and T2I-Adapter) to address attribute binding and missing object problems in multi-concept sampling. Extensive experiments demonstrate that Mix-of-Show is capable of composing multiple customized concepts with high fidelity, including characters, objects, and scenes",
    "checked": true,
    "id": "5728ecb3a11c1586c4ae53e11ab395a0263eb5f4",
    "semantic_title": "mix-of-show: decentralized low-rank adaptation for multi-concept customization of diffusion models",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=3XStpETaO8": {
    "title": "A General Framework for Equivariant Neural Networks on Reductive Lie Groups",
    "volume": "poster",
    "abstract": "Reductive Lie Groups, such as the orthogonal groups, the Lorentz group, or the unitary groups, play essential roles across scientific fields as diverse as high energy physics, quantum mechanics, quantum chromodynamics, molecular dynamics, computer vision, and imaging. In this paper, we present a general Equivariant Neural Network architecture capable of respecting the symmetries of the finite-dimensional representations of any reductive Lie Group. Our approach generalizes the successful ACE and MACE architectures for atomistic point clouds to any data equivariant to a reductive Lie group action. We also introduce the lie-nn software library, which provides all the necessary tools to develop and implement such general G-equivariant neural networks. It implements routines for the reduction of generic tensor products of representations into irreducible representations, making it easy to apply our architecture to a wide range of problems and groups. The generality and performance of our approach are demonstrated by applying it to the tasks of top quark decay tagging (Lorentz group) and shape recognition (orthogonal group)",
    "checked": true,
    "id": "45f3e7cc21dba6bdc44945b99e72c4d07dd47523",
    "semantic_title": "a general framework for equivariant neural networks on reductive lie groups",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=86ADcKOHAw": {
    "title": "Nearest Neighbour with Bandit Feedback",
    "volume": "poster",
    "abstract": "In this paper we adapt the nearest neighbour rule to the contextual bandit problem. Our algorithm handles the fully adversarial setting in which no assumptions at all are made about the data-generation process. When combined with a sufficiently fast data-structure for (perhaps approximate) adaptive nearest neighbour search, such as a navigating net, our algorithm is extremely efficient - having a per trial running time polylogarithmic in both the number of trials and actions, and taking only quasi-linear space. We give generic regret bounds for our algorithm and further analyse them when applied to the stochastic bandit problem in euclidean space. A side result of this paper is that, when applied to the online classification problem with stochastic labels, our algorithm can, under certain conditions, have sublinear regret whilst only finding a single nearest neighbour per trial - in stark contrast to the k-nearest neighbours algorithm",
    "checked": true,
    "id": "d81699824858af4621657d78a3f933a24bf4bc98",
    "semantic_title": "nearest neighbour with bandit feedback",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dt71xKyabn": {
    "title": "Curvature Filtrations for Graph Generative Model Evaluation",
    "volume": "poster",
    "abstract": "Graph generative model evaluation necessitates understanding differences between graphs on the distributional level. This entails being able to harness salient attributes of graphs in an efficient manner. Curvature constitutes one such property of graphs, and has recently started to prove useful in characterising graphs. Its expressive properties, stability, and practical utility in model evaluation remain largely unexplored, however. We combine graph curvature descriptors with emerging methods from topological data analysis to obtain robust, expressive descriptors for evaluating graph generative models",
    "checked": true,
    "id": "208b142cbb3d36d664fe10f1b44cb02847b972d6",
    "semantic_title": "curvature filtrations for graph generative model evaluation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=MCj7DLkYqS": {
    "title": "Adversarial Attacks on Online Learning to Rank with Click Feedback",
    "volume": "poster",
    "abstract": "Online learning to rank (OLTR) is a sequential decision-making problem where a learning agent selects an ordered list of items and receives feedback through user clicks. Although potential attacks against OLTR algorithms may cause serious losses in real-world applications, there is limited knowledge about adversarial attacks on OLTR. This paper studies attack strategies against multiple variants of OLTR. Our first result provides an attack strategy against the UCB algorithm on classical stochastic bandits with binary feedback, which solves the key issues caused by bounded and discrete feedback that previous works cannot handle. Building on this result, we design attack algorithms against UCB-based OLTR algorithms in position-based and cascade models. Finally, we propose a general attack strategy against any algorithm under the general click model. Each attack algorithm manipulates the learning agent into choosing the target attack item $T-o(T)$ times, incurring a cumulative cost of $o(T)$. Experiments on synthetic and real data further validate the effectiveness of our proposed attack algorithms",
    "checked": true,
    "id": "e40274d8da40b1220f005d2542b879f02648bc1b",
    "semantic_title": "adversarial attacks on online learning to rank with click feedback",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qlJoo2y3gY": {
    "title": "Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
    "volume": "poster",
    "abstract": "Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order. After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches",
    "checked": true,
    "id": "36e511da4438cdbf8d6bab92af94b9f3eb420003",
    "semantic_title": "bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k2UVKezeWn": {
    "title": "L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference",
    "volume": "poster",
    "abstract": "Many recent works in simulation-based inference (SBI) rely on deep generative models to approximate complex, high-dimensional posterior distributions. However, evaluating whether or not these approximations can be trusted remains a challenge. Most approaches evaluate the posterior estimator only in expectation over the observation space. This limits their interpretability and is not sufficient to identify for which observations the approximation can be trusted or should be improved. Building upon the well-known classifier two-sample test (C2ST), we introduce $\\ell$-C2ST, a new method that allows for a local evaluation of the posterior estimator at any given observation. It offers theoretically grounded and easy to interpret -- e.g. graphical -- diagnostics, and unlike C2ST, does not require access to samples from the true posterior. In the case of normalizing flow-based posterior estimators, $\\ell$-C2ST can be specialized to offer better statistical power, while being computationally more efficient. On standard SBI benchmarks, $\\ell$-C2ST provides comparable results to C2ST and outperforms alternative local approaches such as coverage tests based on highest predictive density (HPD). We further highlight the importance of local evaluation and the benefit of interpretability of $\\ell$-C2ST on a challenging application from computational neuroscience",
    "checked": true,
    "id": "dee86b96e79bade72603d764ac0424823f30d620",
    "semantic_title": "l-c2st: local diagnostics for posterior approximations in simulation-based inference",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ox7aynitoW": {
    "title": "MIMONets: Multiple-Input-Multiple-Output Neural Networks Exploiting Computation in Superposition",
    "volume": "poster",
    "abstract": "With the advent of deep learning, progressively larger neural networks have been designed to solve complex tasks. We take advantage of these capacity-rich models to lower the cost of inference by exploiting computation in superposition. To reduce the computational burden per input, we propose Multiple-Input-Multiple-Output Neural Networks (MIMONets) capable of handling many inputs at once. MIMONets augment various deep neural network architectures with variable binding mechanisms to represent an arbitrary number of inputs in a compositional data structure via fixed-width distributed representations. Accordingly, MIMONets adapt nonlinear neural transformations to process the data structure holistically, leading to a speedup nearly proportional to the number of superposed input items in the data structure. After processing in superposition, an unbinding mechanism recovers each transformed input of interest. MIMONets also provide a dynamic trade-off between accuracy and throughput by an instantaneous on-demand switching between a set of accuracy-throughput operating points, yet within a single set of fixed parameters. We apply the concept of MIMONets to both CNN and Transformer architectures resulting in MIMOConv and MIMOFormer, respectively. Empirical evaluations show that MIMOConv achieves $\\approx 2$–$4\\times$ speedup at an accuracy delta within [+0.68, -3.18]% compared to WideResNet CNNs on CIFAR10 and CIFAR100. Similarly, MIMOFormer can handle $2$–$4$ inputs at once while maintaining a high average accuracy within a [-1.07, -3.43]% delta on the long range arena benchmark. Finally, we provide mathematical bounds on the interference between superposition channels in MIMOFormer. Our code is available at https://github.com/IBM/multiple-input-multiple-output-nets",
    "checked": false,
    "id": "872a1ef38a5a5455e0935c242daeb7d5845851bd",
    "semantic_title": "an fpga-based residual recurrent neural network for real-time video super-resolution",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=3aVZhMfsyz": {
    "title": "Volume Feature Rendering for Fast Neural Radiance Field Reconstruction",
    "volume": "poster",
    "abstract": "Neural radiance fields (NeRFs) are able to synthesize realistic novel views from multi-view images captured from distinct positions and perspectives. In NeRF's rendering pipeline, neural networks are used to represent a scene independently or transform queried learnable feature vector of a point to the expected color or density. With the aid of geometry guides either in the form of occupancy grids or proposal networks, the number of color neural network evaluations can be reduced from hundreds to dozens in the standard volume rendering framework. However, many evaluations of the color neural network are still a bottleneck for fast NeRF reconstruction. This paper revisits volume feature rendering (VFR) for the purpose of fast NeRF reconstruction. The VFR integrates the queried feature vectors of a ray into one feature vector, which is then transformed to the final pixel color by a color neural network. This fundamental change to the standard volume rendering framework requires only one single color neural network evaluation to render a pixel, which substantially lowers the high computational complexity of the rendering framework attributed to a large number of color neural network evaluations. Consequently, we can use a comparably larger color neural network to achieve a better rendering quality while maintaining the same training and rendering time costs. This approach achieves the state-of-the-art rendering quality on both synthetic and real-world datasets while requiring less training time compared with existing methods",
    "checked": true,
    "id": "5105cc856715fa006c566b69617018c1c083498b",
    "semantic_title": "volume feature rendering for fast neural radiance field reconstruction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FM81CI68Iz": {
    "title": "FedL2P: Federated Learning to Personalize",
    "volume": "poster",
    "abstract": "Federated learning (FL) research has made progress in developing algorithms for distributed learning of global models, as well as algorithms for local personalization of those common models to the specifics of each client's local data distribution. However, different FL problems may require different personalization strategies, and it may not even be possible to define an effective one-size-fits-all personalization strategy for all clients: Depending on how similar each client's optimal predictor is to that of the global model, different personalization strategies may be preferred. In this paper, we consider the federated meta-learning problem of learning personalization strategies. Specifically, we consider meta-nets that induce the batch-norm and learning rate parameters for each client given local data statistics. By learning these meta-nets through FL, we allow the whole FL network to collaborate in learning a customized personalization strategy for each client. Empirical results show that this framework improves on a range of standard hand-crafted personalization baselines in both label and feature shift situations",
    "checked": true,
    "id": "37b2af849c63dccd6a9bf24ccc3a7165b8a7558b",
    "semantic_title": "fedl2p: federated learning to personalize",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZZgfS1DbmO": {
    "title": "Continuous Parametric Optical Flow",
    "volume": "poster",
    "abstract": "In this paper, we present continuous parametric optical flow, a parametric representation of dense and continuous motion over arbitrary time interval. In contrast to existing discrete-time representations (i.e., flow in between consecutive frames), this new representation transforms the frame-to-frame pixel correspondences to dense continuous flow. In particular, we present a temporal-parametric model that employs B-splines to fit point trajectories using a limited number of frames. To further improve the stability and robustness of the trajectories, we also add an encoder with a neural ordinary differential equation (ODE) to represent features associated with specific times. We also contribute a synthetic dataset and introduce two evaluation perspectives to measure the accuracy and robustness of continuous flow estimation. Benefiting from the combination of explicit parametric modeling and implicit feature optimization, our model focuses on motion continuity and outperforms than the flow-based and point-tracking approaches for fitting long-term and variable sequences",
    "checked": false,
    "id": "2d766a59c792f04acc795b44d57a78cd48f9e655",
    "semantic_title": "dense continuous-time optical flow from events and frames",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=vZRiMjo826": {
    "title": "Extremal Domain Translation with Neural Optimal Transport",
    "volume": "poster",
    "abstract": "In many unpaired image domain translation problems, e.g., style transfer or super-resolution, it is important to keep the translated image similar to its respective input image. We propose the extremal transport (ET) which is a mathematical formalization of the theoretically best possible unpaired translation between a pair of domains w.r.t. the given similarity function. Inspired by the recent advances in neural optimal transport (OT), we propose a scalable algorithm to approximate ET maps as a limit of partial OT maps. We test our algorithm on toy examples and on the unpaired image-to-image translation task. The code is publicly available at https://github.com/milenagazdieva/ExtremalNeuralOptimalTransport",
    "checked": true,
    "id": "cf0730e638dcc6b090720e830a27872f7d0e5f2b",
    "semantic_title": "extremal domain translation with neural optimal transport",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=OCtv4NyahI": {
    "title": "A Guide Through the Zoo of Biased SGD",
    "volume": "poster",
    "abstract": "Stochastic Gradient Descent (SGD) is arguably the most important single algorithm in modern machine learning. Although SGD with unbiased gradient estimators has been studied extensively over at least half a century, SGD variants relying on biased estimators are rare. Nevertheless, there has been an increased interest in this topic in recent years. However, existing literature on SGD with biased estimators lacks coherence since each new paper relies on a different set of assumptions, without any clear understanding of how they are connected, which may lead to confusion. We address this gap by establishing connections among the existing assumptions, and presenting a comprehensive map of the underlying relationships. Additionally, we introduce a new set of assumptions that is provably weaker than all previous assumptions, and use it to present a thorough analysis of BiasedSGD in both convex and non-convex settings, offering advantages over previous results. We also provide examples where biased estimators outperform their unbiased counterparts or where unbiased versions are simply not available. Finally, we demonstrate the effectiveness of our framework through experimental results that validate our theoretical findings",
    "checked": true,
    "id": "2b49533bf144c37515c7ec1f28e7466ca44ff251",
    "semantic_title": "a guide through the zoo of biased sgd",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B94G0MXWQX": {
    "title": "CamoPatch: An Evolutionary Strategy for Generating Camoflauged Adversarial Patches",
    "volume": "poster",
    "abstract": "Deep neural networks (DNNs) have demonstrated vulnerabilities to adversarial examples, which raises concerns about their reliability in safety-critical applications. While the majority of existing methods generate adversarial examples by making small modifications to the entire image, recent research has proposed a practical alternative known as adversarial patches. Adversarial patches have shown to be highly effective in causing DNNs to misclassify by distorting a localized area (patch) of the image. However, existing methods often produce clearly visible distortions since they do not consider the visibility of the patch. To address this, we propose a novel method for constructing adversarial patches that approximates the appearance of the area it covers. We achieve this by using a set of semi-transparent, RGB-valued circles, drawing inspiration from the computational art community. We utilize an evolutionary strategy to optimize the properties of each shape, and employ a simulated annealing approach to optimize the patch's location. Our approach achieves better or comparable performance to state-of-the-art methods on ImageNet DNN classifiers while achieving a lower $l_2$ distance from the original image. By minimizing the visibility of the patch, this work further highlights the vulnerabilities of DNNs to adversarial patches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AKAMNDe2Sw": {
    "title": "Boosting Adversarial Transferability by Achieving Flat Local Maxima",
    "volume": "poster",
    "abstract": "Transfer-based attack adopts the adversarial examples generated on the surrogate model to attack various models, making it applicable in the physical world and attracting increasing interest. Recently, various adversarial attacks have emerged to boost adversarial transferability from different perspectives. In this work, inspired by the observation that flat local minima are correlated with good generalization, we assume and empirically validate that adversarial examples at a flat local region tend to have good transferability by introducing a penalized gradient norm to the original loss function. Since directly optimizing the gradient regularization norm is computationally expensive and intractable for generating adversarial examples, we propose an approximation optimization method to simplify the gradient update of the objective function. Specifically, we randomly sample an example and adopt a first-order procedure to approximate the curvature of the second-order Hessian matrix, which makes computing more efficient by interpolating two Jacobian matrices. Meanwhile, in order to obtain a more stable gradient direction, we randomly sample multiple examples and average the gradients of these examples to reduce the variance due to random sampling during the iterative process. Extensive experimental results on the ImageNet-compatible dataset show that the proposed method can generate adversarial examples at flat local regions, and significantly improve the adversarial transferability on either normally trained models or adversarially trained models than the state-of-the-art attacks. Our codes are available at: https://github.com/Trustworthy-AI-Group/PGN",
    "checked": true,
    "id": "08480c48b2c1564d73d02a774b0eb9ca571dd520",
    "semantic_title": "boosting adversarial transferability by achieving flat local maxima",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=hcXDbbzgoh": {
    "title": "Taylor TD-learning",
    "volume": "poster",
    "abstract": "Many reinforcement learning approaches rely on temporal-difference (TD) learning to learn a critic. However, TD-learning updates can be high variance. Here, we introduce a model-based RL framework, Taylor TD, which reduces this variance in continuous state-action settings. Taylor TD uses a first-order Taylor series expansion of TD updates. This expansion allows Taylor TD to analytically integrate over stochasticity in the action-choice, and some stochasticity in the state distribution for the initial state and action of each TD update. We include theoretical and empirical evidence that Taylor TD updates are indeed lower variance than standard TD updates. Additionally, we show Taylor TD has the same stable learning guarantees as standard TD-learning with linear function approximation under a reasonable assumption. Next, we combine Taylor TD with the TD3 algorithm, forming TaTD3. We show TaTD3 performs as well, if not better, than several state-of-the art model-free and model-based baseline algorithms on a set of standard benchmark tasks",
    "checked": true,
    "id": "9b8a0da395016bb27da95acd5402511e6857e456",
    "semantic_title": "taylor td-learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=966yOmwk6d": {
    "title": "Towards Data-Algorithm Dependent Generalization: a Case Study on Overparameterized Linear Regression",
    "volume": "poster",
    "abstract": "One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent even for overparameterized linear regression. In many scenarios, this failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. This paper demonstrate that the generalization behavior of overparameterized model should be analyzed in a both data-relevant and algorithm-relevant manner. To make a formal characterization, We introduce a notion called data-algorithm compatibility, which considers the generalization behavior of the entire data-dependent training trajectory, instead of traditional last-iterate analysis. We validate our claim by studying the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that if we take early stopping iterates into consideration, generalization can hold with significantly weaker restrictions on the problem instance than the previous last-iterate analysis",
    "checked": true,
    "id": "b24149600bf2db7d7719b32bab97623baf519e0d",
    "semantic_title": "towards data-algorithm dependent generalization: a case study on overparameterized linear regression",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=gdzxWGGxWE": {
    "title": "How do Minimum-Norm Shallow Denoisers Look in Function Space?",
    "volume": "poster",
    "abstract": "Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers --- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of simple rank-one piecewise linear interpolations aligned with edges and/or faces connecting training samples. We empirically verify this alignment phenomenon on synthetic data and real images",
    "checked": true,
    "id": "270a3a28be03293900aac529a517d2ef56aee0c2",
    "semantic_title": "how do minimum-norm shallow denoisers look in function space?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H15KtcyHvn": {
    "title": "Training Fully Connected Neural Networks is $\\exists\\mathbb{R}$-Complete",
    "volume": "poster",
    "abstract": "We consider the algorithmic problem of finding the optimal weights and biases for a two-layer fully connected neural network to fit a given set of data points, also known as empirical risk minimization. We show that the problem is $\\exists\\mathbb{R}$-complete. This complexity class can be defined as the set of algorithmic problems that are polynomial-time equivalent to finding real roots of a multivariate polynomial with integer coefficients. Furthermore, we show that arbitrary algebraic numbers are required as weights to be able to train some instances to optimality, even if all data points are rational. Our result already applies to fully connected instances with two inputs, two outputs, and one hidden layer of ReLU neurons. Thereby, we strengthen a result by Abrahamsen, Kleist and Miltzow [NeurIPS 2021]. A consequence of this is that a combinatorial search algorithm like the one by Arora, Basu, Mianjy and Mukherjee [ICLR 2018] is impossible for networks with more than one output dimension, unless $\\text{NP} = \\exists\\mathbb{R}$",
    "checked": false,
    "id": "4d149e0c6f3f8bb1c211193c75dae293f2922ca6",
    "semantic_title": "training fully connected neural networks is ∃r-complete",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=dnB71DMyDD": {
    "title": "The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions",
    "volume": "poster",
    "abstract": "Inference and simulation in the context of high-dimensional dynamical systems remain computationally challenging problems. Some form of dimensionality reduction is required to make the problem tractable in general. In this paper, we propose a novel approximate Gaussian filtering and smoothing method which propagates low-rank approximations of the covariance matrices. This is accomplished by projecting the Lyapunov equations associated with the prediction step to a manifold of low-rank matrices, which are then solved by a recently developed, numerically stable, dynamical low-rank integrator. Meanwhile, the update steps are made tractable by noting that the covariance update only transforms the column space of the covariance matrix, which is low-rank by construction. The algorithm differentiates itself from existing ensemble-based approaches in that the low-rank approximations of the covariance matrices are deterministic, rather than stochastic. Crucially, this enables the method to reproduce the exact Kalman filter as the low-rank dimension approaches the true dimensionality of the problem. Our method reduces computational complexity from cubic (for the Kalman filter) to quadratic in the state-space size in the worst-case, and can achieve linear complexity if the state-space model satisfies certain criteria. Through a set of experiments in classical data-assimilation and spatio-temporal regression, we show that the proposed method consistently outperforms the ensemble-based methods in terms of error in the mean and covariance with respect to the exact Kalman filter. This comes at no additional cost in terms of asymptotic computational complexity",
    "checked": true,
    "id": "040405698374352a264f04b485eac30142006f0b",
    "semantic_title": "the rank-reduced kalman filter: approximate dynamical-low-rank filtering in high dimensions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CzkOzKWpMa": {
    "title": "Optimal cross-learning for contextual bandits with unknown context distributions",
    "volume": "poster",
    "abstract": "We consider the problem of designing contextual bandit algorithms in the ``cross-learning'' setting of Balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. We specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. In this setting, we resolve an open problem of Balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of $\\widetilde{O}(\\sqrt{TK})$, independent of the number of contexts. As a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set. At the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between estimation of the unknown distribution and the actions played by the algorithm. This technique may be of independent interest for other learning problems involving estimation of an unknown context distribution",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5JcKKRX2iH": {
    "title": "GeoTMI: Predicting Quantum Chemical Property with Easy-to-Obtain Geometry via Positional Denoising",
    "volume": "poster",
    "abstract": "As quantum chemical properties have a dependence on their geometries, graph neural networks (GNNs) using 3D geometric information have achieved high prediction accuracy in many tasks. However, they often require 3D geometries obtained from high-level quantum mechanical calculations, which are practically infeasible, limiting their applicability to real-world problems. To tackle this, we propose a new training framework, GeoTMI, that employs denoising process to predict properties accurately using easy-to-obtain geometries (corrupted versions of correct geometries, such as those obtained from low-level calculations). Our starting point was the idea that the correct geometry is the best description of the target property. Hence, to incorporate information of the correct, GeoTMI aims to maximize mutual information between three variables: the correct and the corrupted geometries and the property. GeoTMI also explicitly updates the corrupted input to approach the correct geometry as it passes through the GNN layers, contributing to more effective denoising. We investigated the performance of the proposed method using 3D GNNs for three prediction tasks: molecular properties, a chemical reaction property, and relaxed energy in a heterogeneous catalytic system. Our results showed consistent improvements in accuracy across various tasks, demonstrating the effectiveness and robustness of GeoTMI",
    "checked": false,
    "id": "51f0fd6c6ea9276b4dbaa7ec2835257baa75eba3",
    "semantic_title": "geotmi:predicting quantum chemical property with easy-to-obtain geometry via positional denoising",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=BTRcVP7ZJn": {
    "title": "Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing",
    "volume": "poster",
    "abstract": "Pruning schemes have been widely used in practice to reduce the complexity of trained models with a massive number of parameters. In fact, several practical studies have shown that if the pruned model is fine-tuned with some gradient-based updates it generalizes well to new samples. Although the above pipeline, which we refer to as pruning + fine-tuning, has been extremely successful in lowering the complexity of trained models, there is very little known about the theory behind this success. In this paper we address this issue by investigating the pruning + fine-tuning framework on the overparameterized matrix sensing problem with the ground truth denoted $U_\\star \\in \\mathbb{R}^{d \\times r}$ and the overparameterized model $U \\in \\mathbb{R}^{d \\times k}$ with $k \\gg r$. We study the approximate local minima of the mean square error, augmented with a smooth version of a group Lasso regularizer, $\\sum_{i=1}^{k} \\lVert Ue_i \\rVert_2 $. In particular, we provably show that pruning all the columns below a certain explicit $\\ell_2$-norm threshold results in a solution $U_{\\text{prune}}$ which has the minimum number of columns $r$, yet close to the ground truth in training loss. Moreover, in the subsequent fine-tuning phase, gradient descent initialized at $U_{\\text{prune}}$ converges at a linear rate to its limit. While our analysis provides insights into the role of regularization in pruning, we also show that running gradient descent in the absence of regularization results in models which {are not suitable for greedy pruning}, i.e., many columns could have their $\\ell_2$ norm comparable to that of the maximum. Lastly, we show that our results also extend for the training and pruning of two-layer neural networks with quadratic activation functions. To the best of our knowledge, our results provide the first rigorous insights on why greedy pruning + fine-tuning leads to smaller models which also generalize well",
    "checked": false,
    "id": "02c79727ab428d3a2a7bb915193801f9ea710779",
    "semantic_title": "greedy pruning with group lasso provably generalizes for matrix sensing and neural networks with quadratic activations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MamHShmHiX": {
    "title": "Approximate inference of marginals using the IBIA framework",
    "volume": "poster",
    "abstract": "Exact inference of marginals in probabilistic graphical models (PGM) is known to be intractable, necessitating the use of approximate methods. Most of the existing variational techniques perform iterative message passing in loopy graphs which is slow to converge for many benchmarks. In this paper, we propose a new algorithm for marginal inference that is based on the incremental build-infer-approximate (IBIA) paradigm. Our algorithm converts the PGM into a sequence of linked clique tree forests (SLCTF) with bounded clique sizes, and then uses a heuristic belief update algorithm to infer the marginals. For the special case of Bayesian networks, we show that if the incremental build step in IBIA uses the topological order of variables then (a) the prior marginals are consistent in all CTFs in the SLCTF and (b) the posterior marginals are consistent once all evidence variables are added to the SLCTF. In our approach, the belief propagation step is non-iterative and the accuracy-complexity trade-off is controlled using user-defined clique size bounds. Results for several benchmark sets from recent UAI competitions show that our method gives either better or comparable accuracy than existing variational and sampling based methods, with smaller runtimes",
    "checked": true,
    "id": "ffbe50603c25a6d96c9cb8d7aeb9f4bafe5243aa",
    "semantic_title": "approximate inference of marginals using the ibia framework",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oMm1dfo3tK": {
    "title": "Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo",
    "volume": "poster",
    "abstract": "In this paper, we propose Barrier Hamiltonian Monte Carlo (BHMC), a version of the HMC algorithm which aims at sampling from a Gibbs distribution $\\pi$ on a manifold $\\mathsf{M}$, endowed with a Hessian metric $\\mathfrak{g}$ derived from a self-concordant barrier. Our method relies on Hamiltonian dynamics which comprises $\\mathfrak{g}$. Therefore, it incorporates the constraints defining $\\mathsf{M}$ and is able to exploit its underlying geometry. However, the corresponding Hamiltonian dynamics is defined via non separable Ordinary Differential Equations (ODEs) in contrast to the Euclidean case. It implies unavoidable bias in existing generalization of HMC to Riemannian manifolds. In this paper, we propose a new filter step, called ``involution checking step'', to address this problem. This step is implemented in two versions of BHMC, coined continuous BHMC (c-bHMC) and numerical BHMC (n-BHMC) respectively. Our main results establish that these two new algorithms generate reversible Markov chains with respect to $\\pi$ and do not suffer from any bias in comparison to previous implementations. Our conclusions are supported by numerical experiments where we consider target distributions defined on polytopes",
    "checked": true,
    "id": "7d9c23f4f1ac60d09957097d4ab811dab7160848",
    "semantic_title": "unbiased constrained sampling with self-concordant barrier hamiltonian monte carlo",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Z16jo3d6OD": {
    "title": "A Unified Framework for Rank-based Loss Minimization",
    "volume": "poster",
    "abstract": "The empirical loss, commonly referred to as the average loss, is extensively utilized for training machine learning models. However, in order to address the diverse performance requirements of machine learning models, the use of the rank-based loss is prevalent, replacing the empirical loss in many cases. The rank-based loss comprises a weighted sum of sorted individual losses, encompassing both convex losses like the spectral risk, which includes the empirical risk and conditional value-at-risk, and nonconvex losses such as the human-aligned risk and the sum of the ranked range loss. In this paper, we introduce a unified framework for the optimization of the rank-based loss through the utilization of a proximal alternating direction method of multipliers. We demonstrate the convergence and convergence rate of the proposed algorithm under mild conditions. Experiments conducted on synthetic and real datasets illustrate the effectiveness and efficiency of the proposed algorithm",
    "checked": true,
    "id": "60b26fc17d8495b9880b4589396ee7baded530ed",
    "semantic_title": "a unified framework for rank-based loss minimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xbbknN9QFs": {
    "title": "On Evaluating Adversarial Robustness of Large Vision-Language Models",
    "volume": "poster",
    "abstract": "Large vision-language models (VLMs) such as GPT-4 have achieved unprecedented performance in response generation, especially with visual inputs, enabling more creative and adaptable interaction than large language models such as ChatGPT. Nonetheless, multimodal generation exacerbates safety concerns, since adversaries may successfully evade the entire system by subtly manipulating the most vulnerable modality (e.g., vision). To this end, we propose evaluating the robustness of open-source large VLMs in the most realistic and high-risk setting, where adversaries have only black-box system access and seek to deceive the model into returning the targeted responses. In particular, we first craft targeted adversarial examples against pretrained models such as CLIP and BLIP, and then transfer these adversarial examples to other VLMs such as MiniGPT-4, LLaVA, UniDiffuser, BLIP-2, and Img2Prompt. In addition, we observe that black-box queries on these VLMs can further improve the effectiveness of targeted evasion, resulting in a surprisingly high success rate for generating targeted responses. Our findings provide a quantitative understanding regarding the adversarial vulnerability of large VLMs and call for a more thorough examination of their potential security flaws before deployment in practice. Our project page: https://yunqing-me.github.io/AttackVLM/",
    "checked": true,
    "id": "8ecdbfe011b7189fa0ee49ffc4e42a93d728a371",
    "semantic_title": "on evaluating adversarial robustness of large vision-language models",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=90O5cvFZkZ": {
    "title": "GUST: Combinatorial Generalization by Unsupervised Grouping with Neuronal Coherence",
    "volume": "poster",
    "abstract": "Dynamically grouping sensory information into structured entities is essential for understanding the world of combinatorial nature. However, the grouping ability and therefore combinatorial generalization are still challenging artificial neural networks. Inspired by the evidence that successful grouping is indicated by neuronal coherence in the human brain, we introduce GUST (Grouping Unsupervisely by Spike Timing network), an iterative network architecture with biological constraints to bias the network towards a dynamical state of neuronal coherence that softly reflects the grouping information in the temporal structure of its spiking activity. We evaluate and analyze the model on synthetic datasets. Interestingly, the segregation ability is directly learned from superimposed stimuli with a succinct unsupervised objective. Two learning stages are present, from coarsely perceiving global features to additionally capturing local features. Further, the learned symbol-like building blocks can be systematically composed to represent novel scenes in a bio-plausible manner",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yj3lFEyfnl": {
    "title": "Boosting Learning for LDPC Codes to Improve the Error-Floor Performance",
    "volume": "poster",
    "abstract": "Low-density parity-check (LDPC) codes have been successfully commercialized in communication systems due to their strong error correction capabilities and simple decoding process. However, the error-floor phenomenon of LDPC codes, in which the error rate stops decreasing rapidly at a certain level, presents challenges for achieving extremely low error rates and deploying LDPC codes in scenarios demanding ultra-high reliability. In this work, we propose training methods for neural min-sum (NMS) decoders to eliminate the error-floor effect. First, by leveraging the boosting learning technique of ensemble networks, we divide the decoding network into two neural decoders and train the post decoder to be specialized for uncorrected words that the first decoder fails to correct. Secondly, to address the vanishing gradient issue in training, we introduce a block-wise training schedule that locally trains a block of weights while retraining the preceding block. Lastly, we show that assigning different weights to unsatisfied check nodes effectively lowers the error-floor with a minimal number of weights. By applying these training methods to standard LDPC codes, we achieve the best error-floor performance compared to other decoding methods. The proposed NMS decoder, optimized solely through novel training methods without additional modules, can be integrated into existing LDPC decoders without incurring extra hardware costs. The source code is available at https://github.com/ghy1228/LDPC_Error_Floor",
    "checked": true,
    "id": "b6349b90ff724023ad9281f539cecfd2e0f305bf",
    "semantic_title": "boosting learning for ldpc codes to improve the error-floor performance",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=apjOYp3mOa": {
    "title": "LICO: Explainable Models with Language-Image COnsistency",
    "volume": "poster",
    "abstract": "Interpreting the decisions of deep learning models has been actively studied since the explosion of deep neural networks. One of the most convincing interpretation approaches is salience-based visual interpretation, such as Grad-CAM, where the generation of attention maps depends merely on categorical labels. Although existing interpretation methods can provide explainable decision clues, they often yield partial correspondence between image and saliency maps due to the limited discriminative information from one-hot labels. This paper develops a Language-Image COnsistency model for explainable image classification, termed LICO, by correlating learnable linguistic prompts with corresponding visual features in a coarse-to-fine manner. Specifically, we first establish a coarse global manifold structure alignment by minimizing the distance between the distributions of image and language features. We then achieve fine-grained saliency maps by applying optimal transport (OT) theory to assign local feature maps with class-specific prompts. Extensive experimental results on eight benchmark datasets demonstrate that the proposed LICO achieves a significant improvement in generating more explainable attention maps in conjunction with existing interpretation methods such as Grad-CAM. Remarkably, LICO improves the classification performance of existing models without introducing any computational overhead during inference",
    "checked": true,
    "id": "5a3744d3c871730661ff0f32330b0810608a9ca8",
    "semantic_title": "lico: explainable models with language-image consistency",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oScaeIibRx": {
    "title": "Softmax Output Approximation for Activation Memory-Efficient Training of Attention-based Networks",
    "volume": "poster",
    "abstract": "In this paper, we propose to approximate the softmax output, which is the key product of the attention mechanism, to reduce its activation memory usage when training attention-based networks (aka Transformers). During the forward pass of the network, the proposed softmax output approximation method stores only a small fraction of the entire softmax output required for back-propagation and evicts the rest of the softmax output from memory. Then, during the backward pass, the evicted softmax activation output is approximated to compose the gradient to perform back-propagation for model training. Considering most attention-based models heavily rely on the softmax-based attention module that usually takes one of the biggest portions of the network, approximating the softmax activation output can be a simple yet effective way to decrease the training memory requirement of many attention-based networks. The experiment with various attention-based models and relevant tasks, i.e., machine translation, text classification, and sentiment analysis, shows that it curtails the activation memory usage of the softmax-based attention module by up to 84% (6.2× less memory) in model training while achieving comparable or better performance, e.g., up to 5.4% higher classification accuracy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N0m9c0FqUV": {
    "title": "Active Learning-Based Species Range Estimation",
    "volume": "poster",
    "abstract": "We propose a new active learning approach for efficiently estimating the geographic range of a species from a limited number of on the ground observations. We model the range of an unmapped species of interest as the weighted combination of estimated ranges obtained from a set of different species. We show that it is possible to generate this candidate set of ranges by using models that have been trained on large weakly supervised community collected observation data. From this, we develop a new active querying approach that sequentially selects geographic locations to visit that best reduce our uncertainty over an unmapped species' range. We conduct a detailed evaluation of our approach and compare it to existing active learning methods using an evaluation dataset containing expert-derived ranges for one thousand species. Our results demonstrate that our method outperforms alternative active learning methods and approaches the performance of end-to-end trained models, even when only using a fraction of the data. This highlights the utility of active learning via transfer learned spatial representations for species range estimation. It also emphasizes the value of leveraging emerging large-scale crowdsourced datasets, not only for modeling a species' range, but also for actively discovering them",
    "checked": true,
    "id": "80271ec5eff54439f5ac7433b08d09c33068c820",
    "semantic_title": "active learning-based species range estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7WQt1J13ex": {
    "title": "Generative Modeling through the Semi-dual Formulation of Unbalanced Optimal Transport",
    "volume": "poster",
    "abstract": "Optimal Transport (OT) problem investigates a transport map that bridges two distributions while minimizing a given cost function. In this regard, OT between tractable prior distribution and data has been utilized for generative modeling tasks. However, OT-based methods are susceptible to outliers and face optimization challenges during training. In this paper, we propose a novel generative model based on the semi-dual formulation of Unbalanced Optimal Transport (UOT). Unlike OT, UOT relaxes the hard constraint on distribution matching. This approach provides better robustness against outliers, stability during training, and faster convergence. We validate these properties empirically through experiments. Moreover, we study the theoretical upper-bound of divergence between distributions in UOT. Our model outperforms existing OT-based generative models, achieving FID scores of 2.97 on CIFAR-10 and 5.80 on CelebA-HQ-256. The code is available at \\url{https://github.com/Jae-Moo/UOTM}",
    "checked": true,
    "id": "705e0046d23d66f0bfcefc06814716041df181c9",
    "semantic_title": "generative modeling through the semi-dual formulation of unbalanced optimal transport",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=Oc1SIKxwdV": {
    "title": "Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors",
    "volume": "poster",
    "abstract": "Deployed language models decay over time due to shifting inputs, changing user needs, or emergent world-knowledge gaps. When such problems are identified, we want to make targeted edits while avoiding expensive retraining. However, current model editors, which modify such behaviors of pre-trained models, degrade model performance quickly across multiple, sequential edits. We propose GRACE, a \\textit{lifelong} model editing method, which implements spot-fixes on streaming errors of a deployed model, ensuring minimal impact on unrelated inputs. GRACE writes new mappings into a pre-trained model's latent space, creating a discrete, local codebook of edits without altering model weights. This is the first method enabling thousands of sequential edits using only streaming errors. Our experiments on T5, BERT, and GPT models show GRACE's state-of-the-art performance in making and retaining edits, while generalizing to unseen inputs. Our code is available at [github.com/thartvigsen/grace](https://www.github.com/thartvigsen/grace})",
    "checked": true,
    "id": "560b1bc012588731b26748e33236570df777baa0",
    "semantic_title": "aging with grace: lifelong model editing with discrete key-value adaptors",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=R6wXP7txer": {
    "title": "The Utility of \"Even if\" Semifactual Explanation to Optimise Positive Outcomes",
    "volume": "poster",
    "abstract": "When users receive either a positive or negative outcome from an automated system, Explainable AI (XAI) has almost exclusively focused on how to mutate negative outcomes into positive ones by crossing a decision boundary using counterfactuals (e.g., *\"If you earn 2k more, we will accept your loan application\"*). Here, we instead focus on positive outcomes, and take the novel step of using XAI to optimise them (e.g., *\"Even if you wish to half your down-payment, we will still accept your loan application\"*). Explanations such as these that employ \"even if...\" reasoning, and do not cross a decision boundary, are known as semifactuals. To instantiate semifactuals in this context, we introduce the concept of *Gain* (i.e., how much a user stands to benefit from the explanation), and consider the first causal formalisation of semifactuals. Tests on benchmark datasets show our algorithms are better at maximising gain compared to prior work, and that causality is important in the process. Most importantly however, a user study supports our main hypothesis by showing people find semifactual explanations more useful than counterfactuals when they receive the positive outcome of a loan acceptance",
    "checked": false,
    "id": "93055cf2cf5f59adbca7bf928810094a39055f93",
    "semantic_title": "the utility of \"even if...\" semifactual explanation to optimise positive outcomes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RACcp8Zbr9": {
    "title": "Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions",
    "volume": "poster",
    "abstract": "We study the tradeoff between consistency and robustness in the context of a single-trajectory time-varying Markov Decision Process (MDP) with untrusted machine-learned advice. Our work departs from the typical approach of treating advice as coming from black-box sources by instead considering a setting where additional information about how the advice is generated is available. We prove a first-of-its-kind consistency and robustness tradeoff given Q-value advice under a general MDP model that includes both continuous and discrete state/action spaces. Our results highlight that utilizing Q-value advice enables dynamic pursuit of the better of machine-learned advice and a robust baseline, thus result in near-optimal performance guarantees, which provably improves what can be obtained solely with black-box advice",
    "checked": true,
    "id": "3e54661d0bbb13f3840bae07c2e288225fa537f7",
    "semantic_title": "beyond black-box advice: learning-augmented algorithms for mdps with q-value predictions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=zAXg8dW8ZO": {
    "title": "One-Line-of-Code Data Mollification Improves Optimization of Likelihood-based Generative Models",
    "volume": "poster",
    "abstract": "Generative Models (GMs) have attracted considerable attention due to their tremendous success in various domains, such as computer vision where they are capable to generate impressive realistic-looking images. Likelihood-based GMs are attractive due to the possibility to generate new data by a single model evaluation. However, they typically achieve lower sample quality compared to state-of-the-art score-based Diffusion Models (DMs). This paper provides a significant step in the direction of addressing this limitation. The idea is to borrow one of the strengths of score-based DMs, which is the ability to perform accurate density estimation in low-density regions and to address manifold overfitting by means of data mollification. We propose a view of data mollification within likelihood-based GMs as a continuation method, whereby the optimization objective smoothly transitions from simple-to-optimize to the original target. Crucially, data mollification can be implemented by adding one line of code in the optimization loop, and we demonstrate that this provides a boost in generation quality of likelihood-based GMs, without computational overheads. We report results on real-world image data sets and UCI benchmarks with popular likelihood-based GMs, including variants of variational autoencoders and normalizing flows, showing large improvements in FID score and density estimation",
    "checked": true,
    "id": "7323db3dcdcadd23df7322329b99e2392d4216b5",
    "semantic_title": "one-line-of-code data mollification improves optimization of likelihood-based generative models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PJhjkSFlbG": {
    "title": "Dynamics Generalisation in Reinforcement Learning via Adaptive Context-Aware Policies",
    "volume": "poster",
    "abstract": "While reinforcement learning has achieved remarkable successes in several domains, its real-world application is limited due to many methods failing to generalise to unfamiliar conditions. In this work, we consider the problem of generalising to new transition dynamics, corresponding to cases in which the environment's response to the agent's actions differs. For example, the gravitational force exerted on a robot depends on its mass and changes the robot's mobility. Consequently, in such cases, it is necessary to condition an agent's actions on extrinsic state information and pertinent contextual information reflecting how the environment responds. While the need for context-sensitive policies has been established, the manner in which context is incorporated architecturally has received less attention. Thus, in this work, we present an investigation into how context information should be incorporated into behaviour learning to improve generalisation. To this end, we introduce a neural network architecture, the Decision Adapter, which generates the weights of an adapter module and conditions the behaviour of an agent on the context information. We show that the Decision Adapter is a useful generalisation of a previously proposed architecture and empirically demonstrate that it results in superior generalisation performance compared to previous approaches in several environments. Beyond this, the Decision Adapter is more robust to irrelevant distractor variables than several alternative methods",
    "checked": true,
    "id": "858d4a0fb0c005cec34f109d55baf0c256a10f20",
    "semantic_title": "dynamics generalisation in reinforcement learning via adaptive context-aware policies",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WYYpxVsKpR": {
    "title": "Necessary and Sufficient Conditions for Optimal Decision Trees using Dynamic Programming",
    "volume": "poster",
    "abstract": "Global optimization of decision trees has shown to be promising in terms of accuracy, size, and consequently human comprehensibility. However, many of the methods used rely on general-purpose solvers for which scalability remains an issue. Dynamic programming methods have been shown to scale much better because they exploit the tree structure by solving subtrees as independent subproblems. However, this only works when an objective can be optimized separately for subtrees. We explore this relationship in detail and show necessary and sufficient conditions for such separability and generalize previous dynamic programming approaches into a framework that can optimize any combination of separable objectives and constraints. Experiments on five application domains show the general applicability of this framework, while outperforming the scalability of general-purpose solvers by a large margin",
    "checked": false,
    "id": "b284ee247d440b669451bf42daf16d9d47430ca7",
    "semantic_title": "optimal decision trees for separable objectives: pushing the limits of dynamic programming",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XOotfgPiUF": {
    "title": "FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models",
    "volume": "poster",
    "abstract": "Semantic segmentation has witnessed tremendous progress due to the proposal of various advanced network architectures. However, they are extremely hungry for delicate annotations to train, and the acquisition is laborious and unaffordable. Therefore, we present FreeMask in this work, which resorts to synthetic images from generative models to ease the burden of both data collection and annotation procedures. Concretely, we first synthesize abundant training images conditioned on the semantic masks provided by realistic datasets. This yields extra well-aligned image-mask training pairs for semantic segmentation models. We surprisingly observe that, solely trained with synthetic images, we already achieve comparable performance with real ones (e.g., 48.3 vs. 48.5 mIoU on ADE20K, and 49.3 vs. 50.5 on COCO-Stuff). Then, we investigate the role of synthetic images by joint training with real images, or pre-training for real images. Meantime, we design a robust filtering principle to suppress incorrectly synthesized regions. In addition, we propose to inequally treat different semantic masks to prioritize those harder ones and sample more corresponding synthetic images for them. As a result, either jointly trained or pre-trained with our filtered and re-sampled synthesized images, segmentation models can be greatly enhanced, e.g., from 48.7 to 52.0 on ADE20K",
    "checked": true,
    "id": "9d0e80302cdd1cfac77637591e140053d2524d7c",
    "semantic_title": "freemask: synthetic images with dense annotations make stronger segmentation models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yjYwbZBJyl": {
    "title": "Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension",
    "volume": "poster",
    "abstract": "The success of over-parameterized neural networks trained to near-zero training error has caused great interest in the phenomenon of benign overfitting, where estimators are statistically consistent even though they interpolate noisy training data. While benign overfitting in fixed dimension has been established for some learning methods, current literature suggests that for regression with typical kernel methods and wide neural networks, benign overfitting requires a high-dimensional setting, where the dimension grows with the sample size. In this paper, we show that the smoothness of the estimators, and not the dimension, is the key: benign overfitting is possible if and only if the estimator's derivatives are large enough. We generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension. Conversely, we show that benign overfitting is possible for regression with a sequence of spiky-smooth kernels with large derivatives. Using neural tangent kernels, we translate our results to wide neural networks. We prove that while infinite-width networks do not overfit benignly with the ReLU activation, this can be fixed by adding small high-frequency fluctuations to the activation function. Our experiments verify that such neural networks, while overfitting, can indeed generalize well even on low-dimensional data sets",
    "checked": true,
    "id": "5dc47ebf42525aed852644c8281bf750705051e6",
    "semantic_title": "mind the spikes: benign overfitting of kernels and neural networks in fixed dimension",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4IWJZjbRFj": {
    "title": "Removing Hidden Confounding in Recommendation: A Unified Multi-Task Learning Approach",
    "volume": "poster",
    "abstract": "In recommender systems, the collected data used for training is always subject to selection bias, which poses a great challenge for unbiased learning. Previous studies proposed various debiasing methods based on observed user and item features, but ignored the effect of hidden confounding. To address this problem, recent works suggest the use of sensitivity analysis for worst-case control of the unknown true propensity, but only valid when the true propensity is near to the nominal propensity within a finite bound. In this paper, we first perform theoretical analysis to reveal the possible failure of previous approaches, including propensity-based, multi-task learning, and bi-level optimization methods, in achieving unbiased learning when hidden confounding is present. Then, we propose a unified multi-task learning approach to remove hidden confounding, which uses a few unbiased ratings to calibrate the learned nominal propensities and nominal error imputations from biased data. We conduct extensive experiments on three publicly available benchmark datasets containing a fully exposed large-scale industrial dataset, validating the effectiveness of the proposed methods in removing hidden confounding",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BopG5dhH7L": {
    "title": "A Computationally Efficient Sparsified Online Newton Method",
    "volume": "poster",
    "abstract": "Second-order methods hold significant promise for enhancing the convergence of deep neural network training; however, their large memory and computational demands have limited their practicality. Thus there is a need for scalable second-order methods that can efficiently train large models. In this paper, we introduce the Sparsified Online Newton~(SONew) method, a memory-efficient second-order algorithm that yields a sparsified yet effective preconditioner. The algorithm emerges from a novel use of the LogDet matrix divergence measure; we combine it with sparsity constraints to minimize regret in the online convex optimization framework. Empirically, we test our method on large scale benchmarks of up to 1B parameters. We achieve up to $30\\\\%$ faster convergence, $3.4\\\\%$ relative improvement in validation performance, and $80\\\\%$ relative improvement in training loss, in comparison to memory efficient optimizers including first order methods. Powering the method is a surprising fact -- imposing structured sparsity patterns, like tridiagonal and banded structure, requires little to no overhead, making it as efficient and parallelizable as first-order methods. In wall-clock time, tridiagonal SONew is only about $3\\\\%$ slower per step than first-order methods but gives overall gains due to much faster convergence. In contrast, one of the state-of-the-art (SOTA) memory-intensive second-order methods, Shampoo, is unable to scale to large benchmarks. Additionally, while Shampoo necessitates significant engineering efforts to scale to large benchmarks, SONew offers a more straightforward implementation, increasing its practical appeal. SONew code is available at: https://github.com/devvrit/SONew",
    "checked": true,
    "id": "d1041b5cfb05bfd404025804199517f37b5765a8",
    "semantic_title": "a computationally efficient sparsified online newton method",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yvpenkym8A": {
    "title": "Integration-free Training for Spatio-temporal Multimodal Covariate Deep Kernel Point Processes",
    "volume": "poster",
    "abstract": "In this study, we propose a novel deep spatio-temporal point process model, Deep Kernel Mixture Point Processes (DKMPP), that incorporates multimodal covariate information. DKMPP is an enhanced version of Deep Mixture Point Processes (DMPP), which uses a more flexible deep kernel to model complex relationships between events and covariate data, improving the model's expressiveness. To address the intractable training procedure of DKMPP due to the non-integrable deep kernel, we utilize an integration-free method based on score matching, and further improve efficiency by adopting a scalable denoising score matching method. Our experiments demonstrate that DKMPP and its corresponding score-based estimators outperform baseline models, showcasing the advantages of incorporating covariate information, utilizing a deep kernel, and employing score-based estimators",
    "checked": true,
    "id": "475af20b4207156cb822df420545a24ae33138a2",
    "semantic_title": "integration-free training for spatio-temporal multimodal covariate deep kernel point processes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mr4OpbZEiB": {
    "title": "Task-Robust Pre-Training for Worst-Case Downstream Adaptation",
    "volume": "poster",
    "abstract": "Pre-training has achieved remarkable success when transferred to downstream tasks. In machine learning, we care about not only the good performance of a model but also its behavior under reasonable shifts of condition. The same philosophy holds when pre-training a foundation model. However, the foundation model may not uniformly behave well for a series of related downstream tasks. This happens, for example, when conducting mask recovery regression where the recovery ability or the training instances diverge like pattern features are extracted dominantly on pre-training, but semantic features are also required on a downstream task. This paper considers pre-training a model that guarantees a uniformly good performance over the downstream tasks. We call this goal as *downstream-task robustness*. Our method first separates the upstream task into several representative ones and applies a simple minimax loss for pre-training. We then design an efficient algorithm to solve the minimax loss and prove its convergence in the convex setting. In the experiments, we show both on large-scale natural language processing and computer vision datasets our method increases the metrics on worse-case downstream tasks. Additionally, some theoretical explanations for why our loss is beneficial are provided. Specifically, we show fewer samples are inherently required for the most challenging downstream task in some cases",
    "checked": true,
    "id": "6ce1d63d8d56d1f45c09316b0c0314b405f86a66",
    "semantic_title": "task-robust pre-training for worst-case downstream adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8HzOyg1ngp": {
    "title": "Efficient Subgame Refinement for Extensive-form Games",
    "volume": "poster",
    "abstract": "Subgame solving is an essential technique in addressing large imperfect information games, with various approaches developed to enhance the performance of refined strategies in the abstraction of the target subgame. However, directly applying existing subgame solving techniques may be difficult, due to the intricate nature and substantial size of many real-world games. To overcome this issue, recent subgame solving methods allow for subgame solving on limited knowledge order subgames, increasing their applicability in large games; yet this may still face obstacles due to extensive information set sizes. To address this challenge, we propose a generative subgame solving (GS2) framework, which utilizes a generation function to identify a subset of the earliest-reached nodes, reducing the size of the subgame. Our method is supported by a theoretical analysis and employs a diversity-based generation function to enhance safety. Experiments conducted on medium-sized games as well as the challenging large game of GuanDan demonstrate a significant improvement over the blueprint",
    "checked": false,
    "id": "e74d0a1ba493420145f641f438d303952c78a978",
    "semantic_title": "safe subgame resolving for extensive form correlated equilibrium",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EkcO9tHm6S": {
    "title": "Recaptured Raw Screen Image and Video Demoiréing via Channel and Spatial Modulations",
    "volume": "poster",
    "abstract": "Capturing screen contents by smartphone cameras has become a common way for information sharing. However, these images and videos are often degraded by moiré patterns, which are caused by frequency aliasing between the camera filter array and digital display grids. We observe that the moiré patterns in raw domain is simpler than those in sRGB domain, and the moiré patterns in raw color channels have different properties. Therefore, we propose an image and video demoiréing network tailored for raw inputs. We introduce a color-separated feature branch, and it is fused with the traditional feature-mixed branch via channel and spatial modulations. Specifically, the channel modulation utilizes modulated color-separated features to enhance the color-mixed features. The spatial modulation utilizes the feature with large receptive field to modulate the feature with small receptive field. In addition, we build the first well-aligned raw video demoiréing (RawVDemoiré) dataset and propose an efficient temporal alignment method by inserting alternating patterns. Experiments demonstrate that our method achieves state-of-the-art performance for both image and video demoiréing. Our dataset and code will be released after the acceptance of this work",
    "checked": true,
    "id": "df655e4a6dc0c729ba84c61adc9e61e56bf63b13",
    "semantic_title": "recaptured raw screen image and video demoiréing via channel and spatial modulations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hIGZujtOQv": {
    "title": "Unleashing the Power of Graph Data Augmentation on Covariate Distribution Shift",
    "volume": "poster",
    "abstract": "The issue of distribution shifts is emerging as a critical concern in graph representation learning. From the perspective of invariant learning and stable learning, a recently well-established paradigm for out-of-distribution generalization, stable features of the graph are assumed to causally determine labels, while environmental features tend to be unstable and can lead to the two primary types of distribution shifts. The correlation shift is often caused by the spurious correlation between environmental features and labels that differs between the training and test data; the covariate shift often stems from the presence of new environmental features in test data. However, most strategies, such as invariant learning or graph augmentation, typically struggle with limited training environments or perturbed stable features, thus exposing limitations in handling the problem of covariate shift. To address this challenge, we propose a simple-yet-effective data augmentation strategy, Adversarial Invariant Augmentation (AIA), to handle the covariate shift on graphs. Specifically, given the training data, AIA aims to extrapolate and generate new environments, while concurrently preserving the original stable features during the augmentation process. Such a design equips the graph classification model with an enhanced capability to identify stable features in new environments, thereby effectively tackling the covariate shift in data. Extensive experiments with in-depth empirical analysis demonstrate the superiority of our approach. The implementation codes are publicly available at https://github.com/yongduosui/AIA",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Oj7Mrb4009": {
    "title": "Eliminating Catastrophic Overfitting Via Abnormal Adversarial Examples Regularization",
    "volume": "poster",
    "abstract": "Single-step adversarial training (SSAT) has demonstrated the potential to achieve both efficiency and robustness. However, SSAT suffers from catastrophic overfitting (CO), a phenomenon that leads to a severely distorted classifier, making it vulnerable to multi-step adversarial attacks. In this work, we observe that some adversarial examples generated on the SSAT-trained network exhibit anomalous behaviour, that is, although these training samples are generated by the inner maximization process, their associated loss decreases instead, which we named abnormal adversarial examples (AAEs). Upon further analysis, we discover a close relationship between AAEs and classifier distortion, as both the number and outputs of AAEs undergo a significant variation with the onset of CO. Given this observation, we re-examine the SSAT process and uncover that before the occurrence of CO, the classifier already displayed a slight distortion, indicated by the presence of few AAEs. Furthermore, the classifier directly optimizing these AAEs will accelerate its distortion, and correspondingly, the variation of AAEs will sharply increase as a result. In such a vicious circle, the classifier rapidly becomes highly distorted and manifests as CO within a few iterations. These observations motivate us to eliminate CO by hindering the generation of AAEs. Specifically, we design a novel method, termed Abnormal Adversarial Examples Regularization (AAER), which explicitly regularizes the variation of AAEs to hinder the classifier from becoming distorted. Extensive experiments demonstrate that our method can effectively eliminate CO and further boost adversarial robustness with negligible additional computational overhead. Our implementation can be found at https://github.com/tmllab/2023_NeurIPS_AAER",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t7lnhhi7De": {
    "title": "Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network",
    "volume": "poster",
    "abstract": "Generative Flow Networks (GFlowNets), a class of generative models over discrete and structured sample spaces, have been previously applied to the problem of inferring the marginal posterior distribution over the directed acyclic graph (DAG) of a Bayesian Network, given a dataset of observations. Based on recent advances extending this framework to non-discrete sample spaces, we propose in this paper to approximate the joint posterior over not only the structure of a Bayesian Network, but also the parameters of its conditional probability distributions. We use a single GFlowNet whose sampling policy follows a two-phase process: the DAG is first generated sequentially one edge at a time, and then the corresponding parameters are picked once the full structure is known. Since the parameters are included in the posterior distribution, this leaves more flexibility for the local probability models of the Bayesian Network, making our approach applicable even to non-linear models parametrized by neural networks. We show that our method, called JSP-GFN, offers an accurate approximation of the joint posterior, while comparing favorably against existing methods on both simulated and real data",
    "checked": true,
    "id": "6e5e65ec544bc7ec1c18954f678ae586dc553ea1",
    "semantic_title": "joint bayesian inference of graphical structure and parameters with a single generative flow network",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=yBoVwpGa5E": {
    "title": "Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from a Minimax Game Perspective",
    "volume": "poster",
    "abstract": "Adversarial Training (AT) has become arguably the state-of-the-art algorithm for extracting robust features. However, researchers recently notice that AT suffers from severe robust overfitting problems, particularly after learning rate (LR) decay. In this paper, we explain this phenomenon by viewing adversarial training as a dynamic minimax game between the model trainer and the attacker. Specifically, we analyze how LR decay breaks the balance between the minimax game by empowering the trainer with a stronger memorization ability, and show such imbalance induces robust overfitting as a result of memorizing non-robust features. We validate this understanding with extensive experiments, and provide a holistic view of robust overfitting from the dynamics of both the two game players. This understanding further inspires us to alleviate robust overfitting by rebalancing the two players by either regularizing the trainer's capacity or improving the attack strength. Experiments show that the proposed ReBalanced Adversarial Training (ReBAT) can attain good robustness and does not suffer from robust overfitting even after very long training. Code is available at https://github.com/PKU-ML/ReBAT",
    "checked": true,
    "id": "c77538947e7aa9acf298e479624778bca65e4920",
    "semantic_title": "balance, imbalance, and rebalance: understanding robust overfitting from a minimax game perspective",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f3JNQd7CHM": {
    "title": "The Learnability of In-Context Learning",
    "volume": "poster",
    "abstract": "In-context learning is a surprising and important phenomenon that emerged when modern language models were scaled to billions of learned parameters. Without modifying a large language model's weights, it can be tuned to perform various downstream natural language tasks simply by including concatenated training examples of these tasks in its input. Though disruptive for many practical applications of large language models, this emergent learning paradigm is not well understood from a theoretical perspective. In this paper, we propose a first-of-its-kind PAC based framework for in-context learnability, and use it to provide the first finite sample complexity results for the in-context learning setup. Our framework includes an initial pretraining phase, which fits a function to the pretraining distribution, and then a second in-context learning phase, which keeps this function constant and concatenates training examples of the downstream task in its input. We use our framework in order to prove that, under mild assumptions, when the pretraining distribution is a mixture of latent tasks (a model often considered for natural language pretraining), these tasks can be efficiently learned via in-context learning, even though the model's weights are unchanged and the input significantly diverges from the pretraining distribution. Our theoretical analysis reveals that in this setting, in-context learning is more about identifying the task than about learning it, a result which is in line with a series of recent empirical findings. We hope that the in-context learnability framework presented in this paper will facilitate future progress towards a deeper understanding of this important new learning paradigm",
    "checked": true,
    "id": "da3aca9d7b50da823f669c983edeb60445720fe0",
    "semantic_title": "the learnability of in-context learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=Psj0jHocm1": {
    "title": "Contextually Affinitive Neighborhood Refinery for Deep Clustering",
    "volume": "poster",
    "abstract": "Previous endeavors in self-supervised learning have enlightened the research of deep clustering from an instance discrimination perspective. Built upon this foundation, recent studies further highlight the importance of grouping semantically similar instances. One effective method to achieve this is by promoting the semantic structure preserved by neighborhood consistency. However, the samples in the local neighborhood may be limited due to their close proximity to each other, which may not provide substantial and diverse supervision signals. Inspired by the versatile re-ranking methods in the context of image retrieval, we propose to employ an efficient online re-ranking process to mine more informative neighbors in a Contextually Affinitive (ConAff) Neighborhood, and then encourage the cross-view neighborhood consistency. To further mitigate the intrinsic neighborhood noises near cluster boundaries, we propose a progressively relaxed boundary filtering strategy to circumvent the issues brought by noisy neighbors. Our method can be easily integrated into the generic self-supervised frameworks and outperforms the state-of-the-art methods on several popular benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NN60HKTur2": {
    "title": "Extracting Reward Functions from Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion models have achieved remarkable results in image generation, and have similarly been used to learn high-performing policies in sequential decision-making tasks. Decision-making diffusion models can be trained on lower-quality data, and then be steered with a reward function to generate near-optimal trajectories. We consider the problem of extracting a reward function by comparing a decision-making diffusion model that models low-reward behavior and one that models high-reward behavior; a setting related to inverse reinforcement learning. We first define the notion of a \\emph{relative reward function of two diffusion models} and show conditions under which it exists and is unique. We then devise a practical learning algorithm for extracting it by aligning the gradients of a reward function -- parametrized by a neural network -- to the difference in outputs of both diffusion models. Our method finds correct reward functions in navigation environments, and we demonstrate that steering the base model with the learned reward functions results in significantly increased performance in standard locomotion benchmarks. Finally, we demonstrate that our approach generalizes beyond sequential decision-making by learning a reward-like function from two large-scale image generation diffusion models. The extracted reward function successfully assigns lower rewards to harmful images",
    "checked": true,
    "id": "7e2af9a5f665e9b6a95c3065f19aa06b1c012db9",
    "semantic_title": "extracting reward functions from diffusion models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=p4SjKPchJy": {
    "title": "Riemannian stochastic optimization methods avoid strict saddle points",
    "volume": "poster",
    "abstract": "Many modern machine learning applications - from online principal component analysis to covariance matrix identification and dictionary learning - can be formulated as minimization problems on Riemannian manifolds, typically solved with a Riemannian stochastic gradient method (or some variant thereof). However, in many cases of interest, the resulting minimization problem is _not_ geodesically convex, so the convergence of the chosen solver to a desirable solution - i.e., a local minimizer - is by no means guaranteed. In this paper, we study precisely this question, that is, whether stochastic Riemannian optimization algorithms are guaranteed to avoid saddle points with probability $1$. For generality, we study a family of retraction-based methods which, in addition to having a potentially much lower per-iteration cost relative to Riemannian gradient descent, include other widely used algorithms, such as natural policy gradient methods and mirror descent in ordinary convex spaces. In this general setting, we show that, under mild assumptions for the ambient manifold and the oracle providing gradient information, the policies under study avoid strict saddle points / submanifolds with probability $1$, from any initial condition. This result provides an important sanity check for the use of gradient methods on manifolds as it shows that, almost always, the end state of a stochastic Riemannian algorithm can only be a local minimizer",
    "checked": true,
    "id": "0a0e53a0c8dfe647cfab76f8c3e5413f759a7811",
    "semantic_title": "riemannian stochastic optimization methods avoid strict saddle points",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AG9A7Ae9r3": {
    "title": "DIFFER:Decomposing Individual Reward for Fair Experience Replay in Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "Cooperative multi-agent reinforcement learning (MARL) is a challenging task, as agents must learn complex and diverse individual strategies from a shared team reward. However, existing methods struggle to distinguish and exploit important individual experiences, as they lack an effective way to decompose the team reward into individual rewards. To address this challenge, we propose DIFFER, a powerful theoretical framework for decomposing individual rewards to enable fair experience replay in MARL. By enforcing the invariance of network gradients, we establish a partial differential equation whose solution yields the underlying individual reward function. The individual TD-error can then be computed from the solved closed-form individual rewards, indicating the importance of each piece of experience in the learning task and guiding the training process. Our method elegantly achieves an equivalence to the original learning framework when individual experiences are homogeneous, while also adapting to achieve more muscular efficiency and fairness when diversity is observed. Our extensive experiments on popular benchmarks validate the effectiveness of our theory and method, demonstrating significant improvements in learning efficiency and fairness. Code is available in supplement material",
    "checked": false,
    "id": "7b211e8d24de8ba3658aa560b87de31856ab9783",
    "semantic_title": "differ: decomposing individual reward for fair experience replay in multi-agent reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mVywRIDNIl": {
    "title": "Reining Generalization in Offline Reinforcement Learning via Representation Distinction",
    "volume": "poster",
    "abstract": "Offline Reinforcement Learning (RL) aims to address the challenge of distribution shift between the dataset and the learned policy, where the value of out-of-distribution (OOD) data may be erroneously estimated due to overgeneralization. It has been observed that a considerable portion of the benefits derived from the conservative terms designed by existing offline RL approaches originates from their impact on the learned representation. This observation prompts us to scrutinize the learning dynamics of offline RL, formalize the process of generalization, and delve into the prevalent overgeneralization issue in offline RL. We then investigate the potential to rein the generalization from the representation perspective to enhance offline RL. Finally, we present Representation Distinction (RD), an innovative plug-in method for improving offline RL algorithm performance by explicitly differentiating between the representations of in-sample and OOD state-action pairs generated by the learning policy. Considering scenarios in which the learning policy mirrors the behavioral policy and similar samples may be erroneously distinguished, we suggest a dynamic adjustment mechanism for RD based on an OOD data generator to prevent data representation collapse and further enhance policy performance. We demonstrate the efficacy of our approach by applying RD to specially-designed backbone algorithms and widely-used offline RL algorithms. The proposed RD method significantly improves their performance across various continuous control tasks on D4RL datasets, surpassing several state-of-the-art offline RL algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vvoWPYqZJA": {
    "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
    "volume": "poster",
    "abstract": "Large-scale pre-training and instruction tuning have been successful at creating general-purpose language models with broad competence. However, building general-purpose vision-language models is challenging due to the rich input distributions and task diversity resulting from the additional visual input. Although vision-language pretraining has been widely studied, vision-language instruction tuning remains under-explored. In this paper, we conduct a systematic and comprehensive study on vision-language instruction tuning based on the pretrained BLIP-2 models. We gather 26 publicly available datasets, covering a wide variety of tasks and capabilities, and transform them into instruction tuning format. Additionally, we introduce an instruction-aware Query Transformer, which extracts informative features tailored to the given instruction. Trained on 13 held-in datasets, InstructBLIP attains state-of-the-art zero-shot performance across all 13 held-out datasets, substantially outperforming BLIP-2 and larger Flamingo models. Our models also lead to state-of-the-art performance when finetuned on individual downstream tasks (e.g., 90.7% accuracy on ScienceQA questions with image contexts). Furthermore, we qualitatively demonstrate the advantages of InstructBLIP over concurrent multimodal models. All InstructBLIP models are open-source",
    "checked": true,
    "id": "8bd6a2a89503be083176f2cc26fabedb79238cbd",
    "semantic_title": "instructblip: towards general-purpose vision-language models with instruction tuning",
    "citation_count": 221,
    "authors": []
  },
  "https://openreview.net/forum?id=AmwgBjXqc3": {
    "title": "Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness",
    "volume": "poster",
    "abstract": "Counterfactual fairness requires that a person would have been classified in the same way by an AI or other algorithmic system if they had a different protected class, such as a different race or gender. This is an intuitive standard, as reflected in the U.S. legal system, but its use is limited because counterfactuals cannot be directly observed in real-world data. On the other hand, group fairness metrics (e.g., demographic parity or equalized odds) are less intuitive but more readily observed. In this paper, we use \\textit{causal context} to bridge the gaps between counterfactual fairness, robust prediction, and group fairness. First, we motivate counterfactual fairness by showing that there is not necessarily a fundamental trade-off between fairness and accuracy because, under plausible conditions, the counterfactually fair predictor is in fact accuracy-optimal in an unbiased target distribution. Second, we develop a correspondence between the causal graph of the data-generating process and which, if any, group fairness metrics are equivalent to counterfactual fairness. Third, we show that in three common fairness contexts—measurement error, selection on label, and selection on predictors—counterfactual fairness is equivalent to demographic parity, equalized odds, and calibration, respectively. Counterfactual fairness can sometimes be tested by measuring relatively simple group fairness metrics",
    "checked": true,
    "id": "e204c4a15d1d06fabb760f41fa6603bbe64a2714",
    "semantic_title": "causal context connects counterfactual fairness to robust prediction and group fairness",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TjJJmcHw9p": {
    "title": "Exact recovery and Bregman hard clustering of node-attributed Stochastic Block Model",
    "volume": "poster",
    "abstract": "Classic network clustering tackles the problem of identifying sets of nodes (communities) that have similar connection patterns. However, in many scenarios nodes also have attributes that are correlated and can also be used to identify node clusters. Thus, network information (edges) and node information (attributes) can be jointly leveraged to design high-performance clustering algorithms. Under a general model for the network and node attributes, this work establishes an information-theoretic criteria for the exact recovery of community labels and characterizes a phase transition determined by the Chernoff-Hellinger divergence of the model. The criteria shows how network and attribute information can be exchanged in order to have exact recovery (e.g., more reliable network information requires less reliable attribute information). This work also presents an iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attributes belong to exponential families. This covers a broad range of possible interactions (e.g., edges with weights) and attributes (e.g., non-Gaussian models) while also exploring the connection between exponential families and Bregman divergences. Extensive numerical experiments using synthetic and real data indicate that the proposed algorithm outperforms algorithms that leverage only network or only attribute information as well as recently proposed algorithms that perform clustering using both sources of information. The contributions of this work provide insights into the fundamental limits and practical techniques for inferring community labels on node-attributed networks",
    "checked": true,
    "id": "eae608b83d3952344b85c34a9779971694512555",
    "semantic_title": "exact recovery and bregman hard clustering of node-attributed stochastic block model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YiwMpyMdPX": {
    "title": "Evaluating Neuron Interpretation Methods of NLP Models",
    "volume": "poster",
    "abstract": "Neuron interpretation offers valuable insights into how knowledge is structured within a deep neural network model. While a number of neuron interpretation methods have been proposed in the literature, the field lacks a comprehensive comparison among these methods. This gap hampers progress due to the absence of standardized metrics and benchmarks. The commonly used evaluation metric has limitations, and creating ground truth annotations for neurons is impractical. Addressing these challenges, we propose an evaluation framework based on voting theory. Our hypothesis posits that neurons consistently identified by different methods carry more significant information. We rigorously assess our framework across a diverse array of neuron interpretation methods. Notable findings include: i) despite the theoretical differences among the methods, neuron ranking methods share over 60% of their rankings when identifying salient neurons, ii) the neuron interpretation methods are most sensitive to the last layer representations, iii) Probeless neuron ranking emerges as the most consistent method",
    "checked": true,
    "id": "36e55c0ccc8565ffe816b7c2b5df98e5a209709b",
    "semantic_title": "evaluating neuron interpretation methods of nlp models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=5r3e27I9Gy": {
    "title": "Composing Parameter-Efficient Modules with Arithmetic Operation",
    "volume": "poster",
    "abstract": "As an efficient alternative to conventional full fine-tuning, parameter-efficient fine-tuning (PEFT) is becoming the prevailing method to adapt pretrained language models. In PEFT, a lightweight module is learned on each dataset while the underlying pretrained language model remains unchanged, resulting in multiple compact modules representing diverse skills when applied to various domains and tasks. In this paper, we propose to compose these parameter-efficient modules through linear arithmetic operations in the weight space, thereby integrating different module capabilities. Specifically, we first define an addition and negation operator for the module, and then further compose these two basic operators to perform flexible arithmetic. Our approach requires no additional training and enables highly flexible module composition. We apply different arithmetic operations to compose the parameter-efficient modules for (1) distribution generalization, (2) multi-tasking, (3) detoxifying, and (4) domain transfer. Additionally, we extend our approach to detoxify Alpaca-LoRA, the latest instruction-tuned large language model based on LLaMA. Empirical results demonstrate that our approach produces new and effective parameter-efficient modules that significantly outperform existing ones across all settings",
    "checked": false,
    "id": "7f1a473834eea608980e4e04cce21be18d65b9b6",
    "semantic_title": "composing parameter-efficient modules with arithmetic operations",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=KTRwpWCMsC": {
    "title": "Conformal Prediction for Time Series with Modern Hopfield Networks",
    "volume": "poster",
    "abstract": "To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains",
    "checked": true,
    "id": "5d1f73ab5e3bdc93f10873a9ac8c7579bb2ebf8c",
    "semantic_title": "conformal prediction for time series with modern hopfield networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=7aoVQkNmQ6": {
    "title": "Generalized equivalences between subsampling and ridge regularization",
    "volume": "poster",
    "abstract": "We establish precise structural and risk equivalences between subsampling and ridge regularization for ensemble ridge estimators. Specifically, we prove that linear and quadratic functionals of subsample ridge estimators, when fitted with different ridge regularization levels $\\lambda$ and subsample aspect ratios $\\psi$, are asymptotically equivalent along specific paths in the $(\\lambda,\\psi)$-plane (where $\\psi$ is the ratio of the feature dimension to the subsample size). Our results only require bounded moment assumptions on feature and response distributions and allow for arbitrary joint distributions. Furthermore, we provide a data-dependent method to determine the equivalent paths of $(\\lambda,\\psi)$. An indirect implication of our equivalences is that optimally tuned ridge regression exhibits a monotonic prediction risk in the data aspect ratio. This resolves a recent open problem raised by Nakkiran et al. for general data distributions under proportional asymptotics, assuming a mild regularity condition that maintains regression hardness through linearized signal-to-noise ratios",
    "checked": true,
    "id": "2a860f73917bbc3e45b74ccb189ecca3c4ffb821",
    "semantic_title": "generalized equivalences between subsampling and ridge regularization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=MtekhXRP4h": {
    "title": "Convolutional Neural Operators for robust and accurate learning of PDEs",
    "volume": "poster",
    "abstract": "Although very successfully used in conventional machine learning, convolution based neural network architectures -- believed to be inconsistent in function space -- have been largely ignored in the context of learning solution operators of PDEs. Here, we present novel adaptations for convolutional neural networks to demonstrate that they are indeed able to process functions as inputs and outputs. The resulting architecture, termed as convolutional neural operators (CNOs), is designed specifically to preserve its underlying continuous nature, even when implemented in a discretized form on a computer. We prove a universality theorem to show that CNOs can approximate operators arising in PDEs to desired accuracy. CNOs are tested on a novel suite of benchmarks, encompassing a diverse set of PDEs with multi-scale solutions and are observed to significantly outperform baselines, paving the way for an alternative framework for robust and accurate operator learning",
    "checked": true,
    "id": "39b2f20b885673511e98e5eaf043c9eeded8612b",
    "semantic_title": "convolutional neural operators for robust and accurate learning of pdes",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=qVMPXrX4FR": {
    "title": "LambdaBeam: Neural Program Search with Higher-Order Functions and Lambdas",
    "volume": "poster",
    "abstract": "Search is an important technique in program synthesis that allows for adaptive strategies such as focusing on particular search directions based on execution results. Several prior works have demonstrated that neural models are effective at guiding program synthesis searches. However, a common drawback of those approaches is the inability to handle iterative loops, higher-order functions, or lambda functions, thus limiting prior neural searches from synthesizing longer and more general programs. We address this gap by designing a search algorithm called LambdaBeam that can construct arbitrary lambda functions that compose operations within a given DSL. We create semantic vector representations of the execution behavior of the lambda functions and train a neural policy network to choose which lambdas to construct during search, and pass them as arguments to higher-order functions to perform looping computations. Our experiments show that LambdaBeam outperforms neural, symbolic, and LLM-based techniques in an integer list manipulation domain",
    "checked": true,
    "id": "42a448e89850d5746a34140342ea4781164e3d87",
    "semantic_title": "lambdabeam: neural program search with higher-order functions and lambdas",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=45RBLZBJid": {
    "title": "Accelerated On-Device Forward Neural Network Training with Module-Wise Descending Asynchronism",
    "volume": "poster",
    "abstract": "On-device learning faces memory constraints when optimizing or fine-tuning on edge devices with limited resources. Current techniques for training deep models on edge devices rely heavily on backpropagation. However, its high memory usage calls for a reassessment of its dominance. In this paper, we propose forward gradient descent (FGD) as a potential solution to overcome the memory capacity limitation in on-device learning. However, FGD's dependencies across layers hinder parallel computation and can lead to inefficient resource utilization. To mitigate this limitation, we propose AsyncFGD, an asynchronous framework that decouples dependencies, utilizes module-wise stale parameters, and maximizes parallel computation. We demonstrate its convergence to critical points through rigorous theoretical analysis. Empirical evaluations conducted on NVIDIA's AGX Orin, a popular embedded device, show that AsyncFGD reduces memory consumption and enhances hardware efficiency, offering a novel approach to on-device learning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0FhKURbTyF": {
    "title": "Efficient Potential-based Exploration in Reinforcement Learning using Inverse Dynamic Bisimulation Metric",
    "volume": "poster",
    "abstract": "Reward shaping is an effective technique for integrating domain knowledge into reinforcement learning (RL). However, traditional approaches like potential-based reward shaping totally rely on manually designing shaping reward functions, which significantly restricts exploration efficiency and introduces human cognitive biases. While a number of RL methods have been proposed to boost exploration by designing an intrinsic reward signal as exploration bonus. Nevertheless, these methods heavily rely on the count-based episodic term in their exploration bonus which falls short in scalability. To address these limitations, we propose a general end-to-end potential-based exploration bonus for deep RL via potentials of state discrepancy, which motivates the agent to discover novel states and provides them with denser rewards without manual intervention. Specifically, we measure the novelty of adjacent states by calculating their distance using the bisimulation metric-based potential function, which enhances agent's exploration and ensures policy invariance. In addition, we offer a theoretical guarantee on our inverse dynamic bisimulation metric, bounding the value difference and ensuring that the agent explores states with higher TD error, thus significantly improving training efficiency. The proposed approach is named \\textbf{LIBERTY} (exp\\textbf{L}oration v\\textbf{I}a \\textbf{B}isimulation m\\textbf{E}t\\textbf{R}ic-based s\\textbf{T}ate discrepanc\\textbf{Y}) which is comprehensively evaluated on the MuJoCo and the Arcade Learning Environments. Extensive experiments have verified the superiority and scalability of our algorithm compared with other competitive methods",
    "checked": false,
    "id": "d4838211d7f65628f56b9f6faab30a95ff7b51f8",
    "semantic_title": "for prediction city region re-weighting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q6bVqOgGxP": {
    "title": "Triple Eagle: Simple, Fast and Practical Budget-Feasible Mechanisms",
    "volume": "poster",
    "abstract": "We revisit the classical problem of designing Budget-Feasible Mechanisms (BFMs) for submodular valuation functions, which has been extensively studied since the seminal paper of Singer [FOCS'10] due to its wide applications in crowdsourcing and social marketing. We propose TripleEagle, a novel algorithmic framework for designing BFMs, based on which we present several simple yet effective BFMs that achieve better approximation ratios than the state-of-the-art work. Moreover, our BFMs are the first in the literature to achieve linear complexities while ensuring obvious strategyproofness, making them more practical than the previous BFMs. We conduct extensive experiments to evaluate the empirical performance of our BFMs, and the experimental results strongly demonstrate the efficiency and effectiveness of our approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JzQlGqBm8d": {
    "title": "Block Low-Rank Preconditioner with Shared Basis for Stochastic Optimization",
    "volume": "poster",
    "abstract": "Adaptive methods with non-diagonal preconditioning have shown state-of-the-art results on various tasks. However, their computational complexity and memory requirement makes it challenging to scale these methods to modern neural network architectures. To address this challenge, some previous works have adopted block-diagonal preconditioners. However, the memory cost of storing the block-diagonal matrix remains substantial, leading to the use of smaller block sizes and ultimately resulting in suboptimal performance. To reduce the time and memory complexity without sacrificing performance, we propose approximating each diagonal block of the second moment matrix by low-rank matrices and enforcing the same basis for the blocks within each layer. We provide theoretical justification for such sharing and design an algorithm to efficiently maintain this shared-basis block low-rank approximation during training. Our results on a deep autoencoder and a transformer benchmark demonstrate that the proposed method outperforms first-order methods with slightly more time and memory usage, while also achieving competitive or superior performance compared to other second-order methods with less time and memory usage",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bNNIf8F9OU": {
    "title": "Empowering Collaborative Filtering with Principled Adversarial Contrastive Loss",
    "volume": "poster",
    "abstract": "Contrastive Learning (CL) has achieved impressive performance in self-supervised learning tasks, showing superior generalization ability. Inspired by the success, adopting CL into collaborative filtering (CF) is prevailing in semi-supervised topK recommendations. The basic idea is to routinely conduct heuristic-based data augmentation and apply contrastive losses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges make this adoption suboptimal, such as the issue of out-of-distribution, the risk of false negatives, and the nature of top-K evaluation. They necessitate the CL-based CF scheme to focus more on mining hard negatives and distinguishing false negatives from the vast unlabeled user-item interactions, for informative contrast signals. Worse still, there is limited understanding of contrastive loss in CF methods, especially w.r.t. its generalization ability. To bridge the gap, we delve into the reasons underpinning the success of contrastive loss in CF, and propose a principled Adversarial InfoNCE loss (AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods. AdvInfoNCE adaptively explores and assigns hardness to each negative instance in an adversarial fashion and further utilizes a fine-grained hardness-aware ranking criterion to empower the recommender's generalization ability. Training CF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both synthetic and real-world benchmark datasets, thus showing its generalization ability to mitigate out-of-distribution problems. Given the theoretical guarantees and empirical superiority of AdvInfoNCE over most contrastive loss functions, we advocate its adoption as a standard loss in recommender systems, particularly for the out-of-distribution tasks. Codes are available at https://github.com/LehengTHU/AdvInfoNCE",
    "checked": true,
    "id": "96d47d8e9bdbd88161ef4d807f5add0b42c58a41",
    "semantic_title": "empowering collaborative filtering with principled adversarial contrastive loss",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NapL36HSBT": {
    "title": "Provably Robust Temporal Difference Learning for Heavy-Tailed Rewards",
    "volume": "poster",
    "abstract": "In a broad class of reinforcement learning applications, stochastic rewards have heavy-tailed distributions, which lead to infinite second-order moments for stochastic (semi)gradients in policy evaluation and direct policy optimization. In such instances, the existing RL methods may fail miserably due to frequent statistical outliers. In this work, we establish that temporal difference (TD) learning with a dynamic gradient clipping mechanism, and correspondingly operated natural actor-critic (NAC), can be provably robustified against heavy-tailed reward distributions. It is shown in the framework of linear function approximation that a favorable tradeoff between bias and variability of the stochastic gradients can be achieved with this dynamic gradient clipping mechanism. In particular, we prove that robust versions of TD learning achieve sample complexities of order $\\mathcal{O}(\\varepsilon^{-\\frac{1}{p}})$ and $\\mathcal{O}(\\varepsilon^{-1-\\frac{1}{p}})$ with and without the full-rank assumption on the feature matrix, respectively, under heavy-tailed rewards with finite moments of order $(1+p)$ for some $p\\in(0,1]$, both in expectation and with high probability. We show that a robust variant of NAC based on Robust TD learning achieves $\\tilde{\\mathcal{O}}(\\varepsilon^{-4-\\frac{2}{p}})$ sample complexity. We corroborate our theoretical results with numerical experiments",
    "checked": true,
    "id": "4c0333c745f3a15c4a801215ea22f1123d27486a",
    "semantic_title": "provably robust temporal difference learning for heavy-tailed rewards",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oNuam8eFz2": {
    "title": "Particle-based Variational Inference with Generalized Wasserstein Gradient Flow",
    "volume": "poster",
    "abstract": "Particle-based variational inference methods (ParVIs) such as Stein variational gradient descent (SVGD) update the particles based on the kernelized Wasserstein gradient flow for the Kullback-Leibler (KL) divergence. However, the design of kernels is often non-trivial and can be restrictive for the flexibility of the method. Recent works show that functional gradient flow approximations with quadratic form regularization terms can improve performance. In this paper, we propose a ParVI framework, called generalized Wasserstein gradient descent (GWG), based on a generalized Wasserstein gradient flow of the KL divergence, which can be viewed as a functional gradient method with a broader class of regularizers induced by convex functions. We show that GWG exhibits strong convergence guarantees. We also provide an adaptive version that automatically chooses Wasserstein metric to accelerate convergence. In experiments, we demonstrate the effectiveness and efficiency of the proposed framework on both simulated and real data problems",
    "checked": true,
    "id": "8eb4390ca78625517ca758e37cc3399a6c65e9c2",
    "semantic_title": "particle-based variational inference with generalized wasserstein gradient flow",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s86M8naPSv": {
    "title": "Soft-Unification in Deep Probabilistic Logic",
    "volume": "poster",
    "abstract": "A fundamental challenge in neuro-symbolic AI is to devise primitives that fuse the logical and neural concepts. The Neural Theorem Prover has proposed the notion of soft-unification to turn the symbolic comparison between terms (i.e. unification) into a comparison in embedding space. It has been shown that soft-unification is a powerful mechanism that can be used to learn logic rules in an end-to-end differentiable manner. We study soft-unification from a conceptual point and outline several desirable properties of this operation. These include non-redundancy in the proof, well-defined proof scores, and non-sparse gradients. Unfortunately, these properties are not satisfied by previous systems such as the Neural Theorem Prover. Therefore, we introduce a more principled framework called DeepSoftLog based on probabilistic rather than fuzzy semantics. Our experiments demonstrate that DeepSoftLog can outperform the state-of-the-art on neuro-symbolic benchmarks, highlighting the benefits of these properties",
    "checked": false,
    "id": "4a1a0338634e1bd4c32eb289bb52fe0c7a409abc",
    "semantic_title": "neupsl: neural probabilistic soft logic",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=GtYlxtwO74": {
    "title": "Robust covariance estimation with missing values and cell-wise contamination",
    "volume": "poster",
    "abstract": "Large datasets are often affected by cell-wise outliers in the form of missing or erroneous data. However, discarding any samples containing outliers may result in a dataset that is too small to accurately estimate the covariance matrix. Moreover, the robust procedures designed to address this problem require the invertibility of the covariance operator and thus are not effective on high-dimensional data. In this paper, we propose an unbiased estimator for the covariance in the presence of missing values that does not require any imputation step and still achieves near minimax statistical accuracy with the operator norm. We also advocate for its use in combination with cell-wise outlier detection methods to tackle cell-wise contamination in a high-dimensional and low-rank setting, where state-of-the-art methods may suffer from numerical instability and long computation times. To complement our theoretical findings, we conducted an experimental study which demonstrates the superiority of our approach over the state of the art both in low and high dimension settings",
    "checked": true,
    "id": "80fd879f8ecdddab7876e8169dbdd9d255194047",
    "semantic_title": "robust covariance estimation with missing values and cell-wise contamination",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8lbFwpebeu": {
    "title": "Investigating how ReLU-networks encode symmetries",
    "volume": "poster",
    "abstract": "Many data symmetries can be described in terms of group equivariance and the most common way of encoding group equivariances in neural networks is by building linear layers that are group equivariant. In this work we investigate whether equivariance of a network implies that all layers are equivariant. On the theoretical side we find cases where equivariance implies layerwise equivariance, but also demonstrate that this is not the case generally. Nevertheless, we conjecture that CNNs that are trained to be equivariant will exhibit layerwise equivariance and explain how this conjecture is a weaker version of the recent permutation conjecture by Entezari et al.\\ [2022]. We perform quantitative experiments with VGG-nets on CIFAR10 and qualitative experiments with ResNets on ImageNet to illustrate and support our theoretical findings. These experiments are not only of interest for understanding how group equivariance is encoded in ReLU-networks, but they also give a new perspective on Entezari et al.'s permutation conjecture as we find that it is typically easier to merge a network with a group-transformed version of itself than merging two different networks",
    "checked": true,
    "id": "8659a5e60a3e9c81b4123bc9ad94f2b85162385b",
    "semantic_title": "investigating how relu-networks encode symmetries",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M7FQpIdo0X": {
    "title": "Enhancing Minority Classes by Mixing: An Adaptative Optimal Transport Approach for Long-tailed Classification",
    "volume": "poster",
    "abstract": "Real-world data usually confronts severe class-imbalance problems, where several majority classes have a significantly larger presence in the training set than minority classes. One effective solution is using mixup-based methods to generate synthetic samples to enhance the presence of minority classes. Previous approaches mix the background images from the majority classes and foreground images from the minority classes in a random manner, which ignores the sample-level semantic similarity, possibly resulting in less reasonable or less useful images. In this work, we propose an adaptive image-mixing method based on optimal transport (OT) to incorporate both class-level and sample-level information, which is able to generate semantically reasonable and meaningful mixed images for minority classes. Due to its flexibility, our method can be combined with existing long-tailed classification methods to enhance their performance and it can also serve as a general data augmentation method for balanced datasets. Extensive experiments indicate that our method achieves effective performance for long-tailed classification tasks. The code is available at https://github.com/JintongGao/Enhancing-Minority-Classes-by-Mixing",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oOXZ5JEjPb": {
    "title": "Activity Grammars for Temporal Action Segmentation",
    "volume": "poster",
    "abstract": "Sequence prediction on temporal data requires the ability to understand compositional structures of multi-level semantics beyond individual and contextual properties of parts. The task of temporal action segmentation remains challenging for the reason, aiming at translating an untrimmed activity video into a sequence of action segments. This paper addresses the problem by introducing an effective activity grammar to guide neural predictions for temporal action segmentation. We propose a novel grammar induction algorithm, dubbed KARI, that extracts a powerful context-free grammar from action sequence data. We also develop an efficient generalized parser, dubbed BEP, that transforms frame-level probability distributions into a reliable sequence of actions according to the induced grammar with recursive rules. Our approach can be combined with any neural network for temporal action segmentation to enhance the sequence prediction and discover its compositional structure. Experimental results demonstrate that our method significantly improves temporal action segmentation in terms of both performance and interpretability on two standard benchmarks, Breakfast and 50 Salads",
    "checked": false,
    "id": "bfd8093b1b25f52953e2098182bcef2af97f97c2",
    "semantic_title": "local–global transformer neural network for temporal action segmentation",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=TRbklCR2ZW": {
    "title": "GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER",
    "volume": "poster",
    "abstract": "Video generation necessitates both global coherence and local realism. This work presents a novel non-autoregressive method GLOBER, which first generates global features to obtain comprehensive global guidance and then synthesizes video frames based on the global features to generate coherent videos. Specifically, we propose a video auto-encoder, where a video encoder encodes videos into global features, and a video decoder, built on a diffusion model, decodes the global features and synthesizes video frames in a non-autoregressive manner. To achieve maximum flexibility, our video decoder perceives temporal information through normalized frame indexes, which enables it to synthesize arbitrary sub video clips with predetermined starting and ending frame indexes. Moreover, a novel adversarial loss is introduced to improve the global coherence and local realism between the synthesized video frames. Finally, we employ a diffusion-based video generator to fit the global features outputted by the video encoder for video generation. Extensive experimental results demonstrate the effectiveness and efficiency of our proposed method, and new state-of-the-art results have been achieved on multiple benchmarks",
    "checked": true,
    "id": "4c170259862c65d4077d63ee9784a109aa42c34c",
    "semantic_title": "glober: coherent non-autoregressive video generation via global guided video decoder",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oFpBnt6bgC": {
    "title": "Generate What You Prefer: Reshaping Sequential Recommendation via Guided Diffusion",
    "volume": "poster",
    "abstract": "Sequential recommendation aims to recommend the next item that matches a user's interest, based on the sequence of items he/she interacted with before. Scrutinizing previous studies, we can summarize a common learning-to-classify paradigm— given a positive item, a recommender model performs negative sampling to add negative items and learns to classify whether the user prefers them or not, based on his/her historical interaction sequence. Although effective, we reveal two inherent limitations: (1) it may differ from human behavior in that a user could imagine an oracle item in mind and select potential items matching the oracle; and (2) the classification is limited in the candidate pool with noisy or easy supervision from negative samples, which dilutes the preference signals towards the oracle item. Yet, generating the oracle item from the historical interaction sequence is mostly unexplored. To bridge the gap, we reshape sequential recommendation as a learning-to-generate paradigm, which is achieved via a guided diffusion model, termed DreamRec. Specifically, for a sequence of historical items, it applies a Transformer encoder to create guidance representations. Noising target items explores the underlying distribution of item space; then, with the guidance of historical interactions, the denoising process generates an oracle item to recover the positive item, so as to cast off negative sampling and depict the true preference of the user directly. We evaluate the effectiveness of DreamRec through extensive experiments and comparisons with existing methods. Codes and data are open-sourced at https://github.com/YangZhengyi98/DreamRec",
    "checked": true,
    "id": "c718c0a7185b16edc29432fe943489ca630c3c48",
    "semantic_title": "generate what you prefer: reshaping sequential recommendation via guided diffusion",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=r7g9nFsulw": {
    "title": "Learning Adaptive Tensorial Density Fields for Clean Cryo-ET Reconstruction",
    "volume": "poster",
    "abstract": "We present a novel learning-based framework for reconstructing 3D structures from tilt-series cryo-Electron Tomography (cryo-ET) data. Cryo-ET is a powerful imaging technique that can achieve near-atomic resolutions. Still, it suffers from challenges such as missing-wedge acquisition, large data size, and high noise levels. Our framework addresses these challenges by using an adaptive tensorial-based representation for the 3D density field of the scanned sample. First, we optimize a quadtree structure to partition the volume of interest. Then, we learn a vector-matrix factorization of the tensor representing the density field in each node. Moreover, we use a loss function that combines a differentiable tomographic formation model with three regularization terms: total variation, boundary consistency constraint, and an isotropic Fourier prior. Our framework allows us to query the density at any location using the learned representation and obtain a high-quality 3D tomogram. We demonstrate the superiority of our framework over existing methods using synthetic and real data. Thus, our framework boosts the quality of the reconstruction while reducing the computation time and the memory footprint. The code is available at https://github.com/yuanhaowang1213/adaptivetensordf",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cgiP4cMBP9": {
    "title": "Fine-Grained Cross-View Geo-Localization Using a Correlation-Aware Homography Estimator",
    "volume": "poster",
    "abstract": "In this paper, we introduce a novel approach to fine-grained cross-view geo-localization. Our method aligns a warped ground image with a corresponding GPS-tagged satellite image covering the same area using homography estimation. We first employ a differentiable spherical transform, adhering to geometric principles, to accurately align the perspective of the ground image with the satellite map. This transformation effectively places ground and aerial images in the same view and on the same plane, reducing the task to an image alignment problem. To address challenges such as occlusion, small overlapping range, and seasonal variations, we propose a robust correlation-aware homography estimator to align similar parts of the transformed ground image with the satellite image. Our method achieves sub-pixel resolution and meter-level GPS accuracy by mapping the center point of the transformed ground image to the satellite image using a homography matrix and determining the orientation of the ground camera using a point above the central axis. Operating at a speed of 30 FPS, our method outperforms state-of-the-art techniques, reducing the mean metric localization error by 21.3\\% and 32.4\\% in same-area and cross-area generalization tasks on the VIGOR benchmark, respectively, and by 34.4\\% on the KITTI benchmark in same-area evaluation",
    "checked": true,
    "id": "42518af29f4430908353d21d731a7eb458daa8ce",
    "semantic_title": "fine-grained cross-view geo-localization using a correlation-aware homography estimator",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5BqDSw8r5j": {
    "title": "Adaptive Normalization for Non-stationary Time Series Forecasting: A Temporal Slice Perspective",
    "volume": "poster",
    "abstract": "Deep learning models have progressively advanced time series forecasting due to their powerful capacity in capturing sequence dependence. Nevertheless, it is still challenging to make accurate predictions due to the existence of non-stationarity in real-world data, denoting the data distribution rapidly changes over time. To mitigate such a dilemma, several efforts have been conducted by reducing the non-stationarity with normalization operation. However, these methods typically overlook the distribution discrepancy between the input series and the horizon series, and assume that all time points within the same instance share the same statistical properties, which is too ideal and may lead to suboptimal relative improvements. To this end, we propose a novel slice-level adaptive normalization, referred to \\textbf{SAN}, which is a novel scheme for empowering time series forecasting with more flexible normalization and denormalization. SAN includes two crucial designs. First, SAN tries to eliminate the non-stationarity of time series in units of a local temporal slice (i.e., sub-series) rather than a global instance. Second, SAN employs a slight network module to independently model the evolving trends of statistical properties of raw time series. Consequently, SAN could serve as a general model-agnostic plugin and better alleviate the impact of the non-stationary nature of time series data. We instantiate the proposed SAN on four widely used forecasting models and test their prediction results on benchmark datasets to evaluate its effectiveness. Also, we report some insightful findings to deeply analyze and understand our proposed SAN. We make our codes publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ykMdzevPkJ": {
    "title": "DiffTraj: Generating GPS Trajectory with Diffusion Probabilistic Model",
    "volume": "poster",
    "abstract": "Pervasive integration of GPS-enabled devices and data acquisition technologies has led to an exponential increase in GPS trajectory data, fostering advancements in spatial-temporal data mining research. Nonetheless, GPS trajectories contain personal geolocation information, rendering serious privacy concerns when working with raw data. A promising approach to address this issue is trajectory generation, which involves replacing original data with generated, privacy-free alternatives. Despite the potential of trajectory generation, the complex nature of human behavior and its inherent stochastic characteristics pose challenges in generating high-quality trajectories. In this work, we propose a spatial-temporal diffusion probabilistic model for trajectory generation (DiffTraj). This model effectively combines the generative abilities of diffusion models with the spatial-temporal features derived from real trajectories. The core idea is to reconstruct and synthesize geographic trajectories from white noise through a reverse trajectory denoising process. Furthermore, we propose a Trajectory UNet (Traj-UNet) deep neural network to embed conditional information and accurately estimate noise levels during the reverse process. Experiments on two real-world datasets show that DiffTraj can be intuitively applied to generate high-fidelity trajectories while retaining the original distributions. Moreover, the generated results can support downstream trajectory analysis tasks and significantly outperform other methods in terms of geo-distribution evaluations",
    "checked": true,
    "id": "9b0909714d8e24183a305ccd1038d899cb66fb53",
    "semantic_title": "difftraj: generating gps trajectory with diffusion probabilistic model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q9CNA7B7v2": {
    "title": "SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process",
    "volume": "poster",
    "abstract": "In this paper, we explore a principal way to enhance the quality of object masks produced by different segmentation models. We propose a model-agnostic solution called SegRefiner, which offers a novel perspective on this problem by interpreting segmentation refinement as a data generation process. As a result, the refinement process can be smoothly implemented through a series of denoising diffusion steps. Specifically, SegRefiner takes coarse masks as inputs and refines them using a discrete diffusion process. By predicting the label and corresponding states-transition probabilities for each pixel, SegRefiner progressively refines the noisy masks in a conditional denoising manner. To assess the effectiveness of SegRefiner, we conduct comprehensive experiments on various segmentation tasks, including semantic segmentation, instance segmentation, and dichotomous image segmentation. The results demonstrate the superiority of our SegRefiner from multiple aspects. Firstly, it consistently improves both the segmentation metrics and boundary metrics across different types of coarse masks. Secondly, it outperforms previous model-agnostic refinement methods by a significant margin. Lastly, it exhibits a strong capability to capture extremely fine details when refining high-resolution images. The source code and trained models are available at [SegRefiner.git](https://github.com/MengyuWang826/SegRefiner)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y50AnAbKp1": {
    "title": "CSOT: Curriculum and Structure-Aware Optimal Transport for Learning with Noisy Labels",
    "volume": "poster",
    "abstract": "Learning with noisy labels (LNL) poses a significant challenge in training a well-generalized model while avoiding overfitting to corrupted labels. Recent advances have achieved impressive performance by identifying clean labels and correcting corrupted labels for training. However, the current approaches rely heavily on the model's predictions and evaluate each sample independently without considering either the global or local structure of the sample distribution. These limitations typically result in a suboptimal solution for the identification and correction processes, which eventually leads to models overfitting to incorrect labels. In this paper, we propose a novel optimal transport (OT) formulation, called Curriculum and Structure-aware Optimal Transport (CSOT). CSOT concurrently considers the inter- and intra-distribution structure of the samples to construct a robust denoising and relabeling allocator. During the training process, the allocator incrementally assigns reliable labels to a fraction of the samples with the highest confidence. These labels have both global discriminability and local coherence. Notably, CSOT is a new OT formulation with a nonconvex objective function and curriculum constraints, so it is not directly compatible with classical OT solvers. Here, we develop a lightspeed computational method that involves a scaling iteration within a generalized conditional gradient framework to solve CSOT efficiently. Extensive experiments demonstrate the superiority of our method over the current state-of-the-arts in LNL",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lYNSvp51a7": {
    "title": "Lift Yourself Up: Retrieval-augmented Text Generation with Self-Memory",
    "volume": "poster",
    "abstract": "With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation (we define this as primal problem). The traditional approach for memory retrieval involves selecting memory that exhibits the highest similarity to the input. However, this method is constrained by the quality of the fixed corpus from which memory is retrieved. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a novel framework, selfmem, which addresses this limitation by iteratively employing a retrieval-augmented generator to create an unbounded memory pool and using a memory selector to choose one output as memory for the subsequent generation round. This enables the model to leverage its own output, referred to as self-memory, for improved generation. We evaluate the effectiveness of selfmem on three distinct text generation tasks: neural machine translation, abstractive text summarization, and dialogue generation, under two generation paradigms: fine-tuned small model and few-shot LLM. Our approach achieves state-of-the-art results in four directions in JRC-Acquis translation dataset, 50.3 ROUGE-1 in XSum, and 62.9 ROUGE-1 in BigPatent, demonstrating the potential of self-memory in enhancing retrieval-augmented generation models. Furthermore, we conduct thorough analyses of each component in the selfmem framework to identify current system bottlenecks and provide insights for future research",
    "checked": false,
    "id": "41b796b026a1d322de6ef0b280d3e2e68eee65bd",
    "semantic_title": "lift yourself up: retrieval-augmented text generation with self memory",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=kdFR6IUEW6": {
    "title": "Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition",
    "volume": "poster",
    "abstract": "This work proposes POMP, a prompt pre-training method for vision-language models. Being memory and computation efficient, POMP enables the learned prompt to condense semantic information for a rich set of visual concepts with over twenty-thousand classes. Once pre-trained, the prompt with a strong transferable ability can be directly plugged into a variety of visual recognition tasks including image classification, semantic segmentation, and object detection, to boost recognition performances in a zero-shot manner. Empirical evaluation shows that POMP achieves state-of-the-art performances on 21 datasets, e.g., 67.0% average accuracy on 10 classification datasets (+3.1% compared to CoOp) and 84.4 hIoU on open-vocabulary Pascal VOC segmentation (+6.9 compared to ZSSeg)",
    "checked": true,
    "id": "c326672bfa418dd70a49d2dfe6dbbadb15354f7b",
    "semantic_title": "prompt pre-training with twenty-thousand classes for open-vocabulary visual recognition",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=q0RfX96un8": {
    "title": "On the Consistency of Maximum Likelihood Estimation of Probabilistic Principal Component Analysis",
    "volume": "poster",
    "abstract": "Probabilistic principal component analysis (PPCA) is currently one of the most used statistical tools to reduce the ambient dimension of the data. From multidimensional scaling to the imputation of missing data, PPCA has a broad spectrum of applications ranging from science and engineering to quantitative finance.\\\\ Despite this wide applicability in various fields, hardly any theoretical guarantees exist to justify the soundness of the maximal likelihood (ML) solution for this model. In fact, it is well known that the maximum likelihood estimation (MLE) can only recover the true model parameters up to a rotation. The main obstruction is posed by the inherent identifiability nature of the PPCA model resulting from the rotational symmetry of the parameterization. To resolve this ambiguity, we propose a novel approach using quotient topological spaces and in particular, we show that the maximum likelihood solution is consistent in an appropriate quotient Euclidean space. Furthermore, our consistency results encompass a more general class of estimators beyond the MLE. Strong consistency of the ML estimate and consequently strong covariance estimation of the PPCA model have also been established under a compactness assumption",
    "checked": true,
    "id": "fcebd1fca7c6e8894be31abba79d1da80f55c0cb",
    "semantic_title": "on the consistency of maximum likelihood estimation of probabilistic principal component analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EO1KuHoR0V": {
    "title": "AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models",
    "volume": "poster",
    "abstract": "Audio editing is applicable for various purposes, such as adding background sound effects, replacing a musical instrument, and repairing damaged audio. Recently, some diffusion-based methods achieved zero-shot audio editing by using a diffusion and denoising process conditioned on the text description of the output audio. However, these methods still have some problems: 1) they have not been trained on editing tasks and cannot ensure good editing effects; 2) they can erroneously modify audio segments that do not require editing; 3) they need a complete description of the output audio, which is not always available or necessary in practical scenarios. In this work, we propose AUDIT, an instruction-guided audio editing model based on latent diffusion models. Specifically, \\textbf{AUDIT} has three main design features: 1) we construct triplet training data (instruction, input audio, output audio) for different audio editing tasks and train a diffusion model using instruction and input (to be edited) audio as conditions and generating output (edited) audio; 2) it can automatically learn to only modify segments that need to be edited by comparing the difference between the input and output audio; 3) it only needs edit instructions instead of full target audio descriptions as text input. AUDIT achieves state-of-the-art results in both objective and subjective metrics for several audio editing tasks (e.g., adding, dropping, replacement, inpainting, super-resolution). Demo samples are available at https://audit-demopage.github.io/",
    "checked": true,
    "id": "187703129bb0da27e0d3bda51320bb85efd34821",
    "semantic_title": "audit: audio editing by following instructions with latent diffusion models",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=pLcSrn8NpJ": {
    "title": "An active learning framework for multi-group mean estimation",
    "volume": "poster",
    "abstract": "We consider a fundamental problem where there are multiple groups whose data distributions are unknown, and an analyst would like to learn the mean of each group. We consider an active learning framework to sequentially collect $T$ samples with bandit, each period observing a sample from a chosen group. After observing a sample, the analyst may update their estimate of the mean and variance of that group and choose the next group accordingly. The objective is to dynamically collect samples to minimize the $p$-norm of the vector of variances of our mean estimators after $T$ rounds. We propose an algorithm, Variance-UCB, that selects groups according to a an upper bound on the variance estimate adjusted to the $p$-norm chosen. We show that the regret of Variance-UCB is $O(T^{-2})$ for finite $p$, and prove that no algorithm can do better. When $p$ is infinite, we recover the $O(T^{-1.5})$ obtained in \\cite{activelearning, carpentier2011upper} and provide a new lower bound showing that no algorithm can do better",
    "checked": false,
    "id": "f5079f73589b3b07160ffbe5d9fe88bffd3e3b22",
    "semantic_title": "activity report project-team models and algorithms for artiﬁcial intelligence",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jfsjKBDB1z": {
    "title": "From ViT Features to Training-free Video Object Segmentation via Streaming-data Mixture Models",
    "volume": "poster",
    "abstract": "In the task of semi-supervised video object segmentation, the input is the binary mask of an object in the first frame, and the desired output consists of the corresponding masks of that object in the subsequent frames. Existing leading solutions have two main drawbacks: 1) an expensive and typically-supervised training on videos; 2) a large memory footprint during inference. Here we present a training-free solution, with a low-memory footprint, that yields state-of-the-art results. The proposed method combines pre-trained deep learning-based features (trained on still images) with more classical methods for streaming-data clustering. Designed to adapt to temporal concept drifts and generalize to diverse video content without relying on annotated images or videos, the method eliminates the need for additional training or fine-tuning, ensuring fast inference and immediate applicability to new videos. Concretely, we represent an object via a dynamic ensemble of temporally- and spatially-coherent mixtures over a representation built from pre-trained ViT features and positional embeddings. A convolutional conditional random field further improves spatial coherence and helps reject outliers. We demonstrate the efficacy of the method on key benchmarks: the DAVIS-2017 and YouTube-VOS 2018 validation datasets. Moreover, by the virtue of the low-memory footprint of the compact cluster-based representation, the method scales gracefully to high-resolution ViT features. Our code is available at https://github.com/BGU-CS-VIL/Training-Free-VOS",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4nSDDokpfK": {
    "title": "Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery Approach",
    "volume": "poster",
    "abstract": "We present a new method of training energy-based models (EBMs) for anomaly detection that leverages low-dimensional structures within data. The proposed algorithm, Manifold Projection-Diffusion Recovery (MPDR), first perturbs a data point along a low-dimensional manifold that approximates the training dataset. Then, EBM is trained to maximize the probability of recovering the original data. The training involves the generation of negative samples via MCMC, as in conventional EBM training, but from a different distribution concentrated near the manifold. The resulting near-manifold negative samples are highly informative, reflecting relevant modes of variation in data. An energy function of MPDR effectively learns accurate boundaries of the training data distribution and excels at detecting out-of-distribution samples. Experimental results show that MPDR exhibits strong performance across various anomaly detection tasks involving diverse data types, such as images, vectors, and acoustic signals",
    "checked": true,
    "id": "f4a3b5d4b8ea54136bb231b13ba75fe8d02b2f5c",
    "semantic_title": "energy-based models for anomaly detection: a manifold diffusion recovery approach",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d6LShzSTOP": {
    "title": "Unsupervised Image Denoising with Score Function",
    "volume": "poster",
    "abstract": "Though achieving excellent performance in some cases, current unsupervised learning methods for single image denoising usually have constraints in applications. In this paper, we propose a new approach which is more general and applicable to complicated noise models. Utilizing the property of score function, the gradient of logarithmic probability, we define a solving system for denoising. Once the score function of noisy images has been estimated, the denoised result can be obtained through the solving system. Our approach can be applied to multiple noise models, such as the mixture of multiplicative and additive noise combined with structured correlation. Experimental results show that our method is comparable when the noise model is simple, and has good performance in complicated cases where other methods are not applicable or perform poorly",
    "checked": true,
    "id": "a8580d337e8da5da751cf4805492e823f340cad9",
    "semantic_title": "unsupervised image denoising with score function",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EY4OHikuBm": {
    "title": "Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks",
    "volume": "poster",
    "abstract": "Most reinforcement learning methods rely heavily on dense, well-normalized environment rewards. DreamerV3 recently introduced a model-based method with a number of tricks that mitigate these limitations, achieving state-of-the-art on a wide range of benchmarks with a single set of hyperparameters. This result sparked discussion about the generality of the tricks, since they appear to be applicable to other reinforcement learning algorithms. Our work applies DreamerV3's tricks to PPO and is the first such empirical study outside of the original work. Surprisingly, we find that the tricks presented do not transfer as general improvements to PPO. We use a high quality PPO reference implementation and present extensive ablation studies totaling over 10,000 A100 hours on the Arcade Learning Environment and the DeepMind Control Suite. Though our experiments demonstrate that these tricks do not generally outperform PPO, we identify cases where they succeed and offer insight into the relationship between the implementation tricks. In particular, PPO with these tricks performs comparably to PPO on Atari games with reward clipping and significantly outperforms PPO without reward clipping",
    "checked": true,
    "id": "ee73ed1ee6af52d44e26f02fe2f9188e0dad511a",
    "semantic_title": "reward scale robustness for proximal policy optimization via dreamerv3 tricks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D7LdL2SCCi": {
    "title": "Optimal Transport Model Distributional Robustness",
    "volume": "poster",
    "abstract": "Distributional robustness is a promising framework for training deep learning models that are less vulnerable to adversarial examples and data distribution shifts. Previous works have mainly focused on exploiting distributional robustness in the data space. In this work, we explore an optimal transport-based distributional robustness framework in model spaces. Specifically, we examine a model distribution within a Wasserstein ball centered on a given model distribution that maximizes the loss. We have developed theories that enable us to learn the optimal robust center model distribution. Interestingly, our developed theories allow us to flexibly incorporate the concept of sharpness awareness into training, whether it's a single model, ensemble models, or Bayesian Neural Networks, by considering specific forms of the center model distribution. These forms include a Dirac delta distribution over a single model, a uniform distribution over several models, and a general Bayesian Neural Network. Furthermore, we demonstrate that Sharpness-Aware Minimization (SAM) is a specific case of our framework when using a Dirac delta distribution over a single model, while our framework can be seen as a probabilistic extension of SAM. To validate the effectiveness of our framework in the aforementioned settings, we conducted extensive experiments, and the results reveal remarkable improvements compared to the baselines",
    "checked": true,
    "id": "7e0a4562b155be05917043846c468d8c1f7f01d0",
    "semantic_title": "optimal transport model distributional robustness",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=9pLaDXX8m3": {
    "title": "NeRF-IBVS: Visual Servo Based on NeRF for Visual Localization and Navigation",
    "volume": "poster",
    "abstract": "Visual localization is a fundamental task in computer vision and robotics. Training existing visual localization methods requires a large number of posed images to generalize to novel views, while state-of-the-art methods generally require dense ground truth 3D labels for supervision. However, acquiring a large number of posed images and dense 3D labels in the real world is challenging and costly. In this paper, we present a novel visual localization method that achieves accurate localization while using only a few posed images compared to other localization methods. To achieve this, we first use a few posed images with coarse pseudo-3D labels provided by NeRF to train a coordinate regression network. Then a coarse pose is estimated from the regression network with PNP. Finally, we use the image-based visual servo (IBVS) with the scene prior provided by NeRF for pose optimization. Furthermore, our method can provide effective navigation prior, which enable navigation based on IBVS without using custom markers and depth sensor. Extensive experiments on 7-Scenes and 12-Scenes datasets demonstrate that our method outperforms state-of-the-art methods under the same setting, with only 5\\% to 25\\% training data. Furthermore, our framework can be naturally extended to the visual navigation task based on IBVS, and its effectiveness is verified in simulation experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZrG8kTbt70": {
    "title": "WalkLM: A Uniform Language Model Fine-tuning Framework for Attributed Graph Embedding",
    "volume": "poster",
    "abstract": "Graphs are widely used to model interconnected entities and improve downstream predictions in various real-world applications. However, real-world graphs nowadays are often associated with complex attributes on multiple types of nodes and even links that are hard to model uniformly, while the widely used graph neural networks (GNNs) often require sufficient training toward specific downstream predictions to achieve strong performance. In this work, we take a fundamentally different approach than GNNs, to simultaneously achieve deep joint modeling of complex attributes and flexible structures of real-world graphs and obtain unsupervised generic graph representations that are not limited to specific downstream predictions. Our framework, built on a natural integration of language models (LMs) and random walks (RWs), is straightforward, powerful and data-efficient. Specifically, we first perform attributed RWs on the graph and design an automated program to compose roughly meaningful textual sequences directly from the attributed RWs; then we fine-tune an LM using the RW-based textual sequences and extract embedding vectors from the LM, which encapsulates both attribute semantics and graph structures. In our experiments, we evaluate the learned node embeddings towards different downstream prediction tasks on multiple real-world attributed graph datasets and observe significant improvements over a comprehensive set of state-of-the-art unsupervised node embedding methods. We believe this work opens a door for more sophisticated technical designs and empirical evaluations toward the leverage of LMs for the modeling of real-world graphs",
    "checked": false,
    "id": "d2ecb191cb037c96d4c2ad0a47a49ba82b701285",
    "semantic_title": "walklm : a uniform language model fine-tuning framework for attributed graph embedding",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E4P5kVSKlT": {
    "title": "On the Asymptotic Learning Curves of Kernel Ridge Regression under Power-law Decay",
    "volume": "poster",
    "abstract": "The widely observed 'benign overfitting phenomenon' in the neural network literature raises the challenge to the `bias-variance trade-off' doctrine in the statistical learning theory. Since the generalization ability of the 'lazy trained' over-parametrized neural network can be well approximated by that of the neural tangent kernel regression, the curve of the excess risk (namely, the learning curve) of kernel ridge regression attracts increasing attention recently. However, most recent arguments on the learning curve are heuristic and are based on the 'Gaussian design' assumption. In this paper, under mild and more realistic assumptions, we rigorously provide a full characterization of the learning curve in the asymptotic sense under a power-law decay condition of the eigenvalues of the kernel and also the target function. The learning curve elaborates the effect and the interplay of the choice of the regularization parameter, the source condition and the noise. In particular, our results suggest that the 'benign overfitting phenomenon' exists in over-parametrized neural networks only when the noise level is small",
    "checked": true,
    "id": "80b2c855201d4e218ed577ad6c28e6c2bbaefe9d",
    "semantic_title": "on the asymptotic learning curves of kernel ridge regression under power-law decay",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7anW5TWbCJ": {
    "title": "Information Theoretic Lower Bounds for Information Theoretic Upper Bounds",
    "volume": "poster",
    "abstract": "We examine the relationship between the mutual information between the output model and the empirical sample and the algorithm's generalization in the context of stochastic convex optimization. Despite increasing interest in information-theoretic generalization bounds, it is uncertain if these bounds can provide insight into the exceptional performance of various learning algorithms. Our study of stochastic convex optimization reveals that, for true risk minimization, dimension-dependent mutual information is necessary. This indicates that existing information-theoretic generalization bounds fall short in capturing the generalization capabilities of algorithms like SGD and regularized ERM, which have dimension-independent sample complexity",
    "checked": true,
    "id": "cb399e2e52653ada4237bd228ba94988810c0730",
    "semantic_title": "information theoretic lower bounds for information theoretic upper bounds",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=BuGFwUS9B3": {
    "title": "Incomplete Multimodality-Diffused Emotion Recognition",
    "volume": "poster",
    "abstract": "Human multimodal emotion recognition (MER) aims to perceive and understand human emotions via various heterogeneous modalities, such as language, vision, and acoustic. Compared with unimodality, the complementary information in the multimodalities facilitates robust emotion understanding. Nevertheless, in real-world scenarios, the missing modalities hinder multimodal understanding and result in degraded MER performance. In this paper, we propose an Incomplete Multimodality-Diffused emotion recognition (IMDer) method to mitigate the challenge of MER under incomplete multimodalities. To recover the missing modalities, IMDer exploits the score-based diffusion model that maps the input Gaussian noise into the desired distribution space of the missing modalities and recovers missing data abided by their original distributions. Specially, to reduce semantic ambiguity between the missing and the recovered modalities, the available modalities are embedded as the condition to guide and refine the diffusion-based recovering process. In contrast to previous work, the diffusion-based modality recovery mechanism in IMDer allows to simultaneously reach both distribution consistency and semantic disambiguation. Feature visualization of the recovered modalities illustrates the consistent modality-specific distribution and semantic alignment. Besides, quantitative experimental results verify that IMDer obtains state-of-the-art MER accuracy under various missing modality patterns",
    "checked": false,
    "id": "859ccb98f1ca79b1ddb1ff6d3f7a7766762a26df",
    "semantic_title": "multimodal learning with incompleteness towards multimodal sentiment analysis and emotion recognition task",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hiwF7aG1dt": {
    "title": "Iteratively Learn Diverse Strategies with State Distance Information",
    "volume": "poster",
    "abstract": "In complex reinforcement learning (RL) problems, policies with similar rewards may have substantially different behaviors. It remains a fundamental challenge to optimize rewards while also discovering as many *diverse* strategies as possible, which can be crucial in many practical applications. Our study examines two design choices for tackling this challenge, i.e., *diversity measure* and *computation framework*. First, we find that with existing diversity measures, visually indistinguishable policies can still yield high diversity scores. To accurately capture the behavioral difference, we propose to incorporate the state-space distance information into the diversity measure. In addition, we examine two common computation frameworks for this problem, i.e., population-based training (PBT) and iterative learning (ITR). We show that although PBT is the precise problem formulation, ITR can achieve comparable diversity scores with higher computation efficiency, leading to improved solution quality in practice. Based on our analysis, we further combine ITR with two tractable realizations of the state-distance-based diversity measures and develop a novel diversity-driven RL algorithm, *State-based Intrinsic-reward Policy Optimization* (SIPO), with provable convergence properties. We empirically examine SIPO across three domains from robot locomotion to multi-agent games. In all of our testing environments, SIPO consistently produces strategically diverse and human-interpretable policies that cannot be discovered by existing baselines",
    "checked": true,
    "id": "e61b7cf01b7efff5c324ffbb2c5055080f2be937",
    "semantic_title": "iteratively learn diverse strategies with state distance information",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YZSLDEE0mw": {
    "title": "Contrast, Attend and Diffuse to Decode High-Resolution Images from Brain Activities",
    "volume": "poster",
    "abstract": "Decoding visual stimuli from neural responses recorded by functional Magnetic Resonance Imaging (fMRI) presents an intriguing intersection between cognitive neuroscience and machine learning, promising advancements in understanding human visual perception. However, the task is challenging due to the noisy nature of fMRI signals and the intricate pattern of brain visual representations. To mitigate these challenges, we introduce a two-phase fMRI representation learning framework. The first phase pre-trains an fMRI feature learner with a proposed Double-contrastive Mask Auto-encoder to learn denoised representations. The second phase tunes the feature learner to attend to neural activation patterns most informative for visual reconstruction with guidance from an image auto-encoder. The optimized fMRI feature learner then conditions a latent diffusion model to reconstruct image stimuli from brain activities. Experimental results demonstrate our model's superiority in generating high-resolution and semantically accurate images, substantially exceeding previous state-of-the-art methods by 39.34% in the 50-way-top-1 semantic classification accuracy. The code implementations will be available at https://github.com/soinx0629/vis_dec_neurips/",
    "checked": true,
    "id": "e9fbd2894968ae31118188758b6fd4d95adb6f39",
    "semantic_title": "contrast, attend and diffuse to decode high-resolution images from brain activities",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FskZtRvMJI": {
    "title": "RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization",
    "volume": "poster",
    "abstract": "Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeling quantiles of it as weighted quantile mixtures of per-agent return distribution utilities. RiskQ satisfies the RIGM principle for the VaR and distorted risk metrics. We show that RiskQ can obtain promising performance through extensive experiments. The source code of RiskQ is available in https://github.com/xmu-rl-3dv/RiskQ",
    "checked": true,
    "id": "87fbcfffdd5c1a3cca52deed98df0a8bb8d5fc94",
    "semantic_title": "riskq: risk-sensitive multi-agent reinforcement learning value factorization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t1jLRFvBqm": {
    "title": "Object-Centric Learning for Real-World Videos by Predicting Temporal Feature Similarities",
    "volume": "poster",
    "abstract": "Unsupervised video-based object-centric learning is a promising avenue to learn structured representations from large, unlabeled video collections, but previous approaches have only managed to scale to real-world datasets in restricted domains. Recently, it was shown that the reconstruction of pre-trained self-supervised features leads to object-centric representations on unconstrained real-world image datasets. Building on this approach, we propose a novel way to use such pre-trained features in the form of a temporal feature similarity loss. This loss encodes semantic and temporal correlations between image patches and is a natural way to introduce a motion bias for object discovery. We demonstrate that this loss leads to state-of-the-art performance on the challenging synthetic MOVi datasets. When used in combination with the feature reconstruction loss, our model is the first object-centric video model that scales to unconstrained video datasets such as YouTube-VIS. https://martius-lab.github.io/videosaur/",
    "checked": true,
    "id": "c41864045d7326f4f69de2cf9ca44beaac476c53",
    "semantic_title": "object-centric learning for real-world videos by predicting temporal feature similarities",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=uoG1fLIK2s": {
    "title": "Sample-efficient Multi-objective Molecular Optimization with GFlowNets",
    "volume": "poster",
    "abstract": "Many crucial scientific problems involve designing novel molecules with desired properties, which can be formulated as a black-box optimization problem over the *discrete* chemical space. In practice, multiple conflicting objectives and costly evaluations (e.g., wet-lab experiments) make the *diversity* of candidates paramount. Computational methods have achieved initial success but still struggle with considering diversity in both objective and search space. To fill this gap, we propose a multi-objective Bayesian optimization (MOBO) algorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an acquisition function optimizer, with the purpose of sampling a diverse batch of candidate molecular graphs from an approximate Pareto front. Using a single preference-conditioned hypernetwork, HN-GFN learns to explore various trade-offs between objectives. We further propose a hindsight-like off-policy strategy to share high-performing molecules among different preferences in order to speed up learning for HN-GFN. We empirically illustrate that HN-GFN has adequate capacity to generalize over preferences. Moreover, experiments in various real-world MOBO settings demonstrate that our framework predominantly outperforms existing methods in terms of candidate quality and sample efficiency. The code is available at https://github.com/violet-sto/HN-GFN",
    "checked": true,
    "id": "83b465e220132c5dd6bc2bdc93b077c8760c4975",
    "semantic_title": "sample-efficient multi-objective molecular optimization with gflownets",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=EhdNQiOWgQ": {
    "title": "SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models",
    "volume": "poster",
    "abstract": "Test-time adaptation (TTA) is a special and practical setting in unsupervised domain adaptation, which allows a pre-trained model in a source domain to adapt to unlabeled test data in another target domain. To avoid the computation-intensive backbone fine-tuning process, the zero-shot generalization potentials of the emerging pre-trained vision-language models (e.g., CLIP, CoOp) are leveraged to only tune the run-time prompt for unseen test domains. However, existing solutions have yet to fully exploit the representation capabilities of pre-trained models as they only focus on the entropy-based optimization and the performance is far below the supervised prompt adaptation methods, e.g., CoOp. In this paper, we propose SwapPrompt, a novel framework that can effectively leverage the self-supervised contrastive learning to facilitate the test-time prompt adaptation. SwapPrompt employs a dual prompts paradigm, i.e., an online prompt and a target prompt that averaged from the online prompt to retain historical information. In addition, SwapPrompt applies a swapped prediction mechanism, which takes advantage of the representation capabilities of pre-trained models to enhance the online prompt via contrastive learning. Specifically, we use the online prompt together with an augmented view of the input image to predict the class assignment generated by the target prompt together with an alternative augmented view of the same image. The proposed SwapPrompt can be easily deployed on vision-language models without additional requirement, and experimental results show that it achieves state-of-the-art test-time adaptation performance on ImageNet and nine other datasets. It is also shown that SwapPrompt can even achieve comparable performance with supervised prompt adaptation methods",
    "checked": false,
    "id": "4f9766356478ddf606457af735f70682839194b1",
    "semantic_title": "vpa: fully test-time visual prompt adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eX6xDto3Ed": {
    "title": "Flat Seeking Bayesian Neural Networks",
    "volume": "poster",
    "abstract": "Bayesian Neural Networks (BNNs) provide a probabilistic interpretation for deep learning models by imposing a prior distribution over model parameters and inferring a posterior distribution based on observed data. The model sampled from the posterior distribution can be used for providing ensemble predictions and quantifying prediction uncertainty. It is well-known that deep learning models with lower sharpness have better generalization ability. However, existing posterior inferences are not aware of sharpness/flatness in terms of formulation, possibly leading to high sharpness for the models sampled from them. In this paper, we develop theories, the Bayesian setting, and the variational inference approach for the sharpness-aware posterior. Specifically, the models sampled from our sharpness-aware posterior, and the optimal approximate posterior estimating this sharpness-aware posterior, have better flatness, hence possibly possessing higher generalization ability. We conduct experiments by leveraging the sharpness-aware posterior with state-of-the-art Bayesian Neural Networks, showing that the flat-seeking counterparts outperform their baselines in all metrics of interest",
    "checked": true,
    "id": "6c11fb8fb7084547ff4be63d8ddb6f0dfee71765",
    "semantic_title": "flat seeking bayesian neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=51PLYhMFWz": {
    "title": "Towards a fuller understanding of neurons with Clustered Compositional Explanations",
    "volume": "poster",
    "abstract": "Compositional Explanations is a method for identifying logical formulas of concepts that approximate the neurons' behavior. However, these explanations are linked to the small spectrum of neuron activations (i.e., the highest ones) used to check the alignment, thus lacking completeness. In this paper, we propose a generalization, called Clustered Compositional Explanations, that combines Compositional Explanations with clustering and a novel search heuristic to approximate a broader spectrum of the neuron behavior. We define and address the problems connected to the application of these methods to multiple ranges of activations, analyze the insights retrievable by using our algorithm, and propose desiderata qualities that can be used to study the explanations returned by different algorithms",
    "checked": true,
    "id": "de8b7184a3eb80c90c54b59c7d26b7ee0386dfea",
    "semantic_title": "towards a fuller understanding of neurons with clustered compositional explanations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0EG6qUQ4xE": {
    "title": "AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation",
    "volume": "poster",
    "abstract": "Diffusion models have gained significant attention in the realm of image generation due to their exceptional performance. Their success has been recently expanded to text generation via generating all tokens within a sequence concurrently. However, natural language exhibits a far more pronounced sequential dependency in comparison to images, and the majority of existing language models are trained with a left-to-right auto-regressive approach. To account for the inherent sequential characteristic of natural language, we introduce Auto-Regressive Diffusion (AR-Diffusion). AR-Diffusion ensures that the generation of tokens on the right depends on the generated ones on the left, a mechanism achieved through employing a dynamic number of denoising steps that vary based on token position. This results in tokens on the left undergoing fewer denoising steps than those on the right, thereby enabling them to generate earlier and subsequently influence the generation of tokens on the right. In a series of experiments on various text generation tasks, including text summarization, machine translation, and common sense generation, AR-Diffusion clearly demonstrated its superiority over existing diffusion language models and that it can be $100\\times\\sim600\\times$ faster when achieving comparable results. Our code is available at https://github.com/microsoft/ProphetNet/tree/master/AR-diffusion",
    "checked": true,
    "id": "54b6e5dcef733c151adef0ac06430f63cb301a36",
    "semantic_title": "ar-diffusion: auto-regressive diffusion model for text generation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=eUf0CaS5AP": {
    "title": "XAGen: 3D Expressive Human Avatars Generation",
    "volume": "poster",
    "abstract": "Recent advances in 3D-aware GAN models have enabled the generation of realistic and controllable human body images. However, existing methods focus on the control of major body joints, neglecting the manipulation of expressive attributes, such as facial expressions, jaw poses, hand poses, and so on. In this work, we present XAGen, the first 3D generative model for human avatars capable of expressive control over body, face, and hands. To enhance the fidelity of small-scale regions like face and hands, we devise a multi-scale and multi-part 3D representation that models fine details. Based on this representation, we propose a multi-part rendering technique that disentangles the synthesis of body, face, and hands to ease model training and enhance geometric quality. Furthermore, we design multi-part discriminators that evaluate the quality of the generated avatars with respect to their appearance and fine-grained control capabilities. Experiments show that XAGen surpasses state-of-the-art methods in terms of realism, diversity, and expressive control abilities. Code and data will be made available at https://showlab.github.io/xagen",
    "checked": true,
    "id": "28008ea664a6cf0d4d4fe37105bfb279f73a755b",
    "semantic_title": "xagen: 3d expressive human avatars generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=scYa9DYUAy": {
    "title": "VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset",
    "volume": "poster",
    "abstract": "Vision and text have been fully explored in contemporary video-text foundational models, while other modalities such as audio and subtitles in videos have not received sufficient attention. In this paper, we resort to establish connections between multi-modality video tracks, including Vision, Audio, and Subtitle, and Text by exploring an automatically generated large-scale omni-modality video caption dataset called VAST-27M. Specifically, we first collect 27 million open-domain video clips and separately train a vision and an audio captioner to generate vision and audio captions. Then, we employ an off-the-shelf Large Language Model (LLM) to integrate the generated captions, together with subtitles and instructional prompts into omni-modality captions. Based on the proposed VAST-27M dataset, we train an omni-modality video-text foundational model named VAST, which can perceive and process vision, audio, and subtitle modalities from video, and better support various tasks including vision-text, audio-text, and multi-modal video-text tasks (retrieval, captioning and QA). Extensive experiments have been conducted to demonstrate the effectiveness of our proposed VAST-27M corpus and VAST foundation model. VAST achieves 22 new state-of-the-art results on various cross-modality benchmarks",
    "checked": true,
    "id": "4e33c5756aa18d248cf50fef9382acda1e0f65da",
    "semantic_title": "vast: a vision-audio-subtitle-text omni-modality foundation model and dataset",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=9qG6cMGUWk": {
    "title": "Generalized Logit Adjustment: Calibrating Fine-tuned Models by Removing Label Bias in Foundation Models",
    "volume": "poster",
    "abstract": "Foundation models like CLIP allow zero-shot transfer on various tasks without additional training data. Yet, the zero-shot performance is less competitive than a fully supervised one. Thus, to enhance the performance, fine-tuning and ensembling are also commonly adopted to better fit the downstream tasks. However, we argue that such prior work has overlooked the inherent biases in foundation models. Due to the highly imbalanced Web-scale training set, these foundation models are inevitably skewed toward frequent semantics, and thus the subsequent fine-tuning or ensembling is still biased. In this study, we systematically examine the biases in foundation models and demonstrate the efficacy of our proposed Generalized Logit Adjustment (GLA) method. Note that bias estimation in foundation models is challenging, as most pre-train data cannot be explicitly assessed like in traditional long-tailed classification tasks. To this end, GLA has an optimization-based bias estimation approach for debiasing foundation models. As our work resolves a fundamental flaw in the pre-training, the proposed GLA demonstrates significant improvements across a diverse range of tasks: it achieves 1.5 pp accuracy gains on ImageNet, an large average improvement (1.4-4.6 pp) on 11 few-shot datasets, 2.4 pp gains on long-tailed classification. Codes are in https://github.com/BeierZhu/GLA",
    "checked": true,
    "id": "44800883e82c7bc7c45c2adb6257cd0a0be42610",
    "semantic_title": "generalized logit adjustment: calibrating fine-tuned models by removing label bias in foundation models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2Ibp83esmb": {
    "title": "Constructing Non-isotropic Gaussian Diffusion Model Using Isotropic Gaussian Diffusion Model for Image Editing",
    "volume": "poster",
    "abstract": "Score-based diffusion models (SBDMs) have achieved state-of-the-art results in image generation. In this paper, we propose a Non-isotropic Gaussian Diffusion Model (NGDM) for image editing, which requires editing the source image while preserving the image regions irrelevant to the editing task. We construct NGDM by adding independent Gaussian noises with different variances to different image pixels. Instead of specifically training the NGDM, we rectify the NGDM into an isotropic Gaussian diffusion model with different pixels having different total forward diffusion time. We propose to reverse the diffusion by designing a sampling method that starts at different time for different pixels for denoising to generate images using the pre-trained isotropic Gaussian diffusion model. Experimental results show that NGDM achieves state-of-the-art performance for image editing tasks, considering the trade-off between the fidelity to the source image and alignment with the desired editing target",
    "checked": false,
    "id": "cfff3c7fa21b0aa9342e4e9a34f95d48617370d7",
    "semantic_title": "conditional generative modeling for images, 3d animations, and video",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gpJw8f4tIU": {
    "title": "Contrastive Retrospection: honing in on critical steps for rapid learning and generalization in RL",
    "volume": "poster",
    "abstract": "In real life, success is often contingent upon multiple critical steps that are distant in time from each other and from the final reward. These critical steps are challenging to identify with traditional reinforcement learning (RL) methods that rely on the Bellman equation for credit assignment. Here, we present a new RL algorithm that uses offline contrastive learning to hone in on these critical steps. This algorithm, which we call Contrastive Retrospection (ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of prototypes for the critical steps in a task by a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes. The prototypes in ConSpec provide two key benefits for credit assignment: (i) They enable rapid identification of all the critical steps. (ii) They do so in a readily interpretable manner, enabling out-of-distribution generalization when sensory features are altered. Distinct from other contemporary RL approaches to credit assignment, ConSpec takes advantage of the fact that it is easier to retrospectively identify the small set of steps that success is contingent upon (and ignoring other states) than it is to prospectively predict reward at every taken step. ConSpec greatly improves learning in a diverse set of RL tasks. The code is available at the link: https://github.com/sunchipsster1/ConSpec",
    "checked": true,
    "id": "86acc5ad9c3476630555b442d1d10d9c75de8c6a",
    "semantic_title": "contrastive retrospection: honing in on critical steps for rapid learning and generalization in rl",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TtCPFN5fhO": {
    "title": "Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection",
    "volume": "poster",
    "abstract": "For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \\textbf{O}ptimal \\textbf{P}arameter and \\textbf{N}euron \\textbf{P}runing (\\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all training samples. In the second step, the parameters and neurons with exceptionally large or close to zero sensitivities are removed for prediction. Our proposal is training-free, compatible with other post-hoc methods, and exploring the information from all training data. Extensive experiments are performed on multiple OOD detection tasks and model architectures, showing that our proposed OPNP consistently outperforms the existing methods by a large margin",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VkUNovXoxx": {
    "title": "Nonparametric Teaching for Multiple Learners",
    "volume": "poster",
    "abstract": "We study the problem of teaching multiple learners simultaneously in the nonparametric iterative teaching setting, where the teacher iteratively provides examples to the learner for accelerating the acquisition of a target concept. This problem is motivated by the gap between current single-learner teaching setting and the real-world scenario of human instruction where a teacher typically imparts knowledge to multiple students. Under the new problem formulation, we introduce a novel framework -- Multi-learner Nonparametric Teaching (MINT). In MINT, the teacher aims to instruct multiple learners, with each learner focusing on learning a scalar-valued target model. To achieve this, we frame the problem as teaching a vector-valued target model and extend the target model space from a scalar-valued reproducing kernel Hilbert space used in single-learner scenarios to a vector-valued space. Furthermore, we demonstrate that MINT offers significant teaching speed-up over repeated single-learner teaching, particularly when the multiple learners can communicate with each other. Lastly, we conduct extensive experiments to validate the practicality and efficiency of MINT",
    "checked": true,
    "id": "5781ddcd249cbee5032824d86e36dda506c62c3e",
    "semantic_title": "nonparametric teaching for multiple learners",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UvIN8oQ4uI": {
    "title": "Guiding Large Language Models via Directional Stimulus Prompting",
    "volume": "poster",
    "abstract": "We introduce Directional Stimulus Prompting, a novel framework for guiding black-box large language models (LLMs) towards specific desired outputs. Instead of directly adjusting LLMs, our method employs a small tunable policy model (e.g., T5) to generate an auxiliary directional stimulus prompt for each input instance. These directional stimulus prompts act as nuanced, instance-specific hints and clues to guide LLMs in generating desired outcomes, such as including specific keywords in the generated summary. Our approach sidesteps the challenges of direct LLM tuning by optimizing the policy model to explore directional stimulus prompts that align LLMs with desired behaviors. The policy model can be optimized through 1) supervised fine-tuning using labeled data and 2) reinforcement learning from offline or online rewards based on the LLM's output. We evaluate our method across various tasks, including summarization, dialogue response generation, and chain-of-thought reasoning. Our experiments indicate a consistent improvement in the performance of LLMs such as ChatGPT, Codex, and InstructGPT on these supervised tasks with minimal labeled data. Remarkably, by utilizing merely 80 dialogues from the MultiWOZ dataset, our approach boosts ChatGPT's performance by a relative 41.4%, achieving or exceeding the performance of some fully supervised state-of-the-art models. Moreover, the instance-specific chain-of-thought prompt generated through our method enhances InstructGPT's reasoning accuracy, outperforming both generalized human-crafted prompts and those generated through automatic prompt engineering. The code and data are publicly available at https://github.com/Leezekun/Directional-Stimulus-Prompting",
    "checked": true,
    "id": "b0435af3063195e8ae880489e64ccde64e6d7563",
    "semantic_title": "guiding large language models via directional stimulus prompting",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=U9zRgpgdFI": {
    "title": "A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space",
    "volume": "poster",
    "abstract": "Transformers are widely used deep learning architectures. Existing transformers are mostly designed for sequences (texts or time series), images or videos, and graphs. This paper proposes a novel transformer model for massive (up to a million) point samples in continuous space. Such data are ubiquitous in environment sciences (e.g., sensor observations), numerical simulations (e.g., particle-laden flow, astrophysics), and location-based services (e.g., POIs and trajectories). However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density. To address these challenges, we propose a new hierarchical spatial transformer model, which includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation. We also design an uncertainty quantification branch to estimate prediction confidence related to input feature noise and point sparsity. We provide a theoretical analysis of computational time complexity and memory costs. Extensive experiments on both real-world and synthetic datasets show that our method outperforms multiple baselines in prediction accuracy and our model can scale up to one million points on one NVIDIA A100 GPU. The code is available at https://github.com/spatialdatasciencegroup/HST",
    "checked": true,
    "id": "6480d65a03dc789204e6c84b627a1764432869b8",
    "semantic_title": "a hierarchical spatial transformer for massive point samples in continuous space",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0N73P8pH2l": {
    "title": "ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection",
    "volume": "poster",
    "abstract": "In diffusion models, UNet is the most popular network backbone, since its long skip connects (LSCs) to connect distant network blocks can aggregate long-distant information and alleviate vanishing gradient. Unfortunately, UNet often suffers from unstable training in diffusion models which can be alleviated by scaling its LSC coefficients smaller. However, theoretical understandings of the instability of UNet in diffusion models and also the performance improvement of LSC scaling remain absent yet. To solve this issue, we theoretically show that the coefficients of LSCs in UNet have big effects on the stableness of the forward and backward propagation and robustness of UNet. Specifically, the hidden feature and gradient of UNet at any layer can oscillate and their oscillation ranges are actually large which explains the instability of UNet training. Moreover, UNet is also provably sensitive to perturbed input, and predicts an output distant from the desired output, yielding oscillatory loss and thus oscillatory gradient. Besides, we also observe the theoretical benefits of the LSC coefficient scaling of UNet in the stableness of hidden features and gradient and also robustness. Finally, inspired by our theory, we propose an effective coefficient scaling framework ScaleLong that scales the coefficients of LSC in UNet and better improve the training stability of UNet. Experimental results on CIFAR10, CelebA, ImageNet and COCO show that our methods are superior to stabilize training, and yield about 1.5x training acceleration on different diffusion models with UNet or UViT backbones",
    "checked": true,
    "id": "99388222489dd3375e8ede0225160e6a3a0812e4",
    "semantic_title": "scalelong: towards more stable training of diffusion model via scaling network long skip connection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ql6LVyi2Dg": {
    "title": "Stability and Generalization of the Decentralized Stochastic Gradient Descent Ascent Algorithm",
    "volume": "poster",
    "abstract": "The growing size of available data has attracted increasing interest in solving minimax problems in a decentralized manner for various machine learning tasks. Previous theoretical research has primarily focused on the convergence rate and communication complexity of decentralized minimax algorithms, with little attention given to their generalization. In this paper, we investigate the primal-dual generalization bound of the decentralized stochastic gradient descent ascent (D-SGDA) algorithm using the approach of algorithmic stability under both convex-concave and nonconvex-nonconcave settings. Our theory refines the algorithmic stability in a decentralized manner and demonstrates that the decentralized structure does not destroy the stability and generalization of D-SGDA, implying that it can generalize as well as the vanilla SGDA in certain situations. Our results analyze the impact of different topologies on the generalization bound of the D-SGDA algorithm beyond trivial factors such as sample sizes, learning rates, and iterations. We also evaluate the optimization error and balance it with the generalization gap to obtain the optimal population risk of D-SGDA in the convex-concave setting. Additionally, we perform several numerical experiments which validate our theoretical findings",
    "checked": true,
    "id": "bc7e1c25cacedd20d965e86cfb071eda16da0310",
    "semantic_title": "stability and generalization of the decentralized stochastic gradient descent ascent algorithm",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4mPiqh4pLb": {
    "title": "Multi-Modal Inverse Constrained Reinforcement Learning from a Mixture of Demonstrations",
    "volume": "poster",
    "abstract": "Inverse Constraint Reinforcement Learning (ICRL) aims to recover the underlying constraints respected by expert agents in a data-driven manner. Existing ICRL algorithms typically assume that the demonstration data is generated by a single type of expert. However, in practice, demonstrations often comprise a mixture of trajectories collected from various expert agents respecting different constraints, making it challenging to explain expert behaviors with a unified constraint function. To tackle this issue, we propose a Multi-Modal Inverse Constrained Reinforcement Learning (MMICRL) algorithm for simultaneously estimating multiple constraints corresponding to different types of experts. MMICRL constructs a flow-based density estimator that enables unsupervised expert identification from demonstrations, so as to infer the agent-specific constraints. Following these constraints, MMICRL imitates expert policies with a novel multi-modal constrained policy optimization objective that minimizes the agent-conditioned policy entropy and maximizes the unconditioned one. To enhance robustness, we incorporate this objective into the contrastive learning framework. This approach enables imitation policies to capture the diversity of behaviors among expert agents. Extensive experiments in both discrete and continuous environments show that MMICRL outperforms other baselines in terms of constraint recovery and control performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GsCTjmYe5v": {
    "title": "REFINE: A Fine-Grained Medication Recommendation System Using Deep Learning and Personalized Drug Interaction Modeling",
    "volume": "poster",
    "abstract": "Patients with co-morbidities often require multiple medications to manage their conditions. However, existing medication recommendation systems only offer class-level medications and regard all interactions among drugs to have the same level of severity. This limits their ability to provide personalized and safe recommendations tailored to individual needs. In this work, we introduce a deep learning-based fine-grained medication recommendation system called REFINE, which is designed to improve treatment outcomes and minimize adverse drug interactions. In order to better characterize patients' health conditions, we model the trend in medication dosage titrations and lab test responses, and adapt the vision transformer to obtain effective patient representations. We also model drug interaction severity levels as weighted graphs to learn safe drug combinations and design a balanced loss function to avoid overly conservative recommendations and miss medications that might be needed for certain conditions. Extensive experiments on two real-world datasets show that REFINE outperforms state-of-the-art techniques",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bf6WFWNCUP": {
    "title": "MG-ViT: A Multi-Granularity Method for Compact and Efficient Vision Transformers",
    "volume": "poster",
    "abstract": "Vision Transformer (ViT) faces obstacles in wide application due to its huge computational cost. Almost all existing studies on compressing ViT adopt the manner of splitting an image with a single granularity, with very few exploration of splitting an image with multi-granularity. As we know, important information often randomly concentrate in few regions of an image, necessitating multi-granularity attention allocation to an image. Enlightened by this, we introduce the multi-granularity strategy to compress ViT, which is simple but effective. We propose a two-stage multi-granularity framework, MG-ViT, to balance ViT's performance and computational cost. In single-granularity inference stage, an input image is split into a small number of patches for simple inference. If necessary, multi-granularity inference stage will be instigated, where the important patches are further subsplit into multi-finer-grained patches for subsequent inference. Moreover, prior studies on compression only for classification, while we extend the multi-granularity strategy to hierarchical ViT for downstream tasks such as detection and segmentation. Extensive experiments Prove the effectiveness of the multi-granularity strategy. For instance, on ImageNet, without any loss of performance, MG-ViT reduces 47\\% FLOPs of LV-ViT-S and 56\\% FLOPs of DeiT-S",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UJ9o8wbB5U": {
    "title": "Provably Safe Reinforcement Learning with Step-wise Violation Constraints",
    "volume": "poster",
    "abstract": "We investigate a novel safe reinforcement learning problem with step-wise violation constraints. Our problem differs from existing works in that we focus on stricter step-wise violation constraints and do not assume the existence of safe actions, making our formulation more suitable for safety-critical applications that need to ensure safety in all decision steps but may not always possess safe actions, e.g., robot control and autonomous driving. We propose an efficient algorithm SUCBVI, which guarantees $\\widetilde{\\mathcal{O}}(\\sqrt{ST})$ or gap-dependent $\\widetilde{\\mathcal{O}}(S/\\mathcal{C}_{\\mathrm{gap}} + S^2AH^2)$ step-wise violation and $\\widetilde{\\mathcal{O}}(\\sqrt{H^3SAT})$ regret. Lower bounds are provided to validate the optimality in both violation and regret performance with respect to the number of states $S$ and the total number of steps $T$. Moreover, we further study an innovative safe reward-free exploration problem with step-wise violation constraints. For this problem, we design algorithm SRF-UCRL to find a near-optimal safe policy, which achieves nearly state-of-the-art sample complexity $\\widetilde{\\mathcal{O}}((\\frac{S^2AH^2}{\\varepsilon}+\\frac{H^4SA}{\\varepsilon^2})(\\log(\\frac{1}{\\delta})+S))$, and guarantees $\\widetilde{\\mathcal{O}}(\\sqrt{ST})$ violation during exploration. Experimental results demonstrate the superiority of our algorithms in safety performance and corroborate our theoretical results",
    "checked": true,
    "id": "fea5768ae960d2539cf16ef8bc926a6d50d8f343",
    "semantic_title": "provably safe reinforcement learning with step-wise violation constraints",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=4vGVQVz5KG": {
    "title": "Unsupervised Behavior Extraction via Random Intent Priors",
    "volume": "poster",
    "abstract": "Reward-free data is abundant and contains rich prior knowledge of human behaviors, but it is not well exploited by offline reinforcement learning (RL) algorithms. In this paper, we propose UBER, an unsupervised approach to extract useful behaviors from offline reward-free datasets via diversified rewards. UBER assigns different pseudo-rewards sampled from a given prior distribution to different agents to extract a diverse set of behaviors, and reuse them as candidate policies to facilitate the learning of new tasks. Perhaps surprisingly, we show that rewards generated from random neural networks are sufficient to extract diverse and useful behaviors, some even close to expert ones. We provide both empirical and theoretical evidences to justify the use of random priors for the reward function. Experiments on multiple benchmarks showcase UBER's ability to learn effective and diverse behavior sets that enhance sample efficiency for online RL, outperforming existing baselines. By reducing reliance on human supervision, UBER broadens the applicability of RL to real-world scenarios with abundant reward-free data",
    "checked": true,
    "id": "e3b365cc2ea3a6c82eaf9428a5e7a716aa54da72",
    "semantic_title": "unsupervised behavior extraction via random intent priors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2bRG4Hj8qd": {
    "title": "Towards Accelerated Model Training via Bayesian Data Selection",
    "volume": "poster",
    "abstract": "Mislabeled, duplicated, or biased data in real-world scenarios can lead to prolonged training and even hinder model convergence. Traditional solutions prioritizing easy or hard samples lack the flexibility to handle such a variety simultaneously. Recent work has proposed a more reasonable data selection principle by examining the data's impact on the model's generalization loss. However, its practical adoption relies on less principled approximations and additional holdout data. This work solves these problems by leveraging a lightweight Bayesian treatment and incorporating off-the-shelf zero-shot predictors built on large-scale pre-trained models. The resulting algorithm is efficient and easy to implement. We perform extensive empirical studies on challenging benchmarks with considerable data noise and imbalance in the online batch selection scenario, and observe superior training efficiency over competitive baselines. Notably, on the challenging WebVision benchmark, our method can achieve similar predictive performance with significantly fewer training iterations than leading data selection methods",
    "checked": true,
    "id": "8bf0045e1807d418c6924476b9643f32d2c715f8",
    "semantic_title": "towards accelerated model training via bayesian data selection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PHbqznMa1i": {
    "title": "Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time",
    "volume": "poster",
    "abstract": "We give a polynomial-time algorithm for learning high-dimensional halfspaces with margins in $d$-dimensional space to within desired TV distance when the ambient distribution is an unknown affine transformation of the $d$-fold product of an (unknown) symmetric one-dimensional logconcave distribution, and the halfspace is introduced by deleting at least an $\\epsilon$ fraction of the data in one of the component distributions. Notably, our algorithm does not need labels and establishes the unique (and efficient) identifiability of the hidden halfspace under this distributional assumption. The sample and time complexity of the algorithm are polynomial in the dimension and $1/\\epsilon$. The algorithm uses only the first two moments of *suitable re-weightings* of the empirical distribution, which we call *contrastive moments*; its analysis uses classical facts about generalized Dirichlet polynomials and relies crucially on a new monotonicity property of the moment ratio of truncations of logconcave distributions. Such algorithms, based only on first and second moments were suggested in earlier work, but hitherto eluded rigorous guarantees. Prior work addressed the special case when the underlying distribution is Gaussian via Non-Gaussian Component Analysis. We improve on this by providing polytime guarantees based on Total Variation (TV) distance, in place of existing moment-bound guarantees that can be super-polynomial. Our work is also the first to go beyond Gaussians in this setting",
    "checked": true,
    "id": "11fb35f9ffe911c759e9c991955e20734c28bf23",
    "semantic_title": "contrastive moments: unsupervised halfspace learning in polynomial time",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0zeLTZAqaJ": {
    "title": "Accelerating Monte Carlo Tree Search with Probability Tree State Abstraction",
    "volume": "poster",
    "abstract": "Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have achieved superhuman performance in many challenging tasks. However, the computational complexity of MCTS-based algorithms is influenced by the size of the search space. To address this issue, we propose a novel probability tree state abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A general tree state abstraction with path transitivity is defined. In addition, the probability tree state abstraction is proposed for fewer mistakes during the aggregation step. Furthermore, the theoretical guarantees of the transitivity and aggregation error bound are justified. To evaluate the effectiveness of the PTSA algorithm, we integrate it with state-of-the-art MCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental results on different tasks demonstrate that our method can accelerate the training process of state-of-the-art algorithms with 10%-45% search space reduction",
    "checked": true,
    "id": "390c48b9faafb6c655e2da75e8b1673bfcad6a36",
    "semantic_title": "accelerating monte carlo tree search with probability tree state abstraction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v54eUIayFh": {
    "title": "UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild",
    "volume": "poster",
    "abstract": "Achieving machine autonomy and human control often represent divergent objectives in the design of interactive AI systems. Visual generative foundation models such as Stable Diffusion show promise in navigating these goals, especially when prompted with arbitrary languages. However, they often fall short in generating images with spatial, structural, or geometric controls. The integration of such controls, which can accommodate various visual conditions in a single unified model, remains an unaddressed challenge. In response, we introduce UniControl, a new generative foundation model that consolidates a wide array of controllable condition-to-image (C2I) tasks within a singular framework, while still allowing for arbitrary language prompts. UniControl enables pixel-level-precise image generation, where visual conditions primarily influence the generated structures and language prompts guide the style and context. To equip UniControl with the capacity to handle diverse visual conditions, we augment pretrained text-to-image diffusion models and introduce a task-aware HyperNet to modulate the diffusion models, enabling the adaptation to different C2I tasks simultaneously. Trained on nine unique C2I tasks, UniControl demonstrates impressive zero-shot generation abilities with unseen visual conditions. Experimental results show that UniControl often surpasses the performance of single-task-controlled methods of comparable model sizes. This control versatility positions UniControl as a significant advancement in the realm of controllable visual generation",
    "checked": true,
    "id": "f6fdac9b5e771394d22bfd5fbaf8147a52b6e792",
    "semantic_title": "unicontrol: a unified diffusion model for controllable visual generation in the wild",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=2z8noau98f": {
    "title": "Mutual Information Regularized Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "The major challenge of offline RL is the distribution shift that appears when out-of-distribution actions are queried, which makes the policy improvement direction biased by extrapolation errors. Most existing methods address this problem by penalizing the policy or value for deviating from the behavior policy during policy improvement or evaluation. In this work, we propose a novel MISA framework to approach offline RL from the perspective of Mutual Information between States and Actions in the dataset by directly constraining the policy improvement direction. MISA constructs lower bounds of mutual information parameterized by the policy and Q-values. We show that optimizing this lower bound is equivalent to maximizing the likelihood of a one-step improved policy on the offline dataset. Hence, we constrain the policy improvement direction to lie in the data manifold. The resulting algorithm simultaneously augments the policy evaluation and improvement by adding mutual information regularizations. MISA is a general framework that unifies conservative Q-learning (CQL) and behavior regularization methods (e.g., TD3+BC) as special cases. We introduce 3 different variants of MISA, and empirically demonstrate that tighter mutual information lower bound gives better offline RL performance. In addition, our extensive experiments show MISA significantly outperforms a wide range of baselines on various tasks of the D4RL benchmark, e.g., achieving 742.9 total points on gym-locomotion tasks. Our code is attached and will be released upon publication",
    "checked": true,
    "id": "2b23a0e5c1709d4a82e1bd09a83e2cef83d8dfe8",
    "semantic_title": "mutual information regularized offline reinforcement learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=GlWzQhf2lV": {
    "title": "Exploiting Contextual Objects and Relations for 3D Visual Grounding",
    "volume": "poster",
    "abstract": "3D visual grounding, the task of identifying visual objects in 3D scenes based on natural language inputs, plays a critical role in enabling machines to understand and engage with the real-world environment. However, this task is challenging due to the necessity to capture 3D contextual information to distinguish target objects from complex 3D scenes. The absence of annotations for contextual objects and relations further exacerbates the difficulties. In this paper, we propose a novel model, CORE-3DVG, to address these challenges by explicitly learning about contextual objects and relations. Our method accomplishes 3D visual grounding via three sequential modular networks, including a text-guided object detection network, a relation matching network, and a target identification network. During training, we introduce a pseudo-label self-generation strategy and a weakly-supervised method to facilitate the learning of contextual objects and relations, respectively. The proposed techniques allow the networks to focus more effectively on referred objects within 3D scenes by understanding their context better. We validate our model on the challenging Nr3D, Sr3D, and ScanRefer datasets and demonstrate state-of-the-art performance. Our code will be public at https://github.com/yangli18/CORE-3DVG",
    "checked": false,
    "id": "69ff4686b6517a0f9ae59503fedd8ed6e7be9983",
    "semantic_title": "3dvg-transformer: relation modeling for visual grounding on point clouds",
    "citation_count": 72,
    "authors": []
  },
  "https://openreview.net/forum?id=ECBK3TVmZl": {
    "title": "Zero-Regret Performative Prediction Under Inequality Constraints",
    "volume": "poster",
    "abstract": "Performative prediction is a recently proposed framework where predictions guide decision-making and hence influence future data distributions. Such performative phenomena are ubiquitous in various areas, such as transportation, finance, public policy, and recommendation systems. To date, work on performative prediction has only focused on unconstrained problems, neglecting the fact that many real-world learning problems are subject to constraints. This paper bridges this gap by studying performative prediction under inequality constraints. Unlike most existing work that provides only performative stable points, we aim to find the optimal solutions. Anticipating performative gradient is a challenging task, due to the agnostic performative effect on data distributions. To address this issue, we first develop a robust primal-dual framework that requires only approximate gradients up to a certain accuracy, yet delivers the same order of performance as the stationary stochastic primal-dual algorithm without performativity. Based on this framework, we then propose an adaptive primal-dual algorithm for location families. Our analysis demonstrates that the proposed adaptive primal-dual algorithm attains $\\mathcal{O}(\\sqrt{T})$ regret and constraint violations, using only $\\sqrt{T} + 2T$ samples, where $T$ is the time horizon. To our best knowledge, this is the first study and analysis on the optimality of the performative prediction problem under inequality constraints. Finally, we validate the effectiveness of our algorithm and theoretical results through numerical simulations",
    "checked": true,
    "id": "fd8dd3d442a3c95e1b05b9dd8fd6c4e5cd237cb5",
    "semantic_title": "zero-regret performative prediction under inequality constraints",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bGcdjXrU2w": {
    "title": "ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation",
    "volume": "poster",
    "abstract": "Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models. Code is available at https://github.com/gaozhitong/ATTA",
    "checked": true,
    "id": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
    "semantic_title": "atta: anomaly-aware test-time adaptation for out-of-distribution detection in segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Fdfyga5i0A": {
    "title": "Mnemosyne: Learning to Train Transformers with Transformers",
    "volume": "poster",
    "abstract": "In this work, we propose a new class of learnable optimizers, called Mnemosyne. It is based on the novel spatio-temporal low-rank implicit attention Transformers that can learn to train entire neural network architectures, including other Transformers, without any task-specific optimizer tuning. We show that Mnemosyne: (a) outperforms popular LSTM optimizers (also with new feature engineering to mitigate catastrophic forgetting of LSTMs), (b) can successfully train Transformers while using simple meta-training strategies that require minimal computational resources, (c) matches accuracy-wise SOTA hand-designed optimizers with carefully tuned hyper-parameters (often producing top performing models). Furthermore, Mnemosyne provides space complexity comparable to that of its hand-designed first-order counterparts, which allows it to scale to training larger sets of parameters. We conduct an extensive empirical evaluation of Mnemosyne on: (a) fine-tuning a wide range of Vision Transformers (ViTs) from medium-size architectures to massive ViT-Hs (36 layers, 16 heads), (b) pre-training BERT models and (c) soft prompt-tuning large 11B+ T5XXL models. We complement our results with a comprehensive theoretical analysis of the compact associative memory used by Mnemosyne which we believe was never done before",
    "checked": true,
    "id": "936551c6026df296e27a649a34f379357fb57a74",
    "semantic_title": "mnemosyne: learning to train transformers with transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IhxD94i5ra": {
    "title": "Calibration by Distribution Matching: Trainable Kernel Calibration Metrics",
    "volume": "poster",
    "abstract": "Calibration ensures that probabilistic forecasts meaningfully capture uncertainty by requiring that predicted probabilities align with empirical frequencies. However, many existing calibration methods are specialized for post-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on the insight that calibration can be viewed as a distribution matching task, we introduce kernel-based calibration metrics that unify and generalize popular forms of calibration for both classification and regression. These metrics admit differentiable sample estimates, making it easy to incorporate a calibration objective into empirical risk minimization. Furthermore, we provide intuitive mechanisms to tailor calibration metrics to a decision task, and enforce accurate loss estimation and no regret decisions. Our empirical evaluation demonstrates that employing these metrics as regularizers enhances calibration, sharpness, and decision-making across a range of regression and classification tasks, outperforming methods relying solely on post-hoc recalibration",
    "checked": true,
    "id": "7e8f43302006e5e8771e2445af7b06f1c8e7c9c9",
    "semantic_title": "calibration by distribution matching: trainable kernel calibration metrics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YV1MYtj2AR": {
    "title": "MoVie: Visual Model-Based Policy Adaptation for View Generalization",
    "volume": "poster",
    "abstract": "Visual Reinforcement Learning (RL) agents trained on limited views face significant challenges in generalizing their learned abilities to unseen views. This inherent difficulty is known as the problem of $\\textit{view generalization}$. In this work, we systematically categorize this fundamental problem into four distinct and highly challenging scenarios that closely resemble real-world situations. Subsequently, we propose a straightforward yet effective approach to enable successful adaptation of visual $\\textbf{Mo}$del-based policies for $\\textbf{Vie}$w generalization ($\\textbf{MoVie}$) during test time, without any need for explicit reward signals and any modification during training time. Our method demonstrates substantial advancements across all four scenarios encompassing a total of $\\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relative improvement of $\\mathbf{33}$%, $\\mathbf{86}$%, and $\\mathbf{152}$% respectively. The superior results highlight the immense potential of our approach for real-world robotics applications. Code and videos are available at https://yangsizhe.github.io/MoVie/",
    "checked": true,
    "id": "41dc40dc47dcd3ba65044395b20973b155233ff7",
    "semantic_title": "movie: visual model-based policy adaptation for view generalization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=0CbmvZPBGB": {
    "title": "Partial Label Learning with Dissimilarity Propagation guided Candidate Label Shrinkage",
    "volume": "poster",
    "abstract": "In partial label learning (PLL), each sample is associated with a group of candidate labels, among which only one label is correct. The key of PLL is to disambiguate the candidate label set to find the ground-truth label. To this end, we first construct a constrained regression model to capture the confidence of the candidate labels, and multiply the label confidence matrix by its transpose to build a second-order similarity matrix, whose elements indicate the pairwise similarity relationships of samples globally. Then we develop a semantic dissimilarity matrix by considering the complement of the intersection of the candidate label set, and further propagate the initial dissimilarity relationships to the whole data set by leveraging the local geometric structure of samples. The similarity and dissimilarity matrices form an adversarial relationship, which is further utilized to shrink the solution space of the label confidence matrix and promote the dissimilarity matrix. We finally extend the proposed model to a kernel version to exploit the non-linear structure of samples and solve the proposed model by the inexact augmented Lagrange multiplier method. By exploiting the adversarial prior, the proposed method can significantly outperform state-of-the-art PLL algorithms when evaluated on 10 artificial and 7 real-world partial label data sets. We also prove the effectiveness of our method with some theoretical guarantees. The code is publicly available at https://github.com/Yangfc-ML/DPCLS",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2ep5PXEZiw": {
    "title": "Foundation Model is Efficient Multimodal Multitask Model Selector",
    "volume": "poster",
    "abstract": "This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering.A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability, they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee. Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models, making it the first model selection method in the multi-task scenario. For instance, compared with the state- of-the-art method LogME enhanced by our label embeddings, EMMS achieves 9.0%, 26.3%, 20.1%, 54.8%, 12.2% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, while bringing 5.13×, 6.29×, 3.59×, 6.19×, and 5.66× speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector",
    "checked": true,
    "id": "a9a05fdbbc7d469bb4a308c3af39135225a3acba",
    "semantic_title": "foundation model is efficient multimodal multitask model selector",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=YeP8osxOht": {
    "title": "Bandit Social Learning under Myopic Behavior",
    "volume": "poster",
    "abstract": "We study social learning dynamics motivated by reviews on online platforms. The agents collectively follow a simple multi-armed bandit protocol, but each agent acts myopically, without regards to exploration. We allow a wide range of myopic behaviors that are consistent with (parameterized) confidence intervals for the arms' expected rewards. We derive stark exploration failures for any such behavior, and provide matching positive results. As a special case, we obtain the first general results on failure of the greedy algorithm in bandits, thus providing a theoretical foundation for why bandit algorithms should explore",
    "checked": false,
    "id": "58a8abdc17952e20892d45cc81d74d96f59de470",
    "semantic_title": "bandit social learning: exploration under myopic behavior",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=6ePsuwXUwf": {
    "title": "An Efficient End-to-End Training Approach for Zero-Shot Human-AI Coordination",
    "volume": "poster",
    "abstract": "The goal of zero-shot human-AI coordination is to develop an agent that can collaborate with humans without relying on human data. Prevailing two-stage population-based methods require a diverse population of mutually distinct policies to simulate diverse human behaviors. The necessity of such populations severely limits their computational efficiency. To address this issue, we propose E3T, an **E**fficient **E**nd-to-**E**nd **T**raining approach for zero-shot human-AI coordination. E3T employs a mixture of ego policy and random policy to construct the partner policy, making it both coordination-skilled and diverse. In this way, the ego agent is end-to-end trained with this mixture policy without the need of a pre-trained population, thus significantly improving the training efficiency. In addition, a partner modeling module is proposed to predict the partner's action from historical information. With the predicted partner's action, the ego policy is able to adapt its policy and take actions accordingly when collaborating with humans of different behavior patterns. Empirical results on the Overcooked environment show that our method significantly improves the training efficiency while preserving comparable or superior performance than the population-based baselines. Demo videos are available at https://sites.google.com/view/e3t-overcooked",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Znpz1sv4IP": {
    "title": "SE(3) Diffusion Model-based Point Cloud Registration for Robust 6D Object Pose Estimation",
    "volume": "poster",
    "abstract": "In this paper, we introduce an SE(3) diffusion model-based point cloud registration framework for 6D object pose estimation in real-world scenarios. Our approach formulates the 3D registration task as a denoising diffusion process, which progressively refines the pose of the source point cloud to obtain a precise alignment with the model point cloud. Training our framework involves two operations: An SE(3) diffusion process and an SE(3) reverse process. The SE(3) diffusion process gradually perturbs the optimal rigid transformation of a pair of point clouds by continuously injecting noise (perturbation transformation). By contrast, the SE(3) reverse process focuses on learning a denoising network that refines the noisy transformation step-by-step, bringing it closer to the optimal transformation for accurate pose estimation. Unlike standard diffusion models used in linear Euclidean spaces, our diffusion model operates on the SE(3) manifold. This requires exploiting the linear Lie algebra $\\mathfrak{se}(3)$ associated with SE(3) to constrain the transformation transitions during the diffusion and reverse processes. Additionally, to effectively train our denoising network, we derive a registration-specific variational lower bound as the optimization objective for model learning. Furthermore, we show that our denoising network can be constructed with a surrogate registration model, making our approach applicable to different deep registration networks. Extensive experiments demonstrate that our diffusion registration framework presents outstanding pose estimation performance on the real-world TUD-L, LINEMOD, and Occluded-LINEMOD datasets",
    "checked": true,
    "id": "f8a45226715b20deb6618b5f21e307c02cdf8777",
    "semantic_title": "se(3) diffusion model-based point cloud registration for robust 6d object pose estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eMR57voMz1": {
    "title": "Diversify \\& Conquer: Outcome-directed Curriculum RL via Out-of-Distribution Disagreement",
    "volume": "poster",
    "abstract": "Reinforcement learning (RL) often faces the challenges of uninformed search problems where the agent should explore without access to the domain knowledge such as characteristics of the environment or external rewards. To tackle these challenges, this work proposes a new approach for curriculum RL called $\\textbf{D}$iversify for $\\textbf{D}$isagreement \\& $\\textbf{C}$onquer ($\\textbf{D2C}$). Unlike previous curriculum learning methods, D2C requires only a few examples of desired outcomes and works in any environment, regardless of its geometry or the distribution of the desired outcome examples. The proposed method performs diversification of the goal-conditional classifiers to identify similarities between visited and desired outcome states and ensures that the classifiers disagree on states from out-of-distribution, which enables quantifying the unexplored region and designing an arbitrary goal-conditioned intrinsic reward signal in a simple and intuitive way. The proposed method then employs bipartite matching to define a curriculum learning objective that produces a sequence of well-adjusted intermediate goals, which enable the agent to automatically explore and conquer the unexplored region. We present experimental results demonstrating that D2C outperforms prior curriculum RL methods in both quantitative and qualitative aspects, even with the arbitrarily distributed desired outcome examples",
    "checked": false,
    "id": "746eea132521f94d23818a18e57bcadd31710e43",
    "semantic_title": "diversify & conquer: outcome-directed curriculum rl via out-of-distribution disagreement",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R8GF0EsNsI": {
    "title": "Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem",
    "volume": "poster",
    "abstract": "In this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $\\mathcal{O}(\\max\\\\{1/\\epsilon_f^{2},1/\\epsilon_g^{2}\\\\}) $ stochastic oracle queries to obtain a solution that is $\\epsilon_f$-optimal for the upper-level and $\\epsilon_g$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $\\mathcal{O}(\\max\\\\{1/\\epsilon_f^{4},1/\\epsilon_g^{4}\\\\})$. Moreover, for the case that the upper-level function is non-convex, our method requires at most $\\mathcal{O}(\\max\\\\{1/\\epsilon_f^{3},1/\\epsilon_g^{3}\\\\}) $ stochastic oracle queries to find an $(\\epsilon_f, \\epsilon_g)$-stationary point. In the finite-sum setting, we show that the number of stochastic oracle calls required by our method are $\\mathcal{O}(\\sqrt{n}/\\epsilon)$ and $\\mathcal{O}(\\sqrt{n}/\\epsilon^{2})$ for the convex and non-convex settings, respectively, where $\\epsilon=\\min \\\\{\\epsilon_f,\\epsilon_g\\\\}$",
    "checked": true,
    "id": "d5536f4090cedfe2d89d1b39ee39f923815dff00",
    "semantic_title": "projection-free methods for stochastic simple bilevel optimization with convex lower-level problem",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=dyXNh5HLq3": {
    "title": "Compositional Foundation Models for Hierarchical Planning",
    "volume": "poster",
    "abstract": "To make effective decisions in novel environments with long-horizon goals, it is crucial to engage in hierarchical reasoning across spatial and temporal scales. This entails planning abstract subgoal sequences, visually reasoning about the underlying plans, and executing actions in accordance with the devised plan through visual-motor control. We propose Compositional Foundation Models for Hierarchical Planning (HiP), a foundation model which leverages multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks. We use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos. To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement. We illustrate the efficacy and adaptability of our approach in three different long-horizon table-top manipulation tasks",
    "checked": true,
    "id": "024575aec54fb329eb6224684592d85b6672930d",
    "semantic_title": "compositional foundation models for hierarchical planning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=huh0XmSdBK": {
    "title": "NPCL: Neural Processes for Uncertainty-Aware Continual Learning",
    "volume": "poster",
    "abstract": "Continual learning (CL) aims to train deep neural networks efficiently on streaming data while limiting the forgetting caused by new tasks. However, learning transferable knowledge with less interference between tasks is difficult, and real-world deployment of CL models is limited by their inability to measure predictive uncertainties. To address these issues, we propose handling CL tasks with neural processes (NPs), a class of meta-learners that encode different tasks into probabilistic distributions over functions all while providing reliable uncertainty estimates. Specifically, we propose an NP-based CL approach (NPCL) with task-specific modules arranged in a hierarchical latent variable model. We tailor regularizers on the learned latent distributions to alleviate forgetting. The uncertainty estimation capabilities of the NPCL can also be used to handle the task head/module inference challenge in CL. Our experiments show that the NPCL outperforms previous CL approaches. We validate the effectiveness of uncertainty estimation in the NPCL for identifying novel data and evaluating instance-level model confidence. Code is available at https://github.com/srvCodes/NPCL",
    "checked": true,
    "id": "f20140ed835172a476810c479fb3ed368d8e6c91",
    "semantic_title": "npcl: neural processes for uncertainty-aware continual learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=u4YXKKG5dX": {
    "title": "Graph Denoising Diffusion for Inverse Protein Folding",
    "volume": "poster",
    "abstract": "Inverse protein folding is challenging due to its inherent one-to-many mapping characteristic, where numerous possible amino acid sequences can fold into a single, identical protein backbone. This task involves not only identifying viable sequences but also representing the sheer diversity of potential solutions. However, existing discriminative models, such as transformer-based auto-regressive models, struggle to encapsulate the diverse range of plausible solutions. In contrast, diffusion probabilistic models, as an emerging genre of generative approaches, offer the potential to generate a diverse set of sequence candidates for determined protein backbones. We propose a novel graph denoising diffusion model for inverse protein folding, where a given protein backbone guides the diffusion process on the corresponding amino acid residue types. The model infers the joint distribution of amino acids conditioned on the nodes' physiochemical properties and local environment. Moreover, we utilize amino acid replacement matrices for the diffusion forward process, encoding the biologically-meaningful prior knowledge of amino acids from their spatial and sequential neighbors as well as themselves, which reduces the sampling space of the generative process. Our model achieves state-of-the-art performance over a set of popular baseline methods in sequence recovery and exhibits great potential in generating diverse protein sequences for a determined protein backbone structure",
    "checked": true,
    "id": "f3570e639e2acda861ea6efe02a4fcb321d76c40",
    "semantic_title": "graph denoising diffusion for inverse protein folding",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=1YEF6TA8Di": {
    "title": "Langevin Quasi-Monte Carlo",
    "volume": "poster",
    "abstract": "Langevin Monte Carlo (LMC) and its stochastic gradient versions are powerful algorithms for sampling from complex high-dimensional distributions. To sample from a distribution with density $\\pi(\\theta)\\propto \\exp(-U(\\theta)) $, LMC iteratively generates the next sample by taking a step in the gradient direction $\\nabla U$ with added Gaussian perturbations. Expectations w.r.t. the target distribution $\\pi$ are estimated by averaging over LMC samples. In ordinary Monte Carlo, it is well known that the estimation error can be substantially reduced by replacing independent random samples by quasi-random samples like low-discrepancy sequences. In this work, we show that the estimation error of LMC can also be reduced by using quasi-random samples. Specifically, we propose to use completely uniformly distributed (CUD) sequences with certain low-discrepancy property to generate the Gaussian perturbations. Under smoothness and convexity conditions, we prove that LMC with a low-discrepancy CUD sequence achieves smaller error than standard LMC. The theoretical analysis is supported by compelling numerical experiments, which demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "2c39d661fed0ec9e23a525cc2b11c26efc0d04fe",
    "semantic_title": "langevin quasi-monte carlo",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l9BsCh8ikK": {
    "title": "Visual Instruction Inversion: Image Editing via Image Prompting",
    "volume": "poster",
    "abstract": "Text-conditioned image editing has emerged as a powerful tool for editing images. However, in many situations, language can be ambiguous and ineffective in describing specific image edits. When faced with such challenges, visual prompts can be a more informative and intuitive way to convey ideas. We present a method for image editing via visual prompting. Given pairs of example that represent the \"before\" and \"after\" images of an edit, our goal is to learn a text-based editing direction that can be used to perform the same edit on new images. We leverage the rich, pretrained editing capabilities of text-to-image diffusion models by inverting visual prompts into editing instructions. Our results show that with just one example pair, we can achieve competitive results compared to state-of-the-art text-conditioned image editing frameworks",
    "checked": false,
    "id": "f4c62aa336de45273e0fdfcfbd65b3c2e552ad56",
    "semantic_title": "visual instruction inversion: image editing via visual prompting",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=XbInLmYLDr": {
    "title": "DiViNeT: 3D Reconstruction from Disparate Views using Neural Template Regularization",
    "volume": "poster",
    "abstract": "We present a volume rendering-based neural surface reconstruction method that takes as few as three disparate RGB images as input. Our key idea is to regularize the reconstruction, which is severely ill-posed and leaving significant gaps between the sparse views, by learning a set of neural templates that act as surface priors. Our method, coined DiViNet, operates in two stages. The first stage learns the templates, in the form of 3D Gaussian functions, across different scenes, without 3D supervision. In the reconstruction stage, our predicted templates serve as anchors to help \"stitch\" the surfaces over sparse regions. We demonstrate that our approach is not only able to complete the surface geometry but also reconstructs surface details to a reasonable extent from few disparate input views. On the DTU and BlendedMVS datasets, our approach achieves the best reconstruction quality among existing methods in the presence of such sparse views and performs on par, if not better, with competing methods when dense views are employed as inputs",
    "checked": false,
    "id": "22bcebfd4f939e15e5b1356774b9750a568f73e3",
    "semantic_title": "divinet: 3d reconstruction from disparate views via neural template regularization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eYCGrGdKf3": {
    "title": "Unleash the Potential of Image Branch for Cross-modal 3D Object Detection",
    "volume": "poster",
    "abstract": "To achieve reliable and precise scene understanding, autonomous vehicles typically incorporate multiple sensing modalities to capitalize on their complementary attributes. However, existing cross-modal 3D detectors do not fully utilize the image domain information to address the bottleneck issues of the LiDAR-based detectors. This paper presents a new cross-modal 3D object detector, namely UPIDet, which aims to unleash the potential of the image branch from two aspects. First, UPIDet introduces a new 2D auxiliary task called normalized local coordinate map estimation. This approach enables the learning of local spatial-aware features from the image modality to supplement sparse point clouds. Second, we discover that the representational capability of the point cloud backbone can be enhanced through the gradients backpropagated from the training objectives of the image branch, utilizing a succinct and effective point-to-pixel module. Extensive experiments and ablation studies validate the effectiveness of our method. Notably, we achieved the top rank in the highly competitive cyclist class of the KITTI benchmark at the time of submission. The source code is available at https://github.com/Eaphan/UPIDet",
    "checked": true,
    "id": "0ceb765c07eec766ace5a649af4231523a35ba9e",
    "semantic_title": "unleash the potential of image branch for cross-modal 3d object detection",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Orp1K2dZvY": {
    "title": "Weakly Supervised 3D Open-vocabulary Segmentation",
    "volume": "poster",
    "abstract": "Open-vocabulary segmentation of 3D scenes is a fundamental function of human perception and thus a crucial objective in computer vision research. However, this task is heavily impeded by the lack of large-scale and diverse 3D open-vocabulary segmentation datasets for training robust and generalizable models. Distilling knowledge from pre-trained 2D open-vocabulary segmentation models helps but it compromises the open-vocabulary feature as the 2D models are mostly finetuned with close-vocabulary datasets. We tackle the challenges in 3D open-vocabulary segmentation by exploiting pre-trained foundation models CLIP and DINO in a weakly supervised manner. Specifically, given only the open-vocabulary text descriptions of the objects in a scene, we distill the open-vocabulary multimodal knowledge and object reasoning capability of CLIP and DINO into a neural radiance field (NeRF), which effectively lifts 2D features into view-consistent 3D segmentation. A notable aspect of our approach is that it does not require any manual segmentation annotations for either the foundation models or the distillation process. Extensive experiments show that our method even outperforms fully supervised models trained with segmentation annotations in certain scenes, suggesting that 3D open-vocabulary segmentation can be effectively learned from 2D images and text-image pairs. Code is available at https://github.com/Kunhao-Liu/3D-OVS",
    "checked": true,
    "id": "266a8f8a8e1185ae543bf5551a4973877be506e7",
    "semantic_title": "weakly supervised 3d open-vocabulary segmentation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qQnO1HLQHe": {
    "title": "Complex Query Answering on Eventuality Knowledge Graph with Implicit Logical Constraints",
    "volume": "poster",
    "abstract": "Querying knowledge graphs (KGs) using deep learning approaches can naturally leverage the reasoning and generalization ability to learn to infer better answers. Traditional neural complex query answering (CQA) approaches mostly work on entity-centric KGs. However, in the real world, we also need to make logical inferences about events, states, and activities (i.e., eventualities or situations) to push learning systems from System I to System II, as proposed by Yoshua Bengio. Querying logically from an EVentuality-centric KG (EVKG) can naturally provide references to such kind of intuitive and logical inference. Thus, in this paper, we propose a new framework to leverage neural methods to answer complex logical queries based on an EVKG, which can satisfy not only traditional first-order logic constraints but also implicit logical constraints over eventualities concerning their occurrences and orders. For instance, if we know that *Food is bad* happens before *PersonX adds soy sauce*, then *PersonX adds soy sauce* is unlikely to be the cause of *Food is bad* due to implicit temporal constraint. To facilitate consistent reasoning on EVKGs, we propose Complex Eventuality Query Answering (CEQA), a more rigorous definition of CQA that considers the implicit logical constraints governing the temporal order and occurrence of eventualities. In this manner, we propose to leverage theorem provers for constructing benchmark datasets to ensure the answers satisfy implicit logical constraints. We also propose a Memory-Enhanced Query Encoding (MEQE) approach to significantly improve the performance of state-of-the-art neural query encoders on the CEQA task",
    "checked": true,
    "id": "da9bbfb3d3c3ddd76251a9a1069def181ef3128f",
    "semantic_title": "complex query answering on eventuality knowledge graph with implicit logical constraints",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=pw5hEuEroL": {
    "title": "Unified Enhancement of Privacy Bounds for Mixture Mechanisms via $f$-Differential Privacy",
    "volume": "poster",
    "abstract": "Differentially private (DP) machine learning algorithms incur many sources of randomness, such as random initialization, random batch subsampling, and shuffling. However, such randomness is difficult to take into account when proving differential privacy bounds because it induces mixture distributions for the algorithm's output that are difficult to analyze. This paper focuses on improving privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. We derive a closed-form expression of the trade-off function for shuffling models that outperforms the most up-to-date results based on $(\\epsilon,\\delta)$-DP. Moreover, we investigate the effects of random initialization on the privacy of one-iteration DP-GD. Our numerical computations of the trade-off function indicate that random initialization can enhance the privacy of DP-GD. Our analysis of $f$-DP guarantees for these mixture mechanisms relies on an inequality for trade-off functions introduced in this paper. This inequality implies the joint convexity of $F$-divergences. Finally, we study an $f$-DP analog of the advanced joint convexity of the hockey-stick divergence related to $(\\epsilon,\\delta)$-DP and apply it to analyze the privacy of mixture mechanisms",
    "checked": false,
    "id": "417301d5b40c5d2bbc307a9dd3e323416989f80e",
    "semantic_title": "unified enhancement of privacy bounds for mixture mechanisms via f-differential privacy",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=wNpsGwixjG": {
    "title": "Leveraging Early-Stage Robustness in Diffusion Models for Efficient and High-Quality Image Synthesis",
    "volume": "poster",
    "abstract": "While diffusion models have demonstrated exceptional image generation capabilities, the iterative noise estimation process required for these models is compute-intensive and their practical implementation is limited by slow sampling speeds. In this paper, we propose a novel approach to speed up the noise estimation network by leveraging the robustness of early-stage diffusion models. Our findings indicate that inaccurate computation during the early-stage of the reverse diffusion process has minimal impact on the quality of generated images, as this stage primarily outlines the image while later stages handle the finer details that require more sensitive information. To improve computational efficiency, we combine our findings with post-training quantization (PTQ) to introduce a method that utilizes low-bit activation for the early reverse diffusion process while maintaining high-bit activation for the later stages. Experimental results show that the proposed method can accelerate the early-stage computation without sacrificing the quality of the generated images",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8YN62t19AW": {
    "title": "A Unified Discretization Framework for Differential Equation Approach with Lyapunov Arguments for Convex Optimization",
    "volume": "poster",
    "abstract": "The differential equation (DE) approach for convex optimization, which relates optimization methods to specific continuous DEs with rate-revealing Lyapunov functionals, has gained increasing interest since the seminal paper by Su--Boyd--Candès (2014). However, the approach still lacks a crucial component to make it truly useful: there is no general, consistent way to transition back to discrete optimization methods. Consequently, even if we derive insights from continuous DEs, we still need to perform individualized and tedious calculations for the analysis of each method. This paper aims to bridge this gap by introducing a new concept called ``weak discrete gradient'' (wDG), which consolidates the conditions required for discrete versions of gradients in the DE approach arguments. We then define abstract optimization methods using wDG and provide abstract convergence theories that parallel those in continuous DEs. We demonstrate that many typical optimization methods and their convergence rates can be derived as special cases of this abstract theory. The proposed unified discretization framework for the differential equation approach to convex optimization provides an easy environment for developing new optimization methods and achieving competitive convergence rates with state-of-the-art methods, such as Nesterov's accelerated gradient",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JX6UloWrmE": {
    "title": "Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition",
    "volume": "poster",
    "abstract": "Meta-reinforcement learning (meta-RL) techniques have demonstrated remarkable success in generalizing deep reinforcement learning across a range of tasks. Nevertheless, these methods often struggle to generalize beyond tasks with parametric variations. To overcome this challenge, we propose Subtask Decomposition and Virtual Training (SDVT), a novel meta-RL approach that decomposes each non-parametric task into a collection of elementary subtasks and parameterizes the task based on its decomposition. We employ a Gaussian mixture VAE to meta-learn the decomposition process, enabling the agent to reuse policies acquired from common subtasks. Additionally, we propose a virtual training procedure, specifically designed for non-parametric task variability, which generates hypothetical subtask compositions, thereby enhancing generalization to previously unseen subtask compositions. Our method significantly improves performance on the Meta-World ML-10 and ML-45 benchmarks, surpassing current state-of-the-art techniques",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FviF8vuz5B": {
    "title": "On Differentially Private Sampling from Gaussian and Product Distributions",
    "volume": "poster",
    "abstract": "We study the problem, where given a dataset of $n$ i.i.d. samples from an unknown distribution $P$, we seek to generate a sample from a distribution that is close to $P$ in total variation distance, under the constraint of differential privacy. We study the settings where $P$ is a multi-dimensional Gaussian distribution with different assumptions: known covariance, unknown bounded covariance, and unknown unbounded covariance. We present new differentially private sampling algorithms, and show that they achieve near-optimal sample complexity in the first two settings. Moreover, when $P$ is a product distribution on the binary hypercube, we obtain a pure-DP algorithm whereas only an approximate-DP algorithm (with slightly worse sample complexity) was previously known",
    "checked": true,
    "id": "b2fab63fc33c48a81fee5f1f8e5071e1b3b0b01f",
    "semantic_title": "on differentially private sampling from gaussian and product distributions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=os2BdbiGwX": {
    "title": "Model and Feature Diversity for Bayesian Neural Networks in Mutual Learning",
    "volume": "poster",
    "abstract": "Bayesian Neural Networks (BNNs) offer probability distributions for model parameters, enabling uncertainty quantification in predictions. However, they often underperform compared to deterministic neural networks. Utilizing mutual learning can effectively enhance the performance of peer BNNs. In this paper, we propose a novel approach to improve BNNs performance through deep mutual learning. The proposed approaches aim to increase diversity in both network parameter distributions and feature distributions, promoting peer networks to acquire distinct features that capture different characteristics of the input, which enhances the effectiveness of mutual learning. Experimental results demonstrate significant improvements in the classification accuracy, negative log-likelihood, and expected calibration error when compared to traditional mutual learning for BNNs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DNHGKeOhLl": {
    "title": "On the Stability-Plasticity Dilemma in Continual Meta-Learning: Theory and Algorithm",
    "volume": "poster",
    "abstract": "We focus on Continual Meta-Learning (CML), which targets accumulating and exploiting meta-knowledge on a sequence of non-i.i.d. tasks. The primary challenge is to strike a balance between stability and plasticity, where a model should be stable to avoid catastrophic forgetting in previous tasks and plastic to learn generalizable concepts from new tasks. To address this, we formulate the CML objective as controlling the average excess risk upper bound of the task sequence, which reflects the trade-off between forgetting and generalization. Based on the objective, we introduce a unified theoretical framework for CML in both static and shifting environments, providing guarantees for various task-specific learning algorithms. Moreover, we first present a rigorous analysis of a bi-level trade-off in shifting environments. To approach the optimal trade-off, we propose a novel algorithm that dynamically adjusts the meta-parameter and its learning rate w.r.t environment change. Empirical evaluations on synthetic and real datasets illustrate the effectiveness of the proposed theory and algorithm",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b2wSODM7iG": {
    "title": "LightSpeed: Light and Fast Neural Light Fields on Mobile Devices",
    "volume": "poster",
    "abstract": "Real-time novel-view image synthesis on mobile devices is prohibitive due to the limited computational power and storage. Using volumetric rendering methods, such as NeRF and its derivatives, on mobile devices is not suitable due to the high computational cost of volumetric rendering. On the other hand, recent advances in neural light field representations have shown promising real-time view synthesis results on mobile devices. Neural light field methods learn a direct mapping from a ray representation to the pixel color. The current choice of ray representation is either stratified ray sampling or Plücker coordinates, overlooking the classic light slab (two-plane) representation, the preferred representation to interpolate between light field views. In this work, we find that using the light slab representation is an efficient representation for learning a neural light field. More importantly, it is a lower-dimensional ray representation enabling us to learn the 4D ray space using feature grids which are significantly faster to train and render. Although mostly designed for frontal views, we show that the light-slab representation can be further extended to non-frontal scenes using a divide-and-conquer strategy. Our method provides better rendering quality than prior light field methods and a significantly better trade-off between rendering quality and speed than prior light field methods",
    "checked": true,
    "id": "092797a2735fdd36089f52d11ca49bc6bf90cee2",
    "semantic_title": "lightspeed: light and fast neural light fields on mobile devices",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q5tuGgqJwt": {
    "title": "Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic Detection of Infeasible Plans",
    "volume": "poster",
    "abstract": "Diffusion-based planning has shown promising results in long-horizon, sparse-reward tasks by training trajectory diffusion models and conditioning the sampled trajectories using auxiliary guidance functions. However, due to their nature as generative models, diffusion models are not guaranteed to generate feasible plans, resulting in failed execution and precluding planners from being useful in safety-critical applications. In this work, we propose a novel approach to refine unreliable plans generated by diffusion models by providing refining guidance to error-prone plans. To this end, we suggest a new metric named restoration gap for evaluating the quality of individual plans generated by the diffusion model. A restoration gap is estimated by a gap predictor which produces restoration gap guidance to refine a diffusion planner. We additionally present an attribution map regularizer to prevent adversarial refining guidance that could be generated from the sub-optimal gap predictor, which enables further refinement of infeasible plans. We demonstrate the effectiveness of our approach on three different benchmarks in offline control settings that require long-horizon planning. We also illustrate that our approach presents explainability by presenting the attribution maps of the gap predictor and highlighting error-prone transitions, allowing for a deeper understanding of the generated plans",
    "checked": true,
    "id": "9d6ad3fc3d0575152fb755722d8e76ea512b9113",
    "semantic_title": "refining diffusion planner for reliable behavior synthesis by automatic detection of infeasible plans",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1mAYtdoYw6": {
    "title": "Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding",
    "volume": "poster",
    "abstract": "Spectral embedding is a powerful graph embedding technique that has received a lot of attention recently due to its effectiveness on Graph Transformers. However, from a theoretical perspective, the universal expressive power of spectral embedding comes at the price of losing two important invariance properties of graphs, sign and basis invariance, which also limits its effectiveness on graph data. To remedy this issue, many previous methods developed costly approaches to learn new invariants and suffer from high computation complexity. In this work, we explore a minimal approach that resolves the ambiguity issues by directly finding canonical directions for the eigenvectors, named Laplacian Canonization (LC). As a pure pre-processing method, LC is light-weighted and can be applied to any existing GNNs. We provide a thorough investigation, from theory to algorithm, on this approach, and discover an efficient algorithm named Maximal Axis Projection (MAP) that works for both sign and basis invariance and successfully canonizes more than 90\\% of all eigenvectors. Experiments on real-world benchmark datasets like ZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing methods while bringing minimal computation overhead. Code is available at \\url{https://github.com/PKU-ML/LaplacianCanonization}",
    "checked": true,
    "id": "d23c3df67a2e9c78160cadfab7f6bc8ee98a045e",
    "semantic_title": "laplacian canonization: a minimalist approach to sign and basis invariant spectral embedding",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=4gLWjSaw4o": {
    "title": "Recovering from Out-of-sample States via Inverse Dynamics in Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "In this paper we deal with the state distributional shift problem commonly encountered in offline reinforcement learning during test, where the agent tends to take unreliable actions at out-of-sample (unseen) states. Our idea is to encourage the agent to follow the so called state recovery principle when taking actions, i.e., besides long-term return, the immediate consequences of the current action should also be taken into account and those capable of recovering the state distribution of the behavior policy are preferred. For this purpose, an inverse dynamics model is learned and employed to guide the state recovery behavior of the new policy. Theoretically, we show that the proposed method helps aligning the transited state distribution of the new policy with the offline dataset at out-of-sample states, without the need of explicitly predicting the transited state distribution, which is usually difficult in high-dimensional and complicated environments. The effectiveness and feasibility of the proposed method is demonstrated with the state-of-the-art performance on the general offline RL benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QGQsOZcQ2H": {
    "title": "Neural Oscillators are Universal",
    "volume": "poster",
    "abstract": "Coupled oscillators are being increasingly used as the basis of machine learning (ML) architectures, for instance in sequence modeling, graph representation learning and in physical neural networks that are used in analog ML devices. We introduce an abstract class of *neural oscillators* that encompasses these architectures and prove that neural oscillators are universal, i.e, they can approximate any continuous and casual operator mapping between time-varying functions, to desired accuracy. This universality result provides theoretical justification for the use of oscillator based ML systems. The proof builds on a fundamental result of independent interest, which shows that a combination of forced harmonic oscillators with a nonlinear read-out suffices to approximate the underlying operators",
    "checked": true,
    "id": "e4a5bfebc5c26c432809d5c564024f789c58eeb8",
    "semantic_title": "neural oscillators are universal",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=wHhPIv5G8Q": {
    "title": "Online Corrupted User Detection and Regret Minimization",
    "volume": "poster",
    "abstract": "In real-world online web systems, multiple users usually arrive sequentially into the system. For applications like click fraud and fake reviews, some users can maliciously perform corrupted (disrupted) behaviors to trick the system. Therefore, it is crucial to design efficient online learning algorithms to robustly learn from potentially corrupted user behaviors and accurately identify the corrupted users in an online manner. Existing works propose bandit algorithms robust to adversarial corruption. However, these algorithms are designed for a single user, and cannot leverage the implicit social relations among multiple users for more efficient learning. Moreover, none of them consider how to detect corrupted users online in the multiple-user scenario. In this paper, we present an important online learning problem named LOCUD to learn and utilize unknown user relations from disrupted behaviors to speed up learning, and identify the corrupted users in an online setting. To robustly learn and utilize the unknown relations among potentially corrupted users, we propose a novel bandit algorithm RCLUB-WCU. To detect the corrupted users, we devise a novel online detection algorithm OCCUD based on RCLUB-WCU's inferred user relations. We prove a regret upper bound for RCLUB-WCU, which asymptotically matches the lower bound with respect to $T$ up to logarithmic factors, and matches the state-of-the-art results in degenerate cases. We also give a theoretical guarantee for the detection accuracy of OCCUD. With extensive experiments, our methods achieve superior performance over previous bandit algorithms and high corrupted user detection accuracy",
    "checked": true,
    "id": "f1827e73c44a67346664f69a57ca6d6b48a55178",
    "semantic_title": "online corrupted user detection and regret minimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=StD4J5ZlI5": {
    "title": "Dataset Diffusion: Diffusion-based Synthetic Data Generation for Pixel-Level Semantic Segmentation",
    "volume": "poster",
    "abstract": "Preparing training data for deep vision models is a labor-intensive task. To address this, generative models have emerged as an effective solution for generating synthetic data. While current generative models produce image-level category labels, we propose a novel method for generating pixel-level semantic segmentation labels using the text-to-image generative model Stable Diffusion (SD). By utilizing the text prompts, cross-attention, and self-attention of SD, we introduce three new techniques: class-prompt appending, class-prompt cross-attention, and self-attention exponentiation. These techniques enable us to generate segmentation maps corresponding to synthetic images. These maps serve as pseudo-labels for training semantic segmenters, eliminating the need for labor-intensive pixel-wise annotation. To account for the imperfections in our pseudo-labels, we incorporate uncertainty regions into the segmentation, allowing us to disregard loss from those regions. We conduct evaluations on two datasets, PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent work. Our benchmarks and code will be released at https://github.com/VinAIResearch/Dataset-Diffusion",
    "checked": false,
    "id": "a6a13dd87672560b9e66e5cfeb25e353f3936848",
    "semantic_title": "dataset diffusion: diffusion-based synthetic dataset generation for pixel-level semantic segmentation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ouLe91yibj": {
    "title": "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
    "volume": "poster",
    "abstract": "Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function. For small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research",
    "checked": true,
    "id": "246e50696ef630f48e3090599165bddf1c879739",
    "semantic_title": "on the properties of kullback-leibler divergence between multivariate gaussian distributions",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=1mJQq6zYaE": {
    "title": "Exploring the Optimal Choice for Generative Processes in Diffusion Models: Ordinary vs Stochastic Differential Equations",
    "volume": "poster",
    "abstract": "The diffusion model has shown remarkable success in computer vision, but it remains unclear whether the ODE-based probability flow or the SDE-based diffusion model is more superior and under what circumstances. Comparing the two is challenging due to dependencies on data distributions, score training, and other numerical issues. In this paper, we study the problem mathematically for two limiting scenarios: the zero diffusion (ODE) case and the large diffusion case. We first introduce a pulse-shape error to perturb the score function and analyze error accumulation of sampling quality, followed by a thorough analysis for generalization to arbitrary error. Our findings indicate that when the perturbation occurs at the end of the generative process, the ODE model outperforms the SDE model with a large diffusion coefficient. However, when the perturbation occurs earlier, the SDE model outperforms the ODE model. We demonstrate that the error of sample generation due to the pulse-shape perturbation is exponentially suppressed as the diffusion term's magnitude increases to infinity. Numerical validation of this phenomenon is provided using Gaussian, Gaussian mixture, and Swiss roll distribution, as well as realistic datasets like MNIST and CIFAR-10",
    "checked": true,
    "id": "2f78b7cbce3c4ee4b42b5cba9ab2165f15e5c627",
    "semantic_title": "exploring the optimal choice for generative processes in diffusion models: ordinary vs stochastic differential equations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=rbw9xCU6Ci": {
    "title": "Adaptive Test-Time Personalization for Federated Learning",
    "volume": "poster",
    "abstract": "Personalized federated learning algorithms have shown promising results in adapting models to various distribution shifts. However, most of these methods require labeled data on testing clients for personalization, which is usually unavailable in real-world scenarios. In this paper, we introduce a novel setting called test-time personalized federated learning (TTPFL), where clients locally adapt a global model in an unsupervised way without relying on any labeled data during test-time. While traditional test-time adaptation (TTA) can be used in this scenario, most of them inherently assume training data come from a single domain, while they come from multiple clients (source domains) with different distributions. Overlooking these domain interrelationships can result in suboptimal generalization. Moreover, most TTA algorithms are designed for a specific kind of distribution shift and lack the flexibility to handle multiple kinds of distribution shifts in FL. In this paper, we find that this lack of flexibility partially results from their pre-defining which modules to adapt in the model. To tackle this challenge, we propose a novel algorithm called ATP to adaptively learns the adaptation rates for each module in the model from distribution shifts among source domains. Theoretical analysis proves the strong generalization of ATP. Extensive experiments demonstrate its superiority in handling various distribution shifts including label shift, image corruptions, and domain shift, outperforming existing TTA methods across multiple datasets and model architectures. Our code is available at https://github.com/baowenxuan/ATP",
    "checked": true,
    "id": "6e28a7531963fd65d9e150fdb0b788de79717ce3",
    "semantic_title": "adaptive test-time personalization for federated learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sg3aCpWUQP": {
    "title": "Errors-in-variables Fr\\'echet Regression with Low-rank Covariate Approximation",
    "volume": "poster",
    "abstract": "Fr\\'echet regression has emerged as a promising approach for regression analysis involving non-Euclidean response variables. However, its practical applicability has been hindered by its reliance on ideal scenarios with abundant and noiseless covariate data. In this paper, we present a novel estimation method that tackles these limitations by leveraging the low-rank structure inherent in the covariate matrix. Our proposed framework combines the concepts of global Fr\\'echet regression and principal component regression, aiming to improve the efficiency and accuracy of the regression estimator. By incorporating the low-rank structure, our method enables more effective modeling and estimation, particularly in high-dimensional and errors-in-variables regression settings. We provide a theoretical analysis of the proposed estimator's large-sample properties, including a comprehensive rate analysis of bias, variance, and additional variations due to measurement errors. Furthermore, our numerical experiments provide empirical evidence that supports the theoretical findings, demonstrating the superior performance of our approach. Overall, this work introduces a promising framework for regression analysis of non-Euclidean variables, effectively addressing the challenges associated with limited and noisy covariate data, with potential applications in diverse fields",
    "checked": true,
    "id": "2f40c3aa0acd3468307841e8dc3adb91a1efd107",
    "semantic_title": "errors-in-variables fr\\'echet regression with low-rank covariate approximation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E0Gw1uz7lU": {
    "title": "Federated Conditional Stochastic Optimization",
    "volume": "poster",
    "abstract": "Conditional stochastic optimization has found applications in a wide range of machine learning tasks, such as invariant learning, AUPRC maximization, and meta-learning. As the demand for training models with large-scale distributed data grows in these applications, there is an increasing need for communication-efficient distributed optimization algorithms, such as federated learning algorithms. This paper considers the nonconvex conditional stochastic optimization in federated learning and proposes the first federated conditional stochastic optimization algorithm (FCSG) with a conditional stochastic gradient estimator and a momentum-based algorithm (\\emph{i.e.}, FCSG-M). To match the lower bound complexity in the single-machine setting, we design an accelerated algorithm (Acc-FCSG-M) via the variance reduction to achieve the best sample and communication complexity. Compared with the existing optimization analysis for Meta-Learning in FL, federated conditional stochastic optimization considers the sample of tasks. Extensive experimental results on various tasks validate the efficiency of these algorithms",
    "checked": true,
    "id": "6feebec35cf95d3d5b94b7e5efb97818f1f6d1f3",
    "semantic_title": "federated conditional stochastic optimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=BXQtgwA2n0": {
    "title": "Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization",
    "volume": "poster",
    "abstract": "Offline reinforcement learning (RL) has received considerable attention in recent years due to its attractive capability of learning policies from offline datasets without environmental interactions. Despite some success in the single-agent setting, offline multi-agent RL (MARL) remains to be a challenge. The large joint state-action space and the coupled multi-agent behaviors pose extra complexities for offline policy optimization. Most existing offline MARL studies simply apply offline data-related regularizations on individual agents, without fully considering the multi-agent system at the global level. In this work, we present OMIGA, a new offline multi-agent RL algorithm with implicit global-to-local value regularization. OMIGA provides a principled framework to convert global-level value regularization into equivalent implicit local value regularizations and simultaneously enables in-sample learning, thus elegantly bridging multi-agent value decomposition and policy learning with offline regularizations. Based on comprehensive experiments on the offline multi-agent MuJoCo and StarCraft II micro-management tasks, we show that OMIGA achieves superior performance over the state-of-the-art offline MARL methods in almost all tasks",
    "checked": true,
    "id": "e6a54f56883e009f09259d98010981d8cf0b80f3",
    "semantic_title": "offline multi-agent reinforcement learning with implicit global-to-local value regularization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Murj6wcjRw": {
    "title": "An Efficient Dataset Condensation Plugin and Its Application to Continual Learning",
    "volume": "poster",
    "abstract": "Dataset condensation (DC) distills a large real-world dataset into a small synthetic dataset, with the goal of training a network from scratch on the latter that performs similarly to the former. State-of-the-art (SOTA) DC methods have achieved satisfactory results through techniques such as accuracy, gradient, training trajectory, or distribution matching. However, these works all perform matching in the high-dimension pixel spaces, ignoring that natural images are usually locally connected and have lower intrinsic dimensions, resulting in low condensation efficiency. In this work, we propose a simple-yet-efficient dataset condensation plugin that matches the raw and synthetic datasets in a low-dimensional manifold. Specifically, our plugin condenses raw images into two low-rank matrices instead of parameterized image matrices. Our plugin can be easily incorporated into existing DC methods, thereby containing richer raw dataset information at limited storage costs to improve the downstream applications' performance. We verify on multiple public datasets that when the proposed plugin is combined with SOTA DC methods, the performance of the network trained on synthetic data is significantly improved compared to traditional DC methods. Moreover, when applying the DC methods as a plugin to continual learning tasks, we observed that our approach effectively mitigates catastrophic forgetting of old tasks under limited memory buffer constraints and avoids the problem of raw data privacy leakage",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ghIBaprxsV": {
    "title": "Hierarchical Semi-Implicit Variational Inference with Application to Diffusion Model Acceleration",
    "volume": "poster",
    "abstract": "Semi-implicit variational inference (SIVI) has been introduced to expand the analytical variational families by defining expressive semi-implicit distributions in a hierarchical manner. However, the single-layer architecture commonly used in current SIVI methods can be insufficient when the target posterior has complicated structures. In this paper, we propose hierarchical semi-implicit variational inference, called HSIVI, which generalizes SIVI to allow more expressive multi-layer construction of semi-implicit distributions. By introducing auxiliary distributions that interpolate between a simple base distribution and the target distribution, the conditional layers can be trained by progressively matching these auxiliary distributions one layer after another. Moreover, given pre-trained score networks, HSIVI can be used to accelerate the sampling process of diffusion models with the score matching objective. We show that HSIVI significantly enhances the expressiveness of SIVI on several Bayesian inference problems with complicated target distributions. When used for diffusion model acceleration, we show that HSIVI can produce high quality samples comparable to or better than the existing fast diffusion model based samplers with a small number of function evaluations on various datasets",
    "checked": true,
    "id": "875f9a43708ae0b4d8a922774b1dcc6ed2c2f4b3",
    "semantic_title": "hierarchical semi-implicit variational inference with application to diffusion model acceleration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l6R4Go3noz": {
    "title": "Fine-Grained Visual Prompting",
    "volume": "poster",
    "abstract": "Vision-Language Models (VLMs), such as CLIP, have demonstrated impressive zero-shot transfer capabilities in image-level visual perception. However, these models have shown limited performance in instance-level tasks that demand precise localization and recognition. Previous works have suggested that incorporating visual prompts, such as colorful boxes or circles, can improve the ability of models to recognize objects of interest. Nonetheless, compared to language prompting, visual prompting designs are rarely explored. Existing approaches, which employ coarse visual cues such as colorful boxes or circles, often result in sub-optimal performance due to the inclusion of irrelevant and noisy pixels. In this paper, we carefully study the visual prompting designs by exploring more fine-grained markings, such as segmentation masks and their variations. In addition, we introduce a new zero-shot framework that leverages pixel-level annotations acquired from a generalist segmentation model for fine-grained visual prompting. Consequently, our investigation reveals that a straightforward application of blur outside the target mask, referred to as the Blur Reverse Mask, exhibits exceptional effectiveness. This proposed prompting strategy leverages the precise mask annotations to reduce focus on weakly related regions while retaining spatial coherence between the target and the surrounding background. Our **F**ine-**G**rained **V**isual **P**rompting (**FGVP**) demonstrates superior performance in zero-shot comprehension of referring expressions on the RefCOCO, RefCOCO+, and RefCOCOg benchmarks. It outperforms prior methods by an average margin of 3.0\\% to 4.6\\%, with a maximum improvement of 12.5\\% on the RefCOCO+ testA subset. The part detection experiments conducted on the PACO dataset further validate the preponderance of FGVP over existing visual prompting techniques. Code is available at https://github.com/ylingfeng/FGVP",
    "checked": true,
    "id": "a01a9c4a114fbf201540268f928ccf77bc3f9357",
    "semantic_title": "fine-grained visual prompting",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=0NuseeBuB4": {
    "title": "Gaussian Mixture Solvers for Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kR21XsZeAr": {
    "title": "Subclass-Dominant Label Noise: A Counterexample for the Success of Early Stopping",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FNn4zibGvw": {
    "title": "Hyperbolic VAE via Latent Gaussian Distributions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NNtsO5L27J": {
    "title": "Efficient Low-rank Backpropagation for Vision Transformer Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2dtU9ZbgSN": {
    "title": "Bilevel Coreset Selection in Continual Learning: A New Formulation and Algorithm",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uEJfW3OtUm": {
    "title": "Static and Sequential Malicious Attacks in the Context of Selective Forgetting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CQuRzAgjg9": {
    "title": "Online Clustering of Bandits with Misspecified User Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KD6MFeWSAd": {
    "title": "The probability flow ODE is provably fast",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=czwZnNf60r": {
    "title": "Exploring Diverse In-Context Configurations for Image Captioning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XcQzXeF7fX": {
    "title": "On Calibrating Diffusion Probabilistic Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SA2KrosYjY": {
    "title": "Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qPyvuFT0U9": {
    "title": "Statistical Insights into HSIC in High Dimensions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ev2XuqvJCy": {
    "title": "Spiking PointNet: Spiking Neural Networks for Point Clouds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=trHfuGQyyr": {
    "title": "Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X8dbFcAox2": {
    "title": "Self-Weighted Contrastive Learning among Multiple Views for Mitigating Representation Degeneration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SIE9N5nnHg": {
    "title": "Adversarial Robustness through Random Weight Sampling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wFuemocyHZ": {
    "title": "Restart Sampling for Improving Generative Processes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=exGOXqxR0L": {
    "title": "Geometry-Aware Adaptation for Pretrained Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XKP3mAsNHd": {
    "title": "Incentives in Private Collaborative Machine Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6oiux75UDj": {
    "title": "Bayesian Optimization with Cost-varying Variable Subsets",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cBS5CU96Jq": {
    "title": "Conditional Score Guidance for Text-Driven Image-to-Image Translation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lJDoPAjkCV": {
    "title": "Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pIXTMrBe7f": {
    "title": "What Makes Good Examples for Visual In-Context Learning?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e1oe8F2tjV": {
    "title": "Multinomial Logistic Regression: Asymptotic Normality on Null Covariates in High-Dimensions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=97E3YXvcFM": {
    "title": "Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sUFGPYS25Q": {
    "title": "D-Separation for Causal Self-Explanation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uOEeui0rL7": {
    "title": "Breadcrumbs to the Goal: Supervised Goal Selection from Human-in-the-Loop Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9v6gpFTfCM": {
    "title": "Unbiased Compression Saves Communication in Distributed Optimization: When and How Much?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OiivS2mqQf": {
    "title": "Augmentation-Aware Self-Supervision for Data-Efficient GAN Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V4hqq2NGTW": {
    "title": "Perceptual Kalman Filters: Online State Estimation under a Perfect Perceptual-Quality Constraint",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vnGcubtzR1": {
    "title": "On the Overlooked Pitfalls of Weight Decay and How to Mitigate Them: A Gradient-Norm Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IOSaJ7ukgf": {
    "title": "DSR: Dynamical Surface Representation as Implicit Neural Networks for Protein",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0tnhFpyWjb": {
    "title": "Two-Stage Predict+Optimize for MILPs with Unknown Parameters in Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t7ZowrDWVw": {
    "title": "Achieving Cross Modal Generalization with Multimodal Unified Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zsOOqjaj2z": {
    "title": "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BYywOFbRFz": {
    "title": "Waypoint Transformer: Reinforcement Learning via Supervised Learning with Intermediate Targets",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H4GsteoL0M": {
    "title": "On the Overlooked Structure of Stochastic Gradients",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mVTyeQIiE4": {
    "title": "Hierarchical Gaussian Mixture based Task Generative Model for Robust Meta-Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iv2sTQtbst": {
    "title": "Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bUgqyyNo8j": {
    "title": "Model-Based Reparameterization Policy Gradient Methods: Theory and Practical Algorithms",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4iV26fZPUD": {
    "title": "Train 'n Trade: Foundations of Parameter Markets",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4iMpwAlza1": {
    "title": "Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ljgM3vNqfQ": {
    "title": "Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8hKCNVqrlf": {
    "title": "A Riemannian Exponential Augmented Lagrangian Method for Computing the Projection Robust Wasserstein Distance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wjp1AYB8lH": {
    "title": "Large Language Models as Commonsense Knowledge for Large-Scale Task Planning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tdyLryDebq": {
    "title": "FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GEQZ52oqxa": {
    "title": "$L_2$-Uniform Stability of Randomized Learning Algorithms: Sharper Generalization Bounds and Confidence Boosting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RW7rZ8Y3Bp": {
    "title": "Federated Spectral Clustering via Secure Similarity Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EI6BHFKA5p": {
    "title": "Neural Graph Generation from Graph Statistics",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=090ORrOAPL": {
    "title": "On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ymBG2xs9Zf": {
    "title": "Model-Based Control with Sparse Neural Dynamics",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mlo2kM11ZB": {
    "title": "Birder: Communication-Efficient 1-bit Adaptive Optimizer for Practical Distributed DNN Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M8CYKLHoEN": {
    "title": "Fast Rank-1 Lattice Targeted Sampling for Black-box Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VCOZaczCHg": {
    "title": "Mixed-Initiative Multiagent Apprenticeship Learning for Human Training of Robot Teams",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A253n2EXCd": {
    "title": "Tuning Multi-mode Token-level Prompt Alignment across Modalities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VhbV56AJNt": {
    "title": "Variance-Reduced Gradient Estimation via Noise-Reuse in Online Evolution Strategies",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xazhn0JoNx": {
    "title": "Making Scalable Meta Learning Practical",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O1lYncfVOO": {
    "title": "S-CLIP: Semi-supervised Vision-Language Learning using Few Specialist Captions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oFaLc6fHSt": {
    "title": "Gradient Informed Proximal Policy Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YwgA3avHrP": {
    "title": "Text Promptable Surgical Instrument Segmentation with Vision-Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q8mH2d6uw2": {
    "title": "Deep Contract Design via Discontinuous Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6ldTxwhgtP": {
    "title": "Towards A Richer 2D Understanding of Hands at Scale",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0eRDQQK2TW": {
    "title": "A Finite-Particle Convergence Rate for Stein Variational Gradient Descent",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wff6DWFY2W": {
    "title": "Towards Semi-Structured Automatic ICD Coding via Tree-based Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vlDbqzwczj": {
    "title": "A Novel Approach for Effective Multi-View Clustering with Information-Theoretic Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1M8nDkUU9b": {
    "title": "Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous Graph Diffusion Functionals",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ds8iLujo3p": {
    "title": "Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VbYdaK8ek0": {
    "title": "Efficient Adaptation of Large Vision Transformer via Adapter Re-Composing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sOQBHlCmzp": {
    "title": "Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BmIW6U0rz8": {
    "title": "Koopman Kernel Regression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2RQhgx1WLA": {
    "title": "DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mIm0hsUUt1": {
    "title": "Efficient Testable Learning of Halfspaces with Adversarial Label Noise",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ddKCg3OhGw": {
    "title": "Functional Equivalence and Path Connectivity of Reducible Hyperbolic Tangent Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sqqASmpA2R": {
    "title": "Stable and low-precision training for large-scale vision-language models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PhFVF0gwid": {
    "title": "Provable Guarantees for Generative Behavior Cloning: Bridging Low-Level Stability and High-Level Behavior",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z2he2Y0MoH": {
    "title": "Wide Neural Networks as Gaussian Processes: Lessons from Deep Equilibrium Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qs4swxtIAQ": {
    "title": "TabMT: Generating tabular data with masked transformers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IWWWulAX7g": {
    "title": "Fine-grained Late-interaction Multi-modal Retrieval for Retrieval Augmented Visual Question Answering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TwLHB8sKme": {
    "title": "Tools for Verifying Neural Models' Training Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZBzYWP2Gpl": {
    "title": "AdANNS: A Framework for Adaptive Semantic Search",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C4rRqkXFyC": {
    "title": "Clustering the Sketch: Dynamic Compression for Embedding Tables",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5SIz31OGFV": {
    "title": "Inconsistency, Instability, and Generalization Gap of Deep Neural Network Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ErAP8kF4tG": {
    "title": "Logarithmic Bayes Regret Bounds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xcGhx9FdxM": {
    "title": "Adversarial Resilience in Sequential Prediction via Abstention",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LCwToX315b": {
    "title": "Hardness of Low Rank Approximation of Entrywise Transformed Matrix Products",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h3kuB4z2G9": {
    "title": "Front-door Adjustment Beyond Markov Equivalence with Limited Graph Knowledge",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HtMXRGbUMt": {
    "title": "Understanding and Mitigating Copying in Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sp0yOBfelp": {
    "title": "On Generalization Bounds for Projective Clustering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2izFpGERjU": {
    "title": "A Combinatorial Algorithm for Approximating the Optimal Transport in the Parallel and MPC Settings",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZQzm0Z47jz": {
    "title": "Rethinking the Role of Token Retrieval in Multi-Vector Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v6YzxwJlQn": {
    "title": "Deep Equilibrium Based Neural Operators for Steady-State PDEs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OjlZqQzw51": {
    "title": "Percentile Criterion Optimization in Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5aeyKAZr0L": {
    "title": "Approximately Equivariant Graph Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e8RZwixcE4": {
    "title": "Using Imperfect Surrogates for Downstream Inference: Design-based Supervised Learning for Social Science Applications of Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6SRE9GZ9s6": {
    "title": "Preference-grounded Token-level Guidance for Language Model Fine-tuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ihlT8yvQ2I": {
    "title": "GNNEvaluator: Evaluating GNN Performance On Unseen Graphs Without Labels",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g8bjq0qxOl": {
    "title": "Where Did I Come From? Origin Attribution of AI-Generated Images",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ydxnan4P2G": {
    "title": "Your representations are in the network: composable and parallel adaptation for large scale models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KXbAgvLi2l": {
    "title": "Faster Relative Entropy Coding with Greedy Rejection Coding",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZBB8EFO7ma": {
    "title": "Aiming towards the minimizers: fast convergence of SGD for overparametrized problems",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8XRMbNAP6Z": {
    "title": "Near-Optimal $k$-Clustering in the Sliding Window Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EcmqyXekuP": {
    "title": "Mobilizing Personalized Federated Learning in Infrastructure-Less and Heterogeneous Environments via Random Walk Stochastic ADMM",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cOQH8YO255": {
    "title": "The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UPo8vlZ0wQ": {
    "title": "Fast Asymptotically Optimal Algorithms for Non-Parametric Stochastic Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7RMGI4slcb": {
    "title": "Order Matters in the Presence of Dataset Imbalance for Multilingual Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VPrir0p5b6": {
    "title": "Continuous-Time Functional Diffusion Processes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F1mv2L7Rkb": {
    "title": "Invariant Anomaly Detection under Distribution Shifts: A Causal Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w7LxAZfDfv": {
    "title": "InfoCD: A Contrastive Chamfer Distance Loss for Point Cloud Completion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4zWEyYGGfI": {
    "title": "A Unified Detection Framework for Inference-Stage Backdoor Defenses",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CruxS0C0LS": {
    "title": "Finding Local Minima Efficiently in Decentralized Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oef30oScVB": {
    "title": "Demystifying Structural Disparity in Graph Neural Networks: Can One Size Fit All?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Nh5dp6Uuvx": {
    "title": "Improving neural network representations using human similarity judgments",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OwpaO4w6K7": {
    "title": "Jigsaw: Learning to Assemble Multiple Fractured Objects",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sqTcCXkG4P": {
    "title": "Sparsity-Preserving Differentially Private Training of Large Embedding Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BRpi8YAfac": {
    "title": "Passive learning of active causal strategies in agents and language models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kLIieSS2P3": {
    "title": "On the choice of Perception Loss Function for Learned Video Compression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=L74NTrzH1O": {
    "title": "PrObeD: Proactive Object Detection Wrapper",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CDTifMbUNc": {
    "title": "Refined Mechanism Design for Approximately Structured Priors via Active Regression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QG4nJBNEar": {
    "title": "CAT-Walk: Inductive Hypergraph Learning via Set Walks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pLOWV1UGF6": {
    "title": "Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lds9D17HRd": {
    "title": "A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IyWpP2e0bF": {
    "title": "Block Coordinate Plug-and-Play Methods for Blind Inverse Problems",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EcReRm7q9p": {
    "title": "Optimal Treatment Allocation for Efficient Policy Evaluation in Sequential Decision Making",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C6fvJ2RfsL": {
    "title": "Self-Consistent Velocity Matching of Probability Flows",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LMU2RNwdh2": {
    "title": "An Inverse Scaling Law for CLIP Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Cxn1FpnNvG": {
    "title": "Neural Circuits for Fast Poisson Compressed Sensing in the Olfactory Bulb",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hHUZ5V9XFu": {
    "title": "Equivariant Flow Matching with Hybrid Probability Transport for 3D Molecule Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6EqUpqMnwl": {
    "title": "Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4yXnnCK3r9": {
    "title": "On Proper Learnability between Average- and Worst-case Robustness",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JK2oPrP8B3": {
    "title": "Global Identifiability of $\\ell_1$-based Dictionary Learning via Matrix Volume Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oKqaWlEfjY": {
    "title": "Worst-case Performance of Popular Approximate Nearest Neighbor Search Implementations: Guarantees and Limitations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wImYhdu4VF": {
    "title": "Learning a 1-layer conditional generative model in total variation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=25vRtG56YH": {
    "title": "Beyond Normal: On the Evaluation of Mutual Information Estimators",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GCY9C43A4L": {
    "title": "TaskMet: Task-driven Metric Learning for Model Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LZ4WgwmrUJ": {
    "title": "High-dimensional Contextual Bandit Problem without Sparsity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XddoUFpjkP": {
    "title": "Bayesian Learning via Q-Exponential Process",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qSCziWQBPD": {
    "title": "The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness in ReLU Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7962B4nXX7": {
    "title": "Learning Energy-based Model via Dual-MCMC Teaching",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q6X038vKgU": {
    "title": "Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nZ0jnXizyR": {
    "title": "Uncertainty Quantification via Neural Posterior Principal Components",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ody3RBUuJS": {
    "title": "FedGCN: Convergence-Communication Tradeoffs in Federated Training of Graph Convolutional Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SHBksHKutP": {
    "title": "Contextual Stochastic Bilevel Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qcQhBli5Ho": {
    "title": "Multi-Head Adapter Routing for Cross-Task Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4SkPTD6XNP": {
    "title": "Cal-DETR: Calibrated Detection Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fUZUoSLXw3": {
    "title": "Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RJpAz15D0S": {
    "title": "Cheaply Estimating Inference Efficiency Metrics for Autoregressive Transformer Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qqcIM8NiiB": {
    "title": "PHOTOSWAP: Personalized Subject Swapping in Images",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cANkPsVtsw": {
    "title": "Characterization and Learning of Causal Graphs with Small Conditioning Sets",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=znudaK78u8": {
    "title": "Active Learning for Semantic Segmentation with Multi-class Label Query",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dTj5tH94xv": {
    "title": "Does a sparse ReLU network training problem always admit an optimum ?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mumEBl0arj": {
    "title": "Thinker: Learning to Plan and Act",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=URAZeoIC1q": {
    "title": "Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ISRyILhAyS": {
    "title": "CD-GraB: Coordinating Distributed Example Orders for Provably Accelerated Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rG1M3kOVba": {
    "title": "FLuID: Mitigating Stragglers in Federated Learning using Invariant Dropout",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cAhJF87GN0": {
    "title": "Explainable Brain Age Prediction using coVariance Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DIBcdjWV7k": {
    "title": "Don't just prune by magnitude! Your mask topology is a secret weapon",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n6ztJ3Lrdj": {
    "title": "Learning with Explanation Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XqcXf7ix5q": {
    "title": "Locality-Aware Generalizable Implicit Neural Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tUyW68cRqr": {
    "title": "Language Semantic Graph Guided Data-Efficient Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lp9GR2t3hn": {
    "title": "ProtoDiff: Learning to Learn Prototypical Networks by Task-Guided Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xgY4QcOiEZ": {
    "title": "Learning a Neuron by a Shallow ReLU Network: Dynamics and Implicit Bias for Correlated Inputs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=noMktb4ait": {
    "title": "Joint Feature and Differentiable $ k $-NN Graph Learning using Dirichlet Energy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3xSwxlB0fd": {
    "title": "Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games with Bandit Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Enzew8XujO": {
    "title": "Transfer learning for atomistic simulations using GNNs and kernel mean embeddings",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1A4ZqTmnye": {
    "title": "Task-aware Distributed Source Coding under Dynamic Bandwidth",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OlSTwlz96r": {
    "title": "Federated Multi-Objective Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PmqBJ02V1p": {
    "title": "Adaptive Principal Component Regression with Applications to Panel Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JIKM2vS8XU": {
    "title": "DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=snY3FOnlQi": {
    "title": "AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FgakGFpll1": {
    "title": "A Metadata-Driven Approach to Understand Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jRL6ErxMVB": {
    "title": "Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MirclT6zpv": {
    "title": "Delayed Algorithms for Distributed Stochastic Weakly Convex Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RiSMijlsLT": {
    "title": "SimMMDG: A Simple and Effective Framework for Multi-modal Domain Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=orh4e0AO9R": {
    "title": "Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d0VItRE2ZH": {
    "title": "VRA: Variational Rectified Activation for Out-of-distribution Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PYSfn5xXEe": {
    "title": "ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BI031mw7iS": {
    "title": "Flow: Per-instance Personalized Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dFSeZm6dTC": {
    "title": "CP-SLAM: Collaborative Neural Point-based SLAM System",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KUBFYAPdqN": {
    "title": "Trading-off price for data quality to achieve fair online allocation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=znW5jNIOED": {
    "title": "Optimizing over trained GNNs via symmetry breaking",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dmD63sv0TZ": {
    "title": "Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal Discovery",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EqnZqrbFrc": {
    "title": "Sample Complexity of Goal-Conditioned Hierarchical Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HrL1oblm1a": {
    "title": "Assessor360: Multi-sequence Network for Blind Omnidirectional Image Quality Assessment",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LCnjG1IEfm": {
    "title": "Normalization-Equivariant Neural Networks with Application to Image Denoising",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=neu9JlNweE": {
    "title": "Post-processing Private Synthetic Data for Improving Utility on Selected Measures",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tz4ECtAu8e": {
    "title": "GEX: A flexible method for approximating influence via Geometric Ensemble",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qxF8Pge6vM": {
    "title": "Reinforcement Learning with Simple Sequence Priors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eR7PrfJe9o": {
    "title": "Classification of Heavy-tailed Features in High Dimensions: a Superstatistical Approach",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gwvwbsnTps": {
    "title": "Composable Coresets for Determinant Maximization: Greedy is Almost Optimal",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qHrZszJSXj": {
    "title": "Don't be so Monotone: Relaxing Stochastic Line Search in Over-Parameterized Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4ZaPpVDjGQ": {
    "title": "Breaking the Communication-Privacy-Accuracy Tradeoff with $f$-Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Tt6DrRCgJV": {
    "title": "GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iATY9W5Xw7": {
    "title": "CAST: Cross-Attention in Space and Time for Video Action Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fj0ZeRtUTU": {
    "title": "Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dDk6URGRXP": {
    "title": "Online Inventory Problems: Beyond the i.i.d. Setting with Online Convex Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HWGWeaN76q": {
    "title": "On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $\\epsilon$-Greedy Exploration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VtkGvGcGe3": {
    "title": "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B01uiWhjpc": {
    "title": "Parameterizing Context: Unleashing the Power of Parameter-Efficient Fine-Tuning and In-Context Tuning for Continual Table Semantic Parsing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nXNsqB4Yr1": {
    "title": "Aggregating Capacity in FL through Successive Layer Training for Computationally-Constrained Devices",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ou1VRZ4j4y": {
    "title": "Learning Multi-agent Behaviors from Distributed and Streaming Demonstrations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kChEBODIx9": {
    "title": "Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WK8LQzzHwW": {
    "title": "Unsupervised Anomaly Detection with Rejection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aZ9hvpnp0k": {
    "title": "Anchor Data Augmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d85pPNBHLt": {
    "title": "Meta-AdaM: An Meta-Learned Adaptive Optimizer with Momentum for Few-Shot Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Gh67ZZ6zkS": {
    "title": "PreDiff: Precipitation Nowcasting with Latent Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bw82hwg5Q3": {
    "title": "Self-Evaluation Guided Beam Search for Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HNd4qTJxkW": {
    "title": "A Heat Diffusion Perspective on Geodesic Preserving Dimensionality Reduction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bv9mmH0LGF": {
    "title": "Global Structure-Aware Diffusion Process for Low-light Image Enhancement",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=28RTu9MOT6": {
    "title": "Improving Graph Matching with Positional Reconstruction Encoder-Decoder Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1FVmMlifl7": {
    "title": "How a Student becomes a Teacher: learning and forgetting through Spectral methods",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gySmwdmVDF": {
    "title": "Query-based Temporal Fusion with Explicit Motion for 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TNAGFUcSP7": {
    "title": "Learning Rate Free Bayesian Inference in Constrained Domains",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sQBGVw5qH9": {
    "title": "Cocktail: Mixing Multi-Modality Control for Text-Conditional Image Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZULq9QV8rH": {
    "title": "Self-Supervised Learning with Lie Symmetries for Partial Differential Equations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4RoD1o7yq6": {
    "title": "Binary Classification with Confidence Difference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S6ajVZy6FA": {
    "title": "A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IgDa5Ynm9l": {
    "title": "Efficient Model-Free Exploration in Low-Rank MDPs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=54z8M7NTbJ": {
    "title": "GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4KZhZJSPYU": {
    "title": "When Does Confidence-Based Cascade Deferral Suffice?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sodl2c3aTM": {
    "title": "Dynamically Masked Discriminator for GANs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lk6KDG6qI7": {
    "title": "A Theoretical Analysis of the Test Error of Finite-Rank Kernel Ridge Regression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LSYQB4CwD3": {
    "title": "Three Towers: Flexible Contrastive Learning with Pretrained Image Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ByDy2mlkig": {
    "title": "On the explainable properties of 1-Lipschitz Neural Networks: An Optimal Transport Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ePkLqJh5kw": {
    "title": "Combating Bilateral Edge Noise for Robust Link Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HYo2Ao3hP8": {
    "title": "SLIBO-Net: Floorplan Reconstruction via Slicing Box Representation with Local Geometry Regularization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6cc69ArD3O": {
    "title": "Globally injective and bijective neural operators",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IQRc3FrYOG": {
    "title": "Mutual-Information Regularized Multi-Agent Policy Iteration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9iafshF7s3": {
    "title": "Rewrite Caption Semantics: Bridging Semantic Gaps for Language-Supervised Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xFtuNq23D5": {
    "title": "Boosting Spectral Clustering on Incomplete Data via Kernel Correction and Affinity Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5XshcizH9w": {
    "title": "Understanding Contrastive Learning via Distributionally Robust Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UFW67uduJd": {
    "title": "MEMTO: Memory-guided Transformer for Multivariate Time Series Anomaly Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vfp8sDST4g": {
    "title": "Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=clCELP8zFb": {
    "title": "Convergent Bregman Plug-and-Play Image Restoration for Poisson Inverse Problems",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eoDNaH3pfB": {
    "title": "Black-Box Differential Privacy for Interactive ML",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IGTbT9P1ti": {
    "title": "Connecting Multi-modal Contrastive Representations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WBq6Q4ml04": {
    "title": "Top-Ambiguity Samples Matter: Understanding Why Deep Ensemble Works in Selective Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tF7W8ai8J3": {
    "title": "Federated Compositional Deep AUC Maximization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DP2lioYIYl": {
    "title": "A Theory of Unsupervised Translation Motivated by Understanding Animal Communication",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7b4oobeB4w": {
    "title": "Bias in Evaluation Processes: An Optimization-Based Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LCHmP68Gtj": {
    "title": "SNAP: Self-Supervised Neural Maps for Visual Positioning and Semantic Understanding",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TW99HrZCJU": {
    "title": "Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DDmH3H78iJ": {
    "title": "Discrete-Smoothness in Online Algorithms with Predictions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=csdEeUn0ve": {
    "title": "Efficient RL with Impaired Observability: Learning to Act with Delayed and Missing State Observations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dKeWh6EzBB": {
    "title": "SwiFT: Swin 4D fMRI Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jX49iKr6vb": {
    "title": "Beyond Deep Ensembles: A Large-Scale Evaluation of Bayesian Deep Learning under Distribution Shift",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eIFZtkshgH": {
    "title": "AD-PT: Autonomous Driving Pre-Training with Large-scale Point Cloud Dataset",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wLiMhVJ7fx": {
    "title": "Calibrating Neural Simulation-Based Inference with Differentiable Coverage Probability",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=chlTA9Cegc": {
    "title": "A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vUXNNLatFv": {
    "title": "A Unified Framework for Uniform Signal Recovery in Nonlinear Generative Compressed Sensing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uqkUguNu40": {
    "title": "Fused Gromov-Wasserstein Graph Mixup for Graph-level Classifications",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l61Kp1zBwC": {
    "title": "Relative Entropic Optimal Transport: a (Prior-aware) Matching Perspective to (Unbalanced) Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1kZx7JiuA2": {
    "title": "Implicit Transfer Operator Learning: Multiple Time-Resolution Models for Molecular Dynamics",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ywrPcBEXdC": {
    "title": "Revisiting Adversarial Robustness Distillation from the Perspective of Robust Fairness",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JMrIeKjTAe": {
    "title": "Generalised f-Mean Aggregation for Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5ZMBiS1uMq": {
    "title": "Self-Adaptive Motion Tracking against On-body Displacement of Flexible Sensors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6XC5iKqRVm": {
    "title": "DELTA: Diverse Client Sampling for Fasting Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RTRS3ZTsSj": {
    "title": "ANPL: Towards Natural Programming with Interactive Decomposition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ffFcRPpnWx": {
    "title": "RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KFj0Q1EXvU": {
    "title": "Multi-Step Generalized Policy Improvement by Leveraging Approximate Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YmEDnMynuO": {
    "title": "GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PXsqbAjpQd": {
    "title": "SHOT: Suppressing the Hessian along the Optimization Trajectory for Gradient-Based Meta-Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RNVwm4BzXO": {
    "title": "Towards Consistent Video Editing with Text-to-Image Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JzQ7QClAdF": {
    "title": "Opening the Vocabulary of Egocentric Actions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=haniyY7zm1": {
    "title": "Exact Generalization Guarantees for (Regularized) Wasserstein Distributionally Robust Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jh3UNSQK0l": {
    "title": "Finite-Time Analysis of Single-Timescale Actor-Critic",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LhVJdq4cZm": {
    "title": "AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Psnph85KYc": {
    "title": "Interpretable Graph Networks Formulate Universal Algebra Conjectures",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fbpTObq6TW": {
    "title": "A fast heuristic to optimize time-space tradeoff for large models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4anryczeED": {
    "title": "Likelihood Ratio Confidence Sets for Sequential Decision Making",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M7r2CO4tJC": {
    "title": "Geometric Algebra Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WxnrX42rnS": {
    "title": "STORM: Efficient Stochastic Transformer based World Models for Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dOanKg3jKS": {
    "title": "From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vx1JadlOIt": {
    "title": "VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JtIqG47DAQ": {
    "title": "Penalising the biases in norm regularisation enforces sparsity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C8pvL8Qbfa": {
    "title": "Conservative Offline Policy Adaptation in Multi-Agent Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s1jQ91yFAb": {
    "title": "On Certified Generalization in Structured Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QwQ5HhhSNo": {
    "title": "Is Distance Matrix Enough for Geometric Deep Learning?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j5AoleAIru": {
    "title": "What You See is What You Read? Improving Text-Image Alignment Evaluation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p8gTWkFIvx": {
    "title": "Modality-Independent Teachers Meet Weakly-Supervised Audio-Visual Event Parser",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kMmAYbT0VL": {
    "title": "Point Cloud Completion with Pretrained Text-to-Image Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tcotyjon2a": {
    "title": "CQM: Curriculum Reinforcement Learning with a Quantized World Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bt7pQ7o7zG": {
    "title": "Chatting Makes Perfect: Chat-based Image Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=35dOU92OJM": {
    "title": "Idempotent Learned Image Compression with Right-Inverse",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oO1IreC6Sd": {
    "title": "Neural Fields with Hard Constraints of Arbitrary Differential Order",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mgy6sgslPY": {
    "title": "Optimize Planning Heuristics to Rank, not to Estimate Cost-to-Goal",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OJ0c6um1An": {
    "title": "LLMScore: Unveiling the Power of Large Language Models in Text-to-Image Synthesis Evaluation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wYKU1C77sa": {
    "title": "Language-driven Scene Synthesis using Multi-conditional Diffusion Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T3SstRu5fq": {
    "title": "PUCA: Patch-Unshuffle and Channel Attention for Enhanced Self-Supervised Image Denoising",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wkIBfnGPTA": {
    "title": "VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VUvLSnMZdX": {
    "title": "Score-based Data Assimilation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xBqjoG0NxM": {
    "title": "SODA: Robust Training of Test-Time Data Adaptors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xNyR7DXUzJ": {
    "title": "RL-based Stateful Neural Adaptive Sampling and Denoising for Real-Time Path Tracing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hoyL1Ypjoo": {
    "title": "Macro Placement by Wire-Mask-Guided Black-Box Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NU2kGsA4TT": {
    "title": "SceneScape: Text-Driven Consistent Scene Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bJJY9TFfe0": {
    "title": "Deep Optimal Transport: A Practical Algorithm for Photo-realistic Image Restoration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fKQEmHoLb6": {
    "title": "Learning Energy-Based Prior Model with Diffusion-Amortized MCMC",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2jUKhUrBxP": {
    "title": "Memory-Efficient Fine-Tuning of Compressed Large Language Models via sub-4-bit Integer Quantization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lvvaNwnP6M": {
    "title": "H-InDex: Visual Reinforcement Learning with Hand-Informed Representations for Dexterous Manipulation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UkAGqeWTuL": {
    "title": "Inner-Outer Aware Reconstruction Model for Monocular 3D Scene Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ylPX5D7It7": {
    "title": "Understanding How Consistency Works in Federated Learning via Stage-wise Relaxed Initialization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SxVHyYavHy": {
    "title": "DeepSimHO: Stable Pose Estimation for Hand-Object Interaction via Physics Simulation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DPeBX79eNz": {
    "title": "Transfer Learning with Affine Model Transformation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E2zoGTkTbW": {
    "title": "Reward Imputation with Sketching for Contextual Batched Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fWLf8DV0fI": {
    "title": "Rethinking Tokenizer and Decoder in Masked Graph Modeling for Molecules",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ECRgBK6sk1": {
    "title": "Prototype-based Aleatoric Uncertainty Quantification for Cross-modal Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6vtZIoxZoJ": {
    "title": "PUe: Biased Positive-Unlabeled Learning Enhancement by Causal Inference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U1Kr8FTyhQ": {
    "title": "Topological RANSAC for instance verification and retrieval without fine-tuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WpuBEtrn0t": {
    "title": "Regularizing Neural Networks with Meta-Learning Generative Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0vdEHDwamk": {
    "title": "Lovász Principle for Unsupervised Graph Representation Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e1l4ZYprQH": {
    "title": "MathNAS: If Blocks Have a Role in Mathematical Architecture Design",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WRtlsxA5h7": {
    "title": "Orthogonal Non-negative Tensor Factorization based Multi-view Clustering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NLFqlDeuzt": {
    "title": "Understanding the Limitations of Deep Models for Molecular property prediction: Insights and Solutions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zQOYGDc9pu": {
    "title": "Optimized Covariance Design for AB Test on Social Network under Interference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DOdaV0Hqdy": {
    "title": "Off-Policy Evaluation for Human Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ixcsBZw5pl": {
    "title": "Non-adversarial training of Neural SDEs with signature kernel scores",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d86B6Mdweq": {
    "title": "3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IjZa2fQ8tL": {
    "title": "StableFDG: Style and Attention Based Learning for Federated Domain Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HvhagNdf5z": {
    "title": "Synthetic-to-Real Pose Estimation with Geometric Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QlbZabgMdK": {
    "title": "Goal-conditioned Offline Planning from Curious Exploration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A4zzxu82a7": {
    "title": "Koopa: Learning Non-stationary Time Series Dynamics with Koopman Predictors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VPTZVVP4tm": {
    "title": "LogSpecT: Feasible Graph Learning Model from Stationary Signals with Recovery Guarantees",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K9xHDD6mic": {
    "title": "Graph Mixture of Experts: Learning on Large-Scale Graphs with Explicit Diversity Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GcEIvidYSw": {
    "title": "Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bXvmnpCMmq": {
    "title": "Kissing to Find a Match: Efficient Low-Rank Permutation Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yHdTscY6Ci": {
    "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x816mCbWpR": {
    "title": "Recasting Continual Learning as Sequence Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=992vogTP1L": {
    "title": "Generalization bounds for neural ordinary differential equations and deep residual networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vwr4bHHsRT": {
    "title": "Optimal Regret Is Achievable with Bounded Approximate Inference Error: An Enhanced Bayesian Upper Confidence Bound Framework",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lwg3ohkFRv": {
    "title": "CARE: Modeling Interacting Dynamics Under Temporal Environmental Variation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FCwfZj1bQl": {
    "title": "Anytime-Competitive Reinforcement Learning with Policy Prior",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wiv21EJ0Vd": {
    "title": "Zero-shot Visual Relation Detection via Composite Visual Cues from Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KQyXyIAfK8": {
    "title": "SOC: Semantic-Assisted Object Cluster for Referring Video Object Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZViPzk1sUI": {
    "title": "Structured Semidefinite Programming for Recovering Structured Preconditioners",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cGdGh3Mp2W": {
    "title": "NeuroGF: A Neural Representation for Fast Geodesic Distance and Path Queries",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vbm5UCaYeh": {
    "title": "Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed Rewards",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZRBGwpeewz": {
    "title": "Revisiting Area Convexity: Faster Box-Simplex Games and Spectrahedral Generalizations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tkenkPYkxj": {
    "title": "Exponential Lower Bounds for Fictitious Play in Potential Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8Ba7VJ7xiM": {
    "title": "Analyzing Generalization of Neural Networks through Loss Path Kernels",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YFW6MVGVTn": {
    "title": "NICE: NoIse-modulated Consistency rEgularization for Data-Efficient GANs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gJHAT79cZU": {
    "title": "NeRF Revisited: Fixing Quadrature Instability in Volume Rendering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FCwF5431IY": {
    "title": "Directed Cyclic Graph for Causal Discovery from Multivariate Functional Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KMeFZopsqP": {
    "title": "First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fpElyckKkd": {
    "title": "Data-Informed Geometric Space Selection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ydKWoqWZ3t": {
    "title": "PAC-Bayesian Spectrally-Normalized Bounds for Adversarially Robust Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rih3hsSWx8": {
    "title": "Transformed Low-Rank Parameterization Can Help Robust Generalization for Tensor Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=caUhYUVsLl": {
    "title": "Augmentation-free Dense Contrastive Distillation for Efficient Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1MUxtSBUox": {
    "title": "Budgeting Counterfactual for Offline RL",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JtF0ugNMv2": {
    "title": "From Distribution Learning in Training to Gradient Search in Testing for Combinatorial Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KBXcDAaZE7": {
    "title": "Towards Free Data Selection with General-Purpose Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=clJTNssgn6": {
    "title": "Hierarchical Vector Quantized Transformer for Multi-class Unsupervised Anomaly Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JwNXeBdkeo": {
    "title": "Provably (More) Sample-Efficient Offline RL with Options",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jUdZCcoOu3": {
    "title": "RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CYCzfXn6cZ": {
    "title": "Survival Permanental Processes for Survival Analysis with Time-Varying Covariates",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B5XwENgy0T": {
    "title": "Communication-Efficient Federated Bilevel Optimization with Global and Local Lower Level Problems",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R6qMmdl4qP": {
    "title": "Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j4QVhftpYM": {
    "title": "Resolving the Tug-of-War: A Separation of Communication and Learning in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PjBEUTVzoe": {
    "title": "Implicit Bias of (Stochastic) Gradient Descent for Rank-1 Linear Neural Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sq0m11cUMV": {
    "title": "Belief Projection-Based Reinforcement Learning for Environments with Delayed Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tFsxtqGmkn": {
    "title": "Maximum State Entropy Exploration using Predecessor and Successor Representations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yiehppUCO2": {
    "title": "E2PNet: Event to Point Cloud Registration with Spatio-Temporal Representation Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MYfqIVcQrp": {
    "title": "Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nMH5cUaSj8": {
    "title": "GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1ZvEtnrHS1": {
    "title": "Convolutional State Space Models for Long-Range Spatiotemporal Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AT6NaLPwy0": {
    "title": "A Reduction-based Framework for Sequential Decision Making with Delayed Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xyj46OxEhK": {
    "title": "Look Ma, No Hands! Agent-Environment Factorization of Egocentric Videos",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PAYXfIUKWY": {
    "title": "Effective Robustness against Natural Distribution Shifts for Models with Different Training Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gO60SSGOMy": {
    "title": "Content-based Unrestricted Adversarial Attack",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wwkQUiaKbo": {
    "title": "Adapting Fairness Interventions to Missing Values",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A6JDQDv7Nt": {
    "title": "Keep Various Trajectories: Promoting Exploration of Ensemble Policies in Continuous Control",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IYe8j7Gy8f": {
    "title": "Intriguing Properties of Quantization at Scale",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xxllzjt6T5": {
    "title": "ReSync: Riemannian Subgradient-based Robust Rotation Synchronization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3ZrGmenVM2": {
    "title": "Deep learning with kernels through RKHM and the Perron-Frobenius operator",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cQdc9Dyk4i": {
    "title": "GraphMP: Graph Neural Network-based Motion Planning with Efficient Graph Search",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xq1QvViDdW": {
    "title": "Beyond Unimodal: Generalising Neural Processes for Multimodal Uncertainty Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7irm2VJARb": {
    "title": "Structure from Duplicates: Neural Inverse Graphics from a Pile of Objects",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2FMJtNDLeE": {
    "title": "A General Theory of Correct, Incorrect, and Extrinsic Equivariance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oi45JlpSOT": {
    "title": "Multi-Fidelity Multi-Armed Bandits Revisited",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gThGBHhqcU": {
    "title": "Rethinking Conditional Diffusion Sampling with Progressive Guidance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JCN9YsZiwB": {
    "title": "Deep Non-line-of-sight Imaging from Under-scanning Measurements",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y6IGTNMdLT": {
    "title": "Model Shapley: Equitable Model Valuation with Black-box Access",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W6U2xSbiE1": {
    "title": "Black-box Backdoor Defense via Zero-shot Image Purification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cMUBkkTrMo": {
    "title": "Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5yedZXV7wt": {
    "title": "Many-body Approximation for Non-negative Tensors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mSNfjOcDUv": {
    "title": "InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural Language Understanding",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QIBpzaDCAv": {
    "title": "Lossy Image Compression with Conditional Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rLpLjCBW4J": {
    "title": "Preconditioning Matters: Fast Global Convergence of Non-convex Matrix Factorization via Scaled Gradient Descent",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7blSUMwe7R": {
    "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d1wjMBYbP1": {
    "title": "Zero-Shot Anomaly Detection via Batch Normalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mookk2nLO9": {
    "title": "Efficient Sampling of Stochastic Differential Equations with Positive Semi-Definite Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QQidjdmyPp": {
    "title": "Fractal Landscapes in Policy Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0Iw2dLh8uq": {
    "title": "Multi-Agent Meta-Reinforcement Learning: Sharper Convergence Rates with Task Similarity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GqXbfVmEPW": {
    "title": "Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ubgdInLSF9": {
    "title": "SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two Seconds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NRnm5xO8Hz": {
    "title": "Geometric Analysis of Matrix Sensing over Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7DZAVpOoAK": {
    "title": "Defending against Data-Free Model Extraction by Distributionally Robust Defensive Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LelK6Mfoey": {
    "title": "On Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8niGwlkLAX": {
    "title": "Sparse Deep Learning for Time Series Data: Theory and Applications",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e1WgjvFGWp": {
    "title": "Large Language Models of Code Fail at Completing Code with Potential Bugs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sqkGJjIRfG": {
    "title": "HASSOD: Hierarchical Adaptive Self-Supervised Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ER0bcYXvvo": {
    "title": "Byzantine-Tolerant Methods for Distributed Variational Inequalities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l6pYRbuHpO": {
    "title": "Practical Contextual Bandits with Feedback Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=loixpHDZKj": {
    "title": "Robust Learning for Smoothed Online Convex Optimization with Feedback Delay",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LLETO26Ga2": {
    "title": "Disentanglement via Latent Quantization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lkBygTc0SI": {
    "title": "Do SSL Models Have Déjà Vu? A Case of Unintended Memorization in Self-supervised Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SpStmVboGy": {
    "title": "Solving a Class of Non-Convex Minimax Optimization in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=twmHKU3Ds4": {
    "title": "DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gMjIUZBKH8": {
    "title": "AdaVAE: Bayesian Structural Adaptation for Variational Autoencoders",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C9wTM5xyw2": {
    "title": "Causal discovery from observational and interventional data across multiple environments",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ArRycLMoUg": {
    "title": "Neural Lyapunov Control for Discrete-Time Systems",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sv5bo2StIx": {
    "title": "The Distortion of Binomial Voting Defies Expectation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tnRboxQIec": {
    "title": "Dream the Impossible: Outlier Imagination with Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vBwSACOB3x": {
    "title": "Neural Algorithmic Reasoning Without Intermediate Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7ntySBR3Ey": {
    "title": "Energy-Efficient Scheduling with Predictions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IJblKO45YU": {
    "title": "Goal-Conditioned Predictive Coding for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ecRaDicXxw": {
    "title": "DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KOVWXcrFIK": {
    "title": "Fast Attention Requires Bounded Entries",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PzYAMXmIT3": {
    "title": "Does Visual Pretraining Help End-to-End Reasoning?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ezqI5WgGvY": {
    "title": "CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6lnoUqFd5R": {
    "title": "Learning the Efficient Frontier",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xZvGrzRq17": {
    "title": "For SALE: State-Action Representation Learning for Deep Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lDI3ZuyzM9": {
    "title": "AutoGO: Automated Computation Graph Optimization for Neural Network Evolution",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bRyduWAAVT": {
    "title": "Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iajxrSgOSX": {
    "title": "DELIFFAS: Deformable Light Fields for Fast Avatar Synthesis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=39cFjnRpYm": {
    "title": "Time-uniform confidence bands for the CDF under nonstationarity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FFdrXkm3Cz": {
    "title": "On the spectral bias of two-layer linear networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gf5xJVQS5p": {
    "title": "Learning to Configure Separators in Branch-and-Cut",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HKueO74ZTB": {
    "title": "Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond Examples",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f71xXsoG1v": {
    "title": "Provable convergence guarantees for black-box variational inference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uZvG0HLkOB": {
    "title": "Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lJWUJWLCJo": {
    "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YFSrf8aciU": {
    "title": "Inverse Reinforcement Learning with the Average Reward Criterion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NsPbMwyxRl": {
    "title": "On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bH4LVNVXUo": {
    "title": "Asymmetric Certified Robustness via Feature-Convex Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PxcWJqO3qj": {
    "title": "Learning Exponential Families from Truncated Samples",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UlJcZoawgU": {
    "title": "Extending the Design Space of Graph Neural Networks by Rethinking Folklore Weisfeiler-Lehman",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K4FK7I8Jnl": {
    "title": "MAG-GNN: Reinforcement Learning Boosted Graph Neural Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pXtVyj4R33": {
    "title": "The Best of Both Worlds in Network Population Games: Reaching Consensus and Convergence to Equilibrium",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iAAXq60Bw1": {
    "title": "Geodesic Multi-Modal Mixup for Robust Fine-Tuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r6xGZ0XL2g": {
    "title": "Meta-Learning Adversarial Bandit Algorithms",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sq4o3tjWaj": {
    "title": "What's Left? Concept Grounding with Logic-Enhanced Foundation Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vqGWslLeEw": {
    "title": "Revisiting the Minimalist Approach to Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ekMLUoC2sq": {
    "title": "Simultaneous embedding of multiple attractor manifolds in a recurrent neural network using constrained gradient optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BqZ70BEtuW": {
    "title": "SANFlow: Semantic-Aware Normalizing Flow for Anomaly Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CCq73CGMyV": {
    "title": "Video Dynamics Prior: An Internal Learning Approach for Robust Video Enhancements",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DEC7NxDJLh": {
    "title": "Coupled Reconstruction of Cortical Surfaces by Diffeomorphic Mesh Deformation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S0xrBMFihS": {
    "title": "Dense-Exponential Random Features: Sharp Positive Estimators of the Gaussian Kernel",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8FbuHeVU7D": {
    "title": "Differentially Private Statistical Inference through $\\beta$-Divergence One Posterior Sampling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FFOYWUpBca": {
    "title": "C-Disentanglement: Discovering Causally-Independent Generative Factors under an Inductive Bias of Confounder",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6UCMa0Qgej": {
    "title": "Adversarial Model for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xBhvMu4J03": {
    "title": "Do Not Marginalize Mechanisms, Rather Consolidate!",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3Cj67k38st": {
    "title": "HotBEV: Hardware-oriented Transformer-based Multi-View 3D Detector for BEV Perception",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uJmsYZiu3E": {
    "title": "Fair Allocation of Indivisible Chores: Beyond Additive Costs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fze7P9oy6l": {
    "title": "Supported Value Regularization for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N56hAiQvot": {
    "title": "PackQViT: Faster Sub-8-bit Vision Transformers via Full and Packed Quantization on the Mobile",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NuoIThPPag": {
    "title": "Label-Only Model Inversion Attacks via Knowledge Transfer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pKnhUWqZTJ": {
    "title": "PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oaJEB5Qcia": {
    "title": "FGPrompt: Fine-grained Goal Prompting for Image-goal Navigation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jt10uWlEbc": {
    "title": "Fine-grained Expressivity of Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bISkJSa5Td": {
    "title": "Neural Lad: A Neural Latent Dynamics Framework for Times Series Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cZS5X3PLOR": {
    "title": "Data Minimization at Inference Time",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gsi9lJ3994": {
    "title": "NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tGPx7HdBr4": {
    "title": "Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mv96iC6TMX": {
    "title": "Near-Linear Time Algorithm for the Chamfer Distance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=78yDLKi95p": {
    "title": "Language Model Tokenizers Introduce Unfairness Between Languages",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=inIONNg8Sq": {
    "title": "History Filtering in Imperfect Information Games: Algorithms and Complexity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GPtroppvUM": {
    "title": "Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and New Directions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Tb7np0MInj": {
    "title": "Fast Trainable Projection for Robust Fine-tuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9ych3krqP0": {
    "title": "MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ecv1GMiXSk": {
    "title": "Better Correlation and Robustness: A Distribution-Balanced Self-Supervised Learning Framework for Automatic Dialogue Evaluation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fem6BIJkdv": {
    "title": "Representation Learning via Consistent Assignment of Views over Random Partitions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aW5bSuduF1": {
    "title": "Drift doesn't Matter: Dynamic Decomposition with Diffusion Reconstruction for Unstable Multivariate Time Series Anomaly Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9QsdPQlWiE": {
    "title": "Test-time Training for Matching-based Video Object Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dJZ3MvDw86": {
    "title": "Causal-structure Driven Augmentations for Text OOD Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2URr3mkagy": {
    "title": "Revisiting Implicit Differentiation for Learning Problems in Optimal Control",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r9fzp8eyhZ": {
    "title": "Learning Invariant Molecular Representation in Latent Discrete Space",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d7a5TpePV7": {
    "title": "How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=898RcRYWCg": {
    "title": "Tame a Wild Camera: In-the-Wild Monocular Camera Calibration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zyzluw0hC4": {
    "title": "3D molecule generation by denoising voxel grids",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0hwq2vOHT4": {
    "title": "Described Object Detection: Liberating Object Detection with Flexible Expressions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FOFJmR1oxt": {
    "title": "BCDiff: Bidirectional Consistent Diffusion for Instantaneous Trajectory Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f7wFwPJwBe": {
    "title": "Learning Re-sampling Methods with Parameter Attribution for Image Super-resolution",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E58gaxJN1d": {
    "title": "Learning from Visual Observation via Offline Pretrained State-to-Go Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sXMQPKbLXf": {
    "title": "DiffPack: A Torsional Diffusion Model for Autoregressive Protein Side-Chain Packing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OGQWZ3p0Zn": {
    "title": "Inserting Anybody in Diffusion Models via Celeb Basis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MmCtXvW6GO": {
    "title": "Trade-off Between Efficiency and Consistency for Removal-based Explanations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xJLEQQrFia": {
    "title": "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=38dQv3OwN3": {
    "title": "Fairness Aware Counterfactuals for Subgroups",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OZEfMD7axv": {
    "title": "SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KtvPdGb31Z": {
    "title": "Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SaMrN9tnxE": {
    "title": "ReMaX: Relaxing for Better Training on Efficient Panoptic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xOzlW2vUYc": {
    "title": "CrossGNN: Confronting Noisy Multivariate Time Series Via Cross Interaction Refinement",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zIEaOZ0saA": {
    "title": "New Complexity-Theoretic Frontiers of Tractability for Neural Network Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ymHM1qRUeb": {
    "title": "Covariance-adaptive best arm identification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pplq1TRnma": {
    "title": "Metis: Understanding and Enhancing In-Network Regular Expressions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PbMBfRpVgU": {
    "title": "Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YoghyvSG0H": {
    "title": "Diffusion-SS3D: Diffusion Model for Semi-supervised 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dEDdRWunxU": {
    "title": "Fed-CO$_{2}$: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QvIvWMaQdX": {
    "title": "SOAR: Improved Indexing for Approximate Nearest Neighbor Search",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3IyL2XWDkG": {
    "title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UlHueVjAKr": {
    "title": "Textually Pretrained Speech Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1SF2tiopYJ": {
    "title": "CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BL9Pc7xsdX": {
    "title": "Fast Model DeBias with Machine Unlearning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IMiGRqltQQ": {
    "title": "Why Not Looking backward?\" A Robust Two-Step Method to Automatically Terminate Bayesian Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=woptnU6fh1": {
    "title": "BayesDAG: Gradient-Based Posterior Inference for Causal Discovery",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9ieV1hnuva": {
    "title": "Hypervolume Maximization: A Geometric View of Pareto Set Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s97ezbqoDZ": {
    "title": "RH-BrainFS: Regional Heterogeneous Multimodal Brain Networks Fusion Strategy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f56xMRb7Vt": {
    "title": "Norm-guided latent space exploration for text-to-image generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BOP5McdqGy": {
    "title": "Uncovering and Quantifying Social Biases in Code Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sLhXMkI0kx": {
    "title": "On skip connections and normalisation layers in deep optimisation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UpN2wfrLec": {
    "title": "Language Is Not All You Need: Aligning Perception with Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1WMdoiVMov": {
    "title": "Robust Knowledge Transfer in Tiered Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9MwidIH4ea": {
    "title": "Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G7sQlfTzmY": {
    "title": "On the Pareto Front of Multilingual Neural Machine Translation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6EDHfVHicP": {
    "title": "DDF-HO: Hand-Held Object Reconstruction via Conditional Directed Distance Field",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r8LYNleLf9": {
    "title": "TexQ: Zero-shot Network Quantization with Texture Feature Distribution Calibration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MWp3SwoHmH": {
    "title": "MCUFormer: Deploying Vision Tranformers on Microcontrollers with Limited Memory",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=utQms7PPx5": {
    "title": "All Points Matter: Entropy-Regularized Distribution Alignment for Weakly-supervised 3D Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JvOZ4IIjwP": {
    "title": "Train Hard, Fight Easy: Robust Meta Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=axRMkinASf": {
    "title": "Greedy Poisson Rejection Sampling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZKVxABGJ6r": {
    "title": "PanoGRF: Generalizable Spherical Radiance Fields for Wide-baseline Panoramas",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ks0RSFNxPO": {
    "title": "Time-Independent Information-Theoretic Generalization Bounds for SGLD",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=leS8668NJm": {
    "title": "Toward Re-Identifying Any Animal",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rW4mNcDxpS": {
    "title": "Wasserstein Gradient Flows for Optimizing Gaussian Mixture Policies",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A954O4tDmU": {
    "title": "AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l4CZCKXoSn": {
    "title": "FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tAwjG5bM7H": {
    "title": "A Bounded Ability Estimation for Computerized Adaptive Testing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8qePPvL1VY": {
    "title": "One-for-All: Bridge the Gap Between Heterogeneous Architectures in Knowledge Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PBpEb86bj7": {
    "title": "ATMAN: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=shXnfALjuH": {
    "title": "FD-Align: Feature Discrimination Alignment for Fine-tuning Pre-Trained Models in Few-Shot Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IN3hQx1BrC": {
    "title": "Task-aware world model learning with meta weighting via bi-level optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J0Pvvxspmz": {
    "title": "SUBP: Soft Uniform Block Pruning for 1$\\times$N Sparse CNNs Multithreading Acceleration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J6Niv3yrMq": {
    "title": "Glance and Focus: Memory Prompting for Multi-Event Video Question Answering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RteNLuc8D9": {
    "title": "Dynamic Personalized Federated Learning with Adaptive Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XXagS1RQH0": {
    "title": "Learning-to-Rank Meets Language: Boosting Language-Driven Ordering Alignment for Ordinal Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BRSgVw85Mc": {
    "title": "Optimal privacy guarantees for a relaxed threat model: Addressing sub-optimal adversaries in differentially private machine learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XvGQ6F3sG8": {
    "title": "Self-supervised Graph Neural Networks via Low-Rank Decomposition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hrkmlPhp1u": {
    "title": "UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gJewjFjfN2": {
    "title": "Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rzlqOVExUA": {
    "title": "GALOPA: Graph Transport Learning with Optimal Plan Alignment",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=irRHgjePdR": {
    "title": "Improving Compositional Generalization using Iterated Learning and Simplicial Embeddings",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NP5xb00Y6a": {
    "title": "Fairly Recommending with Social Attributes: A Flexible and Controllable Optimization Approach",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HFQFAyNucq": {
    "title": "ResMem: Learn what you can and memorize the rest",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k8U8ZijXHh": {
    "title": "PDF: Point Diffusion Implicit Function for Large-scale Scene Neural Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ir6WWkFR80": {
    "title": "Punctuation-level Attack: Single-shot and Single Punctuation Can Fool Text Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B6HSIgvyJ3": {
    "title": "A Batch-to-Online Transformation under Random-Order Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K9dmkfZcMu": {
    "title": "A Recurrent Neural Circuit Mechanism of Temporal-scaling Equivariant Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x9FOu3W6iy": {
    "title": "Thrust: Adaptively Propels Large Language Models with External Knowledge",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jIhX7SpfCz": {
    "title": "CluB: Cluster Meets BEV for LiDAR-Based 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EdIGMCHk4l": {
    "title": "RRHF: Rank Responses to Align Language Models with Human Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h8vJVABiBP": {
    "title": "Learning Modulated Transformation in GANs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DdViWdxCTs": {
    "title": "Uncovering Prototypical Knowledge for Weakly Open-Vocabulary Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F5DYsAc7Rt": {
    "title": "GRAND-SLAMIN' Interpretable Additive Modeling with Structural Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=492Hfmgejy": {
    "title": "Lightweight Vision Transformer with Bidirectional Interaction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dQLsvKNwZC": {
    "title": "Safe Exploration in Reinforcement Learning: A Generalized Formulation and Algorithms",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M6OmjAZ4CX": {
    "title": "Language Models can Solve Computer Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=69dAz94zPv": {
    "title": "Logarithmic-Regret Quantum Learning Algorithms for Zero-Sum Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1SAzP7W43j": {
    "title": "Single-Stage Visual Query Localization in Egocentric Videos",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ts0d8PvTeB": {
    "title": "Meta-Adapter: An Online Few-shot Learner for Vision-Language Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=doWqIXcRlq": {
    "title": "Revisit Weakly-Supervised Audio-Visual Video Parsing from the Language Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6vnwhzRinw": {
    "title": "Efficient Uncertainty Quantification and Reduction for Over-Parameterized Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cm53OBkctM": {
    "title": "Bayesian Learning of Optimal Policies in Markov Decision Processes with Countably Infinite State-Space",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FiClXlUqA7": {
    "title": "A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w2F8Fm6Sg3": {
    "title": "Balanced Training for Sparse GANs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g6We1SwaY9": {
    "title": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oGxE2Nvlda": {
    "title": "UniT: A Unified Look at Certified Robust Training against Text Adversarial Perturbation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QoeOVgayLp": {
    "title": "Selective Sampling and Imitation Learning via Online Regression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rN99gLCBe4": {
    "title": "Continuous-time Analysis of Anchor Acceleration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xSEhb2j3TK": {
    "title": "Act As You Wish: Fine-Grained Control of Motion Diffusion Model with Hierarchical Semantic Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3ZICE99e6n": {
    "title": "ReTR: Modeling Rendering Via Transformer for Generalizable Neural Surface Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cYkSt7jqlx": {
    "title": "Context-guided Embedding Adaptation for Effective Topic Modeling in Low-Resource Regimes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kVfHQV668B": {
    "title": "Towards Efficient Pre-Trained Language Model via Feature Correlation Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jL2eJxPK88": {
    "title": "Fast Partitioned Learned Bloom Filter",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xxfHMqNcum": {
    "title": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SaII5qMgKH": {
    "title": "Learning to Parameterize Visual Attributes for Open-set Fine-grained Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I5SM5y57k2": {
    "title": "On Robust Streaming for Learning with Experts: Algorithms and Lower Bounds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ES32O8mBK3": {
    "title": "H3T: Efficient Integration of Memory Optimization and Parallelism for Large-scale Transformer Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VKbEO2eh5w": {
    "title": "Test-Time Distribution Normalization for Contrastively Learned Visual-language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aec58UfBzA": {
    "title": "RanPAC: Random Projections and Pre-trained Models for Continual Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cdlmsnQkZ9": {
    "title": "Learning non-Markovian Decision-Making from State-only Sequences",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BnV2M2WFaY": {
    "title": "Noise-Adaptive Thompson Sampling for Linear Contextual Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Kd5W4JRsfV": {
    "title": "Layer-Neighbor Sampling --- Defusing Neighborhood Explosion in GNNs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fvm9jVcpBn": {
    "title": "Sensitivity in Translation Averaging",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EgCjf1vjMB": {
    "title": "Training Private Models That Know What They Don't Know",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wRhLd65bDt": {
    "title": "Improving Diffusion-Based Image Synthesis with Context Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BExDjNDYkN": {
    "title": "HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ykvvv0gc4R": {
    "title": "Deep Momentum Multi-Marginal Schrödinger Bridge",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XyAP8ScqLV": {
    "title": "An Empirical Study Towards Prompt-Tuning for Graph Contrastive Pre-Training in Recommendations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RWcfpmjlYm": {
    "title": "BanditPAM++: Faster $k$-medoids Clustering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rlPUJ60bwM": {
    "title": "False Discovery Proportion control for aggregated Knockoffs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4AmJVaJ78I": {
    "title": "Block-Coordinate Methods and Restarting for Solving Extensive-Form Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qy07OHsJT5": {
    "title": "Diffusion Schrödinger Bridge Matching",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HWNl9PAYIP": {
    "title": "Video Prediction Models as Rewards for Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dAJrxQz1lk": {
    "title": "A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FM8thAWqiO": {
    "title": "Core-sets for Fair and Diverse Data Summarization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gpqBGyKeKH": {
    "title": "Spectral Evolution and Invariance in Linear-width Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RmxP5ZcQhC": {
    "title": "Agnostic Multi-Group Active Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KAWaeKOEkx": {
    "title": "DropCompute: simple and more robust distributed synchronous training via compute variance reduction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3H37XciUEv": {
    "title": "Post Hoc Explanations of Language Models Can Improve Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FtZ7lUwH99": {
    "title": "Dynamic Pricing and Learning with Bayesian Persuasion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gbhixjg2dX": {
    "title": "Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1g0A9kE8Id": {
    "title": "Learning Unseen Modality Interaction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=639RkUOmW8": {
    "title": "No-Regret Learning with Unbounded Losses: The Case of Logarithmic Pooling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6jNQ1AY1Uf": {
    "title": "Synthetic Experience Replay",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fjXTcUUgaC": {
    "title": "Policy Finetuning in Reinforcement Learning via Design of Experiments using Offline Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ne6zeqLFCZ": {
    "title": "Symbolic Discovery of Optimization Algorithms",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TnTDiCppx5": {
    "title": "Predict-then-Calibrate: A New Perspective of Robust Contextual LP",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hI6EPhq70A": {
    "title": "Face Reconstruction from Facial Templates by Learning Latent Space of a Generator Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jooPcatnVF": {
    "title": "Implicit Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bsNslV3Ahe": {
    "title": "Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c4Xc0uTLXW": {
    "title": "Tight Bounds for Volumetric Spanners and Applications",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1osmdAfD4P": {
    "title": "Online Convex Optimization with Unbounded Memory",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MV0INFAKGq": {
    "title": "Tanimoto Random Features for Scalable Molecular Machine Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6JJq5TW9Mc": {
    "title": "Learning World Models with Identifiable Factorization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ks7Mf5lzSx": {
    "title": "SpatialRank: Urban Event Ranking with NDCG Optimization on Spatiotemporal Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2XT3UpOv48": {
    "title": "Structured Federated Learning through Clustered Additive Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1HKJ3lPz6m": {
    "title": "Learning and Collusion in Multi-unit Auctions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=77i6itptQW": {
    "title": "IDEA: An Invariant Perspective for Efficient Domain Adaptive Image Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xmxgMij3LY": {
    "title": "Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3kitbpEZZO": {
    "title": "Beyond probability partitions: Calibrating neural networks with semantic aware grouping",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8WvYAycmDJ": {
    "title": "MixFormerV2: Efficient Fully Transformer Tracking",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Isy7gl1Hqc": {
    "title": "Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qA0uHmaVKk": {
    "title": "Complex-valued Neurons Can Learn More but Slower than Real-valued Neurons via Gradient Descent",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=No52399wXA": {
    "title": "IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MUwr2YVJfN": {
    "title": "HEDNet: A Hierarchical Encoder-Decoder Network for 3D Object Detection in Point Clouds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7uPnuoYqac": {
    "title": "Federated Learning with Manifold Regularization and Normalized Update Reaggregation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nO5i1XdUS0": {
    "title": "Eliminating Domain Bias for Federated Learning in Representation Space",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Uc5yyiytR1": {
    "title": "Identification of Nonlinear Latent Hierarchical Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nA9Fh3HFHJ": {
    "title": "Deconstructing Data Reconstruction: Multiclass, Weight Decay and General Losses",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ganlU27uvj": {
    "title": "Slot-guided Volumetric Object Radiance Fields",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vybQs1Gbuk": {
    "title": "Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9i8MD9btc8": {
    "title": "(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CGj72TyGJy": {
    "title": "Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p4PckNQR8k": {
    "title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8GuEVzAUQS": {
    "title": "Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HlIAoCHDWW": {
    "title": "Learning in the Presence of Low-dimensional Structure: A Spiked Random Matrix Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vZHk1QlBQW": {
    "title": "ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=35nFSbEBks": {
    "title": "Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DNdN26m2Jk": {
    "title": "Crystal Structure Prediction by Joint Equivariant Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KYxD9YCQBH": {
    "title": "ReContrast: Domain-Specific Anomaly Detection via Contrastive Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3fd776zKmo": {
    "title": "Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LnySNEJAQt": {
    "title": "Flow Factorized Representation Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M7hijAPA4B": {
    "title": "Feature Dropout: Revisiting the Role of Augmentations in Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BEHlPdBZ2e": {
    "title": "TensorNet: Cartesian Tensor Representations for Efficient Learning of Molecular Potentials",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5UOYGfobhC": {
    "title": "Uni3DETR: Unified 3D Detection Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rmQgQCZWiP": {
    "title": "Managing Temporal Resolution in Continuous Value Estimation: A Fundamental Trade-off",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BVN9Kgvwzv": {
    "title": "From Cloze to Comprehension: Retrofitting Pre-trained Masked Language Models to Pre-trained Machine Reader",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G5RwHpBUv0": {
    "title": "Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dAbGv5Jz5U": {
    "title": "Contrastive Sampling Chains in Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JvYSSPtQyk": {
    "title": "DASpeech: Directed Acyclic Transformer for Fast and High-quality Speech-to-Speech Translation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cczH4Xl7Zo": {
    "title": "Towards Distribution-Agnostic Generalized Category Discovery",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IZRlMABK4l": {
    "title": "Efficient Test-Time Adaptation for Super-Resolution with Second-Order Degradation and Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3Fc9gnR0fa": {
    "title": "Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1qvx610Cu7": {
    "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RqjQL08UFc": {
    "title": "Spectral Co-Distillation for Personalized Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zqOcW3R9rd": {
    "title": "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QLllDwizVd": {
    "title": "Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y3g1PV5R9l": {
    "title": "PTQD: Accurate Post-Training Quantization for Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PIDNxRRJ8w": {
    "title": "Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZgVJvaAS2h": {
    "title": "A Unified Conditional Framework for Diffusion-based Image Restoration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aW9BqtRQkh": {
    "title": "Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zGdH4tKtOW": {
    "title": "Optimal Treatment Regimes for Proximal Causal Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IzlRh5qwmG": {
    "title": "Swap Agnostic Learning, or Characterizing Omniprediction via Multicalibration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nFsbQHFmj2": {
    "title": "Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mcx8IGneYw": {
    "title": "Neural Lighting Simulation for Urban Scenes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HtqnVSCj3q": {
    "title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BqTv1Mtuhu": {
    "title": "Designing Robust Transformers using Robust Kernel Density Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LWxjWoBTsr": {
    "title": "Large Language Models can Implement Policy Iteration",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GEtXhqKW6X": {
    "title": "iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5MG5C5aS6m": {
    "title": "Global Optimality in Bivariate Gradient-based DAG Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Fy1S3v4UAk": {
    "title": "A Dual-Stream Neural Network Explains the Functional Segregation of Dorsal and Ventral Visual Pathways in Human Brains",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KoaFh16uOc": {
    "title": "StyleDrop: Text-to-Image Synthesis of Any Style",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=L0QwnevT0F": {
    "title": "Truly Scale-Equivariant Deep Nets with Fourier Layers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uPSQv0leAu": {
    "title": "Data Selection for Language Models via Importance Resampling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gAP52Z2dar": {
    "title": "Inverse Preference Learning: Preference-based RL without a Reward Function",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JdhyIa0azI": {
    "title": "Neural Functional Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fmYmXNPmhv": {
    "title": "Permutation Equivariant Neural Functionals",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=46gYakmj4e": {
    "title": "Unsupervised Protein-Ligand Binding Energy Prediction via Neural Euler's Rotation Equation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OmTMaTbjac": {
    "title": "MAViL: Masked Audio-Video Learners",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2ePf1sBgLU": {
    "title": "Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hpt1i5j6wh": {
    "title": "Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4VAF3d5jNg": {
    "title": "Adaptive Selective Sampling for Online Prediction with Experts",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CzAFnfwbGd": {
    "title": "Coneheads: Hierarchy Aware Attention",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4qG2RKuZaA": {
    "title": "Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d4f40zJJIS": {
    "title": "Structural Pruning for Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TDS3kqRteY": {
    "title": "REx: Data-Free Residual Quantization Error Expansion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rqE0fEQDqs": {
    "title": "PointGPT: Auto-regressively Generative Pre-training from Point Clouds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IPNg84RF1k": {
    "title": "Towards Characterizing the First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aMTiwdK3y8": {
    "title": "FourierHandFlow: Neural 4D Hand Representation Using Fourier Query Flow",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=thPI8hrA4V": {
    "title": "GlyphControl: Glyph Conditional Control for Visual Text Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZZWg9jJQ1j": {
    "title": "Generalizable Lightweight Proxy for Robust NAS against Diverse Perturbations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=71P7ugOGCV": {
    "title": "Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J8Ajf9WfXP": {
    "title": "LLM-Pruner: On the Structural Pruning of Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dR6p49RYLq": {
    "title": "NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9UxUTGCteW": {
    "title": "LuminAIRe: Illumination-Aware Conditional Image Repainting for Lighting-Realistic Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JSVXZKqfLU": {
    "title": "Latent exploration for Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zrLxHYvIFL": {
    "title": "Discover and Align Taxonomic Context Priors for Open-world Semi-Supervised Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ct0zPIe3xs": {
    "title": "Saving 100x Storage: Prototype Replay for Reconstructing Training Sample Distribution in Class-Incremental Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l6ypbj6Nv5": {
    "title": "Generative Category-level Object Pose Estimation via Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fwvfxDbUFw": {
    "title": "Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vHRLS8HhK1": {
    "title": "Generalized Weighted Path Consistency for Mastering Atari Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xHNzWHbklj": {
    "title": "Towards Better Dynamic Graph Learning: New Architecture and Unified Library",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1hZwxBgQ3G": {
    "title": "Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7WTA298wts": {
    "title": "Masked Image Residual Learning for Scaling Deeper Vision Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=75Mxzfoeq7": {
    "title": "No-Regret Learning in Dynamic Competition with Reference Effects Under Logit Demand",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VFhN15Vlkj": {
    "title": "Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WjgCRrOgip": {
    "title": "Repetition In Repetition Out: Towards Understanding Neural Text Degeneration from the Data Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f0Jj3C3Pnp": {
    "title": "HubRouter: Learning Global Routing via Hub Generation and Pin-hub Connection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O63qgtebjH": {
    "title": "Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Re2NHYoZ5l": {
    "title": "Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hCg4w8L8Dt": {
    "title": "Knowledge Distillation for High Dimensional Search Index",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wn82NbmvJy": {
    "title": "Accelerating Value Iteration with Anchoring",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RFE1eI0zNZ": {
    "title": "Public Opinion Field Effect Fusion in Representation Learning for Trending Topics Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pjky9XG8zP": {
    "title": "One Less Reason for Filter Pruning: Gaining Free Adversarial Robustness with Structured Grouped Kernel Pruning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CxUuCydMDU": {
    "title": "Diffusion Probabilistic Models for Structured Node Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ph65E1bE6A": {
    "title": "Overcoming Recency Bias of Normalization Statistics in Continual Learning: Balance and Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UYl9IIsjq7": {
    "title": "Decompose Novel into Known: Part Concept Learning For 3D Novel Class Discovery",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lclQ2RvWYu": {
    "title": "A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uDV4lA0gZ6": {
    "title": "Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FT2q2B4cKZ": {
    "title": "Markovian Sliced Wasserstein Distances: Beyond Independent Projections",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=THfl8hdVxH": {
    "title": "White-Box Transformers via Sparse Rate Reduction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K30wTdIIYc": {
    "title": "Controlling Text-to-Image Diffusion by Orthogonal Finetuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nRfClnMhVX": {
    "title": "Interpretability at Scale: Identifying Causal Mechanisms in Alpaca",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6RiqluMFNz": {
    "title": "Robust Lipschitz Bandits to Adversarial Corruptions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WjDj6W872v": {
    "title": "Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=umvV3yvo4N": {
    "title": "Energy-Based Sliced Wasserstein Distance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cRzt1umRNx": {
    "title": "Riemannian Residual Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VhLU3pStsl": {
    "title": "Estimating Riemannian Metric with Noise-Contaminated Intrinsic Distance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3Py8A1j5N3": {
    "title": "DP-HyPO: An Adaptive Private Framework for Hyperparameter Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b6XvK2de99": {
    "title": "One-Step Diffusion Distillation via Deep Equilibrium Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GiiOpKinGm": {
    "title": "Multi-Player Zero-Sum Markov Games with Networked Separable Interactions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=znY173SCxu": {
    "title": "Time-Reversed Dissipation Induces Duality Between Minimizing Gradient Norm and Function Value",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o50nH0sV9x": {
    "title": "Certifiably Robust Graph Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XbVnNXaIQY": {
    "title": "Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tGuMwFnRZX": {
    "title": "Latent Graph Inference with Limited Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1recIOnzOF": {
    "title": "Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wUNPmdE273": {
    "title": "Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=L9ZTvJ5jVx": {
    "title": "Latent Field Discovery in Interacting Dynamical Systems with Neural Fields",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VIaw1XHb4G": {
    "title": "Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AkK3S2spZs": {
    "title": "Strategic Data Sharing between Competitors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R2rJq5OHdr": {
    "title": "Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fKVEMNmWqU": {
    "title": "Reduced Policy Optimization for Continuous Control with Hard Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jown9RvYn7": {
    "title": "Domain Re-Modulation for Few-Shot Generative Domain Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HMhEFKDQ6J": {
    "title": "Unifying GANs and Score-Based Diffusion as Generative Particle Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I8t9RKDnz2": {
    "title": "State Regularized Policy Optimization on Data with Dynamics Shift",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WUott1ZvRj": {
    "title": "Rank-DETR for High Quality Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aGZp61S9Lj": {
    "title": "Enhancing Adaptive History Reserving by Spiking Convolutional Block Attention Module in Recurrent Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vEzcRdiTkP": {
    "title": "On Class Distributions Induced by Nearest Neighbor Graphs for Node Classification of Tabular Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hSTaTBIUCj": {
    "title": "Imagine That! Abstract-to-Intricate Text-to-Image Synthesis with Scene Graph Hallucination Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bLB4vTwSbC": {
    "title": "Greatness in Simplicity: Unified Self-Cycle Consistency for Parser-Free Virtual Try-On",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LV83JEihHu": {
    "title": "Exploring Question Decomposition for Zero-Shot VQA",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kuxu4lCRr5": {
    "title": "PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9D0fELXbrg": {
    "title": "Scale-teaching: Robust Multi-scale Training for Time Series Classification with Noisy Labels",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KIPAIy329j": {
    "title": "SEGA: Instructing Text-to-Image Models using Semantic Guidance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YVMc3KiWBQ": {
    "title": "Offline Reinforcement Learning with Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xrK3QA9mLo": {
    "title": "FaceComposer: A Unified Model for Versatile Facial Content Creation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fyLvHzEssH": {
    "title": "Neural (Tangent Kernel) Collapse",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YPQg2RTFD8": {
    "title": "Harnessing Hard Mixed Samples with Decoupled Regularizer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f39Q3JyoIi": {
    "title": "Collaborative Alignment of NLP Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jOuxQGRVoQ": {
    "title": "IEBins: Iterative Elastic Bins for Monocular Depth Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q5Eb6qIKux": {
    "title": "VanillaNet: the Power of Minimalism in Deep Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EmOIP3t9nk": {
    "title": "ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RRUVZygUtr": {
    "title": "Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=phnGilhPH8": {
    "title": "FedFed: Feature Distillation against Data Heterogeneity in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9rmwPAjk9O": {
    "title": "Gradient-Free Kernel Stein Discrepancy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ytrhsvGP0r": {
    "title": "Epidemic Learning: Boosting Decentralized Learning with Randomized Communication",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D8oHQ2qSTj": {
    "title": "Fairness-guided Few-shot Prompting for Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h3MShWMxNt": {
    "title": "Scattering Vision Transformer: Spectral Mixing Matters",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZOKhtz2Z9X": {
    "title": "Encoding Human Behavior in Information Design through Deep Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o7W0Zet6p3": {
    "title": "Recovering Unbalanced Communities in the Stochastic Block Model with Application to Clustering with a Faulty Oracle",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uiiVSVADDc": {
    "title": "Annotator: A Generic Active Learning Baseline for LiDAR Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pj6X6GqNy8": {
    "title": "Learning Fine-grained View-Invariant Representations from Unpaired Ego-Exo Videos via Temporal Alignment",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2cYxNWNzk3": {
    "title": "Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c9fXCzR5fK": {
    "title": "Sequential Subset Matching for Dataset Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dB4lvScPIj": {
    "title": "SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=quMBEd27x9": {
    "title": "Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pE3yaP0Eqg": {
    "title": "FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness for Semi-Supervised Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TKjX41IP7n": {
    "title": "CoDet: Co-occurrence Guided Region-Word Alignment for Open-Vocabulary Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bRlEwWd7Vy": {
    "title": "Distributionally Robust Bayesian Optimization with $\\varphi$-divergences",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=txPdKZrrZF": {
    "title": "Fed-FA: Theoretically Modeling Client Data Divergence for Federated Language Backdoor Defense",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7LtzqnfuOs": {
    "title": "Dual Self-Awareness Value Decomposition Framework without Individual Global Max for Cooperative MARL",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q5FAZAIooz": {
    "title": "Diff-Foley: Synchronized Video-to-Audio Synthesis with Latent Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kS8rIH43Zc": {
    "title": "Bayesian Active Causal Discovery with Multi-Fidelity Experiments",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FmpH0CYWiX": {
    "title": "NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and Repulsive UDF",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QGrkbaan79": {
    "title": "RADAR: Robust AI-Text Detection via Adversarial Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z28nPtAVxx": {
    "title": "Optimal Extragradient-Based Algorithms for Stochastic Variational Inequalities with Separable Structure",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LROEcjVkv5": {
    "title": "Asymptotically Optimal Quantile Pure Exploration for Infinite-Armed Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7ETbK9lQd7": {
    "title": "Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pcuC65JWAa": {
    "title": "Reducing Blackwell and Average Optimality to Discounted MDPs via the Blackwell Discount Factor",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VAQp2EnZeW": {
    "title": "Training Neural Networks is NP-Hard in Fixed Dimension",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=deaHiTb6Cu": {
    "title": "Fast Exact Leverage Score Sampling from Khatri-Rao Products with Applications to Tensor Decomposition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iWWLgcUTZU": {
    "title": "PCF-GAN: generating sequential data via the characteristic function of measures on the path space",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qCglMj6A4z": {
    "title": "Gradient Descent with Linearly Correlated Noise: Theory and Applications to Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tQYGjnxPOm": {
    "title": "D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mvSDs51eqQ": {
    "title": "Optimality in Mean Estimation: Beyond Worst-Case, Beyond Sub-Gaussian, and Beyond $1+\\alpha$ Moments",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gdVcFOvxT3": {
    "title": "Finding Safe Zones of Markov Decision Processes Policies",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BGvkwZEGt7": {
    "title": "Large Language Models Are Latent Variable Models: Explaining and Finding Good Demonstrations for In-Context Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yGLokEhdh9": {
    "title": "Augmented Memory Replay-based Continual Learning Approaches for Network Intrusion Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y9U0IJ2uFr": {
    "title": "SNEkhorn: Dimension Reduction with Symmetric Entropic Affinities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TjgG4UT62W": {
    "title": "Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=716PvHoDct": {
    "title": "VPGTrans: Transfer Visual Prompt Generator across LLMs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wFH5hZAwYz": {
    "title": "Sharp Calibrated Gaussian Processes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VsbrdJpwpT": {
    "title": "AdaptSSR: Pre-training User Model with Augmentation-Adaptive Self-Supervised Ranking",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pcpjtYNJCH": {
    "title": "Initialization-Dependent Sample Complexity of Linear Predictors and Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GYjV1M5s0D": {
    "title": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2BpoGPSDCR": {
    "title": "Solving Inverse Physics Problems with Score Matching",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ktYjrgOENR": {
    "title": "DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HffQOS3mk8": {
    "title": "Diffusion-Based Probabilistic Uncertainty Estimation for Active Domain Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h4r00NGkjR": {
    "title": "VideoComposer: Compositional Video Synthesis with Motion Controllability",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iQlK3VJxV7": {
    "title": "Uncertainty-Aware Alignment Network for Cross-Domain Video-Text Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=luyXPdkNSN": {
    "title": "K-Nearest-Neighbor Local Sampling Based Conditional Independence Testing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SGKbHXoLCI": {
    "title": "Collaborative Learning via Prediction Consensus",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pWZ97hUQtQ": {
    "title": "Principled Weight Initialisation for Input-Convex Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1q0feiJ2i4": {
    "title": "Large Language Models are Visual Reasoning Coordinators",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lxGFGMMSVl": {
    "title": "Spontaneous symmetry breaking in generative diffusion models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=67MTWzhEOn": {
    "title": "Revisit the Power of Vanilla Knowledge Distillation: from Small Scale to Large Scale",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cwjh8lqmOL": {
    "title": "GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nJFJcgjnGo": {
    "title": "Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rsrfEIdawr": {
    "title": "DäRF: Boosting Radiance Fields from Sparse Input Views with Monocular Depth Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DVWIA9v9Jm": {
    "title": "R-divergence for Estimating Model-oriented Distribution Discrepancy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eW233GDOpm": {
    "title": "Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pirH9ycaNg": {
    "title": "Kernelized Reinforcement Learning with Order Optimal Regret Bounds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SVUQX1W7RL": {
    "title": "DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2NkGfA66Ne": {
    "title": "Segment Anything in 3D with NeRFs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n3ZVdny7OH": {
    "title": "DRAUC: An Instance-wise Distributionally Robust AUC Optimization Framework",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i0OmcF14Kf": {
    "title": "State-space models with layer-wise nonlinearity are universal approximators with exponential decaying memory",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IXWaWPkGke": {
    "title": "Optimization or Architecture: How to Hack Kalman Filtering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eTp4RetK74": {
    "title": "ASPEN: Breaking Operator Barriers for Efficient Parallelization of Deep Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iB3Ew6z4WL": {
    "title": "MultiMoDN—Multimodal, Multi-Task, Interpretable Modular Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v5Aaxk4sSy": {
    "title": "Improving Adversarial Robustness via Information Bottleneck Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MDxZYFR5Me": {
    "title": "Imbalanced Mixed Linear Regression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c2LZyTyddi": {
    "title": "BIOT: Biosignal Transformer for Cross-data Learning in the Wild",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I9GNrInbdf": {
    "title": "Formulating Discrete Probability Flow Through Optimal Transport",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0LmWBhIYLi": {
    "title": "Universal Prompt Tuning for Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e8i7OaPj0q": {
    "title": "Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eCgWNU2Imw": {
    "title": "On Sparse Modern Hopfield Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=avuRopYsCg": {
    "title": "Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human Actions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7xlrdSOm3g": {
    "title": "A Theory of Multimodal Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P9I2VQv1uC": {
    "title": "Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yDvb3mlogA": {
    "title": "Closing the gap between the upper bound and lower bound of Adam's iteration complexity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uv3ge0goPa": {
    "title": "Training Your Image Restoration Network Better with Random Weight Network as Optimization Function",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m0RbqrUM26": {
    "title": "StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Eq9AFZlAjt": {
    "title": "Unbounded Differentially Private Quantile and Maximum Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6f320HfMeS": {
    "title": "Conformalized matrix completion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b5R8mbqo9Q": {
    "title": "A Heavy-Tailed Algebra for Probabilistic Programming",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Poj71ASubN": {
    "title": "What Knowledge Gets Distilled in Knowledge Distillation?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dpdbbN7AKr": {
    "title": "Large-Scale Distributed Learning via Private On-Device LSH",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZqSx5vXOgC": {
    "title": "Bypass Exponential Time Preprocessing: Fast Neural Network Training via Weight-Data Correlation Preprocessing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q3fA5tTod3": {
    "title": "Brain Dissection: fMRI-trained Networks Reveal Spatial Selectivity in the Processing of Natural Images",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7yjsYrajlt": {
    "title": "The Target-Charging Technique for Privacy Analysis across Interactive Computations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sC4RbbVKbu": {
    "title": "SutraNets: Sub-series Autoregressive Networks for Long-Sequence, Probabilistic Forecasting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DnVjDRLwVu": {
    "title": "On the Implicit Bias of Linear Equivariant Steerable Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y8p3ThNDmK": {
    "title": "A Unified Algorithm Framework for Unsupervised Discovery of Skills based on Determinantal Point Process",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ajnThDhuq6": {
    "title": "Improving Robustness with Adaptive Weight Decay",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xr3KAzboHY": {
    "title": "Calibrating \"Cheap Signals\" in Peer Review without a Prior",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pJbEXBBN88": {
    "title": "Adversarial Examples Exist in Two-Layer ReLU Networks for Low Dimensional Linear Subspaces",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C8JdyM7B8I": {
    "title": "Towards Label-free Scene Understanding by Vision Foundation Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pO7d6iFdnc": {
    "title": "ESSEN: Improving Evolution State Estimation for Temporal Networks using Von Neumann Entropy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=STrXsSIEiq": {
    "title": "Learning Robust Statistics for Simulation-based Inference under Model Misspecification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1h92PmnKov": {
    "title": "Momentum Provably Improves Error Feedback!",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cBIPcZKFdw": {
    "title": "Strategic Apple Tasting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iAcEmyhwk2": {
    "title": "Sharp Bounds for Generalized Causal Sensitivity Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EUiIbwV379": {
    "title": "Better Private Linear Regression Through Better Private Feature Selection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vtqymej1tA": {
    "title": "Multiplication-Free Transformer Training via Piecewise Affine Operations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7eHn64wOVy": {
    "title": "Random-Access Infinite Context Length for Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e0tt2G8hqf": {
    "title": "Aligning Gradient and Hessian for Neural Signed Distance Function",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eT1QOsssRB": {
    "title": "Strategyproof Voting under Correlated Beliefs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nCwStXFDQu": {
    "title": "FouriDown: Factoring Down-Sampling into Shuffling and Superposing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wMNpMe0vp3": {
    "title": "A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GxL6PrmEUw": {
    "title": "Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Asx5eDqFZl": {
    "title": "FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ackajXqei2": {
    "title": "Mixed Samples as Probes for Unsupervised Model Selection in Domain Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PSngfm5B9q": {
    "title": "Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4iTAUsyisM": {
    "title": "Data-Dependent Bounds for Online Portfolio Selection Without Lipschitzness and Smoothness",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5F04bU79eK": {
    "title": "Provable Guarantees for Neural Networks via Gradient Feature Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NemifGnD2E": {
    "title": "GNeSF: Generalizable Neural Semantic Fields",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dHF3Im8Aic": {
    "title": "LMC: Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uZjpSBTPik": {
    "title": "CL-NeRF: Continual Learning of Neural Radiance Fields for Evolving Scene Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sQyRQjun46": {
    "title": "Understanding and Addressing the Pitfalls of Bisimulation-based Representations in Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1TJaITmK2Q": {
    "title": "Adaptive Topological Feature via Persistent Homology: Filtration Learning for Point Clouds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TPeAmxwPK2": {
    "title": "Parameter and Computation Efficient Transfer Learning for Vision-Language Pre-trained Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sFGkL5BsPi": {
    "title": "Q-DM: An Efficient Low-bit Quantized Diffusion Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V4YeOvsQfu": {
    "title": "Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nrQif5tH7O": {
    "title": "Leave No Stone Unturned: Mine Extra Knowledge for Imbalanced Facial Expression Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PARMyW6xX0": {
    "title": "Type-to-Track: Retrieve Any Object via Prompt-based Tracking",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IiwTFcGGTq": {
    "title": "On the Adversarial Robustness of Out-of-distribution Generalization Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5cPz5hrjy6": {
    "title": "Replicability in Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I5rsM4CY2z": {
    "title": "Deductive Verification of Chain-of-Thought Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BkQM8huiIc": {
    "title": "A normative theory of social conflict",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DpuphOgJqh": {
    "title": "Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g9gjpFOiO4": {
    "title": "Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nArzDm353Y": {
    "title": "Training Transitive and Commutative Multimodal Transformers with LoReTTa",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sWNOvNXGLP": {
    "title": "DISCOVER: Making Vision Networks Interpretable via Competition and Dissection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ViFTWelHVZ": {
    "title": "Efficient Activation Function Optimization through Surrogate Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5VQFAvUHcd": {
    "title": "Replicable Clustering",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aN0llPIbdg": {
    "title": "Scale-Space Hypernetworks for Efficient Biomedical Image Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bpmM6SkDUy": {
    "title": "EDGI: Equivariant Diffusion for Planning with Embodied Agents",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A6X9y8n4sT": {
    "title": "One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Eu4Kkefq7p": {
    "title": "OpenShape: Scaling Up 3D Shape Representation Towards Open-World Understanding",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MdJX5wwKwx": {
    "title": "Optimization of Inter-group criteria for clustering with minimum size constraints",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KTZttLZekH": {
    "title": "On the Constrained Time-Series Generation Problem",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yzZbwQPkmP": {
    "title": "SparseProp: Efficient Event-Based Simulation and Training of Sparse Recurrent Spiking Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jEQRoJzDx8": {
    "title": "Gradient Flossing: Improving Gradient Descent through Dynamic Control of Jacobians",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vpQuCsZXz2": {
    "title": "TransHP: Image Classification with Hierarchical Prompting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wv3bHyQbX7": {
    "title": "Subject-driven Text-to-Image Generation via Apprenticeship Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Eysb8t3MJ5": {
    "title": "GlucoSynth: Generating Differentially-Private Synthetic Glucose Traces",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yhNHpLWJDl": {
    "title": "Finite-Time Analysis of Whittle Index based Q-Learning for Restless Multi-Armed Bandits with Neural Network Function Approximation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WsmBcJarWW": {
    "title": "Weighted ROC Curve in Cost Space: Extending AUC to Cost-Sensitive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CA8tMQiscx": {
    "title": "Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=17Zkztjlgt": {
    "title": "Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oDtyJt5JLk": {
    "title": "Directional diffusion models for graph representation learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mHsxsrLl0y": {
    "title": "Theoretically Guaranteed Bidirectional Data Rectification for Robust Sequential Recommendation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e2wtjx0Yqu": {
    "title": "CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nG35q8pNL9": {
    "title": "What Truly Matters in Trajectory Prediction for Autonomous Driving?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hXevuspQnX": {
    "title": "InsActor: Instruction-driven Physics-based Characters",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FsQWxU5TOL": {
    "title": "Differentiable Blocks World: Qualitative 3D Decomposition by Rendering Primitives",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ij3svnPLzG": {
    "title": "Semi-Supervised Contrastive Learning for Deep Regression with Ordinal Rankings from Spectral Seriation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0DpKUzl1Se": {
    "title": "Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent Representations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pT8DIhsJCw": {
    "title": "Parameter-efficient Tuning of Large-scale Multimodal Foundation Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ESCafo3oD5": {
    "title": "PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B4xF1wfQnF": {
    "title": "Optimal Time Complexities of Parallel Stochastic Optimization Methods Under a Fixed Computation Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n18MhTsSGb": {
    "title": "2Direction: Theoretically Faster Distributed Training with Bidirectional Communication Compression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sUqG96QqZM": {
    "title": "Weakly-Supervised Audio-Visual Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7UdVPRmpif": {
    "title": "On student-teacher deviations in distillation: does it pay to disobey?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tmxjuIFSEc": {
    "title": "SPACE: Single-round Participant Amalgamation for Contribution Evaluation in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FdsS51iif3": {
    "title": "PaintSeg: Painting Pixels for Training-free Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sovxUzPzLN": {
    "title": "Unsupervised Semantic Correspondence Using Stable Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0ORqsMY6OL": {
    "title": "Improved Communication Efficiency in Federated Natural Policy Gradient via ADMM-based Gradient Updates",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kXOXrVnwbb": {
    "title": "DaTaSeg: Taming a Universal Multi-Dataset Multi-Task Segmentation Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kRdaTkaBwC": {
    "title": "Inferring Hybrid Neural Fluid Fields from Videos",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Fe6fDq65aZ": {
    "title": "On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JDnLXc4NOn": {
    "title": "Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YhAZqWhOnS": {
    "title": "Autodecoding Latent 3D Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=puupdGOWUp": {
    "title": "GraphPatcher: Mitigating Degree Bias for Graph Neural Networks via Test-time Augmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ypOiXjdfnU": {
    "title": "Emergent Correspondence from Image Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qgmrC8jhCo": {
    "title": "Convolutional Visual Prompt for Robust Visual Perception",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=paa2OU5jN8": {
    "title": "Free-Bloom: Zero-Shot Text-to-Video Generator with LLM Director and LDM Animator",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cslnCXE9XA": {
    "title": "Counterfactual Generation with Identifiability Guarantees",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nqIIWnwe73": {
    "title": "CLIP4HOI: Towards Adapting CLIP for Practical Zero-Shot HOI Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g49s1N5nmO": {
    "title": "Transformers over Directed Acyclic Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J7VoDuzuKs": {
    "title": "Unlocking Feature Visualization for Deep Network with MAgnitude Constrained Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VqIWgUVsXc": {
    "title": "Does Graph Distillation See Like Vision Dataset Counterpart?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n8JWIzYPRz": {
    "title": "Environment-Aware Dynamic Graph Learning for Out-of-Distribution Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tRKimbAk5D": {
    "title": "Modeling Human Visual Motion Processing with Trainable Motion Energy Sensing and a Self-attention Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4UCktT9XZx": {
    "title": "MuSe-GNN: Learning Unified Gene Representation From Multimodal Biological Graph Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Kig2YJVYfq": {
    "title": "Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YsZTDcIQwQ": {
    "title": "Diversifying Spatial-Temporal Perception for Video Domain Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ozc8XVzwd4": {
    "title": "VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BklIgOO76D": {
    "title": "How many samples are needed to leverage smoothness?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8vuDHCxrmy": {
    "title": "OpenMask3D: Open-Vocabulary 3D Instance Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5UwnKSgY6u": {
    "title": "Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=On0IDMYKw2": {
    "title": "Reading Relevant Feature from Global Representation Memory for Visual Object Tracking",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dybrsuNAB9": {
    "title": "GMSF: Global Matching Scene Flow",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6Odmtoek02": {
    "title": "Probabilistic Weight Fixing: Large-scale training of neural network weight uncertainties for quantisation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gpyeRyc858": {
    "title": "Neural Relation Graph: A Unified Framework for Identifying Label Noise and Outlier Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=etYk6TeO2q": {
    "title": "Causal Discovery from Subsampled Time Series with Proxy Variables",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VNyKBipt91": {
    "title": "Federated Learning via Meta-Variational Dropout",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=805CW5w2CY": {
    "title": "A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2DtxPCL3T5": {
    "title": "Learning to Compress Prompts with Gist Tokens",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GrFsx4mBWF": {
    "title": "Demographic Parity Constrained Minimax Optimal Regression under Linear Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uWNqy09dFW": {
    "title": "Learning Neural Implicit through Volume Rendering with Attentive Depth Fusion Priors",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S1KGaTSOTS": {
    "title": "ClusterFomer: Clustering As A Universal Visual Learner",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DmakwvCJ7l": {
    "title": "Data-Centric Learning from Unlabeled Graphs with Diffusion Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qu6Ln7d9df": {
    "title": "Streaming Factor Trajectory Learning for Temporal Tensor Decomposition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6d9Yxttb3w": {
    "title": "Offline Imitation Learning with Variational Counterfactual Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TcG8jhOPdv": {
    "title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8BPzLxF9p5": {
    "title": "Label-efficient Segmentation via Affinity Propagation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Rp4PA0ez0m": {
    "title": "Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=crNAh1EZKo": {
    "title": "No-regret Algorithms for Fair Resource Allocation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XKeSauhUdJ": {
    "title": "DiffUTE: Universal Text Editing Diffusion Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q6zd1hr7sD": {
    "title": "Unified 3D Segmenter As Prototypical Classifiers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m9uHv1Pxq7": {
    "title": "Learning Motion Refinement for Unsupervised Face Animation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hV52oj0Sik": {
    "title": "A Hierarchical Training Paradigm for Antibody Structure-sequence Co-design",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3YDukx2cpr": {
    "title": "Learning Large Graph Property Prediction via Graph Segment Training",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7gbjsgcN5p": {
    "title": "Unsupervised Optical Flow Estimation with Dynamic Timing Representation for Spike Camera",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5TTV5IZnLL": {
    "title": "Variational Inference with Gaussian Score Matching",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hHv3UuffXV": {
    "title": "Block Broyden's Methods for Solving Nonlinear Equations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JYUN0vYjh9": {
    "title": "Joint Attribute and Model Generalization Learning for Privacy-Preserving Action Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dwfHbm8g66": {
    "title": "Deep Patch Visual Odometry",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AlTyimRsLf": {
    "title": "You Only Condense Once: Two Rules for Pruning Condensed Datasets",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YvO5yTVv5Y": {
    "title": "Online Map Vectorization for Autonomous Driving: A Rasterization Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t877958UGZ": {
    "title": "Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iy4Of0w8ML": {
    "title": "GPEX, A Framework For Interpreting Artificial Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xdQpmUPNHC": {
    "title": "Efficient Symbolic Policy Learning with Differentiable Symbolic Expression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=83LJRUzXWj": {
    "title": "Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IrEYkhuxup": {
    "title": "Why Did This Model Forecast This Future? Information-Theoretic Saliency for Counterfactual Explanations of Probabilistic Regression Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=919tWtJPXe": {
    "title": "Self-supervised Object-Centric Learning for Videos",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N6YNe4KxDc": {
    "title": "Online Learning under Adversarial Nonlinear Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HMqGYxnlpv": {
    "title": "A Simple Yet Effective Strategy to Robustify the Meta Learning Paradigm",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zfHCKDzzC8": {
    "title": "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OFMPrCAMKi": {
    "title": "Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=62zmO4mv8X": {
    "title": "Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=loxinzXlCx": {
    "title": "A Computation and Communication Efficient Method for Distributed Nonconvex Problems in the Partial Participation Setting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xax5eWeObb": {
    "title": "Practical Equivariances via Relational Conditional Neural Processes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WbFhFvjjKj": {
    "title": "Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8ZveVHfmIE": {
    "title": "On the Convergence of Encoder-only Shallow Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2gUCMr6fDY": {
    "title": "TopP&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s8QsYV1VZ2": {
    "title": "AND: Adversarial Neural Degradation for Learning Blind Image Super-Resolution",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mZ3hnyL9bS": {
    "title": "Towards the Difficulty for a Deep Neural Network to Learn Concepts of Different Complexities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YOZaej0ZC7": {
    "title": "On Measuring Fairness in Generative Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gaktiSjatl": {
    "title": "Semi-Implicit Denoising Diffusion Models (SIDDMs)",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m7PIJWOdlY": {
    "title": "Characterizing Graph Datasets for Node Classification: Homophily-Heterophily Dichotomy and Beyond",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dqS1GuoG2V": {
    "title": "The Memory-Perturbation Equation: Understanding Model's Sensitivity to Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HGFcM3UU50": {
    "title": "Aligning Language Models with Human Preferences via a Bayesian Approach",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sf3t6Bth4P": {
    "title": "Enhancing Sharpness-Aware Optimization Through Variance Suppression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4R2Y5B12jm": {
    "title": "CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image Steganography",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Rcit6V3vus": {
    "title": "GenS: Generalizable Neural Surface Reconstruction from Multi-View Images",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lzqaQRsITh": {
    "title": "DiffComplete: Diffusion-based Generative 3D Shape Completion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vO6ZdPWaHc": {
    "title": "Data Pruning via Moving-one-Sample-out",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZwQJRXLjVm": {
    "title": "Rehearsal Learning for Avoiding Undesired Future",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DVm0xxaEq1": {
    "title": "AiluRus: A Scalable ViT Framework for Dense Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jcJVgIFY2r": {
    "title": "Generator Born from Classifier",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lSbbC2VyCu": {
    "title": "Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9kFQEJSyCM": {
    "title": "RangePerception: Taming LiDAR Range View for Efficient and Accurate 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3ofe0lpwQP": {
    "title": "DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X4mmXQ4Nxw": {
    "title": "Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mbaN0Y0QTw": {
    "title": "SEENN: Towards Temporal Spiking Early Exit Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TTkklyFv7e": {
    "title": "NAP: Neural 3D Articulated Object Prior",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UHBrWeFWlL": {
    "title": "Segment Everything Everywhere All at Once",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5sV53leJCv": {
    "title": "Module-wise Training of Neural Networks via the Minimizing Movement Scheme",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9lygTqLdWn": {
    "title": "Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and Motion Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zqyVjCjhYD": {
    "title": "The expressive power of pooling in Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uAyElhYKxg": {
    "title": "(S)GD over Diagonal Linear Networks: Implicit bias, Large Stepsizes and Edge of Stability",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hOOOvOMok5": {
    "title": "Rubik's Cube: High-Order Channel Interactions with a Hierarchical Receptive Field",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QRWA5nTWuM": {
    "title": "Networks are Slacking Off: Understanding Generalization Problem in Image Deraining",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OoPLRGBKjM": {
    "title": "Semantic Image Synthesis with Unconditional Generator",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ChGGbmTNgE": {
    "title": "When Visual Prompt Tuning Meets Source-Free Domain Adaptive Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RuxBLfiEqI": {
    "title": "Diversified Outlier Exposure for Out-of-Distribution Detection via Informative Extrapolation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XvfEYqEbIb": {
    "title": "Non-Rigid Shape Registration via Deep Functional Maps Prior",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9FmolyOHi5": {
    "title": "Spike-driven Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F6j16Qr6Vk": {
    "title": "Toward Better PAC-Bayes Bounds for Uniformly Stable Algorithms",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nXPqMyWUnx": {
    "title": "Mitigating Source Bias for Fairer Weak Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dHQ2av9NzO": {
    "title": "On the Convergence of Black-Box Variational Inference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gaXAjtHic2": {
    "title": "On Private and Robust Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OtU6VvXJue": {
    "title": "Learning to Augment Distributions for Out-of-distribution Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8jg8z3ASiw": {
    "title": "Closing the Computational-Statistical Gap in Best Arm Identification for Combinatorial Semi-bandits",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QlHosp050r": {
    "title": "Weakly-Supervised Concealed Object Segmentation with SAM-based Pseudo Labeling and Multi-scale Feature Grouping",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QW5ouyyIgG": {
    "title": "CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j7U4pFkCYB": {
    "title": "DynPoint: Dynamic Neural Point For View Synthesis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8SCz56sUGP": {
    "title": "Real-World Image Super-Resolution as Multi-Task Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cAyLnMxiTl": {
    "title": "Enhancing Motion Deblurring in High-Speed Scenes with Spike Streams",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ayZpFoAu5c": {
    "title": "On the Ability of Graph Neural Networks to Model Interactions Between Vertices",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5GmTI4LNqX": {
    "title": "Strong and Precise Modulation of Human Percepts via Robustified ANNs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ghzEUGfRMD": {
    "title": "Scaling Laws for Hyperparameter Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DAKAkMhjSR": {
    "title": "A Smooth Binary Mechanism for Efficient Private Continual Observation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WqiZJGNkjn": {
    "title": "MotionGPT: Human Motion as a Foreign Language",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UAFa5ZhR85": {
    "title": "Unsupervised Graph Neural Architecture Search with Disentangled Self-Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VpCjozUOM2": {
    "title": "Chanakya: Learning Runtime Decisions for Adaptive Real-Time Perception",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h3QNH3qeC3": {
    "title": "Customizable Image Synthesis with Multiple Subjects",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=82HeVCqsfh": {
    "title": "Expanding Small-Scale Datasets with Guided Imagination",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mxhb2lCOKL": {
    "title": "Mitigating Test-Time Bias for Fair Image Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZPj7ey5fXa": {
    "title": "PyNeRF: Pyramidal Neural Radiance Fields",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jU9qiRMDtR": {
    "title": "SPRING: Studying Papers and Reasoning to play Games",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qP0Drg2HuH": {
    "title": "Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NIrTSCiIZ7": {
    "title": "Boundary Guided Learning-Free Semantic Control with Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FYqqvQdXhZ": {
    "title": "StyleGAN knows Normal, Depth, Albedo, and More",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nwK8UkK3uB": {
    "title": "Variational Gaussian Processes with Decoupled Conditionals",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Rvk1wdwz1L": {
    "title": "Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=95q46MpBGZ": {
    "title": "Generalizable One-shot 3D Neural Head Avatar",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qyixBZl8Ph": {
    "title": "Global Update Tracking: A Decentralized Learning Algorithm for Heterogeneous Data",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D0MII7rP3R": {
    "title": "Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NyQwBttTnG": {
    "title": "Information Design in Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1DmP6ySKYq": {
    "title": "HeadSculpt: Crafting 3D Head Avatars with Text",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=87Qnneer8l": {
    "title": "Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fW5ZUSVTkv": {
    "title": "Learning Domain-Aware Detection Head with Prompt Tuning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h3CGHf7457": {
    "title": "Multi-modal Queried Object Detection in the Wild",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lRu0dN7BY6": {
    "title": "Social Motion Prediction with Cognitive Hierarchies",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rUldfB4SPT": {
    "title": "PRED: Pre-training via Semantic Rendering on LiDAR Point Clouds",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4vpsQdRBlK": {
    "title": "Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UdrybSp67L": {
    "title": "When can Regression-Adjusted Control Variate Help? Rare Events, Sobolev Embedding and Minimax Optimality",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pQvAL40Cdj": {
    "title": "Detecting Any Human-Object Interaction Relationship: Universal HOI Detector with Spatial Prompt Learning on Foundation Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2rq4LwwjfE": {
    "title": "What Do Deep Saliency Models Learn about Visual Attention?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tp2nEZ5zfP": {
    "title": "NetHack is Hard to Hack",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mSDfBXr8Py": {
    "title": "The Rise of AI Language Pathologists: Exploring Two-level Prompt Learning for Few-shot Weakly-supervised Whole Slide Image Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KRlG7NJUCD": {
    "title": "DAW: Exploring the Better Weighting Function for Semi-supervised Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pcKwgdVAlq": {
    "title": "Binarized Spectral Compressive Imaging",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hxJu0386if": {
    "title": "Focus on Query: Adversarial Mining Transformer for Few-Shot Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=29WbraPk8U": {
    "title": "Sharpness-Aware Minimization Leads to Low-Rank Features",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=25HiFHPcXg": {
    "title": "CAPro: Webly Supervised Learning with Cross-modality Aligned Prototypes",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nSgMh5v5Ne": {
    "title": "Shape Non-rigid Kinematics (SNK): A Zero-Shot Method for Non-Rigid Shape Matching via Unsupervised Functional Map Regularized Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oaGdsgB18L": {
    "title": "TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning over Temporal Knowledge Graph",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s7xWeJQACI": {
    "title": "Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YbYQ0JEQ80": {
    "title": "BiMatting: Efficient Video Matting via Binarization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RA7ND878XP": {
    "title": "Segment Anything in High Quality",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ke3RgcDmfO": {
    "title": "TextDiffuser: Diffusion Models as Text Painters",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UjtiLdXGMC": {
    "title": "LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U4pFV192JQ": {
    "title": "Masked Two-channel Decoupling Framework for Incomplete Multi-view Weak Multi-label Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YdfcKb4Wif": {
    "title": "Learning Trajectories are Generalization Indicators",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LZzsn51DPr": {
    "title": "Echoes Beyond Points: Unleashing the Power of Raw Radar Data in Multi-modality Fusion",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AMIJEupsNq": {
    "title": "3D-Aware Visual Question Answering about Parts, Poses and Occlusions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KTfAtro6vP": {
    "title": "Reinforcement Learning with Fast and Forgetful Memory",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MJbDy2155j": {
    "title": "Bridging the Domain Gap: Self-Supervised 3D Scene Understanding with Foundation Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bn4qZxltsH": {
    "title": "Hierarchical Open-vocabulary Universal Image Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SHyVaWGTO4": {
    "title": "Unlocking Deterministic Robustness Certification on ImageNet",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dsH244r9fA": {
    "title": "Counterfactual-Augmented Importance Sampling for Semi-Offline Policy Evaluation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2BrHBj1Puu": {
    "title": "ISP: Multi-Layered Garment Draping with Implicit Sewing Patterns",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5ytypAqAsR": {
    "title": "No Representation Rules Them All in Category Discovery",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XXPzBhOs4f": {
    "title": "Have it your way: Individualized Privacy Assignment for DP-SGD",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u6Xv3FuF8N": {
    "title": "Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NfpYgGZC3B": {
    "title": "Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k6yNi6DEqK": {
    "title": "L2T-DLN: Learning to Teach with Dynamic Loss Network",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZfFR4d5gUM": {
    "title": "Leveraging the two-timescale regime to demonstrate convergence of neural networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Grz2ijKrWI": {
    "title": "STXD: Structural and Temporal Cross-Modal Distillation for Multi-View 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oyFyOPZUCs": {
    "title": "Language-based Action Concept Spaces Improve Video Self-Supervised Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nIaNgaQvsV": {
    "title": "PromptRestorer: A Prompting Image Restoration Method with Degradation Perception",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1WpmOipyYI": {
    "title": "Tanh Works Better with Asymmetry",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VvnfMeC3gQ": {
    "title": "RevColV2: Exploring Disentangled Representations in Masked Image Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bo5oIoL95U": {
    "title": "Active Reasoning in an Open-World Environment",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zuXyQsXVLF": {
    "title": "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VUlYp3jiEI": {
    "title": "Understanding the Latent Space of Diffusion Models through the Lens of Riemannian Geometry",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yThjbzhIUP": {
    "title": "PGDiff: Guiding Diffusion Models for Versatile Face Restoration via Partial Guidance",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CLjBBd8u2j": {
    "title": "Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rfTFJvTkr2": {
    "title": "Parallel Spiking Neurons with High Efficiency and Ability to Learn Long-term Dependencies",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tfyr2zRVoK": {
    "title": "SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Se71ks7Mfz": {
    "title": "DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zD6lXmTPPh": {
    "title": "A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SVjDiiVySh": {
    "title": "Improving CLIP Training with Language Rewrites",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xpjsOQtKqx": {
    "title": "StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=alLs7EtRJP": {
    "title": "Factorized Contrastive Learning: Going Beyond Multi-view Redundancy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J1gBijopla": {
    "title": "Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BbIxB4xnbq": {
    "title": "LANCE: Stress-testing Visual Models by Generating Language-guided Counterfactual Images",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nbG6zfJtIe": {
    "title": "Learning Curves for Deep Structured Gaussian Feature Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZVRG3toCTT": {
    "title": "Beyond Confidence: Reliable Models Should Also Consider Atypicality",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xx3QgKyghS": {
    "title": "Unsupervised Polychromatic Neural Representation for CT Metal Artifact Reduction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j2oYaFpbrB": {
    "title": "Active Vision Reinforcement Learning under Limited Visual Observability",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pQF9kbM8Ea": {
    "title": "Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MIYBTjCVjR": {
    "title": "Sequential Preference Ranking for Efficient Reinforcement Learning from Human Feedback",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fcYObrixSS": {
    "title": "LEPARD: Learning Explicit Part Discovery for 3D Articulated Shape Reconstruction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xTgM7XLN9P": {
    "title": "Compact Neural Volumetric Video Representations with Dynamic Codebooks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AALLvnv95q": {
    "title": "Training Energy-Based Normalizing Flow with Score-Matching Objectives",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jzseUq55eP": {
    "title": "Metropolis Sampling for Constrained Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jB4wsc1DQW": {
    "title": "Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iPTF2hON1C": {
    "title": "Learning To Dive In Branch And Bound",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BxqPN7KuQS": {
    "title": "Lookup Table meets Local Laplacian Filter: Pyramid Reconstruction Network for Tone Mapping",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x5JCDCvR4b": {
    "title": "Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v1VVKaMYbk": {
    "title": "H2RBox-v2: Incorporating Symmetry for Boosting Horizontal Box Supervised Oriented Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Akslsk891N": {
    "title": "Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W2ZBLdfa16": {
    "title": "PolyDiffuse: Polygonal Shape Reconstruction via Guided Set Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VhcsIxVEd9": {
    "title": "DropPos: Pre-Training Vision Transformers by Reconstructing Dropped Positions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=elPtHcfjpH": {
    "title": "LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y17N9B0vXn": {
    "title": "Towards Higher Ranks via Adversarial Weight Pruning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9Muli2zoFn": {
    "title": "Optimal Transport-Guided Conditional Score-Based Diffusion Model",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bx0SDRVDzF": {
    "title": "Natural Language Instruction-following with Task-related Language Development and Translation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8JMexYVcXB": {
    "title": "DAC-DETR: Divide the Attention Layers and Conquer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KtHquQuyA5": {
    "title": "IDRNet: Intervention-Driven Relation Network for Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v2oGdhbKxi": {
    "title": "MonoUNI: A Unified Vehicle and Infrastructure-side Monocular 3D Object Detection Network with Sufficient Depth Clues",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KTR33hMnMX": {
    "title": "Aligning Optimization Trajectories with Diffusion Models for Constrained Design Generation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RMeQjexaRj": {
    "title": "Elastic Decision Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P5vzRpoOj2": {
    "title": "Temporal Robustness against Data poisoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uFlE0qgtRO": {
    "title": "Focus Your Attention when Few-Shot Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AV3iZlDrzF": {
    "title": "Enhancing User Intent Capture in Session-Based Recommendation with Attribute Patterns",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KipjqOPaZ0": {
    "title": "An Information Theory Perspective on Variance-Invariance-Covariance Regularization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EcN3l6Xmnx": {
    "title": "Learning Time-Invariant Representations for Individual Neurons from Population Dynamics",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eGoE9CVRPc": {
    "title": "RGMIL: Guide Your Multiple-Instance Learning Model with Regressor",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9EndFTDiqh": {
    "title": "Should We Learn Most Likely Functions or Parameters?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ESEM1lNoeS": {
    "title": "Open-Vocabulary Semantic Segmentation via Attribute Decomposition-Aggregation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ECvtxmVP0x": {
    "title": "Visual Explanations of Image-Text Representations via Multi-Modal Information Bottleneck Attribution",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tScBQRNgjk": {
    "title": "ForecastPFN: Synthetically-Trained Zero-Shot Forecasting",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dbaxm9ujq6": {
    "title": "How2comm: Communication-Efficient and Collaboration-Pragmatic Multi-Agent Perception",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5UXXhVI08r": {
    "title": "Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OvPnc5kVsb": {
    "title": "Importance-aware Co-teaching for Offline Model-based Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tJwyg9Zg9G": {
    "title": "Parallel-mentoring for Offline Model-based Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YWSOpYjyG4": {
    "title": "Predicting a Protein's Stability under a Million Mutations",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xu8aG5Q8M3": {
    "title": "LayoutGPT: Compositional Visual Planning and Generation with Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rJc5Lsn5QU": {
    "title": "ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image Collections",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RJq9bVEf6N": {
    "title": "Symbol-LLM: Leverage Language Models for Symbolic System in Visual Human Activity Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h2lkx9SQCD": {
    "title": "Faster Differentially Private Convex Optimization via Second-Order Methods",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zdli6OxpWd": {
    "title": "Counting Distinct Elements Under Person-Level Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xtQ9IGRzIW": {
    "title": "Faster Discrete Convex Function Minimization with Predictions: The M-Convex Case",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kmbG9iBRIb": {
    "title": "Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OlMKa5YZ8e": {
    "title": "KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  }
}