{
  "https://openreview.net/forum?id=M4222IBHsh": {
    "title": "Function Basis Encoding of Numerical Features in Factorization Machines",
    "volume": "main",
    "abstract": "Factorization machine (FM) variants are widely used for large scale real-time content recommendation systems, since they offer an excellent balance between model accuracy and low computational costs for training and inference. These systems are trained on tabular data with both numerical and categorical columns. Incorporating numerical columns poses a challenge, and they are typically incorporated using a scalar transformation or binning, which can be either learned or arbitrarily chosen. In this work, we provide a systematic and theoretically-justified way to incorporate numerical features into FM variants by encoding them into a vector of function values for a set of functions of one's choice. We view FMs as approximators of segmentized functions, namely, functions from a field's value to the real numbers, assuming the remaining fields are assigned some given constants, which we refer to as the segment. From this perspective, we show that our technique yields a model that learns segmentized functions of the numerical feature spanned by the set of functions of one's choice, namely, the spanning coefficients vary between segments. Hence, to improve model accuracy we advocate the use of functions known to have powerful approximation capabilities, and offer the B-Spline basis due to its well-known approximation power, widespread availability in software libraries and its efficiency in terms of computational resources and memory usage. Our technique preserves fast training and inference, and requires only a small modification of the computational graph of an FM model. Therefore, incorporating it into an existing system to improve its performance is easy. Finally, we back our claims with a set of experiments that include a synthetic experiment, performance evaluation on several data-sets, and an A/B test on a real online advertising system which shows improved performance. We have made the code to reproduce the experiments available at https://github.com/alexshtf/cont_features_paper",
    "checked": true,
    "id": "db67afe5e4319fa0494fa2d9673c179bef7e20cf",
    "semantic_title": "function basis encoding of numerical features in factorization machines",
    "citation_count": 0,
    "authors": [
      "Alex Shtoff",
      "Elie Abboud",
      "Rotem Stram",
      "Oren Somekh"
    ]
  },
  "https://openreview.net/forum?id=BsMMc4MEGS": {
    "title": "CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark",
    "volume": "main",
    "abstract": "AI agents have the potential to aid users on a variety of consequential tasks, including conducting scientific research. To spur the development of useful agents, we need benchmarks that are challenging, but more crucially, directly correspond to real-world tasks of interest. This paper introduces such a benchmark, designed to measure the accuracy of AI agents in tackling a crucial yet surprisingly challenging aspect of scientific research: computational reproducibility. This task, fundamental to the scientific process, involves reproducing the results of a study using the provided code and data. We introduce CORE-Bench (Computational Reproducibility Agent Benchmark), a benchmark consisting of 270 tasks based on 90 scientific papers across three disciplines (computer science, social science, and medicine). Tasks in CORE-Bench consist of three difficulty levels and include both language-only and vision-language tasks. We provide an evaluation system to measure the accuracy of agents in a fast and parallelizable way, saving days of evaluation time for each run compared to a sequential implementation. We evaluated two baseline agents: the general-purpose AutoGPT and a task-specific agent called CORE-Agent. We tested both variants using two underlying language models: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 19% on the hardest level of tasks, showing the vast scope for improvement in automating routine scientific tasks. Having agents that can reproduce existing work is a necessary step toward building agents that can conduct novel research and could verify and improve the performance of other research agents. We hope that CORE-Bench can improve the state of reproducibility and spur the development of future research agents",
    "checked": true,
    "id": "4c913d59d150fe7581386b87dfd9f90448a9adee",
    "semantic_title": "core-bench: fostering the credibility of published research through a computational reproducibility agent benchmark",
    "citation_count": 15,
    "authors": [
      "Zachary S Siegel",
      "Sayash Kapoor",
      "Nitya Nadgir",
      "Benedikt Stroebl",
      "Arvind Narayanan"
    ]
  },
  "https://openreview.net/forum?id=xpBHp9WFvk": {
    "title": "Graph Pooling via Ricci Flow",
    "volume": "main",
    "abstract": "Graph Machine Learning often involves the clustering of nodes based on similarity structure encoded in the graph's topology and the nodes' attributes. On homophilous graphs, the integration of pooling layers has been shown to enhance the performance of Graph Neural Networks by accounting for inherent multi-scale structure. Here, similar nodes are grouped together to coarsen the graph and reduce the input size in subsequent layers in deeper architectures. In both settings, the underlying clustering approach can be implemented via graph pooling operators, which often rely on classical tools from Graph Theory. In this work, we introduce a graph pooling operator (ORC-Pool), which utilizes a characterization of the graph's geometry via Ollivier's discrete Ricci curvature and an associated geometric flow. Previous Ricci flow based clustering approaches have shown great promise across several domains, but are by construction unable to account for similarity structure encoded in the node attributes. However, in many ML applications, such information is vital for downstream tasks. ORC-Pool extends such clustering approaches to attributed graphs, allowing for the integration of geometric coarsening into Graph Neural Networks as a pooling layer",
    "checked": true,
    "id": "bf00ec7fb2bd579cd86a431f718b27b661e9e6b9",
    "semantic_title": "graph pooling via ricci flow",
    "citation_count": 3,
    "authors": [
      "Amy Feng",
      "Melanie Weber"
    ]
  },
  "https://openreview.net/forum?id=q7YXEbFOAt": {
    "title": "$\\clubsuit$ CLOVER $\\clubsuit$: Probabilistic Forecasting with Coherent Learning Objective Reparameterization",
    "volume": "main",
    "abstract": "Obtaining accurate probabilistic forecasts is an operational challenge in many applications, such as energy management, climate forecasting, supply chain planning, and resource allocation. Many of these applications present a natural hierarchical structure over the forecasted quantities; and forecasting systems that adhere to this hierarchical structure are said to be coherent. Furthermore, operational planning benefits from the accuracy at all levels of the aggregation hierarchy. However, building accurate and coherent forecasting systems is challenging: classic multivariate time series tools and neural network methods are still being adapted for this purpose. In this paper, we augment an MQForecaster neural network architecture with a modified multivariate Gaussian factor model that achieves coherence by construction. The factor model samples can be differentiated with respect to the model parameters, allowing optimization on arbitrary differentiable learning objectives that align with the forecasting system's goals, including quantile loss and the scaled Continuous Ranked Probability Score (CRPS). We call our method the Coherent Learning Objective Reparametrization Neural Network (CLOVER). In comparison to state-of-the-art coherent forecasting methods, CLOVER achieves significant improvements in scaled CRPS forecast accuracy, with average gains of 15%, as measured on six publicly-available datasets",
    "checked": true,
    "id": "281621d1a0df39322ef203f699e04afd619534cf",
    "semantic_title": "$\\clubsuit$ clover $\\clubsuit$: probabilistic forecasting with coherent learning objective reparameterization",
    "citation_count": 0,
    "authors": [
      "Kin G. Olivares",
      "Geoffrey NÃ©giar",
      "Ruijun Ma",
      "Oinam Nganba Meetei",
      "Mengfei Cao",
      "Michael W. Mahoney"
    ]
  },
  "https://openreview.net/forum?id=H6ChfpM31L": {
    "title": "A persistent homology-based algorithm for unsupervised anomaly detection in time series",
    "volume": "main",
    "abstract": "In this article, we propose a new algorithm for unsupervised anomaly detection in univariate time series, based on topological data analysis. It relies on delay embeddings and on the extraction of persistent cycles from the 1-dimensional persistent homology constructed from the distance to measure Rips filtration. This filtration makes it possible to identify 1-cycles (i.e. loops) corresponding to recurrent patterns by leveraging density information. Points in those cycles are considered as normal, and the algorithm can then assign an anomaly score to any point which is its distance to the normal set. In this paper, we describe the algorithm, make a theoretical study, and test it on several real-world and synthetic datasets, showing that it is competitive with state-of-the-art anomaly detection methods",
    "checked": true,
    "id": "aa88612453f7e39cd2cc9369e997984c7da581f9",
    "semantic_title": "a persistent homology-based algorithm for unsupervised anomaly detection in time series",
    "citation_count": 0,
    "authors": [
      "Alexandre Bois",
      "Brian Tervil",
      "Laurent Oudre"
    ]
  },
  "https://openreview.net/forum?id=Y9kAsYIjYc": {
    "title": "Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web",
    "volume": "main",
    "abstract": "Language model agents (LMA) recently emerged as a promising paradigm on muti-step decision making tasks, often outperforming humans and other reinforcement learning agents. Despite the promise, their performance on real-world applications that often involve combinations of tasks is still underexplored. In this work, we introduce a new benchmark, called CompWoB -- 50 new compositional web automation tasks reflecting more realistic assumptions. We show that while existing prompted LMAs (gpt-3.5-turbo or gpt-4) achieve 94.0% average success rate on base tasks, their performance degrades to 24.9% success rate on compositional tasks. On the other hand, transferred LMAs (finetuned only on base tasks) show less generalization gap, dropping from 85.4% to 54.8%. By balancing data distribution across tasks, we train a new model, HTML-T5++, that surpasses human-level performance (95.2%) on MiniWoB, and achieves the best zero-shot performance on CompWoB (61.5%). While these highlight the promise of small-scale finetuned and transferred models for task compositionality, their performance further degrades under different instruction compositions changing combinational order. In contrast to the recent remarkable success of LMA, our benchmark and detailed analysis emphasize the necessity of building LMAs that are robust and generalizable to task compositionality for real-world deployment",
    "checked": true,
    "id": "7492ef863cd376420de462dd1f041abb91172530",
    "semantic_title": "exposing limitations of language model agents in sequential-task compositions on the web",
    "citation_count": 16,
    "authors": [
      "Hiroki Furuta",
      "Yutaka Matsuo",
      "Aleksandra Faust",
      "Izzeddin Gur"
    ]
  },
  "https://openreview.net/forum?id=JBveijn2OO": {
    "title": "AutoDocSegmenter: A Geometric Approach towards Self-Supervised Document Segmentation",
    "volume": "main",
    "abstract": "Document segmentation, the process of dividing a document into coherent and significant regions, plays a crucial role for diverse applications that require parsing, retrieval, and categorization. However, most existing methods rely on supervised learning, which requires large-scale labeled datasets that are costly and time-consuming to obtain. In this work, we propose a novel self-supervised framework for document segmentation that does not require labeled data. Our framework consists of two components: (1) an unsupervised isothetic covers based pseudo mask generator which approximately segments document objects, and (2) an encoder-decoder network that learns to refine the pseudo masks and segments the document objects accurately. Our approach can handle diverse and intricate document layouts by leveraging the rich information from unlabeled datasets. We demonstrate the effectiveness of our approach on several benchmarks, where it outperforms state-of-the-art document segmentation methods. Our code is available at https://github.com/ankitachatterjee94/AutoDocSegmenter",
    "checked": true,
    "id": "ad237bb2caac9040bc9b1db1f28365c78770c3d4",
    "semantic_title": "autodocsegmenter: a geometric approach towards self-supervised document segmentation",
    "citation_count": 0,
    "authors": [
      "Ankita Chatterjee",
      "Anjali Raj",
      "Soumyadeep Dey",
      "Pratik Jawanpuria",
      "Jayanta Mukhopadhyay",
      "Partha Pratim Das"
    ]
  },
  "https://openreview.net/forum?id=fmKJfbGKFC": {
    "title": "Do Parameters Reveal More than Loss for Membership Inference?",
    "volume": "main",
    "abstract": "Membership inference attacks aim to infer whether an individual record was used to train a model. They are used as a key tool for disclosure auditing. While such evaluations are useful to demonstrate risk, they are computationally expensive and often make strong assumptions about potential adversaries' access to models and training environments, and thus do not provide very tight bounds on leakage from potential attacks. We show how prior claims around black-box access being sufficient for optimal membership inference do not hold for stochastic gradient descent, and that optimal membership inference indeed requires white-box access. Our theoretical results suggest a new white-box inference attack IHA (Inverse Hessian Attack) that explicitly uses model parameters by taking advantage of computing inverse-Hessian vector products. Our results show that both auditors and adversaries may be able to benefit from access to model parameters, and we advocate for further research into white-box methods for membership privacy auditing",
    "checked": true,
    "id": "7bcdd669cfc4d1adb63b256bc47c1c728a518912",
    "semantic_title": "do parameters reveal more than loss for membership inference?",
    "citation_count": 1,
    "authors": [
      "Anshuman Suri",
      "Xiao Zhang",
      "David Evans"
    ]
  },
  "https://openreview.net/forum?id=zZFb1aDUeE": {
    "title": "Privacy Preserving Reinforcement Learning for Population Processes",
    "volume": "main",
    "abstract": "We consider the problem of privacy protection in Reinforcement Learning (RL) algorithms that operate over population processes, a practical but understudied setting that includes, for example, the control of epidemics in large populations of dynamically interacting individuals. In this setting, the RL algorithm interacts with the population over $T$ time steps by receiving population-level statistics as state and performing actions which can affect the entire population at each time step. An individual's data can be collected across multiple interactions and their privacy must be protected at all times. We clarify the Bayesian semantics of Differential Privacy (DP) in the presence of correlated data in population processes through a Pufferfish Privacy analysis. We then give a meta algorithm that can take any RL algorithm as input and make it differentially private. This is achieved by taking an approach that uses DP mechanisms to privatize the state and reward signal at each time step before the RL algorithm receives them as input. Our main theoretical result shows that the value-function approximation error when applying standard RL algorithms directly to the privatized states shrinks quickly as the population size and privacy budget increase. This highlights that reasonable privacy-utility trade-offs are possible for differentially private RL algorithms in population processes. Our theoretical findings are validated by experiments performed on a simulated epidemic control problem over large population sizes",
    "checked": true,
    "id": "629ded516d732a3157e5526d232c7ea9953ac4c9",
    "semantic_title": "privacy preserving reinforcement learning for population processes",
    "citation_count": 1,
    "authors": [
      "Samuel Yang-Zhao",
      "Kee Siong Ng"
    ]
  },
  "https://openreview.net/forum?id=y8DSGN5nuN": {
    "title": "FlexEControl: Flexible and Efficient Multimodal Control for Text-to-Image Generation",
    "volume": "main",
    "abstract": "Controllable text-to-image (T2I) diffusion models generate images conditioned on both text prompts and semantic inputs of other modalities like edge maps. Nevertheless, current controllable T2I methods commonly face challenges related to efficiency and faithfulness, especially when conditioning on multiple inputs from either the same or diverse modalities. In this paper, we propose a novel Flexible and Efficient method, FlexEControl, for controllable T2I generation. At the core of FlexEControl is a unique weight decomposition strategy, which allows for streamlined integration of various input types. This approach not only enhances the faithfulness of the generated image to the control, but also significantly reduces the computational overhead typically associated with multimodal conditioning. Our approach achieves a reduction of 41% in trainable parameters and 30% in memory usage compared with Uni-ControlNet. Moreover, it doubles data efficiency and can flexibly generate images under the guidance of multiple input conditions of various modalities",
    "checked": true,
    "id": "ed310ef5cb4c2d399fc1ed2988188247e6e17d46",
    "semantic_title": "flexecontrol: flexible and efficient multimodal control for text-to-image generation",
    "citation_count": 1,
    "authors": [
      "Xuehai He",
      "Jian Zheng",
      "Jacob Zhiyuan Fang",
      "Robinson Piramuthu",
      "Mohit Bansal",
      "Vicente Ordonez",
      "Gunnar A Sigurdsson",
      "Nanyun Peng",
      "Xin Eric Wang"
    ]
  },
  "https://openreview.net/forum?id=fFVuo4SPfT": {
    "title": "Gradient-guided discrete walk-jump sampling for biological sequence generation",
    "volume": "main",
    "abstract": "In this work, we propose gradient-guided discrete walk-jump sampling (gg-dWJS), a novel discrete sequence generation method for biological sequence optimization. Leveraging gradient guidance in the noisy manifold, we sample from the smoothed data manifold by applying discretized Markov chain Monte Carlo (MCMC) using a denoising model with the gradient-guidance from a discriminative model. This is followed by jumping to the discrete data manifold using a conditional one-step denoising. We showcase our method in two different modalities: discrete image and biological sequence involving antibody and peptide sequence generation tasks in the single objective and multi-objective setting. Through evaluation on these tasks, we show that our method generates high-quality samples that are well-optimized for specific tasks",
    "checked": true,
    "id": "94a9d341afc3afd9f80377b91c4971c698b2018d",
    "semantic_title": "gradient-guided discrete walk-jump sampling for biological sequence generation",
    "citation_count": 1,
    "authors": [
      "Zarif Ikram",
      "Dianbo Liu",
      "M Saifur Rahman"
    ]
  },
  "https://openreview.net/forum?id=950naKZIyh": {
    "title": "Beyond Labeling Oracles - What does it mean to steal ML models?",
    "volume": "main",
    "abstract": "Model extraction attacks are designed to steal trained models with only query access, as is often provided through APIs that ML-as-a-Service providers offer. Machine Learning (ML) models are expensive to train, in part because data is hard to obtain, and a primary incentive for model extraction is to acquire a model while incurring less cost than training from scratch. Literature on model extraction commonly claims or presumes that the attacker is able to save on both data acquisition and labeling costs. We thoroughly evaluate this assumption and find that the attacker often does not. This is because current attacks implicitly rely on the adversary being able to sample from the victim model's data distribution. We thoroughly research factors influencing the success of model extraction. We discover that prior knowledge of the attacker, i.e., access to in-distribution data, dominates other factors like the attack policy the adversary follows to choose which queries to make to the victim model API. Our findings urge the community to redefine the adversarial goals of ME attacks as current evaluation methods misinterpret the ME performance",
    "checked": false,
    "id": "cc104c1c3daa07e298220c42eaf01dc24ff0c15a",
    "semantic_title": "beyond labeling oracles: what does it mean to steal ml models?",
    "citation_count": 4,
    "authors": [
      "Avital Shafran",
      "Ilia Shumailov",
      "Murat A Erdogdu",
      "Nicolas Papernot"
    ]
  },
  "https://openreview.net/forum?id=qZqUFeTtuI": {
    "title": "Statistical Mechanics of Min-Max Problems",
    "volume": "main",
    "abstract": "Min-max optimization problems, also known as saddle point problems, have attracted significant attention due to their applications in various fields, such as fair beamforming, generative adversarial networks (GANs), and adversarial learning. However, understanding the properties of these min-max problems has remained a substantial challenge. This study introduces a statistical mechanical formalism for analyzing the equilibrium values of min-max problems in the high-dimensional limit, while appropriately addressing the order of operations for min and max. As a first step, we apply this formalism to bilinear min-max games and simple GANs, deriving the relationship between the amount of training data and generalization error and indicating the optimal ratio of fake to real data for effective learning. This formalism provides a groundwork for a deeper theoretical analysis of the equilibrium properties in various machine learning methods based on min-max problems and encourages the development of new algorithms and architectures",
    "checked": true,
    "id": "1a38c656bad4f6404e240c4b23e2fe0c49fea074",
    "semantic_title": "statistical mechanics of min-max problems",
    "citation_count": 1,
    "authors": [
      "Yuma Ichikawa",
      "Koji Hukushima"
    ]
  },
  "https://openreview.net/forum?id=whGzYUbIWA": {
    "title": "Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields",
    "volume": "main",
    "abstract": "Understanding the interactions of atoms such as forces in 3D atomistic systems is fundamental to many applications like molecular dynamics and catalyst design. However, simulating these interactions requires compute-intensive ab initio calculations and thus results in limited data for training neural networks. In this paper, we propose to use denoising non-equilibrium structures (DeNS) as an auxiliary task to better leverage training data and improve performance. For training with DeNS, we first corrupt a 3D structure by adding noise to its 3D coordinates and then predict the noise. Different from previous works on denoising, which are limited to equilibrium structures, the proposed method generalizes denoising to a much larger set of non-equilibrium structures. The main difference is that a non-equilibrium structure does not correspond to local energy minima and has non-zero forces, and therefore it can have many possible atomic positions compared to an equilibrium structure. This makes denoising non-equilibrium structures an ill-posed problem since the target of denoising is not uniquely defined. Our key insight is to additionally encode the forces of the original non-equilibrium structure to specify which non-equilibrium structure we are denoising. Concretely, given a corrupted non-equilibrium structure and the forces of the original one, we predict the non-equilibrium structure satisfying the input forces instead of any arbitrary structures. Since DeNS requires encoding forces, DeNS favors equivariant networks, which can easily incorporate forces and other higher-order tensors in node embeddings. We study the effectiveness of training equivariant networks with DeNS on OC20, OC22 and MD17 datasets and demonstrate that DeNS can achieve new state-of-the-art results on OC20 and OC22 and significantly improve training efficiency on MD17",
    "checked": true,
    "id": "54e908a0589c78421ffc476d2674c5007d010ba1",
    "semantic_title": "generalizing denoising to non-equilibrium structures improves equivariant force fields",
    "citation_count": 12,
    "authors": [
      "Yi-Lun Liao",
      "Tess Smidt",
      "Muhammed Shuaibi",
      "Abhishek Das"
    ]
  },
  "https://openreview.net/forum?id=QlTLkH6xRC": {
    "title": "TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f9f09c782155ca4f2ae4b6ffcf28514b439226cd",
    "semantic_title": "totem: tokenized time series embeddings for general time series analysis",
    "citation_count": 14,
    "authors": [
      "Sabera J Talukder",
      "Yisong Yue",
      "Georgia Gkioxari"
    ]
  },
  "https://openreview.net/forum?id=8M6cn6lfrJ": {
    "title": "Transformer Architecture Search for Improving Out-of-Domain Generalization in Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6d6d1e4dbeec5b7306412500ae1f070d0a2f7431",
    "semantic_title": "transformer architecture search for improving out-of-domain generalization in machine translation",
    "citation_count": 0,
    "authors": [
      "Yiheng He",
      "Ruiyi Zhang",
      "Sai Ashish Somayajula",
      "Pengtao Xie"
    ]
  },
  "https://openreview.net/forum?id=t7vWCHmwbG": {
    "title": "Blending Two Styles: Generating Inter-domain Images with MiddleGAN",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5a15479af7272d63c3e55b6f3eaa002eb7b5c887",
    "semantic_title": "blending two styles: generating inter-domain images with middlegan",
    "citation_count": 0,
    "authors": [
      "Collin MacDonald",
      "Zhendong Chu",
      "John Stankovic",
      "Huajie Shao",
      "Gang Zhou",
      "Ashley Gao"
    ]
  },
  "https://openreview.net/forum?id=t9c3pfrR1X": {
    "title": "OmniPred: Language Models as Universal Regressors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6f63ad08cf27183ceb2976b9fb6599ed9b31a522",
    "semantic_title": "omnipred: language models as universal regressors",
    "citation_count": 16,
    "authors": [
      "Xingyou Song",
      "Oscar Li",
      "Chansoo Lee",
      "Bangding Yang",
      "Daiyi Peng",
      "Sagi Perel",
      "Yutian Chen"
    ]
  },
  "https://openreview.net/forum?id=AT9G5s1pOj": {
    "title": "Population Priors for Matrix Factorization",
    "volume": "main",
    "abstract": "We develop an empirical Bayes prior for probabilistic matrix factorization. Matrix factorization models each cell of a matrix with two latent variables, one associated with the cell's row and one associated with the cell's column. How to set the priors of these two latent variables? Drawing from empirical Bayes principles, we consider estimating the priors from data, to find those that best match the populations of row and column latent vectors. Thus we develop the twin population prior. We develop a variational inference algorithm to simultaneously learn the empirical priors and approximate the corresponding posterior. We evaluate this approach with both synthetic and real-world data on diverse applications: movie ratings, book ratings, single-cell gene expression data, and musical preferences. Without needing to tune Bayesian hyperparameters, we find that the twin population prior leads to high-quality predictions, outperforming manually tuned priors",
    "checked": true,
    "id": "66f6b3fafb0d75bf83f37ceac6d70e7dfa51e134",
    "semantic_title": "population priors for matrix factorization",
    "citation_count": 0,
    "authors": [
      "Sohrab Salehi",
      "Achille Nazaret",
      "Sohrab P Shah",
      "David Blei"
    ]
  },
  "https://openreview.net/forum?id=P09rAv8UH7": {
    "title": "Exploring Human-in-the-Loop Test-Time Adaptation by Synergizing Active Learning and Model Selection",
    "volume": "main",
    "abstract": "Existing test-time adaptation (TTA) approaches often adapt models with the unlabeled testing data stream. A recent attempt relaxed the assumption by introducing limited human annotation, referred to as Human-In-the-Loop Test-Time Adaptation (HILTTA) in this study. The focus of existing HILTTA studies lies in selecting the most informative samples to label, a.k.a. active learning. In this work, we are motivated by a pitfall of TTA, i.e. sensitivity to hyper-parameters, and propose to approach HILTTA by synergizing active learning and model selection. Specifically, we first select samples for human annotation (active learning) and then use the labeled data to select optimal hyper-parameters (model selection). To prevent the model selection process from overfitting to local distributions, multiple regularization techniques are employed to complement the validation objective. A sample selection strategy is further tailored by considering the balance between active learning and model selection purposes. We demonstrate on 5 TTA datasets that the proposed HILTTA approach is compatible with off-the-shelf TTA methods and such combinations substantially outperform the state-of-the-art HILTTA methods. Importantly, our proposed method can always prevent choosing the worst hyper-parameters on all off-the-shelf TTA methods. The source code is available at https://github.com/Yushu-Li/HILTTA",
    "checked": true,
    "id": "ffd1b56fb14a1a92f77a2ca70fca23c416682f55",
    "semantic_title": "exploring human-in-the-loop test-time adaptation by synergizing active learning and model selection",
    "citation_count": 0,
    "authors": [
      "Yushu Li",
      "Yongyi Su",
      "Xulei Yang",
      "Kui Jia",
      "Xun Xu"
    ]
  },
  "https://openreview.net/forum?id=tHteJFeN1y": {
    "title": "Node-Specific Space Selection via Localized Geometric Hyperbolicity in Graph Neural Networks",
    "volume": "main",
    "abstract": "Many graph neural networks have been developed to learn graph representations in either Euclidean or hyperbolic space, with all nodes' representations embedded in a single space. However, a graph can have hyperbolic and Euclidean geometries at different regions of the graph. Thus, it is sub-optimal to indifferently embed an entire graph into a single space. In this paper, we explore and analyze two notions of local hyperbolicity, describing the underlying local geometry: geometric (Gromov) and model-based, to determine the preferred space of embedding for each node. The two hyperbolicities' distributions are aligned using the Wasserstein metric such that the calculated geometric hyperbolicity guides the choice of the learned model hyperbolicity. As such our model Joint Space Graph Neural Network (JSGNN) can leverage both Euclidean and hyperbolic spaces during learning by allowing node-specific geometry space selection. We evaluate our model on both node classification and link prediction tasks and observe promising performance compared to baseline models",
    "checked": true,
    "id": "368544c7e492115c81d85d9f68b6309b03f91ae1",
    "semantic_title": "node-specific space selection via localized geometric hyperbolicity in graph neural networks",
    "citation_count": 1,
    "authors": [
      "See Hian Lee",
      "Feng Ji",
      "Wee Peng Tay"
    ]
  },
  "https://openreview.net/forum?id=6GfqN0Ca1Y": {
    "title": "Standard-Deviation-Inspired Regularization for Improving Adversarial Robustness",
    "volume": "main",
    "abstract": "Adversarial Training (AT ) has been demonstrated to improve the robustness of deep neural networks (DNNs) to adversarial attacks. AT is a min-max optimization procedure wherein adversarial examples are generated to train a robust DNN. The inner maximization step of AT maximizes the losses of inputs w.r.t their actual classes. The outer minimization involves minimizing the losses on the adversarial examples obtained from the inner maximization. This work proposes a standard-deviation-inspired (SDI ) regularization term for improving adversarial robustness and generalization. We argue that the inner maximization is akin to minimizing a modified standard deviation of a model's output probabilities. Moreover, we argue that maximizing the modified standard deviation measure may complement the outer minimization of the AT framework. To corroborate our argument, we experimentally show that the SDI measure may be utilized to craft adversarial examples. Furthermore, we show that combining the proposed SDI regularization term with existing AT variants improves the robustness of DNNs to stronger attacks (e.g., CW and Auto-attack) and improves robust generalization",
    "checked": true,
    "id": "03554b8a8ae628974e6eaded6544d4444580b7dd",
    "semantic_title": "standard-deviation-inspired regularization for improving adversarial robustness",
    "citation_count": 0,
    "authors": [
      "Olukorede Fakorede",
      "Modeste Atsague",
      "Jin Tian"
    ]
  },
  "https://openreview.net/forum?id=2Zl0zc7fO8": {
    "title": "Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics",
    "volume": "main",
    "abstract": "Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses. While they excel in multi-modal tasks, the conventional view within the machine learning community has often undervalued/overlooked their capabilities in pure natural language processing. This paper aims to get out of the box and showcase an intriguing characteristic of multi-modal trained LLMs --- our preliminary results suggest that visual instruction tuning, a prevailing strategy to integrate vision knowledge into the LLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA and Ethics benchmarks. Similarly, the latest LLaMA3 series also shows consistent performance gains by 0.6% on average following visual-instruction tuning. Another example is that two versions of proprietary model GPT-4V-turbo, which incorporates visual information, surpasses its LLM-only counterpart GPT-4-turbo by around 1.6% on both aspects. Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data. By presenting those findings, we advocate for a broader exploration into visual-text synergies, positing that such multi-modal interactions could be pivotal in advancing alignment research. In releasing our code at https://github.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration into the intrinsic value of visual-text synergies and, in a broader scope, multi-modal interactions in alignment research",
    "checked": true,
    "id": "eae9ae43c5d4712e775912683268cf1ad02ff38f",
    "semantic_title": "sight beyond text: multi-modal training enhances llms in truthfulness and ethics",
    "citation_count": 15,
    "authors": [
      "Haoqin Tu",
      "Bingchen Zhao",
      "Chen Wei",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=YcnjgKbZQS": {
    "title": "Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) trained on massive datasets may inadvertently acquire sensitive information such as personal details and potentially harmful content. This risk is further heightened in multimodal LLMs (aka MLLMs) as they integrate information from multiple modalities (image and text). Adversaries can exploit this stored knowledge by crafting inputs across modalities to extract sensitive details. Evaluating how effectively MLLMs can forget such information (targeted unlearning) necessitates the creation of high-quality, well-annotated image-text pairs. While significant research has addressed the creation of datasets for unlearning within LLMs, it has primarily concentrated on text modality. Creation of analogous datasets for multimodal data and models remain an understudied area. To address this gap, we first introduce a multimodal unlearning benchmark, UnLOK-VQA (Unlearning Outside Knowledge VQA), as well as an \"attack and-defense\" framework to evaluate methods for deleting specific multimodal knowledge from MLLMs. Our dataset generation process involves an automated pipeline to create samples of varied proximity levels to the target data point for evaluation of generalization and specificity, followed by manual filtering to retain only the high-quality data points. We use this process to extend a visual question-answering dataset for evaluating multimodal information deletion. Next, we present a comprehensive unlearning evaluation involving an attack-and-defense framework consisting of four white box and three blackbox attacks against six unlearning defense objectives. We also design a whitebox attack based on the interpretability of hidden states in LLMs motivated by past work. Our experimental results demonstrate that multimodal extraction attacks (with an attack success rate of 45.5%) are more successful than either image-only (32%) or text-only attacks (39%). The best overall defense mechanism, which removes answer information from internal model hidden states, reduces the success rate of multimodal attack to 15.7%. Furthermore, our findings suggest that larger models exhibit greater resilience to attacks, implying that model scaling could be a valuable strategy for enhancing robustness and developing safer models. UnLOK-VQA thus facilitates a comprehensive evaluation of unlearning in MLLMs and serves as a challenging benchmark for future research in unlearning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vaidehi Patil",
      "Yi-Lin Sung",
      "Peter Hase",
      "Jie Peng",
      "Tianlong Chen",
      "Mohit Bansal"
    ]
  },
  "https://openreview.net/forum?id=d9MhajJT04": {
    "title": "Evaluating Graph Generative Models with Graph Kernels: What Structural Characteristics Are Captured?",
    "volume": "main",
    "abstract": "For many practical problems, it is important to measure similarity between graphs. This can be done via graph kernels. One particular application where the choice of a graph kernel is essential is assessing the quality of graph generative models. However, despite the vast number of graph kernels available in the literature, only basic kernels are usually considered for generative model evaluation. In this paper, we fill this gap and analyze how different graph kernels perform as an ingredient in the pipeline of generative model performance evaluation. To conduct a detailed analysis, we propose a framework for comparing graph kernels in terms of which high-level structural properties they are sensitive to: heterogeneity of degree distribution, the presence of community structure, the presence of latent geometry, and others. For this, we design continuous transitions between random graph models that affect a particular property and measure which graph kernel is sensitive to the corresponding change. We show that using such diverse models with the corresponding transitions is crucial for evaluation: many kernels can successfully capture some properties and fail on others. We also found some well-known kernels that show good performance in our experiments but have been previously overlooked in the literature on evaluating graph generative models",
    "checked": true,
    "id": "c6441ed29c091186f5b007af4ad12d8a1f47e06e",
    "semantic_title": "evaluating graph generative models with graph kernels: what structural characteristics are captured?",
    "citation_count": 0,
    "authors": [
      "Martijn GÃ¶sgens",
      "Alexey Tikhonov",
      "Liudmila Prokhorenkova"
    ]
  },
  "https://openreview.net/forum?id=kmHq3pKIlj": {
    "title": "Lookahead Counterfactual Fairness",
    "volume": "main",
    "abstract": "As machine learning (ML) algorithms are used in applications that involve humans, concerns have arisen that these algorithms may be biased against certain social groups. $\\textit{Counterfactual fairness}$ (CF) is a fairness notion proposed in Kusner et al. (2017) that measures the unfairness of ML predictions; it requires that the prediction perceived by an individual in the real world has the same marginal distribution as it would be in a counterfactual world, in which the individual belongs to a different group. Although CF ensures fair ML predictions, it fails to consider the downstream effects of ML predictions on individuals. Since humans are strategic and often adapt their behaviors in response to the ML system, predictions that satisfy CF may not lead to a fair future outcome for the individuals. In this paper, we introduce $\\textit{lookahead counterfactual fairness}$ (LCF), a fairness notion accounting for the downstream effects of ML models which requires the individual $\\textit{future status}$ to be counterfactually fair. We theoretically identify conditions under which LCF can be satisfied and propose an algorithm based on the theorems. We also extend the concept to path-dependent fairness. Experiments on both synthetic and real data validate the proposed method",
    "checked": true,
    "id": "6f287e3f2f9b6fccd4b93e96d6e0c79cc76d87f8",
    "semantic_title": "lookahead counterfactual fairness",
    "citation_count": 0,
    "authors": [
      "Zhiqun Zuo",
      "Tian Xie",
      "Xuwei Tan",
      "Xueru Zhang",
      "Mohammad Mahdi Khalili"
    ]
  },
  "https://openreview.net/forum?id=15tjpSHI15": {
    "title": "Teacher-Guided Graph Contrastive Learning",
    "volume": "main",
    "abstract": "State-of-the-art self-supervised representation learning methods for Graphs are typically based on contrastive learning (CL) principles. These CL objective functions can be posed as a supervised discriminative task using *'hard'* labels that consider any minor augmented pairs of graphs as 'equally positive'. However, such a notion of 'equal' pairs is incorrect for graphs as even a smaller 'discrete' perturbation may lead to large semantic changes that should be carefully encapsulated within the learned representations. This paper proposes a novel CL framework for GNNs, called *Teacher-guided Graph Contrastive Learning (TGCL)*, that incorporates 'soft' pseudo-labels to facilitate a more regularized discrimination. In particular, we propose a teacher-student framework where the student learns the representation by distilling the teacher's perception. Our TGCL framework can be adapted to existing CL methods to enhance their performance. Our empirical findings validate these claims on both inductive and transductive settings across diverse downstream tasks, including molecular graphs and social networks. Our experiments on benchmark datasets demonstrate that our framework consistently improves the average AUROC scores for molecules' property prediction and social network link prediction. Our code is available at: https://github.com/jayjaynandy/TGCL",
    "checked": true,
    "id": "01edbb5956ff8b1c826cd86b05ca65cac86bd536",
    "semantic_title": "teacher-guided graph contrastive learning",
    "citation_count": 0,
    "authors": [
      "Jay Nandy",
      "Arnab Kumar Mondal",
      "Manohar Kaul",
      "Prathosh AP"
    ]
  },
  "https://openreview.net/forum?id=znlTP5RLur": {
    "title": "A Dual-Perspective Approach to Evaluating Feature Attribution Methods",
    "volume": "main",
    "abstract": "Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. To address the limitations of previous evaluations, in this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods",
    "checked": true,
    "id": "ba326908bd470fb38d8fe546d000260cebcb4d9c",
    "semantic_title": "a dual-perspective approach to evaluating feature attribution methods",
    "citation_count": 0,
    "authors": [
      "Yawei Li",
      "Yang Zhang",
      "Kenji Kawaguchi",
      "Ashkan Khakzar",
      "Bernd Bischl",
      "Mina Rezaei"
    ]
  },
  "https://openreview.net/forum?id=K58n87DE4s": {
    "title": "Adaptive Self-Distillation for Minimizing Client Drift in Heterogeneous Federated Learning",
    "volume": "main",
    "abstract": "Federated Learning (FL) is a machine learning paradigm that enables clients to jointly train a global model by aggregating the locally trained models without sharing any local training data. In practice, there can often be substantial heterogeneity (e.g., class imbalance) across the local data distributions observed by each of these clients. Under such non-iid label distributions across clients, FL suffers from the `client-drift' problem where every client drifts to its own local optimum. This results in slower convergence and poor performance of the aggregated model. To address this limitation, we propose a novel regularization technique based on adaptive self-distillation (ASD) for training models on the client side. Our regularization scheme adaptively adjusts to each client's training data based on the global model's prediction entropy and the client-data label distribution. We show in this paper that our proposed regularization (ASD) can be easily integrated atop existing, state-of-the-art FL algorithms, leading to a further boost in the performance of these off-the-shelf methods. We theoretically explain how incorporation of ASD regularizer leads to reduction in client-drift and empirically justify the generalization ability of the trained model. We demonstrate the efficacy of our approach through extensive experiments on multiple real-world benchmarks and show substantial gains in performance when the proposed regularizer is combined with popular FL methods. The code is provided as supplementary material",
    "checked": true,
    "id": "bfab5f228b26bc774e4fd8c085eb98d06197a5d7",
    "semantic_title": "adaptive self-distillation for minimizing client drift in heterogeneous federated learning",
    "citation_count": 1,
    "authors": [
      "M Yashwanth",
      "Gaurav Kumar Nayak",
      "Arya Singh",
      "Yogesh Simmhan",
      "Anirban Chakraborty"
    ]
  },
  "https://openreview.net/forum?id=4JcqmEZ5zt": {
    "title": "Robust Guided Diffusion for Offline Black-Box Optimization",
    "volume": "main",
    "abstract": "Offline black-box optimization aims to maximize a black-box function using an offline dataset of designs and their measured properties. Two main approaches have emerged: the forward approach, which learns a mapping from input to its value, thereby acting as a proxy to guide optimization, and the inverse approach, which learns a mapping from value to input for conditional generation. (a) Although proxy-free~(classifier-free) diffusion shows promise in robustly modeling the inverse mapping, it lacks explicit guidance from proxies, essential for generating high-performance samples beyond the training distribution. Therefore, we propose \\textit{proxy-enhanced sampling} which utilizes the explicit guidance from a trained proxy to bolster proxy-free diffusion with enhanced sampling control. (b) Yet, the trained proxy is susceptible to out-of-distribution issues. To address this, we devise the module \\textit{diffusion-based proxy refinement}, which seamlessly integrates insights from proxy-free diffusion back into the proxy for refinement. To sum up, we propose \\textit{\\textbf{R}obust \\textbf{G}uided \\textbf{D}iffusion for Offline Black-box Optimization}~(\\textbf{RGD}), combining the advantages of proxy~(explicit guidance) and proxy-free diffusion~(robustness) for effective conditional generation. RGD achieves state-of-the-art results on various design-bench tasks, underscoring its efficacy. Our code is \\href{https://github.com/GGchen1997/RGD}{here}",
    "checked": true,
    "id": "45957487086436f6fcbdd88c6a6dd5f268d9310f",
    "semantic_title": "robust guided diffusion for offline black-box optimization",
    "citation_count": 5,
    "authors": [
      "Can Chen",
      "Christopher Beckham",
      "Zixuan Liu",
      "Xue Liu",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=cSimKw5p6R": {
    "title": "FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance",
    "volume": "main",
    "abstract": "The rapid adoption of large language models (LLMs) has led to a growing number of companies offering generative LLMs as callable services at varying costs. We find that popular generative LLM APIs, such as GPT-4, Gemini 1.5, and Claude 3.5, exhibit heterogeneous pricing structures, with fees that can differ by two orders of magnitude and heterogeneous performance across tasks and input queries. This makes it challenging for users to decide which generative LLM APIs to utilize for their applications and budget. Motivated by these findings, we propose FrugalGPT, an algorithmic framework that adaptively selects which generative LLMs to use for different queries to reduce cost and improve accuracy. Our experiments demonstrate that, for a range of natural language tasks including news classification, reading comprehension, and scientific question answering, FrugalGPT can match the performance of the best individual generative LLM (e.g., GPT-4) with up to a 98% cost reduction or improve the accuracy over GPT-4 by 4% at the same cost. The ideas and findings presented in this paper lay a foundation for using LLMs sustainably and efficiently",
    "checked": true,
    "id": "585f8b9725f5f5e5495c3508d39f70d1c053e190",
    "semantic_title": "frugalgpt: how to use large language models while reducing cost and improving performance",
    "citation_count": 250,
    "authors": [
      "Lingjiao Chen",
      "Matei Zaharia",
      "James Zou"
    ]
  },
  "https://openreview.net/forum?id=GdaP6GgvfN": {
    "title": "Improving Robust Generalization with Diverging Spanned Latent Space",
    "volume": "main",
    "abstract": "Robust generalization (RG), concerning how deep neural networks could perform over adversarial examples generated from unseen dataset, has emerged as an active research topic. Albeit its crucial importance, most previous studies lack a well-founded theoretical analysis and certified error bounds. In this paper, we make a novel attempt to theoretically and empirically study how we could attain a better RG by learning discriminative representation, where the inconsistency of the inter-sample similarity matrix between clean and adversarial examples should be reduced. Our theoretical investigation discloses that introducing this inconsistency as a regularization term, named Gram matrix difference (GMD), will lead to tighter upper error bound and certify a better RG. Meanwhile, we demonstrate that previous efforts to reduce inter-class similarity and increase intra-class similarity among adversarial examples for enhanced adversarial robustness are approximate optimizations of our GMD approach. Furthermore, to avoid the vast optimization complexity introduced by the similarity matrix, we propose to optimize GMD by building a diverging spanned latent space for adversarial examples. On the algorithmic side, this regularization term is implemented as a novel adversarial training (AT) method --- Subspace Diverging (SD) --- to expand the volume difference between the whole latent space's linear span and subspaces' linear spans. Extensive experiments show that the proposed method can improve advanced AT methods and work remarkably well in various datasets including CIFAR-10, CIFAR-100, SVHN, and Tiny-ImageNet",
    "checked": true,
    "id": "e357f7e25e57f2d0a28bfbd7692f3ba1a295bc05",
    "semantic_title": "improving robust generalization with diverging spanned latent space",
    "citation_count": 0,
    "authors": [
      "Owen Dou",
      "Zhiqiang Gao",
      "Hangchi Shen",
      "Ziling Yuan",
      "Shufei Zhang",
      "Kaizhu Huang"
    ]
  },
  "https://openreview.net/forum?id=4c9UzDhg49": {
    "title": "On the theoretical limit of gradient descent for Simple Recurrent Neural Networks with finite precision",
    "volume": "main",
    "abstract": "Despite their great practical successes, the understanding of neural network behavior is still a topical research issue. In particular, the class of functions learnable in the context of a finite precision configuration is an open question. In this paper, we propose to study the limits of gradient descent when such a configuration is set for the class of Simple Recurrent Networks (SRN). We exhibit conditions under which the gradient descend will provably fail. We also design a class of SRN based on Deterministic finite State Automata (DFA) that fulfills the failure requirements. The definition of this class is constructive: we propose an algorithm that, from any DFA, constructs a SRN that computes exactly the same function, a result of interest by its own",
    "checked": true,
    "id": "dff8541affb2d78e0858be3460a6862f22f93133",
    "semantic_title": "on the theoretical limit of gradient descent for simple recurrent neural networks with finite precision",
    "citation_count": 0,
    "authors": [
      "Volodimir Mitarchuk",
      "RÃ©mi Emonet",
      "Remi Eyraud",
      "Amaury Habrard"
    ]
  },
  "https://openreview.net/forum?id=pR3fCmztDf": {
    "title": "Compositional Instruction Following with Language Models and Reinforcement Learning",
    "volume": "main",
    "abstract": "Combining reinforcement learning with language grounding is challenging as the agent needs to explore the environment while simultaneously learning multiple language-conditioned tasks. To address this, we introduce a novel method: the compositionally-enabled reinforcement learning language agent (CERLLA). Our method reduces the sample complexity of tasks specified with language by leveraging compositional policy representations and a semantic parser trained using reinforcement learning and in-context learning. We evaluate our approach in an environment requiring function approximation and demonstrate compositional generalization to novel tasks. Our method significantly outperforms the previous best non-compositional baseline in terms of sample complexity on 162 tasks designed to test compositional generalization. Our model attains a higher success rate and learns in fewer steps than the non-compositional baseline. It reaches a success rate equal to an oracle policy's upper-bound performance of 92%. With the same number of environment steps, the baseline only reaches a success rate of 80%",
    "checked": true,
    "id": "b4151137425392260954a58e2121192872c3fa06",
    "semantic_title": "compositional instruction following with language models and reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Vanya Cohen",
      "Geraud Nangue Tasse",
      "Nakul Gopalan",
      "Steven James",
      "Matthew Gombolay",
      "Ray Mooney",
      "Benjamin Rosman"
    ]
  },
  "https://openreview.net/forum?id=qGVchjFj3a": {
    "title": "Scaling Laws for Imitation Learning in Single-Agent Games",
    "volume": "main",
    "abstract": "Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, many works find it is often unable to fully recover the underlying expert behavior, even in constrained environments like single-agent games. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where \"scaling up\" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting for single-agent games. We first demonstrate our findings on a variety of Atari games, and thereafter focus on the extremely challenging game of NetHack. In all games, we find that IL loss and mean return scale smoothly with the compute budget (FLOPs) and are strongly correlated, resulting in power laws (and variations of them) for training compute-optimal IL agents. Finally, we forecast and train several NetHack agents with IL and find our best agent outperforms the prior state-of-the-art by 1.7x in the offline setting. Our work both demonstrates the scaling behavior of imitation learning in a variety of single-agent games, as well as the viability of scaling up current approaches for increasingly capable agents in NetHack, a game that remains elusively hard for current AI systems",
    "checked": true,
    "id": "d60a55215c8e828271085ff011ed3d9ca45d2cca",
    "semantic_title": "scaling laws for imitation learning in single-agent games",
    "citation_count": 5,
    "authors": [
      "Jens Tuyls",
      "Dhruv Madeka",
      "Kari Torkkola",
      "Dean Foster",
      "Karthik R Narasimhan",
      "Sham M. Kakade"
    ]
  },
  "https://openreview.net/forum?id=qoxusn9u2L": {
    "title": "Extended Deep Submodular Functions",
    "volume": "main",
    "abstract": "We introduce a novel representation of monotone set functions called Extended Deep Submodular functions (EDSFs), which are neural network-representable. EDSFs serve as an extension of Deep Submodular Functions (DSFs), inheriting crucial properties from DSFs while addressing innate limitations. It is known that DSFs can represent a limiting subset of submodular functions. In contrast, we establish that EDSFs possess the capability to represent all monotone submodular functions, a notable enhancement compared to DSFs. Furthermore, our findings demonstrate that EDSFs can represent any monotone set function, indicating the family of EDSFs is equivalent to the family of all monotone set functions. Additionally, we prove that EDSFs maintain the concavity inherent in DSFs when the components of the input vector are non-negative real numbersâan essential feature in certain combinatorial optimization problems. Through extensive experiments, we demonstrate that EDSFs exhibit significantly lower empirical generalization error in representing and learning coverage and cut functions compared to existing baselines, such as DSFs, Deep Sets, and Set Transformers",
    "checked": true,
    "id": "4fd7b02b08c6575a59402eeddc3cea404d8c911f",
    "semantic_title": "extended deep submodular functions",
    "citation_count": 0,
    "authors": [
      "Seyed Mohammad Hosseini",
      "Arash Jamshidi",
      "Seyed Mahdi Noormousavi",
      "Mahdi Siavoshani",
      "Naeimeh Omidvar"
    ]
  },
  "https://openreview.net/forum?id=dHcoMrmWcE": {
    "title": "On the Interdependence between Data Selection and Architecture Optimization in Deep Active Learning",
    "volume": "main",
    "abstract": "Deep active learning (DAL) studies the optimal selection of labeled data for training deep neural networks (DNNs). While data selection in traditional active learning is mostly optimized for given features, in DNN these features are learned and change with the learning process as well as the choices of DNN architectures. How is the optimal selection of data affected by this change is not well understood in DAL. To shed light on this question, we present the first systematic investigation on: 1) the relative performance of representative modern DAL data selection strategies, as the architecture types and sizes change in the underlying DNN architecture (Focus 1), and 2) the effect of optimizing the DNN architecture of a DNN on DAL (Focus 2). The results suggest that the change in the DNN architecture significantly influences and outweighs the benefits of data selection in DAL. These results cautions the community in generalizing DAL findings obtained on specific architectures, while suggesting the importance to optimize the DNN architecture in order to maximize the effect of active data selection in DAL",
    "checked": true,
    "id": "300900b5d6f2e4ca1773f33a2ba8d5e5ef6feaeb",
    "semantic_title": "on the interdependence between data selection and architecture optimization in deep active learning",
    "citation_count": 1,
    "authors": [
      "Pradeep Bajracharya",
      "Rui Li",
      "Linwei Wang"
    ]
  },
  "https://openreview.net/forum?id=t0EJiOd9Lg": {
    "title": "Spectral Self-supervised Feature Selection",
    "volume": "main",
    "abstract": "Choosing a meaningful subset of features from high-dimensional observations in unsupervised settings can greatly enhance the accuracy of downstream analysis tasks, such as clustering or dimensionality reduction, and provide valuable insights into the sources of heterogeneity in a given dataset. In this paper, we propose a self-supervised graph-based approach for unsupervised feature selection. Our method's core involves computing robust pseudo-labels by applying simple processing steps to the graph Laplacian's eigenvectors. The subset of eigenvectors used for computing pseudo-labels is chosen based on a model stability criterion. We then measure the importance of each feature by training a surrogate model to predict the pseudo-labels from the observations. Our approach is shown to be robust to challenging scenarios, such as the presence of outliers and complex substructures. We demonstrate the effectiveness of our method through experiments on real-world datasets from multiple domains, with a particular emphasis on biological datasets",
    "checked": true,
    "id": "d7a749659fbfc6725f42eb5f81752a1fdb44bbf5",
    "semantic_title": "spectral self-supervised feature selection",
    "citation_count": 0,
    "authors": [
      "Daniel Segal",
      "Ofir Lindenbaum",
      "Ariel Jaffe"
    ]
  },
  "https://openreview.net/forum?id=QezxDgd5hf": {
    "title": "Mind the truncation gap: challenges of learning on dynamic graphs with recurrent architectures",
    "volume": "main",
    "abstract": "Systems characterized by evolving interactions, prevalent in social, financial, and biological domains, are effectively modeled as continuous-time dynamic graphs (CTDGs). To manage the scale and complexity of these graph datasets, machine learning (ML) approaches have become essential. However, CTDGs pose challenges for ML because traditional static graph methods fail to account for event timings naturally. Newer approaches, such as graph recurrent neural networks (GRNNs), are inherently time-aware and offer advantages over static methods for CTDGs. Yet, GRNNs face another issue: the short truncation of backpropagation-through-time (BPTT) whose impact has never been properly examined until now. In this work, we demonstrate that this truncation can limit the learning of dependencies more than a hop away, resulting in reduced performance. Through experiments on a novel synthetic task as well as real-world datasets, we reveal that there exists a performance gap between full backpropagation-through-time (F-BPTT) and the truncated backpropagation-through-time (T-BPTT) commonly used to train GRNN models. We term this gap the \"truncation gap\" and argue that understanding and addressing it is essential as the importance of CTDGs grows, discussing potential future directions of research for this type of models",
    "checked": true,
    "id": "e0f84770ce9af9483399afda07c4f67bb9acd9cf",
    "semantic_title": "mind the truncation gap: challenges of learning on dynamic graphs with recurrent architectures",
    "citation_count": 0,
    "authors": [
      "JoÃ£o Bravo",
      "Jacopo Bono",
      "Hugo Ferreira",
      "Pedro Saleiro",
      "Pedro Bizarro"
    ]
  },
  "https://openreview.net/forum?id=p9pxeNupQ5": {
    "title": "Inductive Global and Local Manifold Approximation and Projection",
    "volume": "main",
    "abstract": "Nonlinear dimensional reduction with the manifold assumption, often called manifold learning, has proven its usefulness in a wide range of high-dimensional data analysis. The significant impact of t-SNE and UMAP has catalyzed intense research interest, seeking further innovations toward visualizing not only the local but also the global structure information of the data. Moreover, there have been consistent efforts toward generalizable dimensional reduction that handles unseen data. In this paper, we first propose GLoMAP, a novel manifold learning method for dimensional reduction and high-dimensional data visualization. GLoMAP preserves locally and globally meaningful distance estimates and displays a progression from global to local formation during the course of optimization. Furthermore, we extend GLoMAP to its inductive version, iGLoMAP, which utilizes a deep neural network to map data to its lower-dimensional representation. This allows iGLoMAP to provide lower-dimensional embeddings for unseen points without needing to re-train the algorithm. iGLoMAP is also well-suited for mini-batch learning, enabling large-scale, accelerated gradient calculations. We have successfully applied both GLoMAP and iGLoMAP to the simulated and real-data settings, with competitive experiments against the state-of-the-art methods",
    "checked": true,
    "id": "2562e83654d65d006925ec610649d8cdc86a1ae6",
    "semantic_title": "inductive global and local manifold approximation and projection",
    "citation_count": 1,
    "authors": [
      "Jungeum Kim",
      "Xiao Wang"
    ]
  },
  "https://openreview.net/forum?id=89QT2DsKyj": {
    "title": "LEA: Learning Latent Embedding Alignment Model for fMRI Decoding and Encoding",
    "volume": "main",
    "abstract": "The connection between brain activity and visual stimuli is crucial to understanding the human brain. Although deep generative models have shown advances in recovering brain recordings by generating images conditioned on fMRI signals, it is still challenging to generate consistent semantics. Moreover, predicting fMRI signals from visual stimuli remains a hard problem. In this paper, we introduce a unified framework that addresses both fMRI decoding and encoding. We train two latent spaces to represent and reconstruct fMRI signals and visual images, respectively. By aligning these two latent spaces, we seamlessly transform between the fMRI signal and visual stimuli. Our model, called Latent Embedding Alignment (LEA), can recover visual stimuli from fMRI signals and predict brain activity from images. LEA outperforms existing methods on multiple fMRI decoding and encoding benchmarks. It offers a comprehensive solution for modeling the relationship between fMRI signals and visual stimuli. The codes are available at \\url{https://github.com/naiq/LEA}",
    "checked": true,
    "id": "f20e407db3f68bdc29333f8784b983cdd6448171",
    "semantic_title": "lea: learning latent embedding alignment model for fmri decoding and encoding",
    "citation_count": 2,
    "authors": [
      "Xuelin Qian",
      "Yikai Wang",
      "Xinwei Sun",
      "Yanwei Fu",
      "Xiangyang Xue",
      "Jianfeng Feng"
    ]
  },
  "https://openreview.net/forum?id=YmwzfdJPXE": {
    "title": "TeaMs-RL: Teaching LLMs to Generate Better Instruction Datasets via Reinforcement Learning",
    "volume": "main",
    "abstract": "The development of Large Language Models (LLMs) often confronts challenges stemming from the heavy reliance on human annotators in the reinforcement learning with human feedback (RLHF) framework, or the frequent and costly external queries tied to the self-instruct paradigm. In this work, we pivot to Reinforcement Learning (RL)---but with a twist. Diverging from the typical RLHF, which refines LLMs following instruction data training, we use RL to directly generate the foundational instruction dataset that alone suffices for fine-tuning. Our method, TeaMs-RL, uses a suite of textual operations and rules, prioritizing the diversification of training datasets. It facilitates the generation of high-quality data without excessive reliance on external advanced models, paving the way for a single fine-tuning step and negating the need for subsequent RLHF stages. Our findings highlight key advantages of our approach: reduced need for human involvement and fewer model queries (only $5.73\\%$ of the strong baseline's total), along with enhanced capabilities of LLMs in crafting and comprehending complex instructions compared to strong baselines, and substantially improved model privacy protection. Code is available at the link: https://github.com/SafeRL-Lab/TeaMs-RL",
    "checked": true,
    "id": "9f6ef7c2731658d1eb3eee2b26c2886c8dc632b7",
    "semantic_title": "teams-rl: teaching llms to generate better instruction datasets via reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Shangding Gu",
      "Alois Knoll",
      "Ming Jin"
    ]
  },
  "https://openreview.net/forum?id=qS9pPu8ODt": {
    "title": "Comparing Deterministic and Soft Policy Gradients for Optimizing Gaussian Mixture Actors",
    "volume": "main",
    "abstract": "Gaussian Mixture Models (GMMs) have been recently proposed for approximating actors in actor-critic reinforcement learning algorithms. Such GMM-based actors are commonly optimized using stochastic policy gradients along with an entropy maximization objective. In contrast to previous work, we define and study deterministic policy gradients for optimizing GMM-based actors. Similar to stochastic gradient approaches, our proposed method, denoted $\\textit{Gaussian Mixture Deterministic Policy Gradient}$ (Gamid-PG), encourages policy entropy maximization. To this end, we define the GMM entropy gradient using $\\textit{Variational Approximation}$ of the $KL$-divergence between the GMM's constituting Gaussians. We compare Gamid-PG with common stochastic policy gradient methods on benchmark dense-reward MuJoCo tasks and sparse-reward Fetch tasks. We observe that Gamid-PG outperforms stochastic gradient-based methods in 3/6 MuJoCo tasks while performing similarly on the remaining 3 tasks. In the Fetch tasks, Gamid-PG outperforms single-actor deterministic gradient-based methods while performing worse than stochastic policy gradient methods. Consequently, we conclude that GMMs optimized using deterministic policy gradients (1) should be favorably considered over stochastic gradients in dense-reward continuous control tasks, and (2) improve upon single-actor deterministic gradients",
    "checked": true,
    "id": "0a44386e22527a591878b98a6d91038cf24a34ba",
    "semantic_title": "comparing deterministic and soft policy gradients for optimizing gaussian mixture actors",
    "citation_count": 1,
    "authors": [
      "Sheelabhadra Dey",
      "Guni Sharon"
    ]
  },
  "https://openreview.net/forum?id=fr61ToAd9o": {
    "title": "Federated $\\mathcal{X}$-armed Bandit with Flexible Personalisation",
    "volume": "main",
    "abstract": "This paper introduces a novel approach to personalised federated learning within the $\\mathcal{X}$-armed bandit framework, addressing the challenge of optimising both local and global objectives in a highly heterogeneous environment. Our method employs a surrogate objective function that combines individual client preferences with aggregated global knowledge, allowing for a flexible trade-off between personalisation and collective learning. We propose a phase-based elimination algorithm that achieves sublinear regret with logarithmic communication overhead, making it well-suited for federated settings. Theoretical analysis and empirical evaluations demonstrate the effectiveness of our approach compared to existing methods. Potential applications of this work span various domains, including healthcare, smart home devices, and e-commerce, where balancing personalisation with global insights is crucial",
    "checked": false,
    "id": "2872a72d59ce2dde3e1793ff03bcf41d817e28d8",
    "semantic_title": "federated ð³-armed bandit with flexible personalisation",
    "citation_count": 0,
    "authors": [
      "Ali Arabzadeh",
      "James A. Grant",
      "David S. Leslie"
    ]
  },
  "https://openreview.net/forum?id=FmA1JPWBM8": {
    "title": "Your Classifier Can Be Secretly a Likelihood-Based OOD Detector",
    "volume": "main",
    "abstract": "The ability to detect out-of-distribution (OOD) inputs is critical to guarantee the reliability of classification models deployed in an open environment. A fundamental challenge in OOD detection is that a discriminative classifier is typically trained to estimate the posterior probability $p(y|\\mathbf{z})$ for class $y$ given an input $\\mathbf{z}$, but lacks the explicit likelihood estimation of $p(\\mathbf{z})$ ideally needed for OOD detection. While numerous OOD scoring functions have been proposed for classification models, these estimate scores are often heuristic-driven and cannot be rigorously interpreted as likelihood. To bridge the gap, we propose Intrinsic Likelihood (INK), which offers rigorous likelihood interpretation to modern discriminative-based classifiers. Specifically, our proposed INK score operates on the constrained latent embeddings of a discriminative classifier, which are modeled as a mixture of hyperspherical embeddings with constant norm. We draw a novel connection between the hyperspherical distribution and the intrinsic likelihood, which can be effectively optimized in modern neural networks. Extensive experiments on the OpenOOD benchmark empirically demonstrate that INK establishes a new state-of-the-art in a variety of OOD detection setups, including both far-OOD and near-OOD",
    "checked": true,
    "id": "cdf47d559575db1c8bfc653046bafba0d9c3043c",
    "semantic_title": "your classifier can be secretly a likelihood-based ood detector",
    "citation_count": 4,
    "authors": [
      "Jirayu Burapacheep",
      "Yixuan Li"
    ]
  },
  "https://openreview.net/forum?id=pvol5JyVYB": {
    "title": "Assessing biomedical knowledge robustness in large language models by query-efficient sampling attacks",
    "volume": "main",
    "abstract": "The increasing depth of parametric domain knowledge in large language models (LLMs) is fueling their rapid deployment in real-world applications. Understanding model vulnerabilities in high-stakes and knowledge-intensive tasks is essential to quantifying the trustworthiness of model predictions and regulating model use. The recent discovery of named entities as adversarial examples (i.e. adversarial entities) in natural language processing tasks raises questions about their potential impact on the knowledge robustness of pre-trained and finetuned LLMs in high-stakes and specialized domains. We examined the use of type-consistent entity substitution as a template for collecting adversarial entities for medium-sized billion-parameter LLMs with biomedical knowledge. To this end, we developed an embedding space, gradient-free attack based on powerscaled distance-weighted sampling for robustness evaluation, which has a low query budget and controllable coverage. Our method has favorable query efficiency and scaling over alternative approaches based on blackbox gradient-guided search, which we demonstrated for adversarial distractor generation in biomedical question answering. Subsequent failure mode analysis uncovered two regimes of adversarial entities on the attack surface with distinct characteristics. We also showed that entity substitution attacks can manipulate token-wise Shapley value explanations, which become deceptive in this setting. Our approach complements standard evaluations for high-capacity models and the results highlight the brittleness of domain knowledge in LLMs",
    "checked": true,
    "id": "83ded0f71a4bca1b5d4667873b7d621447eaa166",
    "semantic_title": "assessing biomedical knowledge robustness in large language models by query-efficient sampling attacks",
    "citation_count": 1,
    "authors": [
      "Rui Patrick Xian",
      "Alex Jihun Lee",
      "Satvik Lolla",
      "Vincent Wang",
      "Russell Ro",
      "Qiming Cui",
      "Reza Abbasi-Asl"
    ]
  },
  "https://openreview.net/forum?id=375tU7Tn0S": {
    "title": "Unsupervised Training of Convex Regularizers using Maximum Likelihood Estimation",
    "volume": "main",
    "abstract": "Imaging is a canonical inverse problem, where the task of reconstructing a ground truth from a noisy measurement is typically ill-conditioned or ill-posed. Recent state-of-the-art approaches for imaging use deep learning, spearheaded by unrolled and end-to-end models and trained on various image datasets. However, such methods typically require the availability of ground truth data, which may be unavailable or expensive, leading to a fundamental barrier that can not be addressed by choice of architecture. Unsupervised learning presents a powerful alternative paradigm that bypasses this requirement by allowing to learn directly from noisy measurement data without the need for any ground truth. A principled statistical approach to unsupervised learning is to maximize the marginal likelihood of the model parameters with respect to the given noisy measurements. This paper proposes an unsupervised learning approach that leverages maximum marginal likelihood estimation and stochastic approximation computation in order to train a convex neural network-based image regularization term directly on noisy measurements, improving upon previous work in both model expressiveness and dataset size. Experiments demonstrate that the proposed method produces image priors that are comparable in performance to the analogous supervised models for various image corruption operators, maintaining significantly better generalization properties when compared to end-to-end methods. Moreover, we provide a detailed theoretical analysis of the convergence properties of our proposed algorithm",
    "checked": true,
    "id": "2eca5e8a7684b7ceef9f9d453cbe91e5d3c57aac",
    "semantic_title": "unsupervised training of convex regularizers using maximum likelihood estimation",
    "citation_count": 1,
    "authors": [
      "Hong Ye Tan",
      "Ziruo Cai",
      "Marcelo Pereyra",
      "Subhadip Mukherjee",
      "Junqi Tang",
      "Carola-Bibiane SchÃ¶nlieb"
    ]
  },
  "https://openreview.net/forum?id=7Oqb6zlGWl": {
    "title": "Assessing Robustness via Score-Based Adversarial Image Generation",
    "volume": "main",
    "abstract": "Most adversarial attacks and defenses focus on perturbations within small $\\ell_p$-norm constraints. However, $\\ell_p$ threat models cannot capture all relevant semantics-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate unrestricted adversarial examples that overcome the limitations of $\\ell_p$-norm constraints. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG improves upon the majority of state-of-the-art attacks and defenses across multiple benchmarks. This work highlights the importance of investigating adversarial examples bounded by semantics rather than $\\ell_p$-norm constraints. ScoreAG represents an important step towards more encompassing robustness assessments",
    "checked": true,
    "id": "ae5594a166a6e490884bd46e0d5f947a28f06d27",
    "semantic_title": "assessing robustness via score-based adversarial image generation",
    "citation_count": 6,
    "authors": [
      "Marcel Kollovieh",
      "Lukas Gosch",
      "Marten Lienen",
      "Yan Scholten",
      "Leo Schwinn",
      "Stephan GÃ¼nnemann"
    ]
  },
  "https://openreview.net/forum?id=pCapRF2vFf": {
    "title": "Variational Pseudo Marginal Methods for Jet Reconstruction in Particle Physics",
    "volume": "main",
    "abstract": "Reconstructing jets, which provide vital insights into the properties and histories of subatomic particles produced in high-energy collisions, is a main problem in data analyses of collider physics. This intricate task deals with estimating the latent structure of a jet (binary tree) and involves parameters such as particle energy, momentum, and types. While Bayesian methods offer a natural approach for handling uncertainty and leveraging prior knowledge, they face significant challenges due to the super-exponential growth of potential jet topologies as the number of observed particles increases. To address this, we introduce a Combinatorial Sequential Monte Carlo approach for inferring jet latent structures. As a second contribution, we leverage the resulting estimator to develop a variational inference algorithm for parameter learning. Building on this, we introduce a variational family using a pseudo-marginal framework for a fully Bayesian treatment of all variables, unifying the generative model with the inference process. We illustrate our method's effectiveness through experiments using data generated with a collider physics generative model, highlighting superior speed and accuracy across a range of tasks",
    "checked": true,
    "id": "8c66afc54d0b00c8eb2e19204b08d7084cfb4f27",
    "semantic_title": "variational pseudo marginal methods for jet reconstruction in particle physics",
    "citation_count": 1,
    "authors": [
      "Hanming Yang",
      "Antonio Khalil Moretti",
      "Sebastian Macaluso",
      "Philippe Chlenski",
      "Christian A. Naesseth",
      "Itsik Pe'er"
    ]
  },
  "https://openreview.net/forum?id=TuACCzfty3": {
    "title": "Planning with Consistency Models for Model-Based Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "This paper introduces consistency models to the problem of sequential decision-making. Previous work applying diffusion models to planning within a model-based reinforcement learning framework often struggles with high computational cost during the inference process, primarily due to their reliance on iterative reverse diffusion processes. Consistency models, known for their computational efficiency, have already shown promise in reinforcement learning within the actor-critic algorithm. Therefore, we combine guided consistency distillation with a continuous-time diffusion model in the framework of Decision Diffuser. Our approach, named Consistency Planning, combines the robust planning capabilities of diffusion models with the speed of consistency models. We validate our method on Gym tasks in the D4RL framework, demonstrating that, when compared to its diffusion model counterparts, our method achieves more than a 12-fold increase in speed without any loss in performance",
    "checked": true,
    "id": "b015f66f73db514b5b24b1e7a9d2a26607ca19c8",
    "semantic_title": "planning with consistency models for model-based offline reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Guanquan Wang",
      "Takuya Hiraoka",
      "Yoshimasa Tsuruoka"
    ]
  },
  "https://openreview.net/forum?id=l8E68fD6yp": {
    "title": "For Robust Worst-Group Accuracy, Ignore Group Annotations",
    "volume": "main",
    "abstract": "Existing methods for last layer retraining that aim to optimize worst-group accuracy (WGA) rely heavily on well-annotated groups in the training data. We show, both in theory and practice, that annotation-based data augmentations using either downsampling or upweighting for WGA are susceptible to domain annotation noise. The WGA gap is exacerbated in high-noise regimes for models trained with vanilla empirical risk minimization (ERM). To this end, we introduce Regularized Annotation of Domains (RAD) to train robust last layer classifiers without needing explicit domain annotations. Our results show that RAD is competitive with other recently proposed domain annotation-free techniques. Most importantly, RAD outperforms state-of-the-art annotation-reliant methods even with only 5\\% noise in the training data for several publicly available datasets",
    "checked": true,
    "id": "8d522af3e06a3fed735dd7f218d7f77b36ff09fa",
    "semantic_title": "for robust worst-group accuracy, ignore group annotations",
    "citation_count": 1,
    "authors": [
      "Nathan Stromberg",
      "Rohan Ayyagari",
      "Monica Welfert",
      "Sanmi Koyejo",
      "Richard Nock",
      "Lalitha Sankar"
    ]
  },
  "https://openreview.net/forum?id=PgLbS5yp8n": {
    "title": "Uniformly Distributed Feature Representations for Fair and Robust Learning",
    "volume": "main",
    "abstract": "A fundamental challenge in machine learning is training models that generalize well to distributions different from the training distribution. Empirical Risk Minimization (ERM), which is the predominant learning principle, is known to under-perform in minority sub-populations and fail to generalize well in unseen test domains. In this work, we propose a novel learning principle called Uniform Risk Minimization (URM) to alleviate these issues. We first show theoretically that uniform training data distributions and feature representations support robustness to distribution shifts. Motivated by this result, we propose an empirical method that trains deep neural networks to learn a uniformly distributed feature representation in their final activation layer for improved robustness. Our experiments on multiple datasets for sub-population shifts and domain generalization show that URM improves the generalization of deep neural networks without requiring knowledge of groups or domains during training. URM is competitive with the best existing methods designed for these tasks and can also be easily combined with them for improved performance. Our work sheds light on the importance of the distribution of learned feature representations for model robustness and fairness. Code is available at https://github.com/kiranchari/UniformRiskMinimization",
    "checked": true,
    "id": "d3531230790f475e530c3af548669baead3cb1d0",
    "semantic_title": "uniformly distributed feature representations for fair and robust learning",
    "citation_count": 2,
    "authors": [
      "Kiran Krishnamachari",
      "See-Kiong Ng",
      "Chuan-Sheng Foo"
    ]
  },
  "https://openreview.net/forum?id=44qpZ6pkau": {
    "title": "When low-vision task meets dense prediction tasks with less data: an auxiliary self-trained geometry regularization",
    "volume": "main",
    "abstract": "Many deep learning methods are data-driven, often converging to local minima due to limited training data. This situation poses a challenge in domains where acquiring adequate data is difficult for model training or fine-tuning, such as generalized few-shot semantic segmentation (GFSSeg) and monocular depth estimation (MDE). To this end, we propose a self-trained geometry regularization framework to enhance model training or fine-tuning in scenarios with limited training data using geometric knowledge. Specifically, we propose to leverage low-level geometry information extracted from the training data and define a novel regularization term, which is a plug-and-play module jointly trained with the primary task via multi-task learning. Our proposed regularization neither relies on extra manual labels and data in training nor requires extra computation during the inference stage. We demonstrate the effectiveness of this regularization on GFSSeg and MDE tasks. Notably, it improves the state-of-the-art GFSSeg by 5.61% and 4.26% mIoU of novel classes on PASCAL and COCO in the 1-shot scenario. In MDE, it achieves a relative reduction of SILog error by 16.6% and 9.4% for two recent methods in the KITTI dataset",
    "checked": true,
    "id": "6a3e052d836ea6a17d4c42ca09259b2107676c92",
    "semantic_title": "when low-vision task meets dense prediction tasks with less data: an auxiliary self-trained geometry regularization",
    "citation_count": 0,
    "authors": [
      "ZAIWANG GU",
      "Weide Liu",
      "Xulei Yang",
      "Chuan-Sheng Foo",
      "Jun Cheng"
    ]
  },
  "https://openreview.net/forum?id=DaDBtnWcy9": {
    "title": "A Theoretical Study of The Effects of Adversarial Attacks on Sparse Regression",
    "volume": "main",
    "abstract": "This paper analyzes $\\ell_1$ regularized linear regression under the challenging scenario of having only adversarially corrupted data for training. Firstly, we prove existing deterministic adversarial attacks (e.g., FGSM and variants) focusing on maximizing the loss function can be easily handled with a few samples for support recovery. Hence, we consider a more general, challenging stochastic adversary which can be conditionally dependent on uncorrupted data and show existing models attacking support (Goodfellow et al., 2014; Madry et al., 2017) or Huber model (Prasad et al. 2018) are particular cases of our adversarial model. This enables us to show the counter-intuitive result that an adversary can influence sample complexity by corrupting the ``irrelevant features'', i.e., non-support. Secondly, as any adversarially robust algorithm has limitations, our theoretical analysis identifies that the dependence (covariance) between adversarial perturbations and uncorrupted data plays a critical role in defining the regimes under which this challenging adversary or Lasso can dominate over each other. Thirdly, we derive a necessary condition for support recovery for any algorithm (not restrictive to Lasso), which corroborates our theoretical findings for Lasso. Fourthly, we identify the fundamental limits and address critical scientific questions of which parameters (i.e., mutual incoherence, the maximum and minimum eigenvalue of the covariance matrix, and the budget of adversarial perturbations) play a role in the high or low probability of success of the Lasso algorithm. Also, the derived sample complexity is logarithmic with respect to the size of the regression parameter vector. Our theoretical claims are validated by empirical analysis",
    "checked": true,
    "id": "0846c9a3812dc95550f363b1f16e008216c85951",
    "semantic_title": "a theoretical study of the effects of adversarial attacks on sparse regression",
    "citation_count": 0,
    "authors": [
      "Deepak Maurya",
      "Jean Honorio"
    ]
  },
  "https://openreview.net/forum?id=OaVi1yjdEc": {
    "title": "Generalization Bounds with Logarithmic Negative-Sample Dependence for Adversarial Contrastive Learning",
    "volume": "main",
    "abstract": "Contrastive learning has emerged as a powerful unsupervised learning technique for extracting meaningful representations from unlabeled data by pulling similar data points closer in the representation space and pushing dissimilar ones apart. However, its vulnerability to adversarial attacks remains a critical challenge. To address this, adversarial contrastive learning â incorporating adversarial training into contrastive loss â has emerged as a promising approach to achieving robust representations that can withstand various adversarial attacks. While empirical evidence highlights its effectiveness, a comprehensive theoretical framework has been lacking. In this paper, we fill this gap by introducing generalization bounds for adversarial contrastive learning, offering key theoretical insights. Leveraging the Lipschitz continuity of loss functions, we derive generalization bounds that scale logarithmically with the number of negative samples, $K$, and apply to both linear and non-linear representations, including those obtained from deep neural networks (DNNs). Our theoretical results are supported by experiments on real-world datasets",
    "checked": true,
    "id": "6375acf98b4fd3083bf696fa2142081f6205b4ac",
    "semantic_title": "generalization bounds with logarithmic negative-sample dependence for adversarial contrastive learning",
    "citation_count": 0,
    "authors": [
      "Naghmeh Ghanooni",
      "Waleed Mustafa",
      "Yunwen Lei",
      "Anthony Widjaja Lin",
      "Marius Kloft"
    ]
  },
  "https://openreview.net/forum?id=y4VYzqQ4Me": {
    "title": "Enhancing Contrastive Clustering with Negative Pair-guided Regularization",
    "volume": "main",
    "abstract": "Contrastive Learning (CL) aims to create effective embeddings for input data by minimizing the distance between positive pairs, i.e., different augmentations or views of the same sample. To avoid degeneracy, CL also employs auxiliary loss to maximize the discrepancy between negative pairs formed with views of distinct samples. As a self-supervised learning strategy, CL inherently attempts to cluster input data into natural groups. However, the often improper trade-off between the attractive and repulsive forces, respectively induced by positive and negative pairs, can lead to deformed clustering, particularly when the number of clusters $k$ is unknown. To address this, we propose NRCC, a CL-based deep clustering framework that generates cluster-friendly embeddings. NRCC repurposes Stochastic Gradient Hamiltonian Monte Carlo sampling as an approximately invariant data augmentation, to curate hard negative pairs that judiciously enhance and balance the two adversarial forces through a regularizer. By preserving the cluster structure in the CL embedding, NRCC retains local density landscapes in lower dimensions through neighborhood-conserving projections. This enables the application of mode-seeking clustering algorithms, typically hindered by high-dimensional CL feature spaces, to achieve exceptional accuracy without needing a predetermined $k$. NRCC's superiority is demonstrated across various datasets with different scales and cluster structures, outperforming 20 state-of-the-art methods",
    "checked": true,
    "id": "54ea0cd51a3f32b34cc648940d2103270d0bd9b9",
    "semantic_title": "enhancing contrastive clustering with negative pair-guided regularization",
    "citation_count": 0,
    "authors": [
      "Abhishek Kumar",
      "Anish Chakrabarty",
      "Sankha Subhra Mullick",
      "Swagatam Das"
    ]
  },
  "https://openreview.net/forum?id=JbuP6UV3Fk": {
    "title": "Score-Based Multimodal Autoencoder",
    "volume": "main",
    "abstract": "Multimodal Variational Autoencoders (VAEs) represent a promising group of generative models that facilitate the construction of a tractable posterior within the latent space given multiple modalities. Previous studies have shown that as the number of modalities increases, the generative quality of each modality declines. In this study, we explore an alternative approach to enhance the generative performance of multimodal VAEs by jointly modeling the latent space of independently trained unimodal VAEs using score-based models (SBMs). The role of the SBM is to enforce multimodal coherence by learning the correlation among the latent variables. Consequently, our model combines a better generative quality of unimodal VAEs with coherent integration across different modalities using the latent score-based model. In addition, our approach provides the best unconditional coherence",
    "checked": true,
    "id": "7c190e92e59e6b6089314fd1c78a45a3cc5000c3",
    "semantic_title": "score-based multimodal autoencoder",
    "citation_count": 0,
    "authors": [
      "Daniel Wesego",
      "Pedram Rooshenas"
    ]
  },
  "https://openreview.net/forum?id=LRf19n5Ly3": {
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "volume": "main",
    "abstract": "The model editing problem concerns how language models should learn new facts about the world over time. While empirical research on model editing has drawn widespread attention, the conceptual foundations of model editing remain shaky -- perhaps unsurprisingly, since model editing is essentially belief revision, a storied problem in philosophy that has eluded succinct solutions for decades. Model editing nonetheless demands a solution, since we need to be able to control knowledge within language models. With this goal in mind, this paper critiques the standard formulation of the model editing problem and proposes a formal testbed for model editing research. We first describe 13 open problems with model editing, based on challenges with (1) defining the problem, (2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the first place. Many of the challenges are extremely difficult to address, e.g. determining far-reaching consequences of edits, labeling probabilistic entailments between facts, and updating beliefs of agent simulators. Next, we introduce a semi-synthetic dataset for model editing based on Wikidata, where we can evaluate edits against labels given by an idealized Bayesian agent. This enables us to say exactly how belief revision in language models falls short of a desirable epistemic standard. We encourage further research exploring settings where such a gold standard can be compared against",
    "checked": true,
    "id": "7de74421fb1acafcb41728223c26bc23cbfdb3e0",
    "semantic_title": "fundamental problems with model editing: how should rational belief revision work in llms?",
    "citation_count": 17,
    "authors": [
      "Peter Hase",
      "Thomas Hofweber",
      "Xiang Zhou",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ]
  },
  "https://openreview.net/forum?id=hQIs1CHF6H": {
    "title": "Application of Bagged Copula-GP: Confirming Neural Dependency on Pupil Dilation",
    "volume": "main",
    "abstract": "Advancements in recording techniques has enabled the ability to record thousands of neurons simultaneously, shifting the needs within the field of computational neuroscience to powerful computational and statistical techniques. Copula-GP is a recently developed state-of-the-art parametric mutual information estimator found to outperform other novel non-parametric methods when utilized on highly dimensional data. Here, we utilized Copula-GP together with Gaussian Process Factor Analysis (GPFA) to investigate the information interaction between neuronal processes within the visual cortex of live mice and pupil dilation. We found usage of GPFA as a preprocessing step to Copula-GP was an effective means of investigating neuronal dependence, allowing flexibility in analysis and finding results in agreement with prior literature, and additionally extended Copula-GP with a bagging framework, allowing for the aggregation of model estimations and allowing for more accurate estimation accuracy and representation of dependency shape. We validated our bagging algorithm on simulated data sampled from known distributions, and utilized bagged Copula-GP with GPFA on said neuronal data to find results in agreement with baseline Copula-GP but with more stability",
    "checked": true,
    "id": "6463e860865d08b137d5874d6965c1c56f857276",
    "semantic_title": "application of bagged copula-gp: confirming neural dependency on pupil dilation",
    "citation_count": 0,
    "authors": [
      "Maximilian Walden"
    ]
  },
  "https://openreview.net/forum?id=0RUzRV05Jn": {
    "title": "Toward a Complete Criterion for Value of Information in Insoluble Decision Problems",
    "volume": "main",
    "abstract": "In a decision problem, observations are said to be material if they must be taken into account to perform optimally. Decision problems have an underlying (graphical) causal structure, which may sometimes be used to evaluate certain observations as immaterial. For soluble graphs â ones where important past observations are remembered â there is a complete graphical criterion; one that rules out materiality whenever this can be done on the basis of the graphical structure alone. In this work, we analyse a proposed criterion for insoluble graphs. In particular, we prove that some of the conditions used to prove immateriality are necessary; when they are not satisfied, materiality is possible. We discuss possible avenues and obstacles to proving necessity of the remaining conditions",
    "checked": true,
    "id": "be6831fac6a6f867eabea86dbef00614ea99b142",
    "semantic_title": "toward a complete criterion for value of information in insoluble decision problems",
    "citation_count": 0,
    "authors": [
      "Ryan Carey",
      "Sanghack Lee",
      "Robin J. Evans"
    ]
  },
  "https://openreview.net/forum?id=lAKvQO4vHj": {
    "title": "Risk Bounds for Mixture Density Estimation on Compact Domains via the h-Lifted KullbackâLeibler Divergence",
    "volume": "main",
    "abstract": "We consider the problem of estimating probability density functions based on sample data, using a finite mixture of densities from some component class. To this end, we introduce the $h$-lifted Kullback--Leibler~(KL) divergence as a generalization of the standard KL divergence and a criterion for conducting risk minimization. Under a compact support assumption, we prove an $\\mathcal{O}(1/{\\sqrt{n}})$ bound on the expected estimation error when using the $h$-lifted KL divergence, which extends the results of Rakhlin et al. (2005, ESAIM: Probability and Statistics, Vol. 9) and Li & Barron (1999, Advances in Neural Information Processing Systems, Vol. 12) to permit the risk bounding of density functions that are not strictly positive. We develop a procedure for the computation of the corresponding maximum $h$-lifted likelihood estimators ($h$-MLLEs) using the Majorization-Maximization framework and provide experimental results in support of our theoretical bounds",
    "checked": false,
    "id": "7b9fa4e1c053e5e83155a46cc2728fe126ba29a8",
    "semantic_title": "risk bounds for mixture density estimation on compact domains via the h-lifted kullback-leibler divergence",
    "citation_count": 1,
    "authors": [
      "Mark Chiu Chong",
      "Hien Duy Nguyen",
      "TrungTin Nguyen"
    ]
  },
  "https://openreview.net/forum?id=nm40lbbwoR": {
    "title": "Implicit Regularization of AdaDelta",
    "volume": "main",
    "abstract": "We consider the AdaDelta adaptive optimization algorithm on locally Lipschitz, positively homogeneous, and o-minimally definable neural networks, with either the exponential or the logistic loss. We prove that, after achieving perfect training accuracy, the resulting adaptive gradient flows converge in direction to a Karush-Kuhn-Tucker point of the margin maximization problem, i.e. perform the same implicit regularization as the plain gradient flows. We also prove that the loss decreases to zero and the Euclidean norm of the parameters increases to infinity at the same rates as for the plain gradient flows. Moreover, we consider generalizations of AdaDelta where the exponential decay coefficients may vary with time and the numerical stability terms may be different across the parameters, and we obtain the same results provided the former do not approach 1 too quickly and the latter have isotropic quotients. Finally, we corroborate our theoretical results by numerical experiments on convolutional networks with MNIST and CIFAR-10 datasets",
    "checked": true,
    "id": "319f357837ef09e08579dc0e64d441ea7420ef74",
    "semantic_title": "implicit regularization of adadelta",
    "citation_count": 0,
    "authors": [
      "Matthias Englert",
      "Ranko Lazic",
      "Avi Semler"
    ]
  },
  "https://openreview.net/forum?id=SUMtDJqicd": {
    "title": "Analysis of Classifier-Free Guidance Weight Schedulers",
    "volume": "main",
    "abstract": "Classifier-Free Guidance (CFG) enhances the quality and condition adherence of text-to-image diffusion models. It operates by combining the conditional and unconditional predictions using a fixed weight. However, recent works vary the weights throughout the diffusion process, reporting superior results but without providing any rationale or analysis. By conducting comprehensive experiments, this paper provides insights into CFG weight schedulers. Our findings suggest that simple, monotonically increasing weight schedulers consistently lead to improved performances, requiring merely a single line of code. In addition, more complex parametrized schedulers can be optimized for further improvement, but do not generalize across different models and tasks",
    "checked": true,
    "id": "cdfd77ec921a08a60812757c8dbac88dabeaaf8c",
    "semantic_title": "analysis of classifier-free guidance weight schedulers",
    "citation_count": 20,
    "authors": [
      "Xi WANG",
      "Nicolas Dufour",
      "Nefeli Andreou",
      "Marie-Paule CANI",
      "Victoria Fernandez Abrevaya",
      "David Picard",
      "Vicky Kalogeiton"
    ]
  },
  "https://openreview.net/forum?id=VrWl6yNk1E": {
    "title": "Reinforcement Learning for Node Selection in Branch-and-Bound",
    "volume": "main",
    "abstract": "A big challenge in branch and bound lies in identifying the optimal node within the search tree from which to proceed. Current state-of-the-art selectors utilize either hand-crafted ensembles that automatically switch between naive sub-node selectors, or learned node selectors that rely on individual node data. In contrast to existing approaches that only consider isolated nodes, we propose a novel simulation technique that uses reinforcement learning (RL) while considering the entire tree state. To achieve this, we train a graph neural network that produces a probability distribution based on the path from the model's root to its ``to-be-selected'' leaves. Representing node-selection as a probability distribution allows us to train a decision-making policy using state-of-the-art RL techniques that capture both intrinsic node-quality and node-evaluation costs. Our method induces a high quality node selection policy on a set of varied and complex problem sets, despite only being trained on specially designed, synthetic travelling salesmen problem (TSP) instances. Using such a \\emph{fixed pretrained} policy shows significant improvements on several benchmarks in optimality gap reductions and per-node efficiency under strict time constraints",
    "checked": true,
    "id": "5c6c17cbe5fe0899a9097ac8b38cd3070a1f4e5b",
    "semantic_title": "reinforcement learning for node selection in branch-and-bound",
    "citation_count": 2,
    "authors": [
      "Alexander Julian Mattick",
      "Christopher Mutschler"
    ]
  },
  "https://openreview.net/forum?id=aukOnn7J4M": {
    "title": "Set Features for Anomaly Detection",
    "volume": "main",
    "abstract": "This paper proposes to use set features for detecting anomalies in samples that consist of unusual combinations of normal elements. Many leading methods discover anomalies by detecting an unusual part of a sample. For example, state-of-the-art segmentation-based approaches, first classify each element of the sample (e.g., image patch) as normal or anomalous and then classify the entire sample as anomalous if it contains anomalous elements. However, such approaches do not extend well to scenarios where the anomalies are expressed by an unusual combination of normal elements. In this paper, we overcome this limitation by proposing set features that model each sample by the distribution of its elements. We compute the anomaly score of each sample using a simple density estimation method, using fixed features. Our approach outperforms the previous state-of-the-art in image-level logical anomaly detection and sequence-level time series anomaly detection",
    "checked": true,
    "id": "e77150fd90164d9f27c2d03bf62d03ff7cbd5229",
    "semantic_title": "set features for anomaly detection",
    "citation_count": 0,
    "authors": [
      "Niv Cohen",
      "Issar Tzachor",
      "Yedid Hoshen"
    ]
  },
  "https://openreview.net/forum?id=RYtJmFDAxv": {
    "title": "Separable Operator Networks",
    "volume": "main",
    "abstract": "Operator learning has become a powerful tool in machine learning for modeling complex physical systems governed by partial differential equations (PDEs). Although Deep Operator Networks (DeepONet) show promise, they require extensive data acquisition. Physics-informed DeepONets (PI-DeepONet) mitigate data scarcity but suffer from inefficient training processes. We introduce Separable Operator Networks (SepONet), a novel framework that significantly enhances the efficiency of physics-informed operator learning. SepONet uses independent trunk networks to learn basis functions separately for different coordinate axes, enabling faster and more memory-efficient training via forward-mode automatic differentiation. We provide a universal approximation theorem for SepONet proving the existence of a separable approximation to any nonlinear continuous operator. Then, we comprehensively benchmark its representational capacity and computational performance against PI-DeepONet. Our results demonstrate SepONet's superior performance across various nonlinear and inseparable PDEs, with SepONet's advantages increasing with problem complexity, dimension, and scale. For 1D time-dependent PDEs, SepONet achieves up to 112Ã faster training and 82Ã reduction in GPU memory usage compared to PI-DeepONet, while maintaining comparable accuracy. For the 2D time-dependent nonlinear diffusion equation, SepONet efficiently handles the complexity, achieving a 6.44% mean relative $\\ell_{2}$ test error, while PI-DeepONet fails due to memory constraints. This work paves the way for extreme-scale learning of continuous mappings between infinite-dimensional function spaces. Open source code is available at https://github.com/HewlettPackard/separable-operator-networks",
    "checked": true,
    "id": "df7ccff15abfd241fc963ea0b34062bc42a014fb",
    "semantic_title": "separable operator networks",
    "citation_count": 4,
    "authors": [
      "Xinling Yu",
      "Sean Hooten",
      "Ziyue Liu",
      "Yequan Zhao",
      "Marco Fiorentino",
      "Thomas Van Vaerenbergh",
      "Zheng Zhang"
    ]
  },
  "https://openreview.net/forum?id=SBE2q9qwZj": {
    "title": "Fast Computation of Leave-One-Out Cross-Validation for $k$-NN Regression",
    "volume": "main",
    "abstract": "We describe a fast computation method for leave-one-out cross-validation (LOOCV) for $k$-nearest neighbours ($k$-NN) regression. We show that, under a tie-breaking condition for nearest neighbours, the LOOCV estimate of the mean square error for $k$-NN regression is identical to the mean square error of $(k+1)$-NN regression evaluated on the training data, multiplied by the scaling factor $(k+1)^2/k^2$. Therefore, to compute the LOOCV score, one only needs to fit $(k+1)$-NN regression only once, and does not need to repeat training-validation of $k$-NN regression for the number of training data. Numerical experiments confirm the validity of the fast computation method",
    "checked": false,
    "id": "1f6d45bb8d44e526db7ad2ee3c6d8509a7a8126e",
    "semantic_title": "fast computation of leave-one-out cross-validation for k-nn regression",
    "citation_count": 0,
    "authors": [
      "Motonobu Kanagawa"
    ]
  },
  "https://openreview.net/forum?id=rZNuiFwXVs": {
    "title": "Masked Autoencoders are PDE Learners",
    "volume": "main",
    "abstract": "Neural solvers for partial differential equations (PDEs) have great potential to generate fast and accurate physics solutions, yet their practicality is currently limited by their generalizability. PDEs evolve over broad scales and exhibit diverse behaviors; predicting these phenomena will require learning representations across a wide variety of inputs which may encompass different coefficients, boundary conditions, resolutions, or even equations. As a step towards generalizable PDE modeling, we adapt masked pretraining for physics problems. Through self-supervised learning across PDEs, masked autoencoders can consolidate heterogeneous physics to learn rich latent representations. We show that learned representations can generalize to a limited set of unseen equations or parameters and are meaningful enough to regress PDE coefficients or the classify PDE features. Furthermore, conditioning neural solvers on learned latent representations can improve time-stepping and super-resolution performance across a variety of coefficients, discretizations, or boundary conditions, as well as on certain unseen PDEs. We hope that masked pretraining can emerge as a unifying method across large, unlabeled, and heterogeneous datasets to learn latent physics at scale",
    "checked": true,
    "id": "86460fbb718d37eba311087a36362a4584857438",
    "semantic_title": "masked autoencoders are pde learners",
    "citation_count": 7,
    "authors": [
      "Anthony Zhou",
      "Amir Barati Farimani"
    ]
  },
  "https://openreview.net/forum?id=I0uknSHM2j": {
    "title": "The Unreasonable Effectiveness of Gaussian Score Approximation for Diffusion Models and its Applications",
    "volume": "main",
    "abstract": "Diffusion models have achieved remarkable results in multiple domains of generative modeling. By learning the gradient of smoothed data distributions, they can iteratively generate samples from complex distributions, e.g., of natural images. The learned score function enables their generalization capabilities, but how the learned score relates to the score of the underlying data manifold remains largely unclear. Here, we aim to elucidate this relationship by comparing the learned scores of neural-network-based models to the scores of two kinds of analytically tractable distributions: Gaussians and Gaussian mixtures. The simplicity of the Gaussian model makes it particularly attractive from a theoretical point of view, and we show that it admits a closed-form solution and predicts many qualitative aspects of sample generation dynamics. We claim that the learned neural score is dominated by its linear (Gaussian) approximation for moderate to high noise scales, and supply both theoretical and empirical arguments to support this claim. Moreover, the Gaussian approximation empirically works for a larger range of noise scales than naive theory suggests it should, and is preferentially learned by networks early in training. At smaller noise scales, we observe that learned scores are better described by a coarse-grained (Gaussian mixture) approximation of training data than by the score of the training distribution, a finding consistent with generalization. Our findings enable us to precisely predict the initial phase of trained models' sampling trajectories through their Gaussian approximations. We show that this allows one to leverage the Gaussian analytical solution to skip the first 15-30\\% of sampling steps while maintaining high sample quality (with a near state-of-the-art FID score of 1.93 on CIFAR-10 unconditional generation). This forms the foundation of a novel hybrid sampling method, termed \\textit{analytical teleportation}, which can seamlessly integrate with and accelerate existing samplers, including DPM-Solver-v3 and UniPC. Our findings strengthen the field's theoretical understanding of how diffusion models work and suggest ways to improve the design and training of diffusion models",
    "checked": true,
    "id": "46571763da00b88db7ae2cd504796c79a4031cc7",
    "semantic_title": "the unreasonable effectiveness of gaussian score approximation for diffusion models and its applications",
    "citation_count": 13,
    "authors": [
      "Binxu Wang",
      "John Vastola"
    ]
  },
  "https://openreview.net/forum?id=8JNXOB6FtW": {
    "title": "When Stability meets Sufficiency: Informative Explanations that do not Overwhelm",
    "volume": "main",
    "abstract": "Recent studies evaluating various criteria for explainable artificial intelligence (XAI) suggest that fidelity, stability, and comprehensibility are among the most important metrics considered by users of AI across a diverse collection of usage contexts. We consider these criteria as applied to feature-based attribution methods, which are amongst the most prevalent in XAI literature. Going beyond standard correlation, methods have been proposed that highlight what should be minimally sufficient to justify the classification of an input (viz. pertinent positives). While minimal sufficiency is an attractive property akin to comprehensibility, the resulting explanations are often too sparse for a human to understand and evaluate the local behavior of the model. To overcome these limitations, we incorporate the criteria of stability and fidelity and propose a novel method called Path-Sufficient Explanations Method (PSEM) that outputs a sequence of stable and sufficient explanations for a given input of strictly decreasing size (or value) -- from original input to a minimally sufficient explanation -- which can be thought to trace the local boundary of the model in a stable manner, thus providing better intuition about the local model behavior for the specific input. We validate these claims, both qualitatively and quantitatively, with experiments that show the benefit of PSEM across three modalities (image, tabular and text) as well as versus other path explanations. A user study depicts the strength of the method in communicating the local behavior, where (many) users are able to correctly determine the prediction made by a model",
    "checked": false,
    "id": "0eabae92ca020f09dd33691a2caaa898b2d295fc",
    "semantic_title": "when stability meets suï¬ciency: informative explanations that do not overwhelm",
    "citation_count": 0,
    "authors": [
      "Ronny Luss",
      "Amit Dhurandhar"
    ]
  },
  "https://openreview.net/forum?id=AWRpSgaNfc": {
    "title": "Exact Fractional Inference via Re-Parametrization \\& Interpolation between Tree-Re-Weighted- and Belief Propagation- Algorithms",
    "volume": "main",
    "abstract": "Computing the partition function, $Z$, of an Ising model over a graph of $N$ \\enquote{spins} is most likely exponential in $N$. Efficient variational methods, such as Belief Propagation (BP) and Tree Re-Weighted (TRW) algorithms, compute $Z$ approximately by minimizing the respective (BP- or TRW-) free energy. We generalize the variational scheme by building a $\\lambda$-fractional interpolation, $Z^{(\\lambda)}$, where $\\lambda=0$ and $\\lambda=1$ correspond to TRW- and BP-approximations, respectively. This fractional scheme -- coined Fractional Belief Propagation (FBP) -- guarantees that in the attractive (ferromagnetic) case $Z^{(TRW)} \\geq Z^{(\\lambda)} \\geq Z^{(BP)}$, and there exists a unique (\\enquote{exact}) $\\lambda_*$ such that $Z=Z^{(\\lambda_*)}$. Generalizing the re-parametrization approach of \\citep{wainwright_tree-based_2002} and the loop series approach of \\citep{chertkov_loop_2006}, we show how to express $Z$ as a product, $\\forall \\lambda:\\ Z=Z^{(\\lambda)}{\\tilde Z}^{(\\lambda)}$, where the multiplicative correction, ${\\tilde Z}^{(\\lambda)}$, is an expectation over a node-independent probability distribution built from node-wise fractional marginals. Our theoretical analysis is complemented by extensive experiments with models from Ising ensembles over planar and random graphs of medium and large sizes. Our empirical study yields a number of interesting observations, such as the ability to estimate ${\\tilde Z}^{(\\lambda)}$ with $O(N^{2::4})$ fractional samples and suppression of variation in $\\lambda_*$ estimates with an increase in $N$ for instances from a particular random Ising ensemble, where $[2::4]$ indicates a range from $2$ to $4$. We also verify and discuss the applicability of this approach to the problem of image de-noising. Based on these experiments and the theory, we conclude that both the computation of the partition function and the computation of marginals can be efficiently performed via FBP at the optimal value of $\\lambda_*$",
    "checked": false,
    "id": "4fd23b08d47ed62db34f2ca8b09f10acab3fe1e0",
    "semantic_title": "exact fractional inference via re-parametrization & interpolation between tree-re-weighted- and belief propagation- algorithms",
    "citation_count": 1,
    "authors": [
      "Hamidreza Behjoo",
      "Michael Chertkov"
    ]
  },
  "https://openreview.net/forum?id=NUkEoZ7Toa": {
    "title": "Hierarchical VAE with a Diffusion-based VampPrior",
    "volume": "main",
    "abstract": "Deep hierarchical variational autoencoders (VAEs) are powerful latent variable generative models. In this paper, we introduce Hierarchical VAE with Diffusion-based Variational Mixture of the Posterior Prior (VampPrior). We apply amortization to scale the VampPrior to models with many stochastic layers. The proposed approach allows us to achieve better performance compared to the original VampPrior work and other deep hierarchical VAEs, while using fewer parameters. We empirically validate our method on standard benchmark datasets (MNIST, OMNIGLOT, CIFAR10) and demonstrate improved training stability and latent space utilization",
    "checked": true,
    "id": "bb2342333372a57d558a501312d4a8b610873f8b",
    "semantic_title": "hierarchical vae with a diffusion-based vampprior",
    "citation_count": 3,
    "authors": [
      "Anna Kuzina",
      "Jakub M. Tomczak"
    ]
  },
  "https://openreview.net/forum?id=wFcyJTik90": {
    "title": "Feudal Graph Reinforcement Learning",
    "volume": "main",
    "abstract": "Graph-based representations and message-passing modular policies constitute prominent approaches to tackling composable control problems in reinforcement learning (RL). However, as shown by recent graph deep learning literature, such local message-passing operators can create information bottlenecks and hinder global coordination. The issue becomes more serious in tasks requiring high-level planning. In this work, we propose a novel methodology, named Feudal Graph Reinforcement Learning (FGRL), that addresses such challenges by relying on hierarchical RL and a pyramidal message-passing architecture. In particular, FGRL defines a hierarchy of policies where high-level commands are propagated from the top of the hierarchy down through a layered graph structure. The bottom layers mimic the morphology of the physical system, while the upper layers correspond to higher-order sub-modules. The resulting agents are then characterized by a committee of policies where actions at a certain level set goals for the level below, thus implementing a hierarchical decision-making structure that can naturally implement task decomposition. We evaluate the proposed framework on a graph clustering problem and MuJoCo locomotion tasks; simulation results show that FGRL compares favorably against relevant baselines. Furthermore, an in-depth analysis of the command propagation mechanism provides evidence that the introduced message-passing scheme favors learning hierarchical decision-making policies",
    "checked": true,
    "id": "d9854df0a7474414958dd7d45fbfca4cb0f4a4eb",
    "semantic_title": "feudal graph reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Tommaso Marzi",
      "Arshjot Singh Khehra",
      "Andrea Cini",
      "Cesare Alippi"
    ]
  },
  "https://openreview.net/forum?id=21kO0u6LN0": {
    "title": "Towards Size-Independent Generalization Bounds for Deep Operator Nets",
    "volume": "main",
    "abstract": "In recent times machine learning methods have made significant advances in becoming a useful tool for analyzing physical systems. A particularly active area in this theme has been ``physics-informed machine learning'' which focuses on using neural nets for numerically solving differential equations. In this work, we aim to advance the theory of measuring out-of-sample error while training DeepONets -- which is among the most versatile ways to solve P.D.E systems in one-shot. Firstly, for a class of DeepONets, we prove a bound on their Rademacher complexity which does not explicitly scale with the width of the nets involved. Secondly, we use this to show how the Huber loss can be chosen so that for these DeepONet classes generalization error bounds can be obtained that have no explicit dependence on the size of the nets. The effective capacity measure for DeepONets that we thus derive is also shown to correlate with the behavior of generalization error in experiments",
    "checked": true,
    "id": "17df8a2a5b5615c022c84bbef31ce9401de39948",
    "semantic_title": "towards size-independent generalization bounds for deep operator nets",
    "citation_count": 5,
    "authors": [
      "Pulkit Gopalani",
      "Sayar Karmakar",
      "Dibyakanti Kumar",
      "Anirbit Mukherjee"
    ]
  },
  "https://openreview.net/forum?id=0r9mhjRv1E": {
    "title": "UPS: Efficiently Building Foundation Models for PDE Solving via Cross-Modal Adaptation",
    "volume": "main",
    "abstract": "We present Unified PDE Solvers (UPS), a data- and compute-efficient approach to developing unified neural operators for diverse families of spatiotemporal PDEs from various domains, dimensions, and resolutions. UPS embeds different PDEs into a shared representation space and processes them using a FNO-transformer architecture. Rather than training the network from scratch, which is data-demanding and computationally expensive, we warm-start the transformer from pretrained LLMs and perform explicit alignment to reduce the modality gap while improving data and compute efficiency. The cross-modal UPS achieves state-of-the-art results on a wide range of 1D and 2D PDE families from PDEBench, outperforming existing unified models using 4 times less data and 26 times less compute. Meanwhile, it is capable of few-shot transfer to unseen PDE families and coefficients",
    "checked": true,
    "id": "73e5b9cc3645d37eba7838709abe071cffa21e34",
    "semantic_title": "ups: efficiently building foundation models for pde solving via cross-modal adaptation",
    "citation_count": 6,
    "authors": [
      "Junhong Shen",
      "Tanya Marwah",
      "Ameet Talwalkar"
    ]
  },
  "https://openreview.net/forum?id=dKKY2mDEnD": {
    "title": "Evaluating the Evaluators: Are Validation Methods for Few-Shot Learning Fit for Purpose?",
    "volume": "main",
    "abstract": "Numerous benchmarks for Few-Shot Learning have been proposed in the last decade. However all of these benchmarks focus on performance averaged over many tasks, and the question of how to reliably evaluate and tune models trained for individual few-shot tasks has not been addressed. This paper presents the first investigation into task-level validation---a fundamental step when deploying a model. We measure the accuracy of performance estimators in the few-shot setting, consider strategies for model selection, and examine the reasons for the failure of evaluators usually thought of as being robust. We conclude that cross-validation with a low number of folds is the best choice for directly estimating the performance of a model, whereas using bootstrapping or cross validation with a large number of folds is better for model selection purposes. Overall, we find that with current methods, benchmarks, and validation strategies, one can not get a reliable picture of how effectively methods perform on individual tasks. However, we find that existing methods already provide enough information to enable selection of few-shot learners on a task-level basis",
    "checked": true,
    "id": "14965a770f93ebf3066398e1d070a37aaaa47604",
    "semantic_title": "evaluating the evaluators: are validation methods for few-shot learning fit for purpose?",
    "citation_count": 0,
    "authors": [
      "LuÃ­sa Shimabucoro",
      "Ruchika Chavhan",
      "Timothy Hospedales",
      "Henry Gouk"
    ]
  },
  "https://openreview.net/forum?id=FNBv2vweBI": {
    "title": "Constraining Generative Models for Engineering Design with Negative Data",
    "volume": "main",
    "abstract": "Generative models have recently achieved remarkable success and widespread adoption in society, yet they still often struggle to generate realistic and accurate outputs. This challenge extends beyond language and vision into fields like engineering design, where safety-critical engineering standards and non-negotiable physical laws tightly constrain what outputs are considered acceptable. In this work, we introduce two approaches to guide models toward constraint-satisfying outputs using `negative data' -- examples of what to avoid. Our negative data generative models (NDGMs) outperform state-of-the-art NDGMs by 4x in constraint satisfaction and easily outperform classic generative models using 8x less data in certain problems. To demonstrate this, we rigorously benchmark our NDGMs against 14 baseline models across numerous synthetic and real engineering problems, such as ship hulls with hydrodynamic constraints and vehicle design with impact safety constraints. Our benchmarks showcase both the best-in-class performance of our new NDGM models and the widespread dominance of NDGMs over classic generative models in general. In doing so, we advocate for the more widespread use of NDGMs in engineering design tasks",
    "checked": true,
    "id": "13ce8c7ea8ac0cdb20e6c0f4d16120cb64298f90",
    "semantic_title": "constraining generative models for engineering design with negative data",
    "citation_count": 9,
    "authors": [
      "Lyle Regenwetter",
      "Giorgio Giannone",
      "Akash Srivastava",
      "Dan Gutfreund",
      "Faez Ahmed"
    ]
  },
  "https://openreview.net/forum?id=iBnPpN2hr5": {
    "title": "Strengthening Interpretability: An Investigative Study of Integrated Gradient Methods",
    "volume": "main",
    "abstract": "We conducted a reproducibility study on Integrated Gradients (IG) based methods and the Important Direction Gradient Integration (IDGI) framework. IDGI eliminates the explanation noise in each step of the computation of IG-based methods that use the Riemann Integration for integrated gradient computation. We perform a rigorous theoretical analysis of IDGI and raise a few critical questions that we later address through our study. We also experimentally verify the authors' claims concerning the performance of IDGI over IG-based methods. Additionally, we varied the number of steps used in the Riemann approximation, an essential parameter in all IG methods, and analyzed the corresponding change in results. We also studied the numerical instability of the attribution methods to check the consistency of the saliency maps produced. We developed the complete code to implement IDGI over the baseline IG methods and evaluated them using three metrics since the available code was insufficient for this study. Our code is readily usable and publicly available at https://github.com/ShreeSinghi/TMLR-IDGI",
    "checked": true,
    "id": "1e83a04ad8bad67e25ed05ba8dc72438711c0107",
    "semantic_title": "strengthening interpretability: an investigative study of integrated gradient methods",
    "citation_count": 1,
    "authors": [
      "Shree Singhi",
      "Anupriya Kumari"
    ]
  },
  "https://openreview.net/forum?id=oG65SjZNIF": {
    "title": "Expressive Higher-Order Link Prediction through Hypergraph Symmetry Breaking",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b1a75e8c1bd358c3f190a3db9074d53c55ee1858",
    "semantic_title": "expressive higher-order link prediction through hypergraph symmetry breaking",
    "citation_count": 1,
    "authors": [
      "Simon Zhang",
      "Cheng Xin",
      "Tamal K. Dey"
    ]
  },
  "https://openreview.net/forum?id=dwJluAakM8": {
    "title": "Optimized Tradeoffs for Private Prediction with Majority Ensembling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4a92ca44becb2f778c3d17ec2d57f32c8a6c9a14",
    "semantic_title": "optimized tradeoffs for private prediction with majority ensembling",
    "citation_count": 0,
    "authors": [
      "Shuli Jiang",
      "Qiuyi Zhang",
      "Gauri Joshi"
    ]
  },
  "https://openreview.net/forum?id=PlaZD2nGCl": {
    "title": "Dataset Distillation via Curriculum Data Synthesis in Large Data Era",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8c9a5565b8b284e8ed60bdb2864e106ba5c6bd3e",
    "semantic_title": "dataset distillation via curriculum data synthesis in large data era",
    "citation_count": 9,
    "authors": [
      "Zeyuan Yin",
      "Zhiqiang Shen"
    ]
  },
  "https://openreview.net/forum?id=N8M2yqRicS": {
    "title": "Active Learning for Level Set Estimation Using Randomized Straddle Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "065bfd2583c8bdf67e97a3c3f9bc4ab074e10794",
    "semantic_title": "active learning for level set estimation using randomized straddle algorithms",
    "citation_count": 3,
    "authors": [
      "Yu Inatsu",
      "Shion Takeno",
      "Kentaro KUTSUKAKE",
      "Ichiro Takeuchi"
    ]
  },
  "https://openreview.net/forum?id=x2uFJ79OjK": {
    "title": "UniCtrl: Improving the Spatiotemporal Consistency of Text-to-Video Diffusion Models via Training-Free Unified Attention Control",
    "volume": "main",
    "abstract": "Video Diffusion Models have been developed for video generation, usually integrating text and image conditioning to enhance control over the generated content. Despite the progress, ensuring consistency across frames remains a challenge, particularly when using text prompts as control conditions. To address this problem, we introduce UniCtrl, a novel, plug-and-play method that is universally applicable to improve the spatiotemporal consistency and motion diversity of videos generated by text-to-video models without additional training. UniCtrl ensures semantic consistency across different frames through cross-frame self-attention control, and meanwhile, enhances the motion quality and spatiotemporal consistency through motion injection and spatiotemporal synchronization. Our experimental results demonstrate UniCtrl's efficacy in enhancing various text-to-video models, confirming its effectiveness and universality",
    "checked": true,
    "id": "56851adbacd4f5a670b005cc3c2f86ec328f81c3",
    "semantic_title": "unictrl: improving the spatiotemporal consistency of text-to-video diffusion models via training-free unified attention control",
    "citation_count": 8,
    "authors": [
      "Tian Xia",
      "Xuweiyi Chen",
      "Sihan Xu"
    ]
  },
  "https://openreview.net/forum?id=IJlbuSrXmk": {
    "title": "Audio-Visual Dataset Distillation",
    "volume": "main",
    "abstract": "In this article, we introduce \\textit{audio-visual dataset distillation}, a task to construct a smaller yet representative synthetic audio-visual dataset that maintains the cross-modal semantic association between audio and visual modalities. Dataset distillation techniques have primarily focused on image classification. However, with the growing capabilities of audio-visual models and the vast datasets required for their training, it is necessary to explore distillation methods beyond the visual modality. Our approach builds upon the foundation of Distribution Matching (DM), extending it to handle the unique challenges of audio-visual data. A key challenge is to jointly learn synthetic data that distills both the modality-wise information and natural alignment from real audio-visual data. We introduce a vanilla audio-visual distribution matching framework that separately trains visual-only and audio-only DM components, enabling us to investigate the effectiveness of audio-visual integration and various multimodal fusion methods. To address the limitations of unimodal distillation, we propose two novel matching losses: implicit cross-matching and cross-modal gap matching. These losses work in conjunction with the vanilla unimodal distribution matching loss to enforce cross-modal alignment and enhance the audio-visual dataset distillation process. Extensive audio-visual classification and retrieval experiments on four audio-visual datasets, AVE, MUSIC-21, VGGSound, and VGGSound-10K, demonstrate the effectiveness of our proposed matching approaches and validate the benefits of audio-visual integration with condensed data. This work establishes a new frontier in audio-visual dataset distillation, paving the way for further advancements in this exciting field. \\textit{Our source code and pre-trained models will be released}",
    "checked": true,
    "id": "5a7ae5ba0544977a735c7defcaec58f6ba854e84",
    "semantic_title": "audio-visual dataset distillation",
    "citation_count": 1,
    "authors": [
      "Saksham Singh Kushwaha",
      "Siva Sai Nagender Vasireddy",
      "Kai Wang",
      "Yapeng Tian"
    ]
  },
  "https://openreview.net/forum?id=Flh5EXz8dA": {
    "title": "Stealthy Backdoor Attack via Confidence-driven Sampling",
    "volume": "main",
    "abstract": "Backdoor attacks facilitate unauthorized control in the testing stage by carefully injecting harmful triggers during the training phase of deep neural networks. Previous works have focused on improving the stealthiness of the trigger while randomly selecting samples to attack. However, we find that random selection harms the stealthiness of the model. In this paper, we identify significant pitfalls of random sampling, which make the attacks more detectable and easier to defend against. To improve the stealthiness of existing attacks, we introduce a method of strategically poisoning samples near the model's decision boundary, aiming to minimally alter the model's behavior (decision boundary) before and after backdooring. Our main insight for detecting boundary samples is exploiting the confidence scores as a metric for being near the decision boundary and selecting those to poison (inject) the attack. The proposed approach makes it significantly harder for defenders to identify the attacks. Our method is versatile and independent of any specific trigger design. We provide theoretical insights and conduct extensive experiments to demonstrate the effectiveness of the proposed method",
    "checked": true,
    "id": "3e746e1e69e9fae72182367e64192c48d3d5fada",
    "semantic_title": "stealthy backdoor attack via confidence-driven sampling",
    "citation_count": 0,
    "authors": [
      "Pengfei He",
      "Yue Xing",
      "Han Xu",
      "Jie Ren",
      "Yingqian Cui",
      "Shenglai Zeng",
      "Jiliang Tang",
      "Makoto Yamada",
      "Mohammad Sabokrou"
    ]
  },
  "https://openreview.net/forum?id=PtnwXd13SF": {
    "title": "Positional Encoding Helps Recurrent Neural Networks Handle a Large Vocabulary",
    "volume": "main",
    "abstract": "This study reports an unintuitive finding that positional encoding enhances learning of recurrent neural networks (RNNs). Positional encoding is a high-dimensional representation of time indices on input data. Most famously, positional encoding complements the capabilities of Transformer neural networks, which lack an inherent mechanism for representing the data order. By contrast, RNNs can encode the temporal information of data points on their own, rendering their use of positional encoding seemingly redundant/unnecessary. Nonetheless, investigations through synthetic benchmarks reveal an advantage of coupling positional encoding and RNNs, especially for handling a large vocabulary that yields low-frequency tokens. Further scrutinization unveils that these low-frequency tokens destabilizes the gradients of vanilla RNNs, and the positional encoding resolves this instability. These results shed a new light on the utility of positional encoding beyond its canonical role as a timekeeper for Transformers",
    "checked": true,
    "id": "bf9805e010c0063f906a281d99fedf244fd41604",
    "semantic_title": "positional encoding helps recurrent neural networks handle a large vocabulary",
    "citation_count": 3,
    "authors": [
      "Takashi Morita"
    ]
  },
  "https://openreview.net/forum?id=m4bE9Y9FlX": {
    "title": "AdaWaveNet: Adaptive Wavelet Network for Time Series Analysis",
    "volume": "main",
    "abstract": "Time series data analysis is a critical component in various domains such as finance, healthcare, and meteorology. Despite the progress in deep learning for time series analysis, there remains a challenge in addressing the non-stationary nature of time series data. Most of the existing models, which are built on the assumption of constant statistical properties over time, often struggle to capture the temporal dynamics in realistic time series and result in bias and error in time series analysis. This paper introduces the Adaptive Wavelet Network (AdaWaveNet), a novel approach that employs Adaptive Wavelet Transformation for multi-scale analysis of non-stationary time series data. AdaWaveNet designed a lifting scheme-based wavelet decomposition and construction mechanism for adaptive and learnable wavelet transforms, which offers enhanced flexibility and robustness in analysis. We conduct extensive experiments on 10 datasets across 3 different tasks, including forecasting, imputation, and a newly established super-resolution task. The evaluations demonstrate the effectiveness of AdaWaveNet over existing methods in all three tasks, which illustrates its potential in various real-world applications",
    "checked": true,
    "id": "5b67b39bf62e1ae544da2ca6427613c575b08121",
    "semantic_title": "adawavenet: adaptive wavelet network for time series analysis",
    "citation_count": 2,
    "authors": [
      "Han Yu",
      "Peikun Guo",
      "Akane Sano"
    ]
  },
  "https://openreview.net/forum?id=ZRXwHRXm8i": {
    "title": "CREW: Facilitating Human-AI Teaming Research",
    "volume": "main",
    "abstract": "With the increasing deployment of artificial intelligence (AI) technologies, the potential of humans working with AI agents has been growing at a great speed. Human-AI teaming is an important paradigm for studying various aspects when humans and AI agents work together. The unique aspect of Human-AI teaming research is the need to jointly study humans and AI agents, demanding multidisciplinary research efforts from machine learning to human-computer interaction, robotics, cognitive science, neuroscience, psychology, social science, and complex systems. However, existing platforms for Human-AI teaming research are limited, often supporting oversimplified scenarios and a single task, or specifically focusing on either human-teaming research or multi-agent AI algorithms. We introduce \\textbf{CREW}, a platform to facilitate Human-AI teaming research in real-time decision-making scenarios and engage collaborations from multiple scientific disciplines, with a strong emphasis on human involvement. It includes pre-built tasks for cognitive studies and Human-AI teaming with expandable potentials from our modular design. Following conventional cognitive neuroscience research, CREW also supports multimodal human physiological signal recording for behavior analysis. Moreover, CREW benchmarks real-time human-guided reinforcement learning agents using state-of-the-art algorithms and well-tuned baselines. With CREW, we were able to conduct 50 human subject studies within a week to verify the effectiveness of our benchmark",
    "checked": true,
    "id": "a8b4dbff77e2ab4b319622a5da2156e52a130b0b",
    "semantic_title": "crew: facilitating human-ai teaming research",
    "citation_count": 4,
    "authors": [
      "Lingyu Zhang",
      "Zhengran Ji",
      "Boyuan Chen"
    ]
  },
  "https://openreview.net/forum?id=hbtG6s6e7r": {
    "title": "Growing Tiny Networks: Spotting Expressivity Bottlenecks and Fixing Them Optimally",
    "volume": "main",
    "abstract": "Machine learning tasks are generally formulated as optimization problems, where one searches for an optimal function within a certain functional space. In practice, parameterized functional spaces are considered, in order to be able to perform gradient descent. Typically, a neural network architecture is chosen and fixed, and its parameters (connection weights) are optimized, yielding an architecture-dependent result. This way of proceeding however forces the evolution of the function during training to lie within the realm of what is expressible with the chosen architecture, and prevents any optimization across architectures. Costly architectural hyper-parameter optimization is often performed to compensate for this. Instead, we propose to adapt the architecture on the fly during training. We show that the information about desirable architectural changes, due to expressivity bottlenecks when attempting to follow the functional gradient, can be extracted from backpropagation. To do this, we propose a mathematical definition of expressivity bottlenecks, which enables us to detect, quantify and solve them while training, by adding suitable neurons. Thus, while the standard approach requires large networks, in terms of number of neurons per layer, for expressivity and optimization reasons, we provid tools and properties to develop an architecture starting with a very small number of neurons. As a proof of concept, we show results~on the CIFAR dataset, matching large neural network accuracy, with competitive training time, while removing the need for standard architectural hyper-parameter search",
    "checked": true,
    "id": "ee9278121ab6797d9cd897bdc3686f110f05a218",
    "semantic_title": "growing tiny networks: spotting expressivity bottlenecks and fixing them optimally",
    "citation_count": 4,
    "authors": [
      "Manon Verbockhaven",
      "ThÃ©o Rudkiewicz",
      "Sylvain Chevallier",
      "Guillaume Charpiat"
    ]
  },
  "https://openreview.net/forum?id=PkHkPQMTxg": {
    "title": "Learning State Reachability as a Graph in Translation Invariant Goal-based Reinforcement Learning Tasks",
    "volume": "main",
    "abstract": "Deep Reinforcement Learning proved efficient at learning universal control policies when the goal state is close enough to the starting state, or when the value function features few discontinuities. But reaching goals that require long action sequences in complex environments remains difficult. Drawing inspiration from the cognitive process which reuses learned atomic skills in a global planning procedure, we propose an algorithm which encodes reachability between abstract goals as a graph, and produces plans in this goal space. Transitions between goals rely on the exploitation of a learned policy which enjoys a property we call \\emph{translation invariant local optimality}, which encodes the intuition that goal-reaching skills can be reused throughout the state space. Overall, our contribution permits solving large and difficult navigation tasks, outperforming related methods from the literature",
    "checked": true,
    "id": "ba59c7d157a84e4019b717d41fbd447a52008dea",
    "semantic_title": "learning state reachability as a graph in translation invariant goal-based reinforcement learning tasks",
    "citation_count": 0,
    "authors": [
      "Hedwin BONNAVAUD",
      "Alexandre Albore",
      "Emmanuel Rachelson"
    ]
  },
  "https://openreview.net/forum?id=ogEM2H9IGK": {
    "title": "No Identity, no problem: Motion through detection for people tracking",
    "volume": "main",
    "abstract": "Tracking-by-detection has become the de facto standard approach to people tracking. To increase robustness, some approaches incorporate re-identification using appearance models and regressing motion offset, which requires costly identity annotations. In this paper, we propose exploiting motion clues while providing supervision only for the detections, which is much easier to do. Our algorithm predicts detection heatmaps at two different times, along with a 2D motion estimate between the two images. It then warps one heatmap using the motion estimate and enforces consistency with the other one. This provides the required supervisory signal on the motion without the need for any motion annotations. In this manner, we couple the information obtained from different images during training and increase accuracy, especially in crowded scenes and when using low frame-rate sequences. We show that our approach delivers state-of-the-art results for single- and multi-view multi-target tracking on the MOT17 and WILDTRACK datasets",
    "checked": true,
    "id": "52557077f403e1c9e5f95fc05a231fbb1cfaafdc",
    "semantic_title": "no identity, no problem: motion through detection for people tracking",
    "citation_count": 0,
    "authors": [
      "Martin Engilberge",
      "Friedrich Wilke Grosche",
      "Pascal Fua"
    ]
  },
  "https://openreview.net/forum?id=jmwEiC9bq2": {
    "title": "Stability and Generalization in Free Adversarial Training",
    "volume": "main",
    "abstract": "While adversarial training methods have significantly improved the robustness of deep neural networks against norm-bounded adversarial perturbations, the generalization gap between their performance on training and test data is considerably greater than that of standard empirical risk minimization. Recent studies have aimed to connect the generalization properties of adversarially trained classifiers to the min-max optimization algorithm used in their training. In this work, we analyze the interconnections between generalization and optimization in adversarial training using the algorithmic stability framework. Specifically, our goal is to compare the generalization gap of neural networks trained using the vanilla adversarial training method, which fully optimizes perturbations at every iteration, with the free adversarial training method, which simultaneously optimizes norm-bounded perturbations and classifier parameters. We prove bounds on the generalization error of these methods, indicating that the free adversarial training method may exhibit a lower generalization gap between training and test samples due to its simultaneous min-max optimization of classifier weights and perturbation variables. We conduct several numerical experiments to evaluate the train-to-test generalization gap in vanilla and free adversarial training methods. Our empirical findings also suggest that the free adversarial training method could lead to a smaller generalization gap over a similar number of training iterations. The paper code is available at https://github.com/Xiwei-Cheng/Stability_FreeAT",
    "checked": true,
    "id": "f35e5998541f3b9a482e4c4880ec7b8feb0818c6",
    "semantic_title": "stability and generalization in free adversarial training",
    "citation_count": 3,
    "authors": [
      "Xiwei Cheng",
      "Kexin Fu",
      "Farzan Farnia"
    ]
  },
  "https://openreview.net/forum?id=r8wXaLJBIS": {
    "title": "Data-Centric Defense: Shaping Loss Landscape with Augmentations to Counter Model Inversion",
    "volume": "main",
    "abstract": "Machine Learning models have shown susceptibility to various privacy attacks, with model inversion (MI) attacks posing a significant threat. Current defense techniques are mostly \\emph{model-centric}, involving modifying model training or inference. However, these approaches require model trainers' cooperation, are computationally expensive, and often result in a significant privacy-utility tradeoff. To address these limitations, we propose a novel \\emph{data-centric} approach to mitigate MI attacks. Compared to traditional model-centric techniques, our approach offers the unique advantage of enabling each individual user to control their data's privacy risk, aligning with findings from a Cisco survey that only a minority actively seek privacy protection. Specifically, we introduce several privacy-focused data augmentations that modify the private data uploaded to the model trainer. These augmentations shape the resulting model's loss landscape, making it challenging for attackers to generate private target samples. Additionally, we provide theoretical analysis to explain why such augmentations can reduce the risk of model inversion. We evaluate our approach against state-of-the-art MI attacks and demonstrate its effectiveness and robustness across various model architectures and datasets. Specifically, in standard face recognition benchmarks, we reduce face reconstruction success rates to $\\leq5\\%$, while maintaining high utility with only a 2\\% classification accuracy drop, significantly surpassing state-of-the-art model-centric defenses. This is the first study to propose a data-centric approach for mitigating model inversion attacks, showing promising potential for decentralized privacy protection",
    "checked": true,
    "id": "7df7360c3f587bc99d4254ea9a95ace620cfaa07",
    "semantic_title": "data-centric defense: shaping loss landscape with augmentations to counter model inversion",
    "citation_count": 2,
    "authors": [
      "Si Chen",
      "Feiyang Kang",
      "Nikhil Abhyankar",
      "Ming Jin",
      "Ruoxi Jia"
    ]
  },
  "https://openreview.net/forum?id=EDHQDsqiSe": {
    "title": "Modeling Causal Mechanisms with Diffusion Models for Interventional and Counterfactual Queries",
    "volume": "main",
    "abstract": "We consider the problem of answering observational, interventional, and counterfactual queries in a causally sufficient setting where only observational data and the causal graph are available. Utilizing the recent developments in diffusion models, we introduce diffusion-based causal models (DCM) to learn causal mechanisms, that generate unique latent encodings. These encodings enable us to directly sample under interventions and perform abduction for counterfactuals. Diffusion models are a natural fit here, since they can encode each node to a latent representation that acts as a proxy for exogenous noise. Our empirical evaluations demonstrate significant improvements over existing state-of-the-art methods for answering causal queries. Furthermore, we provide theoretical results that offer a methodology for analyzing counterfactual estimation in general encoder-decoder models, which could be useful in settings beyond our proposed approach",
    "checked": true,
    "id": "4d41ef90c02eb4e27b8565c68b5814059e686af0",
    "semantic_title": "modeling causal mechanisms with diffusion models for interventional and counterfactual queries",
    "citation_count": 12,
    "authors": [
      "Patrick Chao",
      "Patrick BlÃ¶baum",
      "Sapan Kirit Patel",
      "Shiva Kasiviswanathan"
    ]
  },
  "https://openreview.net/forum?id=PdbaruPVUY": {
    "title": "Confidence Intervals and Simultaneous Confidence Bands Based on Deep Learning",
    "volume": "main",
    "abstract": "Deep learning models have significantly improved prediction accuracy in various fields, gaining recognition across numerous disciplines. Yet, an aspect of deep learning that remains insufficiently addressed is the assessment of prediction uncertainty. Producing reliable uncertainty estimators could be crucial in practical terms. For instance, predictions associated with a high degree of uncertainty could be sent for further evaluation. Recent works in uncertainty quantification of deep learning predictions, including Bayesian posterior credible intervals and a frequentist confidence-interval estimation, have proven to yield either invalid or overly conservative intervals. Furthermore, there is currently no method for quantifying uncertainty that can accommodate deep neural networks for survival (time-to-event) data that involves right-censored outcomes. In this work, we provide a non-parametric bootstrap method that disentangles data uncertainty from the noise inherent in the adopted optimization algorithm. %, ensuring that based on deep learning estimators with small bias, the resulting point-wise confidence intervals or the simultaneous confidence bands are accurate (i.e., valid and not overly conservative). The validity of the proposed approach is demonstrated through an extensive simulation study, which shows that the method is accurate (i.e., valid and not overly conservative) as long as the network is sufficiently deep to ensure that the estimators provided by the deep neural network exhibit minimal bias. Otherwise, undercoverage of up to 8\\% is observed. The proposed ad-hoc method can be easily integrated into any deep neural network without interfering with the training process. The utility of the proposed approach is demonstrated through two applications: constructing simultaneous confidence bands for survival curves generated by deep neural networks dealing with right-censored survival data, and constructing a confidence interval for classification probabilities in the context of binary classification regression. Code for the data analysis and reported simulation is available at Githubsite: \\url{https://github.com/Asafba123/Survival_bootstrap}",
    "checked": true,
    "id": "e7bd7b764f9924b4df5f068e38d2fb4ae828c665",
    "semantic_title": "confidence intervals and simultaneous confidence bands based on deep learning",
    "citation_count": 0,
    "authors": [
      "Asaf Ben Arie",
      "Malka Gorfine"
    ]
  },
  "https://openreview.net/forum?id=QdGtwjDgub": {
    "title": "Contaminated Online Convex Optimization",
    "volume": "main",
    "abstract": "In online convex optimization, some efficient algorithms have been designed for each of the individual classes of objective functions, e.g., convex, strongly convex, and exp-concave. However, existing regret analyses, including those of universal algorithms, are limited to cases in which the objective functions in all rounds belong to the same class and cannot be applied to cases in which the property of objective functions may change in each time step. This paper introduces a novel approach to address such cases, proposing a new regime we term as \\textit{contaminated} online convex optimization. For the contaminated case, we demonstrate that the regret is lower bounded by $\\Omega(\\log T + \\sqrt{k})$. Here, $k$ signifies the level of contamination in the objective functions. We also demonstrate that the regret is bounded by $O(\\log T+\\sqrt{k\\log T})$ when universal algorithms are used. When our proposed algorithms with additional information are employed, the regret is bounded by $O(\\log T+\\sqrt{k})$, which matches the lower bound. These are intermediate bounds between a convex case and a strongly convex or exp-concave case",
    "checked": true,
    "id": "b384643066c27fa5751f9248b3da4e933c434293",
    "semantic_title": "contaminated online convex optimization",
    "citation_count": 0,
    "authors": [
      "Tomoya Kamijima",
      "Shinji Ito"
    ]
  },
  "https://openreview.net/forum?id=p6KIteShzf": {
    "title": "Deep Tabular Learning via Distillation and Language Guidance",
    "volume": "main",
    "abstract": "Tabular data is arguably one of the most ubiquitous data structures in application domains such as science, healthcare, finance and manufacturing. Given the recent success of deep learning (DL), there has been a surge of new DL models for tabular learning. However, despite the efforts, tabular DL models still clearly trail behind tree-based approaches. In this work, we propose DisTab, a novel framework for tabular learning based on the transformer architecture. Our method leverages model distillation to mimic the favorable inductive biases of tree-based models, and incorporates language guidance for more expressive feature embeddings. Empirically, DisTab outperforms existing tabular DL models and is highly competitive against tree-based models across diverse datasets, effectively closing the gap with these methods",
    "checked": true,
    "id": "c372728857a301d1972cf79c7fced8fec0ef2e6f",
    "semantic_title": "deep tabular learning via distillation and language guidance",
    "citation_count": 0,
    "authors": [
      "Ruohan Wang",
      "Wenhao Fu",
      "Carlo Ciliberto"
    ]
  },
  "https://openreview.net/forum?id=SP8DLl6jgb": {
    "title": "Feature Distillation Improves Zero-Shot Transfer from Synthetic Images",
    "volume": "main",
    "abstract": "Vision-language foundation models such as CLIP have showcased impressive zero-shot capabilities. However, their applicability in resource-constrained environments is limited due to their size and the resulting latency. Knowledge distillation allows to mitigate these challenges by distilling small image encoders that can replace the large CLIP image encoder. In a zero-shot setting, where only the class names are known, no real domain images can be used for this process. Instead, we investigate the use of synthetic images for this purpose. Unlike existing works that focus on improving the quality of synthetic images to bridge the performance gap compared to training on natural images, we find the choice of loss to be a crucial factor. Specifically, minimizing only the distance between the student and teacher image features, without incorporating image captions in the loss function, increases the robustness to spurious features and data corruptions. As a result, this feature distillation approach greatly improves the transfer performance from synthetic to real images. Leveraging these insights, we are able to train domain-specific students that achieve zero-shot performance comparable to a ViT-B/32 teacher on six fine-grained classification datasets while using up to 92% fewer parameters",
    "checked": true,
    "id": "fd225c6f0eb39f318339e79e582bb850bbaa6de7",
    "semantic_title": "feature distillation improves zero-shot transfer from synthetic images",
    "citation_count": 0,
    "authors": [
      "Niclas Popp",
      "Jan Hendrik Metzen",
      "Matthias Hein"
    ]
  },
  "https://openreview.net/forum?id=093Q9VxaWt": {
    "title": "Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity",
    "volume": "main",
    "abstract": "On tabular data, a significant body of literature has shown that current deep learning (DL) models perform at best similarly to Gradient Boosted Decision Trees (GBDTs), while significantly underperforming them on outlier data. However, these works often study problem settings which may not fully capture the complexities of real-world scenarios. We identify a natural tabular data setting where DL models can outperform GBDTs: tabular Learning-to-Rank (LTR) under label scarcity. Tabular LTR applications, including search and recommendation, often have an abundance of unlabeled data, and scarce labeled data. We show that DL rankers can utilize unsupervised pretraining to exploit this unlabeled data. In extensive experiments over both public and proprietary datasets, we show that pretrained DL rankers consistently outperform GBDT rankers on ranking metrics, sometimes by as much as 38%, both overall and on outliers",
    "checked": true,
    "id": "5754c27ce8e5b8badd04367aa6041ec1ac00c6c6",
    "semantic_title": "pretrained deep models outperform gbdts in learning-to-rank under label scarcity",
    "citation_count": 1,
    "authors": [
      "Charlie Hou",
      "Kiran Koshy Thekumparampil",
      "Michael Shavlovsky",
      "Giulia Fanti",
      "Yesh Dattatreya",
      "sujay sanghavi"
    ]
  },
  "https://openreview.net/forum?id=EUF2R6VBeU": {
    "title": "Revisiting Discrete Soft Actor-Critic",
    "volume": "main",
    "abstract": "We study the adaption of Soft Actor-Critic (SAC), which is considered as a state-of-the-art reinforcement learning (RL) algorithm, from continuous action space to discrete action space. We revisit vanilla discrete SAC and provide an in-depth understanding of its Q value underestimation and performance instability issues when applied to discrete settings. We thereby propose Stable Discrete SAC (SDSAC), an algorithm that leverages entropy-penalty and double average Q-learning with Q-clip to address these issues. Extensive experiments on typical benchmarks with discrete action space, including Atari games and a large-scale MOBA game, show the efficacy of our proposed method. Our code is at: https://github.com/coldsummerday/SD-SAC.git",
    "checked": true,
    "id": "5e22b42365973bf757d7183f95e82c86ae5120dc",
    "semantic_title": "revisiting discrete soft actor-critic",
    "citation_count": 13,
    "authors": [
      "haibin zhou",
      "Tong Wei",
      "Zichuan Lin",
      "junyou li",
      "Junliang Xing",
      "Yuanchun Shi",
      "Li Shen",
      "Chao Yu",
      "Deheng Ye"
    ]
  },
  "https://openreview.net/forum?id=rlloVZoKrX": {
    "title": "SQL-PaLM: Improved large language model adaptation for Text-to-SQL",
    "volume": "main",
    "abstract": "Text-to-SQL, the process of translating natural language into Structured Query Language (SQL), represents a transformative application of large language models (LLMs), potentially revolutionizing how humans interact with data. This paper introduces the SQL-PaLM framework, a comprehensive solution for understanding and enhancing Text-to-SQL using LLMs, using in the learning regimes of few-shot prompting and instruction fine-tuning. With few-shot prompting, we explore the effectiveness of consistency decoding with execution-based error filtering. With instruction fine-tuning, we delve deep in understanding the critical paradigms that influence the performance of tuned LLMs. In particular, we investigate how performance can be improved through expanded training data coverage and diversity, synthetic data augmentation, and integrating query-specific database content. We propose a test-time selection method to further refine accuracy by integrating SQL outputs from multiple paradigms with execution feedback as guidance. Additionally, we tackle the practical challenge of navigating intricate databases with a significant number of tables and columns, proposing efficient techniques for accurately selecting relevant database elements to enhance Text-to-SQL performance. Our holistic approach yields substantial advancements in Text-to-SQL, as demonstrated on two key public benchmarks, Spider and BIRD. Through comprehensive ablations and error analyses, we shed light on the strengths and weaknesses of our framework, offering valuable insights into Text-to-SQL's future work",
    "checked": true,
    "id": "e0e1fcdbc5b41fcd1cd15001b4861a738411c910",
    "semantic_title": "sql-palm: improved large language model adaptation for text-to-sql",
    "citation_count": 60,
    "authors": [
      "Ruoxi Sun",
      "Sercan O Arik",
      "Alexandre Muzio",
      "Lesly Miculicich",
      "Satya Kesav Gundabathula",
      "Pengcheng Yin",
      "Hanjun Dai",
      "Hootan Nakhost",
      "Rajarishi Sinha",
      "Zifeng Wang",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=7q5UewlAdM": {
    "title": "Î»-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space",
    "volume": "main",
    "abstract": "Despite the recent advances in personalized text-to-image (P-T2I) generative models, it remains challenging to perform finetuning-free multi-subject-driven T2I in a resource-efficient manner. Predominantly, contemporary approaches, involving the training of hypernetworks and Multimodal Large Language Models (MLLMs), require heavy computing resources that range from 600 to 12300 GPU hours of training. These subject-driven T2I methods hinge on Latent Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention layers. While LDMs offer distinct advantages, P-T2I methods' reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image. Through empirical evidences we find that CLIP (vision) latent space is already expressive enough to preserve the fine-grained details. Building upon this insight, in this paper, we present Î»-ECLIPSE, a diffusion-agnostic prior-training strategy that works in the latent space of a pre-trained CLIP model without relying on the diffusion UNet models. Î»-ECLIPSE leverages the image-text interleaved pre-training for fast and effective multi-subject-driven P-T2I. Through extensive experiments, we establish that Î»-ECLIPSE surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization. Î»-ECLIPSE performs multi-subject driven P-T2I with just 34M parameters and is trained on a mere 74 GPU hours. Additionally, Î»-ECLIPSE demonstrates the unique ability to perform multi-concept interpolations. Project page: \\url{https://eclipse-t2i.github.io/Lambda-ECLIPSE/}",
    "checked": true,
    "id": "b4cb0ec227a375f5eda335a80d46888c6299556d",
    "semantic_title": "Î»-eclipse: multi-concept personalized text-to-image diffusion models by leveraging clip latent space",
    "citation_count": 35,
    "authors": [
      "Maitreya Patel",
      "Sangmin Jung",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://openreview.net/forum?id=HV9lXOIZYw": {
    "title": "The Harmonic Indel Distance",
    "volume": "main",
    "abstract": "This short note introduces the harmonic indel distance (HID), a new distance between strings where the cost of an insertion or deletion is inversely proportional to the string length. We present a closed-form formula and show that the HID is a proper distance metric. Then we perform an experimental comparison of HID to normalized and unnormalized versions of the indel distance on benchmark tasks for biomedical sequence data. We finally show planar embeddings of the benchmark datasets to provide some insights into the geometry of the metric spaces associated with the different distance metrics",
    "checked": false,
    "id": "ddc1b4a77b42fd6486434cbec54227fc5e943857",
    "semantic_title": "qtl mapping under salt stress in rice using a kalarataâazucena population",
    "citation_count": 0,
    "authors": [
      "Bob Pepin"
    ]
  },
  "https://openreview.net/forum?id=TXzz9xwdpv": {
    "title": "Calibration Attacks: A Comprehensive Study of Adversarial Attacks on Model Confidence",
    "volume": "main",
    "abstract": "In this work, we highlight and perform a comprehensive study on calibration attacks, a form of adversarial attacks that aim to trap victim models to be heavily miscalibrated without altering their predicted labels, hence endangering the trustworthiness of the models and follow-up decision making based on their confidence. We propose four typical forms of calibration attacks: underconfidence, overconfidence, maximum miscalibration, and random confidence attacks, conducted in both the black-box and white-box setups. We demonstrate that the attacks are highly effective on both convolutional and attention-based models: with a small number of queries, they seriously skew confidence without changing the predictive performance. Given the potential danger, we further investigate the effectiveness of a wide range of adversarial defence and recalibration methods, including our proposed defences specifically designed for calibration attacks to mitigate the harm. From the ECE and KS scores, we observe that there are still significant limitations in handling calibration attacks. To the best of our knowledge, this is the first dedicated study that provides a comprehensive investigation on calibration-focused attacks. We hope this study helps attract more attention to these types of attacks and hence hamper their potential serious damages. To this end, this work also provides detailed analyses to understand the characteristics of the attacks",
    "checked": true,
    "id": "840858af633999ebb5452c188388e1cf3e9ddec5",
    "semantic_title": "calibration attacks: a comprehensive study of adversarial attacks on model confidence",
    "citation_count": 1,
    "authors": [
      "Stephen Obadinma",
      "Xiaodan Zhu",
      "Hongyu Guo"
    ]
  },
  "https://openreview.net/forum?id=bEwAAEmRbh": {
    "title": "Large-width asymptotics and training dynamics of $\\alpha$-Stable ReLU neural networks",
    "volume": "main",
    "abstract": "Large-width asymptotic properties of neural networks (NNs) with Gaussian distributed weights have been extensively investigated in the literature, with major results characterizing their large-width asymptotic behavior in terms of Gaussian processes and their large-width training dynamics in terms of the neural tangent kernel (NTK). In this paper, we study large-width asymptotics and training dynamics of $\\alpha$-Stable ReLU-NNs, namely NNs with ReLU activation function and $\\alpha$-Stable distributed weights, with $\\alpha\\in(0,2)$. For $\\alpha\\in(0,2]$, $\\alpha$-Stable distributions form a broad class of heavy tails distributions, with the special case $\\alpha=2$ corresponding to the Gaussian distribution. Firstly, we show that if the NN's width goes to infinity, then a rescaled $\\alpha$-Stable ReLU-NN converges weakly (in distribution) to an $\\alpha$-Stable process, which generalizes the Gaussian process. As a difference with respect to the Gaussian setting, our result shows that the activation function affects the scaling of the $\\alpha$-Stable NN; more precisely, in order to achieve the infinite-width $\\alpha$-Stable process, the ReLU activation requires an additional logarithmic term in the scaling with respect to sub-linear activations. Secondly, we characterize the large-width training dynamics of $\\alpha$-Stable ReLU-NNs in terms an infinite-width random kernel, which is referred to as the $\\alpha$-Stable NTK, and we show that the gradient descent achieves zero training error at linear rate, for a sufficiently large width, with high probability. Differently from the NTK arising in the Gaussian setting, the $\\alpha$-Stable NTK is a random kernel; more precisely, the randomness of the $\\alpha$-Stable ReLU-NN at initialization does not vanish in the large-width training dynamics",
    "checked": false,
    "id": "4ee5c41c3aa76939422a438355e9527dcd4189ee",
    "semantic_title": "large-width asymptotics and training dynamics of Î±-stable relu neural networks",
    "citation_count": 1,
    "authors": [
      "Stefano Favaro",
      "Sandra Fortini",
      "Stefano Peluchetti"
    ]
  },
  "https://openreview.net/forum?id=hafnY2PiTn": {
    "title": "Towards Understanding Adversarial Transferability in Federated Learning",
    "volume": "main",
    "abstract": "We investigate a specific security risk in FL: a group of malicious clients has impacted the model during training by disguising their identities and acting as benign clients but later switching to an adversarial role. They use their data, which is part of the training set, to train a substitute model and conduct transferable adversarial attacks against the federated model. This type of attack is subtle and hard to detect because these clients initially appear to be benign. The key question we address is: How robust is the FL system to such covert attacks, especially compared to traditional centralized learning systems? We empirically show that the proposed attack imposes a high-security risk to current FL systems. By using only 3\\% of the client's data, we achieve the highest attack rate of over 80\\%. To further offer a full understanding of the challenges the FL system faces in transferable attacks, we provide a comprehensive analysis of the transfer robustness of FL across a spectrum of configurations. Surprisingly, FL systems show a higher level of robustness than their centralized counterparts, especially when both systems are equally good at handling regular, non-malicious data. We attribute this increased robustness to two main factors: 1) Decentralized Data Training: Each client trains the model on its own data, reducing the overall impact of any single malicious client. 2) Model Update Averaging: The updates from each client are averaged together, further diluting any malicious alterations. Both practical experiments and theoretical analyses support our conclusions. This research not only sheds light on the resilience of FL systems against hidden attacks but also raises important considerations for their future application and developmentã",
    "checked": true,
    "id": "d06402cd20cfb842b74497268dec1ba260594697",
    "semantic_title": "towards understanding adversarial transferability in federated learning",
    "citation_count": 1,
    "authors": [
      "Yijiang Li",
      "Ying Gao",
      "Haohan Wang"
    ]
  },
  "https://openreview.net/forum?id=1ZTfzA9bXw": {
    "title": "DTRNet: Precisely Correcting Selection Bias in Individual-Level Continuous Treatment Effect Estimation by Reweighted Disentangled Representation",
    "volume": "main",
    "abstract": "Estimating the individual-level continuous treatment effect holds significant practical importance in various decision-making domains, such as personalized healthcare and customized marketing. However, most current methods for individual treatment effect estimation are limited to discrete treatments and struggle to precisely adjust for selection bias under continuous settings, leading to inaccurate estimation. To address these challenges, we propose a novel Disentangled Representation Network (DTRNet) to estimate the individualized dose-response function (IDRF), which learns disentangled representations and precisely adjusts for selection bias. To the best of our knowledge, our work is the first attempt to precisely adjust for selection bias in continuous settings. Extensive results on synthetic and semi-synthetic datasets demonstrate that our DTRNet outperforms most state-of-the-art methods. Our code is available at \\href{https://github.com/xuanxuan03021/DTRNet_final_2}{DTRNet}",
    "checked": true,
    "id": "4154c5afe4faac68758aac93568d9fcd510547ee",
    "semantic_title": "dtrnet: precisely correcting selection bias in individual-level continuous treatment effect estimation by reweighted disentangled representation",
    "citation_count": 0,
    "authors": [
      "Mengxuan Hu",
      "Zhixuan Chu",
      "Sheng Li"
    ]
  },
  "https://openreview.net/forum?id=0e1Kn76HM1": {
    "title": "Uncertainty in Graph Neural Networks: A Survey",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have been extensively used in various real-world applications. However, the predictive uncertainty of GNNs stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. Therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the GNN predictions. This survey aims to provide a comprehensive overview of the GNNs from the perspective of uncertainty with an emphasis on its integration in graph learning. We compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. Thereby, we bridge the gap between theory and practice, meanwhile connecting different GNN communities. Moreover, our work provides valuable insights into promising directions in this field",
    "checked": true,
    "id": "ca337dbc600b3830d2cd670018764a9488157374",
    "semantic_title": "uncertainty in graph neural networks: a survey",
    "citation_count": 10,
    "authors": [
      "Fangxin Wang",
      "Yuqing Liu",
      "Kay Liu",
      "Yibo Wang",
      "Sourav Medya",
      "Philip S. Yu"
    ]
  },
  "https://openreview.net/forum?id=orHH4fCtR8": {
    "title": "Repositioning the Subject within Image",
    "volume": "main",
    "abstract": "Current image manipulation primarily centers on static manipulation, such as replacing specific regions within an image or altering its overall style. In this paper, we introduce an innovative dynamic manipulation task, subject repositioning. This task involves relocating a user-specified subject to a desired position while preserving the image's fidelity. Our research reveals that the fundamental sub-tasks of subject repositioning, which include filling the void left by the repositioned subject, reconstructing obscured portions of the subject and blending the subject to be consistent with surrounding areas, can be effectively reformulated as a unified, prompt-guided inpainting task. Consequently, we can employ a single diffusion generative model to address these sub-tasks using various task prompts learned through our proposed task inversion technique. Additionally, we integrate pre-processing and post-processing techniques to further enhance the quality of subject repositioning. These elements together form our SEgment-gEnerate-and-bLEnd (SEELE) framework. To assess SEELE's effectiveness in subject repositioning, we assemble a real-world subject repositioning dataset called ReS. Results of SEELE on ReS demonstrate its efficacy. Code and ReS dataset are available at https://yikai-wang.github.io/seele/",
    "checked": true,
    "id": "c2a0375feaa2b7aea0a0d8d0007ce1c6f28fb190",
    "semantic_title": "repositioning the subject within image",
    "citation_count": 2,
    "authors": [
      "Yikai Wang",
      "Chenjie Cao",
      "Ke Fan",
      "Qiaole Dong",
      "Yifan Li",
      "Xiangyang Xue",
      "Yanwei Fu"
    ]
  },
  "https://openreview.net/forum?id=Z8A3HDgS0E": {
    "title": "FLR: Label-Mixture Regularization for Federated Learning with Noisy Labels",
    "volume": "main",
    "abstract": "Label noise in federated learning (FL) has garnered increasing attention due to the decentralized nature of FL, where data is collected from multiple clients with potentially different levels of label noise. This study introduces two pivotal contributions to this domain. First, we anatomize the memorization phenomenon in FL into server-side and client-side components, marking the first investigation into how these distinct forms of memorization impact learning. Second, to mitigate the memorization in FL, we present the Federated Label-mixture Regularization (FLR) strategy, a straightforward yet effective approach that employs regularization through pseudo labels generated by merging local and global model predictions. This method not only improves the accuracy of the global model in both i.i.d. and non-i.i.d. settings but also effectively counters the memorization of noisy labels. We empirically find that FLR aligns with and advances existing FL and noisy label mitigation methods over multiple datasets under various levels of data heterogeneity and label noise",
    "checked": true,
    "id": "87bac31c357cf5b7a950790988b042e37567c118",
    "semantic_title": "flr: label-mixture regularization for federated learning with noisy labels",
    "citation_count": 0,
    "authors": [
      "Taehyeon Kim",
      "Donggyu Kim",
      "Se-Young Yun"
    ]
  },
  "https://openreview.net/forum?id=ZewaRoZehI": {
    "title": "Pretraining a Neural Operator in Lower Dimensions",
    "volume": "main",
    "abstract": "There has recently been increasing attention towards developing foundational neural Partial Differential Equation (PDE) solvers and neural operators through large-scale pertaining. However, unlike vision and language models that make use of abundant and inexpensive (unlabeled) data for pretraining, these neural solvers usually rely on simulated PDE data, which can be costly to obtain, especially for high dimensional PDEs. In this work, we aim to Pretrain neural PDE solvers on Lower Dimensional PDEs (PreLowD) where data collection is the least expensive. We evaluated the effectiveness of this pretraining strategy in similar PDEs in higher dimensions. We use the Factorized Fourier Neural Operator (FFNO) due to having the necessary flexibility to be applied to PDE data of arbitrary spatial dimensions and reuse trained parameters in lower dimensions. In addition, our work sheds light on the effect of the fine-tuning configuration to make the most of this pretraining strategy. Code is available at https://github.com/BaratiLab/PreLowD",
    "checked": true,
    "id": "80f3d60c826b0a24ceae3d3a569b5b279ecb9c41",
    "semantic_title": "pretraining a neural operator in lower dimensions",
    "citation_count": 1,
    "authors": [
      "AmirPouya Hemmasian",
      "Amir Barati Farimani"
    ]
  },
  "https://openreview.net/forum?id=tYxRyNT0TC": {
    "title": "Perception Stitching: Zero-Shot Perception Encoder Transfer for Visuomotor Robot Policies",
    "volume": "main",
    "abstract": "Vision-based imitation learning has shown promising capabilities of endowing robots with various motion skills given visual observation. However, current visuomotor policies fail to adapt to drastic changes in their visual observations. We present Perception Stitching that enables strong zero-shot adaptation to large visual changes by directly stitching novel combinations of visual encoders. Our key idea is to enforce modularity of visual encoders by aligning the latent visual features among different visuomotor policies. Our method disentangles the perceptual knowledge with the downstream motion skills and allows the reuse of the visual encoders by directly stitching them to a policy network trained with partially different visual conditions. We evaluate our method in various simulated and real-world manipulation tasks. While baseline methods failed at all attempts, our method could achieve zero-shot success in real-world visuomotor tasks. Our quantitative and qualitative analysis of the learned features of the policy network provides more insights into the high performance of our proposed method",
    "checked": true,
    "id": "652836fb8798b97f1eb1a9123df7b3da60933d4c",
    "semantic_title": "perception stitching: zero-shot perception encoder transfer for visuomotor robot policies",
    "citation_count": 1,
    "authors": [
      "Pingcheng Jian",
      "Easop Lee",
      "Zachary I. Bell",
      "Michael M. Zavlanos",
      "Boyuan Chen"
    ]
  },
  "https://openreview.net/forum?id=oS4SkVKA7S": {
    "title": "Scale Equalization for Multi-Level Feature Fusion",
    "volume": "main",
    "abstract": "Deep neural networks have exhibited remarkable performance in a variety of computer vision fields, especially in semantic segmentation tasks. Their success is often attributed to multi-level feature fusion, which enables them to understand both global and local information from an image. However, multi-level features from parallel branches exhibits different scales, which is a universal and unwanted flaw that leads to detrimental gradient descent, thereby degrading performance in semantic segmentation. We discover that scale disequilibrium is caused by bilinear upsampling, which is supported by both theoretical and empirical evidence. Based on this observation, we propose injecting scale equalizers to achieve scale equilibrium across multi-level features after bilinear upsampling. Our proposed scale equalizers are easy to implement, applicable to any architecture, hyperparameter-free, implementable without requiring extra computational cost, and guarantee scale equilibrium for any dataset. Experiments showed that adopting scale equalizers consistently improved the mIoU index across various target datasets, including ADE20K, PASCAL VOC 2012, and Cityscapes, as well as various decoder choices, including UPerHead, PSPHead, ASPPHead, SepASPPHead, and FCNHead",
    "checked": true,
    "id": "9c09b35a3e6222e30eef53ff1337e956ba96b364",
    "semantic_title": "scale equalization for multi-level feature fusion",
    "citation_count": 1,
    "authors": [
      "Bum Jun Kim",
      "Sang Woo Kim"
    ]
  },
  "https://openreview.net/forum?id=25FT0DqhVZ": {
    "title": "Multi-LoRA Composition for Image Generation",
    "volume": "main",
    "abstract": "Low-Rank Adaptation (LoRA) is extensively utilized in text-to-image models for the accurate rendition of specific elements like distinct characters or unique styles in generated images. Nonetheless, existing methods face challenges in effectively composing multiple LoRAs, especially as the number of LoRAs to be integrated grows, thus hindering the creation of complex imagery. In this paper, we study multi-LoRA composition through a decoding-centric perspective. We present two training-free methods: \\textsc{LoRA Switch}, which alternates between different LoRAs at each denoising step, and \\textsc{LoRA Composite}, which simultaneously incorporates all LoRAs to guide more cohesive image synthesis. To evaluate the proposed approaches, we establish \\texttt{ComposLoRA}, a new comprehensive testbed as part of this research. It features a diverse range of LoRA categories with 480 composition sets. Utilizing an evaluation framework based on GPT-4V, our findings demonstrate a clear improvement in performance with our methods over the prevalent baseline, particularly evident when increasing the number of LoRAs in a composition. The code, benchmarks, LoRA weights, and all evaluation details are available on our project website: https://maszhongming.github.io/Multi-LoRA-Composition",
    "checked": true,
    "id": "db40e0e2a7557bb4c9e4ab2e4f81bc3ec85abb17",
    "semantic_title": "multi-lora composition for image generation",
    "citation_count": 41,
    "authors": [
      "Ming Zhong",
      "yelong shen",
      "Shuohang Wang",
      "Yadong Lu",
      "Yizhu Jiao",
      "Siru Ouyang",
      "Donghan Yu",
      "Jiawei Han",
      "Weizhu Chen"
    ]
  },
  "https://openreview.net/forum?id=r9eNUDe2im": {
    "title": "Trusted Aggregation (TAG): Backdoor Defense in Federated Learning",
    "volume": "main",
    "abstract": "Federated learning is a framework for training machine learning models from clients with multiple local data sets without access to the data in its aggregate. Instead, a shared model is jointly learned through an interactive process between a centralized server that combines locally learned model gradients or weights from the client. However, the lack of data transparency naturally raises concerns about model security. Recently, several state-of-the-art backdoor attacks have been proposed, which achieve high attack success rates while simultaneously being difficult to detect, leading to compromised federated learning models. In this paper, motivated by differences in the logits of models trained with and without the presence of backdoor attacks, we propose a defense method that can prevent backdoor attacks from influencing the model while maintaining the accuracy of the original classification task. TAG leverages a small validation data set to estimate the most considerable change a benign client's local training can make to the shared model, which can be used to filter clients from updating the shared model. Experimental results on multiple data sets show that TAG defends against backdoor attacks even when 40 percent of user submissions to update the shared model are malicious",
    "checked": true,
    "id": "8487e04f5f58913392e29141f95a7ee875db10c4",
    "semantic_title": "trusted aggregation (tag): backdoor defense in federated learning",
    "citation_count": 0,
    "authors": [
      "Joseph Lavond",
      "Minhao Cheng",
      "Yao Li"
    ]
  },
  "https://openreview.net/forum?id=tkswb7XoYB": {
    "title": "Zero-Order One-Point Gradient Estimate in Consensus-Based Distributed Stochastic Optimization",
    "volume": "main",
    "abstract": "In this work, we consider a distributed multi-agent stochastic optimization problem, where each agent holds a local objective function that is smooth and strongly convex and that is subject to a stochastic process. The goal is for all agents to collaborate to find a common solution that optimizes the sum of these local functions. With the practical assumption that agents can only obtain noisy numerical function queries at precisely one point at a time, we consider an extention of a standard consensus-based distributed stochastic gradient (DSG) method to the bandit setting where we do not have access to the gradient, and we introduce a zero-order (ZO) one-point estimate (1P-DSG). We analyze the convergence of this techniques using stochastic approximation tools, and we prove that it \\textit{converges almost surely to the optimum} despite the biasedness of our gradient estimate. We then study the convergence rate of our method. With constant step sizes, our method competes with its first-order (FO) counterparts by achieving a linear rate $O(\\varrho^k)$ as a function of number of iterations $k$. To the best of our knowledge, this is the first work that proves this rate in the noisy estimation setting or with one-point estimators. With vanishing step sizes, we establish a rate of $O(\\frac{1}{\\sqrt{k}})$ after a sufficient number of iterations $k > K_0$. This rate matches the lower bound of centralized techniques utilizing one-point estimators. We then provide a regret bound of $O(\\sqrt{k})$ with vanishing step sizes. We further illustrate the usefulness of the proposed technique using numerical experiments",
    "checked": true,
    "id": "09cda509a4cc76d6985c0e8f5aee3213cec74513",
    "semantic_title": "zero-order one-point gradient estimate in consensus-based distributed stochastic optimization",
    "citation_count": 0,
    "authors": [
      "Elissa Mhanna",
      "Mohamad Assaad"
    ]
  },
  "https://openreview.net/forum?id=MzSf70uXJO": {
    "title": "Towards Empirical Interpretation of Internal Circuits and Properties in Grokked Transformers on Modular Polynomials",
    "volume": "main",
    "abstract": "Grokking has been actively explored to reveal the mystery of delayed generalization and identifying interpretable representations and algorithms inside the grokked models is a suggestive hint to understanding its mechanism. Grokking on modular addition has been known to implement Fourier representation and its calculation circuits with trigonometric identities in Transformers. Considering the periodicity in modular arithmetic, the natural question is to what extent these explanations and interpretations hold for the grokking on other modular operations beyond addition. For a closer look, we first hypothesize that (1) any modular operations can be characterized with distinctive Fourier representation or internal circuits, (2) grokked models obtain common features transferable among similar operations, and (3) mixing datasets with similar operations promotes grokking. Then, we extensively examine them by learning Transformers on complex modular arithmetic tasks, including polynomials. Our Fourier analysis and novel progress measure for modular arithmetic, Fourier Frequency Density and Fourier Coefficient Ratio, characterize distinctive internal representations of grokked models per modular operation; for instance, polynomials often result in the superposition of the Fourier components seen in elementary arithmetic, but clear patterns do not emerge in challenging non-factorizable polynomials. In contrast, our ablation study on the pre-grokked models reveals that the transferability among the models grokked with each operation can be only limited to specific combinations, such as from elementary arithmetic to linear expressions. Moreover, some multi-task mixtures may lead to co-grokking -- where grokking simultaneously happens for all the tasks -- and accelerate generalization, while others may not find optimal solutions. We empirically provide significant steps towards the interpretability of internal circuits learned through modular operations, where analytical solutions are not attainable",
    "checked": true,
    "id": "b71aade02f9e6272c81f3e23458298dbebb1a322",
    "semantic_title": "towards empirical interpretation of internal circuits and properties in grokked transformers on modular polynomials",
    "citation_count": 7,
    "authors": [
      "Hiroki Furuta",
      "Gouki Minegishi",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ]
  },
  "https://openreview.net/forum?id=FQAgFgkaFG": {
    "title": "Demonstration-Guided Multi-Objective Reinforcement Learning",
    "volume": "main",
    "abstract": "Multi-objective reinforcement learning (MORL) closely mirrors real-world conditions and has consequently gained attention. However, training a MORL policy from scratch is more challenging as it needs to balance multiple objectives according to differing preferences during policy optimization. Demonstrations often embody a wealth of domain knowledge that can improve MORL training efficiency without specific design. We propose an algorithm i.e. demonstration-guided multi-objective reinforcement learning (DG-MORL), which is the first MORL algorithm that can use prior demonstrations to enhance training efficiency seamlessly. Our novel algorithm aligns prior demonstrations with latent preferences via corner weight support. We also propose a \\textit{self-evolving mechanism} to gradually refine the demonstration set and avoid sub-optimal demonstration from hindering the training. DG-MORL offers a universal framework that can be utilized for any MORL algorithm. Our empirical studies demonstrate DG-MORL's superiority over state-of-the-art MORL algorithms, establishing its robustness and efficacy. We also provide the sample complexity lower bound and the upper bound of Pareto regret of the algorithm",
    "checked": false,
    "id": "033b96503d85082445fc724b91d5ab252934418f",
    "semantic_title": "demonstration guided multi-objective reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ]
  },
  "https://openreview.net/forum?id=9m2k96cDMK": {
    "title": "Weighted L1 and L0 Regularization Using Proximal Operator Splitting Methods",
    "volume": "main",
    "abstract": "This paper develops a joint weighted $\\displaystyle \\normlone$- and $\\displaystyle \\normlzero$-norm (WL1L0) regularization method by leveraging proximal operators and translation mapping techniques to mitigate the bias introduced by the $\\displaystyle \\normlone$-norm in applications to high-dimensional data. A weighting parameter $\\alpha$ is incorporated to control the influence of both regularizers. Our broadly applicable model is nonconvex and nonsmooth, but we show convergence for the alternating direction method of multipliers (ADMM) and the strictly contractive PeacemanâRachford splitting method (SCPRSM). Moreover, we evaluate the effectiveness of our model on both simulated and real high-dimensional genomic datasets by comparing with adaptive versions of the least absolute shrinkage and selection operator (LASSO), elastic net (EN), smoothly clipped absolute deviation (SCAD) and minimax concave penalty (MCP). The results show that WL1L0 outperforms the LASSO, EN, SCAD and MCP by consistently achieving the lowest mean squared error (MSE) across all datasets, indicating its superior ability to handling large high-dimensional data. Furthermore, the WL1L0-SCPRSM also achieves the sparsest solution",
    "checked": true,
    "id": "b583da1ea8e70040c0866a63b41830cf61262da8",
    "semantic_title": "weighted l1 and l0 regularization using proximal operator splitting methods",
    "citation_count": 2,
    "authors": [
      "Zewude A. Berkessa",
      "Patrik Waldmann"
    ]
  },
  "https://openreview.net/forum?id=FvxTseSYRk": {
    "title": "Reproducibility Study of \"Languange-Image COnsistency",
    "volume": "main",
    "abstract": "This report aims to verify the findings and expand upon the evaluation and training methods from the paper LICO: Explainable Models with Language-Image COnsistency. The main claims from the original paper are that LICO (i) enhances interpretability by producing more explainable saliency maps in conjunction with a post-hoc explainability method and (ii) improves image classification performance without computational overhead during inference. We have reproduced the key experiments conducted by Lei et al.; however, the obtained results do not support the original claims. Additionally, we identify a limitation in the paper's evaluation method, which favors non-robust models, and propose robust experimental setups for more comprehensive quantitative analysis. Furthermore, we undertake additional studies on LICO's training methodology to enhance its interpretability. Our code is available at https://github.com/konradszewczyk/lico-reproduction",
    "checked": true,
    "id": "e0dab9fcd4e687432b140672f414953ce1de15b1",
    "semantic_title": "reproducibility study of \"languange-image consistency",
    "citation_count": 0,
    "authors": [
      "Konrad Szewczyk",
      "Patrik Bartak",
      "Mikhail Vlasenko",
      "Fanmin Shi"
    ]
  },
  "https://openreview.net/forum?id=oAkSRhl3qU": {
    "title": "Mitigating Relative Over-Generalization in Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "In decentralized multi-agent reinforcement learning, agents learning in isolation can lead to relative over-generalization (RO), where optimal joint actions are undervalued in favor of suboptimal ones. This hinders effective coordination in cooperative tasks, as agents tend to choose actions that are individually rational but collectively suboptimal. To address this issue, we introduce MaxMax Q-Learning (MMQ), which employs an iterative process of sampling and evaluating potential next states, selecting those with maximal Q-values for learning. This approach refines approximations of ideal state transitions, aligning more closely with the optimal joint policy of collaborating agents. We provide theoretical analysis supporting MMQ's potential and present empirical evaluations across various environments susceptible to RO. Our results demonstrate that MMQ frequently outperforms existing baselines, exhibiting enhanced convergence and sample efficiency",
    "checked": true,
    "id": "28030b8f202e4ae2246e4fae5cfbc9c5aec8f00c",
    "semantic_title": "mitigating relative over-generalization in multi-agent reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Ting Zhu",
      "Yue Jin",
      "Jeremie Houssineau",
      "Giovanni Montana"
    ]
  },
  "https://openreview.net/forum?id=STwxyUfpNV": {
    "title": "An Investigation of Offline Reinforcement Learning in Factorisable Action Spaces",
    "volume": "main",
    "abstract": "Expanding reinforcement learning (RL) to offline domains generates promising prospects, particularly in sectors where data collection poses substantial challenges or risks. Pivotal to the success of transferring RL offline is mitigating overestimation bias in value estimates for state-action pairs absent from data. Whilst numerous approaches have been proposed in recent years, these tend to focus primarily on continuous or small-scale discrete action spaces. Factorised discrete action spaces, on the other hand, have received relatively little attention, despite many real-world problems naturally having factorisable actions. In this work, we undertake a formative investigation into offline reinforcement learning in factorisable action spaces. Using value-decomposition as formulated in DecQN as a foundation, we present the case for a factorised approach and conduct an extensive empirical evaluation of several offline techniques adapted to the factorised setting. In the absence of established benchmarks, we introduce a suite of our own comprising datasets of varying quality and task complexity. Advocating for reproducible research and innovation, we make all datasets available for public use alongside our code base: https://github.com/AlexBeesonWarwick/OfflineRLFactorisableActionSpaces",
    "checked": true,
    "id": "694ebabb3f27e492b18eda01f33ee2da551db8ab",
    "semantic_title": "an investigation of offline reinforcement learning in factorisable action spaces",
    "citation_count": 2,
    "authors": [
      "Alex Beeson",
      "David Ireland",
      "Giovanni Montana"
    ]
  },
  "https://openreview.net/forum?id=weuALLWUV2": {
    "title": "Gaussian-Smoothed Sliced Probability Divergences",
    "volume": "main",
    "abstract": "Gaussian smoothed sliced Wasserstein distance has been recently introduced for comparing probability distributions, while preserving privacy on the data. It has been shown that it provides performances similar to its non-smoothed (non-private) counterpart. However, the computational and statistical properties of such a metric have not yet been well-established. This work investigates the theoretical properties of this distance as well as those of generalized versions denoted as Gaussian-smoothed sliced divergences ${\\text{G}}_{\\sigma}\\text{SW}_p$. We first show that smoothing and slicing preserve the metric property and the weak topology. To study the sample complexity of such divergences, we then introduce $\\hat{\\hat\\mu}_{n}$ the { double empirical distribution} for the smoothed-projected $\\mu$. The distribution $\\hat{\\hat\\mu}_{n}$ is a result of a double sampling process: one from sampling according to the origin distribution $\\mu$ and the second according to the convolution of the projection of $\\mu$ on the unit sphere and the Gaussian smoothing. We particularly focus on the Gaussian smoothed sliced Wasserstein distance ${\\text{G}}_{\\sigma}\\text{SW}_p$ and prove that it converges with a rate $O(n^{-1/{2p}})$. We also derive other properties, including continuity, of different divergences with respect to the smoothing parameter. We support our theoretical findings with empirical studies in the context of privacy-preserving domain adaptation",
    "checked": true,
    "id": "7d067a7dd156f78803d6a173bd946ae7bb7a4666",
    "semantic_title": "gaussian-smoothed sliced probability divergences",
    "citation_count": 0,
    "authors": [
      "Mokhtar Z. Alaya",
      "Alain Rakotomamonjy",
      "Maxime Berar",
      "Gilles Gasso"
    ]
  },
  "https://openreview.net/forum?id=AkdQ266kHj": {
    "title": "Differentially Private Latent Diffusion Models",
    "volume": "main",
    "abstract": "Diffusion models (DMs) are one of the most widely used generative models for producing high-quality images. However, a flurry of recent papers points out that DMs are least private forms of image generators, by extracting a significant number of near-identical replicas of training images from DMs. Existing privacy-enhancing techniques for DMs, unfortunately, do not provide a good privacy-utility tradeoff. In this paper, we aim to improve the current state of DMs with differential privacy (DP) by adopting the Latent Diffusion Models (LDMs). LDMs are equipped with powerful pre-trained autoencoders that map the high-dimensional pixels into lower-dimensional latent representations, in which DMs are trained, yielding a more efficient and fast training of DMs. Rather than fine-tuning the entire LDMs, we fine-tune only the attention modules of LDMs with DP-SGD, reducing the number of trainable parameters by roughly 90% and achieving a better privacy-accuracy trade-off. Our approach allows us to generate realistic, high-dimensional images (256x256) conditioned on text prompts with DP guarantees, which, to the best of our knowledge, has not been attempted before. Our approach provides a promising direction for training more powerful, yet training-efficient differentially private DMs, producing high-quality DP images. Our code is available at https://anonymous.4open.science/r/DP-LDM-4525",
    "checked": true,
    "id": "57053dd68e22e326e24969d4253c74ba1fc19820",
    "semantic_title": "differentially private latent diffusion models",
    "citation_count": 26,
    "authors": [
      "Michael F Liu",
      "Saiyue Lyu",
      "Margarita Vinaroz",
      "Mijung Park"
    ]
  },
  "https://openreview.net/forum?id=phk5CcKTcc": {
    "title": "On Intriguing Layer-Wise Properties of Robust Overfitting in Adversarial Training",
    "volume": "main",
    "abstract": "Adversarial training has proven to be one of the most effective methods to defend against adversarial attacks. Nevertheless, robust overfitting is a common obstacle in adversarial training of deep networks. There is a common belief that the features learned by different network layers have different properties, however, existing works generally investigate robust overfitting by considering a DNN as a single unit and hence the impact of different network layers on robust overfitting remains unclear. In this work, we divide a DNN into a series of layers and investigate the effect of different network layers on robust overfitting. We find that different layers exhibit distinct properties towards robust overfitting, and in particular, robust overfitting is mostly related to the optimization of latter parts of the network. Based upon the observed effect, we propose a \\emph{robust adversarial training} (RAT) prototype: in a minibatch, we optimize the front parts of the network as usual, and adopt additional measures to regularize the optimization of the latter parts. Based on the prototype, we designed two realizations of RAT, and extensive experiments demonstrate that RAT can eliminate robust overfitting and boost adversarial robustness over the standard adversarial training",
    "checked": true,
    "id": "97631249660889b8639518e5cf41e257182b5f62",
    "semantic_title": "on intriguing layer-wise properties of robust overfitting in adversarial training",
    "citation_count": 0,
    "authors": [
      "Duke Nguyen",
      "Chaojian Yu",
      "Vinoth Nandakumar",
      "Young Choon Lee",
      "Tongliang Liu"
    ]
  },
  "https://openreview.net/forum?id=MHJlFCqXdA": {
    "title": "Is Value Functions Estimation with Classification Plug-and- play for Offline Reinforcement Learning?",
    "volume": "main",
    "abstract": "In deep Reinforcement Learning (RL), value functions are typically approximated using deep neural networks and trained via mean squared error regression objectives to fit the true value functions. Recent research has proposed an alternative approach, utilizing the cross-entropy classification objective, which has demonstrated improved performance and scalability of RL algorithms. However, existing study have not extensively benchmarked the effects of this replacement across various domains, as the primary objective was to demonstrate the efficacy of the concept across a broad spectrum of tasks, without delving into in-depth analysis. Our work seeks to empirically investigate the impact of such a replacement in an offline RL setup and analyze the effects of different aspects on performance. Through large-scale experiments conducted across a diverse range of tasks using different algorithms, we aim to gain deeper insights into the implications of this approach. Our results reveal that incorporating this change can lead to superior performance over state-of-the-art solutions for some algorithms in certain tasks, while maintaining comparable performance levels in other tasks, however for other algorithms this modification might lead to the dramatic performance drop. This findings are crucial for further application of classification approach in research and practical tasks",
    "checked": false,
    "id": "4af1e358b5ebaaa86231e0634d73757d19e9aece",
    "semantic_title": "is value functions estimation with classification plug-and-play for offline reinforcement learning?",
    "citation_count": 2,
    "authors": [
      "Denis Tarasov",
      "Kirill Brilliantov",
      "Dmitrii Kharlapenko"
    ]
  },
  "https://openreview.net/forum?id=TBLMrHaFFH": {
    "title": "Improved Variational Bayesian Phylogenetic Inference using Mixtures",
    "volume": "main",
    "abstract": "We introduce VBPI-Mixtures, an algorithm aimed at improving the precision of phylogenetic posterior distributions, with a focus on accurately approximating tree-topologies and branch lengths. Although Variational Bayesian Phylogenetic Inference (VBPI)âa state-of-the-art black-box variational inference (BBVI) frameworkâhas achieved significant success in approximating these distributions, it faces challenges in dealing with the multimodal nature of tree-topology posteriors. While advanced deep learning techniques like normalizing flows and graph neural networks have enhanced VBPI's approximations of branch-length posteriors, there has been a gap in improving its tree-topology posterior approximations. Our novel VBPI-Mixtures algorithm addresses this gap by leveraging recent advancements in mixture learning within the BBVI domain. Consequently, VBPI-Mixtures can capture distributions over tree-topologies that other VBPI algorithms cannot model. Across eight real phylogenetic datasets and compared to the considered benchmarks, we show that VBPI-Mixtures result in lower-variance estimators of the marginal log-likelihood and smaller KL divergences to an MCMC-based approximation of the true tree-topology posterior",
    "checked": true,
    "id": "9fa299449205df09501005fc441bab5a2262d408",
    "semantic_title": "improved variational bayesian phylogenetic inference using mixtures",
    "citation_count": 5,
    "authors": [
      "Ricky MolÃ©n",
      "Oskar Kviman",
      "Jens Lagergren"
    ]
  },
  "https://openreview.net/forum?id=skLtdUVaJa": {
    "title": "Mantis: Interleaved Multi-Image Instruction Tuning",
    "volume": "main",
    "abstract": "Large multimodal models (LMMs) have shown great results in single-image vision language tasks. However, their abilities to solve multi-image visual language tasks is yet to be improved. The existing LMMs like OpenFlamingo, Emu2, and Idefics gain their multi-image ability through pre-training on hundreds of millions of noisy interleaved image-text data from the web, which is neither efficient nor effective. In this paper, we aim to build strong multi-image LMMs via instruction tuning with academic-level resources. Therefore, we meticulously construct Mantis-Instruct containing 721K multi-image instruction data to train a family of Mantis models. The instruction tuning empowers Mantis with different multi-image skills like co-reference, comparison, reasoning, and temporal understanding. We evaluate Mantis on 8 multi-image benchmarks and 6 single-image benchmarks. Mantis-Idefics2 can achieve SoTA results on all the multi-image benchmarks and beat the strongest multi-image baseline, Idefics2-8B by an average of 13 absolute points. Notably, Idefics2-8B was pre-trained on 140M interleaved multi-image data, which is 200x larger than Mantis-Instruct. We observe that Mantis performs equivalently well on the held-in and held-out benchmarks, which shows its generalization ability. We further evaluate Mantis on single-image benchmarks and demonstrate that Mantis also maintains a strong single-image performance on par with CogVLM and Emu2. Our results show that multi-image abilities are not necessarily gained through massive pre-training, instead, they can be gained by low-cost instruction tuning. The training and evaluation of Mantis has paved the road for future work to improve LMMs' multi-image abilities",
    "checked": true,
    "id": "63455557c532abc09fa9a229d2fa7f9bf98b8ae4",
    "semantic_title": "mantis: interleaved multi-image instruction tuning",
    "citation_count": 125,
    "authors": [
      "Dongfu Jiang",
      "Xuan He",
      "Huaye Zeng",
      "Cong Wei",
      "Max Ku",
      "Qian Liu",
      "Wenhu Chen"
    ]
  },
  "https://openreview.net/forum?id=WHIwUjbJEh": {
    "title": "Beyond Loss Functions: Exploring Data-Centric Approaches with Diffusion Model for Domain Generalization",
    "volume": "main",
    "abstract": "There has been a huge effort to tackle the Domain Generalization (DG) problem with a focus on developing new loss functions. Inspired by the image generation capabilities of the diffusion models, we pose a pivotal question: Can diffusion models function as data augmentation tools to address DG from a data-centric perspective, rather than relying on the loss functions? Our findings reveal that trivial cross-domain data augmentation (CDGA) along with the vanilla ERM using readily available diffusion models without additional finetuning outperforms state-of-the-art (SOTA) training algorithms. This paper delves into the exploration of why and how this rudimentary data generation can outperform complicated DG algorithms. With the help of domain shift quantification tools, We empirically show that CDGA reduces the domain shift between domains. We empirically reveal connections between the loss landscape, adversarial robustness, and data generation, illustrating that CDGA reduces loss sharpness and improves robustness against adversarial shifts in data. Additionally, we discuss our intuitions that CDGA along with ERM can be considered as a way to replace the pointwise kernel estimates in ERM with new density estimates in the \\textit{vicinity of domain pairs} which can diminish the true data estimation error of ERM under domain shift scenario. These insights advocate for further investigation into the potential of data-centric approaches in DG",
    "checked": true,
    "id": "02010b071d58cb4fbd8a974c3ccf503f550b2334",
    "semantic_title": "beyond loss functions: exploring data-centric approaches with diffusion model for domain generalization",
    "citation_count": 1,
    "authors": [
      "Sobhan Hemati",
      "Mahdi Beitollahi",
      "Amir Hossein Estiri",
      "Bassel Al Omari",
      "Soufiane Lamghari",
      "Yasser H. Khalil",
      "Xi Chen",
      "Guojun Zhang"
    ]
  },
  "https://openreview.net/forum?id=frb6sLbACS": {
    "title": "DrGNN: Deep Residual Graph Neural Network with Contrastive Learning",
    "volume": "main",
    "abstract": "Recent studies reveal that deep representation learning models without proper regularization can suffer from the dimensional collapse problem, i.e., representation vectors span over a lower dimensional space. In the domain of graph deep representation learning, the phenomenon that the node representations are indistinguishable and even shrink to a constant vector is called oversmoothing. Based on the analysis of the rank of node representations, we find that representation oversmoothing and dimensional collapse are highly related to each other in deep graph neural networks, and the oversmoothing problem can be interpreted by the dimensional collapse of the node representation matrix. Then, to address the dimensional collapse and the oversmoothing together in deep graph neural networks, we first find vanilla residual connections and contrastive learning producing sub-optimal outcomes by ignoring the structured constraints of graph data. Motivated by this, we propose a novel graph neural network named DrGNN to alleviate the oversmoothing issue from the perspective of addressing dimensional collapse. Specifically, in DrGNN, we design a topology-preserving residual connection for graph neural networks to force the low-rank of hidden representations close to the full-rank input features. Also, we propose the structure-guided contrastive learning to ensure only close neighbors who share similar local connections can have similar representations. Empirical experiments on multiple real-world datasets demonstrate that DrGNN outperforms state-of-the-art deep graph representation baseline algorithms. The code of our method is available at the GitHub link: https://github.com/zhenglecheng/DrGNN",
    "checked": true,
    "id": "b1874882c2c30f16cd548214bf81e0a73fbd20d3",
    "semantic_title": "drgnn: deep residual graph neural network with contrastive learning",
    "citation_count": 7,
    "authors": [
      "Lecheng Zheng",
      "Dongqi Fu",
      "Ross Maciejewski",
      "Jingrui He"
    ]
  },
  "https://openreview.net/forum?id=nuzFG0Rbhy": {
    "title": "A Single Transformer for Scalable Vision-Language Modeling",
    "volume": "main",
    "abstract": "We present SOLO, a single transformer for Scalable visiOn-Language mOdeling. Current large vision-language models (LVLMs) such as LLaVA mostly employ heterogeneous architectures that connect pre-trained visual encoders with large language models (LLMs) to facilitate visual recognition and complex reasoning. Although achieving remarkable performance with relatively lightweight training, we identify four primary scalability limitations: (1) The visual capacity is constrained by pre-trained visual encoders, which are typically an order of magnitude smaller than LLMs. (2) The heterogeneous architecture complicates the use of established hardware and software infrastructure. (3) Study of scaling laws on such architecture must consider three separate components â visual encoder, connector, and LLMs, which complicates the analysis. (4) The use of existing visual encoders typically requires following a pre-defined specification of image inputs pre-processing, for example, by reshaping inputs to fixed-resolution square images. This inflexibility can create bottlenecks and impede scalability. A unified single Transformer architecture, like \\approach, effectively addresses these scalability concerns in LVLMs; however, its limited adoption in the modern context likely stems from the absence of reliable training recipes that balance both modalities and ensure stable training for billion-scale models. In this paper, we introduce the first open-source training recipe for developing SOLO, an open-source 7B LVLM with the single Transformer architecture using moderate academic resources (8 x A100 80GB GPUs). The training recipe involves initializing from LLMs, sequential pre-training on ImageNet and web-scale data, and instruction fine-tuning on our curated high-quality datasets. On extensive evaluation, SOLO demonstrates performance comparable to LLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning",
    "checked": true,
    "id": "c57fc2f10a7b9b1cdcbcbba66eaae924ea2717ad",
    "semantic_title": "a single transformer for scalable vision-language modeling",
    "citation_count": 17,
    "authors": [
      "Yangyi Chen",
      "Xingyao Wang",
      "Hao Peng",
      "Heng Ji"
    ]
  },
  "https://openreview.net/forum?id=99GovbuMcP": {
    "title": "Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness",
    "volume": "main",
    "abstract": "The remarkable advances in deep learning have led to the emergence of many off-the-shelf classifiers, e.g., large pre-trained models. However, since they are typically trained on clean data, they remain vulnerable to adversarial attacks. Despite this vulnerability, their superior performance and transferability make off-the-shelf classifiers still valuable in practice, demanding further work to provide adversarial robustness for them in a post-hoc manner. A recently proposed method, denoised smoothing, leverages a denoiser model in front of the classifier to obtain provable robustness without additional training. However, the denoiser often creates hallucination, i.e., images that have lost the semantics of their originally assigned class, leading to a drop in robustness. Furthermore, its noise-and-denoise procedure introduces a significant distribution shift from the original distribution, causing the denoised smoothing framework to achieve sub-optimal robustness. In this paper, we introduce Fine-Tuning with Confidence-Aware Denoised Image Selection (FT-CADIS), a novel fine-tuning scheme to enhance the certified robustness of off-the-shelf classifiers. FT-CADIS is inspired by the observation that the confidence of off-the-shelf classifiers can effectively identify hallucinated images during denoised smoothing. Based on this, we develop a confidence-aware training objective to handle such hallucinated images and improve the stability of fine-tuning from denoised images. In this way, the classifier can be fine-tuned using only images that are beneficial for adversarial robustness. We also find that such a fine-tuning can be done by merely updating a small fraction (i.e., 1%) of parameters of the classifier. Extensive experiments demonstrate that FT-CADIS has established the state-of-the-art certified robustness among denoised smoothing methods across all $l_2$-adversary radius in a variety of benchmarks, such as CIFAR-10 and ImageNet",
    "checked": true,
    "id": "82ae50104e0062c2e4c149cf28cc546794cc52c4",
    "semantic_title": "confidence-aware denoised fine-tuning of off-the-shelf models for certified robustness",
    "citation_count": 0,
    "authors": [
      "Suhyeok Jang",
      "Seojin Kim",
      "Jinwoo Shin",
      "Jongheon Jeong"
    ]
  },
  "https://openreview.net/forum?id=GSp2WC7q0r": {
    "title": "Towards Backwards-Compatible Data with Confounded Domain Adaptation",
    "volume": "main",
    "abstract": "Most current domain adaptation methods address either covariate shift or label shift, but are not applicable where they occur simultaneously and are confounded with each other. Domain adaptation approaches which do account for such confounding are designed to adapt covariates to optimally predict a particular label whose shift is confounded with covariate shift. In this paper, we instead seek to achieve general-purpose data backwards compatibility. This would allow the adapted covariates to be used for a variety of downstream problems, including on pre-existing prediction models and on data analytics tasks. To do this we consider a modification of generalized label shift (GLS), which we call confounded shift. We present a novel framework for this problem, based on minimizing the expected divergence between the source and target conditional distributions, conditioning on possible confounders. Within this framework, we provide concrete implementations using the Gaussian reverse Kullback-Leibler divergence and the maximum mean discrepancy. Finally, we demonstrate our approach on synthetic and real datasets",
    "checked": true,
    "id": "f6b7cc8e4bd91a930b237b4ff4d77b1ce6be70a8",
    "semantic_title": "towards backwards-compatible data with confounded domain adaptation",
    "citation_count": 0,
    "authors": [
      "Calvin McCarter"
    ]
  },
  "https://openreview.net/forum?id=JXCe2ZcUXr": {
    "title": "Feature learning as alignment: a structural property of gradient descent in non-linear neural networks",
    "volume": "main",
    "abstract": "Understanding the mechanisms through which neural networks extract statistics from input-label pairs through feature learning is one of the most important unsolved problems in supervised learning. Prior works demonstrated that the gram matrices of the weights (the neural feature matrices, NFM) and the average gradient outer products (AGOP) become correlated during training, in a statement known as the neural feature ansatz (NFA). Through the NFA, the authors introduce mapping with the AGOP as a general mechanism for neural feature learning. However, these works do not provide a theoretical explanation for this correlation or its origins. In this work, we further clarify the nature of this correlation, and explain its emergence. We show that this correlation is equivalent to alignment between the left singular structure of the weight matrices and the newly defined pre-activation tangent features at each layer. We further establish that the alignment is driven by the interaction of weight changes induced by SGD with the pre-activation features, and analyze the resulting dynamics analytically at early times in terms of simple statistics of the inputs and labels. We prove the derivative alignment occurs with high probability in specific high dimensional settings. Finally, motivated by the observation that the NFA is driven by this centered correlation, we introduce a simple optimization rule that dramatically increases the NFA correlations at any given layer and improves the quality of features learned",
    "checked": true,
    "id": "e7259e25247ea91d3952d904b438f474882300a9",
    "semantic_title": "feature learning as alignment: a structural property of gradient descent in non-linear neural networks",
    "citation_count": 2,
    "authors": [
      "Daniel Beaglehole",
      "Ioannis Mitliagkas",
      "Atish Agarwala"
    ]
  },
  "https://openreview.net/forum?id=0h1DtRK6dA": {
    "title": "Bayesian Computation Meets Topology",
    "volume": "main",
    "abstract": "Computational topology recently started to emerge as a novel paradigm for characterising the âshape' of high-dimensional data, leading to powerful algorithms in (un)supervised representation learning. While capable of capturing prominent features at multiple scales, topological methods cannot readily be used for Bayesian inference. We develop a novel approach that bridges this gap, making it possible to perform parameter estimation in a Bayesian framework, using topology-based loss functions. Our method affords easy integration into topological machine learning algorithms. We demonstrate its efficacy for parameter estimation in different simulation settings",
    "checked": true,
    "id": "40c090a996263704b0e64d0e162121e80a807ec7",
    "semantic_title": "bayesian computation meets topology",
    "citation_count": 0,
    "authors": [
      "Julius von Rohrscheidt",
      "Bastian Rieck",
      "Sebastian M Schmon"
    ]
  },
  "https://openreview.net/forum?id=tBkj2I1mJY": {
    "title": "Language Models Speed Up Local Search for Finding Programmatic Policies",
    "volume": "main",
    "abstract": "Encoding policies that solve sequential decision-making problems as programs offers advantages over neural representations, such as interpretability and modifiability of the policies. On the downside, programmatic policies are elusive because their generation requires one to search in spaces of programs that are often discontinuous. In this paper, we leverage the ability of large language models (LLMs) to write computer programs to speed up the synthesis of programmatic policies. We use an LLM to provide initial candidates for the policy, which are then improved by local search. Empirical results in three problems that are challenging for programmatic representations show that LLMs can speed up local search and facilitate the synthesis of policies. We conjecture that LLMs are effective in this setting because we give them access to the outcomes of the policies rollouts. That way, LLMs can try policies encoding different behaviors, once they observe what a previous policy has accomplished. This process forces the search to explore different parts of the space through \"exploratory initial programs\". Experiments also show that much of the knowledge LLMs leverage comes from the domain-specific language that defines the search space - the overall performance of the system drops sharply if we change the name of the functions used in the language to meaningless names. Since our system only queries the LLM in the first step of the search, it offers an economical method for using LLMs to guide the synthesis of policies",
    "checked": true,
    "id": "788da945220bafbae80ac152e68ec608dc61442e",
    "semantic_title": "language models speed up local search for finding programmatic policies",
    "citation_count": 0,
    "authors": [
      "Quazi Asif Sadmine",
      "Hendrik Baier",
      "Levi Lelis"
    ]
  },
  "https://openreview.net/forum?id=mDGvrH7lju": {
    "title": "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder",
    "volume": "main",
    "abstract": "Symmetries of input and latent vectors have provided valuable insights for disentanglement learning in VAEs. However, only a few works were proposed as an unsupervised method, and even these works require known factor information in training data. We propose a novel method, Composite Factor-Aligned Symmetry Learning (CFASL), which is integrated into VAEs for learning symmetry-based disentanglement in unsupervised learning without any knowledge of the dataset factor information. CFASL incorporates three novel features for learning symmetry-based disentanglement: 1) Injecting inductive bias to align latent vector dimensions to factor-aligned symmetries within an explicit learnable symmetry code-book 2) Learning a composite symmetry to express unknown factors change between two random samples by learning factor-aligned symmetries within the codebook 3) Inducing group equivariant encoder and decoder in training VAEs with the two conditions. In addition, we propose an extended evaluation metric for multi-factor changes in comparison to disentanglement evaluation in VAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a significant improvement of disentanglement in single-factor change, and multi-factor change conditions compared to state-of-the-art methods",
    "checked": true,
    "id": "345428fcaaf74c33132e1ef2d119fc3eac33dd5c",
    "semantic_title": "cfasl: composite factor-aligned symmetry learning for disentanglement in variational autoencoder",
    "citation_count": 0,
    "authors": [
      "Hee-Jun Jung",
      "Jaehyoung Jeong",
      "Kangil Kim"
    ]
  },
  "https://openreview.net/forum?id=FlxnywWi14": {
    "title": "Modular Federated Contrastive Learning with Twin Normalization for Resource-limited Clients",
    "volume": "main",
    "abstract": "Despite recent progress in federated learning (FL), the challenge of training a global model across clients, having heterogeneous, class-imbalanced, and unlabeled data, is not fully resolved. Self-supervised learning requires deep and wide networks, and federal training of those networks induces a huge communication/computation burden on the client side. We propose Modular Federated Contrastive Learning (MFCL) by changing the training framework from end-to-end to modular, meaning that instead of federally training the entire network, only the first layers are trained federally through a server, and other layers are trained at another server without any forward/backward passes between servers. We also propose Twin Normalization (TN) to tackle data heterogeneity. Results show that ResNet-18 trained with MFCL(TN) on CIFAR-10 achieves $84.1\\%$ accuracy when data is severely heterogeneous while reducing the communication burden and memory footprint compared to end-to-end training. The code will be released upon paper acceptance",
    "checked": true,
    "id": "d13745e9100514aa1b8ca3fda025fd7bdd017e1e",
    "semantic_title": "modular federated contrastive learning with twin normalization for resource-limited clients",
    "citation_count": 0,
    "authors": [
      "Azadeh Motamedi",
      "IL MIN KIM"
    ]
  },
  "https://openreview.net/forum?id=yHUtuvoIQv": {
    "title": "Graphon-Explainer: Generating Model-Level Explanations for Graph Neural Networks using Graphons",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) form the backbone of several state-of-the-art methods for performing machine learning tasks on graphs. As GNNs find application across diverse real-world scenarios, ensuring their interpretability and reliability becomes imperative. In this paper, we propose Graphon-Explainer, a model-level explanation method to elucidate the high-level decision-making process of a GNN. Graphon-Explainer learns a graphonâa symmetric, continuous function viewed as a weighted adjacency matrix of an infinitely large graphâto approximate the distribution of a target class as learned by the GNN. The learned graphon then acts as a generative model, yielding distinct graph motifs deemed significant by the GNN for the target class. Unlike existing model-level explanation methods for GNNs, which are limited to explaining a GNN for individual target classes, Graphon-Explainer can also generate synthetic graphs close to the decision boundary between two target classes by interpolating graphons of both classes, aiding in characterizing the GNN model's decision boundary. Furthermore, Graphon-Explainer is model-agnostic, does not rely on additional black-box models, and does not require manually specified handcrafted constraints for explanation generation. The effectiveness of our method is validated through thorough theoretical analysis and extensive experimentation on both synthetic and real-world datasets on the task of graph classification. Results demonstrate its capability to effectively learn and generate diverse graph patterns identified by a trained GNN, thus enhancing its interpretability for end-users",
    "checked": true,
    "id": "3484e564b6ac154e5007b056c8e5b2e1b8bfc0d8",
    "semantic_title": "graphon-explainer: generating model-level explanations for graph neural networks using graphons",
    "citation_count": 1,
    "authors": [
      "Sayan Saha",
      "Sanghamitra Bandyopadhyay"
    ]
  },
  "https://openreview.net/forum?id=R6ey5DKaoX": {
    "title": "Simple Steps to Success: A Method for Step-Based Counterfactual Explanations",
    "volume": "main",
    "abstract": "Algorithmic recourse is a process that leverages counterfactual explanations, going beyond understanding why a system produced a given classification, to providing a user with actions they can take to change their predicted outcome. Existing approaches to compute such interventions---known as recourse---identify a set of points that satisfy some desiderata---e.g. an intervention in the underlying causal graph, minimizing a cost function, etc. Satisfying these criteria, however, requires extensive knowledge of the underlying model structure, an often unrealistic amount of information in several domains. We propose a data-driven and model-agnostic framework to compute counterfactual explanations. We introduce StEP, a computationally efficient method that offers incremental steps along the data manifold that directs users towards their desired outcome. We show that StEP uniquely satisfies a desirable set of axioms. Furthermore, via a thorough empirical and theoretical investigation, we show that StEP offers provable robustness and privacy guarantees while outperforming popular methods along important metrics",
    "checked": true,
    "id": "59b641e4751e66b050508597dff67fb725296b00",
    "semantic_title": "simple steps to success: a method for step-based counterfactual explanations",
    "citation_count": 0,
    "authors": [
      "Jenny Hamer",
      "Nicholas Perello",
      "Jason Valladares",
      "Vignesh Viswanathan",
      "Yair Zick"
    ]
  },
  "https://openreview.net/forum?id=PNcgJMJcdl": {
    "title": "Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models",
    "volume": "main",
    "abstract": "Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, sometimes outweighing the computational cost savings. This paper demonstrates that not all sample selection differences result in performance degradation. Furthermore, we show that suitable training methods can mitigate the decline of active learning performance caused by certain selection discrepancies. Building upon detailed analysis, we propose a novel method, aligned selection via proxy, which improves proxy-based active learning performance by updating pre-computed features and selecting a proper training method. Extensive experiments validate that our method improves the total cost of efficient active learning while maintaining computational efficiency",
    "checked": true,
    "id": "83d48db63b58b89c481a6aeda7eb3874226962fe",
    "semantic_title": "feature alignment: rethinking efficient active learning via proxy in the context of pre-trained models",
    "citation_count": 0,
    "authors": [
      "Ziting Wen",
      "Oscar Pizarro",
      "Stefan B. Williams"
    ]
  },
  "https://openreview.net/forum?id=4TZ4DE24fX": {
    "title": "Bandits with Mean Bounds",
    "volume": "main",
    "abstract": "We study a variant of the bandit problem where side information in the form of bounds on the mean of each arm is provided. We prove that these translate to tighter estimates of subgaussian factors and develop novel algorithms that exploit these estimates. In the linear setting, we present the Restricted-set OFUL (R-OFUL) algorithm that additionally uses the geometric properties of the problem to (potentially) restrict the set of arms being played and reduce exploration rates for suboptimal arms. In the stochastic case, we propose the non-optimistic Global Under-Explore (GLUE) algorithm which employs the inferred subgaussian estimates to adapt the rate of exploration for the arms. We analyze the regret of R-OFUL and GLUE, showing that our regret upper bounds are never worse than that of the standard OFUL and UCB algorithms respectively. Further, we also consider a practically motivated setting of learning from confounded logs where mean bounds appear naturally",
    "checked": false,
    "id": "7af5e9a4995e78c40b5ca45e42eab62e78554034",
    "semantic_title": "budgeted multi-armed bandits with asymmetric confidence intervals",
    "citation_count": 1,
    "authors": [
      "Nihal Sharma",
      "Soumya Basu",
      "Karthikeyan Shanmugam",
      "Sanjay Shakkottai"
    ]
  },
  "https://openreview.net/forum?id=nWnYSLncXa": {
    "title": "Merging Text Transformer Models from Different Initializations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f5ef6a08cb02669a2bcd21084ffe80af3fe504a1",
    "semantic_title": "merging text transformer models from different initializations",
    "citation_count": 8,
    "authors": [
      "Neha Verma",
      "Maha Elbayad"
    ]
  },
  "https://openreview.net/forum?id=0uwe0z2Hqm": {
    "title": "Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e2527f621a171b190f5a8d3aeb83a60fde586df1",
    "semantic_title": "deep-graph-sprints: accelerated representation learning in continuous-time dynamic graphs",
    "citation_count": 0,
    "authors": [
      "Ahmad Naser Eddin",
      "Jacopo Bono",
      "David Oliveira Aparicio",
      "Hugo Ferreira",
      "Pedro Manuel Pinto Ribeiro",
      "Pedro Bizarro"
    ]
  },
  "https://openreview.net/forum?id=oI2Tpd4tiP": {
    "title": "Contrastive Learning with Adaptive Neighborhoods for Brain Age Prediction on 3D Stiffness Maps",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1ad6fa0d292c15aba26b81427561c8b93b2433cc",
    "semantic_title": "contrastive learning with adaptive neighborhoods for brain age prediction on 3d stiffness maps",
    "citation_count": 0,
    "authors": [
      "Jakob TrÃ¤uble",
      "Lucy V Hiscox",
      "Curtis Johnson",
      "Carola-Bibiane SchÃ¶nlieb",
      "Gabriele S Kaminski Schierle",
      "Angelica I Aviles-Rivero"
    ]
  },
  "https://openreview.net/forum?id=usvg3yhjAx": {
    "title": "Heterogeneous graph adaptive flow network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "007e28276e089831b28ad4e8beab066bfa5f5fd6",
    "semantic_title": "heterogeneous graph adaptive flow network",
    "citation_count": 0,
    "authors": [
      "Lu Yiqi",
      "Feng Ji",
      "Wee Peng Tay"
    ]
  },
  "https://openreview.net/forum?id=fJEsas1z8J": {
    "title": "MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection",
    "volume": "main",
    "abstract": "Combining the strengths of many existing predictors to obtain a Mixture of Experts which is superior to its individual components is an effective way to improve the performance without having to develop new architectures or train a model from scratch. However, surprisingly, we find that naively combining off-the-shelf object detectors in a similar way to Deep Ensembles, can often lead to degraded performance. We identify that the primary cause of this issue is that the predictions of the experts do not match their performance, a term referred to as miscalibration. Consequently, the most confident detector dominates the final predictions, preventing the mixture from leveraging all the predictions from the experts appropriately. To address this, when constructing the Mixture of Experts for object detection, we propose to combine their predictions in a manner which reflects the individual performance of the experts; an objective we achieve by first calibrating the predictions before filtering and refining them. We term this approach the Mixture of Calibrated Experts (MoCaE) and demonstrate its effectiveness through extensive experiments on 5 different detection tasks, showing that it: (i) improves object detectors on COCO and instance segmentation methods on LVIS by up to $\\sim 2.5$ AP; (ii) reaches state-of-the-art on COCO test-dev with $65.1$ AP and on DOTA with $82.62$ $\\mathrm{AP_{50}}$; (iii) outperforms single models consistently on recent detection tasks such as Open Vocabulary Object Detection. Code is available at: https://github.com/fiveai/MoCaE",
    "checked": true,
    "id": "68134d575dfef21b067c910e5fb5152dddfa81d0",
    "semantic_title": "mocae: mixture of calibrated experts significantly improves object detection",
    "citation_count": 7,
    "authors": [
      "Kemal Oksuz",
      "Selim Kuzucu",
      "Tom Joy",
      "Puneet K. Dokania"
    ]
  },
  "https://openreview.net/forum?id=p4Y844vJWG": {
    "title": "IM-Context: In-Context Learning for Imbalanced Regression Tasks",
    "volume": "main",
    "abstract": "Regression models often fail to generalize effectively in regions characterized by highly imbalanced label distributions. Previous methods for deep imbalanced regression rely on gradient-based weight updates, which tend to overfit in underrepresented regions. This paper proposes a paradigm shift towards in-context learning as an effective alternative to conventional in-weight learning methods, particularly for addressing imbalanced regression. In-context learning refers to the ability of a model to condition itself, given a prompt sequence composed of in-context samples (input-label pairs) alongside a new query input to generate predictions, without requiring any parameter updates. In this paper, we study the impact of the prompt sequence on the model performance from both theoretical and empirical perspectives. We emphasize the importance of localized context in reducing bias within regions of high imbalance. Empirical evaluations across a variety of real-world datasets demonstrate that in-context learning substantially outperforms existing in-weight learning methods in scenarios with high levels of imbalance",
    "checked": true,
    "id": "1a2dd2aa7a996b7cb60c6d3343e559619372325c",
    "semantic_title": "im-context: in-context learning for imbalanced regression tasks",
    "citation_count": 1,
    "authors": [
      "Ismail Nejjar",
      "Faez Ahmed",
      "Olga Fink"
    ]
  },
  "https://openreview.net/forum?id=lIsCS8b6zj": {
    "title": "Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey",
    "volume": "main",
    "abstract": "Large models represent a groundbreaking advancement in multiple application fields, enabling remarkable achievements across various tasks. However, their unprecedented scale comes with significant computational costs. These models, often consisting of billions of parameters, require vast amounts of computational resources for execution. Especially, the expansive scale and computational demands pose considerable challenges when customizing them for particular downstream tasks, particularly over the hardware platforms constrained by computational capabilities. Parameter Efficient Fine-Tuning (PEFT) provides a practical solution by efficiently adjusting the large models over the various downstream tasks. In particular, PEFT refers to the process of adjusting the parameters of a pre-trained large model to adapt it to a specific task or domain while minimizing the number of additional parameters introduced or computational resources required. This approach is particularly important when dealing with large-scale language models with high parameter counts, as fine-tuning these models from scratch can be computationally expensive and resource-intensive, posing considerable challenges in the supporting system platform design. In this survey, we present comprehensive studies of various PEFT algorithms, examining their performance and computational overhead. Moreover, we provide an overview of applications developed using different PEFT algorithms and discuss common techniques employed to mitigate PEFT computation costs. In addition to providing an extensive survey from an algorithmic standpoint, we also examine various real-world system designs to investigate the implementation costs associated with different PEFT approaches. This survey serves as a valuable resource for researchers aiming to understand both the PEFT algorithm and its system implementation, offering detailed insights into recent advancements and practical applications",
    "checked": true,
    "id": "916b4926cda574dc3f9486bb9994b6f2788dd800",
    "semantic_title": "parameter-efficient fine-tuning for large models: a comprehensive survey",
    "citation_count": 401,
    "authors": [
      "Zeyu Han",
      "Chao Gao",
      "Jinyang Liu",
      "Jeff Zhang",
      "Sai Qian Zhang"
    ]
  },
  "https://openreview.net/forum?id=mVAp0eDfyR": {
    "title": "Federated Graph Learning with Graphless Clients",
    "volume": "main",
    "abstract": "Federated graph learning is tasked with training machine learning models, such as Graph Neural Networks (GNNs), for multiple clients, each with its own graph data. Existing methods usually assume that each client has both node features and graph structure of its graph data. In real-world scenarios, however, there exist federated learning systems where only a part of the clients have such data while other clients graphless clients may only have features. This naturally leads to a novel problem in federated graph learning: how to jointly train a model over distributed graph data with graphless clients? To tackle this problem, we propose a novel Federated Graph Structure Learning (FedGSL) framework in this paper. In FedGSL, we devise a local graph learner on each graphless client which learns the local graph structure with the structure knowledge transferred from other clients. To enable structure knowledge transfer, we design a GNN model and a feature encoder on each client. During local training, the feature encoder retains the local graph structure knowledge together with the GNN model via knowledge distillation, and the structure knowledge is transferred among clients in global update. Our extensive experiments on five real-world graph datasets demonstrate the superiority of FedGSL over other five federated learning approaches",
    "checked": true,
    "id": "96a6f62de3602ca4f8be1717767964a9139ac9b1",
    "semantic_title": "federated graph learning with graphless clients",
    "citation_count": 3,
    "authors": [
      "Xingbo Fu",
      "Song Wang",
      "Yushun Dong",
      "Binchi Zhang",
      "Chen Chen",
      "Jundong Li"
    ]
  },
  "https://openreview.net/forum?id=HVxumpoWBm": {
    "title": "One by One, Continual Coordinating with Humans via Hyper-Teammate Identification",
    "volume": "main",
    "abstract": "One of the primary objectives in modern artificial intelligence researches is to empower agents to effectively coordinate with diverse teammates, particularly human teammates. Previous studies focused on training agents either with a fixed population of pre-generated teammates or through the co-evolution of distinct populations of agents and teammates. However, it is challenging to enumerate all possible teammates in advance, and it is costly, or even impractical to maintain such a sufficiently diverse population and repeatedly interact with previously encountered teammates. Additional design considerations, such as prioritized sampling, are also required to ensure efficient training. To address these challenges and obtain an efficient human-AI coordination paradigm, we propose a novel approach called \\textbf{Concord}. Considering that human participants tend to occur in a sequential manner, we model the training process with different teammates as a continual learning framework, akin to how humans learn and adapt in the real world. We propose a mechanism based on hyper-teammate identification to prevent catastrophic forgetting while promoting forward knowledge transfer. Concretely, we introduce a teammate recognition module that captures the identification of corresponding teammates. Leveraging the identification, a well-coordinated AI policy can be generated via the hyper-network. The entire framework is trained in a decomposed policy gradient manner, allowing for effective credit assignment among agents. This approach enables us to train agents with each generated teammate or humans one by one, ensuring that agents can coordinate effectively with concurrent teammates without forgetting previous knowledge. Our approach outperforms multiple baselines in various multi-agent benchmarks, either with generated human proxies or real human participants",
    "checked": true,
    "id": "d2553058dcdcc8fffe1d77922cc41e6d06c5fa64",
    "semantic_title": "one by one, continual coordinating with humans via hyper-teammate identification",
    "citation_count": 0,
    "authors": [
      "Cong Guan",
      "Feng Chen",
      "Ke Xue",
      "Chunpeng Fan",
      "Lichao Zhang",
      "Ziqian Zhang",
      "Pengyao Zhao",
      "Zongzhang Zhang",
      "Chao Qian",
      "Lei Yuan",
      "Yang Yu"
    ]
  },
  "https://openreview.net/forum?id=IEKtMMSblm": {
    "title": "PLUM: Improving Inference Efficiency By Leveraging Repetition-Sparsity Trade-Off",
    "volume": "main",
    "abstract": "Efficient inference of Deep Neural Networks (DNNs) on resource-constrained edge devices is essential. Quantization and sparsity are key techniques that translate to repetition and sparsity within tensors at the hardware-software interface. This paper introduces the concept of repetition-sparsity trade-off that helps explain computational efficiency during inference. We propose PLUM, a unified co-design framework that integrates DNN inference systems and quantization (forward and backward pass) to leverage the repetition-sparsity trade-off to improve inference efficiency. Our results demonstrate that PLUM's quantization method is more accurate than binary quantization with the same number of non-zero weights. Detailed analysis indicates that signed binarization generates a smaller distribution of effectual (non-zero) parameters nested within a larger distribution of total parameters of latent full-precision weights for a DNN block. Finally, the proposed PLUM framework achieves a 26% speedup on real hardware, doubles energy efficiency, and reduces density by 2.8Ã compared to binary methods while retaining top-1 accuracy when compared to prior-art methods for ResNets on ImageNet (by achieving 66.2% top-1 accuracy), presenting an alternative solution for deploying efficient models in resource-limited environments",
    "checked": true,
    "id": "39885e59f10f034c90310857fef9c34b8f6403a4",
    "semantic_title": "plum: improving inference efficiency by leveraging repetition-sparsity trade-off",
    "citation_count": 0,
    "authors": [
      "Sachit Kuhar",
      "Yash Jain",
      "Alexey Tumanov"
    ]
  },
  "https://openreview.net/forum?id=Ea0LrPORzM": {
    "title": "Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries",
    "volume": "main",
    "abstract": "Federated Reinforcement Learning (FRL) allows multiple agents to collaboratively build a decision making policy without sharing raw trajectories. However, if a small fraction of these agents are adversarial, it can lead to catastrophic results. We propose a policy gradient based approach that is robust to adversarial agents which can send arbitrary values to the server. Under this setting, our results form the first global convergence guarantees with general parametrization. These results demonstrate resilience with adversaries, while achieving optimal sample complexity of order $\\tilde{\\mathcal{O}}\\left( \\frac{1}{N\\epsilon^2} \\left( 1+ \\frac{f^2}{N}\\right)\\right)$, where $N$ is the total number of agents and $f < N/2$ is the number of adversarial agents",
    "checked": true,
    "id": "008020b041f49c6fd50cd0e4a827949c17e99257",
    "semantic_title": "global convergence guarantees for federated policy gradient methods with adversaries",
    "citation_count": 2,
    "authors": [
      "Swetha Ganesh",
      "Jiayu Chen",
      "Gugan Thoppe",
      "Vaneet Aggarwal"
    ]
  },
  "https://openreview.net/forum?id=zz6FesdDbB": {
    "title": "The Klarna Product Page Dataset: Web Element Nomination with Graph Neural Networks and Large Language Models",
    "volume": "main",
    "abstract": "Web automation holds the potential to revolutionize how users interact with the digital world, offering unparalleled assistance and simplifying tasks via sophisticated computational methods. Central to this evolution is the web element nomination task, which entails identifying unique elements on webpages. Unfortunately, the development of algorithmic designs for web automation is hampered by the scarcity of comprehensive and realistic datasets that reflect the complexity faced by real-world applications on the Web. To address this, we introduce the Klarna Product Page Dataset, a comprehensive and diverse collection of webpages that surpasses existing datasets in richness and variety. The dataset features 51,701 manually labeled product pages from 8,175 e-commerce websites across eight geographic regions, accompanied by a dataset of rendered page screenshots. To initiate research on the Klarna Product Page Dataset, we empirically benchmark a range of Graph Neural Networks (GNNs) on the web element nomination task. We make three important contributions. First, we found that a simple Convolutional GNN (GCN) outperforms complex state-of-the-art nomination methods, and further enhance its performance using a Reversible GNN (RevGNN) architecture. Second, we introduce a training refinement procedure that involves identifying a small number of relevant elements from each page using the aforementioned GNN. These elements are then passed to a Large Language Model for the final nomination. This procedure significantly improves the nomination accuracy by 10.9 percentage points on our challenging dataset, without any need for fine-tuning. Finally, in response to another prevalent challenge in this field â the abundance of training methodologies suitable for element nomination â we introduce the Challenge Nomination Training Procedure, a training method that further boosts nomination accuracy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandra Hotti",
      "Riccardo Sven Risuleo",
      "Stefan Magureanu",
      "Aref Moradi",
      "Jens Lagergren"
    ]
  },
  "https://openreview.net/forum?id=qIWazsRaTR": {
    "title": "Towards Provable Log Density Policy Gradient",
    "volume": "main",
    "abstract": "Policy gradient methods are a vital ingredient behind the success of modern reinforcement learning. Modern policy gradient methods, although successful, introduce a residual error in gradient estimation. In this work, we argue that this residual term is significant and correcting for it could potentially improve sample-complexity of reinforcement learning methods. To that end, we propose log density gradient to estimate the policy gradient, which corrects for this residual error term. Log density gradient method computes policy gradient by utilising the state-action discounted distributional formulation. We first present the equations needed to exactly find the log density gradient for a tabular Markov Decision Processes (MDPs). For more complex environments, we propose a temporal difference (TD) method that approximates log density gradient by utilizing backward on-policy samples. Since backward sampling from a Markov chain is highly restrictive we also propose a min-max optimization that can approximate log density gradient using just on-policy samples. We also prove uniqueness, and convergence under linear function approximation, for this min-max optimization. Finally, we show that the sample complexity of our min-max optimization to be of the order of $m^{-1/2}$, where $m$ is the number of on-policy samples. We also demonstrate a proof-of-concept for our log density gradient method on gridworld environment, and observe that our method is able to improve upon the classical policy gradient method by a clear margin, thus indicating a promising novel direction to develop reinforcement learning algorithms that require fewer samples",
    "checked": true,
    "id": "8721a9bb198a089df260a84dcdc4cc6dd1cb638f",
    "semantic_title": "towards provable log density policy gradient",
    "citation_count": 0,
    "authors": [
      "Pulkit Katdare",
      "Anant A Joshi",
      "Katherine Rose Driggs-Campbell"
    ]
  },
  "https://openreview.net/forum?id=uphsKDj0Uu": {
    "title": "Practical Synthesis of Mixed-Tailed Data with Normalizing Flows",
    "volume": "main",
    "abstract": "Capturing the correct tail behavior is difficult, yet essential for a faithful generative model. In this work, we provide an improved framework for training flows-based models with robust capabilities to capture the tail behavior of mixed-tail data. We propose a combination of a tail-flexible base distribution and a robust training algorithm to enable the flow to model heterogeneous tail behavior in the target distribution. We support our claim with extensive experiments on synthetic and real world data",
    "checked": true,
    "id": "4b27ba4b8230d0372668a63b44ed3915d6962191",
    "semantic_title": "practical synthesis of mixed-tailed data with normalizing flows",
    "citation_count": 1,
    "authors": [
      "Saba Amiri",
      "Eric Nalisnick",
      "Adam Belloum",
      "Sander Klous",
      "Leon Gommans"
    ]
  },
  "https://openreview.net/forum?id=vXevE43NxF": {
    "title": "Single-Shot Plug-and-Play Methods for Inverse Problems",
    "volume": "main",
    "abstract": "The utilisation of Plug-and-Play (PnP) priors in inverse problems has become increasingly prominent in recent years. This preference is based on the mathematical equivalence between the general proximal operator and the regularised denoiser, facilitating the adaptation of various off-the-shelf denoiser priors to a wide range of inverse problems. However, existing PnP models predominantly rely on pre-trained denoisers using large datasets. In this work, we introduce Single-Shot PnP methods (SS-PnP), shifting the focus to solving inverse problems with minimal data. First, we integrate Single-Shot proximal denoisers into iterative methods, enabling training with single instances. Second, we propose implicit neural priors based on a novel function that preserves relevant frequencies to capture fine details while avoiding the issue of vanishing gradients. We demonstrate, through extensive numerical and visual experiments, that our method leads to better approximations",
    "checked": true,
    "id": "734415b11c78c57910503b2c18ccf1d0078b8117",
    "semantic_title": "single-shot plug-and-play methods for inverse problems",
    "citation_count": 3,
    "authors": [
      "Yanqi Cheng",
      "Lipei Zhang",
      "Zhenda Shen",
      "Shujun Wang",
      "Lequan Yu",
      "Raymond H. Chan",
      "Carola-Bibiane SchÃ¶nlieb",
      "Angelica I Aviles-Rivero"
    ]
  },
  "https://openreview.net/forum?id=cc4v6v310f": {
    "title": "Hashing with Uncertainty Quantification via Sampling-based Hypothesis Testing",
    "volume": "main",
    "abstract": "To quantify different types of uncertainty when deriving hash-codes for image retrieval, we develop a probabilistic hashing model(ProbHash). Sampling-based hypothesis testing is then derived for hashing with uncertainty quantification(HashUQ) in ProbHash to improve the granularity of hashing-based retrieval by prioritizing the data with confident hash-codes. HashUQ can drastically improve the retrieval performance without sacrificing computational efficiency. For efficient deployment of HashUQ in real-world applications, we discretize the quantified uncertainty to reduce the potential storage overhead. Experimental results show that our HashUQ can achieve state-of-the-art retrieval performance on three image datasets. Ablation experiments on model hyperparameters, different model components, and effects of UQ are also provided with performance comparisons. Our code is available at https://github.com/QianLab/HashUQ",
    "checked": true,
    "id": "76cfa0ed18fcfbeda68fc4b2eca2964f20a59e02",
    "semantic_title": "hashing with uncertainty quantification via sampling-based hypothesis testing",
    "citation_count": 0,
    "authors": [
      "Yucheng Wang",
      "Mingyuan Zhou",
      "Xiaoning Qian"
    ]
  },
  "https://openreview.net/forum?id=EhC84fT2yA": {
    "title": "Adaptively Robust and Sparse $K$-means Clustering",
    "volume": "main",
    "abstract": "While $K$-means is known to be a standard clustering algorithm, its performance may be compromised due to the presence of outliers and high-dimensional noisy variables. This paper proposes adaptively robust and sparse $K$-means clustering (ARSK) to address these practical limitations of the standard $K$-means algorithm. For robustness, we introduce a redundant error component for each observation, and this additional parameter is penalized using a group sparse penalty. To accommodate the impact of high-dimensional noisy variables, the objective function is modified by incorporating weights and implementing a penalty to control the sparsity of the weight vector. The tuning parameters to control the robustness and sparsity are selected by $\\rm Gap$ statistics.Through simulation experiments and real data analysis, we demonstrate the proposed method's superiority to existing algorithms in identifying clusters without outliers and informative variables simultaneously",
    "checked": false,
    "id": "f7b5e894c3222af022b2731d341ff3170c55d496",
    "semantic_title": "adaptively robust and sparse k-means clustering",
    "citation_count": 1,
    "authors": [
      "HAO LI",
      "Shonosuke Sugasawa",
      "Shota Katayama"
    ]
  },
  "https://openreview.net/forum?id=lIy0TEUou7": {
    "title": "Modular Quantization-Aware Training for 6D Object Pose Estimation",
    "volume": "main",
    "abstract": "Edge applications, such as collaborative robotics and spacecraft rendezvous, demand efficient 6D object pose estimation on resource-constrained embedded platforms. Existing 6D object pose estimation networks are often too large for such deployments, necessitating compression while maintaining reliable performance. To address this challenge, we introduce Modular Quantization-Aware Training (MQAT), an adaptive and mixed-precision quantization-aware training strategy that exploits the modular structure of modern 6D object pose estimation architectures. MQAT guides a systematic gradated modular quantization sequence and determines module-specific bit precisions, leading to quantized models that outperform those produced by state-of-the-art uniform and mixed-precision quantization techniques. Our experiments showcase the generality of MQAT across datasets, architectures, and quantization algorithms. Additionally, we observe that MQAT quantized models can achieve an accuracy boost (>7% ADI-0.1d) over the baseline full-precision network while reducing model size by a factor of 4x or more. Project Page: https://saqibjaved1.github.io/MQAT_",
    "checked": true,
    "id": "bf3c2fab011803e42f83592723c0599215bd05a3",
    "semantic_title": "modular quantization-aware training for 6d object pose estimation",
    "citation_count": 0,
    "authors": [
      "Saqib Javed",
      "Chengkun Li",
      "Andrew Lawrence Price",
      "Yinlin Hu",
      "Mathieu Salzmann"
    ]
  },
  "https://openreview.net/forum?id=NxhXtkPYsk": {
    "title": "SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer",
    "volume": "main",
    "abstract": "Existing data augmentation in self-supervised learning, while diverse, fails to preserve the inherent structure of natural images. This results in distorted augmented samples with compromised semantic information, ultimately impacting downstream performance. To overcome this limitation, we propose SASSL: Style Augmentations for Self Supervised Learning, a novel data augmentation technique based on Neural Style Transfer. SASSL decouples semantic and stylistic attributes in images and applies transformations exclusively to their style while preserving content, generating diverse samples that better retain semantic information. SASSL boosts top-1 image classification accuracy on ImageNet by up to 2 percentage points compared to established self-supervised methods like MoCo, SimCLR, and BYOL, while achieving superior transfer learning performance across various datasets. Because SASSL can be performed asynchronously as part of the data augmentation pipeline, these performance impacts can be obtained with no change in pretraining throughput",
    "checked": true,
    "id": "f5ec5651a3c6e44db3ef8a24d77206693456bcbb",
    "semantic_title": "sassl: enhancing self-supervised learning via neural style transfer",
    "citation_count": 1,
    "authors": [
      "Renan A. Rojas-Gomez",
      "Karan Singhal",
      "Ali Etemad",
      "Alex Bijamov",
      "Warren Richard Morningstar",
      "Philip Andrew Mansfield"
    ]
  },
  "https://openreview.net/forum?id=rx1QNhsNsK": {
    "title": "Analyzing the Impact of Learnable Softmax Temperature in Contrastive Visual-Textual Alignment Systems: Benefits, Drawbacks, and Alternative Approaches",
    "volume": "main",
    "abstract": "This work does NOT read like \"fabricate motivation - propose something - obtain sota results\". Instead, we provide an in-depth analysis of the learnable softmax temperature parameter in the practical training of contrastive visual-textual alignment models, commonly known as CLIP models. This parameter is critical for optimal system performance, yet its mechanism and potential drawbacks have been largely overlooked. Our study addresses this gap and proposes a novel solution by utilizing the architecture of Vision Transformers (ViTs). We focus on the crucial role of the softmax temperature in managing noisy training data. We demonstrate that there is a balance in the gradient of the contrastive loss, with the temperature parameter acting as a distance scaling factor. If not properly calibrated, the model struggles to align positive pairs due to numerical issues in the loss term. Conversely, a high temperature can lead to unstable learning dynamics. We explore alternative approaches to mitigate this problem from a topological perspective of the contrastive loss. Ultimately, we leverage multiple class tokens embedded within the transformer architecture to present a concise solution. This configuration significantly enhances zero-shot classification performance, improving baseline CLIP models pretrained on large-scale datasets by an average of 6.1%",
    "checked": true,
    "id": "f94be067339ec5fc90a48fb07458af070d55d395",
    "semantic_title": "analyzing the impact of learnable softmax temperature in contrastive visual-textual alignment systems: benefits, drawbacks, and alternative approaches",
    "citation_count": 0,
    "authors": [
      "Zhun Sun",
      "Chao Li"
    ]
  },
  "https://openreview.net/forum?id=d6kqUKzG3V": {
    "title": "Sparsifying Bayesian neural networks with latent binary variables and normalizing flows",
    "volume": "main",
    "abstract": "Artificial neural networks are powerful machine learning methods used in many modern applications. A common issue is that they have millions or billions of parameters, and therefore tend to overfit. Bayesian neural networks (BNN) can improve on this since they incorporate parameter uncertainty. Latent binary Bayesian neural networks (LBBNN) further take into account structural uncertainty by allowing the weights to be turned on or off, enabling inference in the joint space of weights and structures. Mean-field variational inference is typically used for computation within such models. In this paper, we will consider two extensions of variational inference for the LBBNN: Firstly, by using the local reparametrization trick (LCRT), we improve computational efficiency. Secondly, and more importantly, by using normalizing flows on the variational posterior distribution of the LBBNN parameters, we learn a more flexible variational posterior than the mean field Gaussian. Experimental results on real data show that this improves predictive power compared to using mean field variational inference on the LBBNN method, while also obtaining sparser networks. We also perform two simulation studies. In the first, we consider variable selection in a logistic regression setting, where the more flexible variational distribution improves results. In the second study, we compare predictive uncertainty based on data generated from two-dimensional Gaussian distributions. Here, we argue that our Bayesian methods lead to more realistic estimates of predictive uncertainty",
    "checked": true,
    "id": "bc9f777afde9e903c7cf918b6d4b1b0ac11673e7",
    "semantic_title": "sparsifying bayesian neural networks with latent binary variables and normalizing flows",
    "citation_count": 3,
    "authors": [
      "Lars Skaaret-Lund",
      "Geir Storvik",
      "Aliaksandr Hubin"
    ]
  },
  "https://openreview.net/forum?id=1SCptTFtmV": {
    "title": "Interpreting CLIP: Insights on the Robustness to ImageNet Distribution Shifts",
    "volume": "main",
    "abstract": "What distinguishes robust models from non-robust ones? While for ImageNet distribution shifts it has been shown that such differences in robustness can be traced back predominantly to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 16 robust zero-shot CLIP vision encoders with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp), and comparing them to the representation spaces of less robust models with identical backbones, but different (pre)training sets or objectives (CLIP pretraining on ImageNet-Captions, and supervised training or finetuning on ImageNet). Through this analysis, we generate three novel insights. Firstly, we detect the presence of outlier features in robust zero-shot CLIP vision encoders, which to the best of our knowledge is the first time these are observed in non-language and non-transformer models. Secondly, we find the existence of outlier features to be an indication of ImageNet shift robustness in models, since we only find them in robust models in our analysis. Lastly, we also investigate the number of unique encoded concepts in the representation space and find zero-shot CLIP models to encode a higher number of unique concepts in their representation space. However, we do not find this to be an indicator of ImageNet shift robustness and hypothesize that it is rather related to the language supervision",
    "checked": true,
    "id": "fa3766d093185892c6617d962c337709c4c065ab",
    "semantic_title": "interpreting clip: insights on the robustness to imagenet distribution shifts",
    "citation_count": 2,
    "authors": [
      "Jonathan CrabbÃ©",
      "Pau Rodriguez",
      "Vaishaal Shankar",
      "Luca Zappella",
      "Arno Blaas"
    ]
  },
  "https://openreview.net/forum?id=MH7xfUWHfP": {
    "title": "Class-Discriminative Attention Maps for Vision Transformers",
    "volume": "main",
    "abstract": "Importance estimators are explainability methods that quantify feature importance for deep neural networks (DNN). In vision transformers (ViT), the self-attention mechanism naturally leads to attention maps, which are sometimes interpreted as importance scores that indicate which input features ViT models are focusing on. However, attention maps do not account for signals from downstream tasks. To generate explanations that are sensitive to downstream tasks, we have developed class-discriminative attention maps (CDAM), a gradient-based extension that estimates feature importance with respect to a known class or a latent concept. CDAM scales attention scores by how relevant the corresponding tokens are for the predictions of a classifier head. In addition to targeting the supervised classifier, CDAM can explain an arbitrary concept shared by selected samples by measuring similarity in the latent space of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which average a series of CDAMs with slightly altered tokens. Our quantitative benchmarks include correctness, compactness, and class sensitivity, in comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated CDAM excel across all three benchmarks. In particular, our results suggest that existing importance estimators may not provide sufficient class-sensitivity. We demonstrate the utility of CDAM in medical images by training and explaining malignancy and biomarker prediction models based on lung Computed Tomography (CT) scans. Overall, CDAM is shown to be highly class-discriminative and semantically relevant, while providing compact explanations",
    "checked": true,
    "id": "a8770ebc716005551cc7d860ec78d6551a00145d",
    "semantic_title": "class-discriminative attention maps for vision transformers",
    "citation_count": 4,
    "authors": [
      "Lennart Brocki",
      "Jakub Binda",
      "Neo Christopher Chung"
    ]
  },
  "https://openreview.net/forum?id=ojWtq4n7Ag": {
    "title": "Beyond Text: Utilizing Vocal Cues to Improve Decision Making in LLMs for Robot Navigation Tasks",
    "volume": "main",
    "abstract": "While LLMs excel in processing text in these human conversations, they struggle with the nuances of verbal instructions in scenarios like social navigation, where ambiguity and uncertainty can erode trust in robotic and other AI systems. We can address this shortcoming by moving beyond text and additionally focusing on the paralinguistic features of these audio responses. These features are the aspects of spoken communication that do not involve the literal wording (lexical content) but convey meaning and nuance through how something is said. We present ``Beyond Text''; an approach that improves LLM decision-making by integrating audio transcription along with a subsection of these features, which focus on the affect and more relevant in human-robot conversations. This approach not only achieves a 70.26% winning rate, outperforming existing LLMs by 22.16% to 48.30% (gemini-1.5-pro and gpt-3.5 respectively), but also enhances robustness against token manipulation adversarial attacks, highlighted by a 22.44% less decrease ratio than the text-only language model in winning rate. We also present the first dataset on disfluent human audio-guided instructions for future research in this field. ``Beyond Text'' marks an advancement in social robot navigation and broader Human-Robot interactions, seamlessly integrating text-based guidance with human-audio-informed language models",
    "checked": true,
    "id": "56f87a532e2d5b90e6dc2c48da21fbbacefd4c6e",
    "semantic_title": "beyond text: utilizing vocal cues to improve decision making in llms for robot navigation tasks",
    "citation_count": 5,
    "authors": [
      "Xingpeng Sun",
      "Haoming Meng",
      "Souradip Chakraborty",
      "Amrit Bedi",
      "Aniket Bera"
    ]
  },
  "https://openreview.net/forum?id=HCMDtc0ZhV": {
    "title": "Efficient Model-Agnostic Multi-Group Equivariant Networks",
    "volume": "main",
    "abstract": "Constructing model-agnostic group equivariant networks, such as equitune (Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be computationally expensive for large product groups. We address this problem by providing efficient model-agnostic equivariant designs for two related problems: one where the network has multiple inputs each with potentially different groups acting on them, and another where there is a single input but the group acting on it is a large product group. For the first design, we initially consider a linear model and characterize the entire equivariant space that satisfies this constraint. This characterization gives rise to a novel fusion layer between different channels that satisfies an invariance-symmetry (IS) constraint, which we call an IS layer. We then extend this design beyond linear models, similar to equitune, consisting of equivariant and IS layers. We also show that the IS layer is a universal approximator of invariant-symmetric functions. Inspired by the first design, we use the notion of the IS property to design a second efficient model-agnostic equivariant design for large product groups acting on a single input. For the first design, we provide experiments on multi-image classification where each view is transformed independently with transformations such as rotations. We find equivariant models are robust to such transformations and perform competitively otherwise. For the second design, we consider three applications: language compositionality on the SCAN dataset to product groups; fairness in natural language generation from GPT-2 to address intersectionality; and robust zero-shot image classification with CLIP. Overall, our methods are simple and general, competitive with equitune and its variants, while also being computationally more efficient",
    "checked": true,
    "id": "e6304e2377f787af4b35fb74ca9ad8c58090f408",
    "semantic_title": "efficient model-agnostic multi-group equivariant networks",
    "citation_count": 1,
    "authors": [
      "Razan Baltaji",
      "Sourya Basu",
      "Lav R. Varshney"
    ]
  },
  "https://openreview.net/forum?id=k98ZDblyhN": {
    "title": "Incorporating Inductive Biases to Energy-based Generative Models",
    "volume": "main",
    "abstract": "With the advent of score-matching techniques for model training and Langevin dynamics for sample generation, energy-based models (EBMs) have gained renewed interest as generative models. Recent EBMs usually use neural networks to define their energy functions. In this work, we introduce a novel hybrid approach that combines an EBM with an exponential family model to incorporate inductive bias into data modeling. Specifically, we augment the energy term with a parameter-free statistic function to help the model capture key data statistics. Like an exponential family model, the hybrid model aims to align the distribution statistics with data statistics during model training, even when it only approximately maximizes the data likelihood. This property enables us to impose constraints on the hybrid model. Our empirical study validates the hybrid model's ability to match statistics. Furthermore, experimental results show that data fitting and generation improve when suitable informative statistics are incorporated into the hybrid model",
    "checked": false,
    "id": "2660ab4d5e035ee0ceb4f47e38d2920b02060bf2",
    "semantic_title": "boosting weather forecast via generative superensemble",
    "citation_count": 1,
    "authors": [
      "Yukun Li",
      "Liping Liu"
    ]
  },
  "https://openreview.net/forum?id=h4rUKKfl5S": {
    "title": "SelfXit: An Unsupervised Early Exit Mechanism for Deep Neural Networks",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) have become an essential component in many application domains, including web-based services. A variety of these services require high throughput and (close to) real-time features, for instance, to respond or react to users' requests or to process a stream of incoming data on time. However, the trend in DNN design is towards larger models with many layers and parameters to achieve more accurate results. Although these models are often pre-trained, the computational complexity in such large models can still be relatively significant, hindering low inference latency. In this paper, we propose SelfXit, an end-to-end automated early exiting solution to improve the performance of DNN-based vision services in terms of computational complexity and inference latency. SelfXit adopts the ideas of self-distillation of DNN models and early exits specifically for vision applications. The proposed solution is an automated unsupervised early exiting mechanism that allows early exiting of a large model during inference time if the early exit model in one of the early exits is confident enough for final prediction. One of the main contributions of this paper is that we have implemented the idea as an unsupervised early exiting, meaning that the early exit models do not need access to training data and perform solely based on the incoming data at run-time, making it suitable for applications using pre-trained models. The results of our experiments on two vision tasks (image classification and object detection) show that, on average, early exiting can reduce the computational complexity of these services up to 58% (in terms of FLOP count) and improve their inference latency up to 46% with a low to zero reduction in accuracy. SelfXit also outperforms existing methods, particularly on complex models and larger datasets. It achieves a notable reduction in latency of 51.6% and 30.4% on CIFAR100/Resnet50, with an accompanying increase in accuracy of 2.31% and 0.72\\%, on average, compared to GATI and BranchyNet",
    "checked": true,
    "id": "5d90fd822bde7f8c6453d10277a65472632934d0",
    "semantic_title": "selfxit: an unsupervised early exit mechanism for deep neural networks",
    "citation_count": 0,
    "authors": [
      "Hossein KhademSohi",
      "Mohammadamin Abedi",
      "Yani Ioannou",
      "Steve Drew",
      "Pooyan Jamshidi",
      "Hadi Hemmati"
    ]
  },
  "https://openreview.net/forum?id=yqT7eBz1VJ": {
    "title": "PerSEval: Assessing Personalization in Text Summarizers",
    "volume": "main",
    "abstract": "Personalized summarization models cater to individuals' subjective understanding of saliency, as represented by their reading history and current topics of attention. Existing personalized text summarizers are primarily evaluated based on accuracy measures such as BLEU, ROUGE, and METEOR. However, a recent study argued that accuracy measures are inadequate for evaluating the $\\textit{degree of personalization}$ of these models and proposed EGISES, the first metric to evaluate personalized text summaries. It was suggested that accuracy is a separate aspect and should be evaluated standalone. In this paper, we challenge the necessity of an accuracy leaderboard, suggesting that relying on accuracy-based aggregated results might lead to misleading conclusions. To support this, we delve deeper into EGISES, demonstrating both theoretically and empirically that it measures the $\\textit{degree of responsiveness}$, a necessary but not sufficient condition for degree-of-personalization. We subsequently propose PerSEval, a novel measure that satisfies the required sufficiency condition. Based on the benchmarking of ten SOTA summarization models on the PENS dataset, we empirically establish that -- (i) PerSEval is reliable w.r.t human-judgment correlation (Pearson's $r$ = 0.73; Spearman's $\\rho$ = 0.62; Kendall's $\\tau$ = 0.42), (ii) PerSEval has high rank-stability, (iii) PerSEval as a rank-measure is not entailed by EGISES-based ranking, and (iv) PerSEval can be a standalone rank-measure without the need of any aggregated ranking",
    "checked": true,
    "id": "4ec099ffcacfcaa84590030a9b6fd6ad3d0133bd",
    "semantic_title": "perseval: assessing personalization in text summarizers",
    "citation_count": 1,
    "authors": [
      "Sourish Dasgupta",
      "Ankush Chander",
      "Tanmoy Chakraborty",
      "Parth Borad",
      "Isha Motiyani"
    ]
  },
  "https://openreview.net/forum?id=GDn6z9LIDs": {
    "title": "Learning Unlabeled Clients Divergence for Federated Semi-Supervised Learning via Anchor Model Aggregation",
    "volume": "main",
    "abstract": "Federated semi-supervised learning (FedSemi) refers to scenarios where there may be clients with fully labeled data, clients with partially labeled, and even fully unlabeled clients while preserving data privacy. However, challenges arise from client drift due to undefined heterogeneous class distributions and erroneous pseudo-labels. Existing FedSemi methods typically fail to aggregate models from unlabeled clients due to their inherent unreliability, thus overlooking unique information from their heterogeneous data distribution, leading to sub-optimal results. In this paper, we enable unlabeled client aggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federated Aggregation. SemiAnAgg learns unlabeled client contributions via an anchor model, effectively harnessing their informative value. Our key idea is that by feeding local client data to the same global model and the same consistently initialized anchor model (i.e., random model), we can measure the importance of each unlabeled client accordingly. Extensive experiments demonstrate that SemiAnAgg achieves new state-of-the-art results on four widely used FedSemi benchmarks, leading to substantial performance improvements: a 9% increase in accuracy on CIFAR-100 and a 7.6% improvement in recall on the medical dataset ISIC-18, compared with prior state-of-the-art. Code is available at: https://github.com/xmed-lab/SemiAnAgg",
    "checked": true,
    "id": "ca7b389838f1a25d11775cb3b70f8d1d413f7f88",
    "semantic_title": "learning unlabeled clients divergence for federated semi-supervised learning via anchor model aggregation",
    "citation_count": 0,
    "authors": [
      "Marawan Elbatel",
      "Hualiang Wang",
      "Jixiang CHEN",
      "Hao Wang",
      "Xiaomeng Li"
    ]
  },
  "https://openreview.net/forum?id=U6bA2lhwVV": {
    "title": "Dependency Structure Search Bayesian Optimization for Decision Making Models",
    "volume": "main",
    "abstract": "Many approaches for optimizing decision making models rely on gradient based methods requiring informative feedback from the environment. However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance. Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making models. This problem is exacerbated if the model requires interactions between several agents cooperating to accomplish a shared goal. To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of agent interactions through the concept of role. We introduce Dependency Structure Search Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters, and show an improved regret bound. Our approach shows strong empirical results under malformed or sparse reward",
    "checked": true,
    "id": "0d25fed6841f9a555a70d8bf1d67e17dfdd39884",
    "semantic_title": "dependency structure search bayesian optimization for decision making models",
    "citation_count": 0,
    "authors": [
      "Mohit Rajpal",
      "Lac Gia Tran",
      "Yehong Zhang",
      "Bryan Kian Hsiang Low"
    ]
  },
  "https://openreview.net/forum?id=h48Ri6pmvi": {
    "title": "Let There be Direction in Hypergraph Neural Networks",
    "volume": "main",
    "abstract": "Hypergraphs are a powerful abstraction for modeling high-order interactions between a set of entities of interest and have been attracting a growing interest in the graph-learning literature. In particular, directed hypegraphs are crucial in their capability of representing real-world phenomena involving group relations where two sets of elements affect one another in an asymmetric way. Despite such a vast potential, an established solution to tackle graph-learning tasks on directed hypergraphs is still lacking. For this reason, in this paper we introduce the Generalized Directed Hypergraph Neural Network (GeDi-HNN), the first spectral-based Hypergraph Neural Network (HNN) capable of seamlessly handling hypergraphs with both directed and undirected hyperedges. GeDi-HNN relies on a graph-convolution operator which is built on top of the Generalized Directed Laplacian} $\\vec{L}_N$, a novel complex-valued Hermitian matrix which we introduce in this paper. We prove that $\\vec L_N$ generalizes many previously-proposed Laplacian matrices to directed hypergraphs while enjoying several desirable spectral properties. Extensive computational experiments against state-of-the-art methods on real-world and synthetically-generated datasets demonstrate the efficacy of our proposed HNN. Thanks to effectively leveraging the directional information contained in these datasets, GeDi-HNN achieves a relative-percentage-difference improvement of 7% on average (with a maximum improvement of 23.19%) on the real-world datasets and of 65.3% on average on the synthetic ones",
    "checked": true,
    "id": "44bc6b4b1c998facc3392176c1773252b10d3ded",
    "semantic_title": "let there be direction in hypergraph neural networks",
    "citation_count": 2,
    "authors": [
      "Stefano Fiorini",
      "Stefano Coniglio",
      "Michele Ciavotta",
      "Alessio Del Bue"
    ]
  },
  "https://openreview.net/forum?id=CNJIpI4Gb9": {
    "title": "Deep Kernel Learning of Nonlinear Latent Force Models",
    "volume": "main",
    "abstract": "Scientific processes are often modelled by sets of differential equations. As datasets grow, individually fitting these models and quantifying their uncertainties becomes a computationally challenging task. Latent force models offer a mathematically-grounded balance between data-driven and mechanistic inference in such dynamical systems, whilst accounting for stochasticity in observations and parameters. However, the required derivation and computation of the posterior kernel terms over a low-dimensional latent force is rarely tractable, requiring approximations for complex scenarios such as nonlinear dynamics. In this paper, we overcome this issue by posing the problem as learning the solution operator itself to a class of latent force models, thereby improving the scalability of these models. This is achieved by employing a deep kernel along with a meta-learned embedding of the output functions. Finally, we demonstrate the ability to extrapolate a solution operator trained on simulations to real experimental datasets, as well as scaling to large datasets",
    "checked": true,
    "id": "943f5fb300d9478b1c160a9e3b0fdae73c0096ae",
    "semantic_title": "deep kernel learning of nonlinear latent force models",
    "citation_count": 0,
    "authors": [
      "Jacob Moss",
      "Jeremy England",
      "Pietro Lio"
    ]
  },
  "https://openreview.net/forum?id=auLdS1iuKW": {
    "title": "Locally Adaptive Federated Learning",
    "volume": "main",
    "abstract": "Federated learning is a paradigm of distributed machine learning in which multiple clients coordinate with a central server to learn a model, without sharing their own training data. Standard federated optimization methods such as Federated Averaging (FedAvg) ensure balance among the clients by using the same stepsize for local updates on all clients. However, this means that all clients need to respect the global geometry of the function which could yield slow convergence. In this work, we propose locally adaptive federated learning algorithms, that leverage the local geometric information for each client function. We show that such locally adaptive methods with uncoordinated stepsizes across all clients can be particularly efficient in interpolated (overparameterized) settings, and analyze their convergence in the presence of heterogeneous data for convex and strongly convex settings. We validate our theoretical claims by performing illustrative experiments for both i.i.d. non-i.i.d. cases. Our proposed algorithms match the optimization performance of tuned FedAvg in the convex setting, outperform FedAvg as well as state-of-the-art adaptive federated algorithms like FedAMS for non-convex experiments, and come with superior generalization performance",
    "checked": true,
    "id": "cbe1e307a1b6e7d38c5a3d8236b731a4b4b7bd03",
    "semantic_title": "locally adaptive federated learning",
    "citation_count": 2,
    "authors": [
      "Sohom Mukherjee",
      "Nicolas Loizou",
      "Sebastian U Stich"
    ]
  },
  "https://openreview.net/forum?id=82bNZGMNZa": {
    "title": "Learning under Imitative Strategic Behavior with Unforeseeable Outcomes",
    "volume": "main",
    "abstract": "Machine learning systems have been widely used to make decisions about individuals who may best respond and behave strategically to receive favorable outcomes, e.g., they may genuinely improve the true labels or manipulate observable features directly to game the system without changing labels. Although both behaviors have been studied (often as two separate problems) in the literature, most works assume individuals can (i) perfectly foresee the outcomes of their behaviors when they best respond; (ii) change their features arbitrarily as long as it is affordable, and the costs they need to pay are deterministic functions of feature changes. In this paper, we consider a different setting and focus on imitative strategic behaviors with unforeseeable outcomes, i.e., individuals manipulate/improve by imitating the features of those with positive labels, but the induced feature changes are unforeseeable. We first propose a Stackelberg game to model the interplay between individuals and the decision-maker, under which we examine how the decision-maker's ability to anticipate individual behavior affects its objective function and the individual's best response. We show that the objective difference between the two can be decomposed into three interpretable terms, with each representing the decision-maker's preference for a certain behavior. By exploring the roles of each term, we further illustrate how a decision-maker with adjusted preferences can simultaneously disincentivize manipulation, incentivize improvement, and promote fairness",
    "checked": true,
    "id": "35e21431dbdb38c43bafa5fe832823eaa058e5c0",
    "semantic_title": "learning under imitative strategic behavior with unforeseeable outcomes",
    "citation_count": 3,
    "authors": [
      "Tian Xie",
      "Zhiqun Zuo",
      "Mohammad Mahdi Khalili",
      "Xueru Zhang"
    ]
  },
  "https://openreview.net/forum?id=B80WUNhTAw": {
    "title": "KD-BIRL: Kernel Density Bayesian Inverse Reinforcement Learning",
    "volume": "main",
    "abstract": "Inverse reinforcement learning (IRL) methods infer an agent's reward function using demonstrations of expert behavior. A Bayesian IRL approach models a distribution over candidate reward functions, capturing a degree of uncertainty in the inferred reward function. This is critical in some applications, such as those involving clinical data. Typically, Bayesian IRL algorithms require large demonstration datasets to ensure posterior concentration, which may not be available in practice. In this work, we incorporate existing domain-specific data to achieve better posterior concentration rates. We study a common setting in clinical and biological applications where we have access to expert demonstrations and known reward functions for a set of training tasks. Our aim is to learn the reward function of a new test task given limited expert demonstrations. Existing Bayesian IRL methods impose restrictions on the form of input data, thus limiting the incorporation of training task data. To better leverage information from training tasks, we introduce kernel density Bayesian inverse reinforcement learning (KD-BIRL). Our approach employs a conditional kernel density estimator, which uses the known reward functions of the training tasks to improve the likelihood estimation across a range of reward functions and demonstration samples. Our empirical results highlight KD-BIRL's faster concentration rate in comparison to baselines, particularly in low test task expert demonstration data regimes. Additionally, we are the first to provide theoretical guarantees of posterior concentration for a Bayesian IRL algorithm. Taken together, this work introduces a principled and theoretically grounded framework that enables Bayesian IRL to be applied across a variety of domains, especially those with limited expert demonstration datasets",
    "checked": false,
    "id": "b11096cb11fb3263b68de4c7c5998f621e54657b",
    "semantic_title": "kernel density bayesian inverse reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Aishwarya Mandyam",
      "Didong Li",
      "Andrew Jones",
      "Diana Cai",
      "Barbara E Engelhardt"
    ]
  },
  "https://openreview.net/forum?id=dce6ZGkJ1Z": {
    "title": "Offline Deep Reinforcement Learning for Visual Distractions via Domain Adversarial Training",
    "volume": "main",
    "abstract": "Recent advances in offline reinforcement learning (RL) have relied predominantly on learning from proprioceptive states. However, obtaining proprioceptive states for all objects may not always be feasible, particularly in offline settings. Therefore, RL agents must be capable of learning from raw sensor inputs such as images. However, recent studies have indicated that visual distractions can impair the performance of RL agents when observations in the evaluation environment differ significantly from those in the training environment. This issue is even more crucial in the visual offline RL paradigm, where the collected datasets can differ drastically from the testing environment. In this work, we investigated an adversarial-based algorithm to address the problem of visual distraction in offline RL settings. Our adversarial approach involves training agents to learn features that are more robust against visual distractions. Furthermore, we proposed a complementary dataset to add to the V-D4RL distraction dataset by extending it to more locomotion tasks. We empirically demonstrate that our method surpasses state-of-the-art baselines in tasks on both the VD4RL and proposed dataset when evaluated on random visual distractions",
    "checked": true,
    "id": "5dfea187e225888a8815c518501fbc5520629a84",
    "semantic_title": "offline deep reinforcement learning for visual distractions via domain adversarial training",
    "citation_count": 0,
    "authors": [
      "Jen-Yen Chang",
      "Thomas Westfechtel",
      "Takayuki Osa",
      "Tatsuya Harada"
    ]
  },
  "https://openreview.net/forum?id=4On0PLRI8H": {
    "title": "Self-supervised Color Generalization in Reinforcement Learning",
    "volume": "main",
    "abstract": "A challenge in reinforcement learning lies in effectively deploying trained policies to handle out-of-distribution data and environmental variations. Agents observing pixel-based image data are generally sensitive to background distractions and color changes. Commonly, color generalization is achieved through data augmentation. In contrast, we propose a color-invariant neural network layer that adopts distinct color symmetries in a self-supervised fashion. This allows for color sensitivity while achieving generalization. Our approach is based on dynamic-mode decomposition, which also accommodates spatial and temporal symmetries; we discuss the controlled breaking of the latter. We empirically evaluate our method in the Minigrid, Procgen, and DeepMind Control suites and find improved color sensitivity and generalisation",
    "checked": true,
    "id": "34a0de98fcefc94c4322132d26c82aa470def09b",
    "semantic_title": "self-supervised color generalization in reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Matthias Weissenbacher",
      "Evangelos Routis",
      "Yoshinobu Kawahara"
    ]
  },
  "https://openreview.net/forum?id=EcuwtinFs9": {
    "title": "Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection",
    "volume": "main",
    "abstract": "Likelihood-based deep generative models such as score-based diffusion models and variational autoencoders are state-of-the-art machine learning models approximating high-dimensional distributions of data such as images, text, or audio. One of many downstream tasks they can be naturally applied to is out-of-distribution (OOD) detection. However, seminal work by Nalisnick et al. which we reproduce showed that deep generative models consistently infer higher log-likelihoods for OOD data than data they were trained on, marking an open problem. In this work, we analyse using the gradient of a data point with respect to the parameters of the deep generative model for OOD detection, based on the simple intuition that OOD data should have larger gradient norms than training data. We formalise measuring the size of the gradient as approximating the Fisher information metric. We show that the Fisher information matrix (FIM) has large absolute diagonal values, motivating the use of chi-square distributed, layer-wise gradient norms as features. We combine these features to make a simple, model-agnostic and hyperparameter-free method for OOD detection which estimates the joint density of the layer-wise gradient norms for a given data point. We find that these layer-wise gradient norms are weakly correlated, rendering their combined usage informative, and prove that the layer-wise gradient norms satisfy the principle of (data representation) invariance. Our empirical results indicate that this method outperforms the Typicality test for most deep generative models and image dataset pairings",
    "checked": true,
    "id": "dc84b09e6605a98f0b7bfa4d5473340db0e8c6f7",
    "semantic_title": "approximations to the fisher information metric of deep generative models for out-of-distribution detection",
    "citation_count": 0,
    "authors": [
      "Sam Dauncey",
      "Christopher C. Holmes",
      "Christopher Williams",
      "Fabian Falck"
    ]
  },
  "https://openreview.net/forum?id=fq6aQoMSHz": {
    "title": "Undetectable Steganography for Language Models",
    "volume": "main",
    "abstract": "We introduce a cryptographic method to hide an arbitrary secret payload in the response of a Large Language Model (LLM). A secret key is required to extract the payload from the model's response, and without the key it is provably impossible to distinguish between the responses of the original LLM and the LLM that hides a payload. In particular, the quality of generated text is not affected by the payload. Our approach extends a recent result of Christ, Gunn and Zamir (2023) who introduced an undetectable watermarking scheme for LLMs",
    "checked": true,
    "id": "2c1f043a1fc47e78afd3acd883301bfb8196bf49",
    "semantic_title": "undetectable steganography for language models",
    "citation_count": 1,
    "authors": [
      "Or Zamir"
    ]
  },
  "https://openreview.net/forum?id=0q4zjGMKoA": {
    "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
    "volume": "main",
    "abstract": "Large-scale graphs with node attributes are increasingly common in various real-world applications. Creating synthetic, attribute-rich graphs that mirror real-world examples is crucial, especially for sharing graph data for analysis and developing learning models when original data is restricted to be shared. Traditional graph generation methods are limited in their capacity to handle these complex structures. Recent advances in diffusion models have shown potential in generating graph structures without attributes and smaller molecular graphs. However, these models face challenges in generating large attributed graphs due to the complex attribute-structure correlations and the large size of these graphs. This paper introduces a novel diffusion model, GraphMaker, specifically designed for generating large attributed graphs. We explore various combinations of node attribute and graph structure generation processes, finding that an asynchronous approach more effectively captures the intricate attribute-structure correlations. We also address scalability issues through edge mini-batching generation. To demonstrate the practicality of our approach in graph data dissemination, we introduce a new evaluation pipeline. The evaluation demonstrates that synthetic graphs generated by GraphMaker can be used to develop competitive graph machine learning models for the tasks defined over the original graphs without actually accessing these graphs, while many leading graph generation methods fall short in this evaluation",
    "checked": true,
    "id": "6630a76da223c24ac6cf7b9e1fdfdc2b103793c6",
    "semantic_title": "graphmaker: can diffusion models generate large attributed graphs?",
    "citation_count": 9,
    "authors": [
      "Mufei Li",
      "Eleonora Kreacic",
      "Vamsi K. Potluru",
      "Pan Li"
    ]
  },
  "https://openreview.net/forum?id=BOq3n5ewSP": {
    "title": "AGG: Amortized Generative 3D Gaussians for Single Image to 3D",
    "volume": "main",
    "abstract": "Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image. Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation. 3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps. To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization. Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization. Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module. Our method is evaluated against existing sampling-based 3D Gaussian frameworks and inference-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster",
    "checked": true,
    "id": "ac1c6ed84bdbe6d592ce594b1e4a2e0e1118bda9",
    "semantic_title": "agg: amortized generative 3d gaussians for single image to 3d",
    "citation_count": 45,
    "authors": [
      "Dejia Xu",
      "Ye Yuan",
      "Morteza Mardani",
      "Sifei Liu",
      "Jiaming Song",
      "Zhangyang Wang",
      "Arash Vahdat"
    ]
  },
  "https://openreview.net/forum?id=bgzUSZ8aeg": {
    "title": "More Agents Is All You Need",
    "volume": "main",
    "abstract": "We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method, termed as Agent Forest, is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: https://github.com/MoreAgentsIsAllYouNeed/AgentForest",
    "checked": true,
    "id": "6d8efe141ead5e397ca9a49814d049290292e974",
    "semantic_title": "more agents is all you need",
    "citation_count": 73,
    "authors": [
      "junyou li",
      "Qin Zhang",
      "Yangbin Yu",
      "QIANG FU",
      "Deheng Ye"
    ]
  },
  "https://openreview.net/forum?id=17Ld3davzF": {
    "title": "Certified Robustness against Sparse Adversarial Perturbations via Data Localization",
    "volume": "main",
    "abstract": "Recent work in adversarial robustness suggests that natural data distributions are localized, i.e., they place high probability in small volume regions of the input space, and that this property can be utilized for designing classifiers with improved robustness guarantees for $\\ell_2$-bounded perturbations. Yet, it is still unclear if this observation holds true for more general metrics. In this work, we extend this theory to $\\ell_0$-bounded adversarial perturbations, where the attacker can modify a few pixels of the image but is unrestricted in the magnitude of perturbation, and we show necessary and sufficient conditions for the existence of $\\ell_0$-robust classifiers. Theoretical certification approaches in this regime essentially employ voting over a large ensemble of classifiers. Such procedures are combinatorial and expensive or require complicated certification techniques. In contrast, a simple classifier emerges from our theory, dubbed Box-NN, which naturally incorporates the geometry of the problem and improves upon the current state-of-the-art in certified robustness against sparse attacks for the MNIST and Fashion-MNIST datasets",
    "checked": true,
    "id": "846e9be09a279cff584af20e7b0113c8bcb9cf9e",
    "semantic_title": "certified robustness against sparse adversarial perturbations via data localization",
    "citation_count": 0,
    "authors": [
      "Ambar Pal",
      "Rene Vidal",
      "Jeremias Sulam"
    ]
  },
  "https://openreview.net/forum?id=s5lEUtyVly": {
    "title": "Faster optimal univariate microaggregation",
    "volume": "main",
    "abstract": "Microaggregation is a method to coarsen a dataset, by optimally clustering data points in groups of at least k points, thereby providing a $k$-anonymity type disclosure guarantee for each point in the dataset. Previous algorithms for univariate microaggregation had a $O(kn)$ time complexity. By rephrasing microaggregation as an instance of the concave least weight subsequence problem, in this work we provide improved algorithms that provide an optimal univariate microaggregation on sorted data in $O(n)$ time and space. We further show that our algorithms work not only for sum of squares cost functions, as typically considered, but seamlessly extend to many other cost functions used for univariate microaggregation tasks. In experiments we show that the presented algorithms lead to performance improvements on real hardware",
    "checked": true,
    "id": "45a1b5ffbe48fd360afcb1e470d107c95113e188",
    "semantic_title": "faster optimal univariate microaggregation",
    "citation_count": 0,
    "authors": [
      "Felix I. Stamm",
      "Michael T Schaub"
    ]
  },
  "https://openreview.net/forum?id=SgxeJW4DGk": {
    "title": "Mixture of Latent Experts Using Tensor Products",
    "volume": "main",
    "abstract": "In multi-task learning, the conventional approach involves training a model on multiple tasks simultaneously. However, the training signals from different tasks can interfere with one another, potentially leading to \\textit{negative transfer}. To mitigate this, we propose a novel \\textit{latent-expert} approach (\\texttt{TensorPoly}), that balances parameter efficiency with nuanced routing methods. For \\textit{experts}, we reparameterize Low-Rank Adaptation (\\texttt{LoRA}) by employing an entangled tensor through the use of tensor product operations and name the resulting approach \\texttt{TLoRA}. For \\textit{routing function}, we tailor two innovative routing functions according to the granularity: \\texttt{TensorPoly-I} which directs to each rank within the entangled tensor while \\texttt{TensorPoly-II} offers a finer-grained routing approach targeting each order of the entangled tensor. The experimental results from the multi-task T0-benchmark demonstrate that: 1) all latent-expert approaches surpass the corresponding dense approaches, highlighting the potential of modular language models to mitigate negative inference in multi-task learning and deliver superior outcomes. 2) \\texttt{TensorPoly-I} achieves higher parameter efficiency in adaptation and outperforms other modular LMs, which shows the potential of our approach in multi-task transfer learning \\footnote{The code is released: \\url{https://github.com/microsoft/mttl}}",
    "checked": true,
    "id": "48c786655f7d5c7b3b65f96100aa8e9242e1653e",
    "semantic_title": "mixture of latent experts using tensor products",
    "citation_count": 3,
    "authors": [
      "Zhan Su",
      "Fengran Mo",
      "Prayag Tiwari",
      "Benyou Wang",
      "Qiuchi Li",
      "Jian-Yun Nie",
      "Jakob Grue Simonsen"
    ]
  },
  "https://openreview.net/forum?id=GpULi1dAMm": {
    "title": "Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models",
    "volume": "main",
    "abstract": "We address the long-standing problem of how to learn effective pixel-based image diffusion models at scale, introducing a remarkably simple greedy method for stable training of large-scale, high-resolution models. without the needs for cascaded super-resolution components.The key insight stems from careful pre-training of core components, namely, those responsible for text-to-image alignment vs. high resolution rendering. We first demonstrate the benefits of scaling a Shallow UNet, with no down(up)-sampling enc(dec)oder. Scaling its deep core layers is shown to improve alignment, object structure, and composition. Building on this core model, we propose a greedy algorithm that grows the architecture into high resolution end-to-end models, while preserving the integrity of the pre-trained representation,stabilizing training, and reducing the need for large high-resolution datasets. This enables a single stage model capable of generating high-resolution images without the need of a super-resolution cascade. Our key results rely on public datasets and show that we are able to train non-cascaded models up to 8B parameters with no further regularization schemes.Vermeer, our full pipeline model trained with internal datasets to produce 1024Ã1024 images, without cascades, is preferred by 44.0% vs. 21.4% human evaluators over SDXL",
    "checked": true,
    "id": "7fd0101f52699af7ca82e831723a36c8ae4e1025",
    "semantic_title": "greedy growing enables high-resolution pixel-based diffusion models",
    "citation_count": 3,
    "authors": [
      "Cristina Nader Vasconcelos",
      "Abdullah Rashwan",
      "Austin Waters",
      "Trevor Walker",
      "Keyang Xu",
      "Jimmy Yan",
      "Rui Qian",
      "Yeqing Li",
      "SHIXIN LUO",
      "Yasumasa Onoe",
      "Zarana Parekh",
      "Ivana Kajic",
      "Mandy Guo",
      "Wenlei Zhou",
      "Sarah Rosston",
      "Roopal Garg",
      "Hongliang Fei",
      "Jordi Pont-Tuset",
      "Su Wang",
      "Henna Nandwani",
      "Andrew Bunner",
      "Kevin Swersky",
      "David J. Fleet",
      "Oliver Wang",
      "Jason Michael Baldridge"
    ]
  },
  "https://openreview.net/forum?id=dmxMGW6J7N": {
    "title": "Selective Classification Under Distribution Shifts",
    "volume": "main",
    "abstract": "In selective classification (SC), a classifier abstains from making predictions that are likely to be wrong to avoid excessive errors. To deploy imperfect classifiers---imperfect either due to intrinsic statistical noise of data or for robustness issue of the classifier or beyond---in high-stakes scenarios, SC appears to be an attractive and necessary path to follow. Despite decades of research in SC, most previous SC methods still focus on the ideal statistical setting only, i.e., the data distribution at deployment is the same as that of training, although practical data can come from the wild. To bridge this gap, in this paper, we propose an SC framework that takes into account distribution shifts, termed generalized selective classification, that covers label-shifted (or out-of-distribution) and covariate-shifted samples, in addition to typical in-distribution samples, the first of its kind in the SC literature. We focus on non-training-based confidence-score functions for generalized SC on deep learning (DL) classifiers and propose two novel margin-based score functions. Through extensive analysis and experiments, we show that our proposed score functions are more effective and reliable than the existing ones for generalized SC on a variety of classification tasks and DL classifiers",
    "checked": true,
    "id": "856edb9732aed58ece6fca463cf3531116a0a6b8",
    "semantic_title": "selective classification under distribution shifts",
    "citation_count": 2,
    "authors": [
      "Hengyue Liang",
      "Le Peng",
      "Ju Sun"
    ]
  },
  "https://openreview.net/forum?id=TNKhDBV6PA": {
    "title": "A Distance-based Anomaly Detection Framework for Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "In deep reinforcement learning (RL) systems, abnormal states pose significant risks by potentially triggering unpredictable behaviors and unsafe actions, thus impeding the deployment of RL systems in real-world scenarios. It is crucial for reliable decision-making systems to have the capability to cast an alert whenever they encounter unfamiliar observations that they are not equipped to handle. In this paper, we propose a novel Mahalanobis distance-based (MD) anomaly detection framework, called \\textit{MDX}, for deep RL algorithms. MDX simultaneously addresses random, adversarial, and out-of-distribution (OOD) state outliers in both offline and online settings. It utilizes Mahalanobis distance within class-conditional distributions for each action and operates within a statistical hypothesis testing framework under the Gaussian assumption. We further extend it to robust and distribution-free versions by incorporating Robust MD and conformal inference techniques. Through extensive experiments on classical control environments, Atari games and autonomous driving scenarios, we demonstrate the effectiveness of our MD-based detection framework. MDX offers a simple, unified, and practical tool for enhancing the safety and reliability of RL systems in real-world applications",
    "checked": false,
    "id": "0e872b44bf1d3abd03f3c882cc0f14a6b8c9374e",
    "semantic_title": "a dynamic deep reinforcement learning-bayesian framework for anomaly detection",
    "citation_count": 24,
    "authors": [
      "Hongming Zhang",
      "Ke Sun",
      "bo xu",
      "Linglong Kong",
      "Martin MÃ¼ller"
    ]
  },
  "https://openreview.net/forum?id=fzP4qIiVIh": {
    "title": "Persona-aware Generative Model for Code-mixed Language",
    "volume": "main",
    "abstract": "Code-mixing and script-mixing are prevalent across online social networks and multilingual societies. However, a user's preference toward code-mixing depends on the socioeconomic status, demographics of the user, and the local context, which existing generative models tend to ignore while generating code-mixed texts. In this work, we make a pioneering attempt to develop a persona-aware generative model to generate texts resembling real-life code-mixed texts of individuals. We propose PARADOX, a persona-aware generative model for code-mixed text generation, which is a novel Transformer-based encoder-decoder model that encodes an utterance conditioned on a user's persona and generates code-mixed texts without monolingual reference data. We propose an alignment module that re-calibrates the generated sequence to resemble real-life code-mixed texts. PARADOX generates code-mixed texts that are semantically more meaningful and linguistically more valid. To evaluate the personification capabilities of PARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM KS. On average, PARADOX achieves $1.6$% better CM BLEU, $57$% better perplexity and $32$% better semantic coherence than the non-persona-based counterparts",
    "checked": true,
    "id": "3a0f3c7affd3ac0bf1f98c8c99537088e74a1724",
    "semantic_title": "persona-aware generative model for code-mixed language",
    "citation_count": 1,
    "authors": [
      "Ayan Sengupta",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ]
  },
  "https://openreview.net/forum?id=a7KP5uo0Fp": {
    "title": "The Trifecta: Three simple techniques for training deeper Forward-Forward networks",
    "volume": "main",
    "abstract": "Massive backpropagated models can outperform humans on a variety of tasks but suffer from high power consumption and poor generalisation. Local learning, which focuses on updating subsets of a model's parameters at a time, has emerged as a promising technique to address these issues. Recently, a novel local learning algorithm, called Forward-Forward, has received widespread attention due to its innovative approach to learning. Unfortunately, its application has been limited to smaller datasets due to scalability issues. To this end, we propose The Trifecta, a collection of three simple techniques that drastically improve the Forward-Forward algorithm on deeper networks. Our experiments demonstrate that our models are on par with similarly structured, backpropagation-based models in both training speed and test accuracy on simple datasets. Specifically, we achieve around 84\\% accuracy on CIFAR-10, a notable improvement (25%) over the original FF algorithm",
    "checked": true,
    "id": "4848795923963a3b197314c77880e2a3bd365c6b",
    "semantic_title": "the trifecta: three simple techniques for training deeper forward-forward networks",
    "citation_count": 4,
    "authors": [
      "Thomas Dooms",
      "Ing Jyh Tsang",
      "Jose Oramas"
    ]
  },
  "https://openreview.net/forum?id=MMjRBe4oKF": {
    "title": "Neural Likelihood Approximation for Integer Valued Time Series Data",
    "volume": "main",
    "abstract": "Stochastic processes defined on integer valued state spaces are popular within the physical and biological sciences. These models are necessary for capturing the dynamics of small systems where the individual nature of the populations cannot be ignored and stochastic effects are important. The inference of the parameters of such models, from time series data, is challenging due to intractability of the likelihood. To work at all, current simulation based inference methods require the generation of realisations of the model conditional on the data, which can be both tricky to implement and computationally expensive. In this paper we instead construct a neural likelihood approximation that can be trained using unconditional simulation of the underlying model, which is much simpler. We demonstrate our method by performing inference on a number of ecological and epidemiological models, showing that we can accurately approximate the true posterior while achieving significant computational speed ups compared to current best methods",
    "checked": true,
    "id": "84b02818d070985dcd646f0f7b64d35e197a3096",
    "semantic_title": "neural likelihood approximation for integer valued time series data",
    "citation_count": 0,
    "authors": [
      "Luke O'Loughlin",
      "Andrew J. Black",
      "John Maclean"
    ]
  },
  "https://openreview.net/forum?id=RHUKg8n9tw": {
    "title": "MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Model-based offline reinforcement learning methods (RL) have achieved state-of-the-art performance in many decision-making problems thanks to their sample efficiency and generalizability. Despite these advancements, existing model-based offline RL approaches either focus on theoretical studies without developing practical algorithms or rely on a restricted parametric policy space, thus not fully leveraging the advantages of an unrestricted policy space inherent to model-based methods. To address this limitation, we develop MoMA, a model-based mirror ascent algorithm with general function approximations under partial coverage of offline data. MoMA distinguishes itself from existing literature by employing an unrestricted policy class. In each iteration, MoMA conservatively estimates the value function by a minimization procedure within a confidence set of transition models in the policy evaluation step, then updates the policy with general function approximations instead of commonly-used parametric policy classes in the policy improvement step. Under some mild assumptions, we establish theoretical guarantees for MoMA by proving an upper bound on the suboptimality of the returned policy. We also provide a practically implementable, approximate version of the algorithm. The effectiveness of MoMA is demonstrated via numerical studies",
    "checked": true,
    "id": "0561f94c07249f06e41bdf6e570f432e864622d9",
    "semantic_title": "moma: model-based mirror ascent for offline reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Mao Hong",
      "Zhiyue Zhang",
      "Yue Wu",
      "Yanxun Xu"
    ]
  },
  "https://openreview.net/forum?id=4NHF9AC5ui": {
    "title": "Credal Bayesian Deep Learning",
    "volume": "main",
    "abstract": "Uncertainty quantification and robustness to distribution shifts are important goals in machine learning and artificial intelligence. Although Bayesian Neural Networks (BNNs) allow for uncertainty in the predictions to be assessed, different sources of uncertainty are indistinguishable. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDL allows to train an (uncountably) infinite ensemble of BNNs, using only finitely many elements. This is possible thanks to prior and likelihood finitely generated credal sets (FGCSs), a concept from the imprecise probability literature. Intuitively, convex combinations of a finite collection of prior-likelihood pairs are able to represent infinitely many such pairs. After training, CBDL outputs a set of posteriors on the parameters of the neural network. At inference time, such posterior set is used to derive a set of predictive distributions that is in turn utilized to distinguish between aleatoric and epistemic uncertainties, and to quantify them. The predictive set also produces either (i) a collection of outputs enjoying desirable probabilistic guarantees, or (ii) the single output that is deemed the best, that is, the one having the highest predictive lower probability -- another imprecise-probabilistic concept. CBDL is more robust than single BNNs to prior and likelihood misspecification, and to distribution shift. We show that CBDL is better at quantifying and disentangling different types of uncertainties than single BNNs and ensemble of BNNs. In addition, we apply CBDL to two case studies to demonstrate its downstream tasks capabilities: one, for motion prediction in autonomous driving scenarios, and two, to model blood glucose and insulin dynamics for artificial pancreas control. We show that CBDL performs better when compared to an ensemble of BNNs baseline",
    "checked": true,
    "id": "10dbf09b36c661ce608cb659f93a5fe8f626b637",
    "semantic_title": "credal bayesian deep learning",
    "citation_count": 23,
    "authors": [
      "Michele Caprio",
      "Souradeep Dutta",
      "Kuk Jin Jang",
      "Vivian Lin",
      "Radoslav Ivanov",
      "Oleg Sokolsky",
      "Insup Lee"
    ]
  },
  "https://openreview.net/forum?id=zRZe93OZho": {
    "title": "Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning",
    "volume": "main",
    "abstract": "Transformer models have consistently achieved remarkable results in various domains such as natural language processing and computer vision. However, despite ongoing research efforts to better understand these models, they still lack a comprehensive understanding. This is particularly true for deep time series forecasting methods, where analysis and understanding work is relatively limited. Time series data, unlike image and text information, can be more challenging to interpret and analyze. To address this, we approach the problem from a \\emph{manifold learning} perspective, assuming that the latent representations of time series forecasting models lie next to a low-dimensional manifold. In our study, we focus on analyzing the geometric features of these latent data manifolds, including intrinsic dimension and principal curvatures. Our findings reveal that deep transformer models exhibit similar geometric behavior across layers, and these geometric features are correlated with model performance. Additionally, we observe that untrained models initially have different structures, but they rapidly converge during training. By leveraging our geometric analysis and differentiable tools, we can potentially design new and improved deep forecasting neural networks. This approach complements existing analysis studies and contributes to a better understanding of transformer models in the context of time series forecasting",
    "checked": true,
    "id": "5d75dc74ad9722731216ced074b3db3ed949d6a7",
    "semantic_title": "analyzing deep transformer models for time series forecasting via manifold learning",
    "citation_count": 3,
    "authors": [
      "Ilya Kaufman",
      "Omri Azencot"
    ]
  },
  "https://openreview.net/forum?id=v8enu4jP9B": {
    "title": "Corrective Machine Unlearning",
    "volume": "main",
    "abstract": "Machine Learning models increasingly face data integrity challenges due to the use of large-scale training datasets drawn from the Internet. We study what model developers can do if they detect that some data was manipulated or incorrect. Such manipulated data can cause adverse effects including vulnerability to backdoored samples, systemic biases, and reduced accuracy on certain input domains. Realistically, all manipulated training samples cannot be identified, and only a small, representative subset of the affected data can be flagged. We formalize ``Corrective Machine Unlearning'' as the problem of mitigating the impact of data affected by unknown manipulations on a trained model, only having identified a subset of the corrupted data. We demonstrate that the problem of corrective unlearning has significantly different requirements from traditional privacy-oriented unlearning. We find most existing unlearning methods, including retraining-from-scratch without the deletion set, require most of the manipulated data to be identified for effective corrective unlearning. However, one approach, Selective Synaptic Dampening, achieves limited success, unlearning adverse effects with just a small portion of the manipulated samples in our setting, which shows encouraging signs for future progress. We hope our work spurs research towards developing better methods for corrective unlearning and offers practitioners a new strategy to handle data integrity challenges arising from web-scale training",
    "checked": true,
    "id": "40596974e4847412713cf4aa331838ba024ae8a9",
    "semantic_title": "corrective machine unlearning",
    "citation_count": 18,
    "authors": [
      "Shashwat Goel",
      "Ameya Prabhu",
      "Philip Torr",
      "Ponnurangam Kumaraguru",
      "Amartya Sanyal"
    ]
  },
  "https://openreview.net/forum?id=59DCkSGw8S": {
    "title": "Tree Ensembles for Contextual Bandits",
    "volume": "main",
    "abstract": "We propose a new framework for contextual multi-armed bandits based on tree ensembles. Our framework adapts two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. As part of this framework, we propose a novel method of estimating the uncertainty in tree ensemble predictions. We further demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost and random forests, two popular tree ensemble methods. Compared to state-of-the-art methods based on decision trees and neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks",
    "checked": true,
    "id": "f6154df355deae8a17ea9d35fe83787965e3014a",
    "semantic_title": "tree ensembles for contextual bandits",
    "citation_count": 0,
    "authors": [
      "Hannes Nilsson",
      "Rikard Johansson",
      "Niklas Ãkerblom",
      "Morteza Haghir Chehreghani"
    ]
  },
  "https://openreview.net/forum?id=qt4d0EGZsK": {
    "title": "Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities",
    "volume": "main",
    "abstract": "In this paper we explore evaluation of LLM capabilities. We present measurements of GPT-4 performance on several deterministic tasks; each task involves a basic calculation and takes as input parameter some element drawn from a large well-defined population (e.g., count elements in a list, multiply two k-digit numbers, etc). We examine several conditions per-task and perform enough trials so that statistically significant differences can be detected. This allows us to investigate the sensitivity of task-accuracy both to query phrasing and input parameter population. We find that seemingly trivial modifications in the task-prompt or input population can yield differences far larger than can be explained by sampling effects. For example, performance on a simple list-counting task varies with query-phrasing and list-length, but also with list composition (i.e., the thing-to-be-counted) and object frequency e.g., success when an element accounts for â 50\\% of a list is different from when it accounts for â 70\\% etc). We conclude that efforts to quantify LLM capabilities easily succumb to the language-as-fixed-effect fallacy, where experimental observations are improperly generalized beyond what the data supports. A consequence appears to be that intuitions that have been formed based on interactions with humans form a very unreliable guide as to which input modifications should ``make no difference'' to LLM performance",
    "checked": true,
    "id": "36585c22349a8b485cef9435add85c355b33b851",
    "semantic_title": "can we count on llms? the fixed-effect fallacy and claims of gpt-4 capabilities",
    "citation_count": 8,
    "authors": [
      "Thomas Ball",
      "Shuo Chen",
      "Cormac Herley"
    ]
  },
  "https://openreview.net/forum?id=wfdG2PEOHS": {
    "title": "Nonlinear Behaviour of Critical Points for a Simple Neural Network",
    "volume": "main",
    "abstract": "In severely over-parametrized regimes, neural network optimization can be analyzed by linearization techniques as the neural tangent kernel, which shows gradient descent convergence to zero training error, and landscape analysis, which shows that all local minima are global minima. Practical networks are often much less over-parametrized, and training behavior becomes more nuanced and nonlinear. This paper contains a fine grained analysis of the nonlinearity for a simple shallow network in one dimension. We show that the networks have unfavorable critical points, which can be mitigated by sufficiently high local resolution. Given this resolution, all critical points satisfy $L_2$ loss bounds of optimal adaptive approximation in Sobolev and Besov spaces on convex and concave subdomains of the target function. These bounds cannot be matched by linear approximation methods and show nonlinear and global behavior of the critical point's inner weights",
    "checked": true,
    "id": "8215f5f377412ef5e964dc7b61dab29005eda503",
    "semantic_title": "nonlinear behaviour of critical points for a simple neural network",
    "citation_count": 0,
    "authors": [
      "Gerrit Welper"
    ]
  },
  "https://openreview.net/forum?id=TSUprKRga1": {
    "title": "Measuring Orthogonality in Representations of Generative Models",
    "volume": "main",
    "abstract": "In unsupervised representation learning, models aim to distill essential features from high-dimensional data into lower-dimensional learned representations, guided by inductive biases. Understanding the characteristics that make a good representation remains a topic of ongoing research. Disentanglement of independent generative processes has long been credited with producing high-quality representations. However, focusing solely on representations that adhere to the stringent requirements of most disentanglement metrics, may result in overlooking many high-quality representations, well suited for various downstream tasks. These metrics often demand that generative factors be encoded in distinct, single dimensions aligned with the canonical basis of the representation space. Motivated by these observations, we propose two novel metrics: Importance-Weighted Orthogonality (IWO) and Importance-Weighted Rank (IWR). These metrics evaluate the mutual orthogonality and rank of generative factor subspaces. Throughout extensive experiments on common downstream tasks, over several benchmark datasets and models, IWO and IWR consistently show stronger correlations with downstream task performance than traditional disentanglement metrics. Our findings suggest that representation quality is closer related to the orthogonality of independent generative processes rather than their disentanglement, offering a new direction for evaluating and improving unsupervised learning models",
    "checked": true,
    "id": "e477c64b3ccd2c55b27594515480f08adca7f0eb",
    "semantic_title": "measuring orthogonality in representations of generative models",
    "citation_count": 0,
    "authors": [
      "Robin C. Geyer",
      "Alessandro Torcinovich",
      "JoÃ£o B. S. Carvalho",
      "Alexander Meyer",
      "Joachim M. Buhmann"
    ]
  },
  "https://openreview.net/forum?id=3YlOr7BHkx": {
    "title": "Mislabeled examples detection viewed as probing machine learning models: concepts, survey and extensive benchmark",
    "volume": "main",
    "abstract": "Mislabeled examples are ubiquitous in real-world machine learning datasets, advocating the development of techniques for automatic detection. We show that most mislabeled detection methods can be viewed as probing trained machine learning models using a few core principles. We formalize a modular framework that encompasses these methods, parameterized by only 4 building blocks, as well as a Python library that demonstrates that these principles can actually be implemented. The focus is on classifier-agnostic concepts, with an emphasis on adapting methods developed for deep learning models to non-deep classifiers for tabular data. We benchmark existing methods on (artificial) Completely At Random (NCAR) as well as (realistic) Not At Random (NNAR) labeling noise from a variety of tasks with imperfect labeling rules. This benchmark provides new insights as well as limitations of existing methods in this setup",
    "checked": true,
    "id": "11dee25a8ec4e60d7754d5144927b6bf63c56690",
    "semantic_title": "mislabeled examples detection viewed as probing machine learning models: concepts, survey and extensive benchmark",
    "citation_count": 1,
    "authors": [
      "Thomas George",
      "Pierre Nodet",
      "Alexis Bondu",
      "Vincent Lemaire"
    ]
  },
  "https://openreview.net/forum?id=pMD7A77k3i": {
    "title": "Coordinate Transform Fourier Neural Operators for Symmetries in Physical Modelings",
    "volume": "main",
    "abstract": "Symmetries often arise in many natural sciences; rather than relying on data augmentation or regularization for learning these symmetries, incorporating these inherent symmetries directly into the neural network architecture simplifies the learning process and enhances model performance. The laws of physics, including partial differential equations (PDEs), remain unchanged regardless of the coordinate system employed to depict them, and symmetries sometimes can be natural to illuminate in other coordinate systems. Moreover, symmetries often are associated with the underlying domain shapes. In this work, we consider physical modelings with neural operators (NOs), and we propose an approach based on coordinate transforms (CT) to work on different domain shapes and symmetries. Canonical coordinate transforms are applied to convert both the domain shape and symmetries. For example, a sphere can be naturally converted to a square with periodicities across its edges. The resulting CT-FNO scheme barely increases computational complexity and can be applied to different domain shapes while respecting the symmetries",
    "checked": true,
    "id": "e5485a0112fe48174e5aa5570483875522bb9a33",
    "semantic_title": "coordinate transform fourier neural operators for symmetries in physical modelings",
    "citation_count": 2,
    "authors": [
      "Wenhan Gao",
      "Ruichen Xu",
      "Hong Wang",
      "Yi Liu"
    ]
  },
  "https://openreview.net/forum?id=6j5M75iK3a": {
    "title": "Continual Learning in Open-vocabulary Classification with Complementary Memory Systems",
    "volume": "main",
    "abstract": "We introduce a method for flexible and efficient continual learning in open-vocabulary image classification, drawing inspiration from the complementary learning systems observed in human cognition. Specifically, we propose to combine predictions from a CLIP zero-shot model and the exemplar-based model, using the zero-shot estimated probability that a sample's class is within the exemplar classes. We also propose a ``tree probe'' method, an adaption of lazy learning principles, which enables fast learning from new examples with competitive accuracy to batch-trained linear models. We test in data incremental, class incremental, and task incremental settings, as well as ability to perform flexible inference on varying subsets of zero-shot and learned categories. Our proposed method achieves a good balance of learning speed, target task effectiveness, and zero-shot effectiveness. Code is available at https://github.com/jessemelpolio/TreeProbe",
    "checked": true,
    "id": "b335e189f92683b31dde57db1bf0cee6b13610e8",
    "semantic_title": "continual learning in open-vocabulary classification with complementary memory systems",
    "citation_count": 5,
    "authors": [
      "Zhen Zhu",
      "Weijie Lyu",
      "Yao Xiao",
      "Derek Hoiem"
    ]
  },
  "https://openreview.net/forum?id=lh6vOAHuvo": {
    "title": "AGaLiTe: Approximate Gated Linear Transformers for Online Reinforcement Learning",
    "volume": "main",
    "abstract": "In this paper we investigate transformer architectures designed for partially observable online reinforcement learning. The self-attention mechanism in the transformer architecture is capable of capturing long-range dependencies and it is the main reason behind its effectiveness in processing sequential data. Nevertheless, despite their success, transformers have two significant drawbacks that still limit their applicability in online reinforcement learning: (1) in order to remember all past information, the self-attention mechanism requires access to the whole history to be provided as context. (2) The inference cost in transformers is expensive. In this paper, we introduce recurrent alternatives to the transformer self-attention mechanism that offer context-independent inference cost, leverage long-range dependencies effectively, and performs well in online reinforcement learning task. We quantify the impact of the different components of our architecture in a diagnostic environment and assess performance gains in 2D and 3D pixel-based partially-observable environments (e.g. T-Maze, Mystery Path, Craftax, and Memory Maze). Compared with a state-of-the-art architecture, GTrXL, inference in our approach is at least 40% cheaper while reducing memory use more than 50%. Our approach either performs similarly or better than GTrXL, improving more than 37% upon GTrXL performance in harder tasks",
    "checked": true,
    "id": "886280cada60ec81a7f9d998d6aa7a19238bb400",
    "semantic_title": "agalite: approximate gated linear transformers for online reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Subhojeet Pramanik",
      "Esraa Elelimy",
      "Marlos C. Machado",
      "Adam White"
    ]
  },
  "https://openreview.net/forum?id=giEbq8Khcf": {
    "title": "ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text",
    "volume": "main",
    "abstract": "The utilization of deep learning on electrocardiogram (ECG) analysis has brought the advanced accuracy and efficiency of cardiac healthcare diagnostics. In this work, we address a critical challenge in the field of ECG analysis with deep learning: learning robust representation without large-scale labeled datasets. We propose ECG Semantic Integrator (ESI), a novel multimodal contrastive pretraining framework that jointly learns from ECG signals and associated textual descriptions. ESI employs a dual objective function that comprises a contrastive loss and a captioning loss to develop representations of ECG data. To create a sufficiently large and diverse training dataset, we develop a retrieval-augmented generation (RAG)-based Large Language Model (LLM) pipeline, called Cardio Query Assistant (CQA). This pipeline is designed to generate detailed textual descriptions for ECGs from diverse databases. The generated text includes information about demographics and waveform patterns. This approach enables us to compile a large-scale multimodal dataset with over 660,000 ECG-text pairs for pretraining ESI, which then learns robust and generalizable representations of 12-lead ECG. We validate our approach through various downstream tasks, including arrhythmia detection and ECG-based subject identification. Our experimental results demonstrate substantial improvements over strong baselines in these tasks. These baselines encompass supervised and self-supervised learning methods, as well as prior multimodal pretraining approaches. Our work shows the potential of combining multimodal pretraining to improve the analysis of ECG signals",
    "checked": true,
    "id": "269d38423e4d83f1403b6d977d5a9fc60d6f72ca",
    "semantic_title": "ecg semantic integrator (esi): a foundation ecg model pretrained with llm-enhanced cardiological text",
    "citation_count": 19,
    "authors": [
      "Han Yu",
      "Peikun Guo",
      "Akane Sano"
    ]
  },
  "https://openreview.net/forum?id=y8qGOvUn1r": {
    "title": "LeOCLR: Leveraging Original Images for Contrastive Learning of Visual Representations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0bf7e1f636eb4781eb9399934d699d38cc9d2710",
    "semantic_title": "leoclr: leveraging original images for contrastive learning of visual representations",
    "citation_count": 3,
    "authors": [
      "Mohammad Alkhalefi",
      "Georgios Leontidis",
      "Mingjun Zhong"
    ]
  },
  "https://openreview.net/forum?id=H95g8UpYKY": {
    "title": "Learning Sub-Second Routing Optimization in Computer Networks requires Packet-Level Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2abba74e1a0983afb3bc093c38e1922282fb21a6",
    "semantic_title": "learning sub-second routing optimization in computer networks requires packet-level dynamics",
    "citation_count": 0,
    "authors": [
      "Andreas Boltres",
      "Niklas Freymuth",
      "Patrick Jahnke",
      "Holger Karl",
      "Gerhard Neumann"
    ]
  },
  "https://openreview.net/forum?id=1KCrVMJoJ9": {
    "title": "Structure-Preserving Network Compression Via Low-Rank Induced Training Through Linear Layers Composition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b398b3d06259eff60f74b9e16e3da4c190c8baa9",
    "semantic_title": "structure-preserving network compression via low-rank induced training through linear layers composition",
    "citation_count": 0,
    "authors": [
      "Ismail Alkhouri",
      "Xitong Zhang",
      "Rongrong Wang"
    ]
  },
  "https://openreview.net/forum?id=AUC0Kmn70N": {
    "title": "ProFeAT: Projected Feature Adversarial Training for Self-Supervised Learning of Robust Representations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "488161d3241c251621bdcc96a119602d4031cb7f",
    "semantic_title": "profeat: projected feature adversarial training for self-supervised learning of robust representations",
    "citation_count": 0,
    "authors": [
      "Sravanti Addepalli",
      "Priyam Dey",
      "Venkatesh Babu Radhakrishnan"
    ]
  },
  "https://openreview.net/forum?id=8imVCizVEw": {
    "title": "Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs",
    "volume": "main",
    "abstract": "Anomaly detection in continuous-time dynamic graphs is an emerging field yet under-explored in the context of learning algorithms. In this paper, we pioneer structured analyses of link-level anomalies and graph representation learning for identifying categorically anomalous graph links. First, we introduce a fine-grained taxonomy for edge-level anomalies leveraging structural, temporal, and contextual graph properties. Based on these properties, we introduce a method for generating and injecting typed anomalies into graphs. Next, we introduce a novel method to generate continuous-time dynamic graphs featuring consistencies across either or combinations of time, structure, and context. To enable temporal graph learning methods to detect specific types of anomalous links rather than the bare existence of a link, we extend the generic link prediction setting by: (1) conditioning link existence on contextual edge attributes; and (2) refining the training regime to accommodate diverse perturbations in the negative edge sampler. Comprehensive benchmarks on synthetic and real-world datasets -- featuring synthetic and labeled organic anomalies and employing six state-of-the-art link prediction methods -- validate our taxonomy and generation processes for anomalies and benign graphs, as well as our approach to adapting methods for anomaly detection. Our results reveal that different learning methods excel in capturing different aspects of graph normality and detecting different types of anomalies. We conclude with a comprehensive list of findings highlighting opportunities for future research",
    "checked": true,
    "id": "ebf4fbd90d1556dd0e1ecad2e6a27b3f64eccac7",
    "semantic_title": "learning-based link anomaly detection in continuous-time dynamic graphs",
    "citation_count": 2,
    "authors": [
      "Tim Postuvan",
      "Claas Grohnfeldt",
      "Michele Russo",
      "Giulio Lovisotto"
    ]
  },
  "https://openreview.net/forum?id=FojAV72owK": {
    "title": "Why Fine-grained Labels in Pretraining Benefit Generalization?",
    "volume": "main",
    "abstract": "Recent studies show that pretraining a deep neural network with fine-grained labeled data, followed by fine-tuning on coarse-labeled data for downstream tasks, often yields better generalization than pretraining with coarse-labeled data. While there is ample empirical evidence supporting this, the theoretical justification remains an open problem. This paper addresses this gap by introducing a \"hierarchical multi-view\" structure to confine the input data distribution. Under this framework, we prove that: 1) coarse-grained pretraining only allows a neural network to learn the common features well, while 2) fine-grained pretraining helps the network learn the rare features in addition to the common ones, leading to improved accuracy on hard downstream test samples",
    "checked": true,
    "id": "7cc0bf987f9e002d4978f31942c6fa896d2885d6",
    "semantic_title": "why fine-grained labels in pretraining benefit generalization?",
    "citation_count": 0,
    "authors": [
      "Guan Zhe Hong",
      "Yin Cui",
      "Ariel Fuxman",
      "Stanley H. Chan",
      "Enming Luo"
    ]
  },
  "https://openreview.net/forum?id=MHfoA0Qf6g": {
    "title": "Quantization Variation: A New Perspective on Training Transformers with Low-Bit Precision",
    "volume": "main",
    "abstract": "Despite the outstanding performance of transformers in both language and vision tasks, the expanding computation and model size have increased the demand for efficient deployment. To address the heavy computation and parameter drawbacks, quantization is frequently studied in the community as a representative model compression technique and has seen extensive use on ConvNets. However, due to the unique properties of transformers, the low-bit quantization applications are still limited and underexplored. In this paper, we identify the difficulty of transformer low-bit quantization-aware training on its unique variation behaviors, which significantly differ from ConvNets. Based on comprehensive quantitative analysis, we observe variation in three hierarchies: various module quantization sensitivities, outliers in static weight and activation distribution, and oscillation in dynamic parameter fluctuations. These variations of transformers bring instability to the quantization-aware training (QAT) and negatively influence the performance. We explore the best practices to alleviate the variation's influence during low-bit transformer QAT and propose a variation-aware quantization scheme for both vision and language transformers. We extensively verify and show our scheme can alleviate the variation and improve the performance of transformers across various models and tasks. Our solution substantially improves the 2-bit Swin-T and binary BERT-base, achieving a 3.35% and 1.4% accuracy improvement over previous state-of-the-art methods on ImageNet-1K and GLUE",
    "checked": true,
    "id": "87127eb8c9374a038493ddafbd43dffcf6b0a652",
    "semantic_title": "quantization variation: a new perspective on training transformers with low-bit precision",
    "citation_count": 12,
    "authors": [
      "Xijie Huang",
      "Zhiqiang Shen",
      "Pingcheng Dong",
      "Kwang-Ting Cheng"
    ]
  },
  "https://openreview.net/forum?id=kmKVJl2JWo": {
    "title": "Stochastic Bandits for Egalitarian Assignment",
    "volume": "main",
    "abstract": "We study \\texttt{EgalMAB}, an egalitarian assignment problem in the context of stochastic multi-armed bandits. In \\texttt{EgalMAB}, an agent is tasked with assigning a set of users to arms. At each time step, the agent must assign exactly one arm to each user such that no two users are assigned to the same arm. Subsequently, each user obtains a reward drawn from the unknown reward distribution associated with its assigned arm. The agent's objective is to maximize the minimum expected cumulative reward among all users over a fixed horizon. This problem has applications in areas such as fairness in job and resource allocations, among others. We design and analyze a UCB-based policy \\texttt{EgalUCB} and establish upper bounds on the cumulative regret. In complement, we establish an almost-matching policy-independent impossibility result",
    "checked": true,
    "id": "79db83b0834f4d1e3ae361cd56f4206d45b37bab",
    "semantic_title": "stochastic bandits for egalitarian assignment",
    "citation_count": 1,
    "authors": [
      "Eugene Lim",
      "Vincent Y. F. Tan",
      "Harold Soh"
    ]
  },
  "https://openreview.net/forum?id=bDse8Z2gff": {
    "title": "IRWE: Inductive Random Walk for Joint Inference of Identity and Position Network Embedding",
    "volume": "main",
    "abstract": "Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings",
    "checked": true,
    "id": "d3b019c94b94633ba217cde044d5c5bb0352d7bf",
    "semantic_title": "irwe: inductive random walk for joint inference of identity and position network embedding",
    "citation_count": 0,
    "authors": [
      "Meng QIN",
      "Dit-Yan Yeung"
    ]
  },
  "https://openreview.net/forum?id=JP1GVyF5i5": {
    "title": "Adaptive Training Distributions with Scalable Online Bilevel Optimization",
    "volume": "main",
    "abstract": "Large neural networks pretrained on web-scale corpora are central to modern machine learning. In this paradigm, the distribution of the large, heterogeneous pretraining data rarely matches that of the application domain. This work considers modifying the pretraining distribution in the case where one has a small sample of data reflecting the targeted test conditions. We propose an algorithm motivated by a recent formulation of this setting as an online, bilevel optimization problem. With scalability in mind, our algorithm prioritizes computing gradients at training points which are likely to most improve the loss on the targeted distribution. Empirically, we show that in some cases this approach is beneficial over existing strategies from the domain adaptation literature but may not succeed in other cases. We propose a simple test to evaluate when our approach can be expected to work well and point towards further research to address current limitations",
    "checked": true,
    "id": "571bffdecc86ecae34f19faf7940d1117e30147f",
    "semantic_title": "adaptive training distributions with scalable online bilevel optimization",
    "citation_count": 10,
    "authors": [
      "David Grangier",
      "Pierre Ablin",
      "Awni Hannun"
    ]
  },
  "https://openreview.net/forum?id=kUuPUIPvJ6": {
    "title": "Support-Set Context Matters for Bongard Problems",
    "volume": "main",
    "abstract": "Current machine learning methods struggle to solve Bongard problems, which are a type of IQ test that requires deriving an abstract \"concept\" from a set of positive and negative \"support\" images, and then classifying whether or not a new query image depicts the key concept. On Bongard-HOI, a benchmark for natural-image Bongard problems, most existing methods have reached at best 69% accuracy (where chance is 50%). Low accuracy is often attributed to neural nets' lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not adapt image features given information contained in the support set as a whole, and rely instead on information extracted from individual supports. This is a critical issue, because the \"key concept\" in a typical Bongard problem can often only be distinguished using multiple positives and multiple negatives. We explore simple methods to incorporate this context and show substantial gains over prior works, leading to new state-of-the-art accuracy on Bongard-LOGO (75.3%) and Bongard-HOI (76.4%) compared to methods with equivalent vision backbone architectures and strong performance on the original Bongard problem set (60.8%). Code is available at https://github.com/nraghuraman/bongard-context",
    "checked": true,
    "id": "9da90b733624a22fea4c6212fddb8e73281f23fa",
    "semantic_title": "support-set context matters for bongard problems",
    "citation_count": 0,
    "authors": [
      "Nikhil Raghuraman",
      "Adam W Harley",
      "Leonidas Guibas"
    ]
  },
  "https://openreview.net/forum?id=QEwz7447tR": {
    "title": "A Probabilistic Model behind Self- Supervised Learning",
    "volume": "main",
    "abstract": "In self-supervised learning (SSL), representations are learned via an auxiliary task without annotated labels. A common task is to classify augmentations or different modalities of the data, which share semantic _content_ (e.g. an object in an image) but differ in _style_ (e.g. the object's location). Many approaches to self-supervised learning have been proposed, e.g. SimCLR, CLIP and VicREG, which have recently gained much attention for their representations achieving downstream performance comparable to supervised learning. However, a theoretical understanding of the mechanism behind self-supervised methods eludes. Addressing this, we present a generative latent variable model for self-supervised learning and show that several families of discriminative SSL, including contrastive methods, induce a comparable distribution over representations, providing a unifying theoretical framework for these methods. The proposed model also justifies connections drawn to mutual information and the use of a ``projection head''. Learning representations by fitting the model generatively (termed SimVAE) improves performance over discriminative and other VAE-based methods on simple image benchmarks and significantly narrows the gap between generative and discriminative representation learning in more complex settings. Importantly, as our analysis predicts, SimVAE outperforms self-supervised learning where style information is required, taking an important step toward understanding self-supervised methods and achieving task-agnostic representations",
    "checked": true,
    "id": "0369e7b9323452d5cbb4289c7f5f2d957d79961b",
    "semantic_title": "a probabilistic model behind self- supervised learning",
    "citation_count": 2,
    "authors": [
      "Alice Bizeul",
      "Bernhard SchÃ¶lkopf",
      "Carl Allen"
    ]
  },
  "https://openreview.net/forum?id=A6D3PYSyqJ": {
    "title": "LINOCS: Lookahead Inference of Networked Operators for Continuous Stability",
    "volume": "main",
    "abstract": "Identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. For instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. Such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. Existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. Methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. Here we introduce Lookahead-driven Inference of Networked Operators for Continuous Stability (LINOCS), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. LINOCS integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. We demonstrate LINOCS' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples",
    "checked": true,
    "id": "f005c8b19ca1d9171afc191fc78b81f136ddfb8c",
    "semantic_title": "linocs: lookahead inference of networked operators for continuous stability",
    "citation_count": 4,
    "authors": [
      "Noga Mudrik",
      "Eva Yezerets",
      "Yenho Chen",
      "Christopher John Rozell",
      "Adam Shabti Charles"
    ]
  },
  "https://openreview.net/forum?id=HCRkV3kxHW": {
    "title": "Robust Stochastic Optimization via Gradient Quantile Clipping",
    "volume": "main",
    "abstract": "We introduce a clipping strategy for Stochastic Gradient Descent (SGD) which uses quantiles of the gradient norm as clipping thresholds. We prove that this new strategy provides a robust and efficient optimization algorithm for smooth objectives (convex or non-convex), that tolerates heavy-tailed samples (including infinite variance) and a fraction of outliers in the data stream akin to Huber contamination. Our mathematical analysis leverages the connection between constant step size SGD and Markov chains and handles the bias introduced by clipping in an original way. For strongly convex objectives, we prove that the iteration converges to a concentrated distribution and derive high probability bounds on the final estimation error. In the non-convex case, we prove that the limit distribution is localized on a neighborhood with low gradient. We propose an implementation of this algorithm using rolling quantiles which leads to a highly efficient optimization procedure with strong robustness properties, as confirmed by our numerical experiments",
    "checked": true,
    "id": "0c2d8750c1b4ef4160a24ecb94eb71bc61f3e0f5",
    "semantic_title": "robust stochastic optimization via gradient quantile clipping",
    "citation_count": 2,
    "authors": [
      "Ibrahim Merad",
      "StÃ©phane GaÃ¯ffas"
    ]
  },
  "https://openreview.net/forum?id=XCzuQI0oXR": {
    "title": "Implicit Neural Representations for Robust Joint Sparse-View CT Reconstruction",
    "volume": "main",
    "abstract": "Computed Tomography (CT) is pivotal in industrial quality control and medical diagnostics. Sparse-view CT, offering reduced ionizing radiation, faces challenges due to its under-sampled nature, leading to ill-posed reconstruction problems. Recent advancements in Implicit Neural Representations (INRs) have shown promise in addressing sparse-view CT reconstruction. Recognizing that CT often involves scanning similar subjects, we propose a novel approach to improve reconstruction quality through joint reconstruction of multiple objects using INRs. This approach can potentially utilize the advantages of INRs and the common patterns observed across different objects. While current INR joint reconstruction techniques primarily focus on speeding up the learning process, they are not specifically tailored to enhance the final reconstruction quality. To address this gap, we introduce a novel INR-based Bayesian framework integrating latent variables to capture the common patterns across multiple objects under joint reconstruction. The common patterns then assist in the reconstruction of each object via latent variables, thereby improving the individual reconstruction. Extensive experiments demonstrate that our method achieves higher reconstruction quality with sparse views and remains robust to noise in the measurements as indicated by common numerical metrics. The obtained latent variables can also serve as network initialization for the new object and speed up the learning process",
    "checked": true,
    "id": "c03bb4036d40d3fa66247f6033c318cd9aea7f64",
    "semantic_title": "implicit neural representations for robust joint sparse-view ct reconstruction",
    "citation_count": 4,
    "authors": [
      "Jiayang Shi",
      "Junyi Zhu",
      "Daniel Pelt",
      "Joost Batenburg",
      "Matthew B. Blaschko"
    ]
  },
  "https://openreview.net/forum?id=K6DKrrpYpJ": {
    "title": "Score-based Explainability for Graph Representations",
    "volume": "main",
    "abstract": "Despite the widespread use of unsupervised Graph Neural Networks (GNNs), their post-hoc explainability remains underexplored. Current graph explanation methods typically focus on explaining a single dimension of the final output. However, unsupervised and self-supervised GNNs produce d-dimensional representation vectors whose individual elements lack clear, disentangled semantic meaning. To tackle this issue, we draw inspiration from the success of score-based graph explainers in supervised GNNs and propose a novel framework, grXAI, for graph representation explainability. grXAI generalizes existing score-based graph explainers to identify the subgraph most responsible for constructing the latent representation of the input graph. This framework can be easily and efficiently implemented as a wrapper around existing methods, enabling the explanation of graph representations through connected subgraphs, which are more human-intelligible. Extensive qualitative and quantitative experiments demonstrate grXAI's strong ability to identify subgraphs that effectively explain learned graph representations across various unsupervised tasks and learning algorithms",
    "checked": true,
    "id": "9d0622826f53eb1824d34401f19bd0e09b78dad2",
    "semantic_title": "score-based explainability for graph representations",
    "citation_count": 1,
    "authors": [
      "Ehsan Hajiramezanali",
      "Sepideh Maleki",
      "Max W Shen",
      "Kangway V. Chuang",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ]
  },
  "https://openreview.net/forum?id=cD209UgOX7": {
    "title": "Scaling Up Bayesian Neural Networks with Neural Networks",
    "volume": "main",
    "abstract": "Bayesian Neural Networks (BNNs) offer a principled and natural framework for proper uncertainty quantification in the context of deep learning. They address the typical challenges associated with conventional deep learning methods, such as data insatiability, ad-hoc nature, and susceptibility to overfitting. However, their implementation typically either relies on Markov chain Monte Carlo (MCMC) methods, which are characterized by their computational intensity and inefficiency in a high-dimensional space, or variational inference methods, which tend to underestimate uncertainty. To address this issue, we propose a novel Calibration-Emulation-Sampling (CES) strategy to significantly enhance the computational efficiency of BNN. In this framework, during the initial calibration stage, we collect a small set of samples from the parameter space. These samples serve as training data for the emulator, which approximates the map between parameters and posterior probability. The trained emulator is then used for sampling from the posterior distribution at substantially higher speed compared to the standard BNN. Using simulated and real data, we demonstrate that our proposed method improves computational efficiency of BNN, while maintaining similar performance in terms of prediction accuracy and uncertainty quantification",
    "checked": true,
    "id": "2f7e74bbe5a75dc8e704d5a26ba31a641de647fe",
    "semantic_title": "scaling up bayesian neural networks with neural networks",
    "citation_count": 1,
    "authors": [
      "Zahra Moslemi",
      "Yang Meng",
      "Shiwei Lan",
      "Babak Shahbaba"
    ]
  },
  "https://openreview.net/forum?id=3CmPvcYJnm": {
    "title": "PriViT: Vision Transformers for Private Inference",
    "volume": "main",
    "abstract": "The Vision Transformer (ViT) architecture has emerged as the backbone of choice for state-of-the-art deep models for computer vision applications. However, ViTs are ill-suited for private inference using secure multi-party computation (MPC) protocols, due to the large number of non-polynomial operations (self-attention, feed-forward rectifiers, layer normalization). We develop PriViT, a gradient-based algorithm to selectively Taylorize nonlinearities in ViTs while maintaining their prediction accuracy. Our algorithm is conceptually very simple, easy to implement, and achieves improved performance over existing MPC-friendly transformer architectures in terms of the latency-accuracy Pareto frontier",
    "checked": true,
    "id": "a5435429779f15ea13596d45ebc3c0f5a54daea8",
    "semantic_title": "privit: vision transformers for private inference",
    "citation_count": 0,
    "authors": [
      "Naren Dhyani",
      "Jianqiao Cambridge Mo",
      "Patrick Yubeaton",
      "Minsu Cho",
      "Ameya Joshi",
      "Siddharth Garg",
      "Brandon Reagen",
      "Chinmay Hegde"
    ]
  },
  "https://openreview.net/forum?id=kdTC4ktHPD": {
    "title": "Revisiting Deep Feature Reconstruction for Logical and Structural Industrial Anomaly Detection",
    "volume": "main",
    "abstract": "Industrial anomaly detection is crucial for quality control and predictive maintenance, but it presents challenges due to limited training data, diverse anomaly types, and external factors that alter object appearances. Existing methods commonly detect structural anomalies, such as dents and scratches, by leveraging multi-scale features from image patches extracted through deep pre-trained networks. However, significant memory and computational demands often limit their practical application. Additionally, detecting logical anomaliesâsuch as images with missing or excess elementsârequires an understanding of spatial relationships that traditional patch-based methods fail to capture. In this work, we address these limitations by focusing on Deep Feature Reconstruction (DFR), a memory- and compute-efficient approach for detecting structural anomalies. We further enhance DFR into a unified framework, called ULSAD, which is capable of detecting both structural and logical anomalies. Specifically, we refine the DFR training objective to improve performance in structural anomaly detection, while introducing an attention-based loss mechanism using a global autoencoder-like network to handle logical anomaly detection. Our empirical evaluation across five benchmark datasets demonstrates the performance of ULSAD in detecting and localizing both structural and logical anomalies, outperforming eight state-of-the-art methods. An extensive ablation study further highlights the contribution of each component to the overall performance improvement. Our code is available at https://github.com/sukanyapatra1997/ULSAD-2024.git",
    "checked": true,
    "id": "dc75a9cb764713e41fe4d0c623ab456b5ce3a3da",
    "semantic_title": "revisiting deep feature reconstruction for logical and structural industrial anomaly detection",
    "citation_count": 2,
    "authors": [
      "Sukanya Patra",
      "Souhaib Ben Taieb"
    ]
  },
  "https://openreview.net/forum?id=OxV75W90FN": {
    "title": "Meta-Learning under Task Shift",
    "volume": "main",
    "abstract": "A common assumption in meta-learning is that meta-training and meta-test tasks are drawn from the same distribution. However, this assumption is often not fulfilled. Under such task shift, standard meta-learning algorithms do not work as desired since their unbiasedness is no longer maintained. In this paper, we propose a new meta-learning method called Importance Weighted Meta-Learning (IWML), which preserves unbiasedness even under task shift. Our approach uses both labeled meta-training datasets and unlabeled datasets in tasks obtained from the meta-test task distribution to assign weights to each meta-training task. These weights are determined by the ratio of meta-test and meta-training task densities. Our method enables the model to focus more on the meta-training tasks that closely align with meta-test tasks during the meta-training process. We meta-learn neural network-based models by minimizing the expected weighted meta-training error, which is an unbiased estimator of the expected error over meta-test tasks. The task density ratio is estimated using kernel density estimation, where the distance between tasks is measured by the maximum mean discrepancy. Our empirical evaluation of few-shot classification datasets demonstrates a significant improvement of IWML over existing approaches",
    "checked": true,
    "id": "0489202f5095b46ebce1f0848066c15225f64a54",
    "semantic_title": "meta-learning under task shift",
    "citation_count": 0,
    "authors": [
      "Lei Sun",
      "Yusuke Tanaka",
      "Tomoharu Iwata"
    ]
  },
  "https://openreview.net/forum?id=a1MRjOL6WJ": {
    "title": "LInK: Learning Joint Representations of Design and Performance Spaces through Contrastive Learning for Mechanism Synthesis",
    "volume": "main",
    "abstract": "In this paper, we introduce LInK, a novel framework that integrates contrastive learning of performance and design space with optimization techniques for solving complex inverse problems in engineering design with discrete and continuous variables. We focus on the path synthesis problem for planar linkage mechanisms. By leveraging a multimodal and transformation-invariant contrastive learning framework, LInK learns a joint representation that captures complex physics and design representations of mechanisms, enabling rapid retrieval from a vast dataset of over 10 million mechanisms. This approach improves precision through the warm start of a hierarchical unconstrained nonlinear optimization algorithm, combining the robustness of traditional optimization with the speed and adaptability of modern deep learning methods. Our results on an existing benchmark demonstrate that LInK outperforms existing methods with 28 times less error compared to a state-of-the-art approach while taking 20 times less time on an existing benchmark. Moreover, we introduce a significantly more challenging benchmark, named LINK-ABC, which involves synthesizing linkages that trace the trajectories of English capital alphabetsâan inverse design benchmark task that existing methods struggle with due to large nonlinearities and tiny feasible space. Our results demonstrate that LInK not only advances the field of mechanism design but also broadens the applicability of contrastive learning and optimization to other areas of engineering. The code and data are publicly available at https://github.com/ahnobari/LInK",
    "checked": true,
    "id": "7bf9c14b82dc4589613e0b6235c43bc476aa48dc",
    "semantic_title": "link: learning joint representations of design and performance spaces through contrastive learning for mechanism synthesis",
    "citation_count": 3,
    "authors": [
      "Amin Heyrani Nobari",
      "Akash Srivastava",
      "Dan Gutfreund",
      "Kai Xu",
      "Faez Ahmed"
    ]
  },
  "https://openreview.net/forum?id=rHL329Xa3X": {
    "title": "Universal Functional Regression with Neural Operator Flows",
    "volume": "main",
    "abstract": "Regression on function spaces is typically limited to models with Gaussian process priors. We introduce the notion of universal functional regression, in which we aim to learn a prior distribution over non-Gaussian function spaces that remains mathematically tractable for functional regression. To do this, we develop Neural Operator Flows (OpFlow), an infinite-dimensional extension of normalizing flows. OpFlow is an invertible operator that maps the (potentially unknown) data function space into a Gaussian process, allowing for exact likelihood estimation of functional point evaluations. OpFlow enables robust and accurate uncertainty quantification via drawing posterior samples of the Gaussian process and subsequently mapping them into the data function space. We empirically study the performance of OpFlow on regression and generation tasks with data generated from Gaussian processes with known posterior forms and non-Gaussian processes, as well as real-world earthquake seismograms with an unknown closed-form distribution",
    "checked": true,
    "id": "c3ae485c26a60310aa9df90e2ba95440cb064a85",
    "semantic_title": "universal functional regression with neural operator flows",
    "citation_count": 5,
    "authors": [
      "Yaozhong Shi",
      "Angela F Gao",
      "Zachary E Ross",
      "Kamyar Azizzadenesheli"
    ]
  },
  "https://openreview.net/forum?id=bo8vM9j3UO": {
    "title": "A Theoretical Framework for Zeroth-Order Budget Convex Optimization",
    "volume": "main",
    "abstract": "This paper studies a natural generalization of the problem of minimizing a convex function $f$ by querying its values sequentially. At each time-step $t$, the optimizer selects a query point $X_t$ and invests a budget $b_t$ (chosen by the environment) to obtain a fuzzy evaluation of $f$ at $X_t$ whose accuracy depends on the amount of budget invested in $X_t$ across times. This setting is motivated by the minimization of objectives whose values can only be determined approximately through lengthy or expensive computations, where it is paramount to recycle past information. In the univariate case, we design ReSearch, an anytime parameter-free algorithm for which we prove near-optimal optimization-error guarantees. Then, we present two applications of our univariate analysis. First, we show how to use ReSearch for stochastic convex optimization, obtaining theoretical and empirical improvements on state-of-the-art benchmarks. Second, we handle the $d$-dimensional budget problem by combining ReSearch with a coordinate descent method, presenting theoretical guarantees and experiments",
    "checked": true,
    "id": "6f907bc59eb017b13ff20bf23c95f4282f5d38d6",
    "semantic_title": "a theoretical framework for zeroth-order budget convex optimization",
    "citation_count": 0,
    "authors": [
      "FranÃ§ois Bachoc",
      "Tommaso Cesari",
      "Roberto Colomboni",
      "Andrea Paudice"
    ]
  },
  "https://openreview.net/forum?id=ZVDWzgk6L6": {
    "title": "A Unified Hallucination Mitigation Framework for Large Vision-Language Models",
    "volume": "main",
    "abstract": "Hallucination is a common problem for Large Vision-Language Models (LVLMs) with long generations which is difficult to eradicate. The generation with hallucinations is partially inconsistent with the image content. To mitigate hallucination, current studies either focus on the process of model inference or the results of model generation, but the solutions they design sometimes do not deal appropriately with various types of queries and the hallucinations of the generations about these queries. To accurately deal with various hallucinations, we present a unified framework, Dentist, for hallucination mitigation. The core step is to first classify the queries, then perform different processes of hallucination mitigation based on the classification result, just like a dentist first observes the teeth and then makes a plan. In a simple deployment, Dentist can classify queries as perception or reasoning and easily mitigate potential hallucinations in answers which has been demonstrated in our experiments. On MMbench, we achieve a 13.44%/10.2%/15.8% improvement in accuracy on Image Quality, a Coarse Perception visual question answering (VQA) task, over the baseline InstructBLIP/LLaVA/VisualGLM. Our source code will be released on GitHub",
    "checked": true,
    "id": "088a42203bc9a67e14b1bfd5c1fd25a03c126c08",
    "semantic_title": "a unified hallucination mitigation framework for large vision-language models",
    "citation_count": 3,
    "authors": [
      "Yue Chang",
      "Liqiang Jing",
      "Xiaopeng Zhang",
      "Yue Zhang"
    ]
  },
  "https://openreview.net/forum?id=Ni14fXbyTV": {
    "title": "Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning",
    "volume": "main",
    "abstract": "Current experiments frequently produce high-dimensional, multimodal datasetsâsuch as those combining neural activity and animal behavior or gene expression and phenotypic profilingâwith the goal of extracting useful correlations between the modalities. Often, the first step in analyzing such datasets is dimensionality reduction. We explore two primary classes of approaches to dimensionality reduction (DR): Independent Dimensionality Reduction (IDR) and Simultaneous Dimensionality Reduction (SDR). In IDR methods, of which Principal Components Analysis is a paradigmatic example, each modality is compressed independently, striving to retain as much variation within each modality as possible. In contrast, in SDR, one simultaneously compresses the modalities to maximize the covariation between the reduced descriptions while paying less attention to how much individual variation is preserved. Paradigmatic examples include Partial Least Squares and Canonical Correlations Analysis. Even though these DR methods are a staple of statistics, their relative accuracy and data set size requirements are poorly understood. We use a generative linear model to synthesize multimodal data with known variance and covariance structures to examine these questions. We assess the accuracy of the reconstruction of the covariance structures as a function of the number of samples, signal-to-noise ratio, and the number of varying and covarying signals in the data. Using numerical experiments, we demonstrate that linear SDR methods consistently outperform linear IDR methods and yield higher-quality, more succinct reduced-dimensional representations with smaller datasets. Remarkably, regularized CCA can identify low-dimensional weak covarying structures even when the number of samples is much smaller than the dimensionality of the data, which is a regime challenging for all dimensionality reduction methods. Our work corroborates and explains previous observations in the literature that SDR can be more effective in detecting covariation patterns in data. These findings strengthen the intuition that SDR should be preferred to IDR in real-world data analysis when detecting covariation is more important than preserving variation",
    "checked": true,
    "id": "23979eb4004a522bb92da6db6941bf8f888dca40",
    "semantic_title": "simultaneous dimensionality reduction: a data efficient approach for multimodal representations learning",
    "citation_count": 3,
    "authors": [
      "Eslam Abdelaleem",
      "Ahmed Roman",
      "K. Michael Martini",
      "Ilya Nemenman"
    ]
  },
  "https://openreview.net/forum?id=Uc2mqNPkEq": {
    "title": "Reducing Variance in Meta-Learning via Laplace Approximation for Regression Tasks",
    "volume": "main",
    "abstract": "Given a finite set of sample points, meta-learning algorithms aim to learn an optimal adaptation strategy for new, unseen tasks. Often, this data can be ambiguous as it might belong to different tasks concurrently. This is particularly the case in meta-regression tasks. In such cases, the estimated adaptation strategy is subject to high variance due to the limited amount of support data for each task, which often leads to sub-optimal generalization performance. In this work, we address the problem of variance reduction in gradient-based meta-learning and formalize the class of problems prone to this, a condition we refer to as \\emph{task overlap}. Specifically, we propose a novel approach that reduces the variance of the gradient estimate by weighing each support point individually by the variance of its posterior over the parameters. To estimate the posterior, we utilize the Laplace approximation, which allows us to express the variance in terms of the curvature of the loss landscape of our meta-learner. Experimental results demonstrate the effectiveness of the proposed method and highlight the importance of variance reduction in meta-learning",
    "checked": true,
    "id": "8727729f96e5b7f54e09cc50d6ba0e1b0042d5a3",
    "semantic_title": "reducing variance in meta-learning via laplace approximation for regression tasks",
    "citation_count": 0,
    "authors": [
      "Alfredo Reichlin",
      "Gustaf TegnÃ©r",
      "Miguel Vasco",
      "Hang Yin",
      "MÃ¥rten BjÃ¶rkman",
      "Danica Kragic"
    ]
  },
  "https://openreview.net/forum?id=0mRfQOnkqk": {
    "title": "Budget-Aware Sequential Brick Assembly with Efficient Constraint Satisfaction",
    "volume": "main",
    "abstract": "We tackle the problem of sequential brick assembly with LEGO bricks to create combinatorial 3D structures. This problem is challenging since this brick assembly task encompasses the characteristics of combinatorial optimization problems. In particular, the number of assemblable structures increases exponentially as the number of bricks used increases. To solve this problem, we propose a new method to predict the scores of the next brick position by employing a U-shaped sparse 3D convolutional neural network. Along with the 3D convolutional network, a one-initialized brick-sized convolution filter is used to efficiently validate assembly constraints between bricks without training itself. By the nature of this one-initialized convolution filter, we can readily consider several different brick types by benefiting from modern implementation of convolution operations. To generate a novel structure, we devise a sampling strategy to determine the next brick position considering the satisfaction of assembly constraints. Moreover, our method is designed for either budget-free or budget-aware scenario where a budget may confine the number of bricks and their types. We demonstrate that our method successfully generates a variety of brick structures and outperforms existing methods with Bayesian optimization, deep graph generative model, and reinforcement learning",
    "checked": true,
    "id": "ed64cd040a93756981eccacb3ca0c2a8b70f3855",
    "semantic_title": "budget-aware sequential brick assembly with efficient constraint satisfaction",
    "citation_count": 5,
    "authors": [
      "Seokjun Ahn",
      "Jungtaek Kim",
      "Minsu Cho",
      "Jaesik Park"
    ]
  },
  "https://openreview.net/forum?id=PX06pUVs1P": {
    "title": "Unveiling Adversarially Robust Graph Lottery Tickets",
    "volume": "main",
    "abstract": "Graph lottery tickets (GLTs), comprising a sparse graph neural network (GNN) and a sparse input graph adjacency matrix, can significantly reduce the computing footprint of inference tasks compared to their dense counterparts. However, their performance against adversarial attacks remains to be fully explored. In this paper, we first investigate the resilience of GLTs against different {poisoning attacks based on structure perturbations} and observe that they are vulnerable and show a large drop in classification accuracy. We then present an \\emph{adversarially robust graph sparsification (ARGS)} framework that prunes the adjacency matrix and the GNN weights by minimizing a novel loss function capturing the graph homophily property and information associated with the true labels of the train nodes and the pseudo labels of the test nodes. By iteratively applying ARGS to prune both the perturbed graph adjacency matrix and the GNN model weights, we can find graph lottery tickets that are highly sparse yet achieve competitive performance under different training-time (poisoning) structure-perturbation attacks. Evaluations conducted on various benchmarks, considering {attacks} such as PGD, MetaAttack, PR-BCD, GR-BCD, and adaptive attack, demonstrate that ARGS can significantly improve the robustness of the generated GLTs, even when subjected to high levels of sparsity",
    "checked": true,
    "id": "86ac1bb087408cc05f975c11420388a4bdb74dac",
    "semantic_title": "unveiling adversarially robust graph lottery tickets",
    "citation_count": 0,
    "authors": [
      "Subhajit Dutta Chowdhury",
      "Zhiyu Ni",
      "Qingyuan Peng",
      "Souvik Kundu",
      "Pierluigi Nuzzo"
    ]
  },
  "https://openreview.net/forum?id=llQXLfbGOq": {
    "title": "Attention Normalization Impacts Cardinality Generalization in Slot Attention",
    "volume": "main",
    "abstract": "Object-centric scene decompositions are important representations for downstream tasks in fields such as computer vision and robotics. The recently proposed Slot Attention module, already leveraged by several derivative works for image segmentation and object tracking in videos, is a deep learning component which performs unsupervised object-centric scene decomposition on input images. It is based on an attention architecture, in which latent slot vectors, which hold compressed information on objects, attend to localized perceptual features from the input image. In this paper, we demonstrate that design decisions on normalizing the aggregated values in the attention architecture have considerable impact on the capabilities of Slot Attention to generalize to a higher number of slots and objects as seen during training. We propose and investigate alternatives to the original normalization scheme which increase the generalization capabilities of Slot Attention to varying slot and object counts, resulting in performance gains on the task of unsupervised image segmentation. The newly proposed normalizations represent minimal and easy to implement modifications of the usual Slot Attention module, changing the value aggregation mechanism from a weighted mean operation to a scaled weighted sum operation",
    "checked": true,
    "id": "d81249511979660ed8b50d05d9b0880983cf39fa",
    "semantic_title": "attention normalization impacts cardinality generalization in slot attention",
    "citation_count": 0,
    "authors": [
      "Markus Krimmel",
      "Jan Achterhold",
      "Joerg Stueckler"
    ]
  },
  "https://openreview.net/forum?id=7t7fJT4Gym": {
    "title": "Gromov-Wasserstein-like Distances in the Gaussian Mixture Models Space",
    "volume": "main",
    "abstract": "The Gromov-Wasserstein (GW) distance is frequently used in machine learning to compare distributions across distinct metric spaces. Despite its utility, it remains computationally intensive, especially for large-scale problems. Recently, a novel Wasserstein distance specifically tailored for Gaussian mixture models and known as $ MW_2 $ (mixture Wasserstein) has been introduced by several authors. In scenarios where data exhibit clustering, this approach simplifies to a small-scale discrete optimal transport problem, which complexity depends solely on the number of Gaussian components in the GMMs. This paper aims to extend $ MW_2 $ by introducing new Gromov-type distances. These distances are designed to be isometry-invariant in Euclidean spaces and are applicable for comparing GMMs across different dimensional spaces. Our first contribution is the Mixture Gromov Wasserstein distance ($MGW_2$), which can be viewed as a 'Gromovized' version of $ MW_2 $ . This new distance has a straightforward discrete formulation, making it highly efficient for estimating distances between GMMs in practical applications. To facilitate the derivation of a transport plan between GMMs, we present a second distance, the Embedded Wasserstein distance ($ EW_2 $). This distance turns out to be closely related to several recent alternatives to Gromov-Wasserstein. We show that can be adapted to derive a distance as well as optimal transportation plans between GMMs. We demonstrate the efficiency of these newly proposed distances on medium to large-scale problems, including shape matching and hyperspectral image color transfer",
    "checked": true,
    "id": "2ba1ad7a81e0a91f7c9ea248855cc6f6ccb33003",
    "semantic_title": "gromov-wasserstein-like distances in the gaussian mixture models space",
    "citation_count": 3,
    "authors": [
      "Antoine Salmona",
      "Agnes Desolneux",
      "Julie Delon"
    ]
  },
  "https://openreview.net/forum?id=KCf5CLAXZq": {
    "title": "Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization",
    "volume": "main",
    "abstract": "We present Re-weighted Gradient Descent (RGD), a novel optimization technique that improves the performance of deep neural networks through dynamic sample re-weighting. Leveraging insights from distributionally robust optimization (DRO) with Kullback-Leibler divergence, our method dynamically assigns importance weights to training data during each optimization step. RGD is simple to implement, computationally efficient, and compatible with widely used optimizers such as SGD and Adam. We demonstrate the effectiveness of RGD on various learning tasks, including supervised learning, meta-learning, and out-of-domain generalization. Notably, RGD achieves state-of-the-art results on diverse benchmarks, with improvements of +0.7% on DomainBed, +1.44% on tabular classification, +1.94% on GLUE with BERT, and +1.01% on ImageNet-1K with ViT",
    "checked": true,
    "id": "6f4974c33e758ddd9524684744407b7de5525caf",
    "semantic_title": "stochastic re-weighted gradient descent via distributionally robust optimization",
    "citation_count": 6,
    "authors": [
      "Ramnath Kumar",
      "Kushal Alpesh Majmundar",
      "Dheeraj Mysore Nagaraj",
      "Arun Suggala"
    ]
  },
  "https://openreview.net/forum?id=iMKUMWfRIj": {
    "title": "Towards Trustworthy Reranking: A Simple yet Effective Abstention Mechanism",
    "volume": "main",
    "abstract": "Neural Information Retrieval (NIR) has significantly improved upon heuristic-based Information Retrieval (IR) systems. Yet, failures remain frequent, the models used often being unable to retrieve documents relevant to the user's query. We address this challenge by proposing a lightweight abstention mechanism tailored for real-world constraints, with particular emphasis placed on the reranking phase. We introduce a protocol for evaluating abstention strategies in black-box scenarios (typically encountered when relying on API services), demonstrating their efficacy, and propose a simple yet effective data-driven mechanism. We provide open-source code for experiment replication and abstention implementation, fostering wider adoption and application in diverse contexts",
    "checked": true,
    "id": "bcdecfa83a1715c03e5c3cddeb27260e9707632b",
    "semantic_title": "towards trustworthy reranking: a simple yet effective abstention mechanism",
    "citation_count": 4,
    "authors": [
      "Hippolyte Gisserot-Boukhlef",
      "Manuel Faysse",
      "Emmanuel Malherbe",
      "CELINE HUDELOT",
      "Pierre Colombo"
    ]
  },
  "https://openreview.net/forum?id=1WqLLYgBNt": {
    "title": "Do not trust what you trust: Miscalibration in Semisupervised Learning",
    "volume": "main",
    "abstract": "State-of-the-art semi-supervised learning (SSL) approaches rely on highly confident predictions to serve as pseudo-labels that guide the training on unlabeled samples. An inherent drawback of this strategy stems from the quality of the uncertainty estimates, as pseudo-labels are filtered only based on their degree of uncertainty, regardless of the correctness of their predictions. Thus, assessing and enhancing the uncertainty of network predictions is of paramount importance in the pseudo-labeling process. In this work, we empirically demonstrate that SSL methods based on pseudo-labels are significantly miscalibrated, and formally demonstrate the minimization of the min-entropy, a lower bound of the Shannon entropy, as a potential cause for miscalibration. To alleviate this issue, we integrate a simple penalty term, which enforces the logit distances of the predictions on unlabeled samples to remain low, preventing the network predictions to become overconfident. Comprehensive experiments on a variety of SSL image classification benchmarks demonstrate that the proposed solution systematically improves the calibration performance of relevant SSL models, while also enhancing their discriminative power, being an appealing addition to tackle SSL tasks",
    "checked": false,
    "id": "165838cb2dcb5617c7d5ab4656ddace03171e20a",
    "semantic_title": "do not trust what you trust: miscalibration in semi-supervised learning",
    "citation_count": 2,
    "authors": [
      "Shambhavi Mishra",
      "Balamurali Murugesan",
      "Ismail Ben Ayed",
      "Marco Pedersoli",
      "Jose Dolz"
    ]
  },
  "https://openreview.net/forum?id=ACMNVwcR6v": {
    "title": "Diffusion Models with Deterministic Normalizing Flow Priors",
    "volume": "main",
    "abstract": "For faster sampling and higher sample quality, we propose DiNof ($\\textbf{Di}$ffusion with $\\textbf{No}$rmalizing $\\textbf{f}$low priors), a technique that makes use of normalizing flows and diffusion models. We use normalizing flows to parameterize the noisy data at any arbitrary step of the diffusion process and utilize it as the prior in the reverse diffusion process. More specifically, the forward noising process turns a data distribution into partially noisy data, which are subsequently transformed into a Gaussian distribution by a nonlinear process. The backward denoising procedure begins with a prior created by sampling from the Gaussian distribution and applying the invertible normalizing flow transformations deterministically. To generate the data distribution, the prior then undergoes the remaining diffusion stochastic denoising procedure. Through the reduction of the number of total diffusion steps, we are able to speed up both the forward and backward processes. More importantly, we improve the expressive power of diffusion models by employing both deterministic and stochastic mappings. Experiments on standard image generation datasets demonstrate the advantage of the proposed method over existing approaches. On the unconditional CIFAR10 dataset, for example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method also demonstrates competitive performance on CelebA-HQ-256 dataset as it obtains an FID score of 7.11. Code is available at $\\href{https://github.com/MohsenZand/DiNof}{https://github.com/MohsenZand/DiNof}$",
    "checked": true,
    "id": "5b36ee7c258c0e488a1d6efb92c6588e492e9c35",
    "semantic_title": "diffusion models with deterministic normalizing flow priors",
    "citation_count": 3,
    "authors": [
      "Mohsen Zand",
      "Ali Etemad",
      "Michael Greenspan"
    ]
  },
  "https://openreview.net/forum?id=TeQRze2ZjO": {
    "title": "Equivariant Graph Learning for High-density Crowd Trajectories Modeling",
    "volume": "main",
    "abstract": "Understanding the high-density crowd dynamics of urbanization plays an important role in architectural design and urban planning, preventing the occurrence of crowd crush. Most traditional methods rely on formulas designed based on expert knowledge, which are inflexible and incomplete to model complex real-world crowd trajectories. To address the issue, recent studies propose to simulate crowds via data-driven models. However, these models fail to learn the inherent symmetry of high-density crowd trajectories, leading to insufficient generalization ability. For example, existing models can not predict left-to-right trajectories by learning right-to-left trajectories, even though they share similar patterns. In this work, we propose a novel Equivariant Graph Learning framework for high-density crowd dynamic modeling, called CrowdEGL. It utilizes an additional objective to encourage models to predict the transformed output given the input under the same transformation. We summarize three types of transformation groups, which are determined by the symmetry of environments. To explicitly incorporate these augmented data, a multi-channel GNN is employed to learn the latent graph embedding of pedestrian patterns. Finally, to model dense crowd interactions, future positions of original and transformed inputs are obtained by multiple independent graph decoders. Extensive experiments on 8 datasets from 5 different environments show that CrowdEGL outperforms existing models by a large margin",
    "checked": true,
    "id": "5a0573ab2bc699c0b54b67be2053973a14e60e66",
    "semantic_title": "equivariant graph learning for high-density crowd trajectories modeling",
    "citation_count": 0,
    "authors": [
      "Yang Liu",
      "Zinan Zheng",
      "Yu Rong",
      "Jia Li"
    ]
  },
  "https://openreview.net/forum?id=3G7mFdGVRW": {
    "title": "Efficient Identification of Direct Causal Parents via Invariance and Minimum Error Testing",
    "volume": "main",
    "abstract": "Invariant causal prediction (ICP) is a popular technique for finding causal parents (direct causes) of a target via exploiting distribution shifts and invariance testing (Peters et al., 2016). However, since ICP needs to run an exponential number of tests and fails to identify parents when distribution shifts only affect a few variables, applying ICP to practical large scale problems is challenging. We propose MMSE-ICP and fastICP, two approaches which employ an error inequality to address the identifiability problem of ICP. The inequality states that the minimum prediction error of the predictor using causal parents is the smallest among all predictors which do not use descendants. fastICP is an efficient approximation tailored for large problems as it exploits the inequality and a heuristic to run fewer tests. MMSE-ICP and fastICP not only outperform competitive baselines in many simulations but also achieve state-of-the-art result on a large scale real data benchmark",
    "checked": true,
    "id": "5190c1d97acff68fd2d0e9970053300d07a3facc",
    "semantic_title": "efficient identification of direct causal parents via invariance and minimum error testing",
    "citation_count": 1,
    "authors": [
      "Minh Nguyen",
      "Mert R. Sabuncu"
    ]
  },
  "https://openreview.net/forum?id=9vEVeX9oIv": {
    "title": "Strategies for Pretraining Neural Operators",
    "volume": "main",
    "abstract": "Pretraining for partial differential equation (PDE) modeling has recently shown promise in scaling neural operators across datasets to improve generalizability and performance. Despite these advances, our understanding of how pretraining affects neural operators is still limited; studies generally propose tailored architectures and datasets that make it challenging to compare or examine different pretraining frameworks. To address this, we compare various pretraining methods without optimizing architecture choices to characterize pretraining dynamics on different models and datasets as well as to understand its scaling and generalization behavior. We find that pretraining is highly dependent on model and dataset choices, but in general transfer learning or physics-based pretraining strategies work best. In addition, pretraining performance can be further improved by using data augmentations. Lastly, pretraining can be additionally beneficial when fine-tuning in scarce data regimes or when generalizing to downstream data similar to the pretraining distribution. Through providing insights into pretraining neural operators for physics prediction, we hope to motivate future work in developing and evaluating pretraining methods for PDEs",
    "checked": true,
    "id": "b775198af561b89e562f258af605c3daa577f748",
    "semantic_title": "strategies for pretraining neural operators",
    "citation_count": 6,
    "authors": [
      "Anthony Zhou",
      "Cooper Lorsung",
      "AmirPouya Hemmasian",
      "Amir Barati Farimani"
    ]
  },
  "https://openreview.net/forum?id=XGAdBXlFcj": {
    "title": "Linear Weight Interpolation Leads to Transient Performance Gains",
    "volume": "main",
    "abstract": "We train copies of a neural network on different sets of SGD noise and find that linearly interpolating their weights can, remarkably, produce networks that perform significantly better than the original networks. However, such interpolated networks consistently end up in unfavorable regions of the optimization landscape: with further training, their performance fails to improve or degrades, effectively undoing the performance gained from the interpolation. We identify two quantities that impact an interpolated network's performance and relate our observations to linear mode connectivity. Finally, we investigate this phenomenon from the lens of example importance and find that performance improves and degrades almost exclusively on the harder subsets of the training data, while performance is stable on the easier subsets. Our work represents a step towards a better understanding of neural network loss landscapes and weight interpolation in deep learning",
    "checked": true,
    "id": "e5efa344110a032dc926daf1527c5101b97abe50",
    "semantic_title": "linear weight interpolation leads to transient performance gains",
    "citation_count": 1,
    "authors": [
      "Gaurav Iyer",
      "Gintare Karolina Dziugaite",
      "David Rolnick"
    ]
  },
  "https://openreview.net/forum?id=lUnlHS1FYT": {
    "title": "A Semi-Bayesian Nonparametric Estimator of the Maximum Mean Discrepancy Measure: Applications in Goodness-of-Fit Testing and Generative Adversarial Networks",
    "volume": "main",
    "abstract": "A classic inferential problem in statistics is the goodness-of-fit (GOF) test. Performing such tests can be challenging when the hypothesized parametric model has an intractable likelihood and its distributional form is not available. Bayesian methods for GOF testing can be appealing due to their ability to incorporate expert knowledge through prior distributions. However, standard Bayesian methods for this test often require strong distributional assumptions on the data and their relevant parameters. To address this issue, we propose a semi-Bayesian nonparametric (semi-BNP) procedure based on the maximum mean discrepancy (MMD) measure that can be applied to the GOF test. We introduce a novel Bayesian estimator for the MMD, which enables the development of a measure-based hypothesis test for intractable models. Through extensive experiments, we demonstrate that our proposed test outperforms frequentist MMD-based methods by achieving a lower false rejection and acceptance rate of the null hypothesis. Furthermore, we showcase the versatility of our approach by embedding the proposed estimator within a generative adversarial network (GAN) framework. It facilitates a robust BNP learning approach as another significant application of our method. With our BNP procedure, this new GAN approach can enhance sample diversity and improve inferential accuracy compared to traditional techniques",
    "checked": true,
    "id": "a5e1446febfaf4e137d049ecca47c7b50e78ee0c",
    "semantic_title": "a semi-bayesian nonparametric estimator of the maximum mean discrepancy measure: applications in goodness-of-fit testing and generative adversarial networks",
    "citation_count": 1,
    "authors": [
      "Forough Fazeli-Asl",
      "Michael Minyi Zhang",
      "Lizhen Lin"
    ]
  },
  "https://openreview.net/forum?id=vNZlnznmV2": {
    "title": "Learning Hierarchical Relational Representations through Relational Convolutions",
    "volume": "main",
    "abstract": "An evolving area of research in deep learning is the study of architectures and inductive biases that support the learning of relational feature representations. In this paper, we address the challenge of learning representations of hierarchical relationsâthat is, higher-order relational patterns among groups of objects. We introduce \"relational convolutional networks\", a neural architecture equipped with computational mechanisms that capture progressively more complex relational features through the composition of simple modules. A key component of this framework is a novel operation that captures relational patterns in groups of objects by convolving graphlet filtersâlearnable templates of relational patternsâagainst subsets of the input. Composing relational convolutions gives rise to a deep architecture that learns representations of higher-order, hierarchical relations. We present the motivation and details of the architecture, together with a set of experiments to demonstrate how relational convolutional networks can provide an effective framework for modeling relational tasks that have hierarchical structure",
    "checked": true,
    "id": "c090df2d56fbf9b953a4c6868cb196abac110b84",
    "semantic_title": "learning hierarchical relational representations through relational convolutions",
    "citation_count": 2,
    "authors": [
      "Awni Altabaa",
      "John Lafferty"
    ]
  },
  "https://openreview.net/forum?id=6DflIABPQP": {
    "title": "The Impact of Syntactic and Semantic Proximity on Machine Translation with Back-Translation",
    "volume": "main",
    "abstract": "Unsupervised on-the-fly back-translation, in conjunction with multilingual pretraining, is the dominant method for unsupervised neural machine translation. Theoretically, however, the method should not work in general. We therefore conduct controlled experiments with artificial languages to determine what properties of languages make back-translation an effective training method, covering lexical, syntactic, and semantic properties. We find, contrary to popular belief, that (i)~parallel word frequency distributions, (ii)~partially shared vocabulary, and (iii)~similar syntactic structure across languages are not sufficient to explain the success of back-translation. We show however that even crude semantic signal (similar lexical fields across languages) does improve alignment of two languages through back-translation. We conjecture that rich semantic dependencies, parallel across languages, are at the root of the success of unsupervised methods based on back-translation. Overall, the success of unsupervised machine translation was far from being analytically guaranteed. Instead, it is another proof that languages of the world share deep similarities, and we hope to show how to identify which of these similarities can serve the development of unsupervised, cross-linguistic tools",
    "checked": true,
    "id": "b0a0efc32e5493bd1aa42472ea973aaf0a367293",
    "semantic_title": "the impact of syntactic and semantic proximity on machine translation with back-translation",
    "citation_count": 2,
    "authors": [
      "Nicolas Guerin",
      "Emmanuel Chemla",
      "Shane Steinert-Threlkeld"
    ]
  },
  "https://openreview.net/forum?id=MP8bmxvWt6": {
    "title": "Improving Generalization of Complex Models under Unbounded Loss Using PAC-Bayes Bounds",
    "volume": "main",
    "abstract": "Previous research on PAC-Bayes learning theory has focused extensively on establishing tight upper bounds for test errors. A recently proposed training procedure called PAC-Bayes training, updates the model toward minimizing these bounds. Although this approach is theoretically sound, in practice, it has not achieved a test error as low as those obtained by empirical risk minimization (ERM) with carefully tuned regularization hyperparameters. Additionally, existing PAC-Bayes training algorithms often require bounded loss functions and may need a search over priors with additional datasets, which limits their broader applicability. In this paper, we introduce a new PAC-Bayes training algorithm with improved performance and reduced reliance on prior tuning. This is achieved by establishing a new PAC-Bayes bound for unbounded loss and a theoretically grounded approach that involves jointly training the prior and posterior using the same dataset. Our comprehensive evaluations across various classification tasks and neural network architectures demonstrate that the proposed method not only outperforms existing PAC-Bayes training algorithms but also approximately matches the test accuracy of ERM that is optimized by SGD/Adam using various regularization methods with optimal hyperparameters",
    "checked": true,
    "id": "d54191a9c1e4e7b46b40ae87ed27a8592280a520",
    "semantic_title": "improving generalization of complex models under unbounded loss using pac-bayes bounds",
    "citation_count": 3,
    "authors": [
      "Xitong Zhang",
      "Avrajit Ghosh",
      "Guangliang Liu",
      "Rongrong Wang"
    ]
  },
  "https://openreview.net/forum?id=l0Uum9SJgM": {
    "title": "Contrastive Class Anchor Learning for Open Set Object Recognition in Driving Scenes",
    "volume": "main",
    "abstract": "Conventional object recognition models operate under closed-set assumptions presuming that the training dataset is sufficiently comprehensive that any object detected during inference can be assigned to some known prior class. This assumption is flawed and potentially dangerous for real-world applications such as driving scene perception where diverse objects and unexpected behaviours should be expected. In order to progress towards trusted autonomous platforms object recognition models need Open Set Recognition (OSR) methods capable of identifying unknown classes while maintaining good performance on known classes. Existing OSR methods are mostly designed for image data and utilize generative models which are hard to train. In this paper, we propose S2CA, a Supervised Contrastive Class Anchor learning method which leverages contrastive learning principles to effectively reject unknown classes by increasing intra-class compactness and inter-class sparsity of known classes in feature space. We train a feature encoder through contrastive learning while ensuring that features of known classes form compact clusters, and then transfer the trained encoder to the OSR task. During inference, the model rejects unknown classes based on class-agnostic information in feature space and class-related information in logit space. The proposed OSR method is simple yet powerful. It is not only suitable for image-based object recognition models, but can also be used for a variety of lidar-based object recognition models. We demonstrate superior performance of S2CA when compared with state of the art methods on two widely used driving scene recognition datasets, i.e., KITTI and nuScenes",
    "checked": true,
    "id": "0c15fd48e37aa02556e3d03979f944dfb005a1bc",
    "semantic_title": "contrastive class anchor learning for open set object recognition in driving scenes",
    "citation_count": 1,
    "authors": [
      "Zizhao Li",
      "Kourosh Khoshelham",
      "Joseph West"
    ]
  },
  "https://openreview.net/forum?id=38P40gJPrI": {
    "title": "Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model",
    "volume": "main",
    "abstract": "Current state-of-the-art diffusion models employ U-Net architectures containing convolutional and (qkv) self-attention layers. The U-Net processes images while being conditioned on the time embedding input for each sampling step and the class or caption embedding input corresponding to the desired conditional generation. Such conditioning involves scale-and-shift operations to the convolutional layers but does not directly affect the attention layers. While these standard architectural choices are certainly effective, not conditioning the attention layers feels arbitrary and potentially suboptimal. In this work, we show that simply adding LoRA conditioning to the attention layers without changing or tuning the other parts of the U-Net architecture improves the image generation quality. For example, a drop-in addition of LoRA conditioning to EDM diffusion model yields FID scores of 1.91/1.75 for unconditional and class-conditional CIFAR-10 generation, improving upon the baseline of 1.97/1.79",
    "checked": true,
    "id": "c87f3cd6f2e5499331b3dae55d594dfe7efa872e",
    "semantic_title": "simple drop-in lora conditioning on attention layers will improve your diffusion model",
    "citation_count": 5,
    "authors": [
      "Joo Young Choi",
      "Jaesung R. Park",
      "Inkyu Park",
      "Jaewoong Cho",
      "Albert No",
      "Ernest K. Ryu"
    ]
  },
  "https://openreview.net/forum?id=tgFHZMsl1N": {
    "title": "On Safety in Safe Bayesian Optimization",
    "volume": "main",
    "abstract": "Safe Bayesian Optimization (BO) is increasingly used to optimize an unknown function under safety constraints, a central task in robotics, biomedical engineering, and many other disciplines. Due to the safety-critical nature of these applications, it is crucial that theoretical safety guarantees for these algorithms translate into the real world. In this work, we investigate three safety-related issues in SafeOpt-type algorithms, a popular class of safe BO methods. First, these algorithms critically rely on frequentist uncertainty bounds for Gaussian Process (GP) regression, but concrete implementations typically utilize heuristics that invalidate all safety guarantees. We provide a detailed analysis of this problem and introduce Real-$\\beta$-SafeOpt, a variant of the SafeOpt algorithm that leverages recent GP bounds and thus retains all theoretical guarantees. Second, we identify a key technical assumption in SafeOpt-like algorithms, the availability of an upper bound on the reproducing kernel Hilbert space (RKHS) norm of the target function, as a central obstacle to real-world usage. To address this issue, we propose to rely instead on a known Lipschitz and noise bound, and we introduce Lipschitz-only Safe Bayesian Optimization (LoSBO), a SafeOpt-type algorithm using the latter two assumptions. We show empirically that this algorithm is not only safe, but also outperforms the state-of-the-art on several function classes. Third, SafeOpt and derived algorithms rely on a %gridding of the search space, discrete search space, complicating their application to higher-dimensional problems. To broaden the applicability of these algorithms, we introduce Lipschitz-only Safe GP-UCB (LoS-GP-UCB), a LoSBO variant that is applicable to moderately high-dimensional problems, while retaining safety. By analyzing practical safety issues in an important class of safe BO algorithms, and providing ready-to-use algorithms that overcome these issues, this work contributes to bringing safe and reliable machine learning techniques closer to real world applications",
    "checked": true,
    "id": "5893f00546f6a9cc8d2c4c65c4daa7563ddb149c",
    "semantic_title": "on safety in safe bayesian optimization",
    "citation_count": 11,
    "authors": [
      "Christian Fiedler",
      "Johanna Menn",
      "Lukas KreiskÃ¶ther",
      "Sebastian Trimpe"
    ]
  },
  "https://openreview.net/forum?id=qBTgnk2HAf": {
    "title": "IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks",
    "volume": "main",
    "abstract": "In-context learning allows adapting a model to new tasks given a task description at test time. In this paper, we present IMProv - a generative model that is able to in-context learn visual tasks from multimodal prompts. Given a textual description of a visual task (e.g. \"Left: input image, Right: foreground segmentation\"), a few input-output visual examples, or both, the model in-context learns to solve it for a new test input. We train a masked generative transformer on a new dataset of figures from computer vision papers and their associated captions, together with a captioned large-scale image-text dataset. During inference time, we prompt the model with text and/or image task example(s) and have the model inpaint the corresponding output. We show that training our model with text conditioning and scaling the dataset size improves in-context learning for computer vision tasks by over $+10\\%$ AP for Foreground Segmentation, over $+5\\%$ gains in AP for Single Object Detection, and almost $20\\%$ lower LPIPS in Colorization. Our emperical results suggest that vision and language prompts are complementary and it is advantageous to use both to achieve better in-context learning performance",
    "checked": true,
    "id": "604f60f3a73710e8e3ef436d49c8bcbe0249cf22",
    "semantic_title": "improv: inpainting-based multimodal prompting for computer vision tasks",
    "citation_count": 3,
    "authors": [
      "Jiarui Xu",
      "Yossi Gandelsman",
      "Amir Bar",
      "Jianwei Yang",
      "Jianfeng Gao",
      "Trevor Darrell",
      "Xiaolong Wang"
    ]
  },
  "https://openreview.net/forum?id=BKwGowR0Bt": {
    "title": "Adversarial Attacks on Online Learning to Rank with Stochastic Click Models",
    "volume": "main",
    "abstract": "We propose the first study of adversarial attacks on online learning to rank. The goal of the attacker it to misguide the online learning to rank algorithm to place the target item on top of the ranking list linear times to time horizon $T$ with a sublinear attack cost. We propose generalized list poisoning attacks that perturb the ranking list presented to the user. This strategy can efficiently attack any no-regret ranker in general stochastic click models. Furthermore, we propose a click poisoning-based strategy named attack-then-quit that can efficiently attack two representative OLTR algorithms for stochastic click models. We theoretically analyze the success and cost upper bound of the two proposed methods. Experimental results based on synthetic and real-world data further validate the effectiveness and cost-efficiency of the proposed attack strategies",
    "checked": true,
    "id": "9a10a8fc9f02a4580832f15a801bb840f8b0b6d6",
    "semantic_title": "adversarial attacks on online learning to rank with stochastic click models",
    "citation_count": 3,
    "authors": [
      "Zichen Wang",
      "Rishab Balasubramanian",
      "Hui Yuan",
      "chenyu song",
      "Mengdi Wang",
      "Huazheng Wang"
    ]
  },
  "https://openreview.net/forum?id=64HdQKnyTc": {
    "title": "Non-backtracking Graph Neural Networks",
    "volume": "main",
    "abstract": "The celebrated message-passing updates for graph neural networks allow representing large-scale graphs with local and computationally tractable updates. However, the updates suffer from backtracking, i.e., a message flowing through the same edge twice and revisiting the previously visited node. Since the number of message flows increases exponentially with the number of updates, the redundancy in local updates prevents the graph neural network from accurately recognizing a particular message flow relevant for downstream tasks. In this work, we propose to resolve such a redundancy issue via the non-backtracking graph neural network (NBA-GNN) that updates a message without incorporating the message from the previously visited node. We theoretically investigate how NBA-GNN alleviates the over-squashing of GNNs, and establish a connection between NBA-GNN and the impressive performance of non-backtracking updates for stochastic block model recovery. Furthermore, we empirically verify the effectiveness of our NBA-GNN on the long-range graph benchmark and transductive node classification problems",
    "checked": true,
    "id": "8b0135586ebc3402ae284b7a560a35a53f25a3e5",
    "semantic_title": "non-backtracking graph neural networks",
    "citation_count": 4,
    "authors": [
      "Seonghyun Park",
      "Narae Ryu",
      "Gahee Kim",
      "Dongyeop Woo",
      "Se-Young Yun",
      "Sungsoo Ahn"
    ]
  },
  "https://openreview.net/forum?id=UG7rtrsuaT": {
    "title": "Graph Cuts with Arbitrary Size Constraints Through Optimal Transport",
    "volume": "main",
    "abstract": "A common way of partitioning graphs is through minimum cuts. One drawback of classical minimum cut methods is that they tend to produce small groups, which is why more balanced variants such as normalized and ratio cuts have seen more success. However, we believe that with these variants, the balance constraints can be too restrictive for some applications like for clustering of imbalanced datasets, while not being restrictive enough for when searching for perfectly balanced partitions. Here, we propose a new graph cut algorithm for partitioning graphs under arbitrary size constraints. We formulate the graph cut problem as a Gromov-Wasserstein with a concave regularizer problem. We then propose to solve it using an accelerated proximal GD algorithm which guarantees global convergence to a critical point, results in sparse solutions and only incurs an additional ratio of $\\mathcal{O}(\\log(n))$ compared to the classical spectral clustering algorithm but was seen to be more efficient",
    "checked": true,
    "id": "b117fd94ef00deaa11ffaad92eacbd904753d5cd",
    "semantic_title": "graph cuts with arbitrary size constraints through optimal transport",
    "citation_count": 1,
    "authors": [
      "Chakib Fettal",
      "lazhar labiod",
      "Mohamed Nadif"
    ]
  },
  "https://openreview.net/forum?id=h2jpFufyG4": {
    "title": "Reward Poisoning on Federated Reinforcement Learning",
    "volume": "main",
    "abstract": "Federated learning (FL) has become a popular tool for solving traditional Reinforcement Learning (RL) tasks. The multi-agent structure addresses the major concern of data-hungry in traditional RL, while the federated mechanism protects the data privacy of individual agents. Despite the advantage FL brings to RL, Federated Reinforcement Learning (FRL) is inherently susceptible to poisoning, as both FL and RL are vulnerable to such training-time attacks; however, the vulnerability of FRL has not been well-studied before. In this work, we propose a general framework to characterize FRL poisoning as an optimization problem and design a poisoning protocol that can be applied to policy-based FRL. Our framework is versatile, catering to FRL scenarios employing both policy-gradient local RL and actor-critic local RL. In the context of actor-critic configurations, we conduct training for a pair of critics, one private and one public, aimed at maximizing the potency of poisoning. We provably show that our method can strictly hurt the global objective. We verify the effectiveness of our poisoning approach through comprehensive experiments, supported by mainstream RL algorithms, across various RL OpenAI Gym environments covering a wide range of difficulty levels. Within these experiments, we assess our proposed attack by comparing it to various baselines, including standard, poisoned, and robust FRL methods. The results demonstrate the power of the proposed protocol in effectively poisoning FRL systems â It consistently diminishes performance across diverse environments, proving to be more effective than baseline methods. Our work provides new insights into the training-time vulnerability of FL in RL and poses new challenges for designing secure FRL algorithms",
    "checked": true,
    "id": "20cd07e03435df59ced61d13b4de0989f523e930",
    "semantic_title": "reward poisoning on federated reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Evelyn Ma",
      "S. Rasoul Etesami",
      "Praneet Rathi"
    ]
  },
  "https://openreview.net/forum?id=mTOzXLmLKr": {
    "title": "Variational Inference on the Final-Layer Output of Neural Networks",
    "volume": "main",
    "abstract": "Traditional neural networks are simple to train but they typically produce overconfident predictions. In contrast, Bayesian neural networks provide good uncertainty quantification but optimizing them is time consuming due to the large parameter space. This paper proposes to combine the advantages of both approaches by performing Variational Inference in the Final layer Output space (VIFO), because the output space is much smaller than the parameter space. We use neural networks to learn the mean and the variance of the probabilistic output. Using the Bayesian formulation we incorporate collapsed variational inference with VIFO which significantly improves the performance in practice. On the other hand, like standard, non-Bayesian models, VIFO enjoys simple training and one can use Rademacher complexity to provide risk bounds for the model. Experiments show that VIFO provides a good tradeoff in terms of run time and uncertainty quantification, especially for out of distribution data",
    "checked": true,
    "id": "a55fe058b8bc335fd5162494ea24f30b300c3a3c",
    "semantic_title": "variational inference on the final-layer output of neural networks",
    "citation_count": 0,
    "authors": [
      "Yadi Wei",
      "Roni Khardon"
    ]
  },
  "https://openreview.net/forum?id=kLo4TKh0OP": {
    "title": "Conservative Evaluation of Offline Policy Learning",
    "volume": "main",
    "abstract": "The world offers unprecedented amounts of data in real-world domains, from which we can develop successful decision-making systems. It is possible for reinforcement learning (RL) to learn control policies offline from such data but challenging to deploy an agent during learning in safety-critical domains. Offline RL learns from historical data without access to an environment. Therefore, we need a methodology for estimating how a newly-learned agent will perform when deployed in the real environment \\emph{before} actually deploying it. To achieve this, we propose a framework for conservative evaluation of offline policy learning (CEOPL). We focus on being conservative so that the probability that our agent performs below a baseline is approximately $\\delta$, where $\\delta$ specifies how much risk we are willing to accept. In our setting, we assume access to a data stream, split into a train-set to learn an offline policy, and a test-set to estimate a lower-bound on the offline policy using off-policy evaluation with bootstrap confidence intervals. A lower-bound estimate allows us to decide when to deploy our learned policy with minimal risk of overestimation. We demonstrate CEOPL on a range of tasks as well as real-world medical data",
    "checked": true,
    "id": "98ca6cbd88ccd07982ae9a08156dc8c731011775",
    "semantic_title": "conservative evaluation of offline policy learning",
    "citation_count": 0,
    "authors": [
      "Hager Radi Abdelwahed",
      "Josiah P. Hanna",
      "Matthew E. Taylor"
    ]
  },
  "https://openreview.net/forum?id=ycOLyHh1Ue": {
    "title": "Decomposition of Equivariant Maps via Invariant Maps: Application to Universal Approximation under Symmetry",
    "volume": "main",
    "abstract": "In this paper, we develop a theory about the relationship between invariant and equivariant maps with regard to a group $G$. We then leverage this theory in the context of deep neural networks with group symmetries in order to obtain novel insight into their mechanisms. More precisely, we establish a one-to-one relationship between equivariant maps and certain invariant maps. This allows us to reduce arguments for equivariant maps to those for invariant maps and vice versa. As an application, we propose a construction of universal equivariant architectures built from universal invariant networks. We, in turn, explain how the universal architectures arising from our construction differ from standard equivariant architectures known to be universal. Furthermore, we explore the complexity, in terms of the number of free parameters, of our models, and discuss the relation between invariant and equivariant networks' complexity. Finally, we also give an approximation rate for $G$-equivariant deep neural networks with ReLU activation functions for finite group $G$",
    "checked": true,
    "id": "2958b141b766933f8fe12e1a1b2b88921bea0d53",
    "semantic_title": "decomposition of equivariant maps via invariant maps: application to universal approximation under symmetry",
    "citation_count": 0,
    "authors": [
      "Akiyoshi Sannai",
      "Yuuki Takai",
      "Matthieu Cordonnier"
    ]
  },
  "https://openreview.net/forum?id=EIPnUofed9": {
    "title": "Threshold Moving for Online Class Imbalance Learning with Dynamic Evolutionary Cost Vector",
    "volume": "main",
    "abstract": "Existing online class imbalance learning methods fail to achieve optimal performance because their assumptions about enhancing minority classes are hard-coded in model parameters. To learn the model for the performance measure directly instead of using heuristics, we introduce a novel framework based on a dynamic EA called Online Evolutionary Cost Vector (OECV). By bringing the threshold moving method from the cost-sensitive learning paradigm and viewing the cost vector as a hyperparameter, our method transforms the online class imbalance issue into a bi-level optimization problem. The lower layer utilizes a base online classifier for rough prediction, and the upper layer refines the prediction using a threshold moving cost vector learned via a dynamic evolutionary algorithm (EA). OECV benefits from both the efficiency of online learning methods and the high performance of EA, as demonstrated in empirical studies against state-of-the-art methods on thirty datasets. Additionally, we show the effectiveness of the EA component in the ablation study by comparing OECV to its two variants, OECV-n and OECV-ea, respectively. This work reveals the superiority of incorporating EA into online imbalance classification tasks, while its potential extends beyond the scope of the class imbalance setting and warrants future research attention. We release our code for future research",
    "checked": true,
    "id": "c28017e60f33e6f6398bde99a3a1a80a1fad3062",
    "semantic_title": "threshold moving for online class imbalance learning with dynamic evolutionary cost vector",
    "citation_count": 0,
    "authors": [
      "Peijia Qin",
      "Shuxian Li",
      "Xiaoqun Liu",
      "Zubin Zheng",
      "Siang Yew Chong"
    ]
  },
  "https://openreview.net/forum?id=vsZ5A3Zxyr": {
    "title": "Continual Adaptation of Vision Transformers for Federated Learning",
    "volume": "main",
    "abstract": "In this paper, we focus on the important yet understudied problem of Continual Federated Learning (CFL), where a server communicates with a set of clients to incrementally learn new concepts over time without sharing or storing any data. The complexity of this problem is compounded by challenges from both the Continual and Federated Learning perspectives. Specifically, models trained in a CFL setup suffer from catastrophic forgetting which is exacerbated by data heterogeneity across clients. Existing attempts at this problem tend to impose large overheads on clients and communication channels or require access to stored data which renders them unsuitable for real-world use due to privacy. In this paper, we attempt to tackle forgetting and heterogeneity while minimizing overhead costs and without requiring access to any stored data. We study this problem in the context of Vision Transformers and explore parameter-efficient approaches to adapt to dynamic distributions while minimizing forgetting. We achieve this by leveraging a prompting based approach (such that only prompts and classifier heads have to be communicated) and proposing a novel and lightweight generation and distillation scheme to consolidate client models at the server. We formulate this problem for image classification and establish strong baselines for comparison, conduct experiments on CIFAR-100 as well as challenging, large-scale datasets like ImageNet-R and DomainNet. Our approach outperforms both existing methods and our own baselines by as much as 7% while significantly reducing communication and client-level computation costs. Code available at https://github.com/shaunak27/hepco-fed",
    "checked": true,
    "id": "42617d8ae50efab1a09f91107be5ae5227b8e892",
    "semantic_title": "continual adaptation of vision transformers for federated learning",
    "citation_count": 8,
    "authors": [
      "Shaunak Halbe",
      "James Seale Smith",
      "Junjiao Tian",
      "Zsolt Kira"
    ]
  },
  "https://openreview.net/forum?id=2rnTIBm19V": {
    "title": "M$^3$PL: Identifying and Exploiting View Bias of Prompt Learning",
    "volume": "main",
    "abstract": "Prompt learning is an effective means of fine-tuning multi-modal foundation models such as CLIP. Despite existing success, the inner mechanism of multi-modal prompt learning has not been well understood. In this work, we identify an inductive bias of multi-modal prompt learning, which we refer to as view bias, that the learned prompts may extract only a partial subset of useful features (views) and ignore others. This bias can undermine the model's generalization ability, particularly under distribution shifts. We further observe that independently trained prompts have distinct view biases, contrary to the existing belief that they may converge to similar local optima due to having the same cross-modal representation matching objective. Based on our observations, we propose Multi-modal Matching Multi-Prompt Learning (M$^3$PL), which incorporates multiple paired prompts and a cross-modal contrastive regularizer that facilitates the prompt pairs to encapsulate a broader spectrum of views. Extensive experiments show that M$^3$PL effectively boosts the model's generalization capability, achieving state-of-the-art performance under various distribution shifts",
    "checked": false,
    "id": "d4fe9b37399741423986771425169c82a439d107",
    "semantic_title": "m3pl: identifying and exploiting view bias of prompt learning",
    "citation_count": 1,
    "authors": [
      "Chujie Zhao",
      "Tianren Zhang",
      "Guanyu Chen",
      "Yizhou Jiang",
      "Feng Chen"
    ]
  },
  "https://openreview.net/forum?id=a13aYUU9eU": {
    "title": "RLHF Workflow: From Reward Modeling to Online RLHF",
    "volume": "main",
    "abstract": "We present the workflow of Online Iterative Reinforcement Learning from Human Feedback (RLHF) in this technical report, which is widely reported to outperform its offline counterpart by a large margin in the recent large language model (LLM) literature. However, existing open-source RLHF projects are still largely confined to the offline learning setting. In this technical report, we aim to fill in this gap and provide a detailed recipe that is easy to reproduce for online iterative RLHF. In particular, since online human feedback is usually infeasible for open-source communities with limited resources, we start by constructing preference models using a diverse set of open-source datasets and use the constructed proxy preference model to approximate human feedback. Then, we discuss the theoretical insights and algorithmic principles behind online iterative RLHF, followed by a detailed practical implementation. Our trained LLM achieves impressive performance on LLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as well as other academic benchmarks such as HumanEval and TruthfulQA. We have shown that supervised fine-tuning (SFT) and iterative RLHF can obtain state-of-the-art performance with fully open-source datasets. Further, we have made our models, curated datasets, and comprehensive step-by-step code guidebooks publicly available",
    "checked": true,
    "id": "1e53e98e8709748a6385137d8f240787c12fcfd4",
    "semantic_title": "rlhf workflow: from reward modeling to online rlhf",
    "citation_count": 132,
    "authors": [
      "Hanze Dong",
      "Wei Xiong",
      "Bo Pang",
      "Haoxiang Wang",
      "Han Zhao",
      "Yingbo Zhou",
      "Nan Jiang",
      "Doyen Sahoo",
      "Caiming Xiong",
      "Tong Zhang"
    ]
  },
  "https://openreview.net/forum?id=cGpegxy12T": {
    "title": "Calibrated Uncertainty Quantification for Operator Learning via Conformal Prediction",
    "volume": "main",
    "abstract": "Operator learning has been increasingly adopted in scientific and engineering applications, many of which require calibrated uncertainty quantification. Since the output of operator learning is a continuous function, quantifying uncertainty simultaneously at all points in the domain is challenging. Current methods consider calibration at a single point or over one scalar function or make strong assumptions such as Gaussianity. We propose a risk-controlling quantile neural operator, a distribution-free, finite-sample functional calibration conformal prediction method. We provide a theoretical calibration guarantee on the coverage rate, defined as the expected percentage of points on the function domain whose true value lies within the predicted uncertainty ball. Empirical results on a 2D Darcy flow and a 3D car surface pressure prediction task validate our theoretical results, demonstrating calibrated coverage and efficient uncertainty bands outperforming baseline methods. In particular, on the 3D problem, our method is the only one that meets the target calibration percentage (percentage of test samples for which the uncertainty estimates are calibrated) of 98%. Code is available at https://github.com/neuraloperator/neuraloperator/blob/main/scripts/train_uqno_darcy.py",
    "checked": true,
    "id": "80c3c05706b03a2f73594975e1906cda74cca643",
    "semantic_title": "calibrated uncertainty quantification for operator learning via conformal prediction",
    "citation_count": 8,
    "authors": [
      "Ziqi Ma",
      "David Pitt",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=aY2nsgE97a": {
    "title": "Learned feature representations are biased by complexity, learning order, position, and more",
    "volume": "main",
    "abstract": "Representation learning, and interpreting learned representations, are key areas of focus in machine learning and neuroscience. Both fields generally use representations as a means to understand or improve a system's computations. In this work, however, we explore surprising dissociations between representation and computation that may pose challenges for such efforts. We create datasets in which we attempt to match the computational role that different features play, while manipulating other properties of the features or the data. We train various deep learning architectures to compute these multiple abstract features about their inputs. We find that their learned feature representations are systematically biased towards representing some features more strongly than others, depending upon extraneous properties such as feature complexity, the order in which features are learned, and the distribution of features over the inputs. For example, features that are simpler to compute or learned first tend to be represented more strongly and densely than features that are more complex or learned later, even if all features are learned equally well. We also explore how these biases are affected by architectures, optimizers, and training regimes (e.g., in transformers, features decoded earlier in the output sequence also tend to be represented more strongly). Our results help to characterize the inductive biases of gradient-based representation learning. We then illustrate the downstream effects of these biases on various commonly-used methods for analyzing or intervening on representations. These results highlight a key challenge for interpretability---or for comparing the representations of models and brains---disentangling extraneous biases from the computationally important aspects of a system's internal representations",
    "checked": true,
    "id": "d3942757c6760c2ebb55f3c5254b81f110a68e3b",
    "semantic_title": "learned feature representations are biased by complexity, learning order, position, and more",
    "citation_count": 9,
    "authors": [
      "Andrew Kyle Lampinen",
      "Stephanie C.Y. Chan",
      "Katherine Hermann"
    ]
  },
  "https://openreview.net/forum?id=FR8dvo6q8i": {
    "title": "Prioritized Federated Learning: Leveraging Non-Priority Clients for Targeted Model Improvement",
    "volume": "main",
    "abstract": "Federated Learning (FL) is a distributed machine learning approach to learn models on decentralized heterogeneous data, without the need for clients to share their data. Many existing FL approaches assume that all clients have equal importance and construct a global objective based on all clients. We consider a version of FL we call Prioritized FL, where the goal is to learn a weighted mean objective of a subset of clients, designated as priority clients. An important question arises: How do we choose well-aligned non-priority clients to participate in the federation, while discarding misaligned clients? We present FedALIGN (Federated Adaptive Learning with Inclusion of Global Needs) to address this challenge. The algorithm employs a matching strategy that chooses non-priority clients based on how similar the model's loss is on their data compared to the global data, thereby ensuring the use of non-priority client gradients only when it is beneficial for priority clients. This approach ensures mutual benefits as non-priority clients are motivated to join when the model performs satisfactorily on their data, and priority clients can utilize their updates and computational resources when their goals align. We present a convergence analysis that quantifies the trade-off between client selection and speed of convergence. Our algorithm shows faster convergence and higher test accuracy than baselines for various synthetic and benchmark datasets",
    "checked": true,
    "id": "aa3369d4741c8b0b467a0c963bfe668fa02b4245",
    "semantic_title": "prioritized federated learning: leveraging non-priority clients for targeted model improvement",
    "citation_count": 0,
    "authors": [
      "Aditya Narayan Ravi",
      "Ilan Shomorony"
    ]
  },
  "https://openreview.net/forum?id=B6RS6DN0Gt": {
    "title": "HiFE: Hierarchical Feature Ensemble Framework for Few-shot Hypotheses Adaptation",
    "volume": "main",
    "abstract": "The process of transferring knowledge from a source domain to a target domain in the absence of source data constitutes a formidable obstacle within the field of source-free domain adaptation, often termed hypothesis adaptation. Conventional methodologies have been dependent on a robustly trained (strong) source hypothesis to encapsulate the knowledge pertinent to the source domain. However, this strong hypothesis is prone to overfitting the source domain, resulting in diminished generalization performance when applied to the target domain. To mitigate this issue, we advocate for the augmentation of transferable source knowledge via the integration of multiple (weak) source models that are underfitting. Furthermore, we propose a novel architectural framework, designated as the Hierarchical Feature Ensemble (HiFE) framework for Few-Shot Hypotheses Adaptation, which amalgamates features from both the strong and intentionally underfit source models. Empirical evidence from our experiments indicates that these weaker models, while not optimal within the source domain context, contribute to an enhanced generalization capacity of the resultant model for the target domain. Moreover, the HiFE framework we introduce demonstrates superior performance, surpassing other leading baselines across a spectrum of few-shot hypothesis adaptation scenarios",
    "checked": true,
    "id": "bdf6acec8151c0e7a48dabaa5de638e3d036debe",
    "semantic_title": "hife: hierarchical feature ensemble framework for few-shot hypotheses adaptation",
    "citation_count": 0,
    "authors": [
      "Yongfeng Zhong",
      "Haoang Chi",
      "Feng Liu",
      "Xiao-Ming Wu",
      "Bo Han"
    ]
  },
  "https://openreview.net/forum?id=APON4bslQC": {
    "title": "Attribute Graphs Underlying Molecular Generative Models: Path to Learning with Limited Data",
    "volume": "main",
    "abstract": "Training generative models that capture rich semantics of the data and interpreting the latent representations encoded by such models are very important problems in un-/self-supervised learning. In this work, we provide a simple algorithm that relies on perturbation experiments on latent codes of a pre-trained generative autoencoder to uncover an attribute graph that is implied by the generative model. We perform perturbation experiments to check for influence of a given latent variable on a subset of attributes. Given this, we show that one can fit an effective graphical model that models a structural equation model between latent codes taken as exogenous variables and attributes taken as observed variables. One interesting aspect is that a single latent variable controls multiple overlapping subsets of attributes unlike conventional approaches that try to impose full independence. Using a pre-trained generative autoencoder trained on a large dataset of small molecules, we demonstrate that the graphical model between various molecular attributes and latent codes learned by our algorithm can be used to predict a specific property for molecules which are drawn from a different distribution. We compare prediction models trained on various feature subsets chosen by simple baselines, as well as existing causal discovery and sparse learning/feature selection methods, with the ones in the derived Markov blanket from our method. Results show empirically that the predictor that relies on our Markov blanket attributes is robust to distribution shifts when transferred or fine-tuned with a few samples from the new distribution, especially when training data is limited",
    "checked": true,
    "id": "c79d949cbd683433db4639844a15d670f1dfbe46",
    "semantic_title": "attribute graphs underlying molecular generative models: path to learning with limited data",
    "citation_count": 2,
    "authors": [
      "Samuel C Hoffman",
      "Payel Das",
      "Karthikeyan Shanmugam",
      "Kahini Wadhawan",
      "Prasanna Sattigeri"
    ]
  },
  "https://openreview.net/forum?id=E0NPcsEZ2f": {
    "title": "Identifiable Causal Inference with Noisy Treatment and No Side Information",
    "volume": "main",
    "abstract": "In some causal inference scenarios, the treatment variable is measured inaccurately, for instance in epidemiology or econometrics. Failure to correct for the effect of this measurement error can lead to biased causal effect estimates. Previous research has not studied methods that address this issue from a causal viewpoint while allowing for complex nonlinear dependencies and without assuming access to side information. For such a scenario, this study proposes a model that assumes a continuous treatment variable that is inaccurately measured. Building on existing results for measurement error models, we prove that our model's causal effect estimates are identifiable, even without side information and knowledge of the measurement error variance. Our method relies on a deep latent variable model in which Gaussian conditionals are parameterized by neural networks, and we develop an amortized importance-weighted variational objective for training the model. Empirical results demonstrate the method's good performance with unknown measurement error. More broadly, our work extends the range of applications in which reliable causal inference can be conducted",
    "checked": true,
    "id": "02c781cbe8f7853c960d92225af6bf1822cbdc32",
    "semantic_title": "identifiable causal inference with noisy treatment and no side information",
    "citation_count": 2,
    "authors": [
      "Antti PÃ¶llÃ¤nen",
      "Pekka Marttinen"
    ]
  },
  "https://openreview.net/forum?id=sGTfxqRbei": {
    "title": "Hierarchically branched diffusion models leverage dataset structure for class-conditional generation",
    "volume": "main",
    "abstract": "Diffusion models have attained state-of-the-art performance in generating realistic objects, including when conditioning generation on class labels. Current class-conditional diffusion models, however, implicitly model the diffusion process on all classes in a flat fashion, ignoring any known relationships between classes. Class-labeled datasets, including those common in scientific domains, are rife with internal structure. To take advantage of this structure, we propose hierarchically branched diffusion models as a novel framework for class-conditional generation. Branched diffusion models explicitly leverage the inherent relationships between distinct classes in the dataset to learn the underlying diffusion process in a hierarchical manner. We highlight several advantages of branched diffusion models over the current state-of-the-art methods for class-conditional diffusion. Firstly, they can be easily extended to novel classes in a continual-learning setting at scale. Secondly, they enable more sophisticated forms of conditional generation, such as analogy-based conditional generation (i.e. transmutation). Finally, they offer a novel interpretability into the class-conditional generation process. We extensively evaluate branched diffusion models on several benchmark and large real-world scientific datasets, spanning different data modalities (images, tabular data, and graphs). We particularly highlight the advantages of branched diffusion models on a single-cell RNA-seq dataset, where our branched model leverages the intrinsic hierarchical structure between human cell types",
    "checked": true,
    "id": "6f25c087cba145d2c7c79d8e903f2b24d929374c",
    "semantic_title": "hierarchically branched diffusion models leverage dataset structure for class-conditional generation",
    "citation_count": 0,
    "authors": [
      "Alex M Tseng",
      "Max W Shen",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ]
  },
  "https://openreview.net/forum?id=MZ2kKZc8m7": {
    "title": "SA-MLP: Distilling Graph Knowledge from GNNs into Structure-Aware MLP",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4004a6304d4e576671d73b4eb44400728396c32f",
    "semantic_title": "sa-mlp: distilling graph knowledge from gnns into structure-aware mlp",
    "citation_count": 10,
    "authors": [
      "Jie Chen",
      "Mingyuan Bai",
      "Shouzhen Chen",
      "Junbin Gao",
      "Junping Zhang",
      "Jian Pu"
    ]
  },
  "https://openreview.net/forum?id=LUHmWDydue": {
    "title": "Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f3bdb36f067727a49190eb4209e39db2a08bb05f",
    "semantic_title": "generative models are self-watermarked: declaring model authentication through re-generation",
    "citation_count": 1,
    "authors": [
      "Aditya Desu",
      "Xuanli He",
      "Qiongkai Xu",
      "Wei Lu"
    ]
  },
  "https://openreview.net/forum?id=xI6cPQObp0": {
    "title": "Incremental Spatial and Spectral Learning of Neural Operators for Solving Large-Scale PDEs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aaa9a35ae2c5572a242b91a9aa36923124feec32",
    "semantic_title": "incremental spatial and spectral learning of neural operators for solving large-scale pdes",
    "citation_count": 11,
    "authors": [
      "Robert Joseph George",
      "Jiawei Zhao",
      "Jean Kossaifi",
      "Zongyi Li",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=I7JWf8XA2w": {
    "title": "The Real Tropical Geometry of Neural Networks for Binary Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marie-Charlotte Brandenburg",
      "Georg Loho",
      "Guido Montufar"
    ]
  },
  "https://openreview.net/forum?id=NmWp5lFL7L": {
    "title": "Membership Inference Attacks and Privacy in Topic Modeling",
    "volume": "main",
    "abstract": "Recent research shows that large language models are susceptible to privacy attacks that infer aspects of the training data. However, it is unclear if simpler generative models, like topic models, share similar vulnerabilities. In this work, we propose an attack against topic models that can confidently identify members of the training data in Latent Dirichlet Allocation. Our results suggest that the privacy risks associated with generative modeling are not restricted to large neural models. Additionally, to mitigate these vulnerabilities, we explore differentially private (DP) topic modeling. We propose a framework for private topic modeling that incorporates DP vocabulary selection as a pre-processing step, and show that it improves privacy while having limited effects on practical utility",
    "checked": true,
    "id": "f95ccca0cefe14ccc94c402da96c2cd4d412aaea",
    "semantic_title": "membership inference attacks and privacy in topic modeling",
    "citation_count": 1,
    "authors": [
      "Nico Manzonelli",
      "Wanrong Zhang",
      "Salil Vadhan"
    ]
  },
  "https://openreview.net/forum?id=qWh82br6KT": {
    "title": "Rethinking Teacher-Student Curriculum Learning through the Cooperative Mechanics of Experience",
    "volume": "main",
    "abstract": "Teacher-Student Curriculum Learning (TSCL) is a curriculum learning framework that draws inspiration from human cultural transmission and learning. It involves a teacher algorithm shaping the learning process of a learner algorithm by exposing it to controlled experiences. Despite its success, understanding the conditions under which TSCL is effective remains challenging. In this paper, we propose a data-centric perspective to analyze the underlying mechanics of the teacher-student interactions in TSCL. We leverage cooperative game theory to describe how the composition of the set of experiences presented by the teacher to the learner, as well as their order, influences the performance of the curriculum that is found by TSCL approaches. To do so, we demonstrate that for every TSCL problem, an equivalent cooperative game exists, and several key components of the TSCL framework can be reinterpreted using game-theoretic principles. Through experiments covering supervised learning, reinforcement learning, and classical games, we estimate the cooperative values of experiences and use value-proportional curriculum mechanisms to construct curricula, even in cases where TSCL struggles. The framework and experimental setup we present in this work represents a novel foundation for a deeper exploration of TSCL, shedding light on its underlying mechanisms and providing insights into its broader applicability in machine learning",
    "checked": true,
    "id": "81f06c4070771b57df91a2b7ecfbc95bbdb06f6c",
    "semantic_title": "rethinking teacher-student curriculum learning through the cooperative mechanics of experience",
    "citation_count": 0,
    "authors": [
      "Manfred Diaz",
      "Liam Paull",
      "Andrea Tacchetti"
    ]
  },
  "https://openreview.net/forum?id=S3FUKFMRw8": {
    "title": "An Attentive Approach for Building Partial Reasoning Agents from Pixels",
    "volume": "main",
    "abstract": "We study the problem of building reasoning agents that are able to generalize in an effective manner. Towards this goal, we propose an end-to-end approach for building model-based reinforcement learning agents that dynamically focus their reasoning to the relevant aspects of the environment: after automatically identifying the distinct aspects of the environment, these agents dynamically filter out the relevant ones and then pass them to their simulator to perform partial reasoning. Unlike existing approaches, our approach works with pixel-based inputs and it allows for interpreting the focal points of the agent. Our quantitative analyses show that the proposed approach allows for effective generalization in high-dimensional domains with raw observational inputs. We also perform ablation analyses to validate of design choices. Finally, we demonstrate through qualitative analyses that our approach actually allows for building agents that focus their reasoning on the relevant aspects of the environment",
    "checked": true,
    "id": "effebb32c65cfd48c7f53655f3bfe9ac9b9c0c28",
    "semantic_title": "an attentive approach for building partial reasoning agents from pixels",
    "citation_count": 2,
    "authors": [
      "Safa Alver",
      "Doina Precup"
    ]
  },
  "https://openreview.net/forum?id=TB18G0w6Ld": {
    "title": "Fairness Under Demographic Scarce Regime",
    "volume": "main",
    "abstract": "Most existing works on fairness assume the model has full access to demographic information. However, there exist scenarios where demographic information is partially available because a record was not maintained throughout data collection or for privacy reasons. This setting is known as demographic scarce regime. Prior research has shown that training an attribute classifier to replace the missing sensitive attributes (proxy) can still improve fairness. However, using proxy-sensitive attributes worsens fairness-accuracy tradeoffs compared to true sensitive attributes. To address this limitation, we propose a framework to build attribute classifiers that achieve better fairness-accuracy tradeoffs. Our method introduces uncertainty awareness in the attribute classifier and enforces fairness on samples with demographic information inferred with the lowest uncertainty. We show empirically that enforcing fairness constraints on samples with uncertain sensitive attributes can negatively impact the fairness-accuracy tradeoff. Our experiments on five datasets showed that the proposed framework yields models with significantly better fairness-accuracy tradeoffs than classic attribute classifiers. Surprisingly, our framework can outperform models trained with fairness constraints on the true sensitive attributes in most benchmarks. We also show that these findings are consistent with other uncertainty measures such as conformal prediction",
    "checked": true,
    "id": "ebf291e48b8f477bc96c3995f78378b1fd8dcae6",
    "semantic_title": "fairness under demographic scarce regime",
    "citation_count": 3,
    "authors": [
      "Patrik Joslin Kenfack",
      "Samira Ebrahimi Kahou",
      "Ulrich AÃ¯vodji"
    ]
  },
  "https://openreview.net/forum?id=nuIjjebNuu": {
    "title": "MDP: A Generalized Framework for Text-Guided Image Editing by Manipulating the Diffusion Path",
    "volume": "main",
    "abstract": "Image generation using diffusion can be controlled in multiple ways. In this paper, we systematically analyze the equations of modern generative diffusion networks to propose a framework, called MDP, that explains the design space of suitable manipulations. We identify 5 different manipulations, including intermediate latent, conditional embedding, cross attention maps, guidance, and predicted noise. We analyze the corresponding parameters of these manipulations and the manipulation schedule. We show that some previous editing methods fit nicely into our framework. Particularly, we identified one specific configuration as a new type of control by manipulating the predicted noise, which can perform higher-quality edits than previous work for a variety of local and global edits",
    "checked": true,
    "id": "cea059ebc8cddb672488162f67c7e337018288cc",
    "semantic_title": "mdp: a generalized framework for text-guided image editing by manipulating the diffusion path",
    "citation_count": 19,
    "authors": [
      "Qian Wang",
      "Biao Zhang",
      "Michael Birsak",
      "Peter Wonka"
    ]
  },
  "https://openreview.net/forum?id=vgIBAOkIhY": {
    "title": "Preconditioned Neural Posterior Estimation for Likelihood-free Inference",
    "volume": "main",
    "abstract": "Simulation-based inference (SBI) methods enable the estimation of posterior distributions when the likelihood function is intractable, but where model simulation is feasible. Popular neural approaches to SBI are neural posterior estimation (NPE) and its sequential version (SNPE). These methods can outperform statistical SBI approaches such as approximate Bayesian computation (ABC), particularly for relatively small numbers of model simulations. However, we show in this paper that the NPE methods are not guaranteed to be highly accurate, even on problems with low dimension. In such settings the posterior cannot be accurately trained over the prior predictive space, and even the sequential extension remains sub-optimal. To overcome this, we propose preconditioned NPE (PNPE) and its sequential version (PSNPE), which uses a short run of ABC to effectively eliminate regions of parameter space that produce large discrepancies between simulations and data and allow the posterior emulator to be more accurately trained. We present comprehensive empirical evidence that this melding of neural and statistical SBI methods improves performance over a range of examples including a motivating example involving a complex agent-based model applied to real tumour growth data",
    "checked": true,
    "id": "fa548a56e5e35a515be68b99e437f29496b827f8",
    "semantic_title": "preconditioned neural posterior estimation for likelihood-free inference",
    "citation_count": 5,
    "authors": [
      "Xiaoyu Wang",
      "Ryan P. Kelly",
      "David J Warne",
      "Christopher Drovandi"
    ]
  },
  "https://openreview.net/forum?id=S4duStTKGL": {
    "title": "PASS: Pruning Attention Heads with Almost-sure Sparsity Targets",
    "volume": "main",
    "abstract": "Transformer models have been widely used to obtain high accuracy values in multiple fields including natural language processing (NLP), computer vision, and more. This superior performance typically comes at the expense of substantial computational overhead. Multi-head attention is the key factor in the success of Transformer models that has been found to be computationally expensive. Significant research effort has been devoted to improving attention compute efficiency by pruning redundant attention heads. A widely adopted paradigm is to jointly learn a set of gate variables and apply thresholds on gate values to prune heads. Previous work shows a high level of sensitivity to threshold tuning which can limit subnetwork performance and prevent them from wider adoption in practice. We propose the notion of almost-sure sparsity to overcome this limitation and develop a generic framework for Pruning with Almost-Sure Sparsity (PASS) targets over attention heads. To further boost efficiency, we design a novel technique, concentrator, based on which we develop PASSCONC (PASS with CONCentrator). We also present a simple-yet-effective strategy to further improve subnetwork performance by clipping and selectively reopening learned gates. We investigate PASS and PASSCONC on two widely studied architectures: encoder-decoder (ED) Transformer and encoder-only Transformer (e.g., BERT-base). Experiments on IWSLT14 German-to-English translation and GLUE benchmark tasks demonstrate that our approaches outperform the SOTA by achieving up to 1.33 higher BLEU scores, 1.44% higher accuracy, and 60% higher attention speedups",
    "checked": true,
    "id": "e673d258703cc317b3714bc7da0d9d9b02ebc146",
    "semantic_title": "pass: pruning attention heads with almost-sure sparsity targets",
    "citation_count": 3,
    "authors": [
      "Dujian Ding",
      "Ganesh Jawahar",
      "Laks V. S. Lakshmanan"
    ]
  },
  "https://openreview.net/forum?id=o2wEfwUOma": {
    "title": "Overcoming the Stability Gap in Continual Learning",
    "volume": "main",
    "abstract": "Pre-trained deep neural networks (DNNs) are being widely deployed by industry for making business decisions and to serve users; however, a major problem is model decay, where the DNN's predictions become more erroneous over time, resulting in revenue loss or unhappy users. To mitigate model decay, DNNs are retrained from scratch using old and new data. This is computationally expensive, so retraining happens only once performance significantly decreases. Here, we study how continual learning (CL) could potentially overcome model decay in large pre-trained DNNs and greatly reduce computational costs for keeping DNNs up-to-date. We identify the ``stability gap'' as a major obstacle in our setting. The stability gap refers to a phenomenon where learning new data causes large drops in performance for past tasks before CL mitigation methods eventually compensate for this drop. We test two hypotheses to investigate the factors influencing the stability gap and identify a method that vastly reduces this gap. In large-scale experiments for both easy and hard CL distributions (e.g., class incremental learning), we demonstrate that our method reduces the stability gap and greatly increases computational efficiency. Our work aligns CL with the goals of the production setting, where CL is needed for many applications",
    "checked": true,
    "id": "7d347d3c06b4a7d0292560a9409500e493aed1e9",
    "semantic_title": "overcoming the stability gap in continual learning",
    "citation_count": 11,
    "authors": [
      "Md Yousuf Harun",
      "Christopher Kanan"
    ]
  },
  "https://openreview.net/forum?id=XccFHGakyU": {
    "title": "Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness",
    "volume": "main",
    "abstract": "Neural networks (NNs) are known to exhibit simplicity bias where they tend to prefer learning 'simple' features over more 'complex' ones, even when the latter may be more informative. Simplicity bias can lead to the model making biased predictions which have poor out-of-distribution (OOD) generalization and subgroup robustness. To address this, we propose a hypothesis about spurious features that directly connects to simplicity bias: we hypothesize that spurious features on many datasets are simple features that are still predictive of the label. We empirically validate this hypothesis, and subsequently develop a framework which leverages this hypothesis to learn more robust models. In our proposed framework, we first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model. We theoretically study the effect of this regularization and show that it provably reduces reliance on spurious features in certain settings. We also empirically demonstrate the effectiveness of this framework in various problem settings and real-world applications, showing that it effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness",
    "checked": true,
    "id": "6863db6a1d3187556c6084899f8388656511073a",
    "semantic_title": "mitigating simplicity bias in deep learning for improved ood generalization and robustness",
    "citation_count": 4,
    "authors": [
      "Bhavya Vasudeva",
      "Kameron Shahabi",
      "Vatsal Sharan"
    ]
  },
  "https://openreview.net/forum?id=Afc2CucRaR": {
    "title": "A Fisher-Rao gradient flow for entropic mean-field min-max games",
    "volume": "main",
    "abstract": "Gradient flows play a substantial role in addressing many machine learning problems. We examine the convergence in continuous-time of a Fisher-Rao (Mean-Field Birth-Death) gradient flow in the context of solving convex-concave min-max games with entropy regularization. We propose appropriate Lyapunov functions to demonstrate convergence with explicit rates to the unique mixed Nash equilibrium",
    "checked": true,
    "id": "c0e3e00dc3393b0e1d716efd4083ddaa2916efe0",
    "semantic_title": "a fisher-rao gradient flow for entropic mean-field min-max games",
    "citation_count": 3,
    "authors": [
      "Razvan-Andrei Lascu",
      "Mateusz B. Majka",
      "Lukasz Szpruch"
    ]
  },
  "https://openreview.net/forum?id=saV3MPH0kw": {
    "title": "Unsupervised Domain Adaptation by Learning Using Privileged Information",
    "volume": "main",
    "abstract": "Successful unsupervised domain adaptation is guaranteed only under strong assumptions such as covariate shift and overlap between input domains. The latter is often violated in high-dimensional applications like image classification which, despite this limitation, continues to serve as inspiration and benchmark for algorithm development. In this work, we show that training-time access to side information in the form of auxiliary variables can help relax restrictions on input variables and increase the sample efficiency of learning at the cost of collecting a richer variable set. As this information is assumed available only during training, not in deployment, we call this problem unsupervised domain adaptation by learning using privileged information (DALUPI). To solve this problem, we propose a simple two-stage learning algorithm, inspired by our analysis of the expected error in the target domain, and a practical end-to-end variant for image classification. We propose three evaluation tasks based on classification of entities in photos and anomalies in medical images with different types of available privileged information (binary attributes and single or multiple regions of interest). We demonstrate across these tasks that using privileged information in learning can reduce errors in domain transfer compared to baselines, be robust to spurious correlations in the source domain, and increase sample efficiency",
    "checked": true,
    "id": "191cbd8198393aebaa15f2c1e4cdf116f9d58cb0",
    "semantic_title": "unsupervised domain adaptation by learning using privileged information",
    "citation_count": 2,
    "authors": [
      "Adam Breitholtz",
      "Anton Matsson",
      "Fredrik D. Johansson"
    ]
  },
  "https://openreview.net/forum?id=Susy8EAff9": {
    "title": "MaskMA: Towards Zero-Shot Multi-Agent Decision Making with Mask-Based Collaborative Learning",
    "volume": "main",
    "abstract": "Building a single generalist agent with strong zero-shot capability has recently sparked significant advancements. However, extending this capability to multi-agent decision making scenarios presents challenges. Most current works struggle with zero-shot transfer, due to two challenges particular to the multi-agent settings: (a) a mismatch between centralized training and decentralized execution; and (b) difficulties in creating generalizable representations across diverse tasks due to varying agent numbers and action spaces. To overcome these challenges, we propose a Mask-Based collaborative learning framework for Multi-Agent decision making (MaskMA). Firstly, we randomly mask part of the units and collaboratively learn the policies of unmasked units to handle the mismatch. In addition, MaskMA integrates a generalizable action representation by dividing the action space into intrinsic actions solely related to the unit itself and interactive actions involving interactions with other units. This flexibility allows MaskMA to tackle tasks with varying agent numbers and thus different action spaces. Extensive experiments in SMAC reveal MaskMA, with a single model trained on 11 training maps, can achieve an impressive 77.8% average zero-shot win rate on 60 unseen test maps by decentralized execution, while also performing effectively on other types of downstream tasks (e.g., varied policies collaboration, ally malfunction, and ad hoc team play)",
    "checked": true,
    "id": "ee0c4d99ed3c2f1933f8be73a8bfde8f5a4be422",
    "semantic_title": "maskma: towards zero-shot multi-agent decision making with mask-based collaborative learning",
    "citation_count": 1,
    "authors": [
      "Jie Liu",
      "Yinmin Zhang",
      "Chuming Li",
      "Zhiyuan You",
      "Zhanhui Zhou",
      "Chao Yang",
      "Yaodong Yang",
      "Yu Liu",
      "Wanli Ouyang"
    ]
  },
  "https://openreview.net/forum?id=hkNnGqZnpa": {
    "title": "Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code",
    "volume": "main",
    "abstract": "In this work we systematically review the recent advancements in software engineering with language models, covering 70+ models, 40+ evaluation tasks, 180+ datasets, and 900 related works. Unlike previous works, we integrate software engineering (SE) with natural language processing (NLP) by discussing the perspectives of both sides: SE applies language models for development automation, while NLP adopts SE tasks for language model evaluation. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also go beyond programming and review LLMs' application in other software engineering activities including requirement engineering, testing, deployment, and operations in an endeavor to provide a global view of NLP in SE, and identify key challenges and potential future directions in this domain",
    "checked": true,
    "id": "8ae0d020f4099671ca54cd393c27ee57e07fab77",
    "semantic_title": "unifying the perspectives of nlp and software engineering: a survey on language models for code",
    "citation_count": 0,
    "authors": [
      "Ziyin Zhang",
      "Chaoyu Chen",
      "Bingchang Liu",
      "Cong Liao",
      "Zi Gong",
      "Hang Yu",
      "Jianguo Li",
      "Rui Wang"
    ]
  },
  "https://openreview.net/forum?id=OCnTRfmaTb": {
    "title": "Vision Learners Meet Web Image-Text Pairs",
    "volume": "main",
    "abstract": "Most recent self-supervised learning methods are pre-trained on the well-curated ImageNet-1K dataset. In this work, given the excellent scalability of web data, we consider self-supervised pre-training on noisy web sourced image-text paired data. First, we conduct a benchmark study of representative self-supervised pre-training methods on large-scale web data in a like-for-like setting. We compare a range of methods, including single-modal ones that use masked training objectives and multi-modal ones that use image-text constrastive training. We observe that existing multi-modal methods do not outperform their single-modal counterparts on vision transfer learning tasks. We derive an information-theoretical view to explain these benchmark results, which provides insight into how to design a novel vision learner. Inspired by this insight, we present a new visual representation pre-training method, MUlti-modal Generator~(MUG), that learns from scalable web sourced image-text data. MUG achieves state-of-the-art transfer performance on a variety of tasks and demonstrates promising scaling properties. Pre-trained models and code will be made public upon acceptance",
    "checked": true,
    "id": "3062bb79d12ff55c29c8731211a84e8cf344e235",
    "semantic_title": "vision learners meet web image-text pairs",
    "citation_count": 5,
    "authors": [
      "Bingchen Zhao",
      "Quan Cui",
      "Hao Wu",
      "Osamu Yoshie",
      "Cheng Yang",
      "Oisin Mac Aodha"
    ]
  },
  "https://openreview.net/forum?id=6dS1jhdemD": {
    "title": "Pushing the Limits of Gradient Descent for Efficient Learning on Large Images",
    "volume": "main",
    "abstract": "Traditional deep learning models are trained and tested on relatively low-resolution images (< 300 px), and cannot be directly operated on large-scale images due to compute and memory constraints. We propose Patch Gradient Descent (PatchGD), an effective learning strategy that allows us to train the existing CNN and transformer architectures (hereby referred to as deep learning models) on large-scale images in an end-to-end manner. PatchGD is based on the hypothesis that instead of performing gradient-based updates on an entire image at once, it should be possible to achieve a good solution by performing model updates on only small parts of the image at a time, ensuring that the majority of it is covered over the course of iterations. PatchGD thus extensively enjoys better memory and compute efficiency when training models on large-scale images. PatchGD is thoroughly evaluated on PANDA, UltraMNIST, TCGA, and ImageNet datasets with ResNet50, MobileNetV2, ConvNeXtV2, and DeiT models under different memory constraints. Our evaluation clearly shows that PatchGD is much more stable and efficient than the standard gradient-descent method in handling large images, especially when the compute memory is limited. Code is available at https://github.com/nyunAI/PatchGD",
    "checked": true,
    "id": "79ce199a982ad61b83f067c9866dfd8bd39c376e",
    "semantic_title": "pushing the limits of gradient descent for efficient learning on large images",
    "citation_count": 0,
    "authors": [
      "Deepak Gupta",
      "Gowreesh Mago",
      "Arnav Chavan",
      "Dilip Prasad",
      "Rajat Mani Thomas"
    ]
  },
  "https://openreview.net/forum?id=AWiDlO63bH": {
    "title": "Multi-Grid Tensorized Fourier Neural Operator for High- Resolution PDEs",
    "volume": "main",
    "abstract": "Memory complexity and data scarcity have so far prohibited learning solution operators of partial differential equations (PDE) at high resolutions. We address these limitations by introducing a new data-efficient and highly parallelizable operator learning approach with reduced memory requirement and better generalization, called multi-grid tensorized neural operator (MG-TFNO). MG-TFNO scales to large resolutions by leveraging local and global structures of full-scale, real-world phenomena, through a decomposition of both the input domain and the operator's parameter space. Our contributions are threefold: i) we enable parallelization over input samples with a novel multi-grid-based domain decomposition, ii) we represent the parameters of the model in a high-order latent subspace of the Fourier domain, through a global tensor factorization, resulting in an extreme reduction in the number of parameters and improved generalization, and iii) we propose architectural improvements to the backbone FNO. Our approach can be used in any operator learning setting. We demonstrate superior performance on the turbulent Navier-Stokes equations where we achieve less than half the error with over 150Ã compression. The tensorization combined with the domain decomposition, yields over 150Ã reduction in the number of parameters and 7Ã reduction in the domain size without losses in accuracy",
    "checked": false,
    "id": "3a6cbe04cc049d808db5cb49d15d6c0273170a79",
    "semantic_title": "multi-grid tensorized fourier neural operator for high-resolution pdes",
    "citation_count": 36,
    "authors": [
      "Jean Kossaifi",
      "Nikola Borislavov Kovachki",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=WzHuebRSgQ": {
    "title": "A Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs",
    "volume": "main",
    "abstract": "Deep convolutional neural networks (CNNs) have achieved impressive performance in many computer vision tasks. However, their large model sizes require heavy computational resources, making pruning redundant filters from existing pre-trained CNNs an essential task in developing efficient models for resource-constrained devices. Whole-network filter pruning algorithms prune varying fractions of filters from each layer, hence providing greater flexibility. State-of-the-art whole-network pruning methods are either computationally expensive due to the need to calculate the loss for each pruned filter using a training dataset, or use various heuristic / learned criteria for determining the pruning fractions for each layer. Hence there is a need for a simple and efficient technique for whole network pruning. This paper proposes a two-level hierarchical approach for whole-network filter pruning which is efficient and uses the classification loss as the final criterion. The lower-level algorithm (called filter-pruning) uses a sparse-approximation formulation based on linear approximation of filter weights. We explore two algorithms: orthogonal matching pursuit-based greedy selection and a greedy backward pruning approach. The backward pruning algorithm uses a novel closed-form error criterion for efficiently selecting the optimal filter at each stage, thus making the whole algorithm much faster. The higher-level algorithm (called layer-selection) greedily selects the best-pruned layer (pruning using the filter-selection algorithm) using a global pruning criterion. We propose algorithms for two different global-pruning criteria: (1) layerwise-relative error (HBGS), and (2) final classification error (HBGTS). Our suite of algorithms outperforms state-of-the-art pruning methods on ResNet18, ResNet32, ResNet56, VGG16, and ResNext101. Our method reduces the RAM requirement for ResNext101 from 7.6 GB to 1.5 GB and achieves a 94% reduction in FLOPS without losing accuracy on CIFAR-10",
    "checked": true,
    "id": "c1b695cbea6f5ce0e4f4b5f9aa4c83f6e16bf4d6",
    "semantic_title": "a greedy hierarchical approach to whole-network filter-pruning in cnns",
    "citation_count": 0,
    "authors": [
      "Kiran Purohit",
      "Anurag Reddy Parvathgari",
      "Sourangshu Bhattacharya"
    ]
  },
  "https://openreview.net/forum?id=IHJ5OohGwr": {
    "title": "Feedback-guided Data Synthesis for Imbalanced Classification",
    "volume": "main",
    "abstract": "Current status quo in machine learning is to use static datasets of real images for training, which often come from long-tailed distributions. With the recent advances in generative models, researchers have started augmenting these static datasets with synthetic data, reporting moderate performance improvements on classification tasks. We hypothesize that these performance gains are limited by the lack of feedback from the classifier to the generative model, which would promote the usefulness of the generated samples to improve the classifier's performance. In this work, we introduce a framework for augmenting static datasets with useful synthetic samples, which leverages one-shot feedback from the classifier to drive the sampling of the generative model. In order for the framework to be effective, we find that the samples must be close to the support of the real data of the task at hand, and be sufficiently diverse. We validate three feedback criteria on a long-tailed dataset (ImageNet-LT, Places-LT) as well as a group-imbalanced dataset (NICO++). On ImageNet-LT, we achieve state-of-the-art results, with over $4\\%$ improvement on underrepresented classes while being twice efficient in terms of the number of generated synthetic samples. Similarly, on Places-LT we achieve state-of-the-art results as well as nearly $4\\%$ improvement on underrepresented classes. NICO++ also enjoys marked boosts of over $5\\%$ in worst group accuracy. With these results, our framework paves the path towards effectively leveraging state-of-the-art text-to-image models as data sources that can be queried to improve downstream applications",
    "checked": true,
    "id": "3fa1090abbc155c5ac483e71e9f687c91e6c5509",
    "semantic_title": "feedback-guided data synthesis for imbalanced classification",
    "citation_count": 21,
    "authors": [
      "Reyhane Askari Hemmat",
      "Mohammad Pezeshki",
      "Florian Bordes",
      "Michal Drozdzal",
      "Adriana Romero-Soriano"
    ]
  },
  "https://openreview.net/forum?id=WhEHEDP7ZG": {
    "title": "Piecewise-Stationary Dueling Bandits",
    "volume": "main",
    "abstract": "We study the piecewise-stationary dueling bandits problem with $K$ arms, where the time horizon $T$ consists of $M$ stationary segments, each of which is associated with its own preference matrix. The learner repeatedly selects a pair of arms and observes a binary preference between them as feedback. To minimize the accumulated regret, the learner needs to pick the Condorcet winner of each stationary segment as often as possible, despite preference matrices and segment lengths being unknown. We propose the Beat the Winner Reset algorithm and prove a bound on its expected binary weak regret in the stationary case, which tightens the bound of current state-of-art algorithms. We also show a regret bound for the non-stationary case, without requiring knowledge of $M$ or $T$. We further propose and analyze two meta-algorithms, DETECT for weak regret and Monitored Dueling Bandits for strong regret, both based on a detection-window approach that can incorporate any dueling bandit algorithm as a black-box algorithm. Finally, we prove a worst-case lower bound for expected weak regret in the non-stationary case",
    "checked": true,
    "id": "55e65ce7e3b3b2d863675e920fb49efe9571b678",
    "semantic_title": "piecewise-stationary dueling bandits",
    "citation_count": 0,
    "authors": [
      "Patrick Kolpaczki",
      "Eyke HÃ¼llermeier",
      "Viktor Bengs"
    ]
  },
  "https://openreview.net/forum?id=gKeSI8w63Z": {
    "title": "Contrastive Learning with Consistent Representations",
    "volume": "main",
    "abstract": "Contrastive learning demonstrates great promise for representation learning. Data augmentations play a critical role in contrastive learning by providing informative views of the data without necessitating explicit labels. Nonetheless, the efficacy of current methodologies heavily hinges on the quality of employed data augmentation (DA) functions, often chosen manually from a limited set of options. While exploiting diverse data augmentations is appealing, the complexities inherent in both DAs and representation learning can lead to performance deterioration. Addressing this challenge and facilitating the systematic incorporation of diverse data augmentations, this paper proposes Contrastive Learning with Consistent Representations (CoCor). At the heart of CoCor is a novel consistency metric termed DA consistency. This metric governs the mapping of augmented input data to the representation space. Moreover, we propose to learn the optimal mapping locations as a function of DA. Experimental results demonstrate that CoCor notably enhances the generalizability and transferability of learned representations in comparison to baseline methods. The implementation of CoCor can be found at https://github.com/zihuwang97/CoCor",
    "checked": true,
    "id": "b5b18245b55abf0477fed5086e968edd0333933d",
    "semantic_title": "contrastive learning with consistent representations",
    "citation_count": 5,
    "authors": [
      "Zihu Wang",
      "Yu Wang",
      "Zhuotong Chen",
      "Hanbin Hu",
      "Peng Li"
    ]
  },
  "https://openreview.net/forum?id=HSW49uvCNW": {
    "title": "Concept-Driven Continual Learning",
    "volume": "main",
    "abstract": "This paper introduces two novel solutions to the challenge of catastrophic forgetting in continual learning: Interpretability Guided Continual Learning (IG-CL) and Intrinsically Interpretable Neural Network (IN2). These frameworks bring interpretability into continual learning, systematically managing human-understandable concepts within neural network models to enhance knowledge retention from previous tasks. Our methods are designed to enhance interpretability, providing transparency and control over the continual training process. While our primary focus is to provide a new framework to design continual learning algorithms based on interpretability instead of improving performance, we observe that our methods often surpass existing ones: IG-CL employs interpretability tools to guide neural networks, showing an improvement of up to 1.4% in average incremental accuracy over existing methods; IN2, inspired by the Concept Bottleneck Model, adeptly adjusts concept units for both new and existing tasks, reducing average incremental forgetting by up to 9.1%. Both our frameworks demonstrate superior performance compared to exemplar-free methods, are competitive with exemplar-based methods, and can further improve their performance by up to 18% when combined with exemplar-based strategies. Additionally, IG-CL and IN2 are memory-efficient as they do not require extra memory space for storing data from previous tasks. These advancements mark a promising new direction in continual learning through enhanced interpretability",
    "checked": true,
    "id": "978bfed5cdfa10673e62cb10c656b3cc976e13f4",
    "semantic_title": "concept-driven continual learning",
    "citation_count": 1,
    "authors": [
      "Sin-Han Yang",
      "Tuomas Oikarinen",
      "Tsui-Wei Weng"
    ]
  },
  "https://openreview.net/forum?id=hrKHkmLUFk": {
    "title": "Multi-intention Inverse Q-learning for Interpretable Behavior Representation",
    "volume": "main",
    "abstract": "In advancing the understanding of natural decision-making processes, inverse reinforcement learning (IRL) methods have proven instrumental in reconstructing animal's intentions underlying complex behaviors. Given the recent development of a continuous-time multi-intention IRL framework, there has been persistent inquiry into inferring discrete time-varying rewards with IRL. To address this challenge, we introduce the class of hierarchical inverse Q-learning (HIQL) algorithms. Through an unsupervised learning process, HIQL divides expert trajectories into multiple intention segments, and solves the IRL problem independently for each. Applying HIQL to simulated experiments and several real animal behavior datasets, our approach outperforms current benchmarks in behavior prediction and produces interpretable reward functions. Our results suggest that the intention transition dynamics underlying complex decision-making behavior is better modeled by a step function instead of a smoothly varying function. This advancement holds promise for neuroscience and cognitive science, contributing to a deeper understanding of decision-making and uncovering underlying brain mechanisms",
    "checked": true,
    "id": "a1d5ee777646b5420ec61e41a1a301dac10892ba",
    "semantic_title": "multi-intention inverse q-learning for interpretable behavior representation",
    "citation_count": 7,
    "authors": [
      "Hao Zhu",
      "Brice De La Crompe",
      "Gabriel Kalweit",
      "Artur Schneider",
      "Maria Kalweit",
      "Ilka Diester",
      "Joschka Boedecker"
    ]
  },
  "https://openreview.net/forum?id=RDEaIfOiJM": {
    "title": "Large Language Models Synergize with Automated Machine Learning",
    "volume": "main",
    "abstract": "Recently, program synthesis driven by large language models (LLMs) has become increasingly popular. However, program synthesis for machine learning (ML) tasks still poses significant challenges. This paper explores a novel form of program synthesis, targeting ML programs, by combining LLMs and automated machine learning (autoML). Specifically, our goal is to fully automate the generation and optimization of the code of the entire ML workflow, from data preparation to modeling and post-processing, utilizing only textual descriptions of the ML tasks. To manage the length and diversity of ML programs, we propose to break each ML program into smaller, manageable parts. Each part is generated separately by the LLM, with careful consideration of their compatibilities. To ensure compatibilities, we design a testing technique for ML programs. Unlike traditional program synthesis, which typically relies on binary evaluations (i.e., correct or incorrect), evaluating ML programs necessitates more than just binary judgments. Our approach automates the numerical evaluation and optimization of these programs, selecting the best candidates through autoML techniques. In experiments across various ML tasks, our method outperforms existing methods in 10 out of 12 tasks for generating ML programs. In addition, autoML significantly improves the performance of the generated ML programs. In experiments, given the textual task description, our method, Text-to-ML, generates the complete and optimized ML program in a fully autonomous process. The implementation of our method is available at https://github.com/JLX0/llm-automl",
    "checked": true,
    "id": "190a0ffb48e3f3ca8115f8e673f5ed98990ffed8",
    "semantic_title": "large language models synergize with automated machine learning",
    "citation_count": 5,
    "authors": [
      "Jinglue Xu",
      "Jialong Li",
      "Zhen Liu",
      "NAV Suryanarayanan",
      "Guoyuan Zhou",
      "JIA GUO",
      "Hitoshi Iba",
      "Kenji Tei"
    ]
  },
  "https://openreview.net/forum?id=FCs5czlDTr": {
    "title": "Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods",
    "volume": "main",
    "abstract": "We study stochastic Cubic Newton methods for solving general, possibly non-convex minimization problems. We propose a new framework, the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees; it can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing stochastic Cubic Newton methods, allowing arbitrary size batches and using noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also establish complexity bounds for the classes of gradient-dominated objectives that include convex and strongly convex problems. For Auxiliary Learning, we show that using a helper (auxiliary function) can outperform training alone if a given similarity measure is small",
    "checked": true,
    "id": "4debd146804e01531f893e123cb1da77d7cbf44a",
    "semantic_title": "unified convergence theory of stochastic and variance-reduced cubic newton methods",
    "citation_count": 9,
    "authors": [
      "El Mahdi Chayti",
      "Martin Jaggi",
      "Nikita Doikov"
    ]
  },
  "https://openreview.net/forum?id=FMtRZ4xzSi": {
    "title": "Orthogonal Random Features: Explicit Forms and Sharp Inequalities",
    "volume": "main",
    "abstract": "Random features have been introduced to scale up kernel methods via randomization techniques. In particular, random Fourier features and orthogonal random features were used to approximate the popular Gaussian kernel. Random Fourier features are built in this case using a random Gaussian matrix. In this work, we analyze the bias and the variance of the kernel approximation based on orthogonal random features which makes use of Haar orthogonal matrices. We provide explicit expressions for these quantities using normalized Bessel functions, showing that orthogonal random features does not approximate the Gaussian kernel but a Bessel kernel. We also derive sharp exponential bounds supporting the view that orthogonal random features are less dispersed than random Fourier features",
    "checked": true,
    "id": "8b9b82cb1ed1de8111539af707e55d74c32b4f91",
    "semantic_title": "orthogonal random features: explicit forms and sharp inequalities",
    "citation_count": 1,
    "authors": [
      "Nizar Demni",
      "Hachem Kadri"
    ]
  },
  "https://openreview.net/forum?id=sIR8xV7hGl": {
    "title": "The Kernel Perspective on Dynamic Mode Decomposition",
    "volume": "main",
    "abstract": "This manuscript takes a critical look at the interactions between Koopman theory and reproducing kernel Hilbert spaces with an eye towards giving a tighter theoretical foundation for Koopman based dynamic mode decomposition (DMD), a data driven method for modeling a nonlinear dynamical system from snapshots. In particular, this paper explores the various necessary conditions imposed on the dynamics when a Koopman operator is bounded or compact over a reproducing kernel Hilbert space. Ultimately, it is determined that for many RKHSs, the imposition of compactness or boundedness on a Koopman operator forces the dynamics to be affine. However, a numerical method is still recovered in more general cases through the consideration of the Koopman operator as a closed and densely defined operator, which requires a closer examination of the connection between the Koopman operator and a RKHS. By abandoning the feature representation of RKHSs, the tools of function theory are brought to bear, and a simpler algorithm is obtained for DMD than what was introduced in Williams et al (2016). This algorithm is also generalized to utilize vector valued RKHSs",
    "checked": false,
    "id": "e599f93bd6b81ac59a1b6497c6bcee56f6690092",
    "semantic_title": "modal analysis of spatiotemporal data via multivariate gaussian process regression",
    "citation_count": 0,
    "authors": [
      "Efrain Gonzalez",
      "Moad Abudia",
      "Michael Jury",
      "Rushikesh Kamalapurkar",
      "Joel A Rosenfeld"
    ]
  },
  "https://openreview.net/forum?id=2noXK5KBbx": {
    "title": "Graph Structure Learning with Interpretable Bayesian Neural Networks",
    "volume": "main",
    "abstract": "Graphs serve as generic tools to encode the underlying relational structure of data. Often this graph is not given, and so the task of inferring it from nodal observations becomes important. Traditional approaches formulate a convex inverse problem with a smoothness promoting objective and rely on iterative methods to obtain a solution. In supervised settings where graph labels are available, one can unroll and truncate these iterations into a deep network that is trained end-to-end. Such a network is parameter efficient and inherits inductive bias from the optimization formulation, an appealing aspect for data constrained settings in, e.g., medicine, finance, and the natural sciences. But typically such settings care equally about \\textit{uncertainty} over edge predictions, not just point estimates. Here we introduce novel iterations with \\textit{independently interpretable parameters}, i.e., parameters whose values - independent of other parameters' settings - proportionally influence characteristics of the estimated graph, such as edge sparsity. After unrolling these iterations, prior knowledge over such graph characteristics shape \\textit{prior distributions} over these independently interpretable network parameters to yield a Bayesian neural network (BNN) capable of graph structure learning (GSL) from smooth signal observations. Fast execution and parameter efficiency allow for high-fidelity posterior approximation via Markov Chain Monte Carlo (MCMC) and thus uncertainty quantification on edge predictions. Informative priors unlock modeling tools from Bayesian statistics like prior predictive checks. Synthetic and real data experiments corroborate this model's ability to provide well-calibrated estimates of uncertainty, in test cases that include unveiling economic sector modular structure from S$\\&$P$500$ data and recovering pairwise digit similarities from MNIST images. Overall, this framework enables GSL in modest-scale applications where uncertainty on the data structure is paramount",
    "checked": true,
    "id": "d4a2a2d1e598080f8f15315512f0885aeba3c17a",
    "semantic_title": "graph structure learning with interpretable bayesian neural networks",
    "citation_count": 7,
    "authors": [
      "Max Wasserman",
      "Gonzalo Mateos"
    ]
  },
  "https://openreview.net/forum?id=63r6M1JkXm": {
    "title": "Sparse Modal Regression with Mode-Invariant Skew Noise",
    "volume": "main",
    "abstract": "Sparse regression methods have been widely used in many fields for their statistical effectiveness and high interpretability. However, there are few sparse regression methods with skew noise, although statistical modeling using skewness is becoming more important, e.g., in the medical field. The Azzalini's skew-normal distribution and its extensions are well-used for skew noise. Such skew regression methods have a severe problem with statistical interpretability because they model neither mean, median, nor mode. To overcome this problem, we propose a novel sparse regression method based on mode-invariant skew-normal noise. The regression model is easy to interpret in the proposed method because it always models a mode regardless of skewness. The proposed method is simple to implement and optimize, suggesting it is highly scalable to other machine-learning methods. We also provide theoretical guarantees of the proposed method for the average excess risk and the estimation error. Numerical experiments on artificial and real-world data demonstrate that the proposed method performs significantly better and is more stable than other existing methods for various skew-noise data",
    "checked": true,
    "id": "f6cebe711d453769f3ab5d792c0082b380d88ddf",
    "semantic_title": "sparse modal regression with mode-invariant skew noise",
    "citation_count": 0,
    "authors": [
      "Kazuki Koyama",
      "Takayuki Kawashima",
      "Hironori Fujisawa"
    ]
  },
  "https://openreview.net/forum?id=UawaTQzfwy": {
    "title": "Boosting Unsupervised Semantic Segmentation with Principal Mask Proposals",
    "volume": "main",
    "abstract": "Unsupervised semantic segmentation aims to automatically partition images into semantically meaningful regions by identifying global semantic categories within an image corpus without any form of annotation. Building upon recent advances in self-supervised representation learning, we focus on how to leverage these large pre-trained models for the downstream task of unsupervised segmentation. We present PriMaPs â Principal Mask Proposals â decomposing images into semantically meaningful masks based on their feature representation. This allows us to realize unsupervised semantic segmentation by fitting class prototypes to PriMaPs with a stochastic expectation-maximization algorithm, PriMaPs-EM. Despite its conceptual simplicity, PriMaPs-EM leads to competitive results across various pre-trained backbone models, including DINO and DINOv2, and across different datasets, such as Cityscapes, COCO-Stuff, and Potsdam-3. Importantly, PriMaPs-EM is able to boost results when applied orthogonally to current state-of-the-art unsupervised semantic segmentation pipelines. Code is available at https://github.com/visinf/primaps",
    "checked": true,
    "id": "fc246422db7540865c4de95a09b0f19b233304a2",
    "semantic_title": "boosting unsupervised semantic segmentation with principal mask proposals",
    "citation_count": 4,
    "authors": [
      "Oliver Hahn",
      "Nikita Araslanov",
      "Simone Schaub-Meyer",
      "Stefan Roth"
    ]
  },
  "https://openreview.net/forum?id=lpOC6s4BcM": {
    "title": "Invariance & Causal Representation Learning: Prospects and Limitations",
    "volume": "main",
    "abstract": "Learning causal representations without assumptions is known to be fundamentally impossible, thus establishing the need for suitable inductive biases. At the same time, the invariance of causal mechanisms has emerged as a promising principle to address the challenge of out-of-distribution prediction which machine learning models face. In this work, we explore this invariance principle as a candidate assumption to achieve identifiability of causal representations. While invariance has been utilized for inference in settings where the causal variables are observed, theoretical insights of this principle in the context of causal representation learning are largely missing. We assay the connection between invariance and causal representation learning by establishing impossibility results which show that invariance alone is insufficient to identify latent causal variables. Together with practical considerations, we use our results to reflect generally on the commonly used notion of identifiability in causal representation learning and potential adaptations of this goal moving forward",
    "checked": true,
    "id": "4a36cd2b47241dd2823cbb2073e87e963a33c5c5",
    "semantic_title": "invariance & causal representation learning: prospects and limitations",
    "citation_count": 3,
    "authors": [
      "Simon Bing",
      "Tom Hochsprung",
      "Jonas Wahl",
      "Urmi Ninad",
      "Jakob Runge"
    ]
  },
  "https://openreview.net/forum?id=pyD6cujUmL": {
    "title": "MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers",
    "volume": "main",
    "abstract": "Adversarial robustness often comes at the cost of degraded accuracy, impeding real-life applications of robust classification models. Training-based solutions for better trade-offs are limited by incompatibilities with already-trained high-performance large models, necessitating the exploration of training-free ensemble approaches. Observing that robust models are more confident in correct predictions than in incorrect ones on clean and adversarial data alike, we speculate amplifying this \"benign confidence property\" can reconcile accuracy and robustness in an ensemble setting. To achieve so, we propose \"MixedNUTS\", a *training-free* method where the output logits of a robust classifier and a standard non-robust classifier are processed by nonlinear transformations with only three parameters, which are optimized through an efficient algorithm. MixedNUTS then converts the transformed logits into probabilities and mixes them as the overall output. On CIFAR-10, CIFAR-100, and ImageNet datasets, experimental results with custom strong adaptive attacks demonstrate MixedNUTS's vastly improved accuracy and near-SOTA robustness -- it boosts CIFAR-100 clean accuracy by $7.86$ points, sacrificing merely $0.87$ points in robust accuracy",
    "checked": true,
    "id": "1dd923c9bd40628032f0d5cceeb47b821f027992",
    "semantic_title": "mixednuts: training-free accuracy-robustness balance via nonlinearly mixed classifiers",
    "citation_count": 8,
    "authors": [
      "Yatong Bai",
      "Mo Zhou",
      "Vishal M. Patel",
      "Somayeh Sojoudi"
    ]
  },
  "https://openreview.net/forum?id=CXPb4twsrq": {
    "title": "Tabula: Efficiently Computing Nonlinear Activation Functions for Secure Neural Network Inference",
    "volume": "main",
    "abstract": "Multiparty computation approaches to secure neural network inference commonly rely on garbled circuits for securely executing nonlinear activation functions. However, garbled circuits require excessive communication between server and client, impose significant storage overheads, and incur large runtime penalties; for example, securely evaluating ResNet-32 using standard approaches requires more than 300MB of communication, over 10s of runtime, and around 5 GB of preprocessing storage. To reduce these costs, we propose an alternative to garbled circuits: Tabula, an algorithm based on secure lookup tables. Our approach precomputes lookup tables during an offline phase that contains the result of all possible nonlinear function calls. Because these tables incur exponential storage costs in the number of operands and the precision of the input values, we use quantization to reduce these storage costs to make this approach practical. This enables an online phase where securely computing the result of a nonlinear function requires just a single round of communication, with communication cost equal to twice the number of bits of the input to the nonlinear function. In practice our approach costs 2 bytes of communication per nonlinear function call in the online phase. Compared to garbled circuits with quantized inputs, when computing individual nonlinear functions during the online phase, experiments show Tabula uses between $280$-$560 \\times$ less communication, is over $100\\times$ faster, and uses a comparable amount of storage; compared against other state-of-the-art protocols Tabula achieves greater than $40\\times$ communication reduction. This leads to significant performance gains over garbled circuits with quantized inputs during the online phase of secure inference of neural networks: Tabula reduces end-to-end inference communication by up to $9 \\times$ and achieves an end-to-end inference speedup of up to $50 \\times$, while imposing comparable storage and offline preprocessing costs",
    "checked": true,
    "id": "9081970d3833d482b60997627587728d324ec2a1",
    "semantic_title": "tabula: efficiently computing nonlinear activation functions for secure neural network inference",
    "citation_count": 3,
    "authors": [
      "Max Lam",
      "Michael Mitzenmacher",
      "Vijay Janapa Reddi",
      "Gu-Yeon Wei",
      "David Brooks"
    ]
  },
  "https://openreview.net/forum?id=4ZGqCXcUqR": {
    "title": "Switching Latent Bandits",
    "volume": "main",
    "abstract": "We consider a Latent Bandit problem where the latent state keeps changing in time according to an underlying Markov chain, and every state is represented by a specific Bandit instance. At each step, the agent chooses an arm and observes a random reward but is unaware of which MAB he is currently pulling. As typical in Latent Bandits, we assume to know the reward distribution of the arms of all the Bandit instances. Within this setting, our goal is to learn the transition matrix determined by the Markov process. We propose a technique to tackle this estimation problem that results in solving a least-square problem obtained by exploiting the knowledge of the reward distributions and the properties of Markov chains. We prove the consistency of the estimation procedure, and we make a theoretical comparison with standard Spectral Decomposition techniques. We then discuss the dependency of the problem on the number of arms and present an offline method that chooses the best subset of possible arms that can be used for the estimation of the transition model. We ultimately introduce the SL-EC algorithm based on an Explore then Commit strategy that uses the proposed approach to estimate the transition model during the exploration phase. This algorithm achieves a regret of the order $\\widetilde{\\mathcal{O}}(T^{2/3})$ when compared against an oracle that builds a belief representation of the current state using the knowledge of both the observation and transition model and optimizes the expected instantaneous reward at each step. Finally, we illustrate the effectiveness of the approach and compare it with state-of-the-art algorithms for non-stationary bandits and with a modified technique based on spectral decomposition",
    "checked": true,
    "id": "ffbab69db54af40b1c1ff8badc5f479036c27a4a",
    "semantic_title": "switching latent bandits",
    "citation_count": 1,
    "authors": [
      "Alessio Russo",
      "Alberto Maria Metelli",
      "Marcello Restelli"
    ]
  },
  "https://openreview.net/forum?id=DiyYf1Kcdt": {
    "title": "A Bag of Tricks for Few-Shot Class-Incremental Learning",
    "volume": "main",
    "abstract": "We present a bag of tricks framework for few-shot class-incremental learning (FSCIL), which is a challenging form of continual learning that involves continuous adaptation to new tasks with limited samples. FSCIL requires both stability and adaptability, i.e., preserving proficiency in previously learned tasks while learning new ones. Our proposed bag of tricks brings together six key and highly influential techniques that improve stability, adaptability, and overall performance under a unified framework for FSCIL. We organize these tricks into three categories: stability tricks, adaptability tricks, and training tricks. Stability tricks aim to mitigate the forgetting of previously learned classes by enhancing the separation between the embeddings of learned classes and minimizing interference when learning new ones. On the other hand, adaptability tricks focus on the effective learning of new classes. Finally, training tricks improve the overall performance without compromising stability or adaptability. We perform extensive experiments on three benchmark datasets, CIFAR-100, CUB-200, and miniIMageNet, to evaluate the impact of our proposed framework. Our detailed analysis shows that our approach substantially improves both stability and adaptability, establishing a new state-of-the-art by outperforming prior works in the area. We believe our method provides a go-to solution and establishes a robust baseline for future research in this area",
    "checked": true,
    "id": "8e180dadb24db3dcf4cd811d46713d698b8ff411",
    "semantic_title": "a bag of tricks for few-shot class-incremental learning",
    "citation_count": 2,
    "authors": [
      "Shuvendu Roy",
      "Chunjong Park",
      "Aldi Fahrezi",
      "Ali Etemad"
    ]
  },
  "https://openreview.net/forum?id=o1oetBJuSv": {
    "title": "Probabilistic Matching of Real and Generated Data Statistics in Generative Adversarial Networks",
    "volume": "main",
    "abstract": "Generative adversarial networks constitute a powerful approach to generative modeling. While generated samples often are indistinguishable from real data, there is no guarantee that they will follow the true data distribution. For scientific applications in particular, it is essential that the true distribution is well captured by the generated distribution. In this work, we propose a method to ensure that the distributions of certain generated data statistics coincide with the respective distributions of the real data. In order to achieve this, we add a new loss term to the generator loss function, which quantifies the difference between these distributions via suitable $f$-divergences. Kernel density estimation is employed to obtain representations of the true distributions, and to estimate the corresponding generated distributions from minibatch values at each iteration. When compared to other methods, our approach has the advantage that the complete shapes of the distributions are taken into account. We evaluate the method on a synthetic dataset and a real-world dataset and demonstrate improved performance of our approach",
    "checked": true,
    "id": "a2874664c88f5abd39c79687e279145388fbbb5e",
    "semantic_title": "probabilistic matching of real and generated data statistics in generative adversarial networks",
    "citation_count": 1,
    "authors": [
      "Philipp Pilar",
      "Niklas WahlstrÃ¶m"
    ]
  },
  "https://openreview.net/forum?id=z4b4WfvooX": {
    "title": "Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning",
    "volume": "main",
    "abstract": "Detecting out-of-distribution (OOD) samples is a critical task for reliable machine learning. However, it becomes particularly challenging when the models are trained on long-tailed datasets, as the models often struggle to distinguish tail-class in-distribution samples from OOD samples. We examine the main challenges in this problem by identifying the trade-offs between OOD detection and in-distribution (ID) classification, faced by existing methods. We then introduce our method, called *Representation Norm Amplification* (RNA), which solves this challenge by decoupling the two problems. The main idea is to use the norm of the representation as a new dimension for OOD detection, and to develop a training method that generates a noticeable discrepancy in the representation norm between ID and OOD data, while not perturbing the feature learning for ID classification. Our experiments show that RNA achieves superior performance in both OOD detection and classification compared to the state-of-the-art methods, by 1.70\\% and 9.46\\% in FPR95 and 2.43\\% and 6.87\\% in classification accuracy on CIFAR10-LT and ImageNet-LT, respectively. The code for this work is available at <https://github.com/dgshin21/RNA>",
    "checked": true,
    "id": "71fdc063701dc3f431942398d53b0290a9975d32",
    "semantic_title": "representation norm amplification for out-of-distribution detection in long-tail learning",
    "citation_count": 0,
    "authors": [
      "Dong Geun Shin",
      "Hye Won Chung"
    ]
  },
  "https://openreview.net/forum?id=JxxkKt9yrx": {
    "title": "Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning",
    "volume": "main",
    "abstract": "The predominant method for computing confidence intervals (CI) in few-shot learning (FSL) is based on sampling the tasks with replacement, i.e. allowing the same samples to appear in multiple tasks. This makes the CI misleading in that it takes into account the randomness of the sampler but not the data itself. To quantify the extent of this problem, we conduct a comparative analysis between CIs computed with and without replacement. These reveal a notable underestimation by the predominant method. This observation calls for a reevaluation of how we interpret confidence intervals and the resulting conclusions in FSL comparative studies. Our research demonstrates that the use of paired tests can partially address this issue. Additionally, we explore methods to further reduce the (size of the) CI by strategically sampling tasks of a specific size. We also introduce a new optimized benchmark, which can be accessed at https://github.com/RafLaf/FSL-benchmark-again",
    "checked": true,
    "id": "e901c0792d7dbb4f66391437d7857de05ffef95f",
    "semantic_title": "oops, i sampled it again: reinterpreting confidence intervals in few-shot learning",
    "citation_count": 0,
    "authors": [
      "Raphael Lafargue",
      "Luke A Smith",
      "Franck VERMET",
      "Matthias LÃ¶we",
      "Ian Reid",
      "Jack Valmadre",
      "Vincent Gripon"
    ]
  },
  "https://openreview.net/forum?id=bpjU7rLjJ7": {
    "title": "Learning by Self-Explaining",
    "volume": "main",
    "abstract": "Much of explainable AI research treats explanations as a means for model inspection. Yet, this neglects findings from human psychology that describe the benefit of self-explanations in an agent's learning process. Motivated by this, we introduce a novel workflow in the context of image classification, termed Learning by Self-Explaining (LSX). LSX utilizes aspects of self-refining AI and human-guided explanatory machine learning. The underlying idea is that a learner model, in addition to optimizing for the original predictive task, is further optimized based on explanatory feedback from an internal critic model. Intuitively, a learner's explanations are considered \"useful\" if the internal critic can perform the same task given these explanations. We provide an overview of important components of LSX and, based on this, perform extensive experimental evaluations via three different example instantiations. Our results indicate improvements via Learning by Self-Explaining on several levels: in terms of model generalization, reducing the influence of confounding factors, and providing more task-relevant and faithful model explanations. Overall, our work provides evidence for the potential of self-explaining within the learning phase of an AI model",
    "checked": true,
    "id": "31ead991a433f233d490a7efd6c61d5fae98c327",
    "semantic_title": "learning by self-explaining",
    "citation_count": 12,
    "authors": [
      "Wolfgang Stammer",
      "Felix Friedrich",
      "David Steinmann",
      "Manuel Brack",
      "Hikaru Shindo",
      "Kristian Kersting"
    ]
  },
  "https://openreview.net/forum?id=5TaBxctwRZ": {
    "title": "Input Normalized Stochastic Gradient Descent Training for Deep Neural Networks",
    "volume": "main",
    "abstract": "In this paper, we propose a novel optimization algorithm for training machine learning models called Input Normalized Stochastic Gradient Descent (INSGD), inspired by the Normalized Least Mean Squares (NLMS) algorithm used in adaptive filtering. When training complex models on large datasets, choosing optimizer parameters, particularly the learning rate, is crucial to avoid divergence. Our algorithm updates the network weights using stochastic gradient descent with $\\ell_1$ and $\\ell_2$-based normalizations applied to the learning rate, similar to NLMS. However, unlike existing normalization methods, we exclude the error term from the normalization process and instead normalize the update term using the input vector to the neuron. Our experiments demonstrate that our optimization algorithm achieves higher accuracy levels compared to different initialization settings. We evaluate the efficiency of our training algorithm on benchmark datasets using a toy neural network and several mature modern deep networks including ResNet-20, ResNet-50, MobileNetV3, WResNet-18, and Vision Transformer. Our INSGD algorithm improves ResNet-20's CIFAR-10 test accuracy from 92.57\\% to 92.67\\%, MobileNetV3's CIFAR-10 test accuracy from 90.83\\% to 91.13\\%, WResNet-18 on CIFAR-100 from 78.24\\% to 78.47\\%, and ResNet-50's accuracy on ImageNet-1K validation dataset from 75.60\\% to 75.92\\%",
    "checked": true,
    "id": "e50fe4b9474c4ec502be0537de21a7fd39f7b20d",
    "semantic_title": "input normalized stochastic gradient descent training for deep neural networks",
    "citation_count": 0,
    "authors": [
      "Salih Furkan Atici",
      "Hongyi Pan",
      "Ahmet Cetin"
    ]
  },
  "https://openreview.net/forum?id=n40EWwis1j": {
    "title": "Meta Learning for Support Recovery of High-Dimensional Ising Models",
    "volume": "main",
    "abstract": "In this paper, we consider the meta learning problem for estimating the graphs associated with high-dimensional Ising models, using the method of $\\ell_1$-regularized logistic regression for neighborhood selection of each node. Our goal is to use the information learned from the auxiliary tasks in the learning of the novel task to reduce its sufficient sample complexity. To this end, we propose a novel generative model as well as an improper estimation method. In our setting, all the tasks are similar in their random model parameters and supports. By pooling all the samples from the auxiliary tasks to improperly estimate a single parameter vector, we can recover the true support union, assumed small in size, with a high probability with a sufficient sample complexity of $n = O(d^3 \\log p/K)$ per task, for $K$ tasks of Ising models with $p$ nodes and a maximum neighborhood size $d$. This is very relevant for meta learning where there are many tasks $K = O(d^3 \\log p)$, each with very few samples, i.e., $n = O(1)$, in an scenario where multi-task learning fails. We prove a matching information-theoretic lower bound for the necessary number of samples per task, which is $n = \\Omega(d^3 \\log p/K)$, and thus, our algorithm is minimax optimal. Finally, with the support for the novel task restricted to the estimated support union, we prove that consistent neighborhood selection for the novel task can be obtained with a sufficient sample complexity of $O(d^3 \\log d)$. This reduces the original sample complexity of $n = O(d^3 \\log p)$ for learning a single task. We also prove a matching information-theoretic lower bound of $\\Omega(d^3 \\log d)$ for the necessary number of samples",
    "checked": true,
    "id": "b66161243ba084513057e4ea333eb82c945c5180",
    "semantic_title": "meta learning for support recovery of high-dimensional ising models",
    "citation_count": 0,
    "authors": [
      "Huiming Xie",
      "Jean Honorio"
    ]
  },
  "https://openreview.net/forum?id=FkgM06HEbk": {
    "title": "Discriminative reconstruction via simultaneous dense and sparse coding",
    "volume": "main",
    "abstract": "Discriminative features extracted from the sparse coding model have been shown to perform well for classification. Recent deep learning architectures have further improved reconstruction in inverse problems by considering new dense priors learned from data. We propose a novel dense and sparse coding model that integrates both representation capability and discriminative features. The model studies the problem of recovering a dense vector x and a sparse vector u given measurements of the form y = Ax+Bu. Our first analysis relies on a geometric condition, specifically the minimal angle between the spanning subspaces of matrices A and B, which ensures a unique solution to the model. The second analysis shows that, under some conditions on A and B, a convex program recovers the dense and sparse components. We validate the effectiveness of the model on simulated data and propose a dense and sparse autoencoder (DenSaE) tailored to learning the dictionaries from the dense and sparse model. We demonstrate that (i) DenSaE denoises natural images better than architectures derived from the sparse coding model (Bu), (ii) in the presence of noise, training the biases in the latter amounts to implicitly learning the Ax + Bu model, (iii) A and B capture low- and high-frequency contents, respectively, and (iv) compared to the sparse coding model, DenSaE offers a balance between discriminative power and representation",
    "checked": false,
    "id": "3c0c8e5019df284116dedb183a5476fc80630aa9",
    "semantic_title": "continuous sign language recognition via temporal super-resolution network",
    "citation_count": 12,
    "authors": [
      "Abiy Tasissa",
      "Manos Theodosis",
      "Bahareh Tolooshams",
      "Demba E. Ba"
    ]
  },
  "https://openreview.net/forum?id=4WiqHopXQX": {
    "title": "Reproducibility Study Of Learning Fair Graph Representations Via Automated Data Augmentations",
    "volume": "main",
    "abstract": "In this study, we undertake a reproducibility analysis of \"Learning Fair Graph Representations Via Automated Data Augmentations\" by Ling et al. (2022). We assess the validity of the original claims focused on node classification tasks and explore the performance of the Graphair framework in link prediction tasks. Our investigation reveals that we can partially reproduce one of the original three claims and fully substantiate the other two. Additionally, we broaden the application of Graphair from node classification to link prediction across various datasets. Our findings indicate that, while Graphair demonstrates a comparable fairness-accuracy trade-off to baseline models for mixed dyadic-level fairness, it has a superior trade-off for subgroup dyadic-level fairness. These findings underscore Graphair's potential for wider adoption in graph-based learning. Our code base can be found on GitHub at https://github.com/juellsprott/graphair-reproducibility",
    "checked": true,
    "id": "6c55bfaa5c7849b4f18cd110a4e4abf11f954a88",
    "semantic_title": "reproducibility study of learning fair graph representations via automated data augmentations",
    "citation_count": 0,
    "authors": [
      "Thijmen Nijdam",
      "Juell Sprott",
      "Taiki Papandreou-Lazos",
      "Jurgen de Heus"
    ]
  },
  "https://openreview.net/forum?id=2D36otXvBE": {
    "title": "Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis",
    "volume": "main",
    "abstract": "\\textbf{How can balance be quantified in game settings?} This question is crucial for game designers, especially in player-versus-player (PvP) games, where analyzing the strength relations among predefined team compositionsâsuch as hero combinations in multiplayer online battle arena (MOBA) games or decks in card gamesâis essential for enhancing gameplay and achieving balance. We have developed two advanced measures that extend beyond the simplistic win rate to quantify balance in zero-sum competitive scenarios. These measures are derived from win value estimations, which employ strength rating approximations via the Bradley-Terry model and counter relationship approximations via vector quantization, significantly reducing the computational complexity associated with traditional win value estimations. Throughout the learning process of these models, we identify useful categories of compositions and pinpoint their counter relationships, aligning with the experiences of human players without requiring specific game knowledge. Our methodology hinges on a simple technique to enhance codebook utilization in discrete representation with a deterministic vector quantization process for an extremely small state space. Our framework has been validated in popular online games, including \\textit{Age of Empires II}, \\textit{Hearthstone}, \\textit{Brawl Stars}, and \\textit{League of Legends}. The accuracy of the observed strength relations in these games is comparable to traditional pairwise win value predictions, while also offering a more manageable complexity for analysis. Ultimately, our findings contribute to a deeper understanding of PvP game dynamics and present a methodology that significantly improves game balance evaluation and design",
    "checked": true,
    "id": "63845823ee7f32f5e35e65730fae0d9031045614",
    "semantic_title": "identifying and clustering counter relationships of team compositions in pvp games for efficient balance analysis",
    "citation_count": 0,
    "authors": [
      "Chiu-Chou Lin",
      "Yu-Wei Shih",
      "Kuei-Ting Kuo",
      "Yu-Cheng Chen",
      "Chien-Hua Chen",
      "Wei-Chen Chiu",
      "I-Chen Wu"
    ]
  },
  "https://openreview.net/forum?id=30C9AWBW49": {
    "title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games",
    "volume": "main",
    "abstract": "Defining and measuring decision-making styles, also known as playstyles, is crucial in gaming, where these styles reflect a broad spectrum of individuality and diversity. However, finding a universally applicable measure for these styles poses a challenge. Building on $\\textit{Playstyle Distance}$, the first unsupervised metric to measure playstyle similarity based on game screens and raw actions by identifying comparable states with discrete representations for computing policy distance, we introduce three enhancements to increase accuracy: multiscale analysis with varied state granularity, a perceptual kernel rooted in psychology, and the utilization of the intersection-over-union method for efficient evaluation. These innovations not only advance measurement precision but also offer insights into human cognition of similarity. Across two racing games and seven Atari games, our techniques significantly improve the precision of zero-shot playstyle classification, achieving an accuracy exceeding 90\\% with fewer than 512 observation-action pairsâless than half an episode of these games. Furthermore, our experiments with $\\textit{2048}$ and $\\textit{Go}$ demonstrate the potential of discrete playstyle measures in puzzle and board games. We also develop an algorithm for assessing decision-making diversity using these measures. Our findings improve the measurement of end-to-end game analysis and the evolution of artificial intelligence for diverse playstyles",
    "checked": true,
    "id": "c5e18ef4d717b1055d83b78bb77110b6c9bfec45",
    "semantic_title": "perceptual similarity for measuring decision-making style and policy diversity in games",
    "citation_count": 1,
    "authors": [
      "Chiu-Chou Lin",
      "Wei-Chen Chiu",
      "I-Chen Wu"
    ]
  },
  "https://openreview.net/forum?id=2s5YU6CSEz": {
    "title": "AdaFlood: Adaptive Flood Regularization",
    "volume": "main",
    "abstract": "Although neural networks are conventionally optimized towards zero training loss, it has been recently learned that targeting a non-zero training loss threshold, referred to as a flood level, often enables better test time generalization. Current approaches, however, apply the same constant flood level to all training samples, which inherently assumes all the samples have the same difficulty. We present AdaFlood, a novel flood regularization method that adapts the flood level of each training sample according to the difficulty of the sample. Intuitively, since training samples are not equal in difficulty, the target training loss should be conditioned on the instance. Experiments on datasets covering four diverse input modalities -- text, images, asynchronous event sequences, and tabular -- demonstrate the versatility of AdaFlood across data domains and noise levels",
    "checked": true,
    "id": "eb502ef4a639f27757647daac8a9af984ba832d4",
    "semantic_title": "adaflood: adaptive flood regularization",
    "citation_count": 1,
    "authors": [
      "Wonho Bae",
      "Yi Ren",
      "Mohamed Osama Ahmed",
      "Frederick Tung",
      "Danica J. Sutherland",
      "Gabriel L. Oliveira"
    ]
  },
  "https://openreview.net/forum?id=ANXoddnzct": {
    "title": "Mitigating Group Bias in Federated Learning: Beyond Local Fairness",
    "volume": "main",
    "abstract": "The issue of group fairness in machine learning models, where certain sub-populations or groups are favored over others, has been recognized for some time. While many mitigation strategies have been proposed in centralized learning, many of these methods are not directly applicable in federated learning, where data is privately stored on multiple clients. To address this, many proposals try to mitigate bias at the level of clients before aggregation, which we call locally fair training. However, the effectiveness of these approaches is not well understood. In this work, we investigate the theoretical foundation of locally fair training by studying the relationship between global model fairness and local model fairness. Additionally, we prove that for a broad class of fairness metrics, the global model's fairness can be obtained using only summary statistics from local clients. Based on that, we propose a globally fair training algorithm that optimizes the fairness-regularized empirical loss. Real-data experiments demonstrate the promising performance of our proposed approach for enhancing fairness while retaining high accuracy compared to locally fair training methods",
    "checked": true,
    "id": "d7f59dee450e329da02cb5bd0ef3fc2bc0edfa13",
    "semantic_title": "mitigating group bias in federated learning: beyond local fairness",
    "citation_count": 11,
    "authors": [
      "Ganghua Wang",
      "Ali Payani",
      "Myungjin Lee",
      "Ramana Rao Kompella"
    ]
  },
  "https://openreview.net/forum?id=imGl7xItqQ": {
    "title": "A Lennard-Jones Layer for Distribution Normalization",
    "volume": "main",
    "abstract": "We introduce the Lennard-Jones layer (LJL) for the equalization of the density of 2D and 3D point clouds through systematically rearranging points without destroying their overall structure (distribution normalization). LJL simulates a dissipative process of repulsive and weakly attractive interactions between individual points by considering the nearest neighbor of each point at a given moment in time. This pushes the particles into a potential valley, reaching a well-defined stable configuration that approximates an equidistant sampling after the stabilization process. We apply LJLs to redistribute randomly generated point clouds into a randomized uniform distribution. Moreover, LJLs are embedded in the generation process of point cloud networks by adding them at later stages of the inference process. The improvements in 3D point cloud generation utilizing LJLs are evaluated qualitatively and quantitatively. Finally, we apply LJLs to improve the point distribution of a score-based 3D point cloud denoising network. In general, we demonstrate that LJLs are effective for distribution normalization which can be applied at negligible cost without retraining the given neural network",
    "checked": true,
    "id": "c2e777cd856da4646375122d6f1f49cef5f8273b",
    "semantic_title": "a lennard-jones layer for distribution normalization",
    "citation_count": 0,
    "authors": [
      "Mulun Na",
      "Jonathan Klein",
      "Biao Zhang",
      "Wojtek Palubicki",
      "Soren Pirk",
      "Dominik Michels"
    ]
  },
  "https://openreview.net/forum?id=QweNIIqvZf": {
    "title": "Sequential Best-Arm Identification with Application to P300 Speller",
    "volume": "main",
    "abstract": "A brain-computer interface (BCI) is an advanced technology that facilitates direct communication between the human brain and a computer system, by enabling individuals to interact with devices using only their thoughts. The P300 speller is a primary type of BCI system, which allows users to spell words without using a physical keyboard, but instead by capturing and interpreting brain electroencephalogram (EEG) signals under different stimulus presentation paradigms. Traditional non-adaptive presentation paradigms, however, treat each word selection as an isolated event, resulting in a lengthy learning process. To enhance efficiency, we cast the problem as a sequence of best-arm identification tasks within the context of multi-armed bandits, where each task corresponds to the interaction between the user and the system for a single character or word. Leveraging large language models, we utilize the prior knowledge learned from previous tasks to inform and facilitate subsequent tasks. We propose a sequential top-two Thompson sampling algorithm under two scenarios: the fixed-confidence setting and the fixed-budget setting. We study the theoretical property of the proposed algorithm, and demonstrate its substantial empirical improvement through both simulations as well as the data generated from a P300 speller simulator that was built upon the real BCI experiments",
    "checked": true,
    "id": "ebf4b6004fea3eeae31ae2874979558ddc0f30cf",
    "semantic_title": "sequential best-arm identification with application to p300 speller",
    "citation_count": 0,
    "authors": [
      "Xin Zhou",
      "Botao Hao",
      "Tor Lattimore",
      "Jian Kang",
      "Lexin Li"
    ]
  },
  "https://openreview.net/forum?id=GeLLOGsHV9": {
    "title": "EHI: End-to-end Learning of Hierarchical Index for Efficient Dense Retrieval",
    "volume": "main",
    "abstract": "Dense embedding-based retrieval is widely used for semantic search and ranking. However, conventional two-stage approaches, involving contrastive embedding learning followed by approximate nearest neighbor search (ANNS), can suffer from misalignment between these stages. This mismatch degrades retrieval performance. We propose End-to-end Hierarchical Indexing (EHI), a novel method that directly addresses this issue by jointly optimizing embedding generation and ANNS structure. EHI leverages a dual encoder for embedding queries and documents while simultaneously learning an inverted file index (IVF)-style tree structure. To facilitate the effective learning of this discrete structure, EHI introduces dense path embeddings that encodes the path traversed by queries and documents within the tree. Extensive evaluations on standard benchmarks, including MS MARCO (Dev set) and TREC DL19, demonstrate EHI's superiority over traditional ANNS index. Under the same computational constraints, EHI outperforms existing state-of-the-art methods by +1.45% in MRR@10 on MS MARCO (Dev) and +8.2% in nDCG@10 on TREC DL19, highlighting the benefits of our end-to-end approach",
    "checked": true,
    "id": "89b8a8f53bf28f760e50885bab0e6bb2acf2164a",
    "semantic_title": "ehi: end-to-end learning of hierarchical index for efficient dense retrieval",
    "citation_count": 0,
    "authors": [
      "Ramnath Kumar",
      "Anshul Mittal",
      "Nilesh Gupta",
      "Aditya Kusupati",
      "Inderjit S Dhillon",
      "Prateek Jain"
    ]
  },
  "https://openreview.net/forum?id=hv7iXsiBZE": {
    "title": "On the Data Heterogeneity in Adaptive Federated Learning",
    "volume": "main",
    "abstract": "Adaptive federated learning, which benefits from the characteristic of both adaptive optimizer and federated training paradigm, has recently gained lots of attention. Despite achieving outstanding performances on tasks with heavy-tail stochastic gradient noise distributions, adaptive federated learning also suffers from the same data heterogeneity issue as standard federated learning: heterogeneous data distribution across the clients can largely deteriorate the convergence of adaptive federated learning. In this paper, we propose a novel adaptive federated learning framework with local gossip averaging to address this issue. Particularly, we introduce a client re-sampling mechanism and peer-to-peer gossip communications between local clients to mitigate the data heterogeneity without requiring additional gradient computation costs. We theoretically prove the fast convergence for our proposed method under non-convex stochastic settings and empirically demonstrate its superior performances over vanilla adaptive federated learning with client sampling. Moreover, we extend our framework to a communication-efficient variant, in which clients are divided into disjoint clusters determined by their connectivity or communication capabilities. We exclusively perform local gossip averaging within these clusters, leading to an enhancement in network communication efficiency for our proposed method",
    "checked": true,
    "id": "68969fe7221ce135ab1a5000f07bec4556d038f6",
    "semantic_title": "on the data heterogeneity in adaptive federated learning",
    "citation_count": 0,
    "authors": [
      "Yujia Wang",
      "Jinghui Chen"
    ]
  },
  "https://openreview.net/forum?id=GtnipgAomT": {
    "title": "Discffusion: Discriminative Diffusion Models as Few-shot Vision and Language Learners",
    "volume": "main",
    "abstract": "Diffusion models, such as Stable Diffusion, have shown incredible performance on text-to-image generation. Since text-to-image generation often requires models to generate visual concepts with fine-grained details and attributes specified in text prompts, can we leverage the powerful representations learned by pre-trained diffusion models for discriminative tasks such as image-text matching? To answer this question, we propose a novel approach, Discriminative Stable Diffusion (Discffusion), which turns pre-trained text-to-image diffusion models into few-shot discriminative learners. Our approach uses the cross-attention score of a Stable Diffusion model to capture the mutual influence between visual and textual information and fine-tune the model via a new attention-based prompt learning to perform image-text matching. By comparing Discffusion with state-of-the-art methods on several benchmark datasets, we demonstrate the potential of using pre-trained diffusion models for discriminative tasks with superior results on few-shot image-text matching",
    "checked": true,
    "id": "e982886c22d819d96eddc43e553041b966de422d",
    "semantic_title": "discffusion: discriminative diffusion models as few-shot vision and language learners",
    "citation_count": 8,
    "authors": [
      "Xuehai He",
      "Weixi Feng",
      "Tsu-Jui Fu",
      "Varun Jampani",
      "Arjun Reddy Akula",
      "Pradyumna Narayana",
      "S Basu",
      "William Yang Wang",
      "Xin Eric Wang"
    ]
  },
  "https://openreview.net/forum?id=9ZzASCVhDF": {
    "title": "Studying How to Efficiently and Effectively Guide Models with Explanations\" - A Reproducibility Study",
    "volume": "main",
    "abstract": "Model guidance describes the approach of regularizing the explanations of a deep neu- ral network model towards highlighting the correct features to ensure that the model is \"right for the right reasons\". Rao et al. (2023) conducted an in-depth evaluation of ef- fective and efficient model guidance for object classification across various loss functions, attributions methods, models, and 'guidance depths' to study the effectiveness of differ- ent methods. Our work aims to (1) reproduce the main results obtained by Rao et al. (2023), and (2) propose several extensions to their research. We conclude that the major part of the original work is reproducible, with certain minor exceptions, which we discuss in this paper. In our extended work, we point to an issue with the Energy Pointing Game (EPG) metric used for evaluation and propose an extension for increasing its robustness. In addition, we observe the EPG metric's predisposition towards favoring larger bounding boxes, a bias we address by incorporating a corrective penalty term into the original En- ergy loss function. Furthermore, we revisit the feasibility of using segmentation masks in light of the original study's finding that minimal annotated data can significantly boost model performance. Our findings suggests that Energy loss inherently guides models to on-object features without the requirement for segmentation masks. Finally, we explore the role of contextual information in object detection and, contrary to the assumption that focusing solely on object-specific features suffices for accurate classification, our find- ings suggest the importance of contextual cues in certain scenarios. Code available at: https://anonymous.4open.science/r/model_guidance_repro_study",
    "checked": true,
    "id": "eec378af77f40518ed63252f2d8ff5daf51aeb1c",
    "semantic_title": "studying how to efficiently and effectively guide models with explanations\" - a reproducibility study",
    "citation_count": 0,
    "authors": [
      "Adrian Sauter",
      "Milan MiletiÄ",
      "Ryan Ott",
      "Rohith Saai Pemmasani Prabakaran"
    ]
  },
  "https://openreview.net/forum?id=WLcPrq6pu0": {
    "title": "Leveraging Task Structures for Improved Identifiability in Neural Network Representations",
    "volume": "main",
    "abstract": "This work extends the theory of identifiability in supervised learning by considering the consequences of having access to a distribution of tasks. In such cases, we show that linear identifiability is achievable in the general multi-task regression setting. Furthermore, we show that the existence of a task distribution which defines a conditional prior over latent factors reduces the equivalence class for identifiability to permutations and scaling of the true latent factors, a stronger and more useful result than linear identifiability. Crucially, when we further assume a causal structure over these tasks, our approach enables simple maximum marginal likelihood optimization, and suggests potential downstream applications to causal representation learning. Empirically, we find that this straightforward optimization procedure enables our model to outperform more general unsupervised models in recovering canonical representations for both synthetic data and real-world molecular data",
    "checked": true,
    "id": "51106aada62e064ea32fdcc2f4b15d9eac7b3257",
    "semantic_title": "leveraging task structures for improved identifiability in neural network representations",
    "citation_count": 1,
    "authors": [
      "Wenlin Chen",
      "Julien Horwood",
      "Juyeon Heo",
      "JosÃ© Miguel HernÃ¡ndez-Lobato"
    ]
  },
  "https://openreview.net/forum?id=YoWBLu74TL": {
    "title": "Path Development Network with Finite-dimensional Lie Group",
    "volume": "main",
    "abstract": "Signature, lying at the heart of rough path theory, is a central tool for analysing controlled differential equations driven by irregular paths. Recently it has also found extensive applications in machine learning and data science as a mathematically principled, universal feature that boosts the performance of deep learning-based models in sequential data tasks. It, nevertheless, suffers from the curse of dimensionality when paths are high-dimensional. We propose a novel, trainable path development layer, which exploits representations of sequential data through finite-dimensional Lie groups, thus resulting in dimension reduction. Its backpropagation algorithm is designed via optimization on manifolds. Our proposed layer, analogous to recurrent neural networks (RNN), possesses an explicit, simple recurrent unit that alleviates the gradient issues. Our layer demonstrates its strength in irregular time series modelling. Empirical results on a range of datasets show that the development layer consistently and significantly outperforms signature features on accuracy and dimensionality. The compact hybrid model (stacking one-layer LSTM with the development layer) achieves state-of-the-art against various RNN and continuous time series models. Our layer also enhances the performance of modelling dynamics constrained to Lie groups. Code is available at https://github.com/PDevNet/DevNet.git",
    "checked": false,
    "id": "eaad160c10cf37a3164939ef9029df49677527bb",
    "semantic_title": "path development network with finite-dimensional lie group representation",
    "citation_count": 8,
    "authors": [
      "Hang Lou",
      "Siran Li",
      "Hao Ni"
    ]
  },
  "https://openreview.net/forum?id=HwAZDVxkLX": {
    "title": "Biased Dueling Bandits with Stochastic Delayed Feedback",
    "volume": "main",
    "abstract": "The dueling bandit problem, an essential variation of the traditional multi-armed bandit problem, has become significantly prominent recently due to its broad applications in online advertising, recommendation systems, information retrieval, and more. However, in many real-world applications, the feedback for actions is often subject to unavoidable delays and is not immediately available to the agent. This partially observable issue poses a significant challenge to existing dueling bandit literature, as it significantly affects how quickly and accurately the agent can update their policy on the fly. In this paper, we introduce and examine the biased dueling bandit problem with stochastic delayed feedback, revealing that this new practical problem will delve into a more realistic and intriguing scenario involving a preference bias between the selections. We present two algorithms designed to handle situations involving delay. Our first algorithm, requiring complete delay distribution information, achieves the optimal regret bound for the dueling bandit problem when there is no delay. The second algorithm is tailored for situations where the distribution is unknown, but only the expected value of delay is available. We provide a comprehensive regret analysis for the two proposed algorithms and then evaluate their empirical performance on both synthetic and real datasets",
    "checked": true,
    "id": "13adbee696c755558253e2dd1c45f3036ba82bd3",
    "semantic_title": "biased dueling bandits with stochastic delayed feedback",
    "citation_count": 1,
    "authors": [
      "Bongsoo Yi",
      "Yue Kang",
      "Yao Li"
    ]
  },
  "https://openreview.net/forum?id=lXyZr9TLEU": {
    "title": "AdaStop: adaptive statistical testing for sound comparisons of Deep RL agents",
    "volume": "main",
    "abstract": "Recently, the scientific community has questioned the statistical reproducibility of many empirical results, especially in the field of machine learning. To contribute to the resolution of this reproducibility crisis, we propose a theoretically sound methodology for comparing the performance of a set of algorithms. We exemplify our methodology in Deep Reinforcement Learning (Deep RL). The performance of one execution of a Deep RL algorithm is a random variable. Therefore, several independent executions are needed to evaluate its performance. When comparing algorithms with random performance, a major question concerns the number of executions to perform to ensure that the result of the comparison is theoretically sound. Researchers in Deep RL often use less than 5 independent executions to compare algorithms: we claim that this is not enough in general. Moreover, when comparing more than 2 algorithms at once, we have to use a multiple tests procedure to preserve low error guarantees. We introduce AdaStop, a new statistical test based on multiple group sequential tests. When used to compare algorithms, AdaStop adapts the number of executions to stop as early as possible while ensuring that enough information has been collected to distinguish algorithms that have different score distributions. We prove theoretically that AdaStop has a low probability of making a (family-wise) error. We illustrate the effectiveness of AdaStop in various use-cases, including toy examples and Deep RL algorithms on challenging Mujoco environments. AdaStop is the first statistical test fitted to this sort of comparisons: it is both a significant contribution to statistics, and an important contribution to computational studies performed in reinforcement learning and in other domains",
    "checked": true,
    "id": "dc097caebb68fc592063b3b1c1f5dda4a132c703",
    "semantic_title": "adastop: adaptive statistical testing for sound comparisons of deep rl agents",
    "citation_count": 0,
    "authors": [
      "TimothÃ©e Mathieu",
      "Matheus Medeiros Centa",
      "Riccardo Della Vecchia",
      "Hector Kohler",
      "Alena Shilova",
      "Odalric-Ambrym Maillard",
      "Philippe Preux"
    ]
  },
  "https://openreview.net/forum?id=9OHAtWdFWB": {
    "title": "Robust Feature Inference: A Test-time Defense Strategy using Spectral Projections",
    "volume": "main",
    "abstract": "Test-time defenses are used to improve the robustness of deep neural networks to adversarial examples during inference. However, existing methods either require an additional trained classifier to detect and correct the adversarial samples, or perform additional complex optimization on the model parameters or the input to adapt to the adversarial samples at test-time, resulting in a significant increase in the inference time compared to the base model. In this work, we propose a novel test-time defense strategy called Robust Feature Inference (RFI) that is easy to integrate with any existing (robust) training procedure without additional test-time computation. Based on the notion of robustness of features that we present, the key idea is to project the trained models to the most robust feature space, thereby reducing the vulnerability to adversarial attacks in non-robust directions. We theoretically characterize the subspace of the eigenspectrum of the feature covariance that is the most robust for a generalized additive model. Our extensive experiments on CIFAR-10, CIFAR-100, tiny ImageNet and ImageNet datasets for several robustness benchmarks, including the state-of-the-art methods in RobustBench show that RFI improves robustness across adaptive and transfer attacks consistently. We also compare RFI with adaptive test-time defenses to demonstrate the effectiveness of our proposed approach",
    "checked": true,
    "id": "b479ce53b60933b55eeec804116a1d5ca23a923e",
    "semantic_title": "robust feature inference: a test-time defense strategy using spectral projections",
    "citation_count": 0,
    "authors": [
      "Anurag Singh",
      "Mahalakshmi Sabanayagam",
      "Krikamol Muandet",
      "Debarghya Ghoshdastidar"
    ]
  },
  "https://openreview.net/forum?id=isEFziui9p": {
    "title": "A Practical Guide to Sample-based Statistical Distances for Evaluating Generative Models in Science",
    "volume": "main",
    "abstract": "Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular sample-based statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (FrÃ©chet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distances are used in practice, we evaluate generative models from different scientific domains, namely a model of decision-making and a model generating medical images. We showcase that distinct distances can give different results on similar data. Through this guide, we aim to help researchers to use, interpret, and evaluate statistical distances for generative models in science",
    "checked": true,
    "id": "a2bd438ad2db2f8f4aaa1b01c2f6c710c016bd16",
    "semantic_title": "a practical guide to sample-based statistical distances for evaluating generative models in science",
    "citation_count": 14,
    "authors": [
      "Sebastian Bischoff",
      "Alana Darcher",
      "Michael Deistler",
      "Richard Gao",
      "Franziska Gerken",
      "Manuel Gloeckler",
      "Lisa Haxel",
      "Jaivardhan Kapoor",
      "Janne K Lappalainen",
      "Jakob H. Macke",
      "Guy Moss",
      "Matthijs Pals",
      "Felix C Pei",
      "Rachel Rapp",
      "A Erdem SaÄtekin",
      "Cornelius SchrÃ¶der",
      "Auguste Schulz",
      "Zinovia Stefanidi",
      "Shoji Toyota",
      "Linda Ulmer",
      "Julius Vetter"
    ]
  },
  "https://openreview.net/forum?id=1Kzzm22usl": {
    "title": "Learning a Decision Tree Algorithm with Transformers",
    "volume": "main",
    "abstract": "Decision trees are renowned for their ability to achieve high predictive performance while remaining interpretable, especially on tabular data. Traditionally, they are constructed through recursive algorithms, where they partition the data at every node in a tree. However, identifying a good partition is challenging, as decision trees optimized for local segments may not yield global generalization. To address this, we introduce MetaTree, a transformer-based model trained via meta-learning to directly produce strong decision trees. Specifically, we fit both greedy decision trees and globally optimized decision trees on a large number of datasets, and train MetaTree to produce only the trees that achieve strong generalization performance. This training enables MetaTree to emulate these algorithms and intelligently adapt its strategy according to the context, thereby achieving superior generalization performance",
    "checked": true,
    "id": "a6d90be95a3c3584d69bcbcea3cdc00457bacc42",
    "semantic_title": "learning a decision tree algorithm with transformers",
    "citation_count": 6,
    "authors": [
      "Yufan Zhuang",
      "Liyuan Liu",
      "Chandan Singh",
      "Jingbo Shang",
      "Jianfeng Gao"
    ]
  },
  "https://openreview.net/forum?id=dtNEvUOZmA": {
    "title": "InvariantStock: Learning Invariant Features for Mastering the Shifting Market",
    "volume": "main",
    "abstract": "Accurately predicting stock returns is crucial for effective portfolio management. However, existing methods often overlook a fundamental issue in the market, namely, distribution shifts, making them less practical for predicting future markets or newly listed stocks. This study introduces a novel approach to address this challenge by focusing on the acquisition of invariant features across various environments, thereby enhancing robustness against distribution shifts. Specifically, we present InvariantStock, a designed learning framework comprising two key modules: an environment-aware prediction module and an environment-agnostic module. Through the designed learning of these two modules, the proposed method can learn invariant features across different environments in a straightforward manner, significantly improving its ability to handle distribution shifts in diverse market settings. Our results demonstrate that the proposed InvariantStock not only delivers robust and accurate predictions but also outperforms existing baseline methods in both prediction tasks and backtesting within the dynamically changing markets of China and the United States",
    "checked": true,
    "id": "07ea47c4812c4a929c4bef7bc13ccf61684fe80c",
    "semantic_title": "invariantstock: learning invariant features for mastering the shifting market",
    "citation_count": 0,
    "authors": [
      "Haiyao Cao",
      "Jinan Zou",
      "Yuhang Liu",
      "Zhen Zhang",
      "Ehsan Abbasnejad",
      "Anton van den Hengel",
      "Javen Qinfeng Shi"
    ]
  },
  "https://openreview.net/forum?id=7pBKrcn199": {
    "title": "XAI-Based Detection of Adversarial Attacks on Deepfake Detectors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c92ea4a9f9efa6f74fd4f035c220d7f0936c6a54",
    "semantic_title": "xai-based detection of adversarial attacks on deepfake detectors",
    "citation_count": 7,
    "authors": [
      "Ben Pinhasov",
      "Raz Lapid",
      "Rony Ohayon",
      "Moshe Sipper",
      "Yehudit Aperstein"
    ]
  },
  "https://openreview.net/forum?id=4c2pZzG94y": {
    "title": "Robust and Efficient Quantization-aware Training via Coreset Selection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7010de02a9d084606153320af40aeb8b5ae0fd9f",
    "semantic_title": "robust and efficient quantization-aware training via coreset selection",
    "citation_count": 0,
    "authors": [
      "Xijie Huang",
      "Zechun Liu",
      "Shih-Yang Liu",
      "Kwang-Ting Cheng"
    ]
  },
  "https://openreview.net/forum?id=GSnGPgeoS5": {
    "title": "iHyperTime: Interpretable Time Series Generation with Implicit Neural Representations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "27b91b22c49769d9e8b81d3579e27b99fd97d8ea",
    "semantic_title": "ihypertime: interpretable time series generation with implicit neural representations",
    "citation_count": 1,
    "authors": [
      "Elizabeth Fons",
      "Alejandro Sztrajman",
      "Yousef El-Laham",
      "Andrea Coletta",
      "Alexandros Iosifidis",
      "Svitlana Vyetrenko"
    ]
  },
  "https://openreview.net/forum?id=G7p8djzWOl": {
    "title": "Automatic Data Curation for Self-Supervised Learning: A Clustering-Based Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d68e137ff5794b06e18f22039062dc56d16d7023",
    "semantic_title": "automatic data curation for self-supervised learning: a clustering-based approach",
    "citation_count": 23,
    "authors": [
      "Huy V. Vo",
      "Vasil Khalidov",
      "TimothÃ©e Darcet",
      "ThÃ©o Moutakanni",
      "Nikita Smetanin",
      "Marc Szafraniec",
      "Hugo Touvron",
      "camille couprie",
      "Maxime Oquab",
      "Armand Joulin",
      "Herve Jegou",
      "Patrick Labatut",
      "Piotr Bojanowski"
    ]
  },
  "https://openreview.net/forum?id=Ve4Puj2LVT": {
    "title": "On the Stochastic (Variance-Reduced) Proximal Gradient Method for Regularized Expected Reward Optimization",
    "volume": "main",
    "abstract": "We consider a regularized expected reward optimization problem in the non-oblivious setting that covers many existing problems in reinforcement learning (RL). In order to solve such an optimization problem, we apply and analyze the classical stochastic proximal gradient method. In particular, the method has shown to admit an $O(\\epsilon^{-4})$ sample complexity to an $\\epsilon$-stationary point, under standard conditions. Since the variance of the classical stochastic gradient estimator is typically large, which slows down the convergence, we also apply an efficient stochastic variance-reduce proximal gradient method with an importance sampling based ProbAbilistic Gradient Estimator (PAGE). Our analysis shows that the sample complexity can be improved from $O(\\epsilon^{-4})$ to $O(\\epsilon^{-3})$ under additional conditions. Our results on the stochastic (variance-reduced) proximal gradient method match the sample complexity of their most competitive counterparts for discounted Markov decision processes under similar settings. To the best of our knowledge, the proposed methods represent a novel approach in addressing the general regularized reward optimization problem",
    "checked": true,
    "id": "0b834b82df0a595d10a03a7a3782dd50c828c7c5",
    "semantic_title": "on the stochastic (variance-reduced) proximal gradient method for regularized expected reward optimization",
    "citation_count": 1,
    "authors": [
      "Ling Liang",
      "Haizhao Yang"
    ]
  },
  "https://openreview.net/forum?id=iBorskJRrg": {
    "title": "Accelerated Deep Active Learning with Graph-based Sub- Sampling",
    "volume": "main",
    "abstract": "Past years have witnessed the fast and thorough development of active learning, a human-in-the-loop semi-supervised learning that helps reduce the burden of expensive data annotation. Diverse techniques have been proposed to improve the efficiency of label acquisition. However, the existing techniques are mostly intractable at scale on massive unlabeled instances. In particular, the query time and model retraining time of large scale image-data models is usually linear or even quadratic in the size of the unlabeled pool set and its dimension. The main reason for this intractability is the iterative need to scan the pool set at least once in order to select the best samples for label annotation. To alleviate this computational burden we propose efficient Diffusion Graph Active Learning (DGAL). DGAL is used on a pre-computed Variational-Auto-Encoders (VAE) latent space to restrict the pool set to a much smaller candidates set. The sub-sample is then used in deep architectures, to reduce the query time, via an additional standard active learning baseline criterion. DGAL demonstrates a query time versus accuracy trade-off that is two or more orders of magnitude acceleration over state-of-the-art methods. Moreover, we demonstrate the important exploration-exploitation trade-off in DGAL that allows the restricted set to capture the most impactful samples for active learning at each iteration",
    "checked": true,
    "id": "c5e3b8c47fe983ab4aaf72ee5b9600b76ab6e38a",
    "semantic_title": "accelerated deep active learning with graph-based sub- sampling",
    "citation_count": 0,
    "authors": [
      "Dan Kushnir",
      "Shiyun Xu"
    ]
  },
  "https://openreview.net/forum?id=7tlYbcq5DY": {
    "title": "Affordable Generative Agents",
    "volume": "main",
    "abstract": "The emergence of large language models (LLMs) has significantly advanced the simulation of believable interactive agents. However, the substantial cost on maintaining the prolonged agent interactions poses challenge over the deployment of believable LLM-based agents. Therefore, in this paper, we develop Affordable Generative Agents (AGA), a framework for enabling the generation of believable and low-cost interactions on both agent-environment and inter-agents. Specifically, for agent-environment interactions, we substitute repetitive LLM inferences with learned policies; while for inter-agent interactions, we model the social relationships between agents and compress auxiliary dialogue information. Extensive experiments on multiple environments show the effectiveness and efficiency of our proposed framework. Also, we delve into the mechanisms of emergent believable behaviors lying in LLM agents, demonstrating that agents can only generate finite behaviors in fixed environments, based upon which, we understand ways to facilitate emergent interaction behaviors. Our code is publicly available at: https://github.com/AffordableGenerativeAgents/Affordable-Generative-Agents",
    "checked": true,
    "id": "42d8143a2c803a2cf328f0b568a57dcd5b1dedf5",
    "semantic_title": "affordable generative agents",
    "citation_count": 7,
    "authors": [
      "Yangbin Yu",
      "Qin Zhang",
      "junyou li",
      "QIANG FU",
      "Deheng Ye"
    ]
  },
  "https://openreview.net/forum?id=6L6cD65pot": {
    "title": "Vision-Language Dataset Distillation",
    "volume": "main",
    "abstract": "Dataset distillation methods reduce large-scale datasets to smaller sets of synthetic data, preserving sufficient information to quickly train a new model from scratch. However, prior work on dataset distillation has focused exclusively on image classification datasets, whereas modern large-scale datasets are primarily in the vision-language space. In this work, we design the first vision-language dataset distillation method, building on the idea of trajectory matching. A key challenge is that vision-language datasets do not have a set of discrete classes. To overcome this, our proposed method jointly distills image-text pairs in a contrastive formulation. Further, we leverage Low-Rank Adaptation (LoRA) matching to enable more efficient and effective trajectory matching in complex modern vision-language models. Since there are no existing baselines, we compare our distillation approach with three adapted vision-language coreset selection methods. We demonstrate significant improvements on the challenging Flickr30K and COCO retrieval benchmarks: for example, on Flickr30K, the best coreset selection method selecting 1000 image-text pairs for training achieves only 5.6% image-to-text retrieval accuracy (i.e., recall@1); in contrast, our dataset distillation almost doubles that to 9.9% with just 100 training pairs, an order of magnitude fewer",
    "checked": true,
    "id": "a296731ac273834715f3b2c41739574191909259",
    "semantic_title": "vision-language dataset distillation",
    "citation_count": 10,
    "authors": [
      "Xindi Wu",
      "Byron Zhang",
      "Zhiwei Deng",
      "Olga Russakovsky"
    ]
  },
  "https://openreview.net/forum?id=7DzU88VrNU": {
    "title": "Training-free Graph Neural Networks and the Power of Labels as Features",
    "volume": "main",
    "abstract": "We propose training-free graph neural networks (TFGNNs), which can be used without training and can also be improved with optional training, for transductive node classification. We first advocate labels as features (LaF), which is an admissible but not explored technique. We show that LaF provably enhances the expressive power of graph neural networks. We design TFGNNs based on this analysis. In the experiments, we confirm that TFGNNs outperform existing GNNs in the training-free setting and converge with much fewer training iterations than traditional GNNs",
    "checked": true,
    "id": "479d9dcc3c4b33f60fd695306e26525b16683d08",
    "semantic_title": "training-free graph neural networks and the power of labels as features",
    "citation_count": 4,
    "authors": [
      "Ryoma Sato"
    ]
  },
  "https://openreview.net/forum?id=jcleXdnRA1": {
    "title": "C3DM: Constrained-Context Conditional Diffusion Models for Imitation Learning",
    "volume": "main",
    "abstract": "Behavior Cloning (BC) methods are effective at learning complex manipulation tasks. However, they are prone to spurious correlation - expressive models may focus on distractors that are irrelevant to action prediction - and are thus fragile in real-world deployment. Prior methods have addressed this challenge by exploring different model architectures and action representations. However, none were able to balance between sample efficiency and robustness against distractors for solving manipulation tasks with a complex action space. We present Constrained-Context Conditional Diffusion Model (C3DM), a diffusion model policy for solving 6-DoF robotic manipulation tasks with robustness to distractions that can learn deployable robot policies from as little as five demonstrations. A key component of C3DM is a \\emph{fixation} step that helps the action denoiser to focus on task-relevant regions around a predicted \\emph{fixation point} while ignoring distractors in the context. We empirically show that C3DM is robust to out-of-distribution distractors, and consistently achieves high success rates on a wide array of tasks, ranging from table-top manipulation to industrial kitting that require varying levels of precision and robustness to distractors",
    "checked": false,
    "id": "a399b9f3037332c1fbf8c1298f31ea74af3f4653",
    "semantic_title": "constrained-context conditional diffusion models for imitation learning",
    "citation_count": 4,
    "authors": [
      "Vaibhav Saxena",
      "Yotto koga",
      "Danfei Xu"
    ]
  },
  "https://openreview.net/forum?id=HVWODwbrFK": {
    "title": "Memorisation in Machine Learning: A Survey of Results",
    "volume": "main",
    "abstract": "Quantifying the impact of individual data samples on machine learning models is an open research problem. This is particularly relevant when complex and high-dimensional relationships have to be learned from a limited sample of the data generating distribution, such as in deep learning. It was previously shown that, in these cases, models rely not only on extracting patterns which are helpful for generalisation, but also seem to be required to incorporate some of the training data more or less as is, in a process often termed memorisation. This raises the question: if some memorisation is a requirement for effective learning, what are its privacy implications? In this work we consider a broad range of previous definitions and perspectives on memorisation in ML, discuss their interplay with model generalisation and their implications of these phenomena on data privacy. We then propose a framework to reason over what memorisation means in the context of ML training under the prism of individual sample's influence on the model. Moreover, we systematise methods allowing practitioners to detect the occurrence of memorisation or quantify it and contextualise our findings in a broad range of ML learning settings. Finally, we discuss memorisation in the context of privacy attacks, differential privacy and adversarial actors",
    "checked": true,
    "id": "574c7791ac7a64e5d35b15c257d77a7e4aac3d35",
    "semantic_title": "memorisation in machine learning: a survey of results",
    "citation_count": 2,
    "authors": [
      "Dmitrii Usynin",
      "Moritz Knolle",
      "Georgios Kaissis"
    ]
  },
  "https://openreview.net/forum?id=4bo6XAnutd": {
    "title": "Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix",
    "volume": "main",
    "abstract": "In computer vision, the vision transformer (ViT) has increasingly superseded the convolutional neural network (CNN) for improved accuracy and robustness. However, ViT's large model sizes and high sample complexity make it difficult to train on resource-constrained edge devices. Split learning (SL) emerges as a viable solution, leveraging server-side resources to train ViTs while utilizing private data from distributed devices. However, SL requires additional information exchange for weight updates between the device and the server, which can be exposed to various attacks on private training data. To mitigate the risk of data breaches in classification tasks, inspired from the CutMix regularization, we propose a novel privacy-preserving SL framework that injects Gaussian noise into smashed data and mixes randomly chosen patches of smashed data across clients, coined DP-CutMixSL. Our analysis demonstrates that DP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy protection against membership inference attacks during forward propagation. Through simulations, we show that DP-CutMixSL improves privacy protection against membership inference attacks, reconstruction attacks, and label inference attacks, while also improving accuracy compared to DP-SL and DP-MixSL",
    "checked": true,
    "id": "d888e46803ff5365f089f514719d1036d13e3417",
    "semantic_title": "privacy-preserving split learning with vision transformers using patch-wise random and noisy cutmix",
    "citation_count": 3,
    "authors": [
      "Seungeun Oh",
      "Sihun Baek",
      "Jihong Park",
      "Hyelin Nam",
      "Praneeth Vepakomma",
      "Ramesh Raskar",
      "Mehdi Bennis",
      "Seong-Lyun Kim"
    ]
  },
  "https://openreview.net/forum?id=igJ2XPNYbJ": {
    "title": "APBench: A Unified Availability Poisoning Attack and Defenses Benchmark",
    "volume": "main",
    "abstract": "The efficacy of availability poisoning, a method of poisoning data by injecting imperceptible perturbations to prevent its use in model training, has been a hot subject of investigation. Previous research suggested that it was difficult to effectively counteract such poisoning attacks. However, the introduction of various defense methods has challenged this notion. Due to the rapid progress in this field, the performance of different novel methods cannot be accurately validated due to variations in experimental setups. To further evaluate the attack and defense capabilities of these poisoning methods, we have developed a benchmark â APBench for assessing the efficacy of adversarial poisoning. APBench consists of 9 state-of-the-art availability poisoning attacks, 8 defense algorithms, and 4 conventional data augmentation techniques. We also have set up experiments with varying different poisoning ratios, and evaluated the attacks on multiple datasets and their transferability across model architectures. We further conducted a comprehensive evaluation of 2 additional attacks specifically targeting unsupervised models. Our results reveal the glaring inadequacy of existing attacks in safeguarding individual privacy. APBench is open source and available to the deep learning community",
    "checked": true,
    "id": "daa6070fe76d93b896f1b3f25660beb78c75f876",
    "semantic_title": "apbench: a unified availability poisoning attack and defenses benchmark",
    "citation_count": 3,
    "authors": [
      "Tianrui Qin",
      "Xitong Gao",
      "Juanjuan Zhao",
      "Kejiang Ye",
      "Cheng-zhong Xu"
    ]
  },
  "https://openreview.net/forum?id=I9HvzJbUbh": {
    "title": "DFML: Decentralized Federated Mutual Learning",
    "volume": "main",
    "abstract": "In the realm of real-world devices, centralized servers in Federated Learning (FL) present challenges including communication bottlenecks and susceptibility to a single point of failure. Additionally, contemporary devices inherently exhibit model and data heterogeneity. Existing work lacks a Decentralized FL (DFL) framework capable of accommodating such heterogeneity without imposing architectural restrictions or assuming the availability of additional data. To address these issues, we propose a Decentralized Federated Mutual Learning (DFML) framework that is serverless, supports nonrestrictive heterogeneous models, and avoids reliance on additional data. DFML effectively handles model and data heterogeneity through mutual learning, which distills knowledge between clients, and cyclically varying the amount of supervision and distillation signals. Extensive experimental results demonstrate consistent effectiveness of DFML in both convergence speed and global accuracy, outperforming prevalent baselines under various conditions. For example, with the CIFAR-100 dataset and 50 clients, DFML achieves a substantial increase of +17.20% and +19.95% in global accuracy under Independent and Identically Distributed (IID) and non-IID data shifts, respectively",
    "checked": true,
    "id": "494162c4d35e98fd464d60b38dc518a19c9ec190",
    "semantic_title": "dfml: decentralized federated mutual learning",
    "citation_count": 1,
    "authors": [
      "Yasser H. Khalil",
      "Amir Hossein Estiri",
      "Mahdi Beitollahi",
      "Nader Asadi",
      "Sobhan Hemati",
      "Xu Li",
      "Guojun Zhang",
      "Xi Chen"
    ]
  },
  "https://openreview.net/forum?id=ZSqP1RT8jC": {
    "title": "kNN-CLIP: Retrieval Enables Training-Free Segmentation on Continually Expanding Large Vocabularies",
    "volume": "main",
    "abstract": "Continual segmentation has not yet tackled the challenge of improving open-vocabulary segmentation models with training data for accurate segmentation across large, continually expanding vocabularies. We discover that traditional continual training results in severe catastrophic forgetting, failing to outperform a zero-shot segmentation baseline. We introduce a novel training-free strategy, kNN-CLIP, which augments the model with a database of instance embeddings for semantic and panoptic segmentation that achieves zero forgetting. We demonstrate that kNN-CLIP can adapt to continually growing vocabularies without the need for retraining or large memory costs. kNN-CLIP enables open-vocabulary segmentation methods to expand their vocabularies on any domain with a single pass through the data, while only storing compact embeddings. This approach minimizes both compute and memory costs. kNN-CLIP achieves state-of-the-art performance across large-vocabulary semantic and panoptic segmentation datasets. We hope kNN-CLIP represents a significant step forward in enabling more efficient and adaptable continual segmentation, paving the way for advances in real-world large-vocabulary continual segmentation methods",
    "checked": true,
    "id": "e26f7120b9a0698a9873db3cd653a16dcf0ed1e4",
    "semantic_title": "knn-clip: retrieval enables training-free segmentation on continually expanding large vocabularies",
    "citation_count": 7,
    "authors": [
      "Zhongrui Gui",
      "Shuyang Sun",
      "Runjia Li",
      "Jianhao Yuan",
      "Zhaochong An",
      "Karsten Roth",
      "Ameya Prabhu",
      "Philip Torr"
    ]
  },
  "https://openreview.net/forum?id=JRjD0YF3Yd": {
    "title": "Bayesian optimization with derivatives acceleration",
    "volume": "main",
    "abstract": "Bayesian optimization algorithms form an important class of methods to minimize functions that are costly to evaluate, which is a very common situation. These algorithms iteratively infer Gaussian processes from past observations of the function and decide where new observations should be made through the maximization of an acquisition criterion. Often, the objective function is defined on a compact set such as in a hyper-rectangle of the $d$-dimensional real space, and the bounds are chosen wide enough so that the optimum is inside the search domain. In this situation, this work provides a way to integrate in the acquisition criterion the \\textit{a priori} information that these functions, once modeled as GP trajectories, should be evaluated at their minima, and not at any point as usual acquisition criteria do. We propose an adaptation of the widely used Expected Improvement acquisition criterion that accounts only for GP trajectories where the first order partial derivatives are zero and the Hessian matrix is positive definite. The new acquisition criterion keeps an analytical, computationally efficient, expression. This new acquisition criterion is found to improve Bayesian optimization on a test bed of functions made of Gaussian process trajectories in low dimension problems. The addition of first and second order derivative information is particularly useful for multimodal functions",
    "checked": true,
    "id": "fa17c4bafa59c90330a9807f67e47306481a0b0d",
    "semantic_title": "bayesian optimization with derivatives acceleration",
    "citation_count": 2,
    "authors": [
      "Guillaume Perrin",
      "rodolphe le riche"
    ]
  },
  "https://openreview.net/forum?id=XPLXYr7NlR": {
    "title": "Learning $k$-Level Structured Sparse Neural Networks Using Group Envelope Regularization",
    "volume": "main",
    "abstract": "The extensive need for computational resources poses a significant obstacle to deploying large-scale Deep Neural Networks (DNN) on devices with constrained resources. At the same time, studies have demonstrated that a significant number of these DNN parameters are redundant and extraneous. In this paper, we introduce a novel approach for learning structured sparse neural networks, aimed at bridging the DNN hardware deployment challenges. We develop a novel regularization technique, termed Weighted Group Sparse Envelope Function (WGSEF), generalizing the Sparse Envelop Function (SEF), to select (or nullify) neuron groups, thereby reducing redundancy and enhancing computational efficiency. The method speeds up inference time and aims to reduce memory demand and power consumption, thanks to its adaptability which lets any hardware specify group definitions, such as filters, channels, filter shapes, layer depths, a single parameter (unstructured), etc. The properties of the WGSEF enable the pre-definition of a desired sparsity level to be achieved at the training convergence. In the case of redundant parameters, this approach maintains negligible network accuracy degradation or can even lead to improvements in accuracy. Our method efficiently computes the WGSEF regularizer and its proximal operator, in a worst-case linear complexity relative to the number of group variables. Employing a proximal-gradient-based optimization technique, to train the model, it tackles the non-convex minimization problem incorporating the neural network loss and the WGSEF. Finally, we experiment and illustrate the efficiency of our proposed method in terms of the compression ratio, accuracy, and inference latency",
    "checked": false,
    "id": "d0a8a16fb340e8d0561b7daa37c054bbc792ebfd",
    "semantic_title": "learning k-level structured sparse neural networks using group envelope regularization",
    "citation_count": 0,
    "authors": [
      "Yehonathan Refael",
      "Iftach Arbel",
      "Wasim Huleihel"
    ]
  },
  "https://openreview.net/forum?id=gfANevPraH": {
    "title": "Demonstrating and Reducing Shortcuts in Vision-Language Representation Learning",
    "volume": "main",
    "abstract": "Vision-language models (VLMs) mainly rely on contrastive training to learn general-purpose representations of images and captions. We focus on the situation when one image is associated with several captions, each caption containing both information shared among all captions and unique information per caption about the scene depicted in the image. In such cases, it is unclear whether contrastive losses are sufficient for learning task-optimal representations that contain all the information provided by the captions or whether the contrastive learning setup encourages the learning of a simple shortcut that minimizes contrastive loss. We introduce synthetic shortcuts for vision-language: a training and evaluation framework where we inject synthetic shortcuts into image-text data. We show that contrastive VLMs trained from scratch or fine-tuned with data containing these synthetic shortcuts mainly learn features that represent the shortcut. Hence, contrastive losses are not sufficient to learn task-optimal representations, i.e., representations that contain all task-relevant information shared between the image and associated captions. We examine two methods to reduce shortcut learning in our training and evaluation framework: (i) latent target decoding and (ii) implicit feature modification. We show empirically that both methods improve performance on the evaluation task, but only partly reduce shortcut learning when training and evaluating with our shortcut learning framework. Hence, we show the difficulty and challenge of our shortcut learning framework for contrastive vision-language representation learning",
    "checked": true,
    "id": "98855de46c18bfee76ddb6d0283ebc66aeb6e836",
    "semantic_title": "demonstrating and reducing shortcuts in vision-language representation learning",
    "citation_count": 2,
    "authors": [
      "Maurits Bleeker",
      "Mariya Hendriksen",
      "Andrew Yates",
      "Maarten de Rijke"
    ]
  },
  "https://openreview.net/forum?id=db2pFKVcm1": {
    "title": "Variational Bayesian Imaging with an Efficient Surrogate Score-based Prior",
    "volume": "main",
    "abstract": "We propose a surrogate function for efficient yet principled use of score-based priors in Bayesian imaging. We consider ill-posed inverse imaging problems in which one aims for a clean image posterior given incomplete or noisy measurements. Since the measurements do not uniquely determine a true image, a prior is needed to constrain the solution space. Recent work turned score-based diffusion models into principled priors for solving ill-posed imaging problems by appealing to an ODE-based log-probability function. However, evaluating the ODE is computationally inefficient and inhibits posterior estimation of high-dimensional images. Our proposed surrogate prior is based on the evidence lower bound of a score-based diffusion model. We demonstrate the surrogate prior on variational inference for efficient approximate posterior sampling of large images. Compared to the exact prior in previous work, our surrogate accelerates optimization of the variational image distribution by at least two orders of magnitude. We also find that our principled approach gives more accurate posterior estimation than non-variational diffusion-based approaches that involve hyperparameter-tuning at inference. Our work establishes a practical path forward for using score-based diffusion models as general-purpose image priors",
    "checked": true,
    "id": "f4dc6ac54f853569bac1d6c680634d08a5b5460a",
    "semantic_title": "variational bayesian imaging with an efficient surrogate score-based prior",
    "citation_count": 10,
    "authors": [
      "Berthy Feng",
      "Katherine Bouman"
    ]
  },
  "https://openreview.net/forum?id=H8IaxrANWl": {
    "title": "Differentiating Through Integer Linear Programs with Quadratic Regularization and Davis-Yin Splitting",
    "volume": "main",
    "abstract": "In many applications, a combinatorial problem must be repeatedly solved with similar, but distinct parameters. Yet, the parameters $w$ are not directly observed; only contextual data $d$ that correlates with $w$ is available. It is tempting to use a neural network to predict $w$ given $d$. However, training such a model requires reconciling the discrete nature of combinatorial optimization with the gradient-based frameworks used to train neural networks. We study the case where the problem in question is an Integer Linear Program (ILP). We propose applying a three-operator splitting technique, also known as Davis-Yin splitting (DYS), to the quadratically regularized continuous relaxation of the ILP. We prove that the resulting scheme is compatible with the recently introduced Jacobian-free backpropagation (JFB). Our experiments on two representative ILPs: the shortest path problem and the knapsack problem, demonstrate that this combination---DYS on the forward pass, JFB on the backward pass---yields a scheme which scales more effectively to high-dimensional problems than existing schemes",
    "checked": true,
    "id": "e3807ebdb28c020837afd688dad0e40acadc31ee",
    "semantic_title": "differentiating through integer linear programs with quadratic regularization and davis-yin splitting",
    "citation_count": 4,
    "authors": [
      "Daniel McKenzie",
      "Howard Heaton",
      "Samy Wu Fung"
    ]
  },
  "https://openreview.net/forum?id=uvPnTWMLll": {
    "title": "Calibrating Deep Ensemble through Functional Variational Inference",
    "volume": "main",
    "abstract": "Deep Ensemble (DE) is an effective and practical uncertainty quantification approach in deep learning. The uncertainty of DE is usually manifested by the functional inconsistency among the ensemble members, which, yet, originates from unmanageable randomness in the initialization and optimization of neural networks (NNs), and may easily collapse in specific cases. To tackle this issue, we advocate characterizing the functional inconsistency with the empirical covariance of the functions dictated by the ensemble members, and defining a Gaussian process (GP) with it. We perform functional variational inference to tune such a probabilistic model w.r.t. training data and specific prior beliefs. This way, we can explicitly manage the uncertainty of the ensemble of NNs. We further provide strategies to make the training efficient. The proposed approach achieves better uncertainty quantification than DE and its variants across diverse scenarios, while consuming only marginally added training cost compared to standard DE. The code is available at https://github.com/thudzj/DE-GP",
    "checked": true,
    "id": "4007192210b234fcb15125f3f8713e488b0c01b3",
    "semantic_title": "calibrating deep ensemble through functional variational inference",
    "citation_count": 0,
    "authors": [
      "Zhijie Deng",
      "Feng Zhou",
      "Jianfei Chen",
      "Guoqiang Wu",
      "Jun Zhu"
    ]
  },
  "https://openreview.net/forum?id=6OmRkUHgs5": {
    "title": "Federated Variational Inference: Towards Improved Personalization and Generalization",
    "volume": "main",
    "abstract": "Conventional federated learning algorithms train a single global model by leveraging all participating clients' data. However, due to heterogeneity in client generative distributions and predictive models, these approaches may not appropriately approximate the predictive process, converge to an optimal state, or generalize to new clients. We study personalization and generalization in stateless cross-device federated learning setups assuming heterogeneity in client data distributions and predictive models. We first propose a hierarchical generative model and formalize it using Bayesian Inference. We then approximate this process using Variational Inference to train our model efficiently. We call this algorithm Federated Variational Inference (FedVI). We use PAC-Bayes analysis to provide generalization bounds for FedVI. We evaluate our model on FEMNIST and CIFAR-100 image classification and show that FedVI beats the state-of-the-art on both tasks",
    "checked": true,
    "id": "da3d7ef14bea8af2f2d662f6b8c6fb366b9955aa",
    "semantic_title": "federated variational inference: towards improved personalization and generalization",
    "citation_count": 3,
    "authors": [
      "Elahe Vedadi",
      "Joshua V. Dillon",
      "Philip Andrew Mansfield",
      "Karan Singhal",
      "Arash Afkanpour",
      "Warren Richard Morningstar"
    ]
  },
  "https://openreview.net/forum?id=XWQgXLYwv2": {
    "title": "How to choose the right transfer learning protocol? A qualitative analysis in a controlled set-up",
    "volume": "main",
    "abstract": "Transfer learning is a powerful technique that enables model training with limited amounts of data, making it crucial in many data-scarce real-world applications. Typically, transfer learning protocols require first to transfer all the feature-extractor layers of a network pre-trained on a data-rich source task, and then to adapt only the task-specific readout layers to a data-poor target task. This workflow is based on two main assumptions: first, the feature maps of the pre-trained model are qualitatively similar to the ones that would have been learned with enough data on the target task; second, the source representations of the last hidden layers are always the most expressive. In this work, we demonstrate that this is not always the case and that the largest performance gain may be achieved when smaller portions of the pre-trained network are transferred. In particular, we perform a set of numerical experiments in a controlled setting, showing how the optimal transfer depth depends non-trivially on the amount of available training data and on the degree of source-target task similarity, and it is often convenient to transfer only the first layers. We then propose a strategy to detect the most promising source task among the available candidates. This approach compares the internal representations of a network trained entirely from scratch on the target task with those of the networks pre-trained on the potential source tasks",
    "checked": true,
    "id": "a1f000da618279b86a14974364f075d676266c67",
    "semantic_title": "how to choose the right transfer learning protocol? a qualitative analysis in a controlled set-up",
    "citation_count": 1,
    "authors": [
      "Federica Gerace",
      "Diego Doimo",
      "Stefano Sarao Mannelli",
      "Luca Saglietti",
      "Alessandro Laio"
    ]
  },
  "https://openreview.net/forum?id=CSv7GgKHb6": {
    "title": "Graph Harmony: Denoising and Nuclear-Norm Wasserstein Adaptation for Enhanced Domain Transfer in Graph-Structured Data",
    "volume": "main",
    "abstract": "Graph-structured data is prevalent in numerous fields, but the scarcity of labeled instances often limits the effective application of deep learning techniques. Traditional unsupervised domain adaptation (UDA) strategies for graphs typically rely on adversarial learning and pseudo-labeling. However, these methods often fail to leverage the discriminative features of graphs, resulting in class mismatches and unreliable label quality. To overcome these challenges, we developed the Denoising and Nuclear-Norm Wasserstein Adaptation Network (DNAN). DNAN utilizes the Nuclear-Norm Wasserstein Discrepancy (NWD), which simultaneously achieves domain alignment and class distinction. The NWD is integrated with a denoising mechanism using a variational graph autoencoder, with a theoretical analysis provided for the denoising process. This denoising mechanism aims to address domain shifts in structural patterns between the source and target domains. Our comprehensive experiments demonstrate that DNAN outperforms state-of-the-art methods on standard UDA benchmarks for graph classification, highlighting its effectiveness and robustness",
    "checked": true,
    "id": "f958ec39fa4e9f9fd43c17a5b07b60b095b0c313",
    "semantic_title": "graph harmony: denoising and nuclear-norm wasserstein adaptation for enhanced domain transfer in graph-structured data",
    "citation_count": 3,
    "authors": [
      "Mengxi Wu",
      "Mohammad Rostami"
    ]
  },
  "https://openreview.net/forum?id=XzaSGIStXP": {
    "title": "Learning Hybrid Interpretable Models: Theory, Taxonomy, and Methods",
    "volume": "main",
    "abstract": "A hybrid model involves the cooperation of an interpretable model and a complex black box. At inference, any input of the hybrid model is assigned to either its interpretable or complex component based on a gating mechanism. The ratio of data samples sent to the interpretable component is referred to as the model transparency. Despite their high potential, Hybrid Interpretable Models remain under-studied in the interpretability/explainability literature. In this paper, we remedy this fact by presenting a thorough investigation of such models from three perspectives: Theory, Taxonomy, and Methods. First, we highlight the potential generalization benefits of sending samples to an interpretable component by deriving a Probably-Approximately-Correct (PAC) generalization bound. This guarantee indicates a sweet spot for optimal transparency, which suggests that redirecting inputs to an interpretable model can act as regularization. Secondly, we provide a general taxonomy for the different ways of training such models: the Post-Black-Box and Pre-Black-Box paradigms. These approaches differ in the order in which the interpretable and complex components are trained. We show where the state-of-the-art Hybrid-Rule-Set and Companion-Rule-List fall in this taxonomy. Thirdly, we implement the two paradigms in a single method: HybridCORELS, which extends the CORELS algorithm to Hybrid Interpretable Modeling. By leveraging CORELS, HybridCORELS provides a certificate of optimality of its interpretable component and precise control over transparency. We finally show empirically that HybridCORELS is competitive with existing approaches and performs just as well as a standalone black box (or even better) while being partly transparent",
    "checked": true,
    "id": "8136310403b456c3611255276c11728e95f8f067",
    "semantic_title": "learning hybrid interpretable models: theory, taxonomy, and methods",
    "citation_count": 5,
    "authors": [
      "Julien Ferry",
      "Gabriel Laberge",
      "Ulrich AÃ¯vodji"
    ]
  },
  "https://openreview.net/forum?id=dixU4fozPQ": {
    "title": "Closing the gap between SVRG and TD-SVRG with Gradient Splitting",
    "volume": "main",
    "abstract": "Temporal difference (TD) learning is a policy evaluation in reinforcement learning whose performance can be enhanced by variance reduction methods. Recently, multiple works have sought to fuse TD learning with Stochastic Variance Reduced Gradient (SVRG) method to achieve a geometric rate of convergence. However, the resulting convergence rate is significantly weaker than what is achieved by SVRG in the setting of convex optimization. In this work we utilize a recent interpretation of TD-learning as the splitting of the gradient of an appropriately chosen function, thus simplifying the algorithm and fusing TD with SVRG. Our main result is a geometric convergence bound with predetermined learning rate of $1/8$, which is identical to the convergence bound available for SVRG in the convex setting. Our theoretical findings are supported by a set of experiments",
    "checked": true,
    "id": "99a501e2d7338b48c4e57a16f3c8d033b763ddfa",
    "semantic_title": "closing the gap between svrg and td-svrg with gradient splitting",
    "citation_count": 1,
    "authors": [
      "Arsenii Mustafin",
      "Alex Olshevsky",
      "Ioannis Paschalidis"
    ]
  },
  "https://openreview.net/forum?id=A5ulGfDBON": {
    "title": "Finite-Time Analysis of Temporal Difference Learning with Experience Replay",
    "volume": "main",
    "abstract": "Temporal-difference (TD) learning is widely regarded as one of the most popular algorithms in reinforcement learning (RL). Despite its widespread use, it has only been recently that researchers have begun to actively study its finite time behavior, including the finite time bound on mean squared error and sample complexity. On the empirical side, experience replay has been a key ingredient in the success of deep RL algorithms, but its theoretical effects on RL have yet to be fully understood. In this paper, we present a simple decomposition of the Markovian noise terms and provide finite-time error bounds for tabular on-policy TD-learning with experience replay. Specifically, under the Markovian observation model, we demonstrate that for both the averaged iterate and final iterate cases, the error term induced by a constant step-size can be effectively controlled by the size of the replay buffer and the mini-batch sampled from the experience replay buffer",
    "checked": true,
    "id": "e96f736d231cc4506396f6bafddf896ca9257679",
    "semantic_title": "finite-time analysis of temporal difference learning with experience replay",
    "citation_count": 1,
    "authors": [
      "Han-Dong Lim",
      "Donghwan Lee"
    ]
  },
  "https://openreview.net/forum?id=GZORXGxHHT": {
    "title": "The Cold Posterior Effect Indicates Underfitting, and Cold Posteriors Represent a Fully Bayesian Method to Mitigate It",
    "volume": "main",
    "abstract": "The cold posterior effect (CPE) (Wenzel et al., 2020) in Bayesian deep learning shows that, for posteriors with a temperature $T<1$, the resulting posterior predictive could have better performance than the Bayesian posterior ($T=1$). As the Bayesian posterior is known to be optimal under perfect model specification, many recent works have studied the presence of CPE as a model misspecification problem, arising from the prior and/or from the likelihood. In this work, we provide a more nuanced understanding of CPE as we show that misspecification leads to CPE only when the resulting Bayesian posterior underfits. In fact, we theoretically show that if there is no underfitting, there is no CPE. Furthermore, we show that these tempered posteriors with $T < 1$ are indeed proper Bayesian posteriors with a different combination of likelihoods and priors parameterized by $T$. This observation validates the adjustment of the temperature hyperparameter $T$ as a straightforward approach to mitigate underfitting in the Bayesian posterior. In essence, we show that by fine-tuning the temperature $T$ we implicitly utilize alternative Bayesian posteriors, albeit with less misspecified likelihood and prior distributions. The code for replicating the experiments can be found at https://github.com/pyijiezhang/cpe-underfit",
    "checked": true,
    "id": "b90a1457aaa496dd773ef9cd919371dc28bd2a0d",
    "semantic_title": "the cold posterior effect indicates underfitting, and cold posteriors represent a fully bayesian method to mitigate it",
    "citation_count": 2,
    "authors": [
      "Yijie Zhang",
      "Yi-Shan Wu",
      "Luis A. Ortega",
      "Andres R Masegosa"
    ]
  },
  "https://openreview.net/forum?id=LV04KBaIQt": {
    "title": "Meta-Learning Approach for Joint Multimodal Signals with Multimodal Iterative Adaptation",
    "volume": "main",
    "abstract": "In the pursuit of effectively modeling real-world joint multimodal signals, learning to learn multiple Implicit Neural Representations (INRs) jointly has gained attention to overcome data scarcity and enhance fitting speed. However, predominant methods based on multi- modal encoders often underperform due to their reliance on direct data-to-parameter map- ping functions, bypassing the optimization steps necessary for capturing the complexities of real-world signals. To address this gap, we propose Multimodal Iterative Adaptation (MIA), a novel framework that combines the strengths of multimodal fusion with optimization-based meta-learning. The key idea is to enhance the learning of INRs by facilitating exchange of cross-modal knowledge among learners during the iterative optimization processes, improv- ing generalization and enabling a more nuanced adaptation to complex signals. To achieve this, we introduce State Fusion Transformers (SFTs), an attention-based meta-learner de- signed to operate in the backward pass of the learners, aggregating learning states, capturing cross-modal relationships, and predicting enhanced parameter updates for the learners. Our extensive evaluation in various real-world multimodal signal regression setups shows that MIA outperforms existing baselines in both generalization and memorization performances. Our code is available at https://github.com/yhytoto12/MIA",
    "checked": true,
    "id": "f33cde964e43d7166934d2b6cfaad015c27ae817",
    "semantic_title": "meta-learning approach for joint multimodal signals with multimodal iterative adaptation",
    "citation_count": 0,
    "authors": [
      "Sehun Lee",
      "Wonkwang Lee",
      "Gunhee Kim"
    ]
  },
  "https://openreview.net/forum?id=xNkASJL0F6": {
    "title": "Dynamic Structure Estimation from Bandit Feedback using Nonvanishing Exponential Sums",
    "volume": "main",
    "abstract": "This work tackles the dynamic structure estimation problems for periodically behaved discrete dynamical system in the Euclidean space. We assume the observations become sequentially available in a form of bandit feedback contaminated by a sub-Gaussian noise. Under such fairly general assumptions on the noise distribution, we carefully identify a set of recoverable information of periodic structures. Our main results are the (computation and sample) efficient algorithms that exploit asymptotic behaviors of exponential sums to effectively average out the noise effect while preventing the information to be estimated from vanishing. In particular, the novel use of the Weyl sum, a variant of exponential sums, allows us to extract spectrum information for linear systems. We provide sample complexity bounds for our algorithms, and we experimentally validate our theoretical claims on simulations of toy examples, including Cellular Automata",
    "checked": true,
    "id": "e64d750066bc4f38403c16ca865afa5958fc2084",
    "semantic_title": "dynamic structure estimation from bandit feedback using nonvanishing exponential sums",
    "citation_count": 0,
    "authors": [
      "Motoya Ohnishi",
      "Isao Ishikawa",
      "Yuko Kuroki",
      "Masahiro Ikeda"
    ]
  },
  "https://openreview.net/forum?id=e92dgUUfk0": {
    "title": "Improving Black-box Robustness with In-Context Rewriting",
    "volume": "main",
    "abstract": "Machine learning models for text classification often excel on in-distribution (ID) data but struggle with unseen out-of-distribution (OOD) inputs. Most techniques for improving OOD robustness are not applicable to settings where the model is effectively a black box, such as when the weights are frozen, retraining is costly, or the model is leveraged via an API. Test-time augmentation (TTA) is a simple post-hoc technique for improving robustness that sidesteps black-box constraints by aggregating predictions across multiple augmentations of the test input. TTA has seen limited use in NLP due to the challenge of generating effective natural language augmentations. In this work, we propose LLM-TTA, which uses LLM-generated augmentations as TTA's augmentation function. LLM-TTA outperforms conventional augmentation functions across sentiment, toxicity, and news classification tasks for BERT and T5 models, with BERT's OOD robustness improving by an average of 4.48 percentage points without regressing average ID performance. We explore selectively augmenting inputs based on prediction entropy to reduce the rate of expensive LLM augmentations, allowing us to maintain performance gains while reducing the average number of generated augmentations by 57.74\\%. LLM-TTA is agnostic to the task model architecture, does not require OOD labels, and is effective across low and high-resource settings",
    "checked": true,
    "id": "563e59d708457c1271fbc1998faf224565aad2c1",
    "semantic_title": "improving black-box robustness with in-context rewriting",
    "citation_count": 7,
    "authors": [
      "Kyle O'Brien",
      "Nathan Hoyen Ng",
      "Isha Puri",
      "Jorge Mendez-Mendez",
      "Hamid Palangi",
      "Yoon Kim",
      "Marzyeh Ghassemi",
      "Thomas Hartvigsen"
    ]
  },
  "https://openreview.net/forum?id=9sZsjfZV3q": {
    "title": "Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty",
    "volume": "main",
    "abstract": "Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\\rho$ and an alternative adversarial action with probability $\\rho$. We show the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Based on that, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Our results highlight that action-robust RL shares the same sample complexity barriers as standard RL, ensuring robust performance without additional complexity costs. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the other action robust RL algorithms in the presence of action perturbations",
    "checked": true,
    "id": "91d2dd18d19837ae2bd15aa364d0825883eddcd5",
    "semantic_title": "efficient action robust reinforcement learning with probabilistic policy execution uncertainty",
    "citation_count": 2,
    "authors": [
      "Guanlin Liu",
      "Zhihan Zhou",
      "Han Liu",
      "Lifeng Lai"
    ]
  },
  "https://openreview.net/forum?id=0VWXWPmctm": {
    "title": "Pre-trained Hypergraph Convolutional Neural Networks with Self-supervised Learning",
    "volume": "main",
    "abstract": "Hypergraphs are powerful tools for modeling complex interactions across various domains, including biomedicine. However, learning meaningful node representations from hypergraphs remains a challenge. Existing supervised methods often lack generalizability, thereby limiting their real-world applications. We propose a new method, Pre-trained Hypergraph Convolutional Neural Networks with Self-supervised Learning (PhyGCN), which leverages hypergraph structure for self-supervision to enhance node representations. PhyGCN introduces a unique training strategy that integrates variable hyperedge sizes with self-supervised learning, enabling improved generalization to unseen data. Applications on multi-way chromatin interactions and polypharmacy side-effects demonstrate the effectiveness of PhyGCN. As a generic framework for high-order interaction datasets with abundant unlabeled data, PhyGCN holds strong potential for enhancing hypergraph node representations across various domains",
    "checked": false,
    "id": "18b84b573c5d5d3830d8c94d4e2d256e9ff658a7",
    "semantic_title": "phygcn: pre-trained hypergraph convolutional neural networks with self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Yihe Deng",
      "Ruochi Zhang",
      "Pan Xu",
      "Jian Ma",
      "Quanquan Gu"
    ]
  },
  "https://openreview.net/forum?id=nH416rLxtI": {
    "title": "Variational Autoencoding of Dental Point Clouds",
    "volume": "main",
    "abstract": "Digital dentistry has made significant advancements, yet numerous challenges remain. This paper introduces the FDI 16 dataset, an extensive collection of tooth meshes and point clouds. Additionally, we present a novel approach: Variational FoldingNet (VF-Net), a fully probabilistic variational autoencoder for point clouds. Notably, prior latent variable models for point clouds lack a one-to-one correspondence between input and output points. Instead, they rely on optimizing Chamfer distances, a metric that lacks a normalized distributional counterpart, rendering it unsuitable for probabilistic modeling. We replace the explicit minimization of Chamfer distances with a suitable encoder, increasing computational efficiency while simplifying the probabilistic extension. This allows for straightforward application in various tasks, including mesh generation, shape completion, and representation learning. Empirically, we provide evidence of lower reconstruction error in dental reconstruction and interpolation, showcasing state-of-the-art performance in dental sample generation while identifying valuable latent representations",
    "checked": true,
    "id": "3a99770dc4360e9f03c3c808d1065650b2e4d836",
    "semantic_title": "variational autoencoding of dental point clouds",
    "citation_count": 0,
    "authors": [
      "Johan Ziruo Ye",
      "Thomas Ãrkild",
      "Peter Lempel SÃ¸ndergard",
      "SÃ¸ren Hauberg"
    ]
  },
  "https://openreview.net/forum?id=1qZyJQxOof": {
    "title": "The Survival Bandit Problem",
    "volume": "main",
    "abstract": "In this paper, we introduce and study a new variant of the multi-armed bandit problem (MAB), called the survival bandit problem (S-MAB). While in both problems, the objective is to maximize the so-called cumulative reward, in this new variant, the procedure is interrupted if the cumulative reward falls below a preset threshold. This simple yet unexplored extension of the MAB follows from many practical applications. For example, when testing two medicines against each other on voluntary patients, people's lives and health are at stake, and it is necessary to be able to interrupt experiments if serious side effects occur or if the disease syndromes are not dissipated by the treatment. From a theoretical perspective, the S-MAB is the first variant of the MAB where the procedure may or may not be interrupted. We start by formalizing the S-MAB and we define its objective as the minimization of the so-called survival regret, which naturally generalizes the regret of the MAB. Then, we show that the objective of the S-MAB is considerably more difficult than the MAB, in the sense that contrary to the MAB, no policy can achieve a reasonably small (i.e., sublinear) survival regret. Instead, we minimize the survival regret in the sense of Pareto, i.e., we seek a policy whose cumulative reward cannot be improved for some problem instance without being sacrificed for another one. For that purpose, we identify two key components in the survival regret: the regret given no ruin (which corresponds to the regret in the MAB), and the probability that the procedure is interrupted, called the probability of ruin. We derive a lower bound on the probability of ruin, as well as policies whose probability of ruin matches the lower bound. Finally, based on a doubling trick on those policies, we derive a policy which minimizes the survival regret in the sense of Pareto, providing an answer to the open problem by Perotto et al. (COLT 2019)",
    "checked": true,
    "id": "3392a2f11e2cf734e63b1a9bf30faad49a61690d",
    "semantic_title": "the survival bandit problem",
    "citation_count": 4,
    "authors": [
      "Charles Riou",
      "Junya Honda",
      "Masashi Sugiyama"
    ]
  },
  "https://openreview.net/forum?id=MywlrEaFqR": {
    "title": "DIG-MILP: a Deep Instance Generator for Mixed-Integer Linear Programming with Feasibility Guarantee",
    "volume": "main",
    "abstract": "Mixed-integer linear programming (MILP) stands as a notable NP-hard problem pivotal to numerous crucial industrial applications. The development of effective algorithms, the tuning of solvers, and the training of machine learning models for MILP resolution all hinge on access to extensive, diverse, and representative data. Yet compared to the abundant naturally occurring data in image and text realms, MILP is markedly data deficient, underscoring the vital role of synthetic MILP generation. We present DIG-MILP, a deep generative framework adept at extracting deep-level structural features from highly limited MILP data and producing instances that closely mirror the target data. Notably, by leveraging the MILP duality, DIG-MILP guarantees a correct and complete generation space as well as ensures the boundedness and feasibility of the generated instances. Our empirical study highlights the novelty and quality of the instances generated by DIG-MILP through two distinct downstream tasks: (S1) Data sharing, where solver solution times correlate highly positive between original and DIG-MILP-generated instances, allowing data sharing for solver tuning without publishing the original data; (S2) Data Augmentation, wherein the DIG-MILP-generated instances bolster the generalization performance of machine learning models tasked with resolving MILP problems",
    "checked": true,
    "id": "1b4d2628f07786833d29935e9a7d1244b0c560f6",
    "semantic_title": "dig-milp: a deep instance generator for mixed-integer linear programming with feasibility guarantee",
    "citation_count": 6,
    "authors": [
      "Haoyu Peter Wang",
      "Jialin Liu",
      "Xiaohan Chen",
      "Xinshang Wang",
      "Pan Li",
      "Wotao Yin"
    ]
  },
  "https://openreview.net/forum?id=Br5esc2CXR": {
    "title": "Deep Backtracking Counterfactuals for Causally Compliant Explanations",
    "volume": "main",
    "abstract": "Counterfactuals answer questions of what would have been observed under altered circumstances and can therefore offer valuable insights. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative where all causal laws are kept intact. In the present work, we introduce a practical method called deep backtracking counterfactuals (DeepBC) for computing backtracking counterfactuals in structural causal models that consist of deep generative components. We propose two distinct versions of our methodâone utilizing Langevin Monte Carlo sampling and the other employing constrained optimizationâto generate counterfactuals for high-dimensional data. As a special case, our formulation reduces to methods in the field of counterfactual explanations. Compared to these, our approach represents a causally compliant, versatile and modular alternative. We demonstrate these properties experimentally on a modified version of MNIST and CelebA",
    "checked": true,
    "id": "4bec270e8afe2ecb3531895766e3e7dd67b12e27",
    "semantic_title": "deep backtracking counterfactuals for causally compliant explanations",
    "citation_count": 6,
    "authors": [
      "Klaus-Rudolf Kladny",
      "Julius von KÃ¼gelgen",
      "Bernhard SchÃ¶lkopf",
      "Michael Muehlebach"
    ]
  },
  "https://openreview.net/forum?id=ffBj12yh58": {
    "title": "Supervised Domain Adaptation Based on Marginal and Conditional Distributions Alignment",
    "volume": "main",
    "abstract": "Supervised domain adaptation (SDA) is an area of machine learning, where the goal is to achieve good generalization performance on data from a target domain, given a small corpus of labeled training data from the target domain and a large corpus of labeled data from a related source domain. In this work, based on a generalization of a well-known theoretical result of \\citet{ben2010theory}, we propose an SDA approach, in which the adaptation is performed by aligning the marginal and conditional components of the input-label joint distributions. In addition to being theoretically grounded, we demonstrate that the proposed approach has two advantages over existing SDA approaches. First, it applies to a broad collection of learning tasks, such as regression, classification, multi-label classification, and few-shot learning. Second, it takes into account the geometric structure of the input and label spaces. Experimentally, despite its generality, our approach demonstrates on-par or superior results compared with recent state-of-the-art task-specific methods",
    "checked": true,
    "id": "8d879d19f184c47eeea59b983725d0a1d7511227",
    "semantic_title": "supervised domain adaptation based on marginal and conditional distributions alignment",
    "citation_count": 1,
    "authors": [
      "Ori Katz",
      "Ronen Talmon",
      "Uri Shaham"
    ]
  },
  "https://openreview.net/forum?id=5g5zFVj33K": {
    "title": "Doubly Robust Kernel Statistics for Testing Distributional Treatment Effects",
    "volume": "main",
    "abstract": "With the widespread application of causal inference, it is increasingly important to have tools which can test for the presence of causal effects in a diverse array of circumstances. In this vein we focus on the problem of testing for \\emph{distributional} causal effects, where the treatment affects not just the mean, but also higher order moments of the distribution, as well as multidimensional or structured outcomes. We build upon a previously introduced framework, Counterfactual Mean Embeddings, for representing causal distributions within Reproducing Kernel Hilbert Spaces (RKHS) by proposing new, improved, estimators for the distributional embeddings. These improved estimators are inspired by doubly robust estimators of the causal mean, using a similar form within the kernel space. We analyse these estimators, proving they retain the doubly robust property and have improved convergence rates compared to the original estimators. This leads to new permutation-based tests for distributional causal effects, by constructing the test statistics based on the estimators we propose. We experimentally and theoretically demonstrate the validity of our tests",
    "checked": true,
    "id": "ee1fa5747e34e4987a85015999a0a8ed11d78359",
    "semantic_title": "doubly robust kernel statistics for testing distributional treatment effects",
    "citation_count": 2,
    "authors": [
      "Jake Fawkes",
      "Robert Hu",
      "Robin J. Evans",
      "Dino Sejdinovic"
    ]
  },
  "https://openreview.net/forum?id=uHLDkQVtyC": {
    "title": "How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning",
    "volume": "main",
    "abstract": "Despite superior reasoning prowess demonstrated by Large Language Models (LLMs) with Chain-of-Thought (CoT) prompting, a lack of understanding prevails around the internal mechanisms of the models that facilitate CoT generation. This work investigates the neural sub-structures within LLMs that manifest CoT reasoning from a mechanistic point of view. From an analysis of Llama-2 7B applied to multistep reasoning over fictional ontologies, we demonstrate that LLMs deploy multiple parallel pathways of answer generation for step-by-step reasoning. These parallel pathways provide sequential answers from the input question context as well as the generated CoT. We observe a functional rift in the middle layers of the LLM. Token representations in the initial half remain strongly biased towards the pretraining prior, with the in-context prior taking over in the later half. This internal phase shift manifests in different functional components: attention heads that write the answer token appear in the later half, attention heads that move information along ontological relationships appear in the initial half, and so on. To the best of our knowledge, this is the first attempt towards mechanistic investigation of CoT reasoning in LLMs",
    "checked": true,
    "id": "97994e4526ef7eeea59190aa466fbab05fad9187",
    "semantic_title": "how to think step-by-step: a mechanistic understanding of chain-of-thought reasoning",
    "citation_count": 26,
    "authors": [
      "Subhabrata Dutta",
      "Joykirat Singh",
      "Soumen Chakrabarti",
      "Tanmoy Chakraborty"
    ]
  },
  "https://openreview.net/forum?id=WyPKLWPYsr": {
    "title": "Weighted Risk Invariance: Domain Generalization under Invariant Feature Shift",
    "volume": "main",
    "abstract": "Learning models whose predictions are invariant under multiple environments is a promising approach for out-of-distribution generalization. Such models are trained to extract features $X_{\\text{inv}}$ where the conditional distribution $Y \\mid X_{\\text{inv}}$ of the label given the extracted features does not change across environments. Invariant models are also supposed to generalize to shifts in the marginal distribution $p(X_{\\text{inv}})$ of the extracted features $X_{\\text{inv}}$, a type of shift we call an invariant covariate shift. However, we show that proposed methods for learning invariant models underperform under invariant covariate shift, either failing to learn invariant models---even for data generated from simple and well-studied linear-Gaussian models---or having poor finite-sample performance. To alleviate these problems, we propose weighted risk invariance (WRI). Our framework is based on imposing invariance of the loss across environments subject to appropriate reweightings of the training examples. We show that WRI provably learns invariant models, i.e. discards spurious correlations, in linear-Gaussian settings. We propose a practical algorithm to implement WRI by learning the density $p(X_{\\text{inv}})$ and the model parameters simultaneously, and we demonstrate empirically that WRI outperforms previous invariant learning methods under invariant covariate shift",
    "checked": true,
    "id": "7d793b33c681c686fd95e39590c72cedc2345a1e",
    "semantic_title": "weighted risk invariance: domain generalization under invariant feature shift",
    "citation_count": 0,
    "authors": [
      "Gina Wong",
      "Joshua Gleason",
      "Rama Chellappa",
      "Yoav Wald",
      "Anqi Liu"
    ]
  },
  "https://openreview.net/forum?id=ZJ4A3xhADV": {
    "title": "Federated Learning with Reduced Information Leakage and Computation",
    "volume": "main",
    "abstract": "Federated learning (FL) is a distributed learning paradigm that allows multiple decentralized clients to collaboratively learn a common model without sharing local data. Although local data is not exposed directly, privacy concerns nonetheless exist as clients' sensitive information can be inferred from intermediate computations. Moreover, such information leakage accumulates substantially over time as the same data is repeatedly used during the iterative learning process. As a result, it can be particularly difficult to balance the privacy-accuracy trade-off when designing privacy-preserving FL algorithms. This paper introduces Upcycled-FL, a simple yet effective strategy that applies first-order approximation at every even round of model update. Under this strategy, half of the FL updates incur no information leakage and require much less computational and transmission costs. We first conduct the theoretical analysis on the convergence (rate) of Upcycled-FL and then apply two perturbation mechanisms to preserve privacy. Extensive experiments on both synthetic and real-world data show that the Upcycled-FL strategy can be adapted to many existing FL frameworks and consistently improve the privacy-accuracy trade-off",
    "checked": true,
    "id": "22b4e4e31a76aa024e21da82a45da31cc81f8322",
    "semantic_title": "federated learning with reduced information leakage and computation",
    "citation_count": 3,
    "authors": [
      "Tongxin Yin",
      "Xuwei Tan",
      "Xueru Zhang",
      "Mohammad Mahdi Khalili",
      "Mingyan Liu"
    ]
  },
  "https://openreview.net/forum?id=Ry5CXXm1sf": {
    "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion",
    "volume": "main",
    "abstract": "This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models' behavior. The framework includes a representation that captures the general \\textit{syntax} of structural recursion, coupled with two different frameworks for understanding their \\textit{semantics}---one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture. With our framework as a powerful conceptual tool, we identify different issues under various set-ups. The models trained to emulate recursive computations cannot fully capture the recursion yet instead fit short-cut algorithms and thus cannot solve certain edge cases that are under-represented in the training distribution. In addition, it is difficult for state-of-the-art large language models (LLMs) to mine recursive rules from in-context demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating reduction (step-wise computation) of the recursive function",
    "checked": true,
    "id": "16daf858baef5ff2a698596bf26999a618fa521e",
    "semantic_title": "transformer-based models are not yet perfect at learning to emulate structural recursion",
    "citation_count": 12,
    "authors": [
      "Dylan Zhang",
      "Curt Tigges",
      "Zory Zhang",
      "Stella Biderman",
      "Maxim Raginsky",
      "Talia Ringer"
    ]
  },
  "https://openreview.net/forum?id=zOJ846BXhl": {
    "title": "Revisiting Non-separable Binary Classification and its Applications in Anomaly Detection",
    "volume": "main",
    "abstract": "The inability to linearly classify $\\texttt{XOR}$ has motivated much of deep learning. We revisit this age-old problem and show that $\\textit{linear}$ classification of $\\texttt{XOR}$ is indeed possible. Instead of separating data between halfspaces, we propose a slightly different paradigm, $\\texttt{equality separation}$, that adapts the SVM objective to distinguish data within or outside the margin. Our classifier can then be integrated into neural network pipelines with a smooth approximation. From its properties, we intuit that equality separation is suitable for anomaly detection. To formalize this notion, we introduce $\\textit{closing numbers}$, a quantitative measure on the capacity for classifiers to form closed decision regions for anomaly detection. Springboarding from this theoretical connection between binary classification and anomaly detection, we test our hypothesis on supervised anomaly detection experiments, showing that equality separation can detect both seen and unseen anomalies",
    "checked": true,
    "id": "f7e6785ef72fc84037bce7f30f166e278cbed334",
    "semantic_title": "revisiting non-separable binary classification and its applications in anomaly detection",
    "citation_count": 3,
    "authors": [
      "Matthew Lau",
      "ISMAILA SECK",
      "Athanasios P Meliopoulos",
      "Wenke Lee",
      "Eugene Ndiaye"
    ]
  },
  "https://openreview.net/forum?id=JZVqDTNA59": {
    "title": "SEAL: Simultaneous Label Hierarchy Exploration And Learning",
    "volume": "main",
    "abstract": "Label hierarchy is an important source of external knowledge that can enhance classification performance. However, most existing methods rely on predefined label hierarchies that may not match the data distribution. To address this issue, we propose Simultaneous label hierarchy Exploration And Learning (SEAL), a new framework that explores the label hierarchy by augmenting the observed labels with latent labels that follow a prior hierarchical structure. Our approach uses a 1-Wasserstein metric over the tree metric space as an objective function, which enables us to simultaneously learn a data-driven label hierarchy and perform (semi-)supervised learning. We evaluate our method on several standard benchmarks and show that it achieves improved results in semi-supervised image classification scenarios",
    "checked": true,
    "id": "a96b0f3844d436b092ff96129a4e8c080b6519cb",
    "semantic_title": "seal: simultaneous label hierarchy exploration and learning",
    "citation_count": 6,
    "authors": [
      "Zhiquan Tan",
      "Zihao Wang",
      "Yifan Zhang"
    ]
  },
  "https://openreview.net/forum?id=1hcpXd9Jir": {
    "title": "Fast and Effective Weight Update for Pruned Large Language Models",
    "volume": "main",
    "abstract": "Pruning large language models (LLMs) is a challenging task due to their enormous size. The primary difficulty is fine-tuning the model after pruning, which is needed to recover the lost performance caused by dropping weights. Recent approaches have either ignored fine-tuning entirely, focusing on efficient pruning criteria, or attempted layer-wise weight updates, preserving the behavior of each layer. However, even layer-wise weight updates can be costly for LLMs, and previous works have resorted to various approximations. In our paper, we propose a fast and effective weight update algorithm for pruned layers based on the Alternating Direction Method of Multipliers (ADMM). We further extend it with a simple gradual pruning mask selection and achieve state-of-the-art pruning performance across a wide range of LLMs",
    "checked": true,
    "id": "6b4c299c26bdc9a81489121589b6ff70b9ebf403",
    "semantic_title": "fast and effective weight update for pruned large language models",
    "citation_count": 5,
    "authors": [
      "VladimÃ­r BoÅ¾a"
    ]
  },
  "https://openreview.net/forum?id=LNvbgBFPMt": {
    "title": "A Self-Representation Learning Method for Unsupervised Feature Selection using Feature Space Basis",
    "volume": "main",
    "abstract": "Current methods of feature selection based on a self-representation framework use all the features of the original data in their representation framework. This issue carries over redundant and noisy features into the representation space, thereby diminishing the quality and effectiveness of the results. This work proposes a novel representation learning method, dubbed GRSSLFS (Graph Regularized Self-Representation and Sparse Subspace Learning), that mitigates the drawbacks of using all features. GRSSLFS employs an approach for constructing a basis for the feature space, which includes those features with the highest variance. The objective function of GRSSLFS is then developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Moreover, these basis features are incorporated into a manifold learning term to preserve the geometrical structure of the underlying data. We provide an effectiveness and performance evaluation on several widely-used benchmark datasets. The results show that GRSSLFS achieves a high level of performance compared to several classic and state-of-the-art feature selection methods",
    "checked": true,
    "id": "3589272efdb3e147718ed0b6bf0e0a43fa327a04",
    "semantic_title": "a self-representation learning method for unsupervised feature selection using feature space basis",
    "citation_count": 7,
    "authors": [
      "Prayag Tiwari",
      "Farid Saberi Movahed",
      "Saeed Karami",
      "Farshad Saberi-Movahed",
      "Jens Lehmann",
      "Sahar Vahdati"
    ]
  },
  "https://openreview.net/forum?id=TAvGZm2Rqb": {
    "title": "Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints",
    "volume": "main",
    "abstract": "Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key real-world aspects that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type I and type II errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset; and iii) not dealing with human work-capacity constraints. To address these issues, we propose the \\textit{deferral under cost and capacity constraints framework} (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost, subject to workload limitations. We test DeCCaF in a series of cost-sensitive fraud detection scenarios with different teams of 9 synthetic fraud analysts, with individual work-capacity constraints. The results demonstrate that our approach performs significantly better than the baselines in a wide array of scenarios, achieving an average $8.4\\%$ reduction in the misclassification cost. The code used for the experiments is available at https://github.com/feedzai/deccaf",
    "checked": true,
    "id": "b775723b9270314966020fd61e7356cbe12bc360",
    "semantic_title": "cost-sensitive learning to defer to multiple experts with workload constraints",
    "citation_count": 6,
    "authors": [
      "Jean Vieira Alves",
      "Diogo LeitÃ£o",
      "SÃ©rgio Jesus",
      "Marco O. P. Sampaio",
      "Javier LiÃ©bana",
      "Pedro Saleiro",
      "Mario A. T. Figueiredo",
      "Pedro Bizarro"
    ]
  },
  "https://openreview.net/forum?id=voHKJOdCNw": {
    "title": "Task-Relevant Feature Selection with Prediction Focused Mixture Models",
    "volume": "main",
    "abstract": "Probabilistic models, such as mixture models, can encode latent structures that both explain the data and aid specific downstream tasks. We focus on a constrained setting where we want to learn a model with relatively few components (e.g. for interpretability). Simultaneously, we ensure that the components are useful for downstream predictions by introducing \\emph{prediction-focused} modeling for mixtures, which automatically selects data features relevant to a prediction task. Our approach identifies task-relevant input features, outperforms models that are not prediction-focused, and is easy to optimize; most importantly, we also characterize \\emph{when} prediction-focused modeling can be expected to work",
    "checked": true,
    "id": "40fbe18730fbaac8e96de937d9b7816c28d6691d",
    "semantic_title": "task-relevant feature selection with prediction focused mixture models",
    "citation_count": 0,
    "authors": [
      "Abhishek Sharma",
      "Catherine Zeng",
      "Sanjana Narayanan",
      "Sonali Parbhoo",
      "Roy H. Perlis",
      "Finale Doshi-Velez"
    ]
  },
  "https://openreview.net/forum?id=jG7ndW7UHp": {
    "title": "Convergence Analysis and Trajectory Comparison of Gradient Descent for Overparameterized Deep Linear Networks",
    "volume": "main",
    "abstract": "This paper presents a convergence analysis and trajectory comparison of the gradient descent (GD) method for overparameterized deep linear neural networks with different random initializations, demonstrating that the GD trajectory for these networks closely matches that of the corresponding convex optimization problem. This study touches upon one major open theoretical problem in machine learning--why deep neural networks trained with GD methods are efficient in many practical applications? While the solution of this problem is still beyond the reach of general nonlinear deep neural networks, extensive efforts have been invested in studying relevant questions for deep linear neural networks, and many interesting results have been reported to date. For example, recent results on loss landscape show that even though the loss function of deep linear neural networks is non-convex, every local minimizer is also a global minimizer. We focus on the trajectory of GD when applied to deep linear networks and demonstrate that, with appropriate initialization and sufficient width of the hidden layers, the GD trajectory closely matches that of the corresponding convex optimization problem. This result holds regardless of the depth of the network, providing insight into the efficiency of GD in the training of deep neural networks. Furthermore, we show that the GD trajectory for an overparameterized deep linear network automatically avoids bad saddle points",
    "checked": true,
    "id": "e483a798172567f8f04fef4fb819d6c15d374811",
    "semantic_title": "convergence analysis and trajectory comparison of gradient descent for overparameterized deep linear networks",
    "citation_count": 0,
    "authors": [
      "Hongru Zhao",
      "Jinchao Xu"
    ]
  },
  "https://openreview.net/forum?id=AQk0UsituG": {
    "title": "Variational Learning ISTA",
    "volume": "main",
    "abstract": "Compressed sensing combines the power of convex optimization techniques with a sparsity-inducing prior on the signal space to solve an underdetermined system of equations. For many problems, the sparsifying dictionary is not directly given, nor its existence can be assumed. Besides, the sensing matrix can change across different scenarios. Addressing these issues requires solving a sparse representation learning problem, namely dictionary learning, taking into account the epistemic uncertainty of the learned dictionaries and, finally, jointly learning sparse representations and reconstructions under varying sensing matrix conditions. We address both concerns by proposing a variant of the LISTA architecture. First, we introduce Augmented Dictionary Learning ISTA (A-DLISTA), which incorporates an augmentation module to adapt parameters to the current measurement setup. Then, we propose to learn a distribution over dictionaries via a variational approach, dubbed Variational Learning ISTA (VLISTA). VLISTA exploits A-DLISTA as the likelihood model and approximates a posterior distribution over the dictionaries as part of an unfolded LISTA-based recovery algorithm. As a result, VLISTA provides a probabilistic way to jointly learn the dictionary distribution and the reconstruction algorithm with varying sensing matrices. We provide theoretical and experimental support for our architecture and show that our model learns calibrated uncertainties",
    "checked": true,
    "id": "ea2d0358e43120add4a5de41c9b088c629612dc2",
    "semantic_title": "variational learning ista",
    "citation_count": 0,
    "authors": [
      "Fabio Valerio Massoli",
      "Christos Louizos",
      "Arash Behboodi"
    ]
  },
  "https://openreview.net/forum?id=c8WJ4Vozb2": {
    "title": "Correcting Flaws in Common Disentanglement Metrics",
    "volume": "main",
    "abstract": "Disentangled representations are those in which distinct features, such as size or shape, are represented by distinct neurons. Quantifying the extent to which a given representation is disentangled is not straightforward; multiple metrics have been proposed. In this paper, we identify two failings of existing metrics, which mean they can assign a high score to a model which is still entangled, and we propose two new metrics, which redress these problems. First, we use hypothetical toy examples to demonstrate the failure modes we identify for existing metrics. Then, we show that similar situations occur in practice. Finally, we validate our metrics on the downstream task of compositional generalization. We measure the performance of six existing disentanglement models on this downstream compositional generalization task, and show that performance is (a) generally quite poor, (b) correlated, to varying degrees, with most disentanglement metrics, and (c) most strongly correlated with our newly proposed metrics. Anonymous code to reproduce our results is available at https://github.com/anon296/anon",
    "checked": true,
    "id": "3b060cf21852ac5b125bd1c57d9fe5eefb8434d9",
    "semantic_title": "correcting flaws in common disentanglement metrics",
    "citation_count": 3,
    "authors": [
      "Louis Mahon",
      "Lei Sha",
      "Thomas Lukasiewicz"
    ]
  },
  "https://openreview.net/forum?id=BK6Gc10tRy": {
    "title": "Overcoming Order in Autoregressive Graph Generation for Molecule Generation",
    "volume": "main",
    "abstract": "Graph generation is a fundamental problem in various domains, and is of particular interest in chemistry where graphs may be used to represent molecules. Recent work has shown that molecular graph generation using recurrent neural networks (RNNs) is advantageous compared to traditional generative approaches which require converting continuous latent representations into graphs. One issue which arises when treating graph generation as sequential generation is the arbitrary order of the sequence which results from a particular choice of graph flattening method: in the chemistry setting, molecular graphs commonly have multiple SMILES strings corresponding to the same molecule. Inspired by the use case of molecular graph generation, we propose using RNNs, taking into account the non-sequential nature of graphs by adding an Orderless Regularization (OLR) term that encourages the hidden state of the recurrent model to be invariant to different valid orderings present under the training distribution. We demonstrate that sequential molecular graph generation models benefit from our proposed regularization scheme, especially when data is scarce. Our findings contribute to the growing body of research on graph generation and provide a valuable tool for various applications requiring the synthesis of realistic and diverse graph structures",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Edo Cohen-Karlik",
      "Eyal Rozenberg",
      "Daniel Freedman"
    ]
  },
  "https://openreview.net/forum?id=qSFToMqLcq": {
    "title": "Neural Clamping: Joint Input Perturbation and Temperature Scaling for Neural Network Calibration",
    "volume": "main",
    "abstract": "Neural network calibration is an essential task in deep learning to ensure consistency between the confidence of model prediction and the true correctness likelihood. In this paper, we propose a new post-processing calibration method called $\\textbf{Neural Clamping}$, which employs a simple joint input-output transformation on a pre-trained classifier via a learnable universal input perturbation and an output temperature scaling parameter. Moreover, we provide theoretical explanations on why Neural Clamping is provably better than temperature scaling. Evaluated on BloodMNIST, CIFAR-100, and ImageNet image recognition datasets and a variety of deep neural network models, our empirical results show that Neural Clamping significantly outperforms state-of-the-art post-processing calibration methods. The code is available at github.com/yungchentang/NCToolkit, and the demo is available at huggingface.co/spaces/TrustSafeAI/NCTV",
    "checked": true,
    "id": "4b8b62adb68546e2b7f8ec07b765f8f4c2a069b5",
    "semantic_title": "neural clamping: joint input perturbation and temperature scaling for neural network calibration",
    "citation_count": 5,
    "authors": [
      "Yung-Chen Tang",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ]
  },
  "https://openreview.net/forum?id=7HIOUZAoq5": {
    "title": "A replica analysis of under-bagging",
    "volume": "main",
    "abstract": "Under-bagging (UB), which combines under-sampling and bagging, is a popular ensemble learning method for training classifiers on an imbalanced data. Using bagging to reduce the increased variance caused by the reduction in sample size due to under-sampling is a natural approach. However, it has recently been pointed out that in generalized linear models, naive bagging, which does not consider the class imbalance structure, and ridge regularization can produce the same results. Therefore, it is not obvious whether it is better to use UB, which requires an increased computational cost proportional to the number of under-sampled data sets, when training linear models. Given such a situation, in this study, we heuristically derive a sharp asymptotics of UB and use it to compare with several other standard methods for learning from imbalanced data, in the scenario where a linear classifier is trained from a two-component mixture data. The methods compared include the under-sampling (US) method, which trains a model using a single realization of the subsampled data, and the simple weighting (SW) method, which trains a model with a weighted loss on the entire data. It is shown that the performance of UB is improved by increasing the size of the majority class while keeping the size of the minority fixed, even though the class imbalance can be large, especially when the size of the minority class is small. This is in contrast to US, whose performance is almost independent of the majority class size. In this sense, bagging and simple regularization differ as methods to reduce the variance increased by under-sampling. On the other hand, the performance of SW with the optimal weighting coefficients is almost equal to UB, indicating that the combination of reweighting and regularization may be similar to UB",
    "checked": true,
    "id": "7caea3cdfd41a381caa1fe93ced3548a1e65daf8",
    "semantic_title": "a replica analysis of under-bagging",
    "citation_count": 3,
    "authors": [
      "Takashi Takahashi"
    ]
  },
  "https://openreview.net/forum?id=YN0IcnXqsr": {
    "title": "Augment then Smooth: Reconciling Differential Privacy with Certified Robustness",
    "volume": "main",
    "abstract": "Machine learning models are susceptible to a variety of attacks that can erode trust, including attacks against the privacy of training data, and adversarial examples that jeopardize model accuracy. Differential privacy and certified robustness are effective frameworks for combating these two threats respectively, as they each provide future-proof guarantees. However, we show that standard differentially private model training is insufficient for providing strong certified robustness guarantees. Indeed, combining differential privacy and certified robustness in a single system is non-trivial, leading previous works to introduce complex training schemes that lack flexibility. In this work, we present DP-CERT, a simple and effective method that achieves both privacy and robustness guarantees simultaneously by integrating randomized smoothing into standard differentially private model training. Compared to the leading prior work, DP-CERT gives up to a 2.5x increase in certified accuracy for the same differential privacy guarantee on CIFAR10. Through in-depth per-sample metric analysis, we find that larger certifiable radii correlate with smaller local Lipschitz constants, and show that DP-CERT effectively reduces Lipschitz constants compared to other differentially private training methods. Code is available at github.com/layer6ai-labs/dp-cert",
    "checked": true,
    "id": "ad7f073eb1396a294007f21201d58afe52c73332",
    "semantic_title": "augment then smooth: reconciling differential privacy with certified robustness",
    "citation_count": 2,
    "authors": [
      "Jiapeng Wu",
      "Atiyeh Ashari Ghomi",
      "David Glukhov",
      "Jesse C. Cresswell",
      "Franziska Boenisch",
      "Nicolas Papernot"
    ]
  },
  "https://openreview.net/forum?id=BmI5p6wBi0": {
    "title": "Deep Unlearning: Fast and Efficient Gradient-free Class Forgetting",
    "volume": "main",
    "abstract": "Machine unlearning is a prominent and challenging field, driven by regulatory demands for user data deletion and heightened privacy awareness. Existing approaches involve retraining model or multiple finetuning steps for each deletion request, often constrained by computational limits and restricted data access. In this work, we introduce a novel class unlearning algorithm designed to strategically eliminate specific classes from the learned model. Our algorithm first estimates the Retain and the Forget Spaces using Singular Value Decomposition on the layerwise activations for a small subset of samples from the retain and unlearn classes, respectively. We then compute the shared information between these spaces and remove it from the forget space to isolate class-discriminatory feature space. Finally, we obtain the unlearned model by updating the weights to suppress the class discriminatory features from the activation spaces. We demonstrate our algorithm's efficacy on ImageNet using a Vision Transformer with only ~1.5% drop in retain accuracy compared to the original model while maintaining under 1% accuracy on the unlearned class samples. Furthermore, our algorithm exhibits competitive unlearning performance and resilience against Membership Inference Attacks (MIA). Compared to baselines, it achieves an average accuracy improvement of 1.38% on the ImageNet dataset while requiring up to 10x fewer samples for unlearning. Additionally, under stronger MIA attacks on the CIFAR-100 dataset using a ResNet18 architecture, our approach outperforms the best baseline by 1.8%",
    "checked": true,
    "id": "6063e55be14840dede97a56e4f41062bf094548d",
    "semantic_title": "deep unlearning: fast and efficient gradient-free class forgetting",
    "citation_count": 3,
    "authors": [
      "Sangamesh Kodge",
      "Gobinda Saha",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=7jgu4oXsGM": {
    "title": "Dual-windowed Vision Transformer with Angular Self- Attention",
    "volume": "main",
    "abstract": "Following the great success in natural language processing, transformer-based models have emerged as the competitive model against the convolutional neural networks in computer vision. Vision transformer (ViT) and its subsequent variants have exhibited promising performance in tasks such as image classification, object detection and semantic segmentation. The core of vision transformers is the self-attention mechanism, which models the long-range dependency of different tokens. Conventionally, the attention matrix in self-attention is calculated by the scaled dot-product of \\textit{query} (Q) and \\textit{key} (K). In this case, the attention weight would depend on norm of Q and K as well as the angle between them. In this paper, we propose a new attention mechanism named angular self-attention, which replaces the scaled dot-product operation with the angular function in order to effectively model the relationship between tokens. In particular, we propose two forms of functions: quadratic and cosine functions, for our angular self-attention. Based on angular self-attention, we design a new vision transformer architecture called dual-windowed angular vision transformer (\\textbf{DWAViT}). DWAViT is a hierarchical-structured model characterized by the angular self-attention and a new local window mechanism. We evaluate DWAViT on multiple computer vision benchmarks, including image classification on ImageNet-1K, object detection on COCO, and semantic segmentation on ADE20K. Our experimental results also suggest that our model can achieve promising performance on the tasks while maintaining comparable computational cost with that of the baseline models (e.g., Swin Transformer)",
    "checked": true,
    "id": "068e71454d481b451678006797bbbe3ce970eec9",
    "semantic_title": "dual-windowed vision transformer with angular self- attention",
    "citation_count": 0,
    "authors": [
      "Weili Shi",
      "Sheng Li"
    ]
  },
  "https://openreview.net/forum?id=YfPzUX6DdO": {
    "title": "On the Importance of Uncertainty in Decision-Making with Large Language Models",
    "volume": "main",
    "abstract": "We investigate the role of uncertainty in decision-making problems with natural language as input. For such tasks, using Large Language Models as agents has become the norm. However, none of the recent approaches employ any additional phase for estimating the uncertainty the agent has about the world during the decision-making task. We focus on a fundamental decision-making framework with natural language as input, which is the one of contextual bandits, where the context information consists of text. As a representative of the approaches with no uncertainty estimation, we consider an LLM agent with a greedy policy, which picks the action corresponding to the largest predicted reward. We compare this baseline to LLM agents that make active use of uncertainty estimation by integrating the uncertainty in a Thompson Sampling policy. We employ different techniques for uncertainty estimation, such as Laplace Approximation, Dropout, and Epinets. We empirically show on real-world data that the greedy policy performs worse than the Thompson Sampling policies. These findings suggest that, while overlooked in the LLM literature, uncertainty improves performance on bandit tasks with LLM agents",
    "checked": true,
    "id": "4e15901eaaaa9a9c2c30f64e05054ce6f5cdaa97",
    "semantic_title": "on the importance of uncertainty in decision-making with large language models",
    "citation_count": 2,
    "authors": [
      "NicolÃ² Felicioni",
      "Lucas Maystre",
      "Sina Ghiassian",
      "Kamil Ciosek"
    ]
  },
  "https://openreview.net/forum?id=9B6LM2uoEs": {
    "title": "ITEM: Improving Training and Evaluation of Message-Passing based GNNs for top-k recommendation",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs), especially message-passing-based models, have become prominent in top-k recommendation tasks, outperforming matrix factorization models due to their ability to efficiently aggregate information from a broader context. Although GNNs are evaluated with ranking-based metrics, e.g NDCG@k and Recall@k, they remain largely trained with proxy losses, e.g the BPR loss. In this work we explore the use of ranking loss functions to directly optimize the evaluation metrics, an area not extensively investigated in the GNN community for collaborative filtering. We take advantage of smooth approximations of the rank to facilitate end-to-end training of GNNs and propose a Personalized PageRank-based negative sampling strategy tailored for ranking loss functions. Moreover, we extend the evaluation of GNN models for top-k recommendation tasks with an inductive user-centric protocol, providing a more accurate reflection of real-world applications. Our proposed method significantly outperforms the standard BPR loss and more advanced losses across four datasets and four recent GNN architectures while also exhibiting faster training. Demonstrating the potential of ranking loss functions in improving GNN training for collaborative filtering tasks",
    "checked": true,
    "id": "fb3334a2ad42fad700d3f17a998b8dd3aa1ecb93",
    "semantic_title": "item: improving training and evaluation of message-passing based gnns for top-k recommendation",
    "citation_count": 0,
    "authors": [
      "Yannis Karmim",
      "Elias Ramzi",
      "Raphael Fournier-S'niehotta",
      "Nicolas THOME"
    ]
  },
  "https://openreview.net/forum?id=iwCBWULItx": {
    "title": "DeepReShape: Redesigning Neural Networks for Efficient Private Inference",
    "volume": "main",
    "abstract": "Prior work on Private Inference (PI)---inferences performed directly on encrypted input---has focused on minimizing a network's ReLUs, which have been assumed to dominate PI latency rather than FLOPs. Recent work has shown that FLOPs for PI can no longer be ignored and incur high latency penalties. In this paper, we develop DeepReShape, a technique that optimizes neural network architectures under PI's constraints, optimizing for both ReLUs {\\em and} FLOPs for the first time. The key insight is strategically allocating channels to position the network's ReLUs in order of their criticality to network accuracy, simultaneously optimizes ReLU and FLOPs efficiency. DeepReShape automates network development with an efficient process, and we call generated networks HybReNets. We evaluate DeepReShape using standard PI benchmarks and demonstrate a 2.1% accuracy gain with a 5.2$\\times$ runtime improvement at iso-ReLU on CIFAR-100 and an 8.7$\\times$ runtime improvement at iso-accuracy on TinyImageNet. Furthermore, we investigate the significance of network selection in prior ReLU optimizations and shed light on the key network attributes for superior PI performance",
    "checked": true,
    "id": "ec6405ad32353640159fc7daa37128ab3ba92cd0",
    "semantic_title": "deepreshape: redesigning neural networks for efficient private inference",
    "citation_count": 10,
    "authors": [
      "Nandan Kumar Jha",
      "Brandon Reagen"
    ]
  },
  "https://openreview.net/forum?id=8uCNtJ2Fmo": {
    "title": "Exploiting Edge Features in Graph-based Learning with Fused Network Gromov-Wasserstein Distance",
    "volume": "main",
    "abstract": "Pairwise comparison of graphs is key to many applications in Machine Learning ranging from clustering, kernel-based classification/regression and more recently supervised graph prediction. Distances between graphs usually rely on informative representations of these structured objects such as bag of substructures or other graph embeddings. A recently popular solution consists in representing graphs as metric measure spaces, allowing to successfully leverage Optimal Transport, which provides meaningful distances allowing to compare them, namely the Gromov-Wasserstein distance and its variant the Fused Gromov-Wasserstein that applies on node attributed graphs. However, this family of distances overlooks edge attributes, which are essential for many structured objects. In this work, we introduce an extension of the Fused Gromov-Wasserstein distance for comparing graphs whose both nodes and edges have features. We propose novel algorithms for distance and barycenter computation. We present a range of studies that illustrate the properties of the proposed distance and empirically demonstrate its effectiveness in supervised graph prediction tasks",
    "checked": true,
    "id": "ee2022d0ebcd6337d6f017a714c0399666ce3642",
    "semantic_title": "exploiting edge features in graph-based learning with fused network gromov-wasserstein distance",
    "citation_count": 1,
    "authors": [
      "Junjie Yang",
      "Matthieu Labeau",
      "Florence d'AlchÃ©-Buc"
    ]
  },
  "https://openreview.net/forum?id=Nux7OVXpJ9": {
    "title": "Mini-Batch Optimization of Contrastive Loss",
    "volume": "main",
    "abstract": "Contrastive learning has gained significant attention as a pre-training method for self-supervised learning due to its ability to leverage large amounts of unlabeled data. A contrastive loss function ensures that embeddings of positive sample pairs (e.g., from the same class or different views of the same data) are similar, while embeddings of negative pairs are dissimilar. However, practical constraints such as large memory requirements make it infeasible to consider all possible positive and negative pairs, leading to the use of mini-batches. In this paper, we investigate the theoretical aspects of mini-batch optimization in contrastive learning with the InfoNCE loss. We show that mini-batch optimization is equivalent to full-batch optimization if and only if all $\\binom{N}{B}$ mini-batches are selected, while sub-optimality may arise when examining only a subset. We then demonstrate that utilizing high-loss mini-batches can speed up SGD convergence and propose a spectral clustering-based approach for identifying these high-loss mini-batches. Our experimental results validate our theoretical findings and demonstrate that our proposed algorithm outperforms vanilla SGD, providing a better understanding of mini-batch optimization in contrastive learning",
    "checked": true,
    "id": "df07d12c601a2bb1ff033388e2f5efbd0982a54d",
    "semantic_title": "mini-batch optimization of contrastive loss",
    "citation_count": 10,
    "authors": [
      "Jaewoong Cho",
      "Kartik Sreenivasan",
      "Keon Lee",
      "Kyunghoo Mun",
      "Soheun Yi",
      "Jeong-Gwan Lee",
      "Anna Lee",
      "Jy-yong Sohn",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ]
  },
  "https://openreview.net/forum?id=fa1ne8xDGn": {
    "title": "Improved motif-scaffolding with SE(3) flow matching",
    "volume": "main",
    "abstract": "Protein design often begins with the knowledge of a desired function from a motif which motif-scaffolding aims to construct a functional protein around. Recently, generative models have achieved breakthrough success in designing scaffolds for a range of motifs. However, generated scaffolds tend to lack structural diversity, which can hinder success in wet-lab validation. In this work, we extend FrameFlow, an SE(3) flow matching model for protein backbone generation, to perform motif-scaffolding with two complementary approaches. The first is motif amortization, in which FrameFlow is trained with the motif as input using a data augmentation strategy. The second is motif guidance, which performs scaffolding using an estimate of the conditional score from FrameFlow without additional training. On a benchmark of 24 biologically meaningful motifs, we show our method achieves 2.5 times more designable and unique motif-scaffolds compared to state-of-the-art. Code: https://github.com/microsoft/protein-frame-flow",
    "checked": true,
    "id": "182b095a6fbd6bd861989ca25c167369f9342d23",
    "semantic_title": "improved motif-scaffolding with se(3) flow matching",
    "citation_count": 37,
    "authors": [
      "Jason Yim",
      "Andrew Campbell",
      "Emile Mathieu",
      "Andrew Y. K. Foong",
      "Michael Gastegger",
      "Jose Jimenez-Luna",
      "Sarah Lewis",
      "Victor Garcia Satorras",
      "Bastiaan S. Veeling",
      "Frank Noe",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ]
  },
  "https://openreview.net/forum?id=gPtjyzXskg": {
    "title": "XAudit : A Learning-Theoretic Look at Auditing with Explanations",
    "volume": "main",
    "abstract": "Responsible use of machine learning requires models to be audited for undesirable properties. While a body of work has proposed using explanations for auditing, how to do so and why has remained relatively ill-understood. This work formalizes the role of explanations in auditing using inspirations from active learning and investigates if and how model explanations can help audits. As an instantiation of our framework, we look at `feature sensitivity' and propose explanation-based algorithms for auditing linear classifiers and decision trees for this property. Our results illustrate that Counterfactual explanations are extremely helpful for auditing feature sensitivity, even in the worst-case. While Anchor explanations and decision paths may not be as beneficial in the worst-case, in the average-case they do aid significantly as demonstrated by our experiments",
    "checked": true,
    "id": "c1dedca633d3e665a7cd9d543ad23431b1036fd8",
    "semantic_title": "xaudit : a learning-theoretic look at auditing with explanations",
    "citation_count": 1,
    "authors": [
      "Chhavi Yadav",
      "Michal Moshkovitz",
      "Kamalika Chaudhuri"
    ]
  },
  "https://openreview.net/forum?id=0Hm01Vc8zT": {
    "title": "Fair Representation in Submodular Subset Selection: A Pareto Optimization Approach",
    "volume": "main",
    "abstract": "Many machine learning applications, such as feature selection, recommendation, and social advertising, require the joint optimization of the global utility and the representativeness for different groups of items or users. To meet such requirements, we propose a novel multi-objective combinatorial optimization problem called Submodular Maximization with Fair Representation (SMFR), which selects subsets from a ground set, subject to a knapsack or matroid constraint, to maximize a submodular (utility) function $f$ as well as a set of $d$ submodular (representativeness) functions $g_1, \\dots, g_d$. We show that the maximization of $f$ might conflict with the maximization of $g_1, \\dots, g_d$, so that no single solution can optimize all these objectives at the same time. Therefore, we propose a Pareto optimization approach to SMFR, which finds a set of solutions to approximate all Pareto-optimal solutions with different trade-offs between the objectives. Our method converts an instance of SMFR into several submodular cover instances by adjusting the weights of the objective functions; then it computes a set of solutions by running the greedy algorithm on each submodular cover instance. We prove that our method provides approximation guarantees for SMFR under knapsack or matroid constraints. Finally, we demonstrate the effectiveness of SMFR and our proposed approach in two real-world problems: maximum coverage and recommendation",
    "checked": true,
    "id": "abbdafcdff1a980173f565138c0f9069280f2424",
    "semantic_title": "fair representation in submodular subset selection: a pareto optimization approach",
    "citation_count": 1,
    "authors": [
      "Adriano Fazzone",
      "Yanhao Wang",
      "Francesco Bonchi"
    ]
  },
  "https://openreview.net/forum?id=QXLKnrymE1": {
    "title": "Representation Learning Dynamics of Self-Supervised Models",
    "volume": "main",
    "abstract": "Self-Supervised Learning (SSL) is an important paradigm for learning representations from unlabelled data, and SSL with neural networks has been highly successful in practice. However current theoretical analysis of SSL is mostly restricted to generalisation error bounds. In contrast, learning dynamics often provide a precise characterisation of the behaviour of neural networks based models but, so far, are mainly known in supervised settings. In this paper, we study the learning dynamics of SSL models, specifically representations obtained by minimising contrastive and non-contrastive losses. We show that a naive extension of the dymanics of multivariate regression to SSL leads to learning trivial scalar representations that demonstrates dimension collapse in SSL. Consequently, we formulate SSL objectives with orthogonality constraints on the weights, and derive the exact (network width independent) learning dynamics of the SSL models trained using gradient descent on the Grassmannian manifold. We also argue that the infinite width approximation of SSL models significantly deviate from the neural tangent kernel approximations of supervised models. We numerically illustrate the validity of our theoretical findings, and discuss how the presented results provide a framework for further theoretical analysis of contrastive and non-contrastive SSL",
    "checked": true,
    "id": "80ebfa3f03c163671ced714cb729848800719a01",
    "semantic_title": "representation learning dynamics of self-supervised models",
    "citation_count": 3,
    "authors": [
      "Pascal Esser",
      "Satyaki Mukherjee",
      "Debarghya Ghoshdastidar"
    ]
  },
  "https://openreview.net/forum?id=pRt1Vw1DPs": {
    "title": "Learning Counterfactually Invariant Predictors",
    "volume": "main",
    "abstract": "Notions of counterfactual invariance (CI) have proven essential for predictors that are fair, robust, and generalizable in the real world. We propose graphical criteria that yield a sufficient condition for a predictor to be counterfactually invariant in terms of a conditional independence in the observational distribution. In order to learn such predictors, we propose a model-agnostic framework, called Counterfactually Invariant Prediction (CIP), building on the Hilbert-Schmidt Conditional Independence Criterion (HSCIC), a kernel-based conditional dependence measure. Our experimental results demonstrate the effectiveness of CIP in enforcing counterfactual invariance across various simulated and real-world datasets including scalar and multi-variate settings",
    "checked": true,
    "id": "f100e4f6834b875af52eac9d8912720f7a0c4d03",
    "semantic_title": "learning counterfactually invariant predictors",
    "citation_count": 10,
    "authors": [
      "Francesco Quinzan",
      "Cecilia Casolo",
      "Krikamol Muandet",
      "Yucen Luo",
      "Niki Kilbertus"
    ]
  },
  "https://openreview.net/forum?id=wLe1bG93yc": {
    "title": "A Note on the Convergence of Denoising Diffusion Probabilistic Models",
    "volume": "main",
    "abstract": "Diffusion models are one of the most important families of deep generative models. In this note, we derive a quantitative upper bound on the Wasserstein distance between the target distribution and the distribution learned by a diffusion model. Unlike previous works on this topic, our result does not make assumptions on the learned score function. Moreover, our result holds for arbitrary data-generating distributions on bounded instance spaces, even those without a density with respect to Lebesgue measure, and the upper bound does not suffer from exponential dependencies on the ambient space dimension. Our main result builds upon the recent work of Mbacke et al. (2023) and our proofs are elementary",
    "checked": true,
    "id": "dbbf5520cb43ce3acf60b5fae69dfd3907ce659d",
    "semantic_title": "a note on the convergence of denoising diffusion probabilistic models",
    "citation_count": 6,
    "authors": [
      "Sokhna Diarra Mbacke",
      "Omar Rivasplata"
    ]
  },
  "https://openreview.net/forum?id=P3Lyun7CZs": {
    "title": "Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation",
    "volume": "main",
    "abstract": "Data attribution methods trace model behavior back to its training dataset, offering an effective approach to better understand ``black-box'' neural networks. While prior research established quantifiable links between model output and training data in diverse settings, interpreting diffusion model outputs in relation to training samples remains underexplored. In particular, diffusion models operate over a sequence of timesteps instead of instantaneous input-output relationships in previous contexts, posing a significant challenge to extend existing frameworks to diffusion models directly. Notably, we present Diffusion-TracIn that incorporates this temporal dynamics and observe that samples' loss gradient norms are highly dependent on timestep. This trend leads to a prominent bias in influence estimation, and is particularly severe for samples trained on large-norm-inducing timesteps, causing them to be generally influential. To mitigate this bias, we introduce Diffusion-ReTrac as a re-normalized adaptation that retrieves training samples targeted to the test sample of interest, enabling a localized measurement of influence and considerably more intuitive visualization. We demonstrate the efficacy of our approach through various evaluation metrics and auxiliary tasks, outperforming in terms of specificity of attribution by over $60\\%$",
    "checked": true,
    "id": "9041bd51883479ebbc2a492acc30c05758185f33",
    "semantic_title": "data attribution for diffusion models: timestep-induced bias in influence estimation",
    "citation_count": 4,
    "authors": [
      "Tong Xie",
      "Haoyu Li",
      "Andrew Bai",
      "Cho-Jui Hsieh"
    ]
  },
  "https://openreview.net/forum?id=RNsnSLdmV7": {
    "title": "Language Models Are Better Than Humans at Next-token Prediction",
    "volume": "main",
    "abstract": "Current language models are considered to have sub-human capabilities at natural language tasks like question-answering or writing code. However, causal language models are not trained to perform well at these tasks; they are trained to accurately predict the next token given previous tokens in tokenized text. It is not clear whether language models are better or worse than humans at next-token prediction. To try to answer this question, we performed two distinct experiments to directly compare humans and language models on this front: one measuring top-1 accuracy and the other measuring perplexity on OpenWebText. In both experiments, we find humans to be consistently \\emph{worse} than relatively small language models like GPT-Neo-1.3B or GPT-2-large at next-token prediction",
    "checked": true,
    "id": "7cbc7aa08b96de770d9ce5c90d01e75e9df2caee",
    "semantic_title": "language models are better than humans at next-token prediction",
    "citation_count": 12,
    "authors": [
      "Buck Shlegeris",
      "Fabien Roger",
      "Lawrence Chan",
      "Euan McLean"
    ]
  },
  "https://openreview.net/forum?id=Z8wcREe9qV": {
    "title": "Harnessing the Power of Federated Learning in Federated Contextual Bandits",
    "volume": "main",
    "abstract": "Federated learning (FL) has demonstrated great potential in revolutionizing distributed machine learning, and tremendous efforts have been made to extend it beyond the original focus on supervised learning. Among many directions, federated contextual bandits (FCB), a pivotal integration of FL and sequential decision-making, has garnered significant attention in recent years. Despite substantial progress, existing FCB approaches have largely employed their tailored FL components, often deviating from the canonical FL framework. Consequently, even renowned algorithms like FedAvg remain under-utilized in FCB, let alone other FL advancements. Motivated by this disconnection, this work takes one step towards building a tighter relationship between the canonical FL study and the investigations on FCB. In particular, a novel FCB design, termed FedIGW, is proposed to leverage a regression-based CB algorithm, i.e., inverse gap weighting. Compared with existing FCB approaches, the proposed FedIGW design can better harness the entire spectrum of FL innovations, which is concretely reflected as (1) flexible incorporation of (both existing and forthcoming) FL protocols; (2) modularized plug-in of FL analyses in performance guarantees; (3) seamless integration of FL appendages (such as personalization, robustness, and privacy). We substantiate these claims through rigorous theoretical analyses and empirical evaluations",
    "checked": true,
    "id": "d470b07ae85e67b689ba2cbc0be3104f543036b5",
    "semantic_title": "harnessing the power of federated learning in federated contextual bandits",
    "citation_count": 0,
    "authors": [
      "Chengshuai Shi",
      "Ruida Zhou",
      "Kun Yang",
      "Cong Shen"
    ]
  },
  "https://openreview.net/forum?id=Viz7KBqO4A": {
    "title": "Diversity-Preserving $K$--Armed Bandits, Revisited",
    "volume": "main",
    "abstract": "We consider the bandit-based framework for diversity-preserving recommendations introduced by Celis et al. (2019), who approached it in the case of a polytope mainly by a reduction to the setting of linear bandits. We design a UCB algorithm using the specific structure of the setting and show that it enjoys a bounded distribution-dependent regret in the natural cases when the optimal mixed actions put some probability mass on all actions (i.e., when diversity is desirable). The regret lower bounds provided show that otherwise, at least when the model is mean-unbounded, a $\\ln T$ regret is suffered. We also discuss an example beyond the special case of polytopes",
    "checked": false,
    "id": "ae5ccb6689b00fc7d342460fb17a3bca60f88f26",
    "semantic_title": "multi-fidelity multi-armed bandits revisited",
    "citation_count": 5,
    "authors": [
      "Hedi Hadiji",
      "SÃ©bastien Gerchinovitz",
      "Jean-Michel Loubes",
      "Gilles Stoltz"
    ]
  },
  "https://openreview.net/forum?id=7wybYcK1pw": {
    "title": "Masked multi-prediction for multi-aspect anomaly detection",
    "volume": "main",
    "abstract": "In this paper, we address the anomaly detection problem in the context of heterogeneous normal observations and propose an approach that accounts for this heterogeneity. Although prediction-based methods are common to learn normality, the vast majority of previous work predicts a single outcome, which is generally not sufficient to account for the multiplicity of possible normal observations. To address this issue, we introduce a new masked multi-prediction (MMP) approach that produces multiple likely normal outcomes, and show both theoretically and experimentally that it improves normality learning and leads to a better anomaly detection performance. In addition, we observed that normality can be characterized from multiple aspects, depending on the types of anomalies to be detected. Therefore, we propose an adaptation (MMP-AMS) of our approach to cover multiple aspects of normality such as appearance, motion, semantics and location. Since we model each aspect separately, our approach has the advantage of being interpretable and modular, as we can select only a subset of normality aspects. The experiments conducted on several benchmarks show the effectiveness of the proposed approach",
    "checked": true,
    "id": "ab922fe99d399293896a1912cd8e42df48dec414",
    "semantic_title": "masked multi-prediction for multi-aspect anomaly detection",
    "citation_count": 0,
    "authors": [
      "Yassine Naji",
      "Romaric Audigier",
      "Aleksandr Setkov",
      "Angelique Loesch",
      "MichÃ¨le GouiffÃ¨s"
    ]
  },
  "https://openreview.net/forum?id=ZTcxp9xYr2": {
    "title": "Read Between the Layers: Leveraging Multi-Layer Representations for Rehearsal-Free Continual Learning with Pre-Trained Models",
    "volume": "main",
    "abstract": "We address the Continual Learning (CL) problem, wherein a model must learn a sequence of tasks from non-stationary distributions while preserving prior knowledge upon encountering new experiences. With the advancement of foundation models, CL research has pivoted from the initial learning-from-scratch paradigm towards utilizing generic features from large-scale pre-training. However, existing approaches to CL with pre-trained models primarily focus on separating class-specific features from the final representation layer and neglect the potential of intermediate representations to capture low- and mid-level features, which are more invariant to domain shifts. In this work, we propose LayUP, a new prototype-based approach to CL that leverages second-order feature statistics from multiple intermediate layers of a pre-trained network. Our method is conceptually simple, does not require access to prior data, and works out of the box with any foundation model. LayUP surpasses the state of the art in four of the seven class-incremental learning benchmarks, all three domain-incremental learning benchmarks and in six of the seven online continual learning benchmarks, while significantly reducing memory and computational requirements compared to existing baselines. Our results demonstrate that fully exhausting the representational capacities of pre-trained models in CL goes well beyond their final embeddings",
    "checked": false,
    "id": "f004600be7e25df6f2834c70cfd623fddd25093a",
    "semantic_title": "read between the layers: leveraging intra-layer representations for rehearsal-free continual learning with pre-trained models",
    "citation_count": 7,
    "authors": [
      "Kyra Ahrens",
      "Hans Hergen Lehmann",
      "Jae Hee Lee",
      "Stefan Wermter"
    ]
  },
  "https://openreview.net/forum?id=WCUT6leXKf": {
    "title": "SeqLink: A Robust Neural-ODE Architecture for Modelling Partially Observed Time Series",
    "volume": "main",
    "abstract": "Ordinary Differential Equations (ODEs) based models have become popular as foundation models for solving many time series problems. Combining neural ODEs with traditional RNN models has provided the best representation for irregular time series. However, ODEs-based models typically require the trajectory of hidden states to be defined based on either the initial observed value or the most recent observation, raising questions about their effectiveness when dealing with longer sequences and extended time intervals. In this article, we explore the behaviour of the ODEs-based models in the context of time series data with varying degrees of sparsity. We introduce SeqLink, an innovative neural architecture designed to enhance the robustness of sequence representation. Unlike traditional approaches that solely rely on the hidden state generated from the last observed value, SeqLink leverages ODE latent representations derived from multiple data samples, enabling it to generate robust data representations regardless of sequence length or data sparsity level. The core concept behind our model is the definition of hidden states for the unobserved values based on the relationships between samples (links between sequences). Through extensive experiments on partially observed synthetic and real-world datasets, we demonstrate that SeqLink improves the modelling of intermittent time series, consistently outperforming state-of-the-art approaches",
    "checked": true,
    "id": "248581d85b2d4578c3771261ccf209bf38b68efc",
    "semantic_title": "seqlink: a robust neural-ode architecture for modelling partially observed time series",
    "citation_count": 3,
    "authors": [
      "Futoon M. Abushaqra",
      "Hao Xue",
      "Yongli Ren",
      "Flora D. Salim"
    ]
  },
  "https://openreview.net/forum?id=oxAZv3QD6M": {
    "title": "XPL: A Cross-Model framework for Semi-Supervised Prompt Learning in Vision-Language Models",
    "volume": "main",
    "abstract": "Prompt learning, which focuses on learning soft prompts, has emerged as a promising approach for efficiently adapting pretrained vision-language models (VLMs) to multiple downstream tasks. While prior works have shown promising performances on common benchmarks, they typically rely on labeled data samples only. This greatly discredits the information gain from the vast collection of otherwise unlabeled samples available in the wild. To mitigate this, we propose a simple yet efficient cross-model framework to leverage on the unlabeled samples achieving significant gain in model performance. Specifically, we employ a semi-supervised prompt learning approach which makes the learned prompts invariant to the different views of a given unlabeled sample. The multiple views are obtained using different augmentations on the images as well as by varying the lengths of visual and text prompts attached to these samples. Experimenting with this simple yet surprisingly effective approach over a large number of benchmark datasets, we observe a considerable improvement in the quality of soft prompts thereby making an immense gain in image classification performance. Interestingly, our approach also benefits from out-of-domain unlabeled images highlighting the robustness and generalization capabilities",
    "checked": true,
    "id": "5df96854f490c51a131bfe5b0ba32ef77b194691",
    "semantic_title": "xpl: a cross-model framework for semi-supervised prompt learning in vision-language models",
    "citation_count": 0,
    "authors": [
      "Omprakash Chakraborty",
      "Aadarsh Sahoo",
      "Rameswar Panda",
      "Abir Das"
    ]
  },
  "https://openreview.net/forum?id=u8K83M9mbG": {
    "title": "Revisiting Active Learning in the Era of Vision Foundation Models",
    "volume": "main",
    "abstract": "Foundation vision or vision-language models are trained on large unlabeled or noisy data and learn robust representations that can achieve impressive zero- or few-shot performance on diverse tasks. Given these properties, they are a natural fit for _active learning_ (AL), which aims to maximize labeling efficiency. However, the full potential of foundation models has not been explored in the context of AL, specifically in the low-budget regime. In this work, we evaluate how foundation models influence three critical components of effective AL, namely, 1) initial labeled pool selection, 2) ensuring diverse sampling, and 3) the trade-off between representative and uncertainty sampling. We systematically study how the robust representations of foundation models (DINOv2, OpenCLIP) challenge existing findings in active learning. Our observations inform the principled construction of a new simple and elegant AL strategy that balances uncertainty estimated via dropout with sample diversity. We extensively test our strategy on many challenging image classification benchmarks, including natural images as well as out-of-domain biomedical images that are relatively understudied in the AL literature. We also provide a highly performant and efficient implementation of modern AL strategies (including our method) at https://github.com/sanketx/AL-foundation-models",
    "checked": true,
    "id": "5a9b63062cbf5f8347aa6e62364cba792977dd6e",
    "semantic_title": "revisiting active learning in the era of vision foundation models",
    "citation_count": 5,
    "authors": [
      "Sanket Rajan Gupte",
      "Josiah Aklilu",
      "Jeffrey J Nirschl",
      "Serena Yeung-Levy"
    ]
  },
  "https://openreview.net/forum?id=CuyJkNjIVd": {
    "title": "Homogenizing Non-IID Datasets via In-Distribution Knowledge Distillation for Decentralized Learning",
    "volume": "main",
    "abstract": "Decentralized learning enables serverless training of deep neural networks (DNNs) in a distributed manner on multiple nodes. One of the key challenges with decentralized learning is heterogeneity in the data distribution across the nodes. Data heterogeneity results in slow and unstable global convergence and therefore poor generalization performance. In this paper, we propose In-Distribution Knowledge Distillation (IDKD) to address the challenge of heterogeneous data distribution. The goal of IDKD is to homogenize the data distribution across the nodes. While such data homogenization can be achieved by exchanging data among the nodes sacrificing privacy, IDKD achieves the same objective using a common public dataset across nodes without breaking the privacy constraint. This public dataset is different from the training dataset and is used to distill the knowledge from each node and communicate it to its neighbors through the generated labels. With traditional knowledge distillation, the generalization of the distilled model is reduced due to misalignment between the private and public data distribution. Thus, we introduce an Out-of-Distribution (OoD) detector at each node to label a subset of the public dataset that maps close to the local training data distribution. Our experiments on multiple image classification datasets and graph topologies show that the proposed IDKD scheme is more effective than traditional knowledge distillation and achieves state-of-the-art generalization performance on heterogeneously distributed data with minimal communication overhead",
    "checked": true,
    "id": "b5c834d985aa3193e37b5a71b4d97b6bc8ae4f99",
    "semantic_title": "homogenizing non-iid datasets via in-distribution knowledge distillation for decentralized learning",
    "citation_count": 2,
    "authors": [
      "Deepak Ravikumar",
      "Gobinda Saha",
      "Sai Aparna Aketi",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=VGNBUS9TrU": {
    "title": "Combine and Conquer: A Meta-Analysis on Data Shift and Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "This paper introduces a universal approach to seamlessly combine out-of-distribution (OOD) detection scores. These scores encompass a wide range of techniques that leverage the self-confidence of deep learning models and the anomalous behavior of features in the latent space. Not surprisingly, combining such a varied population using simple statistics proves inadequate. To overcome this challenge, we propose a quantile normalization to map these scores into p-values, effectively framing the problem into a multi-variate hypothesis test. Then, we combine these tests using established meta-analysis tools, resulting in a more effective detector with consolidated decision boundaries. Furthermore, we create a probabilistic interpretable criterion by mapping the final statistics into a distribution with known parameters. Through empirical investigation, we explore different types of shifts, each exerting varying degrees of impact on data. Our results demonstrate that our approach significantly improves overall robustness and performance across diverse OOD detection scenarios. Notably, our framework is easily extensible for future developments in detection scores and stands as the first to combine decision boundaries in this context. The code and artifacts associated with this work are publicly available\\footnote{\\url{https://github.com/edadaltocg/detectors}}",
    "checked": true,
    "id": "b6d99b08dc24197ae4926611a7ae6ac84f591572",
    "semantic_title": "combine and conquer: a meta-analysis on data shift and out-of-distribution detection",
    "citation_count": 0,
    "authors": [
      "Eduardo Dadalto CÃ¢mara Gomes",
      "Florence Alberge",
      "Pierre Duhamel",
      "Pablo Piantanida"
    ]
  },
  "https://openreview.net/forum?id=otTFPjziiK": {
    "title": "Directed Graph Transformers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "67c0891943ebc021b47f7d9622f6538f8b43430c",
    "semantic_title": "directed graph transformers",
    "citation_count": 2,
    "authors": [
      "Qitong Wang",
      "Georgios Kollias",
      "Vasileios Kalantzis",
      "Naoki Abe",
      "Mohammed J Zaki"
    ]
  },
  "https://openreview.net/forum?id=4CUkCG6ITe": {
    "title": "Contextual Policies Enable Efficient and Interpretable Inverse Reinforcement Learning for Populations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3129c855261a78349399b4244ad6e52f3205d04a",
    "semantic_title": "contextual policies enable efficient and interpretable inverse reinforcement learning for populations",
    "citation_count": 0,
    "authors": [
      "Ville Tanskanen",
      "Chang Rajani",
      "Perttu HÃ¤mÃ¤lÃ¤inen",
      "Christian Guckelsberger",
      "Arto Klami"
    ]
  },
  "https://openreview.net/forum?id=TwiSBZ0p9u": {
    "title": "NuTime: Numerically Multi-Scaled Embedding for Large- Scale Time-Series Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": "6e2c2ba6b96340527bcb28bcc9d46afa182ed99a",
    "semantic_title": "nutime: numerically multi-scaled embedding for large-scale time series pretraining",
    "citation_count": 5,
    "authors": [
      "Chenguo Lin",
      "Xumeng Wen",
      "Wei Cao",
      "Congrui Huang",
      "Jiang Bian",
      "Stephen Lin",
      "Zhirong Wu"
    ]
  },
  "https://openreview.net/forum?id=P5D2gfi4Gg": {
    "title": "Intriguing Properties of Hyperbolic Embeddings in Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3ddf3d231f03e220c368f70694007a82241fe210",
    "semantic_title": "intriguing properties of hyperbolic embeddings in vision-language models",
    "citation_count": 8,
    "authors": [
      "Sarah Ibrahimi",
      "Mina Ghadimi Atigh",
      "Nanne Van Noord",
      "Pascal Mettes",
      "Marcel Worring"
    ]
  },
  "https://openreview.net/forum?id=Svt75kotzs": {
    "title": "Lyra: Orchestrating Dual Correction in Automated Theorem Proving",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) present an intriguing avenue for exploration in the field of formal theorem proving. Nevertheless, their full potential, particularly concerning the mitigation of hallucinations and refinement through prover error messages, remains an area that has yet to be thoroughly investigated. To enhance the effectiveness of LLMs in the field, we introduce the Lyra, a new framework that employs two distinct correction mechanisms: Tool Correction (TC) and Conjecture Correction (CC). To implement Tool Correction in the post-processing of formal proofs, we leverage prior knowledge to utilize predefined prover tools (e.g., Sledgehammer) for guiding the replacement of incorrect tools. Tool Correction significantly contributes to mitigating hallucinations, thereby improving the overall accuracy of the proof. In addition, we introduce Conjecture Correction, an error feedback mechanism designed to interact with prover to refine formal proof conjectures with prover error messages. Compared to the previous refinement framework, the proposed Conjecture Correction refines generation with instruction but does not collect paired (generation, error & refinement) prompts. Our method has achieved state-of-the-art (SOTA) performance on both miniF2F validation (48.0% â 55.3%) and test (45.5% â 51.2%). We also present 3 IMO problems solved by Lyra. We believe Tool Correction (post-process for hallucination mitigation) and Conjecture Correction (subgoal adjustment from interaction with the environment) could provide a promising avenue for future research in this field",
    "checked": true,
    "id": "d4b542847e1dd227e90479f4b3523a81dee33b7a",
    "semantic_title": "lyra: orchestrating dual correction in automated theorem proving",
    "citation_count": 23,
    "authors": [
      "Chuanyang Zheng",
      "Haiming Wang",
      "Enze Xie",
      "Zhengying Liu",
      "Jiankai Sun",
      "Huajian Xin",
      "Jianhao Shen",
      "Zhenguo Li",
      "Yu Li"
    ]
  },
  "https://openreview.net/forum?id=spJI4LSPIU": {
    "title": "Understanding the Role of Invariance in Transfer Learning",
    "volume": "main",
    "abstract": "Transfer learning is a powerful technique for knowledge-sharing between different tasks. Recent work has found that the representations of models with certain invariances, such as to adversarial input perturbations, achieve higher performance on downstream tasks. These findings suggest that invariance may be an important property in the context of transfer learning. However, the relationship of invariance with transfer performance is not fully understood yet and a number of questions remain. For instance, how important is invariance compared to other factors of the pretraining task? How transferable is learned invariance? In this work, we systematically investigate the importance of representational invariance for transfer learning, as well as how it interacts with other parameters during pretraining. To do so, we introduce a family of synthetic datasets that allow us to precisely control factors of variation both in training and test data. Using these datasets, we a) show that for learning representations with high transfer performance, invariance to the right transformations is as, or often more, important than most other factors such as the number of training samples, the model architecture and the identity of the pretraining classes, b) show conditions under which invariance can harm the ability to transfer representations and c) explore how transferable invariance is between tasks. The code is available [here](https://github.com/tillspeicher/representation-invariance-transfer)",
    "checked": true,
    "id": "68fb64947793d3a15f933e56f471db273b534def",
    "semantic_title": "understanding the role of invariance in transfer learning",
    "citation_count": 1,
    "authors": [
      "Till Speicher",
      "Vedant Nanda",
      "Krishna P. Gummadi"
    ]
  },
  "https://openreview.net/forum?id=8YcUJbxmmC": {
    "title": "Jigsaw Game: Federated Clustering",
    "volume": "main",
    "abstract": "Federated learning has recently garnered significant attention, especially within the domain of supervised learning. However, despite the abundance of unlabeled data on end-users, unsupervised learning problems such as clustering in the federated setting remain underexplored. In this paper, we investigate the federated clustering problem, with a focus on federated k-means. We outline the challenge posed by its non-convex objective and data heterogeneity in the federated framework. To tackle these challenges, we adopt a new perspective by studying the structures of local solutions in k-means and propose a one-shot algorithm called FeCA (Federated Centroid Aggregation). FeCA adaptively refines local solutions on clients, then aggregates these refined client solutions to recover the global solution of the entire dataset in a single round. We empirically demonstrate the robustness of FeCA under various federated scenarios on both synthetic and real-world data. Additionally, we extend FeCA to representation learning and present DeepFeCA, which combines DeepCluster and FeCA for unsupervised feature learning in the federated setting",
    "checked": true,
    "id": "957a1c743cb60cf2f050d9f8815431483167dd49",
    "semantic_title": "jigsaw game: federated clustering",
    "citation_count": 1,
    "authors": [
      "JINXUAN XU",
      "Hong-You Chen",
      "Wei-Lun Chao",
      "Yuqian Zhang"
    ]
  },
  "https://openreview.net/forum?id=Q0nzpRcwWn": {
    "title": "Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings",
    "volume": "main",
    "abstract": "Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as \"simulation-based inference\" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, the trade-off between accuracy and computational demand leaves much space for improvement. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, even for multimodal posteriors, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature and on a biological model of the translation kinetics after mRNA transfection",
    "checked": true,
    "id": "9975cc9d9cfccf68210213647d504c820b53e7a0",
    "semantic_title": "fast, accurate and lightweight sequential simulation-based inference using gaussian locally linear mappings",
    "citation_count": 3,
    "authors": [
      "Henrik HÃ¤ggstrÃ¶m",
      "Pedro L. C. Rodrigues",
      "Geoffroy Oudoumanessah",
      "Florence Forbes",
      "Umberto Picchini"
    ]
  },
  "https://openreview.net/forum?id=Dsavre6gjN": {
    "title": "SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery",
    "volume": "main",
    "abstract": "Sparse basis recovery is a classical and important statistical learning problem when the number of model dimensions $p$ is much larger than the number of samples $n$. However, there has been little work that studies sparse basis recovery in the Federated Learning (FL) setting, where the client data's differential privacy (DP) must also be simultaneously protected. In particular, the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will degrade significantly when $p \\gg n$, and thus, they will fail to learn the true underlying sparse model accurately. In this work, we develop a new differentially private sparse basis recovery algorithm for the FL setting, called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to the FL setting. Further, it combines SMPC (secure multi-party computation) and DP to ensure that only a small amount of noise needs to be added in order to achieve differential privacy. As a result, SPriFed-OMP can efficiently recover the true sparse basis for a linear model with only $n = \\mathcal{O}(\\sqrt{p})$ samples. We further present an enhanced version of our approach, SPriFed-OMP-GRAD, based on gradient privatization, that improves the performance of SPriFed-OMP. Our theoretical analysis and empirical results demonstrate that both SPriFed-OMP and SPriFed-OMP-GRAD terminate in a small number of steps, and they significantly outperform the previous state-of-the-art DP-FL solutions in terms of the accuracy-privacy trade-off",
    "checked": true,
    "id": "3cc57ace75774834109390d53a463e90d4b93c40",
    "semantic_title": "sprifed-omp: a differentially private federated learning algorithm for sparse basis recovery",
    "citation_count": 0,
    "authors": [
      "Ajinkya K Mulay",
      "Xiaojun Lin"
    ]
  },
  "https://openreview.net/forum?id=EzPRgIq2Tk": {
    "title": "Active Sequential Two-Sample Testing",
    "volume": "main",
    "abstract": "A two-sample hypothesis test is a statistical procedure used to determine whether the distributions generating two samples are identical. We consider the two-sample testing problem in a new scenario where the sample measurements (or sample features) are inexpensive to access, but their group memberships (or labels) are costly. To address the problem, we devise the first \\emph{active sequential two-sample testing framework} that not only sequentially but also \\emph{actively queries}. Our test statistic is a likelihood ratio where one likelihood is found by maximization over all class priors, and the other is provided by a probabilistic classification model. The classification model is adaptively updated and used to predict where the (unlabelled) features have a high dependency on labels; labeling the ``high-dependency'' features leads to the increased power of the proposed testing framework. In theory, we provide the proof that our framework produces an \\emph{anytime-valid} $p$-value. In addition, we characterize the proposed framework's gain in testing power by analyzing the mutual information between the feature and label variables in asymptotic and finite-sample scenarios. In practice, we introduce an instantiation of our framework and evaluate it using several experiments; the experiments on the synthetic, MNIST, and application-specific datasets demonstrate that the testing power of the instantiated active sequential test significantly increases while the Type I error is under control",
    "checked": true,
    "id": "31e7e53ec7c96f0501ac4180dff66692d5baf772",
    "semantic_title": "active sequential two-sample testing",
    "citation_count": 2,
    "authors": [
      "Weizhi Li",
      "Prad Kadambi",
      "Pouria Saidi",
      "Karthikeyan Natesan Ramamurthy",
      "Gautam Dasarathy",
      "Visar Berisha"
    ]
  },
  "https://openreview.net/forum?id=DimPeeCxKO": {
    "title": "Simple and Scalable Strategies to Continually Pre-train Large Language Models",
    "volume": "main",
    "abstract": "Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these modelsâsaving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\\rightarrow$English) and a stronger distribution shift (English$\\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that autoregressive transformer-based LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget",
    "checked": true,
    "id": "d0075dd5603c9d477edf0a41f59ab6dcf0e91976",
    "semantic_title": "simple and scalable strategies to continually pre-train large language models",
    "citation_count": 62,
    "authors": [
      "Adam Ibrahim",
      "Benjamin ThÃ©rien",
      "Kshitij Gupta",
      "Mats Leon Richter",
      "Quentin Gregory Anthony",
      "Eugene Belilovsky",
      "TimothÃ©e Lesort",
      "Irina Rish"
    ]
  },
  "https://openreview.net/forum?id=AIc48TjuSt": {
    "title": "Sparse Contextual CDF Regression",
    "volume": "main",
    "abstract": "Estimating cumulative distribution functions (CDFs) of context-dependent random variables is a central statistical task underpinning numerous applications in machine learning and economics. In this work, we extend a recent line of theoretical inquiry into this domain by analyzing the problem of \\emph{sparse contextual CDF regression}, wherein data points are sampled from a convex combination of $s$ context-dependent CDFs chosen from a set of $d$ basis functions. We show that adaptations of several canonical regression methods serve as tractable estimators in this functional sparse regression setting under standard assumptions on the conditioning of the basis functions. In particular, given $n$ data samples, we prove estimation error upper bounds of $\\tilde{O}(\\sqrt{s/n})$ for functional versions of the lasso and Dantzig selector estimators, and $\\tilde{O}(\\sqrt{s}/\\sqrt[4]{n})$ for a functional version of the elastic net estimator. Our results match the corresponding error bounds for finite-dimensional regression and improve upon CDF ridge regression which has $\\tilde{O}(\\sqrt{d/n})$ estimation error. Finally, we obtain a matching information-theoretic lower bound which establishes the minimax optimality of the lasso and Dantzig selector estimators up to logarithmic factors",
    "checked": true,
    "id": "8d1672d393e1f80a1b44ba632e663fcb52d7dbb8",
    "semantic_title": "sparse contextual cdf regression",
    "citation_count": 0,
    "authors": [
      "Kamyar Azizzadenesheli",
      "William Lu",
      "Anuran Makur",
      "Qian Zhang"
    ]
  },
  "https://openreview.net/forum?id=ZAin13msOp": {
    "title": "D3: Data Diversity Design for Systematic Generalization in Visual Question Answering",
    "volume": "main",
    "abstract": "Systematic generalization is a crucial aspect of intelligence, which refers to the ability to generalize to novel tasks by combining known subtasks and concepts. One critical factor that has been shown to influence systematic generalization is the diversity of training data. However, diversity can be defined in various ways, as data have many factors of variation. A more granular understanding of how different aspects of data diversity affect systematic generalization is lacking. We present new evidence in the problem of Visual Question Answering (VQA) that reveals that the diversity of simple tasks (i.e. tasks formed by a few subtasks and concepts) plays a key role in achieving systematic generalization. This implies that it may not be essential to gather a large and varied number of complex tasks, which could be costly to obtain. We demonstrate that this result is independent of the similarity between the training and testing data and applies to well-known families of neural network architectures for VQA (i.e. monolithic architectures and neural module networks). Additionally, we observe that neural module networks leverage all forms of data diversity we evaluated, while monolithic architectures require more extensive amounts of data to do so. These findings provide a first step towards understanding the interactions between data diversity design, neural network architectures, and systematic generalization capabilities",
    "checked": true,
    "id": "8e7254ab110cbf374d1c23f9bbce022ba9d01f1c",
    "semantic_title": "d3: data diversity design for systematic generalization in visual question answering",
    "citation_count": 1,
    "authors": [
      "Amir Rahimi",
      "Vanessa D'Amario",
      "Moyuru Yamada",
      "Kentaro Takemoto",
      "Tomotake Sasaki",
      "Xavier Boix"
    ]
  },
  "https://openreview.net/forum?id=bIiLXdtUVM": {
    "title": "Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI Benchmarks",
    "volume": "main",
    "abstract": "Feature removal is a central building block for eXplainable AI (XAI), both for occlusion-based explanations (Shapley values) as well as their evaluation (pixel flipping, PF). However, occlusion strategies can vary significantly from simple mean replacement up to inpainting with state-of-the-art diffusion models. This ambiguity limits the usefulness of occlusion-based approaches. For example, PF benchmarks lead to contradicting rankings. This is amplified by competing PF measures: Features are either removed starting with most influential first (MIF) or least influential first (LIF). This study proposes two complementary perspectives to resolve this disagreement problem. Firstly, we address the common criticism of occlusion-based XAI, that artificial samples lead to unreliable model evaluations. We propose to measure the reliability by the R(eference)-Out-of-Model-Scope (OMS) score. The R-OMS score enables a systematic comparison of occlusion strategies and resolves the disagreement problem by grouping consistent PF rankings. Secondly, we show that the insightfulness of MIF and LIF is conversely dependent on the R-OMS score. To leverage this, we combine the MIF and LIF measures into the symmetric relevance gain (SRG) measure. This breaks the inherent connection to the underlying occlusion strategy and leads to consistent rankings. This resolves the disagreement problem of PF benchmarks, which we verify for a set of 40 different occlusion strategies",
    "checked": true,
    "id": "12c821e5182054c94ec295657076fbd1e2694090",
    "semantic_title": "decoupling pixel flipping and occlusion strategy for consistent xai benchmarks",
    "citation_count": 21,
    "authors": [
      "Stefan Bluecher",
      "Johanna Vielhaben",
      "Nils Strodthoff"
    ]
  },
  "https://openreview.net/forum?id=YVD1QqWRaj": {
    "title": "PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations",
    "volume": "main",
    "abstract": "Nowadays, the quality of responses generated by different modern large language models (LLMs) is hard to evaluate and compare automatically. Recent studies suggest and predominantly use LLMs for reference-free evaluation of open-ended question answering. More specifically, they use the recognized \"strongest\" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho & MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose (1) the peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on the preferences of two answers. We conduct experiments on two benchmark datasets. We find that our approaches achieve higher accuracy and align better with human judgments. Interestingly, PR can induce a relatively accurate self-ranking of models under the anonymous setting, where each model's name is unrevealed. Our work provides space to explore evaluating models that are hard to compare for humans",
    "checked": true,
    "id": "130d18d1d455336e1a5b06c85784894bb67d87ec",
    "semantic_title": "prd: peer rank and discussion improve large language model based evaluations",
    "citation_count": 102,
    "authors": [
      "Ruosen Li",
      "Teerth Patel",
      "Xinya Du"
    ]
  },
  "https://openreview.net/forum?id=V92PnXQ7UW": {
    "title": "BaSIS-Net: From Point Estimate to Predictive Distribution in Neural Networks - A Bayesian Sequential Importance Sampling Framework",
    "volume": "main",
    "abstract": "Data-driven Deep Learning (DL) models have revolutionized autonomous systems, but ensuring their safety and reliability necessitates the assessment of predictive confidence or uncertainty. Bayesian DL provides a principled approach to quantify uncertainty via probability density functions defined over model parameters. However, the exact solution is intractable for most DL models, and the approximation methods, often based on heuristics, suffer from scalability issues and stringent distribution assumptions and may lack theoretical guarantees. This work develops a Sequential Importance Sampling framework that approximates the posterior probability density function through weighted samples (or particles), which can be used to find the mean, variance, or higher-order moments of the posterior distribution. We demonstrate that propagating particles, which capture information about the higher-order moments, through the layers of the DL model results in increased robustness to natural and malicious noise (adversarial attacks). The variance computed from these particles effectively quantifies the model's decision uncertainty, demonstrating well-calibrated and accurate predictive confidence",
    "checked": true,
    "id": "3ab045f9ac53024566e777ddfe0f8c0835627741",
    "semantic_title": "basis-net: from point estimate to predictive distribution in neural networks - a bayesian sequential importance sampling framework",
    "citation_count": 0,
    "authors": [
      "Giuseppina Carannante",
      "Nidhal Bouaynaya",
      "Ghulam Rasool",
      "Lyudmila Mihaylova"
    ]
  },
  "https://openreview.net/forum?id=nYzws7sSzo": {
    "title": "A General-Purpose Multi-Modal OOD Detection Framework",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) detection seeks to identify test samples that deviate from the training data, which is critical to ensuring the safety and reliability of machine learning (ML) systems. While a plethora of methods have been developed to detect uni-modal OOD samples, only a few have focused on multi-modal OOD detection. Current contrastive learning-based methods primarily address multi-modal OOD detection in a scenario where an image is not related to the class labels in training data. However, ML systems in the real-world applications may encounter a broader spectrum of anomalies caused by different factors like systematic errors in labeling, environmental changes, and sensor malfunctions. Hence, we propose a new method to be able to simultaneously detect anomalies from multiple different OOD scenarios, arising from fine-grained image features and textual descriptions, instead of large categorical information. To achieve this goal, we propose a general-purpose weakly-supervised OOD detection framework, called WOOD, that combines a binary classifier and a contrastive learning module to reap the benefits of both. In order to better distinguish in-distribution (ID) samples from OOD ones, we employ the Hinge loss to constrain the similarity of their latent representations. Moreover, we devise a new scoring metric that fuses predictions from both the binary classifier and contrastive learning to enhance OOD detection. Extensive experimental results on multiple benchmarks demonstrate that the proposed WOOD significantly outperforms the state-of-the-art methods for multi-modal OOD detection. Importantly, our approach can achieve superior detection performance in a variety of OOD scenarios",
    "checked": true,
    "id": "43ed2e413e267e61c29a34961c500b12a6d41c59",
    "semantic_title": "a general-purpose multi-modal ood detection framework",
    "citation_count": 0,
    "authors": [
      "Viet Quoc Duong",
      "Qiong Wu",
      "Zhengyi Zhou",
      "Eric Zavesky",
      "WenLing Hsu",
      "Han Zhao",
      "Huajie Shao"
    ]
  },
  "https://openreview.net/forum?id=hdQspgyFrk": {
    "title": "Federated TD Learning with Linear Function Approximation under Environmental Heterogeneity",
    "volume": "main",
    "abstract": "We initiate the study of federated reinforcement learning under environmental heterogeneity by considering a policy evaluation problem. Our setup involves $N$ agents interacting with environments that share the same state and action space but differ in their reward functions and state transition kernels. Assuming agents can communicate via a central server, we ask: \\textit{Does exchanging information expedite the process of evaluating a common policy?} To answer this question, we provide the first comprehensive finite-time analysis of a federated temporal difference (TD) learning algorithm with linear function approximation, while accounting for Markovian sampling, heterogeneity in the agents' environments, and multiple local updates to save communication. Our analysis crucially relies on several novel ingredients: (i) deriving perturbation bounds on TD fixed points as a function of the heterogeneity in the agents' underlying Markov decision processes (MDPs); (ii) introducing a virtual MDP to closely approximate the dynamics of the federated TD algorithm; and (iii) using the virtual MDP to make explicit connections to federated optimization. Putting these pieces together, we prove that in a low-heterogeneity regime, exchanging model estimates leads to linear convergence speedups in the number of agents. Our theoretical contribution is significant in that it is the first result of its kind in multi-agent/federated reinforcement learning that complements the numerous analogous results in heterogeneous federated optimization",
    "checked": true,
    "id": "a267ddf84cd7814620a03ea0556678705d5f3f23",
    "semantic_title": "federated td learning with linear function approximation under environmental heterogeneity",
    "citation_count": 3,
    "authors": [
      "Han Wang",
      "Aritra Mitra",
      "Hamed Hassani",
      "George J. Pappas",
      "James Anderson"
    ]
  },
  "https://openreview.net/forum?id=vqniLmUDvj": {
    "title": "ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation",
    "volume": "main",
    "abstract": "Image-to-video (I2V) generation aims to use the initial frame (alongside a text prompt) to create a video sequence. A grand challenge in I2V generation is to maintain visual consistency throughout the video: existing methods often struggle to preserve the integrity of the subject, background, and style from the first frame, as well as ensure a fluid and logical progression within the video narrative. To mitigate these issues, we propose ConsistI2V, a diffusion-based method to enhance visual consistency for I2V generation. Specifically, we introduce (1) spatiotemporal attention over the first frame to maintain spatial and motion consistency, (2) noise initialization from the low-frequency band of the first frame to enhance layout consistency. These two approaches enable ConsistI2V to generate highly consistent videos. We also extend the proposed approaches to show their potential to improve consistency in auto-regressive long video generation and camera motion control. To verify the effectiveness of our method, we propose I2V-Bench, a comprehensive evaluation benchmark for I2V generation. Our automatic and human evaluation results demonstrate the superiority of ConsistI2V over existing methods",
    "checked": true,
    "id": "d599dc40c9cb8d6d76554ee7d21d20c22cc7cdb5",
    "semantic_title": "consisti2v: enhancing visual consistency for image-to-video generation",
    "citation_count": 64,
    "authors": [
      "Weiming Ren",
      "Huan Yang",
      "Ge Zhang",
      "Cong Wei",
      "Xinrun Du",
      "Wenhao Huang",
      "Wenhu Chen"
    ]
  },
  "https://openreview.net/forum?id=36OX7uRM5t": {
    "title": "Variational excess risk bound for general state space models",
    "volume": "main",
    "abstract": "In this paper, we consider variational autoencoders (VAE) for general state space models. We consider a backward factorization of the variational distributions to analyze the excess risk associated with VAE. Such backward factorizations were recently proposed to perform online variational learning and to obtain upper bounds on the variational estimation error. When independent trajectories of sequences are observed and under strong mixing assumptions on the state space model and on the variational distribution, we provide an oracle inequality explicit in the number of samples and in the length of the observation sequences. We then derive consequences of this theoretical result. In particular, when the data distribution is given by a state space model, we provide an upper bound for the Kullback-Leibler divergence between the data distribution and its estimator and between the variational posterior and the estimated state space posterior distributions. Under classical assumptions, we prove that our results can be applied to Gaussian backward kernels built with dense and recurrent neural networks",
    "checked": true,
    "id": "fad3039109c5ab6f0c737a5ae2768b38a4cf373d",
    "semantic_title": "variational excess risk bound for general state space models",
    "citation_count": 1,
    "authors": [
      "Elisabeth Gassiat",
      "Sylvain Le Corff"
    ]
  },
  "https://openreview.net/forum?id=KpVJ6CGnwI": {
    "title": "$\\sigma$-PCA: a building block for neural learning of identifiable linear transformations",
    "volume": "main",
    "abstract": "Linear principal component analysis (PCA) learns (semi-)orthogonal transformations by orienting the axes to maximize variance. Consequently, it can only identify orthogonal axes whose variances are clearly distinct, but it cannot identify the subsets of axes whose variances are roughly equal. It cannot eliminate the subspace rotational indeterminacy: it fails to disentangle components with equal variances (eigenvalues), resulting, in each eigen subspace, in randomly rotated axes. In this paper, we propose $\\sigma$-PCA, a method that (1) formulates a unified model for linear and nonlinear PCA, the latter being a special case of linear independent component analysis (ICA), and (2) introduces a missing piece into nonlinear PCA that allows it to eliminate, from the canonical linear PCA solution, the subspace rotational indeterminacy â without whitening the inputs. Whitening, a preprocessing step which converts the inputs into unit-variance inputs, has generally been a prerequisite step for linear ICA methods, which meant that conventional nonlinear PCA could not necessarily preserve the orthogonality of the overall transformation, could not directly reduce dimensionality, and could not intrinsically order by variances. We offer insights on the relationship between linear PCA, nonlinear PCA, and linear ICA â three methods with autoencoder formulations for learning special linear transformations from data, transformations that are (semi-)orthogonal for PCA, and arbitrary unit-variance for ICA. As part of our formulation, nonlinear PCA can be seen as a method that maximizes both variance and statistical independence, lying in the middle between linear PCA and linear ICA, serving as a building block for learning linear transformations that are identifiable",
    "checked": true,
    "id": "dd9a20cd70ce7b7bd1b575c91fbebb2633d1bf42",
    "semantic_title": "$\\sigma$-pca: a building block for neural learning of identifiable linear transformations",
    "citation_count": 0,
    "authors": [
      "Fahdi Kanavati",
      "Lucy Katsnith",
      "Masayuki Tsuneki"
    ]
  },
  "https://openreview.net/forum?id=RkaqxxAOfN": {
    "title": "Bytes Are All You Need: Transformers Operating Directly On File Bytes",
    "volume": "main",
    "abstract": "Modern deep learning approaches usually utilize modality-specific processing. For example, the most common deep learning approach to image classification involves decoding image file bytes into an RGB tensor which is passed into a neural network. Instead, we investigate modality-independent representation learning by performing classification directly on file bytes, without the need for decoding files at inference time. This enables models to operate on various modalities without any hand-designed, modality-specific processing. Our model, ByteFormer, improves ImageNet Top-1 classification accuracy by $5\\%$ (from $72.2\\%$ to $77.33\\%$) relative to DeIT models of similar size. Compared to Perceiver IO, our model requires absolutely no modality-specific processing at inference time, and uses an order of magnitude fewer parameters at equivalent accuracy on ImageNet. We demonstrate that the same ByteFormer architecture can perform audio classification without modifications or modality-specific preprocessing. We achieve $95.42\\%$ classification accuracy on the Speech Commands V2 dataset (comparable to the state-of-the-art accuracy of $98.7\\%$). Additionally, we demonstrate that ByteFormer can operate jointly on images and audio, handling joint classification without explicit knowledge of the input modality. We release our code at https://github.com/apple/corenet/tree/main/projects/byteformer",
    "checked": true,
    "id": "4fb504d4f173929a20eb2109b6a0b678dfad681e",
    "semantic_title": "bytes are all you need: transformers operating directly on file bytes",
    "citation_count": 7,
    "authors": [
      "Maxwell Horton",
      "Sachin Mehta",
      "Ali Farhadi",
      "Mohammad Rastegari"
    ]
  },
  "https://openreview.net/forum?id=lLVmIvZfry": {
    "title": "Improving Variational Autoencoder Estimation from Incomplete Data with Mixture Variational Families",
    "volume": "main",
    "abstract": "We consider the task of estimating variational autoencoders (VAEs) when the training data is incomplete. We show that missing data increases the complexity of the model's posterior distribution over the latent variables compared to the fully-observed case. The increased complexity may adversely affect the fit of the model due to a mismatch between the variational and model posterior distributions. We introduce two strategies based on (i) finite variational-mixture and (ii) imputation-based variational-mixture distributions to address the increased posterior complexity. Through a comprehensive evaluation of the proposed approaches, we show that variational mixtures are effective at improving the accuracy of VAE estimation from incomplete data",
    "checked": true,
    "id": "069fe45f0c6bbfa117dd03b17324ff15d1d8562d",
    "semantic_title": "improving variational autoencoder estimation from incomplete data with mixture variational families",
    "citation_count": 2,
    "authors": [
      "Vaidotas Simkus",
      "Michael U. Gutmann"
    ]
  },
  "https://openreview.net/forum?id=XAD2kcBS50": {
    "title": "Conciliator steering: Imposing user preference in multi-objective reinforcement learning",
    "volume": "main",
    "abstract": "Many real-world problems with multiple objectives require reinforcement learning solutions that can handle trade-offs in a user-preferred manner. In the multi-objective framework, a single algorithm adapting to different user preferences based on a pre-defined reward function and a subjectively defined scalarisation function may be developed. The scalarisation function approximation can be done by fitting a meta-model with information gained from the interaction between the user and the environment or the agent. The interaction requires exact formulation of a constructive feedback, which is also simple for the user to give. In this paper, we propose a novel algorithm, Conciliator steering, that leverages priority order and reward transfer to seek optimal user-preferred policies in multi-objective reinforcement learning under expected scalarised returns criterion. We test Conciliator steering on DeepSeaTreasure v1 benchmark problem and demonstrate that it can find user-preferred policies with effortless and simple user-agent interaction and negligible bias, which has not been possible before. Additionally, we show that on average Conciliator steering results in a fraction of carbon dioxide emissions and total energy consumption when compared to a training of fully connected MNIST classifier, both run on a personal laptop",
    "checked": true,
    "id": "cf1008e42c937249d3e519c6b1f3dd3e76b8539d",
    "semantic_title": "conciliator steering: imposing user preference in multi-objective reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Sara PyykÃ¶lÃ¤",
      "Klavdiya Olegovna Bochenina",
      "Laura Ruotsalainen"
    ]
  },
  "https://openreview.net/forum?id=L2jRavXRxs": {
    "title": "Can LLMs Effectively Leverage Graph Structural Information through Prompts, and Why?",
    "volume": "main",
    "abstract": "Large language models (LLMs) are gaining increasing attention for their capability to process graphs with rich text attributes, especially in a zero-shot fashion. Recent studies demonstrate that LLMs obtain decent text classification performance on common text-rich graph benchmarks, and the performance can be improved by appending encoded structural information as natural languages into prompts. We aim to understand why the incorporation of structural information inherent in graph data can improve the prediction performance of LLMs. First, we rule out the concern of data leakage by curating a novel leakage-free dataset and conducting a comparative analysis alongside a previously widely-used dataset. Second, as past work usually encodes the ego-graph by describing the graph structure in natural language, we ask the question: do LLMs understand the prompts in graph structures? Third, we investigate why LLMs can improve their performance after incorporating structural information. Our exploration of these questions reveals that (i) there is no substantial evidence that the performance of LLMs is significantly attributed to data leakage; (ii) instead of understanding prompts as graph structures, LLMs tend to process prompts more as contextual paragraphs and (iii) the most efficient elements of the local neighborhood included in the prompt are phrases that are pertinent to the node label, rather than the graph structure",
    "checked": true,
    "id": "21510620f0c92dde08741070a00593bcd1815d8c",
    "semantic_title": "can llms effectively leverage graph structural information through prompts, and why?",
    "citation_count": 15,
    "authors": [
      "Jin Huang",
      "Xingjian Zhang",
      "Qiaozhu Mei",
      "Jiaqi Ma"
    ]
  },
  "https://openreview.net/forum?id=SdCuffxg5A": {
    "title": "Solving Robust MDPs through No-Regret Dynamics",
    "volume": "main",
    "abstract": "Reinforcement learning is a powerful framework for training agents to navigate different situations, but it is susceptible to changes in environmental dynamics. Generating an algorithm that can find environmentally robust policies efficiently and handle different model parameterizations without imposing stringent assumptions on the uncertainty set of transitions is difficult due to the intricate interactions between policy and environment. In this paper, we address both of these issues with a No-Regret Dynamics framework that utilizes policy gradient methods and iteratively approximates the worst case environment during training, avoiding assumptions on the uncertainty set. Alongside a toolbox of nonconvex online learning algorithms, we demonstrate that our framework can achieve fast convergence rates for many different problem settings and relax assumptions on the uncertainty set of transitions",
    "checked": true,
    "id": "9101e2aa17807936c31e9de5f1cf3cb177fb9f5a",
    "semantic_title": "solving robust mdps through no-regret dynamics",
    "citation_count": 0,
    "authors": [
      "Etash Kumar Guha"
    ]
  },
  "https://openreview.net/forum?id=72mDxlzRZ1": {
    "title": "Fair Feature Importance Scores for Interpreting Decision Trees",
    "volume": "main",
    "abstract": "Across various sectors such as healthcare, criminal justice, national security, finance, and technology, large-scale machine learning (ML) systems are being deployed to make critical data-driven decisions. Many have asked if we can and should trust these ML systems to be making these decisions. Two critical components are prerequisites for trust in ML systems: interpretability, or the ability to understand why the ML system makes the decisions it does, and fairness, which ensures that ML systems do not exhibit bias against certain individuals or groups. While both interpretability and fairness have garnered substantial attention in the ML literature, methods directly interpreting models in terms of fairness remain limited. This paper considers a popular interpretation for a widely used class of ML models: feature importance scores for decision trees and tree-based models. We introduce a novel Fair Tree Feature Importance Score to assess each feature's impact on fairness or bias in decision trees. Analogous to the mean decrease in impurity for trees, our score quantifies the mean increase (or decrease) in group bias, and extends to interpret tree-based ensembles or surrogates of complex ML systems. Through simulations and real examples on benchmark fairness datasets, we show the validity of our Fair Tree Feature Importance Score, offering meaningful interpretations for both tree-based ensembles and tree-based surrogates of other ML systems",
    "checked": true,
    "id": "cadf077c1608eecb6a63f9bfc4227a882913792a",
    "semantic_title": "fair feature importance scores for interpreting decision trees",
    "citation_count": 2,
    "authors": [
      "Camille Olivia Little",
      "Debolina Halder Lina",
      "Genevera I. Allen"
    ]
  },
  "https://openreview.net/forum?id=nAQSUqEspb": {
    "title": "Todyformer: Towards Holistic Dynamic Graph Transformers with Structure-Aware Tokenization",
    "volume": "main",
    "abstract": "Temporal Graph Neural Networks have garnered substantial attention for their capacity to model evolving structural and temporal patterns while exhibiting impressive performance. However, it is known that these architectures are encumbered by issues that constrain their performance, such as over-squashing and over-smoothing. Meanwhile, Transformers have demonstrated exceptional computational capacity to effectively address challenges related to long-range dependencies. Consequently, we introduce Todyformerâa novel Transformer-based neural network tailored for dynamic graphs. It unifies the local encoding capacity of Message-Passing Neural Networks (MPNNs) with the global encoding of Transformers through i) a novel patchifying paradigm for dynamic graphs to improve over-squashing, ii) a structure-aware parametric tokenization strategy leveraging MPNNs, iii) a Transformer with temporal positional-encoding to capture long-range dependencies, and iv) an encoding architecture that alternates between local and global contextualization, mitigating over-smoothing in MPNNs. Experimental evaluations on public benchmark datasets demonstrate that Todyformer consistently outperforms the state-of-the-art methods for downstream tasks. Furthermore, we illustrate the underlying aspects of the proposed model in effectively capturing extensive temporal dependencies in dynamic graphs",
    "checked": true,
    "id": "77e5ac839c260445c7d46020b7eef2908013eeb7",
    "semantic_title": "todyformer: towards holistic dynamic graph transformers with structure-aware tokenization",
    "citation_count": 3,
    "authors": [
      "Mahdi Biparva",
      "Raika Karimi",
      "Faezeh Faez",
      "Yingxue Zhang"
    ]
  },
  "https://openreview.net/forum?id=jESY2WTZCe": {
    "title": "The Disagreement Problem in Explainable Machine Learning: A Practitioner's Perspective",
    "volume": "main",
    "abstract": "As various post hoc explanation methods are increasingly being leveraged to explain complex models in high-stakes settings, it becomes critical to develop a deeper understanding of if and when the explanations output by these methods disagree with each other, and how such disagreements are resolved in practice. However, there is little to no research that provides answers to these critical questions. In this work, we introduce and study the disagreement problem in explainable machine learning. More specifically, we formalize the notion of disagreement between explanations, analyze how often such disagreements occur in practice, and how practitioners resolve these disagreements. We first conduct interviews with data scientists to understand what constitutes disagreement between explanations generated by different methods for the same model prediction and introduce a novel quantitative framework to formalize this understanding. We then leverage this framework to carry out a rigorous empirical analysis with four real-world datasets, six state-of-the-art post hoc explanation methods, and six different predictive models, to measure the extent of disagreement between the explanations generated by various popular explanation methods. In addition, we carry out an online user study with data scientists to understand how they resolve the aforementioned disagreements. Our results indicate that (1) state-of-the-art explanation methods often disagree in terms of the explanations they output, and (2) machine learning practitioners often employ ad hoc heuristics when resolving such disagreements. These findings suggest that practitioners may be relying on misleading explanations when making consequential decisions. They also underscore the importance of developing principled frameworks for effectively evaluating and comparing explanations output by various explanation techniques",
    "checked": true,
    "id": "e0f12956ccfc1ed005b54cb876d9173c4a18dc75",
    "semantic_title": "the disagreement problem in explainable machine learning: a practitioner's perspective",
    "citation_count": 197,
    "authors": [
      "Satyapriya Krishna",
      "Tessa Han",
      "Alex Gu",
      "Steven Wu",
      "Shahin Jabbari",
      "Himabindu Lakkaraju"
    ]
  },
  "https://openreview.net/forum?id=jDRNEoxVc7": {
    "title": "Choosing the parameter of the Fermat distance: navigating geometry and noise",
    "volume": "main",
    "abstract": "The Fermat distance has been recently established as a valuable tool for machine learning tasks when a natural distance is not directly available to the practitioner or to improve the results given by Euclidean distances by exploiting the geometrical and statistical properties of the dataset. This distance depends on a parameter $\\alpha$ that significantly affects the performance of subsequent tasks. Ideally, the value of $\\alpha$ should be large enough to navigate the geometric intricacies inherent to the problem. At the same time, it should remain restrained enough to avoid any deleterious effects stemming from noise during the distance estimation process. We study both theoretically and through simulations how to select this parameter",
    "checked": true,
    "id": "ace2817445d531a041da7b23fe2e9fdefb9bb5da",
    "semantic_title": "choosing the parameter of the fermat distance: navigating geometry and noise",
    "citation_count": 0,
    "authors": [
      "Frederic Chazal",
      "Laure Ferraris",
      "Pablo Groisman",
      "Matthieu Jonckheere",
      "Frederic Pascal",
      "Facundo FabiÃ¡n Sapienza"
    ]
  },
  "https://openreview.net/forum?id=zF76Ga4EPs": {
    "title": "On the Unreasonable Effectiveness of Federated Averaging with Heterogeneous Data",
    "volume": "main",
    "abstract": "Existing theoretical results (such as (Woodworth et al., 2020a)) predict that the performance of federated averaging (FedAvg) is exacerbated by high data heterogeneity. However, in practice, FedAvg converges pretty well on several naturally heterogeneous datasets. In order to explain this seemingly unreasonable effectiveness of FedAvg that contradicts previous theoretical predictions, this paper introduces the client consensus hypothesis: on certain federated datasets, the average of local models updates on clients starting from the optimum is close to zero. We prove that under this hypothesis, data heterogeneity does not exacerbate the convergence of FedAvg. Moreover, we show that this hypothesis holds for a linear regression problem and some naturally heterogeneous datasets such as FEMNIST and StackOverflow. Therefore, we believe that this hypothesis can better explain the performance of FedAvg in practice",
    "checked": true,
    "id": "57f18f3990c989c7f6d69eaf1b3bd541e5d8baaa",
    "semantic_title": "on the unreasonable effectiveness of federated averaging with heterogeneous data",
    "citation_count": 0,
    "authors": [
      "Jianyu Wang",
      "Rudrajit Das",
      "Gauri Joshi",
      "Satyen Kale",
      "Zheng Xu",
      "Tong Zhang"
    ]
  },
  "https://openreview.net/forum?id=ScAc73Y1oJ": {
    "title": "Revealing an Overlooked Challenge in Class-Incremental Graph Learning",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs), which effectively learn from static graph-structured data, become ineffective when directly applied to streaming data in a continual learning (CL) scenario. In CL, historical data are not available during the current stage due to a number of reasons, such as limited storage, GDPR1 data retention policy, to name a few. A few recent works study this problem, however, they overlook the uniqueness of continual graph learning (CGL), compared to well-studied continual image classification: the unavailability of previous training data further poses challenges to inference in CGL, in additional to the well-known catastrophic forgetting problem. While existing works make a strong assumption that full access of historical data is unavailable during training but provided during inference, which potentially contradicts the continual learning paradigm Van de Ven & Tolias (2019), we study continual graph learning without this strong and contradictory assumption. In this case, without being re-inserted into previous training graphs for inference, streaming test nodes are often more sparsely connected, which makes the inference more difficult due to insufficient neighborhood information. In this work, we propose ReplayGNN (ReGNN) to jointly solve the above two challenges without memory buffers: catastrophic forgetting and poor neighbor information during inference. Extensive experiments demonstrate the effectiveness of our model over baseline models and its effectiveness in different cases with different levels of neighbor information available",
    "checked": true,
    "id": "fd9861806d818fc23f05523271e42ae78c495bfc",
    "semantic_title": "revealing an overlooked challenge in class-incremental graph learning",
    "citation_count": 2,
    "authors": [
      "Daiqing Qi",
      "Handong Zhao",
      "Xiaowei Jia",
      "Sheng Li"
    ]
  },
  "https://openreview.net/forum?id=y3u8OpPHxz": {
    "title": "Selective Pre-training for Private Fine-tuning",
    "volume": "main",
    "abstract": "Text prediction models, when used in applications like email clients or word processors, must protect user data privacy and adhere to model size constraints. These constraints are crucial to meet memory and inference time requirements, as well as to reduce inference costs. Building small, fast, and private domain-specific language models is a thriving area of research. In this work, we show that a careful pre-training on a subset of the public dataset that is guided by the private dataset is crucial to train small language models with differential privacy. On standard benchmarks, small models trained with our new framework achieve state-of-the-art performance. In addition to performance improvements, our results demonstrate that smaller models, through careful pre-training and private fine-tuning, can match the performance of much larger models that do not have access to private data. This underscores the potential of private learning for model compression and enhanced efficiency",
    "checked": true,
    "id": "fec35357525ae87f46067da841478f35e28ed8e9",
    "semantic_title": "selective pre-training for private fine-tuning",
    "citation_count": 19,
    "authors": [
      "Da Yu",
      "Sivakanth Gopi",
      "Janardhan Kulkarni",
      "Zinan Lin",
      "Saurabh Naik",
      "Tomasz Lukasz Religa",
      "Jian Yin",
      "Huishuai Zhang"
    ]
  },
  "https://openreview.net/forum?id=lmgf03HeqV": {
    "title": "Learning Tree-Structured Composition of Data Augmentation",
    "volume": "main",
    "abstract": "Data augmentation is widely used in scenarios where one needs to train a neural network given little labeled data. A common practice of augmentation training is applying a composition of multiple transformations sequentially to the data. Existing augmentation methods such as RandAugment rely on domain expertise to select a list of transformations, while other methods such as AutoAugment formulate an optimization problem over a search space of size $k^d$, which is the number of sequences of length $d$, given a list of $k$ transformation functions. In this paper, we focus on designing efficient algorithms whose running time complexity is much faster than the worst-case complexity of $O(k^d)$, provably. We propose a new algorithm to search for a binary tree-structured composition of $k$ transformations, where each tree node corresponds to one transformation. The binary tree generalizes sequential augmentations, such as the one constructed by SimCLR. Using a top-down, recursive search procedure, our algorithm achieves a runtime complexity of $O(2^d k)$, which is much faster than $O(k^d)$ as $k$ increases above $2$. We apply the algorithm to tackle data distributions with heterogeneous subpopulations, by searching for one tree in each subpopulation, and then learn a weighted combination, leading to a forest of the trees. We validate the proposed algorithms on numerous graph and image data sets, including a multi-label graph classification data set we collected. The data set exhibits significant variations in the sizes of graphs and their average degrees, making it ideal for studying data augmentation. We show that our approach can reduce the computation cost (measured by GPU hours) by 43% over existing augmentation search methods while improving performance by 4.3%. Extensive experiments on contrastive learning also validate the benefit of our approach. The tree structures can be used to interpret the relative importance of each transformation, such as identifying the important transformations on small vs. large graphs",
    "checked": true,
    "id": "e775a93b4c647e2c28ef262b8ec8b2e68dcd2bd9",
    "semantic_title": "learning tree-structured composition of data augmentation",
    "citation_count": 1,
    "authors": [
      "Dongyue Li",
      "Kailai Chen",
      "Predrag Radivojac",
      "Hongyang R. Zhang"
    ]
  },
  "https://openreview.net/forum?id=IZnrCGF9WI": {
    "title": "Large Language Models (LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey",
    "volume": "main",
    "abstract": "Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field",
    "checked": false,
    "id": "2046b2da23eb2f79744eb391d902da9cedf87947",
    "semantic_title": "large language models(llms) on tabular data: prediction, generation, and understanding - a survey",
    "citation_count": 81,
    "authors": [
      "Xi Fang",
      "Weijie Xu",
      "Fiona Anting Tan",
      "Ziqing Hu",
      "Jiani Zhang",
      "Yanjun Qi",
      "Srinivasan H. Sengamedu",
      "Christos Faloutsos"
    ]
  },
  "https://openreview.net/forum?id=thfoUZugvS": {
    "title": "Koopman Spectrum Nonlinear Regulators and Efficient Online Learning",
    "volume": "main",
    "abstract": "Most modern reinforcement learning algorithms optimize a cumulative single-step cost along a trajectory. The optimized motions are often âunnatural', representing, for example, behaviors with sudden accelerations that waste energy and lack predictability. In this work, we present a novel paradigm of controlling nonlinear systems via the minimization of the Koopman spectrum cost: a cost over the Koopman operator of the controlled dynamics. This induces a broader class of dynamical behaviors that evolve over stable manifolds such as nonlinear oscillators, closed loops, and smooth movements. We demonstrate that some dynamics characterizations that are not possible with a cumulative cost are feasible in this paradigm, which generalizes the classical eigenstructure and pole assignments to nonlinear decision making. Moreover, we present a sample efficient online learning algorithm for our problem that enjoys a sub-linear regret bound under some structural assumptions",
    "checked": false,
    "id": "3c0783be1d71b5645fedba893d6a1e330a17c823",
    "semantic_title": "embedding koopman optimal control in robot policy learning",
    "citation_count": 9,
    "authors": [
      "Motoya Ohnishi",
      "Isao Ishikawa",
      "Kendall Lowrey",
      "Masahiro Ikeda",
      "Sham M. Kakade",
      "Yoshinobu Kawahara"
    ]
  },
  "https://openreview.net/forum?id=vgthYeRBAF": {
    "title": "Accurate Neural Network Pruning Requires Rethinking Sparse Optimization",
    "volume": "main",
    "abstract": "Obtaining versions of deep neural networks that are both highly-accurate and highly-sparse % is one of the main challenges in the area of model compression, and several high-performance pruning techniques have been investigated by the community. Yet, much less is known about the interaction between sparsity and the standard stochastic optimization techniques used for training sparse networks, and most existing work uses standard dense schedules and hyperparameters for training sparse networks. In this work, we examine the impact of high sparsity on model training using the standard computer vision and natural language processing sparsity benchmarks. We begin by showing that using standard dense training recipes for sparse training is suboptimal, and provide evidence that this results in *under-training*, loosely defined as using a suboptimal number of passes over the training data. We present training recipes for mitigating this issue for both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and sparse fine-tuning of language models (e.g. BERT/GLUE), achieving state-of-the-art results in both settings in the high-sparsity regime, and providing detailed analyses for the difficulty of sparse training in both scenarios. Our work sets a new benchmark in terms of the accuracies that can be achieved under high sparsity, and should inspire further research into improving sparse model training, to reach higher accuracies under high sparsity, but also to do so efficiently",
    "checked": true,
    "id": "d2a42864605a502325a874bc470481ca1904ea0a",
    "semantic_title": "accurate neural network pruning requires rethinking sparse optimization",
    "citation_count": 13,
    "authors": [
      "Denis Kuznedelev",
      "Eldar Kurtic",
      "Eugenia Iofinova",
      "Elias Frantar",
      "Alexandra Peste",
      "Dan Alistarh"
    ]
  },
  "https://openreview.net/forum?id=DN6sut5fyR": {
    "title": "Learning Network Granger causality using Graph Prior Knowledge",
    "volume": "main",
    "abstract": "Understanding the relationships among multiple entities through Granger causality graphs within multivariate time series data is crucial across various domains, including economics, finance, neurosciences, and genetics. Despite its broad utility, accurately estimating Granger causality graphs in high-dimensional scenarios with few samples remains a persistent chal- lenge. In response, this study introduces a novel model that leverages prior knowledge in the form of a noisy undirected graph to facilitate the learning of Granger causality graphs, while assuming sparsity. In this study we introduce an optimization problem, we propose to solve it with an alternative minimization approach and we proved the convergence of our fitting algorithm, highlighting its effectiveness. Furthermore, we present experimental results derived from both synthetic and real-world datasets. These results clearly illustrate the advantages of our proposed method over existing alternatives, particularly in situations where few samples are available. By incorporating prior knowledge and emphasizing spar- sity, our approach offers a promising solution to the complex problem of estimating Granger causality graphs in high-dimensional, data-scarce environments",
    "checked": true,
    "id": "3f159f93b74e92aefa3c345f12c61f530a348f3a",
    "semantic_title": "learning network granger causality using graph prior knowledge",
    "citation_count": 1,
    "authors": [
      "Lucas Zoroddu",
      "Pierre Humbert",
      "Laurent Oudre"
    ]
  },
  "https://openreview.net/forum?id=aIG2RAtNuX": {
    "title": "Best-of-Both-Worlds Linear Contextual Bandits",
    "volume": "main",
    "abstract": "This study investigates the problem of $K$-armed linear contextual bandits, an instance of the multi-armed bandit problem, under an adversarial corruption. At each round, a decision-maker observes an independent and identically distributed context and then selects an arm based on the context and past observations. After selecting an arm, the decision-maker incurs a loss corresponding to the selected arm. The decision-maker aims to minimize the cumulative loss over the trial. The goal of this study is to develop a strategy that is effective in both stochastic and adversarial environments, with theoretical guarantees. We first formulate the problem by introducing a novel setting of bandits with adversarial corruption, referred to as the contextual adversarial regime with a self-bounding constraint. We assume linear models for the relationship between the loss and the context. Then, we propose a strategy that extends the {\\tt RealLinExp3} by \\citet{Neu2020} and the Follow-The-Regularized-Leader (FTRL). The regret of our proposed algorithm is shown to be upper-bounded by $O\\left(\\min\\left\\{\\frac{(\\log(T))^3}{\\Delta_{*}} + \\sqrt{\\frac{C(\\log(T))^3}{\\Delta_{*}}},\\ \\ \\sqrt{T}(\\log(T))^2\\right\\}\\right)$, where $T \\in\\mathbb{N}$ is the number of rounds, $\\Delta_{*} > 0$ is the constant minimum gap between the best and suboptimal arms for any context, and $C\\in[0, T] $ is an adversarial corruption parameter. This regret upper bound implies $O\\left(\\frac{(\\log(T))^3}{\\Delta_{*}}\\right)$ in a stochastic environment and by $O\\left( \\sqrt{T}(\\log(T))^2\\right)$ in an adversarial environment. We refer to our strategy as the {\\tt Best-of-Both-Worlds (BoBW) RealFTRL}, due to its theoretical guarantees in both stochastic and adversarial regimes",
    "checked": true,
    "id": "78670c42c8956d06af1eb605bc2b4cc226362893",
    "semantic_title": "best-of-both-worlds linear contextual bandits",
    "citation_count": 1,
    "authors": [
      "Masahiro Kato",
      "Shinji Ito"
    ]
  },
  "https://openreview.net/forum?id=RGQsUQDAd9": {
    "title": "Spike Accumulation Forwarding for Effective Training of Spiking Neural Networks",
    "volume": "main",
    "abstract": "In this article, we propose a new paradigm for training spiking neural networks (SNNs), spike accumulation forwarding (SAF). It is known that SNNs are energy-efficient but difficult to train. Consequently, many researchers have proposed various methods to solve this problem, among which online training through time (OTTT) is a method that allows inferring at each time step while suppressing the memory cost. However, to compute efficiently on GPUs, OTTT requires operations with spike trains and weighted summation of spike trains during forwarding. In addition, OTTT has shown a relationship with the Spike Representation, an alternative training method, though theoretical agreement with Spike Representation has yet to be proven. Our proposed method can solve these problems; namely, SAF can halve the number of operations during the forward process, and it can be theoretically proven that SAF is consistent with the Spike Representation and OTTT, respectively. Furthermore, we confirmed the above contents through experiments and showed that it is possible to reduce memory and training time while maintaining accuracy",
    "checked": true,
    "id": "3fce2ce2c9c4f97b99200a5ffaba3a7d3e866cd8",
    "semantic_title": "spike accumulation forwarding for effective training of spiking neural networks",
    "citation_count": 1,
    "authors": [
      "Ryuji Saiin",
      "Tomoya Shirakawa",
      "Sota Yoshihara",
      "Yoshihide Sawada",
      "Hiroyuki Kusumoto"
    ]
  },
  "https://openreview.net/forum?id=i2SuGWtIIm": {
    "title": "Learning the essential in less than 2k additional weights - a simple approach to improve image classification stability under corruptions",
    "volume": "main",
    "abstract": "The performance of image classification on well-known benchmarks such as ImageNet is remarkable, but in safety-critical situations, the accuracy often drops significantly under adverse conditions. To counteract these performance drops, we propose a very simple modification to the models: we pre-pend a single, dimension preserving convolutional layer with a large linear kernel whose purpose it is to extract the information that is essential for image classification. We show that our simple modification can increase the robustness against common corruptions significantly, especially for corruptions of high severity. We demonstrate the impact of our channel-specific layers on ImageNet-100 and ImageNette classification tasks and show an increase of up to 30% accuracy on corrupted data in the top1 accuracy. Further, we conduct a set of designed experiments to qualify the conditions for our findings. Our main result is that a data- and network-dependent linear subspace carries the most important classification information (the essential), which our proposed pre-processing layer approximately identifies for most corruptions, and at very low cost",
    "checked": true,
    "id": "a218a51acaca6c135e57e6d25ed4d5ab9f2e1113",
    "semantic_title": "learning the essential in less than 2k additional weights - a simple approach to improve image classification stability under corruptions",
    "citation_count": 0,
    "authors": [
      "Kai BÃ¤uerle",
      "Patrick MÃ¼ller",
      "Syed Muhammad Kazim",
      "Ivo Ihrke",
      "Margret Keuper"
    ]
  },
  "https://openreview.net/forum?id=PLIt3a4yTm": {
    "title": "Training-free linear image inverses via flows",
    "volume": "main",
    "abstract": "Solving inverse problems without any training involves using a pretrained generative model and making appropriate modifications to the generation process to avoid finetuning of the generative model. While recent methods have explored the use of diffusion models, they still require the manual tuning of many hyperparameters for different inverse problems. In this work, we propose a training-free method for solving linear inverse problems by using pretrained flow models, leveraging the simplicity and efficiency of Flow Matching models, using theoretically-justified weighting schemes, and thereby significantly reducing the amount of manual tuning. In particular, we draw inspiration from two main sources: adopting prior gradient correction methods to the flow regime, and a solver scheme based on conditional Optimal Transport paths. As pretrained diffusion models are widely accessible, we also show how to practically adapt diffusion models for our method. Empirically, our approach requires no problem-specific tuning across an extensive suite of noisy linear inverse problems on high-dimensional datasets, ImageNet-64/128 and AFHQ-256, and we observe that our flow-based method for solving inverse problems improves upon closely-related diffusion-based methods in most settings",
    "checked": true,
    "id": "d72bf83fbeae8df51ab86bb8f3965b40416c8ac7",
    "semantic_title": "training-free linear image inverses via flows",
    "citation_count": 24,
    "authors": [
      "Ashwini Pokle",
      "Matthew J. Muckley",
      "Ricky T. Q. Chen",
      "Brian Karrer"
    ]
  },
  "https://openreview.net/forum?id=PtNyIboDIG": {
    "title": "Cooperative Online Learning with Feedback Graphs",
    "volume": "main",
    "abstract": "We study the interplay between communication and feedback in a cooperative online learning setting, where a network of communicating agents learn a common sequential decision-making task through a feedback graph. We bound the network regret in terms of the independence number of the strong product between the communication network and the feedback graph. Our analysis recovers as special cases many previously known bounds for cooperative online learning with expert or bandit feedback. We also prove an instance-based lower bound, demonstrating that our positive results are not improvable except in pathological cases. Experiments on synthetic data confirm our theoretical findings",
    "checked": false,
    "id": "d262f2fd16acb9ef9418f7d67fe4e7cc5a8332d4",
    "semantic_title": "adversarial online learning with temporal feedback graphs",
    "citation_count": 1,
    "authors": [
      "NicolÃ² Cesa-Bianchi",
      "Tommaso Cesari",
      "Riccardo Della Vecchia"
    ]
  },
  "https://openreview.net/forum?id=142xsInVfp": {
    "title": "On the numerical reliability of nonsmooth autodiff: a MaxPool case study",
    "volume": "main",
    "abstract": "This paper considers the reliability of automatic differentiation for neural networks involving the nonsmooth MaxPool operation across various precision levels (16, 32, 64 bits), architectures (LeNet, VGG, ResNet), and datasets (MNIST, CIFAR10, SVHN, ImageNet). Although AD can be incorrect, recent research has shown that it coincides with the derivative almost everywhere, even in the presence of nonsmooth operations. On the other hand, in practice, AD operates with floating-point numbers, and there is, therefore, a need to explore subsets on which AD can be {\\em numerically} incorrect. Recently, \\cite{bertoin2021numerical} empirically studied how the choice of $\\ReLU'(0)$ changes the output of AD and define a numerical bifurcation zone where using $\\ReLU('0) = 0$ differs from using $\\ReLU'(0) = 1$. To extend this for a broader class of nonsmooth operations, we propose a new numerical bifurcation zone (where AD is incorrect over real numbers) and define a compensation zone (where AD is incorrect over floating-point numbers but correct over reals). Using SGD for training, we found that nonsmooth MaxPool Jacobians with lower norms maintain stable and efficient test accuracy, while higher norms can result in instability and decreased performance. We can use batch normalization, Adam-like optimizers, or increase precision to reduce MaxPool Jacobians influence",
    "checked": true,
    "id": "2832ea7854072899bbd5c29bedb3fc639d282216",
    "semantic_title": "on the numerical reliability of nonsmooth autodiff: a maxpool case study",
    "citation_count": 1,
    "authors": [
      "Ryan Boustany"
    ]
  },
  "https://openreview.net/forum?id=ZeI104QZ8I": {
    "title": "Universal Neurons in GPT2 Language Models",
    "volume": "main",
    "abstract": "A basic question within the emerging field of mechanistic interpretability is the degree to which neural networks learn the same underlying mechanisms. In other words, are neural mechanisms universal across different models? In this work, we study the universality of individual neurons across GPT2 models trained from different initial random seeds, motivated by the hypothesis that universal neurons are likely to be interpretable. In particular, we compute pairwise correlations of neuron activations over 100 million tokens for every neuron pair across five different seeds and find that 1-5\\% of neurons are universal, that is, pairs of neurons which consistently activate on the same inputs. We then study these universal neurons in detail, finding that they usually have clear interpretations and taxonomize them into a small number of neuron families. We conclude by studying patterns in neuron weights to establish several universal functional roles of neurons in simple circuits: deactivating attention heads, changing the entropy of the next token distribution, and predicting the next token to (not) be within a particular set",
    "checked": true,
    "id": "436cd0fe00807bc9d14434f3313dc836530f2dae",
    "semantic_title": "universal neurons in gpt2 language models",
    "citation_count": 47,
    "authors": [
      "Wes Gurnee",
      "Theo Horsley",
      "Zifan Carl Guo",
      "Tara Rezaei Kheirkhah",
      "Qinyi Sun",
      "Will Hathaway",
      "Neel Nanda",
      "Dimitris Bertsimas"
    ]
  },
  "https://openreview.net/forum?id=DLqPhQxgYu": {
    "title": "Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory: Application in Regression",
    "volume": "main",
    "abstract": "In supervised learning, it is quite frequent to be confronted with real imbalanced datasets. This situation leads to a learning difficulty for standard algorithms. Research and solutions in imbalanced learning have mainly focused on classification tasks. Despite its importance, very few solutions exist for imbalanced regression. In this paper, we propose a data augmentation procedure, the GOLIATH algorithm, based on kernel density estimates and especially dedicated to the problem of imbalanced data. This general approach encompasses two large families of synthetic oversampling: those based on perturbations, such as Gaussian Noise, and those based on interpolations, such as SMOTE. It also provides an explicit form of such machine learning algorithms. New synthetic data generators are deduced. We apply GOLIATH in imbalanced regression combining such generator procedures with a new wild-bootstrap resampling technique for the target values. We evaluate the performance of the GOLIATH algorithm in imbalanced regression where we compare our approach with state-of-the-art techniques",
    "checked": false,
    "id": "46eba6f7828134d12fd69148fb3c0164ea5249bc",
    "semantic_title": "generalized oversampling for learning from imbalanced datasets and associated theory",
    "citation_count": 1,
    "authors": [
      "Samuel Stocksieker",
      "Denys Pommeret",
      "Arthur Charpentier"
    ]
  },
  "https://openreview.net/forum?id=nB8foAclpo": {
    "title": "Bit-by-Bit: Investigating the Vulnerabilities of Binary Neural Networks to Adversarial Bit Flipping",
    "volume": "main",
    "abstract": "Binary Neural Networks (BNNs), operating with ultra-low precision weights, incur a significant reduction in storage and compute cost compared to the traditional Deep Neural Networks (DNNs). However, vulnerability of such models against various hardware attacks are yet to be fully unveiled. Towards understanding the potential threat imposed on such highly efficient models, in this paper, we explore a novel adversarial attack paradigm pertaining to BNNs. In specific, we assume the attack to be executed during deployment phase, prior to inference, to achieve malicious intentions, via manipulation of accessible network parameters. We aim to accomplish a graceless degradation in BNN accuracy to a point, where the fully functional network can behave as a random output generator at best, thus subverting the confidence in the system. To this end, we propose an Outlier Gradient-based Evolutionary (OGE) attack, that learns injection of minimal amount of critical bit flips in the pre-trained binary network weights, to introduce classification errors in the inference execution. To the best of our knowledge, this is the first work that leverages the outlier gradient weights to orchestrate a hardware-based bit-flip attack, that is highly effective against the typically resilient low-quantization BNNs. Exhaustive evaluations on popular image recognition datasets including Fashion-MNIST, CIFAR10, GTSRB, and ImageNet demonstrate that, OGE can drop up to 68.1% of the test images mis-classification, by flipping as little as 150 binary weights, out of 10.3 millions in a BNN architecture",
    "checked": true,
    "id": "95c69c2c48138b15b5d161076da2b2a41e907463",
    "semantic_title": "bit-by-bit: investigating the vulnerabilities of binary neural networks to adversarial bit flipping",
    "citation_count": 0,
    "authors": [
      "Shamik Kundu",
      "Sanjay Das",
      "Sayar Karmakar",
      "Arnab Raha",
      "Souvik Kundu",
      "Yiorgos Makris",
      "Kanad Basu"
    ]
  },
  "https://openreview.net/forum?id=hfrPag75Y0": {
    "title": "Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks",
    "volume": "main",
    "abstract": "This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin. For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set. For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin. Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points",
    "checked": true,
    "id": "3b047eb305fe20b34bd9e464b10bf2e41a3c143c",
    "semantic_title": "directional convergence near small initializations and saddles in two-homogeneous neural networks",
    "citation_count": 8,
    "authors": [
      "Akshay Kumar",
      "Jarvis Haupt"
    ]
  },
  "https://openreview.net/forum?id=lrZ2yiqOS2": {
    "title": "Towards Minimal Targeted Updates of Language Models with Targeted Negative Training",
    "volume": "main",
    "abstract": "Generative models of language exhibit impressive capabilities but still place non-negligible probability mass over undesirable outputs. In this work, we address the task of updating a model to avoid unwanted outputs while minimally changing model behavior otherwise, a challenge we refer to as a minimal targeted update. We first formalize the notion of a minimal targeted update and propose a method to achieve such updates using negative examples from a model's generations. Our proposed Targeted Negative Training (TNT) results in updates that keep the new distribution close to the original, unlike existing losses for negative signal which push down probability but do not control what the updated distribution will be. In experiments, we demonstrate that TNT yields a better trade-off between reducing unwanted behavior and maintaining model generation behavior than baselines, paving the way towards a modeling paradigm based on iterative training updates that constrain models from generating undesirable outputs while preserving their impressive capabilities",
    "checked": true,
    "id": "af43312834157f1020f59b49fb729affa6d8a7b0",
    "semantic_title": "towards minimal targeted updates of language models with targeted negative training",
    "citation_count": 1,
    "authors": [
      "Lily H Zhang",
      "Rajesh Ranganath",
      "Arya Tafvizi"
    ]
  },
  "https://openreview.net/forum?id=9YqacugDER": {
    "title": "Towards Understanding Variants of Invariant Risk Minimization through the Lens of Calibration",
    "volume": "main",
    "abstract": "Machine learning models traditionally assume that training and test data are independently and identically distributed. However, in real-world applications, the test distribution often differs from training. This problem, known as out-of-distribution (OOD) generalization, challenges conventional models. Invariant Risk Minimization (IRM) emerges as a solution that aims to identify invariant features across different environments to enhance OOD robustness. However, IRM's complexity, particularly its bi-level optimization, has led to the development of various approximate methods. Our study investigates these approximate IRM techniques, using the consistency and variance of calibration across environments as metrics to measure the invariance aimed for by IRM. Calibration, which measures the reliability of model prediction, serves as an indicator of whether models effectively capture environment-invariant features by showing how uniformly over-confident the model remains across varied environments. Through a comparative analysis of datasets with distributional shifts, we observe that Information Bottleneck-based IRM achieves consistent calibration across different environments. This observation suggests that information compression techniques, such as IB, are potentially effective in achieving model invariance. Furthermore, our empirical evidence indicates that models exhibiting consistent calibration across environments are also well-calibrated. This demonstrates that invariance and cross-environment calibration are empirically equivalent. Additionally, we underscore the necessity for a systematic approach to evaluating OOD generalization. This approach should move beyond traditional metrics, such as accuracy and F1 scores, which fail to account for the model's degree of over-confidence, and instead focus on the nuanced interplay between accuracy, calibration, and model invariance",
    "checked": true,
    "id": "ce4b622ecda1b5a27d391719733f86a3b1bd23a8",
    "semantic_title": "towards understanding variants of invariant risk minimization through the lens of calibration",
    "citation_count": 2,
    "authors": [
      "Kotaro Yoshida",
      "Hiroki Naganuma"
    ]
  },
  "https://openreview.net/forum?id=73uyerai53": {
    "title": "TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality",
    "volume": "main",
    "abstract": "This paper addresses a cross-modal learning framework, where the objective is to enhance the performance of supervised learning in the primary modality using an unlabeled, unpaired secondary modality. Taking a probabilistic approach for missing information estimation, we show that the extra information contained in the secondary modality can be estimated via Nadaraya-Watson (NW) kernel regression, which can further be expressed as a kernelized cross-attention module (under linear transformation). This expression lays the foundation for introducing The Attention Patch (TAP), a simple neural network add-on that can be trained to allow data-level knowledge transfer from the unlabeled modality. We provide extensive numerical simulations using real-world datasets to show that TAP can provide statistically significant improvement in generalization across different domains and different neural network architectures, making use of seemingly unusable unlabeled cross-modal data",
    "checked": true,
    "id": "0f88051371fbfffa4f8323953ee5a294ebca7ef2",
    "semantic_title": "tap: the attention patch for cross-modal knowledge transfer from unlabeled modality",
    "citation_count": 0,
    "authors": [
      "Yinsong Wang",
      "Shahin Shahrampour"
    ]
  },
  "https://openreview.net/forum?id=imAROs79Pb": {
    "title": "Mildly Constrained Evaluation Policy for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Offline reinforcement learning (RL) methodologies enforce constraints on the policy to adhere closely to the behavior policy, thereby stabilizing value learning and mitigating the selection of out-of-distribution (OOD) actions during test time. Conventional approaches apply identical constraints for both value learning and test time inference. However, our findings indicate that the constraints suitable for value estimation may in fact be excessively restrictive for action selection during test time. To address this issue, we propose a Mildly Constrained Evaluation Policy (MCEP) for test time inference with a more constrained target policy for value estimation. Since the target policy has been adopted in various prior approaches, MCEP can be seamlessly integrated with them as a plug-in. We instantiate MCEP based on TD3BC (Fujimoto & Gu, 2021), AWAC (Nair et al., 2020) and DQL (Wang et al., 2023) algorithms. The empirical results on D4RL MuJoCo locomotion, high-dimensional humanoid and a set of 16 robotic manipulation tasks show that the MCEP brought significant performance improvement on classic offline RL methods and can further improve SOTA methods. The codes are open-sourced at \\url{https://github.com/egg-west/MCEP}",
    "checked": true,
    "id": "98955552dcafb726718fc7e248b3fb7c4c9dbbf4",
    "semantic_title": "mildly constrained evaluation policy for offline reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Linjie Xu",
      "zhengyao jiang",
      "Jinyu Wang",
      "Lei Song",
      "Jiang Bian"
    ]
  },
  "https://openreview.net/forum?id=e6sqttxEGX": {
    "title": "Deep End-to-end Causal Inference",
    "volume": "main",
    "abstract": "Causal inference is essential for data-driven decision-making across domains such as business engagement, medical treatment, and policy making. However, in practice, causal inference suffers from many limitations including unknown causal graphs, missing data problems, and mixed data types. To tackle those challenges, we develop Deep End-to-end Causal Inference (DECI) framework, a flow based non-linear additive noise model combined with variational inference, which can perform both Bayesian causal discovery and inference. Theoretically, we show that DECI unifies many existing structural equation model (SEM) based causal inference techniques and can recover the ground truth mechanism under standard assumptions. Motivated by the challenges in the real world, we further extend DECI to heterogeneous, mixed-type data with missing values, allowing for both continuous and discrete treatment decisions. Empirically, we conduct extensive experiments (over a thousand) to show the competitive performance of DECI when compared to relevant baselines for both causal discovery and inference with both synthetic and causal machine learning benchmarks across data types and levels of missingness",
    "checked": true,
    "id": "fc37b0ace634cd7be362dfacac618a8abfc254ff",
    "semantic_title": "deep end-to-end causal inference",
    "citation_count": 91,
    "authors": [
      "Tomas Geffner",
      "Javier Antoran",
      "Adam Foster",
      "Wenbo Gong",
      "Chao Ma",
      "Emre Kiciman",
      "Amit Sharma",
      "Angus Lamb",
      "Martin Kukla",
      "Nick Pawlowski",
      "Agrin Hilmkil",
      "Joel Jennings",
      "Meyer Scetbon",
      "Miltiadis Allamanis",
      "Cheng Zhang"
    ]
  },
  "https://openreview.net/forum?id=3HE4vPNIfX": {
    "title": "A Survey on Fairness Without Demographics",
    "volume": "main",
    "abstract": "The issue of bias in Machine Learning (ML) models is a significant challenge for the machine learning community. Real-world biases can be embedded in the data used to train models, and prior studies have shown that ML models can learn and even amplify these biases. This can result in unfair treatment of individuals based on their inherent characteristics or sensitive attributes such as gender, race, or age. Ensuring fairness is crucial with the increasing use of ML models in high-stakes scenarios and has gained significant attention from researchers in recent years. However, the challenge of ensuring fairness becomes much greater when the assumption of full access to sensitive attributes does not hold. The settings where the hypothesis does not hold include cases where (1) only limited or noisy demographic information is available or (2) demographic information is entirely unobserved due to privacy restrictions. This survey reviews recent research efforts to enforce fairness when sensitive attributes are missing. We propose a taxonomy of existing works and, more importantly, highlight current challenges and future research directions to stimulate research in ML fairness in the setting of missing sensitive attributes",
    "checked": true,
    "id": "7daaf254d0ab21cffd7af6d001c25641f4842cbe",
    "semantic_title": "a survey on fairness without demographics",
    "citation_count": 4,
    "authors": [
      "Patrik Joslin Kenfack",
      "Samira Ebrahimi Kahou",
      "Ulrich AÃ¯vodji"
    ]
  },
  "https://openreview.net/forum?id=LCPzaR9mML": {
    "title": "Multiple Kronecker RLS fusion-based link propagation for drug-side effect prediction",
    "volume": "main",
    "abstract": "Drug-side effect prediction has become an essential area of research in the field of pharmacology. As the use of medications continues to rise, so does the importance of understanding and mitigating the potential risks associated with them. At present, researchers have turned to data-driven methods to predict drug-side effects. Drug-side effect prediction is a link prediction problem, and the related data can be described from various perspectives. To process these kinds of data, a multi-view method, called Multiple Kronecker RLS fusion-based link propagation (MKronRLSF-LP), is proposed. MKronRLSF-LP extends the Kron-RLS by finding the consensus partitions and multiple graph Laplacian constraints in the multi-view setting. Both of these multi-view settings contribute to a higher quality result. Extensive experiments have been conducted on drug-side effect datasets, and our empirical results provide evidence that our approach is effective and robust",
    "checked": true,
    "id": "a63527bfc5bdbb286aecbc16d31c2e4de057109d",
    "semantic_title": "multiple kronecker rls fusion-based link propagation for drug-side effect prediction",
    "citation_count": 0,
    "authors": [
      "Yuqing Qian",
      "Ziyu Zheng",
      "Prayag Tiwari",
      "Yijie Ding",
      "Quan Zou"
    ]
  },
  "https://openreview.net/forum?id=aHtZuZfHcf": {
    "title": "Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting",
    "volume": "main",
    "abstract": "Continual learning research has shown that neural networks suffer from catastrophic forgetting \"at the output level\", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally in comparison with forgetting at the output level. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Taking both aspects into account, we show that, even though forgetting in the representation (i.e. feature forgetting) can be small in absolute terms, when measuring relative to how much was learned during a task, forgetting in the representation tends to be just as catastrophic as forgetting at the output level. Next we show that this feature forgetting is problematic as it substantially slows down the incremental learning of good general representations (i.e. knowledge accumulation). Finally, we study how feature forgetting and knowledge accumulation are affected by different types of continual learning methods",
    "checked": true,
    "id": "f7b643517d52995e514d7e202206e7f45333f7aa",
    "semantic_title": "knowledge accumulation in continually learned representations and the issue of feature forgetting",
    "citation_count": 9,
    "authors": [
      "Timm Hess",
      "Eli Verwimp",
      "Gido M van de Ven",
      "Tinne Tuytelaars"
    ]
  },
  "https://openreview.net/forum?id=8DWrIMuLya": {
    "title": "Estimating class separability of text embeddings with persistent homology",
    "volume": "main",
    "abstract": "This paper introduces an unsupervised method to estimate the class separability of text datasets from a topological point of view. Using persistent homology, we demonstrate how tracking the evolution of embedding manifolds during training can inform about class sep- arability. More specifically, we show how this technique can be applied to detect when the training process stops improving the separability of the embeddings. Our results, validated across binary and multi-class text classification tasks, show that the proposed method's estimates of class separability align with those obtained from supervised methods. This approach offers a novel perspective on monitoring and improving the fine-tuning of sentence transformers for classification tasks, particularly in scenarios where labeled data is scarce. We also discuss how tracking these quantities can provide additional insights into the properties of the trained classifier",
    "checked": true,
    "id": "01fea7f797442c83007476e64cd341917d9b0efc",
    "semantic_title": "estimating class separability of text embeddings with persistent homology",
    "citation_count": 1,
    "authors": [
      "Kostis Gourgoulias",
      "Najah Ghalyan",
      "Maxime Labonne",
      "yash satsangi",
      "Sean Moran",
      "Joseph Sabelja"
    ]
  },
  "https://openreview.net/forum?id=wC4ZID0H9a": {
    "title": "Exploring validation metrics for offline model-based optimisation with diffusion models",
    "volume": "main",
    "abstract": "In model-based optimisation (MBO) we are interested in using machine learning to design candidates that maximise some measure of reward with respect to a black box function called the (ground truth) oracle, which is expensive to compute since it involves executing a real world process. In offline MBO we wish to do so without assuming access to such an oracle during training or validation, with makes evaluation non-straightforward. While an approximation to the ground oracle can be trained and used in place of it during model validation to measure the mean reward over generated candidates, the evaluation is approximate and vulnerable to adversarial examples. Measuring the mean reward of generated candidates over this approximation is one such `validation metric', whereas we are interested in a more fundamental question which is finding which validation metrics correlate the most with the ground truth. This involves proposing validation metrics and quantifying them over many datasets for which the ground truth is known, for instance simulated environments. This is encapsulated under our proposed evaluation framework which is also designed to measure extrapolation, which is the ultimate goal behind leveraging generative models for MBO. While our evaluation framework is model agnostic we specifically evaluate denoising diffusion models due to their state-of-the-art performance, as well as derive interesting insights such as ranking the most effective validation metrics as well as discussing important hyperparameters",
    "checked": true,
    "id": "8f995cbe15e1c1fc2dbc9024b1b56440859761de",
    "semantic_title": "exploring validation metrics for offline model-based optimisation with diffusion models",
    "citation_count": 1,
    "authors": [
      "Christopher Beckham",
      "Alexandre PichÃ©",
      "David Vazquez",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=nK5MazeIpn": {
    "title": "Solving the Tree Containment Problem Using Graph Neural Networks",
    "volume": "main",
    "abstract": "\\textsc{Tree containment} is a fundamental problem in phylogenetics useful for verifying a proposed phylogenetic network, representing the evolutionary history of certain species. \\textsc{Tree containment} asks whether the given phylogenetic tree (for instance, constructed from a DNA fragment showing tree-like evolution) is contained in the given phylogenetic network. In the general case, this is an NP-complete problem. We propose to solve it approximately using Graph Neural Networks. In particular, we propose to combine the given network and the tree and apply a Graph Neural Network to this network-tree graph. This way, we achieve the capability of solving the tree containment instances representing a larger number of species than the instances contained in the training dataset (i.e., our algorithm has the inductive learning ability). Our algorithm demonstrates an accuracy of over $95\\%$ in solving the tree containment problem on instances with up to 100 leaves",
    "checked": true,
    "id": "90daabe7c9d95714b9f884361a6b7d6aaa1d27e5",
    "semantic_title": "solving the tree containment problem using graph neural networks",
    "citation_count": 0,
    "authors": [
      "Arkadiy Dushatskiy",
      "Esther Julien",
      "Leen Stougie",
      "Leo van Iersel"
    ]
  },
  "https://openreview.net/forum?id=Sy6ZOStz5v": {
    "title": "A Simple Video Segmenter by Tracking Objects Along Axial Trajectories",
    "volume": "main",
    "abstract": "Video segmentation requires consistently segmenting and tracking objects over time. Due to the quadratic dependency on input size, directly applying self-attention to video segmentation with high-resolution input features poses significant challenges, often leading to GPU Out-Of-Memory errors. Consequently, modern video segmenters either extend an image segmenter without incorporating any temporal attention or resort to window space-time attention in a naive manner. In this work, we present Axial-VS, a general and simple framework that enhances video segmenters by tracking objects along axial trajectories. The framework tackles video segmentation through two sub-tasks: short-term within-clip segmentation and long-term cross-clip tracking. In the first step, Axial-VS augments an off-the-shelf clip-level video segmenter with the proposed axial-trajectory attention, sequentially tracking objects along the height- and width-trajectories within a clip, thereby enhancing temporal consistency by capturing motion trajectories. The axial decomposition significantly reduces the computational complexity for dense features, and outperforms the window space-time attention in segmentation quality. In the second step, we further employ axial-trajectory attention to the object queries in clip-level segmenters, which are learned to encode object information, thereby aiding object tracking across different clips and achieving consistent segmentation throughout the video. Without bells and whistles, Axial-VS showcases state-of-the-art results on video segmentation benchmarks, emphasizing its effectiveness in addressing the limitations of modern clip-level video segmenters. Code will be made available",
    "checked": true,
    "id": "aaaa88a4c041f176c8a6862748d1b23028275117",
    "semantic_title": "a simple video segmenter by tracking objects along axial trajectories",
    "citation_count": 2,
    "authors": [
      "Ju He",
      "Qihang Yu",
      "Inkyu Shin",
      "Xueqing Deng",
      "Alan Yuille",
      "Xiaohui Shen",
      "Liang-Chieh Chen"
    ]
  },
  "https://openreview.net/forum?id=KxPjuiMgmm": {
    "title": "Targeted Active Learning for Bayesian Decision-Making",
    "volume": "main",
    "abstract": "Active learning is usually applied to acquire labels of informative data points in supervised learning, to maximize accuracy in a sample-efficient way. However, maximizing the supervised learning accuracy is not the end goal when the results are used for decision-making, for example in personalized medicine or economics. We argue that when acquiring samples sequentially, the common practice of separating learning and decision-making is sub-optimal, and we introduce an active learning strategy that takes the down-the-line decision problem into account. Specifically, we adopt a Bayesian experimental design approach, in which the proposed acquisition criterion maximizes the expected information gain on the posterior distribution of the optimal decision. We compare our targeted active learning strategy to existing alternatives on both simulated and real data and show improved performance in decision-making accuracy",
    "checked": false,
    "id": "f491f3181ec4702ac219330e2192294ae0b1c5e8",
    "semantic_title": "transductive active learning: theory and applications",
    "citation_count": 6,
    "authors": [
      "Louis Filstroff",
      "Iiris Sundin",
      "Petrus Mikkola",
      "Aleksei Tiulpin",
      "Juuso KylmÃ¤oja",
      "Samuel Kaski"
    ]
  },
  "https://openreview.net/forum?id=RA4yRhjoXw": {
    "title": "***FastDoc***: Domain-Specific Fast Continual Pre-training Technique using Document-Level Metadata and Taxonomy",
    "volume": "main",
    "abstract": "In this paper, we propose FastDoc (Fast Continual Pre-training Technique using Document Level Metadata and Taxonomy), a novel, compute-efficient framework that utilizes Document metadata and Domain-Specific Taxonomy as supervision signals to continually pre-train transformer encoder on a domain-specific corpus. The main innovation is that during domain-specific pretraining, an open-domain encoder is continually pre-trained using sentence-level embeddings as inputs (to accommodate long documents), however, fine-tuning is done with token-level embeddings as inputs to this encoder. We perform such domain-specific pre-training on three different domains namely customer support, scientific, and legal domains, and compare performance on 6 different downstream tasks and 9 different datasets. The novel use of document-level supervision along with sentence-level embedding input for pre-training reduces pre-training compute by around 1,000, 4,500, and 500 times compared to MLM and/or NSP in Customer Support, Scientific, and Legal Domains, respectively. The reduced training time does not lead to a deterioration in performance. In fact we show that FastDoc either outperforms or performs on par with several competitive transformer-based baselines in terms of character-level F1 scores and other automated metrics in the Customer Support, Scientific, and Legal Domains. Moreover, reduced training aids in mitigating the risk of catastrophic forgetting. Thus, unlike baselines, FastDoc shows a negligible drop in performance on open domain",
    "checked": true,
    "id": "834367bd6d837b89c617b230fd2e382eb65e07fa",
    "semantic_title": "***fastdoc***: domain-specific fast continual pre-training technique using document-level metadata and taxonomy",
    "citation_count": 0,
    "authors": [
      "Abhilash Nandy",
      "Manav Nitin Kapadnis",
      "Sohan Patnaik",
      "Yash Parag Butala",
      "Pawan Goyal",
      "Niloy Ganguly"
    ]
  },
  "https://openreview.net/forum?id=BogwFMz5tU": {
    "title": "Smoothed Robustness Analysis: Bridging worst- and average-case robustness analyses via smoothed analysis",
    "volume": "main",
    "abstract": "The sensitivity to adversarial attacks and noise is a significant drawback of neural networks, and understanding and certifying their robustness has attracted much attention. Studies have attempted to bridge two extreme analyses of robustness; one is the worst-case analysis, which often gives too pessimistic certification, and the other is the average-case analysis, which often fails to give a tight guarantee of robustness. Among them, \\textit{Randomized Smoothing} became prominent by certifying a worst-case region of a classifier under input noise. However, the method still suffers from several limitations, probably due to the lack of a larger underlying framework to locate it. Here, inspired by the \\textit{Smoothed Analysis} of algorithmic complexity, which bridges the worst-case and average-case analyses of algorithms, we provide a theoretical framework for robustness analyses of classifiers, which contains \\textit{Randomized Smoothing} as a special case. Using the framework, we also propose a novel robustness analysis that works even in the small noise regime and thus provides a more confident robustness certification than \\textit{Randomized Smoothing}. To validate the approach, we evaluate the robustness of fully connected and convolutional neural networks on the MNIST and CIFAR-10 datasets, respectively, and find that it indeed improves both adversarial and noise robustness",
    "checked": true,
    "id": "ddb8fb4307b435ae67262eb2f051e47f5f5fac4a",
    "semantic_title": "smoothed robustness analysis: bridging worst- and average-case robustness analyses via smoothed analysis",
    "citation_count": 0,
    "authors": [
      "Thomas Rodrigues Crespo",
      "Jun-nosuke Teramae"
    ]
  },
  "https://openreview.net/forum?id=jD761b5OaE": {
    "title": "Hybrid Active Learning with Uncertainty-Weighted Embeddings",
    "volume": "main",
    "abstract": "We introduce a hybrid active learning method that simultaneously considers uncertainty and diversity for sample selection. Our method consists of two key steps: computing a novel uncertainty-weighted embedding, then applying distance-based sampling for sample selection. Our proposed uncertainty-weighted embedding is computed by weighting a sample's feature representation by an uncertainty measure. We show how this embedding generalizes the gradient embedding of BADGE so it can be used with arbitrary loss functions and be computed more efficiently, especially for dense prediction tasks and network architectures with large numbers of parameters in the final layer. We extensively evaluate the proposed hybrid active learning method on image classification, semantic segmentation and object detection tasks, and demonstrate that it achieves state-of-the-art performance",
    "checked": true,
    "id": "b27ce4e58fe088ca212ee8bd010aaa5111dcc3b6",
    "semantic_title": "hybrid active learning with uncertainty-weighted embeddings",
    "citation_count": 2,
    "authors": [
      "Yinan He",
      "Lile Cai",
      "Jingyi Liao",
      "Chuan-Sheng Foo"
    ]
  },
  "https://openreview.net/forum?id=RIFJsSzwKY": {
    "title": "Nuisances via Negativa: Adjusting for Spurious Correlations via Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "65499b856dc6de0859e645a2277fbac569eeae61",
    "semantic_title": "nuisances via negativa: adjusting for spurious correlations via data augmentation",
    "citation_count": 17,
    "authors": [
      "Aahlad Manas Puli",
      "Nitish Joshi",
      "Yoav Wald",
      "He He",
      "Rajesh Ranganath"
    ]
  },
  "https://openreview.net/forum?id=A6eqDMttcs": {
    "title": "Making Translators Privacy-aware on the User's Side",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "838ede95cf551dece4dfb95c76180cc0b0efa54c",
    "semantic_title": "making translators privacy-aware on the user's side",
    "citation_count": 2,
    "authors": [
      "Ryoma Sato"
    ]
  },
  "https://openreview.net/forum?id=6LePXHr2f3": {
    "title": "Convergences for Minimax Optimization Problems over Infinite-Dimensional Spaces Towards Stability in Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b60213a4b0664c7000123e363d72b06e5188962f",
    "semantic_title": "convergences for minimax optimization problems over infinite-dimensional spaces towards stability in adversarial training",
    "citation_count": 0,
    "authors": [
      "Takashi Furuya",
      "Satoshi Okuda",
      "Kazuma Suetake",
      "Yoshihide Sawada"
    ]
  },
  "https://openreview.net/forum?id=JoU9khOwwr": {
    "title": "CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision-Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": "09abdc58b42df2de138a9cf6b9839b951cd93b55",
    "semantic_title": "comix: a multi-agent reinforcement learning training architecture for efficient decentralized coordination and independent decision making",
    "citation_count": 0,
    "authors": [
      "Giovanni Minelli",
      "Mirco Musolesi"
    ]
  },
  "https://openreview.net/forum?id=Y7FbGcjOuD": {
    "title": "Achieving the Asymptotically Minimax Optimal Sample Complexity of Offline Reinforcement Learning: A DRO-Based Approach",
    "volume": "main",
    "abstract": "Offline reinforcement learning aims to learn from pre-collected datasets without active exploration. This problem faces significant challenges, including limited data availability and distributional shifts. Existing approaches adopt a pessimistic stance towards uncertainty by penalizing rewards of under-explored state-action pairs to estimate value functions conservatively. In this paper, we show that the distributionally robust optimization (DRO) based approach can also address these challenges and is {asymptotically minimax optimal}. Specifically, we directly model the uncertainty in the transition kernel and construct an uncertainty set of statistically plausible transition kernels. We then show that the policy that optimizes the worst-case performance over this uncertainty set has a near-optimal performance in the underlying problem. We first design a metric-based distribution-based uncertainty set such that with high probability the true transition kernel is in this set. We prove that to achieve a sub-optimality gap of $\\epsilon$, the sample complexity is $\\mathcal{O}(S^2C^{\\pi^*}\\epsilon^{-2}(1-\\gamma)^{-4})$, where $\\gamma$ is the discount factor, $S$ is the number of states, and $C^{\\pi^*}$ is the single-policy clipped concentrability coefficient which quantifies the distribution shift. To achieve the optimal sample complexity, we further propose a less conservative value-function-based uncertainty set, which, however, does not necessarily include the true transition kernel. We show that an improved sample complexity of $\\mathcal{O}(SC^{\\pi^*}\\epsilon^{-2}(1-\\gamma)^{-3})$ can be obtained, which asymptotically matches with the minimax lower bound for offline reinforcement learning, and thus is asymptotically minimax optimal",
    "checked": true,
    "id": "6d18a0e7a1bac0664ca105b8550e6952c4db2f33",
    "semantic_title": "achieving the asymptotically minimax optimal sample complexity of offline reinforcement learning: a dro-based approach",
    "citation_count": 1,
    "authors": [
      "Yue Wang",
      "Jinjun Xiong",
      "Shaofeng Zou"
    ]
  },
  "https://openreview.net/forum?id=sHSkJqyQgW": {
    "title": "Promoting Exploration in Memory-Augmented Adam using Critical Momenta",
    "volume": "main",
    "abstract": "Adaptive gradient-based optimizers, notably Adam, have left their mark in training large-scale deep learning models, offering fast convergence and robustness to hyperparameter settings. However, they often struggle with generalization, attributed to their tendency to converge to sharp minima in the loss landscape. To address this, we propose a new memory-augmented version of Adam that encourages exploration towards flatter minima by incorporating a buffer of critical momentum terms during training. This buffer prompts the optimizer to overshoot beyond narrow minima, promoting exploration. Through comprehensive analysis in simple settings, we illustrate the efficacy of our approach in increasing exploration and bias towards flatter minima. We empirically demonstrate that it can improve model performance for image classification on ImageNet and CIFAR10/100, language modelling on Penn Treebank, and online learning tasks on TinyImageNet and 5-dataset. Our code is available at https://github.com/chandar-lab/CMOptimizer",
    "checked": true,
    "id": "086a432f844e96167dbd93edd2ad683295461181",
    "semantic_title": "promoting exploration in memory-augmented adam using critical momenta",
    "citation_count": 1,
    "authors": [
      "Pranshu Malviya",
      "Goncalo Mordido",
      "Aristide Baratin",
      "Reza Babanezhad Harikandeh",
      "Jerry Huang",
      "Simon Lacoste-Julien",
      "Razvan Pascanu",
      "Sarath Chandar"
    ]
  },
  "https://openreview.net/forum?id=rOvaUsF996": {
    "title": "Physics Informed Distillation for Diffusion Models",
    "volume": "main",
    "abstract": "Diffusion models have recently emerged as a potent tool in generative modeling. However, their inherent iterative nature often results in sluggish image generation due to the requirement for multiple model evaluations. Recent progress has unveiled the intrinsic link between diffusion models and Probability Flow Ordinary Differential Equations (ODEs), thus enabling us to conceptualize diffusion models as ODE systems. Simultaneously, Physics Informed Neural Networks (PINNs) have substantiated their effectiveness in solving intricate differential equations through implicit modeling of their solutions. Building upon these foundational insights, we introduce Physics Informed Distillation (PID), which employs a student model to represent the solution of the ODE system corresponding to the teacher diffusion model, akin to the principles employed in PINNs. Through experiments on CIFAR 10 and ImageNet 64x64, we observe that PID achieves performance comparable to recent distillation methods. Notably, it demonstrates predictable trends concerning method-specific hyperparameters and eliminates the need for synthetic dataset generation during the distillation process. Both of which contribute to its easy-to-use nature as a distillation approach for Diffusion Models",
    "checked": true,
    "id": "0f267fdb5b59745224f344ed3de75e552e6ea519",
    "semantic_title": "physics informed distillation for diffusion models",
    "citation_count": 6,
    "authors": [
      "Joshua Tian Jin Tee",
      "Kang Zhang",
      "Hee Suk Yoon",
      "Dhananjaya Nagaraja Gowda",
      "Chanwoo Kim",
      "Chang D. Yoo"
    ]
  },
  "https://openreview.net/forum?id=o8r84MzTQB": {
    "title": "Understanding and Improving Transfer Learning of Deep Models via Neural Collapse",
    "volume": "main",
    "abstract": "With the ever-increasing complexity of large-scale pre-trained models coupled with a shortage of labeled data for downstream training, transfer learning has become the primary approach in many fields, including natural language processing, computer vision, and multi-modal learning. Despite recent progress, the fine-tuning process for large-scale pre-trained models in vision still mostly relies on trial and error. This work investigates the relationship between neural collapse (NC) and transfer learning for classification problems. NC is an intriguing while prevalent phenomenon that has been recently discovered in terms of the final-layer features and linear classifiers of trained neural networks. Specifically, during the terminal phase of training, NC implies that the variability of the features within each class diminishes to zero, while the means of features between classes are maximally and equally distanced. In this work, we examine the NC attributes of pre-trained models on both downstream and training data for transfer learning, and we find strong correlation between feature collapse and downstream performance. In particular, we discovered a systematic pattern that emerges when linear probing pre-trained models on downstream training data: the more feature collapse of pre-trained models on downstream data, the higher the transfer accuracy. Additionally, we also studied the relationship between NC and transfer accuracy on the training data. Moreover, these findings allow us to develop a principled, parameter-efficient fine-tuning method that employs skip-connection to induce the last-layer feature collapse on downstream data. Our proposed fine-tuning methods deliver good performances while reducing fine-tuning parameters by at least 90\\% and mitigating overfitting in situations especially when the downstream data is scarce",
    "checked": true,
    "id": "81d3c9d1f6fcdbe2839f49f79aec4a0df28e3731",
    "semantic_title": "understanding and improving transfer learning of deep models via neural collapse",
    "citation_count": 20,
    "authors": [
      "Xiao Li",
      "Sheng Liu",
      "Jinxin Zhou",
      "Xinyu Lu",
      "Carlos Fernandez-Granda",
      "Zhihui Zhu",
      "Qing Qu"
    ]
  },
  "https://openreview.net/forum?id=o5kYH7bNe3": {
    "title": "VisionAD, a software package of performant anomaly detection algorithms, and Proportion Localised, an interpretable metric",
    "volume": "main",
    "abstract": "We release VisionAD, an anomaly detection library in the domain of images. The library forms the largest and most performant collection of such algorithms to date. Each algorithm is written through a standardised API, for ease of use. The library has a focus on fair benchmarking intended to mitigate the issue of cherry-picked results. It enables rapid experimentation and straightforward integration of new algorithms. In addition, we propose a new metric, Proportion Localised (PL). This reports the proportion of anomalies that are sufficiently localised via classifying each discrete anomaly as localised or not. The metric is far more intuitive as it has a real physical relation, meaning it is attractive to industry-based professionals. We also release the VisionADIndustrial (VADI) benchmark, a thorough benchmarking of the top anomaly detection algorithms. This benchmark calculates the mean across the pooled classes of the MVTec and VisA datasets. We are committed to hosting an updated version of this leaderboard online, and encourage researchers to add, tweak and improve algorithms to climb this leaderboard. VisionAD code is found at https://github.com/alext1995/VisionAD, and Proportion Localised code is found at https://github.com/alext1995/proportion_localised",
    "checked": true,
    "id": "b095a72eaab8eaf297d5e1b82fc339dd4caa76e8",
    "semantic_title": "visionad, a software package of performant anomaly detection algorithms, and proportion localised, an interpretable metric",
    "citation_count": 1,
    "authors": [
      "Alexander D. J. Taylor",
      "Phillip Tregidgo",
      "Jonathan James Morrison",
      "Neill D. F. Campbell"
    ]
  },
  "https://openreview.net/forum?id=ufDh55J1ML": {
    "title": "Holistic Molecular Representation Learning via Multi-view Fragmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "afd36dce430d2e1d562af12ba06b6e68dae08526",
    "semantic_title": "holistic molecular representation learning via multi-view fragmentation",
    "citation_count": 1,
    "authors": [
      "Seojin Kim",
      "Jaehyun Nam",
      "Junsu Kim",
      "Hankook Lee",
      "Sungsoo Ahn",
      "Jinwoo Shin"
    ]
  },
  "https://openreview.net/forum?id=BTgHh0gSSc": {
    "title": "Recent Link Classification on Temporal Graphs Using Graph Profiler",
    "volume": "main",
    "abstract": "The performance of Temporal Graph Learning (TGL) methods are typically evaluated on the future link prediction task, i.e., whether two nodes will get connected and dynamic node classification task, i.e., whether a node's class will change. Comparatively, recent link classification, i.e., to what class an emerging edge belongs to, is investigated much less even though it exists in many industrial settings. In this work, we first formalize recent link classification on temporal graphs as a benchmark downstream task and introduce corresponding benchmark datasets. Secondly, we evaluate the performance of state-of-the-art methods with a statistically meaningful metric Matthews Correlation Coefficient, which is more robust to imbalanced datasets, in addition to the commonly used average precision and area under the curve. We propose several design principles for tailoring models to specific requirements of the task and the dataset including modifications on message aggregation schema, readout layer and time encoding strategy which obtain significant improvement on benchmark datasets. Finally, we propose an architecture that we call Graph Profiler, which is capable of encoding previous events' class information on source and destination nodes. The experiments show that our proposed model achieves an improved Matthews Correlation Coefficient on most cases under interest. We believe the introduction of recent link classification as a benchmark task for temporal graph learning will be useful for the evaluation of prospective methods within the field",
    "checked": true,
    "id": "6fc9ab1636e0524fb8a86cc8b1598df1ae1f6dfc",
    "semantic_title": "recent link classification on temporal graphs using graph profiler",
    "citation_count": 2,
    "authors": [
      "Muberra Ozmen",
      "Thomas Markovich"
    ]
  },
  "https://openreview.net/forum?id=pjKcIzvXWR": {
    "title": "Hyperbolic Random Forests",
    "volume": "main",
    "abstract": "Hyperbolic space is becoming a popular choice for representing data due to the hierarchical structure - whether implicit or explicit - of many real-world datasets. Along with it comes a need for algorithms capable of solving fundamental tasks, such as classification, in hyperbolic space. Recently, multiple papers have investigated hyperbolic alternatives to hyperplane-based classifiers, such as logistic regression and SVMs. While effective, these approaches struggle with more complex hierarchical data. We, therefore, propose to generalize the well-known random forests to hyperbolic space. We do this by redefining the notion of a split using horospheres. Since finding the globally optimal split is computationally intractable, we find candidate horospheres through a large-margin classifier. To make hyperbolic random forests work on multi-class data and imbalanced experiments, we furthermore outline new methods for combining classes based on the lowest common ancestor and class-balanced large-margin losses. Experiments on standard and new benchmarks show that our approach outperforms both conventional random forest algorithms and recent hyperbolic classifiers",
    "checked": true,
    "id": "5e294f97e73dce044f4d317d4887d46d4f56bb62",
    "semantic_title": "hyperbolic random forests",
    "citation_count": 8,
    "authors": [
      "Lars Doorenbos",
      "Pablo MÃ¡rquez Neila",
      "Raphael Sznitman",
      "Pascal Mettes"
    ]
  },
  "https://openreview.net/forum?id=R7PReNELww": {
    "title": "Distributionally Robust Policy Evaluation under General Covariate Shift in Contextual Bandits",
    "volume": "main",
    "abstract": "We introduce a distributionally robust approach that enhances the reliability of offline policy evaluation in contextual bandits under general covariate shifts. Our method aims to deliver robust policy evaluation results in the presence of discrepancies in both context and policy distribution between logging and target data. Central to our methodology is the application of robust regression â a distributionally robust technique tailored here to improve the estimation of conditional reward distribution from logging data. Utilizing the reward model obtained from robust regression, we develop a comprehensive suite of policy value estimators, by integrating our reward model into established evaluation frameworks, namely direct methods and doubly robust methods. Through theoretical analysis, we further establish that the proposed policy value estimators offer a finite sample upper bound for the bias, providing a clear advantage over traditional methods, especially when the shift is large. Finally, we designed an extensive range of policy evaluation scenarios, covering diverse magnitudes of shifts and a spectrum of logging and target policies. Our empirical results indicate that our approach significantly outperforms baseline methods, most notably in 90% of the cases under the policy shift-only settings and 72% of the scenarios under the general covariate shift settings",
    "checked": true,
    "id": "193a544c8992e0fd8f4bf3df01cde2fff1c14d36",
    "semantic_title": "distributionally robust policy evaluation under general covariate shift in contextual bandits",
    "citation_count": 2,
    "authors": [
      "Yihong Guo",
      "Hao Liu",
      "Yisong Yue",
      "Anqi Liu"
    ]
  },
  "https://openreview.net/forum?id=tbOYJwXhcY": {
    "title": "Misspecification-robust Sequential Neural Likelihood for Simulation-based Inference",
    "volume": "main",
    "abstract": "Simulation-based inference techniques are indispensable for parameter estimation of mechanistic and simulable models with intractable likelihoods. While traditional statistical approaches like approximate Bayesian computation and Bayesian synthetic likelihood have been studied under well-specified and misspecified settings, they often suffer from inefficiencies due to wasted model simulations. Neural approaches, such as sequential neural likelihood (SNL) avoid this wastage by utilising all model simulations to train a neural surrogate for the likelihood function. However, the performance of SNL under model misspecification is unreliable and can result in overconfident posteriors centred around an inaccurate parameter estimate. In this paper, we propose a novel SNL method, which through the incorporation of additional adjustment parameters, is robust to model misspecification and capable of identifying features of the data that the model is not able to recover. We demonstrate the efficacy of our approach through several illustrative examples, where our method gives more accurate point estimates and uncertainty quantification than SNL",
    "checked": false,
    "id": "528e2ba2551f940a06d09eff1b6c371c015451c3",
    "semantic_title": "misspecification-robust sequential neural likelihood",
    "citation_count": 13,
    "authors": [
      "Ryan P. Kelly",
      "David J Nott",
      "David Tyler Frazier",
      "David J Warne",
      "Christopher Drovandi"
    ]
  },
  "https://openreview.net/forum?id=Nzy0XmCPuZ": {
    "title": "Rotate the ReLU to Sparsify Deep Networks Implicitly",
    "volume": "main",
    "abstract": "Compact and energy-efficient models have become essential in this era when deep learning-based solutions are widely used for various real-life tasks. In this paper, we propose rotating the ReLU activation to give an additional degree of freedom in conjunction with the appropriate initialization of the rotation. This combination leads to implicit sparsification without the use of a regularizer. We show that this rotated ReLU (RReLU) activation improves the representation capability of the parameters/filters in the network and eliminates those parameters/filters that are not crucial for the task, giving rise to significant savings in memory and computation. While the state-of-the-art regularization-based Network-Slimming method achieves $32.33\\%$ saving in memory and $26.38\\%$ saving in computation with ResNet-$164$, RReLU achieves a saving of $35.92\\%$ in memory and $25.97\\%$ in the computation with a better accuracy. The savings in memory and computation further increase by $64.67\\%$ and $52.96\\%$, respectively, with the introduction of $L_1$ regularization to the RReLU slopes. We note that the slopes of the rotated ReLU activations act as coarse feature extractors and can eliminate unnecessary features before retraining. Our studies indicate that features always choose to pass through a lesser number of filters. We demonstrate the results with popular datasets such as MNIST, CIFAR-10, CIFAR-100, SVHN, and Imagenet with different architectures, including Vision Transformers and EfficientNet. We also briefly study the impact of adversarial attacks on RReLU-based ResNets and observe that we get better adversarial accuracy for the architectures with RReLU than ReLU. We also demonstrate how this concept of rotation can be applied to the GELU and SiLU activation functions, commonly utilized in Transformer and EfficientNet architectures, respectively. The proposed method can be utilized by combining with other structural pruning methods resulting in better sparsity. For the GELU-based multi-layer perceptron (MLP) part of the Transformer, we obtain $2.6\\%$ improvement in accuracy with $6.32\\%$ saving in both memory and computation",
    "checked": true,
    "id": "5e6b6762a43ae5a11bf332f7767f7624173b8c9d",
    "semantic_title": "rotate the relu to sparsify deep networks implicitly",
    "citation_count": 0,
    "authors": [
      "Nancy Nayak",
      "Sheetal Kalyani"
    ]
  },
  "https://openreview.net/forum?id=Ft4kHrOawZ": {
    "title": "Bayesian Quantification with Black-Box Estimators",
    "volume": "main",
    "abstract": "Understanding how different classes are distributed in an unlabeled data set is important for the calibration of probabilistic classifiers and uncertainty quantification. Methods like adjusted classify and count, black-box shift estimators, and invariant ratio estimators use an auxiliary and potentially biased black-box classifier trained on a different data set to estimate the class distribution on the current data set and yield asymptotic guarantees under weak assumptions. We demonstrate that these algorithms are closely related to the inference in a particular probabilistic graphical model approximating the assumed ground-truth generative process, and we propose a Bayesian estimator. Then, we discuss an efficient Markov chain Monte Carlo sampling scheme for the introduced model and show an asymptotic consistency guarantee in the large-data limit. We compare the introduced model against the established point estimators in a variety of scenarios, and show it is competitive, and in some cases superior, with the non-Bayesian alternatives",
    "checked": true,
    "id": "4700b813d5abbbc4daac84b5f528ce7a2b230719",
    "semantic_title": "bayesian quantification with black-box estimators",
    "citation_count": 0,
    "authors": [
      "Albert Ziegler",
      "PaweÅ CzyÅ¼"
    ]
  },
  "https://openreview.net/forum?id=IKH5ziX9dk": {
    "title": "Simple Imputation Rules for Prediction with Missing Data: Theoretical Guarantees vs. Empirical Performance",
    "volume": "main",
    "abstract": "Missing data is a common issue in real-world datasets. This paper studies the performance of impute-then-regress pipelines by contrasting theoretical and empirical evidence. We establish the asymptotic consistency of such pipelines for a broad family of imputation methods. While common sense suggests that a 'good' imputation method produces datasets that are plausible, we show, on the contrary, that, as far as prediction is concerned, crude can be good. Among others, we find that mode-impute is asymptotically sub-optimal, while mean-impute is asymptotically optimal. We then exhaustively assess the validity of these theoretical conclusions on a large corpus of synthetic, semi-real, and real datasets. While the empirical evidence we collect mostly supports our theoretical findings, it also highlights gaps between theory and practice and opportunities for future research, regarding the relevance of the MAR assumption, the complex interdependency between the imputation and regression tasks, and the need for realistic synthetic data generation models",
    "checked": true,
    "id": "a8c682100b006ac575a834197978bb3cb91d6892",
    "semantic_title": "simple imputation rules for prediction with missing data: theoretical guarantees vs. empirical performance",
    "citation_count": 4,
    "authors": [
      "Dimitris Bertsimas",
      "Arthur Delarue",
      "Jean Pauphilet"
    ]
  },
  "https://openreview.net/forum?id=Z20FInfWlm": {
    "title": "DIGNet: Learning Decomposed Patterns in Representation Balancing for Treatment Effect Estimation",
    "volume": "main",
    "abstract": "Estimating treatment effects from observational data is often subject to a covariate shift problem incurred by selection bias. Recent research has sought to mitigate this problem by leveraging representation balancing methods that aim to extract balancing patterns from observational data and utilize them for outcome prediction. The underlying theoretical rationale is that minimizing the unobserved counterfactual error can be achieved through two principles: (I) reducing the risk associated with predicting factual outcomes and (II) mitigating the distributional discrepancy between the treated and controlled samples. However, an inherent trade-off between the two principles can lead to a potential loss of information useful for factual outcome predictions and, consequently, deteriorating treatment effect estimations. In this paper, we propose a novel representation balancing model, DIGNet, for treatment effect estimation. DIGNet incorporates two key components, PDIG and PPBR, which effectively mitigate the trade-off problem by improving one aforementioned principle without sacrificing the other. Specifically, PDIG captures more effective balancing patterns (Principle II) without affecting factual outcome predictions (Principle I), while PPBR enhances factual outcome prediction (Principle I) without affecting the learning of balancing patterns (Principle II). The ablation studies verify the effectiveness of PDIG and PPBR in improving treatment effect estimation, and experimental results on benchmark datasets demonstrate the superior performance of our DIGNet model compared to baseline models",
    "checked": true,
    "id": "f60bd7040a99842e90b0d728aa050246b505b32e",
    "semantic_title": "dignet: learning decomposed patterns in representation balancing for treatment effect estimation",
    "citation_count": 2,
    "authors": [
      "Yiyan HUANG",
      "WANG Siyi",
      "Cheuk Hang LEUNG",
      "Qi WU",
      "Dongdong WANG",
      "Zhixiang Huang"
    ]
  },
  "https://openreview.net/forum?id=10WARaIwFn": {
    "title": "Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape",
    "volume": "main",
    "abstract": "We study the loss landscape of both shallow and deep, mildly overparameterized ReLU neural networks on a generic finite input dataset for the squared error loss. We show both by count and volume that most activation patterns correspond to parameter regions with no bad local minima. Furthermore, for one-dimensional input data, we show most activation regions realizable by the network contain a high dimensional set of global minima and no bad local minima. We experimentally confirm these results by finding a phase transition from most regions having full rank Jacobian to many regions having deficient rank depending on the amount of overparameterization",
    "checked": true,
    "id": "69153beef2c5dfc9a8fa77b3e45d9235ae38231e",
    "semantic_title": "mildly overparameterized relu networks have a favorable loss landscape",
    "citation_count": 8,
    "authors": [
      "Kedar Karhadkar",
      "Michael Murray",
      "Hanna Tseran",
      "Guido Montufar"
    ]
  },
  "https://openreview.net/forum?id=z8d7nT1HWw": {
    "title": "Augmenting Ad-Hoc IR Dataset for Interactive Conversational Search",
    "volume": "main",
    "abstract": "A peculiarity of conversational search systems is that they involve mixed-initiatives such as system-generated query clarifying questions. Evaluating those systems at a large scale on the end task of IR is very challenging, requiring adequate datasets containing such interactions. However, current datasets only focus on either traditional ad-hoc IR tasks or query clarification tasks, the latter being usually seen as a reformulation task from the initial query. Only few datasets are known to contain both document relevance judgments and the associated clarification interactions such as Qulac and ClariQ. Both are based on the TREC Web Track 2009-12 collection but cover a very limited number of topics (237 topics), far from being enough for training and testing conversational IR models. To fill the gap, we propose a methodology to automatically build large-scale conversational IR datasets from ad-hoc IR datasets in order to facilitate explorations on conversational IR. Our methodology is based on two processes: 1) generating query clarification interactions through query clarification and answer generators, and 2) augmenting ad-hoc IR datasets with simulated interactions. In this paper, we focus on MsMarco and augment it with query clarification and answer simulations. We perform a thorough evaluation showing the quality and the relevance of the generated interactions for each initial query. This paper shows the feasibility and utility of augmenting ad-hoc IR datasets for conversational IR",
    "checked": true,
    "id": "c0521234f80762ab4377d116f74e04622454ae13",
    "semantic_title": "augmenting ad-hoc ir dataset for interactive conversational search",
    "citation_count": 0,
    "authors": [
      "Pierre ERBACHER",
      "Jian-Yun Nie",
      "Philippe Preux",
      "Laure Soulier"
    ]
  },
  "https://openreview.net/forum?id=spo705Fyv0": {
    "title": "Text Descriptions are Compressive and Invariant Representations for Visual Learning",
    "volume": "main",
    "abstract": "Modern image classification is based on directly predicting classes via large discriminative networks, which do not directly contain information about the intuitive visual features that may constitute a classification decision. Recently, work in vision-language models (VLM) such as CLIP has provided ways to specify natural language descriptions of image classes, but typically focuses on providing single descriptions for each class. In this work, we demonstrate that an alternative approach, in line with humans' understanding of multiple visual features per class, can also provide compelling performance in the robust few-shot learning setting. In particular, we introduce a novel method, \\textit{SLR-AVD (Sparse Logistic Regression using Augmented Visual Descriptors)}. This method first automatically generates multiple visual descriptions of each class via a large language model (LLM), then uses a VLM to translate these descriptions to a set of visual feature embeddings of each image, and finally uses sparse logistic regression to select a relevant subset of these features to classify each image. Core to our approach is the fact that, information-theoretically, these descriptive features are more invariant to domain shift than traditional image embeddings, even though the VLM training process is not explicitly designed for invariant representation learning. These invariant descriptive features also compose a better input compression scheme. When combined with finetuning, we show that SLR-AVD is able to outperform existing state-of-the-art finetuning approaches in both in-distribution and out-of-distribution tasks",
    "checked": true,
    "id": "a964f5b3b56baa43dee1ec24bc2682b1236f302d",
    "semantic_title": "text descriptions are compressive and invariant representations for visual learning",
    "citation_count": 6,
    "authors": [
      "Zhili Feng",
      "Anna Bair",
      "J Zico Kolter"
    ]
  },
  "https://openreview.net/forum?id=i5yKW1pmjW": {
    "title": "Semi-Supervised Semantic Segmentation via Marginal Contextual Information",
    "volume": "main",
    "abstract": "We present a novel confidence refinement scheme that enhances pseudo-labels in semi-supervised semantic segmentation. Unlike existing methods, which filter pixels with low-confidence predictions in isolation, our approach leverages the spatial correlation of labels in segmentation maps by grouping neighboring pixels and considering their pseudo-labels collectively. With this contextual information, our method, named S4MC, increases the amount of unlabeled data used during training while maintaining the quality of the pseudo-labels, all with negligible computational overhead. Through extensive experiments on standard benchmarks, we demonstrate that S4MC outperforms existing state-of-the-art semi-supervised learning approaches, offering a promising solution for reducing the cost of acquiring dense annotations. For example, S4MC achieves a 1.39 mIoU improvement over the prior art on PASCAL VOC 12 with 366 annotated images. The code to reproduce our experiments is available at https://s4mcontext.github.io/",
    "checked": true,
    "id": "8c134bb229f6347fb7235d19bd98dad1e5869ea0",
    "semantic_title": "semi-supervised semantic segmentation via marginal contextual information",
    "citation_count": 10,
    "authors": [
      "Moshe Kimhi",
      "Shai Kimhi",
      "Evgenii Zheltonozhskii",
      "Or Litany",
      "Chaim Baskin"
    ]
  },
  "https://openreview.net/forum?id=y1pPWFVfvR": {
    "title": "Multimodal Chain-of-Thought Reasoning in Language Models",
    "volume": "main",
    "abstract": "Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer. However, existing CoT studies have primarily focused on the language modality. We propose Multimodal-CoT that incorporates language (text) and vision (images) modalities into a two-stage framework that separates rationale generation and answer inference. In this way, answer inference can leverage better generated rationales that are based on multimodal information. Experimental results on ScienceQA and A-OKVQA benchmark datasets show the effectiveness of our proposed approach. With Multimodal-CoT, our model under 1 billion parameters achieves state-of-the-art performance on the ScienceQA benchmark. Our analysis indicates that Multimodal-CoT offers the advantages of mitigating hallucination and enhancing convergence speed. Code is publicly available at https://github.com/amazon-science/mm-cot",
    "checked": true,
    "id": "780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050",
    "semantic_title": "multimodal chain-of-thought reasoning in language models",
    "citation_count": 467,
    "authors": [
      "Zhuosheng Zhang",
      "Aston Zhang",
      "Mu Li",
      "hai zhao",
      "George Karypis",
      "Alex Smola"
    ]
  },
  "https://openreview.net/forum?id=9fcZNAmnyh": {
    "title": "Contrastive Graph Autoencoder for Shape-based Polygon Retrieval from Large Geometry Datasets",
    "volume": "main",
    "abstract": "Retrieval of polygon geometries with similar shapes from maps is a challenging geographic information task. Existing approaches can not process geometry polygons with complex shapes, (multiple) holes and are sensitive to geometric transformations (e.g., rotations). We propose Contrastive Graph Autoencoder (CGAE), a robust and effective graph representation autoencoder for extracting polygon geometries of similar shapes from real-world building maps based on template queries. By leveraging graph message-passing layers, graph feature augmentation and contrastive learning, the proposed CGAE embeds highly discriminative latent embeddings by reconstructing graph features w.r.t. the graph representations of input polygons, outperforming existing graph-based autoencoders (GAEs) in geometry retrieval of similar polygons. Experimentally, we demonstrate this capability based on template query shapes on real-world datasets and show its high robustness to geometric transformations in contrast to existing GAEs, indicating the strong generalizability and versatility of CGAE, including on complex real-world building footprints",
    "checked": true,
    "id": "75b5906a42bf4c2af97ae7ca07a32344d63e13fb",
    "semantic_title": "contrastive graph autoencoder for shape-based polygon retrieval from large geometry datasets",
    "citation_count": 2,
    "authors": [
      "Zexian Huang",
      "Kourosh Khoshelham",
      "Martin Tomko"
    ]
  },
  "https://openreview.net/forum?id=HU5DOUp6Sa": {
    "title": "Prototypical Self-Explainable Models Without Re-training",
    "volume": "main",
    "abstract": "Explainable AI (XAI) has unfolded in two distinct research directions with, on the one hand, post-hoc methods that explain the predictions of a pre-trained black-box model and, on the other hand, self-explainable models (SEMs) which are trained directly to provide explanations alongside their predictions. While the latter is preferred in safety-critical scenarios, post-hoc approaches have received the majority of attention until now, owing to their simplicity and ability to explain base models without retraining. Current SEMs, instead, require complex architectures and heavily regularized loss functions, thus necessitating specific and costly training. To address this shortcoming and facilitate wider use of SEMs, we propose a simple yet efficient universal method called KMEx (K-Means Explainer), which can convert any existing pre-trained model into a prototypical SEM. The motivation behind KMEx is to enhance transparency in deep learning-based decision-making via class-prototype-based explanations that are diverse and trustworthy without retraining the base model. We compare models obtained from KMEx to state-of-the-art SEMs using an extensive qualitative evaluation to highlight the strengths and weaknesses of each model, further paving the way toward a more reliable and objective evaluation of SEMs\\footnote{The code is available at https://github.com/SrishtiGautam/KMEx}",
    "checked": true,
    "id": "0dff454dc9e0ace62aaa292f3a6cc1e89e64b4e1",
    "semantic_title": "prototypical self-explainable models without re-training",
    "citation_count": 2,
    "authors": [
      "Srishti Gautam",
      "Ahcene Boubekki",
      "Marina MC HÃ¶hne",
      "Michael Kampffmeyer"
    ]
  },
  "https://openreview.net/forum?id=QPuxjsjKCP": {
    "title": "Conservative Prediction via Data-Driven Confidence Minimization",
    "volume": "main",
    "abstract": "In safety-critical applications of machine learning, it is often desirable for a model to be \\textit{conservative}, abstaining from making predictions on ``unknown'' inputs which are not well-represented in the training data. However, detecting unknown examples is challenging, as it is impossible to anticipate all potential inputs at test time. To address this, prior work minimizes model confidence on an auxiliary outlier dataset carefully curated to be disjoint from the training distribution. We theoretically analyze the choice of auxiliary dataset for confidence minimization, revealing two actionable insights: (1) if the auxiliary set contains unknown examples similar to those seen at test time, confidence minimization leads to provable detection of unknown test examples, and (2) if the first condition is satisfied, it is unnecessary to filter out known examples for out-of-distribution (OOD) detection. Motivated by these guidelines, we propose the Data-Driven Confidence Minimization (DCM) framework, which minimizes confidence on an \\textit{uncertainty dataset}. We apply DCM to two problem settings in which conservative prediction is paramount -- selective classification and OOD detection -- and provide a realistic way to gather uncertainty data for each setting. In our experiments, DCM consistently outperforms existing selective classification approaches on 4 datasets when tested on unseen distributions and outperforms state-of-the-art OOD detection methods on 12 ID-OOD dataset pairs, reducing FPR (at TPR $95\\%$) by $6.3\\%$ and $58.1\\%$ on CIFAR-10 and CIFAR-100 compared to Outlier Exposure",
    "checked": true,
    "id": "2a11cfe18a6f39de9e00a24f0c7040d2b7ec7d64",
    "semantic_title": "conservative prediction via data-driven confidence minimization",
    "citation_count": 5,
    "authors": [
      "Caroline Choi",
      "Fahim Tajwar",
      "Yoonho Lee",
      "Huaxiu Yao",
      "Ananya Kumar",
      "Chelsea Finn"
    ]
  },
  "https://openreview.net/forum?id=xYkdmEGhIM": {
    "title": "Physical Reasoning and Object Planning for Household Embodied Agents",
    "volume": "main",
    "abstract": "In this study, we explore the sophisticated domain of task planning for robust household embodied agents, with a particular emphasis on the intricate task of selecting substitute objects. We introduce the \\textbf{C}ommonSense \\textbf{O}bject \\textbf{A}ffordance \\textbf{T}ask \\textbf{(COAT)}, a novel framework designed to analyze reasoning capabilities in commonsense scenarios. This approach is centered on understanding how these agents can effectively identify and utilize alternative objects when executing household tasks, thereby offering insights into the complexities of practical decision-making in real-world environments. Drawing inspiration from factors affecting human decision-making, we explore how large language models tackle this challenge through four meticulously crafted commonsense question-and-answer datasets featuring refined rules and human annotations. Our evaluation of state-of-the-art language models on these datasets sheds light on three pivotal considerations: 1) aligning an object's inherent utility with the task at hand, 2) navigating contextual dependencies (societal norms, safety, appropriateness, and efficiency), and 3) accounting for the current physical state of the object. To maintain accessibility, we introduce five abstract variables reflecting an object's physical condition, modulated by human insights, to simulate diverse household scenarios. Our contributions include insightful human preference mappings for all three factors and four extensive QA datasets (2K, 15k, 60k, 70K questions) probing the intricacies of utility dependencies, contextual dependencies and object physical states. The datasets, along with our findings, are accessible at: \\url{https://github.com/com-phy-affordance/COAT}. This research not only advances our understanding of physical commonsense reasoning in language models but also paves the way for future improvements in household agent intelligence",
    "checked": true,
    "id": "c4b7f1ceef3f91619e80a040dbc5a9fdbd32ab22",
    "semantic_title": "physical reasoning and object planning for household embodied agents",
    "citation_count": 2,
    "authors": [
      "Ayush Agrawal",
      "Raghav Prabhakar",
      "Anirudh Goyal",
      "Dianbo Liu"
    ]
  },
  "https://openreview.net/forum?id=FpaCL1MO2C": {
    "title": "Robust Distortion-free Watermarks for Language Models",
    "volume": "main",
    "abstract": "We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbersâwhich we compute using a randomized watermark keyâto a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language modelsâOPT-1.3B, LLaMA-7B and Alpaca-7Bâto experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \\leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\\% of the tokens via random edits (i.e., substitutions, insertions or deletions). For the Alpaca-7B model, we conduct a case study on the feasibility of watermarking responses to typical user instructions. Due to the lower entropy of the responses, detection is more difficult: around $25\\%$ of the responsesâwhose median length is around $100$ tokensâare detectable with $p \\leq 0.01$, and the watermark is also less robust to certain automated paraphrasing attacks we implement",
    "checked": true,
    "id": "ccaff61e0c1e629d91d78f82a64b3cbc8f3f7023",
    "semantic_title": "robust distortion-free watermarks for language models",
    "citation_count": 184,
    "authors": [
      "Rohith Kuditipudi",
      "John Thickstun",
      "Tatsunori Hashimoto",
      "Percy Liang"
    ]
  },
  "https://openreview.net/forum?id=uSLNzzuiDJ": {
    "title": "Enhancing Low-Precision Sampling via Stochastic Gradient Hamiltonian Monte Carlo",
    "volume": "main",
    "abstract": "Low-precision training has emerged as a promising low-cost technique to enhance the training efficiency of deep neural networks without sacrificing much accuracy. Its Bayesian counterpart can further provide uncertainty quantification and improved generalization accuracy. This paper investigates low-precision sampling via Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) with low-precision and full-precision gradient accumulators for both strongly log-concave and non-log-concave distributions. Theoretically, our results show that to achieve $\\epsilon$-error in the 2-Wasserstein distance for non-log-concave distributions, low-precision SGHMC achieves quadratic improvement ($\\tilde{\\mathcal{O}}\\left({\\epsilon^{-2}{\\mu^*}^{-2}\\log^2\\left({\\epsilon^{-1}}\\right)}\\right)$) compared to the state-of-the-art low-precision sampler, Stochastic Gradient Langevin Dynamics (SGLD) ($\\tilde{\\mathcal{O}}\\left({{\\epsilon}^{-4}{\\lambda^{*}}^{-1}\\log^5\\left({\\epsilon^{-1}}\\right)}\\right)$). Moreover, we prove that low-precision SGHMC is more robust to the quantization error compared to low-precision SGLD due to the robustness of the momentum-based update w.r.t. gradient noise. Empirically, we conduct experiments on synthetic data, and MNIST, CIFAR-10 \\& CIFAR-100 datasets, which validate our theoretical findings. Our study highlights the potential of low-precision SGHMC as an efficient and accurate sampling method for large-scale and resource-limited machine learning",
    "checked": true,
    "id": "79593569c1dcf3a7c4eda809e7fc9ee2eea68e86",
    "semantic_title": "enhancing low-precision sampling via stochastic gradient hamiltonian monte carlo",
    "citation_count": 0,
    "authors": [
      "Ziyi Wang",
      "Yujie Chen",
      "Qifan Song",
      "Ruqi Zhang"
    ]
  },
  "https://openreview.net/forum?id=1iDpP3GWmS": {
    "title": "Online Tensor Max-Norm Regularization via Stochastic Optimization",
    "volume": "main",
    "abstract": "The advent of ubiquitous multidimensional arrays poses unique challenges for low-rank modeling of tensor data due to higher-order relationships, gross noise, and large dimensions of the tensor. In this paper, we consider online low-rank estimation of tensor data where the multidimensional data are revealed sequentially. Induced by the recently proposed tensor-tensor product (t-product), we rigorously deduce the tensor max-norm and formulate the tensor max-norm into an equivalent tensor factorization form, where the factors consist of a tensor basis component and a coefficient one. With this formulation, we develop an online max-norm regularized tensor decomposition (OMRTD) method by alternatively optimizing over the basis component and the coefficient tensor. The algorithm is scalable to the large-scale setting and the sequence of the solutions produced by OMRTD converges to a stationary point of the expected loss function asymptotically. Further, we extend OMRTD for tensor completion. Numerical experiments demonstrate encouraging results for the effectiveness and robustness of our algorithm. The code is available at https://github.com/twugithub/2024-TMLR-OMRTD",
    "checked": true,
    "id": "39ab360954f5e31f7528cb0654230506bfb66456",
    "semantic_title": "online tensor max-norm regularization via stochastic optimization",
    "citation_count": 0,
    "authors": [
      "Tong Wu"
    ]
  },
  "https://openreview.net/forum?id=T6RygOFZ6B": {
    "title": "A Study of the Effects of Transfer Learning on Adversarial Robustness",
    "volume": "main",
    "abstract": "The security and robustness of AI systems are paramount in real-world applications. Previous research has focused on developing methods to train robust networks, assuming the availability of sufficient labeled training data. However, in deployment scenarios with limited training data, existing techniques for training robust networks become impractical. In such low-data scenarios, non-robust training methods often resort to transfer learning. This involves pre-training a network on a large, possibly labeled dataset and fine-tuning it for a new task with a limited set of training samples. The efficacy of transfer learning in enhancing adversarial robustness is not comprehensively explored. Specifically, it remains uncertain whether transfer learning can improve adversarial performance in low-data scenarios. Furthermore, the potential benefits of transfer learning for certified robustness are unexplored. In this paper, we conduct an extensive analysis of the impact of transfer learning on both empirical and certified adversarial robustness. Employing supervised and self-supervised pre-training methods and fine-tuning across 12 downstream tasks representing diverse data availability scenarios, we identify the conditions conducive to training adversarially robust models through transfer learning. Our study reveals that the effectiveness of transfer learning in improving adversarial robustness is attributed to an increase in standard accuracy and not the direct ``transfer'' of robustness from the source to the target task, contrary to previous beliefs. Our findings provide valuable insights for practitioners aiming to deploy robust ML models in their applications",
    "checked": true,
    "id": "b1068c4dca8e5affa5beaf58e65690b71065ca4d",
    "semantic_title": "a study of the effects of transfer learning on adversarial robustness",
    "citation_count": 1,
    "authors": [
      "Pratik Vaishnavi",
      "Kevin Eykholt",
      "Amir Rahmati"
    ]
  },
  "https://openreview.net/forum?id=O3wmRh2SfT": {
    "title": "End-to-End Training Induces Information Bottleneck through Layer-Role Differentiation: A Comparative Analysis with Layer-wise Training",
    "volume": "main",
    "abstract": "End-to-end (E2E) training, optimizing the entire model through error backpropagation, fundamentally supports the advancements of deep learning. Despite its high performance, E2E training faces the problems of memory consumption, parallel computing, and discrepancy with the functionalities of the actual brain. Various alternative methods have been proposed to overcome these difficulties; however, no one can yet match the performance of E2E training, thereby falling short in practicality. Furthermore, there is no deep understanding regarding differences in the trained model properties beyond the performance gap. In this paper, we reconsider why E2E training demonstrates a superior performance through a comparison with layer-wise training, which shares fundamental learning principles and architectures with E2E training, with the granularity of loss evaluation being the only difference. On the basis of the observation that E2E training has an advantage in propagating input information, we analyze the information plane dynamics of intermediate representations based on the Hilbert-Schmidt independence criterion (HSIC). The results of our normalized HSIC value analysis reveal the E2E training ability to exhibit different information dynamics across layers, in addition to efficient information propagation. Furthermore, we show that this layer-role differentiation leads to the final representation following the information bottleneck principle. Our work not only provides the advantages of E2E training in terms of information propagation and the information bottleneck but also suggests the need to consider the cooperative interactions between layers, not just the final layer when analyzing the information bottleneck of deep learning",
    "checked": true,
    "id": "741ccab02a765e0d65d35516e3bea173768dd3c4",
    "semantic_title": "end-to-end training induces information bottleneck through layer-role differentiation: a comparative analysis with layer-wise training",
    "citation_count": 4,
    "authors": [
      "Keitaro Sakamoto",
      "Issei Sato"
    ]
  },
  "https://openreview.net/forum?id=Nm0WX86sKv": {
    "title": "Where Did the Gap Go? Reassessing the Long-Range Graph Benchmark",
    "volume": "main",
    "abstract": "The recent Long-Range Graph Benchmark (LRGB, Dwivedi et al. 2022) introduced a set of graph learning tasks strongly dependent on long-range interaction between vertices. Empirical evidence suggests that on these tasks Graph Transformers significantly outperform Message Passing GNNs (MPGNNs). In this paper, we carefully reevaluate multiple MPGNN baselines as well as the Graph Transformer GPS (RampÃ¡Å¡ek et al. 2022) on LRGB. Through a rigorous empirical analysis, we demonstrate that the reported performance gap is overestimated due to suboptimal hyperparameter choices. It is noteworthy that across multiple datasets the performance gap completely vanishes after basic hyperparameter optimization. In addition, we discuss the impact of lacking feature normalization for LRGB's vision datasets and highlight a spurious implementation of LRGB's link prediction metric. The principal aim of our paper is to establish a higher standard of empirical rigor within the graph machine learning community",
    "checked": true,
    "id": "3a554649bd52321bf5bc7b1641604145dd33526e",
    "semantic_title": "where did the gap go? reassessing the long-range graph benchmark",
    "citation_count": 54,
    "authors": [
      "Jan TÃ¶nshoff",
      "Martin Ritzert",
      "Eran Rosenbluth",
      "Martin Grohe"
    ]
  },
  "https://openreview.net/forum?id=vtiDUgGjyx": {
    "title": "What Does Softmax Probability Tell Us about Classifiers Ranking Across Diverse Test Conditions?",
    "volume": "main",
    "abstract": "This work aims to develop a measure that can accurately rank the performance of various classifiers when they are tested on unlabeled data from out-of-distribution (OOD) distributions. We commence by demonstrating that conventional uncertainty metrics, notably the maximum Softmax prediction probability, possess inherent utility in forecasting model generalization across certain OOD contexts. Building on this insight, we introduce a new measure called Softmax Correlation (SoftmaxCorr). It calculates the cosine similarity between a class-class correlation matrix, constructed from Softmax output vectors across an unlabeled test dataset, and a predefined reference matrix that embodies ideal class correlations. A high resemblance of predictions to the reference matrix signals that the model delivers confident and uniform predictions across all categories, reflecting minimal uncertainty and confusion. Through rigorous evaluation across a suite of datasets, including ImageNet, CIFAR-10, and WILDS, we affirm the predictive validity of SoftmaxCorr in accurately forecasting model performance within both in-distribution (ID) and OOD settings. Furthermore, we discuss the limitations of our proposed measure and suggest avenues for future research",
    "checked": true,
    "id": "95662a93dd80d8d7450196dd5d5f7a7c79aefb2e",
    "semantic_title": "what does softmax probability tell us about classifiers ranking across diverse test conditions?",
    "citation_count": 1,
    "authors": [
      "Weijie Tu",
      "Weijian Deng",
      "Liang Zheng",
      "Tom Gedeon"
    ]
  },
  "https://openreview.net/forum?id=MyQKcQAte6": {
    "title": "Online Continual Learning via Logit Adjusted Softmax",
    "volume": "main",
    "abstract": "Online continual learning is a challenging problem where models must learn from a non-stationary data stream while avoiding catastrophic forgetting. Inter-class imbalance during training has been identified as a major cause of forgetting, leading to model prediction bias towards recently learned classes. In this paper, we theoretically analyze that inter-class imbalance is entirely attributed to imbalanced class-priors, and the function learned from intra-class intrinsic distributions is the optimal classifier that minimizes the class-balanced error. To that end, we present that a simple adjustment of model logits during training can effectively resist prior class bias and pursue the corresponding optimum. Our proposed method, Logit Adjusted Softmax, can mitigate the impact of inter-class imbalance not only in class-incremental but also in realistic scenarios that sum up class and domain incremental learning, with little additional computational cost. We evaluate our approach on various benchmarks and demonstrate significant performance improvements compared to prior arts. For example, our approach improves the best baseline by 4.6% on CIFAR10",
    "checked": true,
    "id": "eee805f2504459a8e580290eb641b4c4d5adc75f",
    "semantic_title": "online continual learning via logit adjusted softmax",
    "citation_count": 3,
    "authors": [
      "Zhehao Huang",
      "Tao Li",
      "Chenhe Yuan",
      "Yingwen Wu",
      "Xiaolin Huang"
    ]
  },
  "https://openreview.net/forum?id=68LsWm2GuD": {
    "title": "Single Image Test-Time Adaptation for Segmentation",
    "volume": "main",
    "abstract": "Test-Time Adaptation methods improve domain shift robustness of deep neural networks. We explore the adaptation of segmentation models to a single unlabelled image with no other data available at test time. This allows individual sample performance analysis while excluding orthogonal factors such as weight restart strategies. We propose two new segmentation \\ac{tta} methods and compare them to established baselines and recent state-of-the-art. The methods are first validated on synthetic domain shifts and then tested on real-world datasets. The analysis highlights that simple modifications such as the choice of the loss function can greatly improve the performance of standard baselines and that different methods and hyper-parameters are optimal for different kinds of domain shift, hindering the development of fully general methods applicable in situations where no prior knowledge about the domain shift is assumed",
    "checked": true,
    "id": "d422b7b4ec623cb2251e34e4f58dd680a523bc1b",
    "semantic_title": "single image test-time adaptation for segmentation",
    "citation_count": 3,
    "authors": [
      "Klara Janouskova",
      "Tamir Shor",
      "Chaim Baskin",
      "Jiri Matas"
    ]
  },
  "https://openreview.net/forum?id=ntWCJrlDD8": {
    "title": "Uncovering Sets of Maximum Dissimilarity on Random Process Data",
    "volume": "main",
    "abstract": "The comparison of local characteristics of two random processes can shed light on periods of time or space at which the processes differ the most. This paper proposes a method that learns about regions with a certain volume, where the marginal attributes of two processes are less similar. The proposed methods are devised in full generality for the setting where the data of interest are themselves stochastic processes, and thus the proposed method can be used for pointing out the regions of maximum dissimilarity with a certain volume, in the contexts of point processes, functional data, and time series. The parameter functions underlying both stochastic processes of interest are modeled via a basis representation, and Bayesian inference is conducted via an integrated nested Laplace approximation. The numerical studies validate the proposed methods, and we showcase their application with case studies on criminology, finance, and medicine",
    "checked": true,
    "id": "d1a6ad5708259311a474d9e90cf05ce3a7b0119d",
    "semantic_title": "uncovering sets of maximum dissimilarity on random process data",
    "citation_count": 0,
    "authors": [
      "Miguel de Carvalho",
      "Gabriel Martos"
    ]
  },
  "https://openreview.net/forum?id=9XRZtZRmEB": {
    "title": "Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters",
    "volume": "main",
    "abstract": "After the recent ground-breaking advances in protein structure prediction, one of the remaining challenges in protein machine learning is to reliably predict distributions of structural states. Parametric models of fluctuations are difficult to fit due to complex covariance structures between degrees of freedom in the protein chain, often causing models to either violate local or global structural constraints. In this paper, we present a new strategy for modelling protein densities in internal coordinates, which uses constraints in 3D space to induce covariance structure between the internal degrees of freedom. We illustrate the potential of the procedure by constructing a variational autoencoder with full covariance output induced by the constraints implied by the conditional mean in 3D, and demonstrate that our approach makes it possible to scale density models of internal coordinates to full protein backbones in two settings: 1) a unimodal setting for proteins exhibiting small fluctuations and limited amounts of available data, and 2) a multimodal setting for larger conformational changes in a high data regime",
    "checked": true,
    "id": "b3bb2fe4436ea001b40c531a978113550e3f3879",
    "semantic_title": "internal-coordinate density modelling of protein structure: covariance matters",
    "citation_count": 1,
    "authors": [
      "Marloes Arts",
      "Jes Frellsen",
      "Wouter Boomsma"
    ]
  },
  "https://openreview.net/forum?id=jjmdiMiag7": {
    "title": "CLIP-QDA: An Explainable Concept Bottleneck Model",
    "volume": "main",
    "abstract": "In this paper, we introduce an explainable algorithm designed from a multi-modal foundation model, that performs fast and explainable image classification. Drawing inspiration from CLIP-based Concept Bottleneck Models (CBMs), our method creates a latent space where each neuron is linked to a specific word. Observing that this latent space can be modeled with simple distributions, we use a Mixture of Gaussians (MoG) formalism to enhance the interpretability of this latent space. Then, we introduce CLIP-QDA, a classifier that only uses statistical values to infer labels from the concepts. In addition, this formalism allows for both local and global explanations. These explanations come from the inner design of our architecture, our work is part of a new family of greybox models, combining performances of opaque foundation models and the interpretability of transparent models. Our empirical findings show that in instances where the MoG assumption holds, CLIP-QDA achieves similar accuracy with state-of-the-art methods CBMs. Our explanations compete with existing XAI methods while being faster to compute",
    "checked": true,
    "id": "a9b2be585a73e4abccc467f4e8ffabd8c213dbbd",
    "semantic_title": "clip-qda: an explainable concept bottleneck model",
    "citation_count": 7,
    "authors": [
      "RÃ©mi Kazmierczak",
      "EloÃ¯se Berthier",
      "Goran Frehse",
      "Gianni Franchi"
    ]
  },
  "https://openreview.net/forum?id=jv1aPQINc4": {
    "title": "Independence Testing for Temporal Data",
    "volume": "main",
    "abstract": "Temporal data are increasingly prevalent in modern data science. A fundamental question is whether two time series are related or not. Existing approaches often have limitations, such as relying on parametric assumptions, detecting only linear associations, and requiring multiple tests and corrections. While many non-parametric and universally consistent dependence measures have recently been proposed, directly applying them to temporal data can inflate the p-value and result in an invalid test. To address these challenges, this paper introduces the temporal dependence statistic with block permutation to test independence between temporal data. Under proper assumptions, the proposed procedure is asymptotically valid and universally consistent for testing independence between stationary time series, and capable of estimating the optimal dependence lag that maximizes the dependence. Moreover, it is compatible with a rich family of distance and kernel based dependence measures, eliminates the need for multiple testing, and exhibits excellent testing power in various simulation settings",
    "checked": false,
    "id": "dfdde1bef075377594eb46d6b66856d1f411cfb3",
    "semantic_title": "more powerful hsic-based independence tests, extension to space-filling designs and functional data",
    "citation_count": 8,
    "authors": [
      "Cencheng Shen",
      "Jaewon Chung",
      "Ronak Mehta",
      "Ting Xu",
      "Joshua T Vogelstein"
    ]
  },
  "https://openreview.net/forum?id=IX5GX8SNtM": {
    "title": "Unleashing the Power of Visual Prompting At the Pixel Level",
    "volume": "main",
    "abstract": "This paper presents a simple and effective visual prompting method for adapting pre-trained models to downstream recognition tasks. Our approach is underpinned by two key designs. First, rather than directly adding together the prompt and the image, we treat the prompt as an extra and independent learnable entity. We show that the strategy of reconciling the prompt and the image matters, and find that warping the prompt around a properly shrinked image empirically works the best. Second, we re-introduce two \"old tricks\" commonly used in building transferable adversarial examples, i.e., input diversity and gradient normalization, into the realm of visual prompting. These techniques improve optimization and enable the prompt to generalize better. We provide extensive experimental results to demonstrate the effectiveness of our method. Using a CLIP model, our prompting method registers a new record of 82.5% average accuracy across 12 popular classification datasets, substantially surpassing the prior art by +5.2%. It is worth noting that such performance not only surpasses linear probing by +2.2%, but, in certain datasets, is on par with the results from fully fine-tuning. Additionally, our prompting method shows competitive performance across different data scales and against distribution shifts",
    "checked": true,
    "id": "7786825fd653b398c3975c3ff876459307d871f4",
    "semantic_title": "unleashing the power of visual prompting at the pixel level",
    "citation_count": 32,
    "authors": [
      "Junyang Wu",
      "Xianhang Li",
      "Chen Wei",
      "Huiyu Wang",
      "Alan Yuille",
      "Yuyin Zhou",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=xl1KhKT3Xx": {
    "title": "RedMotion: Motion Prediction via Redundancy Reduction",
    "volume": "main",
    "abstract": "We introduce RedMotion, a transformer model for motion prediction in self-driving vehicles that learns environment representations via redundancy reduction. Our first type of redundancy reduction is induced by an internal transformer decoder and reduces a variable-sized set of local road environment tokens, representing road graphs and agent data, to a fixed-sized global embedding. The second type of redundancy reduction is obtained by self-supervised learning and applies the redundancy reduction principle to embeddings generated from augmented views of road environments. Our experiments reveal that our representation learning approach outperforms PreTraM, Traj-MAE, and GraphDINO in a semi-supervised setting. Moreover, RedMotion achieves competitive results compared to HPTR or MTR++ in the Waymo Motion Prediction Challenge. Our open-source implementation is available at: https://github.com/kit-mrt/future-motion",
    "checked": true,
    "id": "d47ebac1ebe8bf9eaee436a96997dc6495670955",
    "semantic_title": "redmotion: motion prediction via redundancy reduction",
    "citation_count": 8,
    "authors": [
      "Royden Wagner",
      "Omer Sahin Tas",
      "Marvin Klemp",
      "Carlos Fernandez",
      "Christoph Stiller"
    ]
  },
  "https://openreview.net/forum?id=Yh8Y7a4myU": {
    "title": "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
    "volume": "main",
    "abstract": "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities. This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification",
    "checked": true,
    "id": "075772ce202add302465d77e91f40744f87caeda",
    "semantic_title": "clip meets model zoo experts: pseudo-supervision for visual enhancement",
    "citation_count": 2,
    "authors": [
      "Mohammadreza Salehi",
      "Mehrdad Farajtabar",
      "Maxwell Horton",
      "Fartash Faghri",
      "Hadi Pouransari",
      "Raviteja Vemulapalli",
      "Oncel Tuzel",
      "Ali Farhadi",
      "Mohammad Rastegari",
      "Sachin Mehta"
    ]
  },
  "https://openreview.net/forum?id=BQE4MTAfCE": {
    "title": "Amortized Bayesian Decision Making for simulation-based models",
    "volume": "main",
    "abstract": "Simulation-based inference (SBI) provides a powerful framework for inferring posterior distributions of stochastic simulators in a wide range of domains. In many settings, however, the posterior distribution is not the end goal itself --- rather, the derived parameter values and their uncertainties are used as a basis for deciding what actions to take. Unfortunately, because posterior distributions provided by SBI are (potentially crude) approximations of the true posterior, the resulting decisions can be suboptimal. Here, we address the question of how to perform Bayesian decision making on stochastic simulators, and how one can circumvent the need to compute an explicit approximation to the posterior. Our method trains a neural network on simulated data and can predict the expected cost given any data and action, and can, thus, be directly used to infer the action with lowest cost. We apply our method to several benchmark problems and demonstrate that it induces similar cost as the true posterior distribution. We then apply the method to infer optimal actions in a real-world simulator in the medical neurosciences, the Bayesian Virtual Epileptic Patient, and demonstrate that it allows to infer actions associated with low cost after few simulations",
    "checked": true,
    "id": "7575c109b9ade37bf06528ef381f0b570383bcce",
    "semantic_title": "amortized bayesian decision making for simulation-based models",
    "citation_count": 1,
    "authors": [
      "Mila Gorecki",
      "Jakob H. Macke",
      "Michael Deistler"
    ]
  },
  "https://openreview.net/forum?id=mK6TwmInTg": {
    "title": "Appropriate Balance of Diversification and Intensification Improves Performance and Efficiency of Adversarial Attacks",
    "volume": "main",
    "abstract": "Recently, adversarial attacks that generate adversarial examples by optimizing a multimodal function with many local optimums have attracted considerable research attention. Quick convergence to a nearby local optimum (intensification) and fast enumeration of multiple different local optima (diversification) are important to construct strong attacks. Most existing white-box attacks that use the model's gradient enumerate multiple local optima based on multi-restart; however, our experiments suggest that the ability of diversification based on multi-restart is limited. To tackle this problem, we propose the multi-directions/objectives (MDO) strategy, which uses multiple search directions and objective functions for diversification. Efficient Diversified Attack, a combination of MDO and multi-target strategies, showed further diversification performance, resulting in better performance than recently proposed attacks against around 88% of 41 CNN-based robust models and 100% of 10 more advanced models, including transformer-based architecture. These results suggest a relationship between attack performances and a balance of diversification and intensification, which is beneficial to constructing more potent attacks",
    "checked": true,
    "id": "cf4cbc4b27d69e2955187fd2a753cc17abbba476",
    "semantic_title": "appropriate balance of diversification and intensification improves performance and efficiency of adversarial attacks",
    "citation_count": 0,
    "authors": [
      "Keiichiro Yamamura",
      "Issa Oe",
      "Nozomi Hata",
      "Hiroki Ishikura",
      "Katsuki Fujisawa"
    ]
  },
  "https://openreview.net/forum?id=iV0jktFZ5Y": {
    "title": "Improve Certified Training with Signal-to-Noise Ratio Loss to Decrease Neuron Variance and Increase Neuron Stability",
    "volume": "main",
    "abstract": "Neural network robustness is a major concern in safety-critical applications. Certified robustness provides a reliable lower bound on worst-case robustness, and certified training methods have been developed to enhance it. However, certified training methods often suffer from over-regularization, leading to lower certified robustness. This work addresses this issue by introducing the concepts of neuron variance and neuron stability, examining their impact on over-regularization and model robustness. To tackle the problem, we extend the Signal-to-Noise Ratio (SNR) into the realm of model robustness, offering a novel perspective and developing SNR-inspired losses aimed at optimizing neuron variance and stability to mitigate over-regularization. Through both empirical and theoretical analysis, our SNR-based approach demonstrates superior performance over existing methods on the MNIST and CIFAR-10 datasets. In addition, our exploration of adversarial training uncovers a beneficial correlation between neuron variance and adversarial robustness, leading to an optimized balance between standard and robust accuracy that outperforms baseline methods",
    "checked": true,
    "id": "b641b7e7f4d153ea948c5486441b2a965a965e3f",
    "semantic_title": "improve certified training with signal-to-noise ratio loss to decrease neuron variance and increase neuron stability",
    "citation_count": 3,
    "authors": [
      "Tianhao Wei",
      "Ziwei Wang",
      "Peizhi Niu",
      "ABULIKEMU ABUDUWEILI",
      "Weiye Zhao",
      "Casidhe Hutchison",
      "Eric Sample",
      "Changliu Liu"
    ]
  },
  "https://openreview.net/forum?id=KNAWoKKpi3": {
    "title": "MaskOCR: Scene Text Recognition with Masked Vision-Language Pre-training",
    "volume": "main",
    "abstract": "Text images contain both visual and linguistic information. However, existing pre-training techniques for text recognition mainly focus on either visual representation learning or linguistic knowledge learning. In this paper, we propose a novel approach to unify vision and language pre-training in the classical encoder-decoder recognition framework. We adopt the masked image modeling approach to pre-train the feature encoder using a large set of unlabeled real text images, which allows us to learn strong visual representations. In contrast to introducing linguistic knowledge with an additional language model, we directly pre-train the sequence decoder. Specifically, we transform text data into synthesized text images to unify the data modalities of vision and language, and enhance the language modeling capability of the sequence decoder using a proposed masked image-language modeling scheme. Significantly, the encoder is frozen during the pre-training phase of the sequence decoder. Experimental results demonstrate that our proposed method achieves superior performance on benchmark datasets, including Chinese and English text images. The code for our approach will be made available",
    "checked": true,
    "id": "38630655bbe1091ba8e4346b216e4190a105be31",
    "semantic_title": "maskocr: scene text recognition with masked vision-language pre-training",
    "citation_count": 2,
    "authors": [
      "Pengyuan Lyu",
      "Chengquan Zhang",
      "Shanshan Liu",
      "Meina Qiao",
      "Yangliu Xu",
      "Liang Wu",
      "Kun Yao",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang"
    ]
  },
  "https://openreview.net/forum?id=84M8xwNxrc": {
    "title": "Differentially Private Kernel Inducing Points using features from ScatterNets (DP-KIP-ScatterNet) for Privacy Preserving Data Distillation",
    "volume": "main",
    "abstract": "Data distillation aims to generate a small data set that closely mimics the performance of a given learning algorithm on the original data set. The distilled dataset is hence useful to simplify the training process thanks to its small data size. However, distilled data samples are not necessarily privacy-preserving, even if they are generally humanly indiscernible. To address this limitation, we introduce differentially private kernel inducing points (DP-KIP) for privacy-preserving data distillation. Unlike our original intention to simply apply DP-SGD to the framework of KIP, we find that KIP using infinitely-wide convolutional neural tangent kernels (conv-NTKs) performs better compared to KIP using fully-connected NTKs. However, KIP with conv-NTKs, due to its convolutional and pooling operations, introduces an unbearable computational complexity, requiring hundreds of V100 GPUs in parallel to train, which is impractical and more importantly, such computational resources are inaccessible to many. To overcome this issue, we propose an alternative that does not require pre-training (to avoid a privacy loss) and can well capture complex information on images, as those features from conv-NKTs do, while the computational cost is manageable by a single V100 GPU. To this end, we propose DP-KIP-ScatterNet, which uses the wavelet features from Scattering networks (ScatterNet) instead of those from conv-NTKs, to perform DP-KIP at a reasonable computational cost. We implement DP-KIP-ScatterNet in -- computationally efficient -- JAX and test on several popular image datasets to show its efficacy and its superior performance compared to state-of-the art methods in image data distillation with differential privacy guarantees. Our code is available at https://github.com/ParkLabML/DP-KIP",
    "checked": true,
    "id": "153d4288f593c8d657910642fde23ca59d8df47c",
    "semantic_title": "differentially private kernel inducing points using features from scatternets (dp-kip-scatternet) for privacy preserving data distillation",
    "citation_count": 1,
    "authors": [
      "Margarita Vinaroz",
      "Mijung Park"
    ]
  },
  "https://openreview.net/forum?id=lLE0mWzUrr": {
    "title": "Large Language Models can be Guided to Evade AI-generated Text Detection",
    "volume": "main",
    "abstract": "Large language models (LLMs) have shown remarkable performance in various tasks and have been extensively utilized by the public. However, the increasing concerns regarding the misuse of LLMs, such as plagiarism and spamming, have led to the development of multiple detectors, including fine-tuned classifiers and statistical methods. In this study, we equip LLMs with prompts, rather than relying on an external paraphraser, to evaluate the vulnerability of these detectors. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically construct prompts for evading the detectors. SICO is cost-efficient as it requires only 40 human-written examples and a limited number of LLM inferences to generate a prompt. Moreover, once a task-specific prompt has been constructed, it can be universally used against a wide range of detectors. Extensive experiments across three real-world tasks demonstrate that SICO significantly outperforms the paraphraser baselines and enables GPT-3.5 to successfully evade six detectors, decreasing their AUC by 0.5 on average. Furthermore, a comprehensive human evaluation show that the SICO-generated text achieves human-level readability and task completion rates, while preserving high imperceptibility. Finally, we propose an ensemble approach to enhance the robustness of detectors against SICO attack",
    "checked": true,
    "id": "82817b85081ee075975f4a69039314b7741a979f",
    "semantic_title": "large language models can be guided to evade ai-generated text detection",
    "citation_count": 54,
    "authors": [
      "Ning Lu",
      "Shengcai Liu",
      "Rui He",
      "Yew-Soon Ong",
      "Qi Wang",
      "Ke Tang"
    ]
  },
  "https://openreview.net/forum?id=iKPC7N85Pf": {
    "title": "Predicting the Encoding Error of SIRENs",
    "volume": "main",
    "abstract": "Implicit Neural Representations (INRs), which encode signals such as images, videos, and 3D shapes in the weights of neural networks, are becoming increasingly popular. Among their many applications is signal compression, for which there is great interest in achieving the highest possible fidelity to the original signal subject to constraints such as neural network size, training (encoding) and inference (decoding) time. But training INRs can be a computationally expensive process, making it challenging to determine the best possible tradeoff under such constraints. Towards this goal, we propose a novel problem: predicting the encoding error (i.e. training loss) that an INR will reach on a given training signal. We present a method which predicts the encoding error that a popular INR network (SIREN) will reach, given its network hyperparameters and the signal to encode. This method is trained on a unique dataset of 300,000 SIRENs, trained across a variety of images and hyperparameters. Our predictive method demonstrates the feasibility of this regression problem, and allows users to anticipate the encoding error that a SIREN network will reach in milliseconds instead of minutes or longer. We also provide insights into the behavior of SIREN networks, such as why narrow SIRENs can have very high random variation in encoding error, and how the performance of SIRENs relates to JPEG compression",
    "checked": true,
    "id": "26949ac0e3b87fe73c5ac39457d942cf347dc51a",
    "semantic_title": "predicting the encoding error of sirens",
    "citation_count": 4,
    "authors": [
      "Jeremy Vonderfecht",
      "Feng Liu"
    ]
  },
  "https://openreview.net/forum?id=ydPHjgf6h0": {
    "title": "Adversarial Imitation Learning from Visual Observations using Latent Information",
    "volume": "main",
    "abstract": "We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our model-free approach in latent space matches state-of-the-art performance. Additionally, we show how our method can be used to improve the efficiency of reinforcement learning from pixels by leveraging expert videos. To ensure reproducibility, we provide free access to all the learning curves and open-source our code",
    "checked": true,
    "id": "ca8ffc2615cc76bbb15ceb30076df134ae5cdc25",
    "semantic_title": "adversarial imitation learning from visual observations using latent information",
    "citation_count": 7,
    "authors": [
      "Vittorio Giammarino",
      "James Queeney",
      "Ioannis Paschalidis"
    ]
  },
  "https://openreview.net/forum?id=PUpZXvNqmb": {
    "title": "From Identifiable Causal Representations to Controllable Counterfactual Generation: A Survey on Causal Generative Modeling",
    "volume": "main",
    "abstract": "Deep generative models have shown tremendous capability in data density estimation and data generation from finite samples. While these models have shown impressive performance by learning correlations among features in the data, some fundamental shortcomings are their lack of explainability, tendency to induce spurious correlations, and poor out-of-distribution extrapolation. To remedy such challenges, recent work has proposed a shift toward causal generative models. Causal models offer several beneficial properties to deep generative models, such as distribution shift robustness, fairness, and interpretability. Structural causal models (SCMs) describe data-generating processes and model complex causal relationships and mechanisms among variables in a system. Thus, SCMs can naturally be combined with deep generative models. We provide a technical survey on causal generative modeling categorized into causal representation learning and controllable counterfactual generation methods. We focus on fundamental theory, methodology, drawbacks, datasets, and metrics. Then, we cover applications of causal generative models in fairness, privacy, out-of-distribution generalization, precision medicine, and biological sciences. Lastly, we discuss open problems and fruitful research directions for future work in the field",
    "checked": true,
    "id": "1d3ab3b346bd035d50590af912a7c21b16ffdb1c",
    "semantic_title": "from identifiable causal representations to controllable counterfactual generation: a survey on causal generative modeling",
    "citation_count": 11,
    "authors": [
      "Aneesh Komanduri",
      "Xintao Wu",
      "Yongkai Wu",
      "Feng Chen"
    ]
  },
  "https://openreview.net/forum?id=9UgUMFW67X": {
    "title": "Genetic InfoMax: Exploring Mutual Information Maximization in High-Dimensional Imaging Genetics Studies",
    "volume": "main",
    "abstract": "Genome-wide association studies (GWAS) are used to identify relationships between genetic variations and specific traits. When applied to high-dimensional medical imaging data, a key step is to extract lower-dimensional, yet informative representations of the data as traits. Representation learning for imaging genetics is largely under-explored due to the unique challenges posed by GWAS in comparison to typical visual representation learning. In this study, we tackle this problem from the mutual information (MI) perspective by identifying key limitations of existing methods. We introduce a trans-modal learning framework Genetic InfoMax (GIM), including a regularized MI estimator and a novel genetics-informed transformer to address the specific challenges of GWAS. We evaluate GIM on human brain 3D MRI data and establish standardized evaluation protocols to compare it to existing approaches. Our results demonstrate the effectiveness of GIM and a significantly improved performance on GWAS",
    "checked": true,
    "id": "353910469227c9251ae604f3c2085fc82054fb02",
    "semantic_title": "genetic infomax: exploring mutual information maximization in high-dimensional imaging genetics studies",
    "citation_count": 0,
    "authors": [
      "Yaochen Xie",
      "Ziqian Xie",
      "Sheikh Muhammad Saiful Islam",
      "Degui Zhi",
      "Shuiwang Ji"
    ]
  },
  "https://openreview.net/forum?id=k3d5C0YvfK": {
    "title": "Enhancing Compositional Generalization via Compositional Feature Alignment",
    "volume": "main",
    "abstract": "Real-world applications of machine learning models often confront data distribution shifts, wherein discrepancies exist between the training and test data distributions. In the common multi-domain multi-class setup, as the number of classes and domains scales up, it becomes infeasible to gather training data for every domain-class combination. This challenge naturally leads the quest for models with Compositional Generalization (CG) ability, where models can generalize to unseen domain-class combinations. To delve into the CG challenge, we develop CG-Bench, a suite of CG benchmarks derived from existing real-world image datasets, and observe that the prevalent pretraining-finetuning paradigm on foundational models, such as CLIP and DINOv2, struggles with the challenge. To address this challenge, we propose Compositional Feature Alignment (CFA), a simple two-stage finetuning technique that i) learns two orthogonal linear heads on a pretrained encoder with respect to class and domain labels, and ii) fine-tunes the encoder with the newly learned head frozen. We theoretically and empirically justify that CFA encourages compositional feature learning of pretrained models. We further conduct extensive experiments on CG-Bench for CLIP and DINOv2, two powerful pretrained vision foundation models. Experiment results show that CFA outperforms common finetuning techniques in compositional generalization, corroborating CFA's efficacy in compositional feature learning",
    "checked": true,
    "id": "5c8f4270dc18433425eebacd1b4e41a107556abf",
    "semantic_title": "enhancing compositional generalization via compositional feature alignment",
    "citation_count": 2,
    "authors": [
      "Haoxiang Wang",
      "Haozhe Si",
      "Huajie Shao",
      "Han Zhao"
    ]
  },
  "https://openreview.net/forum?id=PIL3YWXmx2": {
    "title": "Statistical and Computational Complexities of BFGS Quasi-Newton Method for Generalized Linear Models",
    "volume": "main",
    "abstract": "The gradient descent (GD) method has been used widely to solve parameter estimation in generalized linear models (GLMs), a generalization of linear models when the link function can be non-linear. In GLMs with a polynomial link function, it has been shown that in the high signal-to-noise ratio (SNR) regime, due to the problem's strong convexity and smoothness, GD converges linearly and reaches the final desired accuracy in a logarithmic number of iterations. In contrast, in the low SNR setting, where the problem becomes locally convex, GD converges at a slower rate and requires a polynomial number of iterations to reach the desired accuracy. Even though Newton's method can be used to resolve the flat curvature of the loss functions in the low SNR case, its computational cost is prohibitive in high-dimensional settings as it is $\\mathcal{O}(d^3)$, where $d$ the is the problem dimension. To address the shortcomings of GD and Newton's method, we propose the use of the BFGS quasi-Newton method to solve parameter estimation of the GLMs, which has a per iteration cost of $\\mathcal{O}(d^2)$. When the SNR is low, for GLMs with a polynomial link function of degree $p$, we demonstrate that the iterates of BFGS converge linearly to the optimal solution of the population least-square loss function, and the contraction coefficient of the BFGS algorithm is comparable to that of Newton's method. Moreover, the contraction factor of the linear rate is independent of problem parameters and only depends on the degree of the link function $p$. Also, for the empirical loss with $n$ samples, we prove that in the low SNR setting of GLMs with a polynomial link function of degree $p$, the iterates of BFGS reach a final statistical radius of $\\mathcal{O}((d/n)^{\\frac{1}{2p+2}})$ after at most $\\log(n/d)$ iterations. This complexity is significantly less than the number required for GD, which scales polynomially with $(n/d)$",
    "checked": true,
    "id": "166aee5a9b877d143b8eb005054a045be052c707",
    "semantic_title": "statistical and computational complexities of bfgs quasi-newton method for generalized linear models",
    "citation_count": 2,
    "authors": [
      "Qiujiang Jin",
      "Tongzheng Ren",
      "Nhat Ho",
      "Aryan Mokhtari"
    ]
  },
  "https://openreview.net/forum?id=C3FXHxMVuq": {
    "title": "CascadedGaze: Efficiency in Global Context Extraction for Image Restoration",
    "volume": "main",
    "abstract": "Image restoration tasks traditionally rely on convolutional neural networks. However, given the local nature of the convolutional operator, they struggle to capture global information. The promise of attention mechanisms in Transformers is to circumvent this problem, but it comes at the cost of intensive computational overhead. Many recent studies in image restoration have focused on solving the challenge of balancing performance and computational cost via Transformer variants. In this paper, we present CascadedGaze Network (CGNet), an encoder-decoder architecture that employs Global Context Extractor (GCE), a novel and efficient way to capture global information for image restoration. The GCE module leverages small kernels across convolutional layers to learn global dependencies, without requiring self-attention. Extensive experimental results show that our approach outperforms a range of state-of-the-art methods on denoising benchmark datasets including both real image denoising and synthetic image denoising, as well as on image deblurring task, while being more computationally efficient",
    "checked": true,
    "id": "168408d0eb1dfc9241411ebb0283d87d9e5595cb",
    "semantic_title": "cascadedgaze: efficiency in global context extraction for image restoration",
    "citation_count": 12,
    "authors": [
      "Amirhosein Ghasemabadi",
      "Muhammad Kamran Janjua",
      "Mohammad Salameh",
      "CHUNHUA ZHOU",
      "Fengyu Sun",
      "Di Niu"
    ]
  },
  "https://openreview.net/forum?id=57ETChLAOE": {
    "title": "Revisiting stochastic submodular maximization with cardinality constraint: A bandit perspective",
    "volume": "main",
    "abstract": "In this paper, we focus on the problem of maximizing non-negative, monotone, stochastic submodular functions under cardinality constraint. Recent works have explored continuous optimization algorithms via multi-linear extensions for such problems and provided appropriate approximation guarantees. We take a fresh look into this problem from a discrete, (stochastic) greedy perspective under a probably approximately correct (PAC) setting, i.e., the goal is to obtain solutions whose expected objective value is greater than or equal to $(1-1/e-\\epsilon){\\rm OPT}-\\nu$ with at least $1-\\delta$ probability, where ${\\rm OPT}$ is the optimal objective value. Using the theory of multi-armed bandits, we propose novel bandit stochastic greedy (BSG) algorithms in which selection of the next element at iteration $i$ is posed as a $(\\nu_i,\\delta_i)$-PAC best-arm identification problem. Given $(\\nu,\\delta)$-PAC parameters to BSG, we formally characterize a set $\\mathcal{A}(\\nu,\\delta)$ of per-iteration policies such that any policy from this set guarantees a $(\\nu,\\delta)$-PAC solution for the stochastic submodular maximization problem using BSG. We next discuss the problem of learning a policy in $\\mathcal{A}(\\nu,\\delta)$ by minimizing the computational cost. With our learned policy, we show that BSG has lower computational cost than existing stochastic submodular maximization approaches. An interesting outcome of our analysis is the development of both linear and almost-linear time algorithms for the exemplar based clustering problem with $(1-1/e-\\epsilon)$-approximation guarantee under a PAC setting. Lastly, we also study the problem of learning a policy for BSG under budget setting. Experiments on various problems illustrate the efficacy of our approach in terms of optimization quality as well as computational efficiency",
    "checked": true,
    "id": "fd7dca5f119e0af4ec3b74b65e9446179be302fb",
    "semantic_title": "revisiting stochastic submodular maximization with cardinality constraint: a bandit perspective",
    "citation_count": 0,
    "authors": [
      "Pratik Jawanpuria",
      "Bamdev Mishra",
      "Karthik S. Gurumoorthy"
    ]
  },
  "https://openreview.net/forum?id=EE1CBKC0SZ": {
    "title": "TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks",
    "volume": "main",
    "abstract": "We present TIGERScore, a \\textbf{T}rained metric that follows \\textbf{I}nstruction \\textbf{G}uidance to perform \\textbf{E}xplainable, and \\textbf{R}eference-free evaluation over a wide spectrum of text generation tasks. Different from other automatic evaluation methods that only provide arcane scores, TIGERScore is guided by natural language instruction to provide error analysis to pinpoint the mistakes in the generated text. Our metric is based on LLaMA-2, trained on our meticulously curated instruction-tuning dataset MetricInstruct which covers 6 text generation tasks and 23 text generation datasets. The dataset consists of 42K quadruple in the form of (instruction, input, system output $\\rightarrow$ error analysis). We collected the `system outputs' through from a large variety of models to cover different types of errors. To quantitatively assess our metric, we evaluate its correlation with human ratings on 5 held-in datasets, 2 held-out datasets and show that \\metricname{} can achieve the open-source SoTA correlation with human ratings across these datasets and almost approaches GPT-4 evaluator. As a reference-free metric, its correlation can even surpass the best existing reference-based metrics. To further qualitatively assess the rationale generated by our metric, we conduct human evaluation on the generated explanations and found that the explanations are 70.8\\% accurate. Through these experimental results, we believe \\metricname{} demonstrates the possibility of building universal explainable metrics to evaluate any text generation task",
    "checked": true,
    "id": "d238a9770d24d0725656ef6cf4789afebf2126e7",
    "semantic_title": "tigerscore: towards building explainable metric for all text generation tasks",
    "citation_count": 69,
    "authors": [
      "Dongfu Jiang",
      "Yishan Li",
      "Ge Zhang",
      "Wenhao Huang",
      "Bill Yuchen Lin",
      "Wenhu Chen"
    ]
  },
  "https://openreview.net/forum?id=TdJ7lpzAkD": {
    "title": "Interpretable Additive Tabular Transformer Networks",
    "volume": "main",
    "abstract": "Attention based Transformer networks have not only revolutionized Natural Language Processing but have also achieved state-of-the-art results for tabular data modeling. The attention mechanism, in particular, has proven to be highly effective in accurately modeling categorical variables. Although deep learning models recently outperform tree-based models, they often lack a complete comprehension of the individual impact of features because of their opaque nature. In contrast, additive neural network structures have proven to be both predictive and interpretable. Within the context of explainable deep learning, we propose Neural Additive Tabular Transformer Networks (NATT), a modeling framework that combines the intelligibility of additive neural networks with the predictive power of Transformer models. NATT offers inherent intelligibility while achieving similar performance to complex deep learning models. To validate its efficacy, we conduct experiments on multiple datasets and find that NATT performs on par with state-of-the-art methods on tabular data and surpasses other interpretable approaches",
    "checked": true,
    "id": "854aac1fe84429f089ff6a1381f90f29f623c797",
    "semantic_title": "interpretable additive tabular transformer networks",
    "citation_count": 3,
    "authors": [
      "Anton Frederik Thielmann",
      "Arik Reuter",
      "Thomas Kneib",
      "David RÃ¼gamer",
      "Benjamin SÃ¤fken"
    ]
  },
  "https://openreview.net/forum?id=zO4aAVHxPe": {
    "title": "Geometrical aspects of lattice gauge equivariant convolutional neural networks",
    "volume": "main",
    "abstract": "Lattice gauge equivariant convolutional neural networks (L-CNNs) are a framework for convolutional neural networks that can be applied to non-Abelian lattice gauge theories without violating gauge symmetry. We demonstrate how L-CNNs can be equipped with global group equivariance. This allows us to extend the formulation to be equivariant not just under translations but under global lattice symmetries such as rotations and reflections. Additionally, we provide a geometric formulation of L-CNNs and show how convolutions in L-CNNs arise as a special case of gauge equivariant neural networks on SU(N) principal bundles",
    "checked": true,
    "id": "0182110de6f2471cfe57b109b7cfa59675598360",
    "semantic_title": "geometrical aspects of lattice gauge equivariant convolutional neural networks",
    "citation_count": 7,
    "authors": [
      "David I. MÃ¼ller",
      "Jimmy Aronsson",
      "Daniel Schuh"
    ]
  },
  "https://openreview.net/forum?id=r2dx1s1lqG": {
    "title": "Boosting Data-Driven Mirror Descent with Randomization, Equivariance, and Acceleration",
    "volume": "main",
    "abstract": "Learning-to-optimize (L2O) is an emerging research area in large-scale optimization with applications in data science. Recently, researchers have proposed a novel L2O framework called learned mirror descent (LMD), based on the classical mirror descent (MD) algorithm with learnable mirror maps parameterized by input-convex neural networks. The LMD approach has been shown to significantly accelerate convex solvers while inheriting the convergence properties of the classical MD algorithm. This work proposes several practical extensions of the LMD algorithm, addressing its instability, scalability, and feasibility for high-dimensional problems. We first propose accelerated and stochastic variants of LMD, leveraging classical momentum-based acceleration and stochastic optimization techniques for improving the convergence rate and per-iteration computational complexity. Moreover, for the particular application of training neural networks, we derive and propose a novel and efficient parameterization for the mirror potential, exploiting the equivariant structure of the training problems to significantly reduce the dimensionality of the underlying problem. We provide theoretical convergence guarantees for our schemes under standard assumptions and demonstrate their effectiveness in various computational imaging and machine learning applications such as image inpainting, and the training of support vector machines and deep neural networks",
    "checked": true,
    "id": "50313f151af5c64775023ab95f64359ffacc2cd8",
    "semantic_title": "boosting data-driven mirror descent with randomization, equivariance, and acceleration",
    "citation_count": 3,
    "authors": [
      "Hong Ye Tan",
      "Subhadip Mukherjee",
      "Junqi Tang",
      "Carola-Bibiane SchÃ¶nlieb"
    ]
  },
  "https://openreview.net/forum?id=PGLbZpVk2n": {
    "title": "Causal Discovery from Time Series with Hybrids of Constraint-Based and Noise-Based Algorithms",
    "volume": "main",
    "abstract": "Constraint-based methods and noise-based methods are two distinct families of methods proposed for uncovering causal graphs from observational data. However, both operate under strong assumptions that may be challenging to validate or could be violated in real-world scenarios. In response to these challenges, there is a growing interest in hybrid methods that amalgamate principles from both methods, showing robustness to assumption violations. This paper introduces a novel comprehensive framework for hybridizing constraint-based and noise-based methods designed to uncover causal graphs from observational time series. The framework is structured into two classes. The first class employs a noise-based strategy to identify a super graph, containing the true graph, followed by a constraint-based strategy to eliminate unnecessary edges. In the second class, a constraint-based strategy is applied to identify a skeleton, which is then oriented using a noise-based strategy. The paper provides theoretical guarantees for each class under the condition that all assumptions are satisfied, and it outlines some properties when assumptions are violated. To validate the efficacy of the framework, two algorithms from each class are experimentally tested on simulated data, realistic ecological data, and real datasets sourced from diverse applications. Notably, two novel datasets related to Information Technology monitoring are introduced within the set of considered real datasets. The experimental results underscore the robustness and effectiveness of the hybrid approaches across a broad spectrum of datasets",
    "checked": true,
    "id": "0c35c5a7b1425ebcdca5f359376b59272971815c",
    "semantic_title": "causal discovery from time series with hybrids of constraint-based and noise-based algorithms",
    "citation_count": 6,
    "authors": [
      "Daria Bystrova",
      "Charles K. Assaad",
      "Julyan Arbel",
      "Emilie Devijver",
      "Eric Gaussier",
      "Wilfried Thuiller"
    ]
  },
  "https://openreview.net/forum?id=LHl2I2rWZa": {
    "title": "GLASU: A Communication-Efficient Algorithm for Federated Learning with Vertically Distributed Graph Data",
    "volume": "main",
    "abstract": "Vertical federated learning (VFL) is a distributed learning paradigm, where computing clients collectively train a model based on the partial features of the same set of samples they possess. Current research on VFL focuses on the case when samples are independent, but it rarely addresses an emerging scenario when samples are interrelated through a graph. In this work, we train a graph neural network (GNN) through VFL, where each client owns a part of the node features and a different edge set. This data scenario incurs a significant communication overhead, not only because of the handling of distributed features but also due to neighborhood aggregation in a GNN. Moreover, the training analysis is faced with a challenge caused by the biased stochastic gradients. We propose a model-splitting method that splits a backbone GNN across the clients and the server and a communication-efficient algorithm, GLASU, to train such a model. GLASU adopts lazy aggregation and stale updates to skip communication in neighborhood aggregation and in model updates, respectively, greatly reducing communication while enjoying convergence guarantees. We conduct extensive numerical experiments on real-world datasets, showing that GLASU effectively trains a GNN that matches the accuracy of centralized training, while using only a fraction of the time due to communication saving",
    "checked": true,
    "id": "b400baf6862a918355934a9ea98bf1e0c431b789",
    "semantic_title": "glasu: a communication-efficient algorithm for federated learning with vertically distributed graph data",
    "citation_count": 3,
    "authors": [
      "Xinwei Zhang",
      "Mingyi Hong",
      "Jie Chen"
    ]
  },
  "https://openreview.net/forum?id=KLojVqdj2y": {
    "title": "Training Graph Neural Networks Subject to a Tight Lipschitz Constraint",
    "volume": "main",
    "abstract": "We propose a strategy for training a wide range of graph neural networks (GNNs) under tight Lipschitz bound constraints. Specifically, by leveraging graph spectral theory, we derive computationally tractable expressions of a tight Lipschitz constant. This allows us to propose a constrained-optimization approach to control the constant, ensuring robustness to adversarial perturbations. Unlike the existing methods for controlling the Lipschitz constant, our approach reduces the size of the handled matrices by a factor equal to the square of the number of nodes in the graph. We employ a stochastic projected subgradient algorithm, which operates in a block-coordinate manner, with the projection step performed via an accelerated iterative proximal algorithm. We focus on defending against attacks that perturb features while keeping the topology of the graph constant. This contrasts with most of the existing defenses, which tackle perturbations of the graph structure. We report experiments on various datasets in the context of node classification tasks, showing the effectiveness of our constrained GNN model",
    "checked": true,
    "id": "00b23e7dad0b2b70ca3a179518f14234cc8dac60",
    "semantic_title": "training graph neural networks subject to a tight lipschitz constraint",
    "citation_count": 1,
    "authors": [
      "Simona Ioana Juvina",
      "Ana Antonia NeacÈu",
      "JÃ©rÃ´me Rony",
      "Jean-Christophe Pesquet",
      "Corneliu Burileanu",
      "Ismail Ben Ayed"
    ]
  },
  "https://openreview.net/forum?id=WHAmxfLjeJ": {
    "title": "Understanding Smoothness of Vector Gaussian Processes on Product Spaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "26c7884b850100fa72c94af85c0682979c7f2f75",
    "semantic_title": "understanding smoothness of vector gaussian processes on product spaces",
    "citation_count": 1,
    "authors": [
      "Emilio Porcu",
      "Ana Paula Peron",
      "Eugenio Massa",
      "Xavier Emery"
    ]
  },
  "https://openreview.net/forum?id=kxHIK4x8qc": {
    "title": "MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": "b51271a90b386cb0ff723a8a43f1106cbd575833",
    "semantic_title": "magdiff: covariate data set shift detection via activation graphs of deep neural networks",
    "citation_count": 2,
    "authors": [
      "Charles Arnal",
      "Felix Hensel",
      "Mathieu CarriÃ¨re",
      "ThÃ©o Lacombe",
      "Hiroaki Kurihara",
      "Yuichi Ike",
      "Frederic Chazal"
    ]
  },
  "https://openreview.net/forum?id=oCfamUtecN": {
    "title": "Regret Bounds for Noise-Free Cascaded Kernelized Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "587fb638a91e658854719987ba5294d9cdcb5b2a",
    "semantic_title": "regret bounds for noise-free cascaded kernelized bandits",
    "citation_count": 2,
    "authors": [
      "Zihan Li",
      "Jonathan Scarlett"
    ]
  },
  "https://openreview.net/forum?id=KLBD13bsVl": {
    "title": "The Interplay of Uncertainty Modeling and Deep Active Learning: An Empirical Analysis in Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "802e0873a85afa7723ecce56892bf55de3f3bfc3",
    "semantic_title": "the interplay of uncertainty modeling and deep active learning: an empirical analysis in image classification",
    "citation_count": 1,
    "authors": [
      "Denis Huseljic",
      "Marek Herde",
      "Yannick Nagel",
      "Lukas Rauch",
      "Paulius Strimaitis",
      "Bernhard Sick"
    ]
  },
  "https://openreview.net/forum?id=7VB5db72lr": {
    "title": "G4SATBench: Benchmarking and Advancing SAT Solving with Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) have recently emerged as a promising approach for solving the Boolean Satisfiability Problem (SAT), offering potential alternatives to traditional backtracking or local search SAT solvers. However, despite the growing volume of literature in this field, there remains a notable absence of a unified dataset and a fair benchmark to evaluate and compare existing approaches. To address this crucial gap, we present G4SATBench, the first benchmark study that establishes a comprehensive evaluation framework for GNN-based SAT solvers. In G4SATBench, we meticulously curate a large and diverse set of SAT datasets comprising 7 problems with 3 difficulty levels and benchmark a broad range of GNN models across various prediction tasks, training objectives, and inference algorithms. To explore the learning abilities and comprehend the strengths and limitations of GNN-based SAT solvers, we also compare their solving processes with the heuristics in search-based SAT solvers. Our empirical results provide valuable insights into the performance of GNN-based SAT solvers and further suggest that existing GNN models can effectively learn a solving strategy akin to greedy local search but struggle to learn backtracking search in the latent space. Our codebase is available at https://github.com/zhaoyu-li/G4SATBench",
    "checked": true,
    "id": "490446ac0419c2f232b481e4c73117bcffe45576",
    "semantic_title": "g4satbench: benchmarking and advancing sat solving with graph neural networks",
    "citation_count": 6,
    "authors": [
      "Zhaoyu Li",
      "Jinpei Guo",
      "Xujie Si"
    ]
  },
  "https://openreview.net/forum?id=vsez76EAV8": {
    "title": "PaDPaF: Partial Disentanglement with Partially-Federated GANs",
    "volume": "main",
    "abstract": "Federated learning has become a popular machine learning paradigm with many potential real-life applications, including recommendation systems, the Internet of Things (IoT), healthcare, and self-driving cars. Though most current applications focus on classification-based tasks, learning personalized generative models remains largely unexplored, and their benefits in the heterogeneous setting still need to be better understood. This work proposes a novel architecture combining global client-agnostic and local client-specific generative models. We show that using standard techniques for training federated models, our proposed model achieves privacy and personalization by implicitly disentangling the globally-consistent representation (i.e. content) from the client-dependent variations (i.e. style). Using such decomposition, personalized models can generate locally unseen labels while preserving the given style of the client and can predict the labels for all clients with high accuracy by training a simple linear classifier on the global content features. Furthermore, disentanglement enables other essential applications, such as data anonymization, by sharing only the content. Extensive experimental evaluation corroborates our findings, and we also discuss a theoretical motivation for the proposed approach",
    "checked": true,
    "id": "f2e731428232683868322544f8fc6347a3c74626",
    "semantic_title": "padpaf: partial disentanglement with partially-federated gans",
    "citation_count": 2,
    "authors": [
      "Abdulla Jasem Almansoori",
      "Samuel HorvÃ¡th",
      "Martin TakÃ¡Ä"
    ]
  },
  "https://openreview.net/forum?id=KVUtlM60HM": {
    "title": "Archetypal Analysis++: Rethinking the Initialization Strategy",
    "volume": "main",
    "abstract": "Archetypal analysis is a matrix factorization method with convexity constraints. Due to local minima, a good initialization is essential, but frequently used initialization methods yield either sub-optimal starting points or are prone to get stuck in poor local minima. In this paper, we propose archetypal analysis++ (AA++), a probabilistic initialization strategy for archetypal analysis that sequentially samples points based on their influence on the objective function, similar to $k$-means++. In fact, we argue that $k$-means++ already approximates the proposed initialization method. Furthermore, we suggest to adapt an efficient Monte Carlo approximation of $k$-means++ to AA++. In an extensive empirical evaluation of 15 real-world data sets of varying sizes and dimensionalities and considering two pre-processing strategies, we show that AA++ almost always outperforms all baselines, including the most frequently used ones",
    "checked": true,
    "id": "33a7a6c4a7a9cf84c37646ec8a4acaad9d110a40",
    "semantic_title": "archetypal analysis++: rethinking the initialization strategy",
    "citation_count": 1,
    "authors": [
      "Sebastian Mair",
      "Jens SjÃ¶lund"
    ]
  },
  "https://openreview.net/forum?id=vxxi7xzzn7": {
    "title": "Data Pruning Can Do More: A Comprehensive Data Pruning Approach for Object Re-identification",
    "volume": "main",
    "abstract": "Previous studies have demonstrated that not each sample in a dataset is of equal importance during training. Data pruning aims to remove less important or informative samples while still achieving comparable results as training on the original (untruncated) dataset, thereby reducing storage and training costs. However, the majority of data pruning methods are applied to image classification tasks. To our knowledge, this work is the first to explore the feasibility of these pruning methods applied to object re-identification (ReID) tasks, while also presenting a more comprehensive data pruning approach. By fully leveraging the logit history during training, our approach offers a more accurate and comprehensive metric for quantifying sample importance, as well as correcting mislabeled samples and recognizing outliers. Furthermore, our approach is highly efficient, reducing the cost of importance score estimation by 10 times compared to existing methods. Our approach is a plug-and-play, architecture-agnostic framework that can eliminate/reduce 35%, 30%, and 5% of samples/training time on the VeRi, MSMT17 and Market1501 datasets, respectively, with negligible loss in accuracy (< 0.1%). The lists of important, mislabeled, and outlier samples from these ReID datasets are available at https://github.com/Zi-Y/data-pruning-reid",
    "checked": true,
    "id": "e0f526e908fc22c7bdf652adc091330d167f65c5",
    "semantic_title": "data pruning can do more: a comprehensive data pruning approach for object re-identification",
    "citation_count": 2,
    "authors": [
      "Zi Yang",
      "Haojin Yang",
      "Soumajit Majumder",
      "Jorge Cardoso",
      "Guillermo Gallego"
    ]
  },
  "https://openreview.net/forum?id=kPIU8PnJPo": {
    "title": "Scaling Vision-and-Language Navigation With Offline RL",
    "volume": "main",
    "abstract": "The study of vision-and-language navigation (VLN) has typically relied on expert trajectories, which may not always be available in real-world situations due to the significant effort required to collect them. On the other hand, existing approaches to training VLN agents that go beyond available expert data involve data augmentations or online exploration which can be tedious and risky. In contrast, it is easy to access large repositories of suboptimal offline trajectories. Inspired by research in offline reinforcement learning (ORL), we introduce a new problem setup of VLN-ORL which studies VLN using suboptimal demonstration data. We introduce a simple and effective reward-conditioned approach that can account for dataset suboptimality for training VLN agents, as well as benchmarks to evaluate progress and promote research in this area. We empirically study various noise models for characterizing dataset suboptimality among other unique challenges in VLN-ORL and instantiate it for the VLNâ³BERT and MTVM architectures in the R2R and RxR environments. Our experiments demonstrate that the proposed reward-conditioned approach leads to significant performance improvements, even in complex and intricate environments",
    "checked": true,
    "id": "43476ac68d991bb76f288fd979cdb240223b46f5",
    "semantic_title": "scaling vision-and-language navigation with offline rl",
    "citation_count": 1,
    "authors": [
      "Valay Bundele",
      "Mahesh Bhupati",
      "Biplab Banerjee",
      "Aditya Grover"
    ]
  },
  "https://openreview.net/forum?id=2bURaH6RN8": {
    "title": "Momentum-Based Policy Gradient with Second-Order Information",
    "volume": "main",
    "abstract": "Variance-reduced gradient estimators for policy gradient methods have been one of the main focus of research in the reinforcement learning in recent years as they allow acceleration of the estimation process. We propose a variance-reduced policy-gradient method, called SHARP, which incorporates second-order information into stochastic gradient descent (SGD) using momentum with a time-varying learning rate. SHARP algorithm is parameter-free, achieving $\\epsilon$-approximate first-order stationary point with $O(\\epsilon^{-3})$ number of trajectories, while using a batch size of $O(1)$ at each iteration. Unlike most previous work, our proposed algorithm does not require importance sampling which can compromise the advantage of variance reduction process. Moreover, the variance of estimation error decays with the fast rate of $O(1/t^{2/3})$ where $t$ is the number of iterations. Our extensive experimental evaluations show the effectiveness of the proposed algorithm on various control tasks and its advantage over the state of the art in practice",
    "checked": true,
    "id": "fa8c76c432f4fb6901f3545dd20fd02c74297c9b",
    "semantic_title": "momentum-based policy gradient with second-order information",
    "citation_count": 9,
    "authors": [
      "Saber Salehkaleybar",
      "Mohammadsadegh Khorasani",
      "Negar Kiyavash",
      "Niao He",
      "Patrick Thiran"
    ]
  },
  "https://openreview.net/forum?id=HNqEKZDDRc": {
    "title": "Offline Reinforcement Learning via Tsallis Regularization",
    "volume": "main",
    "abstract": "Offline reinforcement learning (RL) focuses on learning a good policy from a fixed dataset. The dataset is generated by an unknown behavior policy through interactions with the environment and contains only a subset of the state-action spaces. Standard off-policy algorithms often perform poorly in this setting, suffering from errorneously optimistic values incurred by the out-of-distribution (OOD) actions not present in the dataset. The optimisim cannot be corrected as no further interaction with the environment is possible. Imposing divergence regularization and in-sample constraints are among the most popular methods to overcoming the issue by ensuring that the learned policy stays close to the behavior policy to minimize the occurrence of OOD actions. This paper proposes Tsallis regularization for offline RL, which aligns the induced sparsemax policies to the in-sample constraint. Sparsemax interpolates existing methods utilizing hard-max and softmax policies, in that only a subset of actions contributes non-zero action probability as compared to softmax (all actions) and hard-max (single action). We leverage this property to model the behavior policy and show that under several assumptions the learned sparsemax policies may have sparsity-conditional KL divergence to the behavior policy, making Tsallis regularization especially suitable for the Behavior Cloning methods. We propose a novel actor-critic algorithm: Tsallis Advantage Weighted Actor-Critic (Tsallis AWAC) generalizing AWAC and analyze its performance in standard Mujoco environments. Our code is available at \\url{https://github.com/lingweizhu/tsallis_regularization}",
    "checked": true,
    "id": "9950fe19120674047c2c3358753e328744347976",
    "semantic_title": "offline reinforcement learning via tsallis regularization",
    "citation_count": 1,
    "authors": [
      "Lingwei Zhu",
      "Matthew Kyle Schlegel",
      "Han Wang",
      "Martha White"
    ]
  },
  "https://openreview.net/forum?id=AYJ3m7BocI": {
    "title": "A Survey on Transferability of Adversarial Examples Across Deep Neural Networks",
    "volume": "main",
    "abstract": "The emergence of Deep Neural Networks (DNNs) has revolutionized various domains by enabling the resolution of complex tasks spanning image recognition, natural language processing, and scientific problem-solving. However, this progress has also brought to light a concerning vulnerability: adversarial examples. These crafted inputs, imperceptible to humans, can manipulate machine learning models into making erroneous predictions, raising concerns for safety-critical applications. An intriguing property of this phenomenon is the transferability of adversarial examples, where perturbations crafted for one model can deceive another, often with a different architecture. This intriguing property enables ``black-box'' attacks which circumvents the need for detailed knowledge of the target model. This survey explores the landscape of the adversarial transferability of adversarial examples. We categorize existing methodologies to enhance adversarial transferability and discuss the fundamental principles guiding each approach. While the predominant body of research primarily concentrates on image classification, we also extend our discussion to encompass other vision tasks and beyond. Challenges and opportunities are discussed, highlighting the importance of fortifying DNNs against adversarial vulnerabilities in an evolving landscape",
    "checked": true,
    "id": "47997f6fb2eb5bcc59a0266d11d07f6c08233d65",
    "semantic_title": "a survey on transferability of adversarial examples across deep neural networks",
    "citation_count": 30,
    "authors": [
      "Jindong Gu",
      "Xiaojun Jia",
      "Pau de Jorge",
      "Wenqian Yu",
      "Xinwei Liu",
      "Avery Ma",
      "Yuan Xun",
      "Anjun Hu",
      "Ashkan Khakzar",
      "Zhijiang Li",
      "Xiaochun Cao",
      "Philip Torr"
    ]
  },
  "https://openreview.net/forum?id=qc2lmWkvk4": {
    "title": "Hybrid Federated Learning for Feature & Sample Heterogeneity: Algorithms and Implementation",
    "volume": "main",
    "abstract": "Federated learning (FL) is a popular distributed machine learning paradigm dealing with distributed and private data sets. Based on the data partition pattern, FL is often categorized into horizontal, vertical, and hybrid settings. All three settings have many applications, but the hybrid FL remains relatively less explored, because it deals with the challenging situation where {\\it both} the feature space and the data samples are {\\it heterogeneous}. This work designs a novel mathematical model that effectively allows the clients to aggregate distributed data with heterogeneous, and possibly overlapping features and samples. Our main idea is to partition each client's model into a feature extractor part and a classifier part, where the former can be used to process the input data, while the latter is used to perform the learning from the extracted features. The heterogeneous feature aggregation is done through building a server model, which assimilates local classifiers and feature extractors through a carefully designed matching mechanism. A communication-efficient algorithm is then designed to train both the client and server models. Finally, we conducted numerical experiments on multiple image classification data sets to validate the performance of the proposed algorithm. To our knowledge, this is the first formulation and algorithm developed for hybrid FL",
    "checked": true,
    "id": "caef92be15924afd723b8d97e5ac000d346e1f46",
    "semantic_title": "hybrid federated learning for feature & sample heterogeneity: algorithms and implementation",
    "citation_count": 3,
    "authors": [
      "Xinwei Zhang",
      "Wotao Yin",
      "Mingyi Hong",
      "Tianyi Chen"
    ]
  },
  "https://openreview.net/forum?id=epcLNhkoEL": {
    "title": "Fixed Budget Best Arm Identification in Unimodal Bandits",
    "volume": "main",
    "abstract": "We consider the best arm identification problem in a fixed budget stochastic multi-armed bandit in which arm means exhibit unimodal structure, i.e., there is only one local maximum. We establish that the probability of misidentifying the optimal arm within a budget of $T$ is lower bounded as $\\mathcal{O}\\left(\\exp\\left\\{-T/\\bar{H}\\right\\}\\right)$, where $\\bar{H}$ depends on the sub-optimality gaps of arms in the neighborhood of the optimal arm. % where $\\bar{H}\\leq 2\\Delta^{-2}$. In contrast to the lower bound for the unstructured case, the error exponent in this bound does not depend on the number of arms $K$ and is smaller by a factor $\\log K$, which captures the gain achievable by exploiting the unimodal structure. We then develop an algorithm named {\\it Fixed Budget Best Arm Unimodal Bandits ( FB-BAUB)} that exploits unimodality to achieve the gain. Specifically, we show that the error probability of \\algo{} is upper bounded as $\\mathcal{O}\\left(\\log_2 K\\exp\\left\\{-T\\Delta^2\\right\\}\\right)$, where $\\Delta$ is the gap between the neighboring arms and $\\bar{H}\\leq 2\\Delta^{-2}$. We demonstrate that \\algo{} outperforms the state-of-the-art algorithms through extensive simulations. Moreover, \\algo{} is parameter-free and simple to implement",
    "checked": true,
    "id": "d2ea6d9a81e1f3888bcd4b75e0a1d03f1785a205",
    "semantic_title": "fixed budget best arm identification in unimodal bandits",
    "citation_count": 0,
    "authors": [
      "Debamita Ghosh",
      "Manjesh Kumar Hanawal",
      "Nikola Zlatanov"
    ]
  },
  "https://openreview.net/forum?id=yf4ciZcgrg": {
    "title": "Restricted Random Pruning at Initialization for High Compression Range",
    "volume": "main",
    "abstract": "Pruning at Initialization (PaI) makes training overparameterized neural networks more efficient by reducing the overall computational cost from training to inference. Recent PaI studies showed that random pruning is more effective than ranking-based pruning, which learns connectivity. However, the effectiveness of each pruning method depends on the existence of skip connections and the compression ratio (the before-after pruning parameter ratio). While random pruning performs better than ranking-based pruning on architectures with skip connections, the superiority without skip connections is reversed in the high compression range. This paper proposes Minimum Connection Assurance (MiCA) that achieves higher accuracy than conventional PaI methods for architectures with and without skip connections, regardless of the compression ratio. MiCA preserves the random connection between the layers and maintains the performance at high compression ratios without the costly connection learning that ranking-based pruning requires. Experiments on image classification using CIFAR-10 and CIFAR-100 and node classification using OGBN-ArXiv show that MiCA enhances the compression ratio and accuracy trade-offs compared to existing PaI methods. In VGG-16 with CIFAR-10, MiCA improves the accuracy of random pruning by $27.0\\%$ at $10^{4.7}\\times$ compression ratio. Furthermore, experimental analysis reveals that increasing the utilization of the nodes through which information flows from the first layer is essential for maintaining high performance at a high compression ratio",
    "checked": true,
    "id": "f4d3e733d01ba0b5e1250551f43ce0117e8e15e3",
    "semantic_title": "restricted random pruning at initialization for high compression range",
    "citation_count": 0,
    "authors": [
      "Hikari Otsuka",
      "Yasuyuki Okoshi",
      "Ãngel LÃ³pez GarcÃ­a-Arias",
      "Kazushi Kawamura",
      "Thiem Van Chu",
      "Daichi Fujiki",
      "Masato Motomura"
    ]
  },
  "https://openreview.net/forum?id=zdtSqZnkx1": {
    "title": "Continual HyperTransformer: A Meta-Learner for Continual Few-Shot Learning",
    "volume": "main",
    "abstract": "We focus on the problem of learning without forgetting from multiple tasks arriving sequentially, where each task is defined using a few-shot episode of novel or already seen classes. We approach this problem using the recently published HyperTransformer (HT), a Transformer-based hypernetwork that generates specialized task-specific CNN weights directly from the support set. In order to learn from a continual sequence of tasks, we propose to recursively re-use the generated weights as input to the HT for the next task. This way, the generated CNN weights themselves act as a representation of previously learned tasks, and the HT is trained to update these weights so that the new task can be learned without forgetting past tasks. This approach is different from most continual learning algorithms that typically rely on using replay buffers, weight regularization or task-dependent architectural changes. We demonstrate that our proposed Continual HyperTransformer method equipped with a prototypical loss is capable of learning and retaining knowledge about past tasks for a variety of scenarios, including learning from mini-batches, and task-incremental and class-incremental learning scenarios",
    "checked": true,
    "id": "5b15258a0eaf0c8cee84141b328a8e03e2edf746",
    "semantic_title": "continual hypertransformer: a meta-learner for continual few-shot learning",
    "citation_count": 4,
    "authors": [
      "Max Vladymyrov",
      "Andrey Zhmoginov",
      "Mark Sandler"
    ]
  },
  "https://openreview.net/forum?id=qItxVbWyfe": {
    "title": "Federated Learning with Convex Global and Local Constraints",
    "volume": "main",
    "abstract": "In practice, many machine learning (ML) problems come with constraints, and their applied domains involve distributed sensitive data that cannot be shared with others, e.g., in healthcare. Collaborative learning in such practical scenarios entails federated learning (FL) for ML problems with constraints, or FL with constraints for short. Despite the extensive developments of FL techniques in recent years, these techniques only deal with unconstrained FL problems or FL problems with simple constraints that are amenable to easy projections. There is little work dealing with FL problems with general constraints. To fill this gap, we take the first step toward building an algorithmic framework for solving FL problems with general constraints. In particular, we propose a new FL algorithm for constrained ML problems based on the proximal augmented Lagrangian (AL) method. %The subproblems of our proposed algorithm are solved by an inexact alternating direction method of multipliers (ADMM). Assuming convex objective and convex constraints plus other mild conditions, we establish the worst-case complexity of the proposed algorithm. Our numerical experiments show the effectiveness of our algorithm in performing Neyman-Pearson classification and fairness-aware learning with nonconvex constraints, in an FL setting",
    "checked": true,
    "id": "2a97b84b77e1582ac1b6c04c73728b480d89c968",
    "semantic_title": "federated learning with convex global and local constraints",
    "citation_count": 1,
    "authors": [
      "Chuan He",
      "Le Peng",
      "Ju Sun"
    ]
  },
  "https://openreview.net/forum?id=cueEUSG7lE": {
    "title": "Group Fairness in Reinforcement Learning via Multi-Objective Rewards",
    "volume": "main",
    "abstract": "Recent works extend classification group fairness measures to sequential decision processes such as reinforcement learning (RL) by measuring fairness as the difference in decision-maker utility (e.g. accuracy) of each group. This approach suffers when decision-maker utility is not perfectly aligned with group utility, such as in repeat loan applications where a false positive (loan default) impacts the groups (applicants) and decision-maker (lender) by different magnitudes. Some works remedy this by measuring fairness in terms of group utility, typically referred to as their \"qualification\", but few works offer solutions that yield group qualification equality. Those that do are prone to violating the \"no-harm\" principle where one or more groups' qualifications are lowered in order to achieve equality. In this work, we characterize this problem space as having three implicit objectives: maximizing decision-maker utility, maximizing group qualification, and minimizing the difference in qualification between groups. We provide a RL policy learning technique that optimizes for these objectives directly by constructing a multi-objective reward function that encodes these objectives as distinct reward signals. Under suitable parameterizations our approach is guaranteed to respect the \"no-harm\" principle",
    "checked": true,
    "id": "ff29345e458bc21c55507e7db2d0e5649c176a2d",
    "semantic_title": "group fairness in reinforcement learning via multi-objective rewards",
    "citation_count": 2,
    "authors": [
      "Jack Blandin",
      "Ian A. Kash"
    ]
  },
  "https://openreview.net/forum?id=oyISaaeHwD": {
    "title": "On Good Practices for Task-Specific Distillation of Large Pretrained Visual Models",
    "volume": "main",
    "abstract": "Large pretrained visual models exhibit remarkable generalization across diverse recognition tasks. Yet, real-world applications often demand compact models tailored to specific problems. Variants of knowledge distillation have been devised for such a purpose, enabling task-specific compact models (the students) to learn from a generic large pretrained one (the teacher). In this paper, we show that the excellent robustness and versatility of recent pretrained models challenge common practices established in the literature, calling for a new set of optimal guidelines for task-specific distillation. To address the lack of samples in downstream tasks, we also show that a variant of Mixup based on stable diffusion complements standard data augmentation. This strategy eliminates the need for engineered text prompts and improves distillation of generic models into streamlined specialized networks",
    "checked": true,
    "id": "b168bd59ae55348b68ae4638e97be27cdd534120",
    "semantic_title": "on good practices for task-specific distillation of large pretrained visual models",
    "citation_count": 1,
    "authors": [
      "Juliette Marrie",
      "Michael Arbel",
      "Julien Mairal",
      "Diane Larlus"
    ]
  },
  "https://openreview.net/forum?id=aVOzWH1Nc5": {
    "title": "Dynamic Online Ensembles of Basis Expansions",
    "volume": "main",
    "abstract": "Practical Bayesian learning often requires (1) online inference, (2) dynamic models, and (3) ensembling over multiple different models. Recent advances have shown how to use random feature approximations to achieve scalable, online ensembling of Gaussian processes with desirable theoretical properties and fruitful applications. One key to these methods' success is the inclusion of a random walk on the model parameters, which makes models dynamic. We show that these methods can be generalized easily to any basis expansion model and that using alternative basis expansions, such as Hilbert space Gaussian processes, often results in better performance. To simplify the process of choosing a specific basis expansion, our method's generality also allows the ensembling of several entirely different models, for example, a Gaussian process and polynomial regression. Finally, we propose a novel method to ensemble static and dynamic models together",
    "checked": true,
    "id": "061122b4dbb461f2f6e32a8c499ba190d5f0b72a",
    "semantic_title": "dynamic online ensembles of basis expansions",
    "citation_count": 5,
    "authors": [
      "Daniel Waxman",
      "Petar Djuric"
    ]
  },
  "https://openreview.net/forum?id=p1a6ruIZCT": {
    "title": "IMEX-Reg: Implicit-Explicit Regularization in the Function Space for Continual Learning",
    "volume": "main",
    "abstract": "Continual learning (CL) remains one of the long-standing challenges for deep neural networks due to catastrophic forgetting of previously acquired knowledge. Although rehearsal-based approaches have been fairly successful in mitigating catastrophic forgetting, they suffer from overfitting on buffered samples and prior information loss, hindering generalization under low-buffer regimes. Inspired by how humans learn using strong inductive biases, we propose \\textbf{IMEX-Reg} to improve the generalization performance of experience rehearsal in CL under low buffer regimes. Specifically, we employ a two-pronged implicit-explicit regularization approach using contrastive representation learning (CRL) and consistency regularization. To further leverage the global relationship between representations learned using CRL, we propose a regularization strategy to guide the classifier toward the activation correlations in the unit hypersphere of the CRL. Our results show that IMEX-Reg significantly improves generalization performance and outperforms rehearsal-based approaches in several CL scenarios. It is also robust to natural and adversarial corruptions with less task-recency bias. Additionally, we provide theoretical insights to support our design decisions further",
    "checked": true,
    "id": "bafbf52e99050d485399daae86c53f302d3e6293",
    "semantic_title": "imex-reg: implicit-explicit regularization in the function space for continual learning",
    "citation_count": 4,
    "authors": [
      "Prashant Shivaram Bhat",
      "Bharath Chennamkulam Renjith",
      "Elahe Arani",
      "Bahram Zonooz"
    ]
  },
  "https://openreview.net/forum?id=KleJZ9ZzYw": {
    "title": "DP-ImgSyn: Dataset Alignment for Obfuscated, Differentially Private Image Synthesis",
    "volume": "main",
    "abstract": "The availability of abundant data has catalyzed the expansion of deep learning vision algorithms. However, certain vision datasets cannot be publicly released due to privacy reasons. Releasing synthetic images instead of private images is a common approach to overcome this issue. A popular method to generate synthetic images is using Generative Adversarial Networks (GANs) with Differential Privacy (DP) guarantees. However, GAN-generated synthetic images are visually similar to private images. This is a severe limitation, particularly when the private dataset depicts visually sensitive and disturbing content. To address this, we propose a non-generative framework, Differentially Private Image Synthesis (DP-ImgSyn), to generate and release synthetic images for image classification tasks. These synthetic images: (1) have DP guarantees, (2) retain the utility of the private images, i.e., a model trained using synthetic images results in similar accuracy as a model trained on private images, (3) the synthetic images are visually dissimilar to private images. DP-ImgSyn consists of the following steps: First, a teacher model is trained on the private images using a DP training algorithm. Second, public images are used as initialization for the synthetic images which are optimized to align them with the private images. The optimization uses the teacher network's batch normalization layer statistics (mean, standard deviation) to inject information about the private images into the synthetic images. Third, the synthetic images and their soft labels, obtained from the teacher model, are released and can be deployed for neural network training on image classification tasks. Our experiments on various image classification datasets show that when using similar DP training mechanisms, our framework performs better than generative techniques (up to $\\approx$ 20% in terms of image classification accuracy)",
    "checked": true,
    "id": "a3fc1f7828da75fe1f15893314790bc702f7cea5",
    "semantic_title": "dp-imgsyn: dataset alignment for obfuscated, differentially private image synthesis",
    "citation_count": 0,
    "authors": [
      "Efstathia Soufleri",
      "Deepak Ravikumar",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=WYGiqSVstK": {
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "volume": "main",
    "abstract": "Visual reasoning is dominated by end-to-end neural networks scaled to billions of model parameters and training examples. However, even the largest models struggle with compositional reasoning, generalization, fine-grained spatial and temporal reasoning, and counting. Visual reasoning with large language models (LLMs) as controllers can, in principle, address these limitations by decomposing the task and solving subtasks by orchestrating a set of (visual) tools. Recently, these models achieved great performance on tasks such as compositional visual question answering, visual grounding, and video temporal reasoning. Nevertheless, in their current form, these models heavily rely on human engineering of in-context examples in the prompt, which are often dataset- and task-specific and require significant labor by highly skilled programmers. In this work, we present a framework that mitigates these issues by introducing spatially and temporally abstract routines and by leveraging a small number of labeled examples to automatically generate in-context examples, thereby avoiding human-created in-context examples. On a number of visual reasoning tasks, we show that our framework leads to consistent gains in performance, makes LLMs as controllers setup more robust, and removes the need for human engineering of in-context examples",
    "checked": true,
    "id": "fc7feeaddc5a38c0d6f0d793737584e5f0bb7519",
    "semantic_title": "towards truly zero-shot compositional visual reasoning with llms as programmers",
    "citation_count": 10,
    "authors": [
      "Aleksandar StaniÄ",
      "Sergi Caelles",
      "Michael Tschannen"
    ]
  },
  "https://openreview.net/forum?id=Wiklo5VpG7": {
    "title": "From Stability to Chaos: Analyzing Gradient Descent Dynamics in Quadratic Regression",
    "volume": "main",
    "abstract": "We conduct a comprehensive investigation into the dynamics of gradient descent using large-order constant step-sizes in the context of quadratic regression models. Within this framework, we reveal that the dynamics can be encapsulated by a specific cubic map, naturally parameterized by the step-size. Through a fine-grained bifurcation analysis concerning the step-size parameter, we delineate five distinct training phases: (1) monotonic, (2) catapult, (3) periodic, (4) chaotic, and (5) divergent, precisely demarcating the boundaries of each phase. As illustrations, we provide examples involving phase retrieval and two-layer neural networks employing quadratic activation functions and constant outer-layers, utilizing orthogonal training data. Our simulations indicate that these five phases also manifest with generic non-orthogonal data. We also empirically investigate the generalization performance when training in the various non-monotonic (and non-divergent) phases. In particular, we observe that performing an ergodic trajectory averaging stabilizes the test error in non-monotonic (and non-divergent) phases",
    "checked": true,
    "id": "909f003b8f56302b2fe0594b93048bdc88d0ce59",
    "semantic_title": "from stability to chaos: analyzing gradient descent dynamics in quadratic regression",
    "citation_count": 8,
    "authors": [
      "Xuxing Chen",
      "Krishna Balasubramanian",
      "Promit Ghosal",
      "Bhavya Kumar Agrawalla"
    ]
  },
  "https://openreview.net/forum?id=Io3jDUC4DP": {
    "title": "Using Skew to Assess the Quality of GAN-generated Image Features",
    "volume": "main",
    "abstract": "The rapid advancement of Generative Adversarial Networks (GANs) necessitates the need to robustly evaluate these models. Among the established evaluation criteria, the FrÃ©chet Inception Distance (FID) has been widely adopted due to its conceptual simplicity, fast computation time, and strong correlation with human perception. However, FID has inherent limitations, mainly stemming from its assumption that feature embeddings follow a Gaussian distribution, and therefore can be defined by their first two moments. As this does not hold in practice, in this paper we explore the importance of third-moments in image feature data and use this information to define a new measure, which we call the Skew Inception Distance (SID). We prove that SID is a pseudometric on probability distributions, show how it extends FID, and present a practical method for its computation. Our numerical experiments support that SID either tracks with FID or, in some cases, aligns more closely with human perception when evaluating image features of ImageNet data. Our work also shows that principal component analysis can be used to speed up the computation time of both FID and SID. Although we focus on using SID on image features for GAN evaluation, SID is applicable much more generally, including for the evaluation of other generative models",
    "checked": true,
    "id": "a1fbb3888406c6e9563c873602d104a5b0db705b",
    "semantic_title": "using skew to assess the quality of gan-generated image features",
    "citation_count": 0,
    "authors": [
      "Lorenzo Luzi",
      "Helen Jenne",
      "Carlos Ortiz Marrero",
      "Ryan Murray"
    ]
  },
  "https://openreview.net/forum?id=raD846nj2q": {
    "title": "Identify Ambiguous Tasks Combining Crowdsourced Labels by Weighting Areas Under the Margin",
    "volume": "main",
    "abstract": "In supervised learning â for instance in image classification â modern massive datasets are commonly labeled by a crowd of workers. The obtained labels in this crowdsourcing setting are then aggregated for training, generally leveraging a per-worker trust score. Yet, such workers oriented approaches discard the tasks' ambiguity. Ambiguous tasks might fool expert workers, which is often harmful for the learning step. In standard supervised learning settings -- with one label per task -- the Area Under the Margin (AUM) was tailored to identify mislabeled data. We adapt the AUM to identify ambiguous tasks in crowdsourced learning scenarios, introducing the Weighted Areas Under the Margin (WAUM). The WAUM is an average of AUMs weighted according to task-dependent scores. We show that the WAUM can help discarding ambiguous tasks from the training set, leading to better generalization performance. We report improvements over existing strategies for learning with a crowd, both on simulated settings, and on real datasets such as CIFAR-10H (a crowdsourced dataset with a high number of answered labels), LabelMe and Music (two datasets with few answered votes)",
    "checked": true,
    "id": "fa9aac3c7aba3ad4b2162c7ec2e0ad8ef4668005",
    "semantic_title": "identify ambiguous tasks combining crowdsourced labels by weighting areas under the margin",
    "citation_count": 5,
    "authors": [
      "Tanguy Lefort",
      "Benjamin Charlier",
      "Alexis Joly",
      "Joseph Salmon"
    ]
  },
  "https://openreview.net/forum?id=mrJi5kdKA4": {
    "title": "DSI2I: Dense Style for Unpaired Exemplar-based Image-to- Image Translation",
    "volume": "main",
    "abstract": "Unpaired exemplar-based image-to-image (UEI2I) translation aims to translate a source image to a target image domain with the style of a target image exemplar, without ground- truth input-translation pairs. Existing UEI2I methods represent style using one vector per image or rely on semantic supervision to define one style vector per object. Here, in contrast, we propose to represent style as a dense feature map, allowing for a finer-grained transfer to the source image without requiring any external semantic information. We then rely on perceptual and adversarial losses to disentangle our dense style and content representations. To stylize the source content with the exemplar style, we extract unsupervised cross-domain semantic correspondences and warp the exemplar style to the source content. We demon- strate the effectiveness of our method on four datasets using standard metrics together with a localized style metric we propose, which measures style similarity in a class-wise man- ner. Our results show that the translations produced by our approach are more diverse, preserve the source content better, and are closer to the exemplars when compared to the state-of-the-art methods",
    "checked": true,
    "id": "7faf3ccdc3d3f80dcf4a4a21df4bfe8efa962c4d",
    "semantic_title": "dsi2i: dense style for unpaired exemplar-based image-to- image translation",
    "citation_count": 1,
    "authors": [
      "Baran Ozaydin",
      "Tong Zhang",
      "Sabine Susstrunk",
      "Mathieu Salzmann"
    ]
  },
  "https://openreview.net/forum?id=yL15ys5swq": {
    "title": "Improving Diffusion Models for Scene Text Editing with Dual Encoders",
    "volume": "main",
    "abstract": "Scene text editing is a challenging task that involves modifying or inserting specified texts in an image while maintaining its natural and realistic appearance. Most previous approaches to this task rely on style-transfer models that crop out text regions and feed them into image transfer models, such as GANs. However, these methods are limited in their ability to change text style and are unable to insert texts into images. Recent advances in diffusion models have shown promise in overcoming these limitations with text-conditional image editing. However, our empirical analysis reveals that state-of-the-art diffusion models struggle with rendering correct text and controlling text style. To address these problems, we propose DIFFSTE to improve pre-trained diffusion models with a dual encoder design, which includes a character encoder for better text legibility and an instruction encoder for better style control. An instruction tuning framework is introduced to train our model to learn the mapping from the text instruction to the corresponding image with either the specified style or the style of the surrounding texts in the background. Such a training method further brings our method the zero-shot generalization ability to the following three scenarios: generating text with unseen font variation, e.g., italic and bold, mixing different fonts to construct a new font, and using more relaxed forms of natural language as the instructions to guide the generation task. We evaluate our approach on five datasets and demonstrate its superior performance in terms of text correctness, image naturalness, and style controllability",
    "checked": true,
    "id": "a820ba23594ba25d1db21116ddb5a55c806ee30a",
    "semantic_title": "improving diffusion models for scene text editing with dual encoders",
    "citation_count": 31,
    "authors": [
      "Jiabao Ji",
      "Guanhua Zhang",
      "Zhaowen Wang",
      "Bairu Hou",
      "Zhifei Zhang",
      "Brian L. Price",
      "Shiyu Chang"
    ]
  },
  "https://openreview.net/forum?id=ongi2oe3Fr": {
    "title": "Continuous U-Net: Faster, Greater and Noiseless",
    "volume": "main",
    "abstract": "Image segmentation is a fundamental task in image analysis and clinical practice. The current state-of-the-art techniques are based on U-shape type encoder-decoder networks with skip connections called U-Net. Despite the powerful performance reported by existing U-Net type networks, they suffer from several major limitations. These issues include the hard coding of the receptive field size, compromising the performance and computational cost, as well as the fact that they do not account for inherent noise in the data. They have problems associated with discrete layers, and do not offer any theoretical underpinning. In this work we introduce continuous U-Net, a novel family of networks for image segmentation. Firstly, continuous U-Net is a continuous deep neural network that introduces new dynamic blocks modelled by second order ordinary differential equations. Secondly, we provide theoretical guarantees for our network demonstrating faster convergence, higher robustness and less sensitivity to noise. Thirdly, we derive qualitative measures to tailor-made segmentation tasks. We demonstrate, through extensive numerical and visual results, that our model outperforms existing U-Net blocks for several medical image segmentation benchmarking datasets",
    "checked": true,
    "id": "798ac4aac5175b453cb9f00b34b2574167ca6b7b",
    "semantic_title": "continuous u-net: faster, greater and noiseless",
    "citation_count": 10,
    "authors": [
      "Chun-Wun Cheng",
      "Christina Runkel",
      "Lihao Liu",
      "Raymond H. Chan",
      "Carola-Bibiane SchÃ¶nlieb",
      "Angelica I Aviles-Rivero"
    ]
  },
  "https://openreview.net/forum?id=hw7inQwRxB": {
    "title": "Decentralized Decoupled Training for Federated Long-Tailed Learning",
    "volume": "main",
    "abstract": "In the real world, the data samples often follow a long-tailed distribution, which poses a great challenge for Federated Learning (FL). That is, when the data is decentralized and long-tailed, FL may produce a poorly-behaved global model that is severely biased towards the head classes with the majority of the training samples. To settle this issue, decoupled training has recently been introduced to FL. Decoupled training aims to re-balance the biased classifier after the normal instance-balanced training, and has achieved promising results in centralized long-tailed learning. The current study directly adopts the decoupled training idea on the server side by re-training the classifier on a set of pseudo features, due to the unavailability of a global balanced dataset in FL. Unfortunately, this practice restricts the capacity of decoupled training in federated long-tailed learning as the low-quality pseudo features lead to a sub-optimal classifier. In this work, motivated by the distributed characteristic of FL, we propose a decentralized decoupled training mechanism by leveraging the abundant real data stored in the local. Specifically, we integrate the local real data with the global gradient prototypes to form the local balanced datasets, and thus re-balance the classifier during the local training. Furthermore, we introduce a supplementary classifier in the training phase to help model the global data distribution, which addresses the problem of contradictory optimization goals caused by performing classifier re-balancing locally. Extensive experiments show that our method consistently outperforms the existing state-of-the-art methods in various settings. Our code is available at https://github.com/keven980716/Federated_Learning_Experiments",
    "checked": true,
    "id": "61f7cd4f6ff77a4c5b90e96d1e4e9402e1e27e1b",
    "semantic_title": "decentralized decoupled training for federated long-tailed learning",
    "citation_count": 1,
    "authors": [
      "Wenkai Yang",
      "Deli Chen",
      "Hao Zhou",
      "Fandong Meng",
      "Jie Zhou",
      "Xu Sun"
    ]
  },
  "https://openreview.net/forum?id=bzTfO4mURl": {
    "title": "FedConv: Enhancing Convolutional Neural Networks for Handling Data Heterogeneity in Federated Learning",
    "volume": "main",
    "abstract": "Federated learning (FL) is an emerging paradigm in machine learning, where a shared model is collaboratively learned using data from multiple devices to mitigate the risk of data leakage. While recent studies posit that Vision Transformer (ViT) outperforms Convolutional Neural Networks (CNNs) in addressing data heterogeneity in FL, the specific architectural components that underpin this advantage have yet to be elucidated. In this paper, we systematically investigate the impact of different architectural elements, such as activation functions and normalization layers, on the performance within heterogeneous FL. Through rigorous empirical analyses, we are able to offer the first-of-its-kind general guidance on micro-architecture design principles for heterogeneous FL. Intriguingly, our findings indicate that with strategic architectural modifications, pure CNNs can achieve a level of robustness that either matches or even exceeds that of ViTs when handling heterogeneous data clients in FL. Additionally, our approach is compatible with existing FL techniques and delivers state-of-the-art solutions across a broad spectrum of FL benchmarks",
    "checked": true,
    "id": "428832c52f141b2d6efcc58d118d5f7e661b4b7e",
    "semantic_title": "fedconv: enhancing convolutional neural networks for handling data heterogeneity in federated learning",
    "citation_count": 1,
    "authors": [
      "Peiran Xu",
      "Zeyu Wang",
      "Jieru Mei",
      "Liangqiong Qu",
      "Alan Yuille",
      "Cihang Xie",
      "Yuyin Zhou"
    ]
  },
  "https://openreview.net/forum?id=Egb0tUZnOY": {
    "title": "Understanding Sparse Neural Networks from their Topology via Multipartite Graph Representations",
    "volume": "main",
    "abstract": "Pruning-at-Initialization (PaI) algorithms provide Sparse Neural Networks (SNNs) which are computationally more efficient than their dense counterparts, and try to avoid performance degradation. While much emphasis has been directed towards \\emph{how} to prune, we still do not know \\emph{what topological metrics} of the SNNs characterize \\emph{good performance}. From prior work, we have layer-wise topological metrics by which SNN performance can be predicted: the Ramanujan-based metrics. To exploit these metrics, proper ways to represent network layers via Graph Encodings (GEs) are needed, with Bipartite Graph Encodings (BGEs) being the \\emph{de-facto} standard at the current stage. Nevertheless, existing BGEs neglect the impact of the inputs, and do not characterize the SNN in an end-to-end manner. Additionally, thanks to a thorough study of the Ramanujan-based metrics, we discover that they are only as good as the \\emph{layer-wise density} as performance predictors, when paired with BGEs. To close both gaps, we design a comprehensive topological analysis for SNNs with both linear and convolutional layers, via (i) a new input-aware Multipartite Graph Encoding (MGE) for SNNs and (ii) the design of new end-to-end topological metrics over the MGE. With these novelties, we show the following: (a) The proposed MGE allows to extract topological metrics that are much better predictors of the accuracy drop than metrics computed from current input-agnostic BGEs; (b) Which metrics are important at different sparsity levels and for different architectures; (c) A mixture of our topological metrics can rank PaI algorithms more effectively than Ramanujan-based metrics",
    "checked": true,
    "id": "1b7c102ec84a2753c97adbe8f701a8a929b7423d",
    "semantic_title": "understanding sparse neural networks from their topology via multipartite graph representations",
    "citation_count": 1,
    "authors": [
      "Elia Cunegatti",
      "Matteo Farina",
      "Doina Bucur",
      "Giovanni Iacca"
    ]
  },
  "https://openreview.net/forum?id=m1OXBLH0dH": {
    "title": "Stochastic Direct Search Methods for Blind Resource Allocation",
    "volume": "main",
    "abstract": "Motivated by programmatic advertising optimization, we consider the task of sequentially allocating budget across a set of resources. At every time step, a feasible allocation is chosen and only a corresponding random return is observed. The goal is to maximize the cumulative expected sum of returns. This is a realistic model for budget allocation across subdivisions of marketing campaigns, with the objective of maximizing the number of conversions. We study direct search (also known as pattern search) methods for linearly constrained and derivative-free optimization in the presence of noise, which apply in particular to sequential budget allocation. These algorithms, which do not rely on hierarchical partitioning of the resource space, are easy to implement; they respect the operational constraints of resource allocation by avoiding evaluation outside of the feasible domain; and, they are also compatible with warm start by being (approximate) descent algorithms. However, they have not yet been analyzed from the perspective of cumulative regret. We show that direct search methods achieves finite regret in the deterministic and unconstrained case. In the presence of evaluation noise and linear constraints, we propose a simple extension of direct search that achieves a regret upper-bound of the order of $T^{2/3}$. We also propose an accelerated version of the algorithm, relying on repeated sequential testing, that significantly improves the practical behavior of the approach",
    "checked": true,
    "id": "68d80631b70cfa32839fa39eb1de1f90f54cac8e",
    "semantic_title": "stochastic direct search methods for blind resource allocation",
    "citation_count": 0,
    "authors": [
      "Juliette Achddou",
      "Olivier CappÃ©",
      "AurÃ©lien Garivier"
    ]
  },
  "https://openreview.net/forum?id=aHk3vctnf1": {
    "title": "Routers in Vision Mixture of Experts: An Empirical Study",
    "volume": "main",
    "abstract": "Mixture-of-Experts (MoE) models are a promising way to scale up model capacity without significantly increasing computational cost. A key component of MoEs is the router, which decides which subset of parameters (experts) process which feature embeddings (tokens). In this paper, we present a comprehensive study of routers in MoEs for computer vision tasks. We introduce a unified MoE formulation that subsumes different MoEs with two parametric routing tensors. This formulation covers both sparse MoE, which uses a binary or hard assignment between experts and tokens, and soft MoE, which uses a soft assignment between experts and weighted combinations of tokens. Routers for sparse MoEs can be further grouped into two variants: Token Choice, which matches experts to each token, and Expert Choice, which matches tokens to each expert. We conduct head-to-head experiments with 6 different routers, including existing routers from prior work and new ones we introduce. We show that (i) many routers originally developed for language modeling can be adapted to perform strongly in vision tasks, (ii) in sparse MoE, Expert Choice routers generally outperform Token Choice routers, and (iii) soft MoEs generally outperform sparse MoEs with a fixed compute budget. These results provide new insights regarding the crucial role of routers in vision MoE models",
    "checked": true,
    "id": "a12bc2ddaa3a91edab682f6822e381ce9323e8fc",
    "semantic_title": "routers in vision mixture of experts: an empirical study",
    "citation_count": 3,
    "authors": [
      "Tianlin Liu",
      "Mathieu Blondel",
      "Carlos Riquelme Ruiz",
      "Joan Puigcerver"
    ]
  },
  "https://openreview.net/forum?id=6rWuWbVmgz": {
    "title": "Sketch and shift: a robust decoder for compressive clustering",
    "volume": "main",
    "abstract": "Compressive learning is an emerging approach to drastically reduce the memory footprint of large-scale learning, by first summarizing a large dataset into a low-dimensional sketch vector, and then decoding from this sketch the latent information needed for learning. In light of recent progress on information preservation guarantees for sketches based on random features, a major objective is to design easy-to-tune algorithms (called decoders) to robustly and efficiently extract this information. To address the underlying non-convex optimization problems, various heuristics have been proposed. In the case of compressive clustering, the standard heuristic is CL-OMPR, a variant of sliding Frank-Wolfe. Yet, CL-OMPR is hard to tune, and the examination of its robustness was overlooked. In this work, we undertake a scrutinized examination of CL-OMPR to circumvent its limitations. In particular, we show how this algorithm can fail to recover the clusters even in advantageous scenarios. To gain insight, we show how the deficiencies of this algorithm can be attributed to optimization difficulties related to the structure of a correlation function appearing at core steps of the algorithm. To address these limitations, we propose an alternative decoder offering substantial improvements over CL-OMPR. Its design is notably inspired from the mean shift algorithm, a classic approach to detect the local maxima of kernel density estimators. The proposed algorithm can extract clustering information from a sketch of the MNIST dataset that is 10 times smaller than previously",
    "checked": true,
    "id": "93cbc331e39c2e2c89db51cb362e969fa7c4ed29",
    "semantic_title": "sketch and shift: a robust decoder for compressive clustering",
    "citation_count": 2,
    "authors": [
      "Ayoub Belhadji",
      "RÃ©mi Gribonval"
    ]
  },
  "https://openreview.net/forum?id=y9IDfODRns": {
    "title": "Inference from Real-World Sparse Measurements",
    "volume": "main",
    "abstract": "Real-world problems often involve complex and unstructured sets of measurements, which occurs when sensors are sparsely placed in either space or time. Being able to model this irregular spatiotemporal data and extract meaningful forecasts is crucial. Deep learning architectures capable of processing sets of measurements with positions varying from set to set, and extracting readouts anywhere are methodologically difficult. Current state-of-the-art models are graph neural networks and require domain-specific knowledge for proper setup. We propose an attention-based model focused on robustness and practical applicability, with two key design contributions. First, we adopt a ViT-like transformer that takes both context points and read-out positions as inputs, eliminating the need for an encoder-decoder structure. Second, we use a unified method for encoding both context and read-out positions. This approach is intentionally straightforward and integrates well with other systems. Compared to existing approaches, our model is simpler, requires less specialized knowledge, and does not suffer from a problematic bottleneck effect, all of which contribute to superior performance. We conduct in-depth ablation studies that characterize this problematic bottleneck in the latent representations of alternative models that inhibit information utilization and impede training efficiency. We also perform experiments across various problem domains, including high-altitude wind nowcasting, two-day weather forecasting, fluid dynamics, and heat diffusion. Our attention-based model consistently outperforms state-of-the-art models in handling irregularly sampled data. Notably, our model reduces the root mean square error (RMSE) for wind nowcasting from 9.24 to 7.98 and for heat diffusion tasks from 0.126 to 0.084",
    "checked": true,
    "id": "3b758b93b682328168265bcbe49f857d17bd1bc3",
    "semantic_title": "inference from real-world sparse measurements",
    "citation_count": 0,
    "authors": [
      "Arnaud Pannatier",
      "Kyle Matoba",
      "FranÃ§ois Fleuret"
    ]
  },
  "https://openreview.net/forum?id=z5AXLMBWdU": {
    "title": "Semantic Positive Pairs for Enhancing Visual Representation Learning of Instance Discrimination Methods",
    "volume": "main",
    "abstract": "Self-supervised learning algorithms (SSL) based on instance discrimination have shown promising results, performing competitively or even outperforming supervised learning counterparts in some downstream tasks. Such approaches employ data augmentation to create two views of the same instance (i.e., positive pairs) and encourage the model to learn good representations by attracting these views closer in the embedding space without collapsing to the trivial solution. However, data augmentation is limited in representing positive pairs, and the repulsion process between the instances during contrastive learning may discard important features for instances that have similar categories. To address this issue, we propose an approach to identify those images with similar semantic content and treat them as positive instances, thereby reducing the chance of discarding important features during representation learning and increasing the richness of the latent representation. Our approach is generic and could work with any self-supervised instance discrimination frameworks such as MoCo and SimSiam. To evaluate our method, we run experiments on three benchmark datasets: ImageNet, STL-10 and CIFAR-10 with different instance discrimination SSL approaches. The experimental results show that our approach consistently outperforms the baseline methods across all three datasets; for instance, we improve upon the vanilla MoCo-v2 by 4.1% on ImageNet under a linear evaluation protocol over 800 epochs. We also report results on semi-supervised learning, transfer learning on downstream tasks, and object detection",
    "checked": true,
    "id": "3f111aeefd8fbf3f6e0765ee11cbc1a7a8526c16",
    "semantic_title": "semantic positive pairs for enhancing visual representation learning of instance discrimination methods",
    "citation_count": 2,
    "authors": [
      "Mohammad Alkhalefi",
      "Georgios Leontidis",
      "Mingjun Zhong"
    ]
  },
  "https://openreview.net/forum?id=Ew73inSyhG": {
    "title": "What do larger image classifiers memorise?",
    "volume": "main",
    "abstract": "The success of modern neural networks has prompted study of the connection between memorisation and generalisation: overparameterised models generalise well, despite being able to perfectly fit (\"memorise\") completely random labels. To carefully study this issue, Feldman (2019) proposed a metric to quantify the degree of memorisation of individual training examples, and empirically computed the corresponding memorisation profile of a ResNet on image classification benchmarks. While an exciting first glimpse into what real-world models memorise, this leaves open a fundamental question: do larger neural models memorise more? This aligns with the common practice of training models of different sizes, each offering different cost-quality trade-offs: while larger models are typically observed to have higher quality, it is of interest to understand whether this is merely a consequence of them memorising larger numbers of input-output patterns. We present a comprehensive empirical analysis of this question on image classification benchmarks. We find that training examples exhibit an unexpectedly diverse set of memorisation trajectories across model sizes: most samples experienced decreased memorisation under larger models, while the rest exhibit cap-shaped or increasing memorisation. We show that various proxies for the Feldman(2019) memorisation score fail to capture these fundamental trends. Lastly, we find that knowledge distillation â an effective and popular model compression technique â tends to inhibit memorisation, while also improving generalisation. Specifically, memorisation is mostly inhibited on examples with increasing memorisation trajectories, thus pointing at how distillation improves generalisation",
    "checked": true,
    "id": "3e5e8d3e149049e3b04d42ccdb80596189f21ca3",
    "semantic_title": "what do larger image classifiers memorise?",
    "citation_count": 5,
    "authors": [
      "Michal Lukasik",
      "Vaishnavh Nagarajan",
      "Ankit Singh Rawat",
      "Aditya Krishna Menon",
      "Sanjiv Kumar"
    ]
  },
  "https://openreview.net/forum?id=PtBzWCaCYB": {
    "title": "Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes",
    "volume": "main",
    "abstract": "Sparse variational approximations are popular methods for scaling up inference and learning in Gaussian processes to larger datasets. For $N$ training points, exact inference has $O(N^3)$ cost; with $M \\ll N$ features, state of the art sparse variational methods have $O(NM^2)$ cost. Recently, methods have been proposed using more sophisticated features; these promise $O(M^3)$ cost, with good performance in low dimensional tasks such as spatial modelling, but they only work with a very limited class of kernels, excluding some of the most commonly used. In this work, we propose integrated Fourier features, which extends these performance benefits to a very broad class of stationary covariance functions. We motivate the method and choice of parameters from a convergence analysis and empirical exploration, and show practical speedup in synthetic and real world spatial regression tasks",
    "checked": true,
    "id": "3b0f66f2cd56bec2d0bf1e79f47b4f909a8c5c42",
    "semantic_title": "integrated variational fourier features for fast spatial modelling with gaussian processes",
    "citation_count": 2,
    "authors": [
      "Talay M Cheema",
      "Carl Edward Rasmussen"
    ]
  },
  "https://openreview.net/forum?id=P1vzXDklar": {
    "title": "Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations",
    "volume": "main",
    "abstract": "We introduce a novel modeling approach for time series imputation and forecasting, tailored to address the challenges often encountered in real-world data, such as irregular samples, missing data, or unaligned measurements from multiple sensors. Our method relies on a continuous-time-dependent model of the series' evolution dynamics. It leverages adaptations of conditional, implicit neural representations for sequential data. A modulation mechanism, driven by a meta-learning algorithm, allows adaptation to unseen samples and extrapolation beyond observed time-windows for long-term predictions. The model provides a highly flexible and unified framework for imputation and forecasting tasks across a wide range of challenging scenarios. It achieves state-of-the-art performance on classical benchmarks and outperforms alternative time-continuous models",
    "checked": true,
    "id": "ee190efa2896b59c80c820aa6dcc8e75d33182be",
    "semantic_title": "time series continuous modeling for imputation and forecasting with implicit neural representations",
    "citation_count": 11,
    "authors": [
      "Etienne Le Naour",
      "Louis Serrano",
      "LÃ©on Migus",
      "Yuan Yin",
      "Ghislain Agoua",
      "Nicolas Baskiotis",
      "patrick gallinari",
      "Vincent Guigue"
    ]
  },
  "https://openreview.net/forum?id=tP1PBrMUlX": {
    "title": "Synthesizing Libraries of Programs with Auxiliary Functions",
    "volume": "main",
    "abstract": "A common approach to program synthesis is to use a learned function to guide the search for a program that satisfies the user's intent. In this paper, we propose a method that offers search guidance, through a domain-dependent auxiliary function, that can be orthogonal to the guidance previous functions provide. Our method, which we call Auxiliary-Based Library Learning (Aulile), searches for a solution in the program space using a base algorithm. If this search does not produce a solution, Aulile enhances the language with a library of programs discovered in the search that optimizes for the auxiliary function. Then, it repeats the search with this library-augmented language. This process is repeated until a solution is found or the system reaches a timeout. We evaluate Aulile in string manipulation tasks. Aulile improved, in some cases by a large margin, the performance of several base algorithms that use different search and learning strategies: Bus, Bustle, Crossbeam, and Bee Search. Our results suggest that Aulile offers an effective method of injecting domain knowledge into existing systems through a library learning scheme that optimizes for an auxiliary function",
    "checked": true,
    "id": "88c9abaedb1997b0b3cd52362d48289f4f04f8fd",
    "semantic_title": "synthesizing libraries of programs with auxiliary functions",
    "citation_count": 1,
    "authors": [
      "Habibur Rahman",
      "Thirupathi Reddy Emireddy",
      "Kenneth Tjhia",
      "Elham Parhizkar",
      "Levi Lelis"
    ]
  },
  "https://openreview.net/forum?id=4KLwep6mA1": {
    "title": "Choosing Wisely and Learning Deeply: Selective Cross-Modality Distillation via CLIP for Domain Generalization",
    "volume": "main",
    "abstract": "Domain Generalization (DG), a crucial research area, seeks to train models across multiple domains and test them on unseen ones. In this paper, we introduce a novel approach, namely, Selective Cross-Modality Distillation for Domain Generalization (SCMD). SCMD leverages the capabilities of large vision-language models, specifically CLIP, to train a more efficient model, ensuring it acquires robust generalization capabilities across unseen domains. Our primary contribution is a unique selection framework strategically designed to identify hard-to-learn samples for distillation. In parallel, we introduce a novel cross-modality module that seamlessly combines the projected features of the student model with the text embeddings from CLIP, ensuring the alignment of similarity distributions. We assess SCMD's performance on various benchmarks, where it empowers a ResNet50 to deliver state-of-the-art performance, surpassing existing domain generalization methods. Furthermore, we provide a theoretical analysis of our selection strategy, offering deeper insight into its effectiveness and potential in the field of DG",
    "checked": true,
    "id": "bd259204065d95e510dbfbb1dc15e967f2c5746e",
    "semantic_title": "choosing wisely and learning deeply: selective cross-modality distillation via clip for domain generalization",
    "citation_count": 0,
    "authors": [
      "Jixuan Leng",
      "Yijiang Li",
      "Haohan Wang"
    ]
  },
  "https://openreview.net/forum?id=EBNJ33Fcrl": {
    "title": "Anticipatory Music Transformer",
    "volume": "main",
    "abstract": "We introduce anticipation: a method for constructing a controllable generative model of a temporal point process (the event process) conditioned asynchronously on realizations of a second, correlated process (the control process). We achieve this by interleaving sequences of events and controls, such that controls appear following stopping times in the event sequence. This work is motivated by problems arising in the control of symbolic music generation. We focus on infilling control tasks, whereby the controls are a subset of the events themselves, and conditional generation completes a sequence of events given the fixed control events. We train anticipatory infilling models using the large and diverse Lakh MIDI music dataset. These models match the performance of autoregressive models for prompted generation, with the additional capability to perform infilling control tasks, including accompaniment. Human evaluators report that an anticipatory model produces accompaniments with similar musicality to even music composed by humans over a 20-second clip",
    "checked": true,
    "id": "ba3adfca2d111a5d61ad928a214c4715e3470d50",
    "semantic_title": "anticipatory music transformer",
    "citation_count": 16,
    "authors": [
      "John Thickstun",
      "David Leo Wright Hall",
      "Chris Donahue",
      "Percy Liang"
    ]
  },
  "https://openreview.net/forum?id=ZFZnvGXXMm": {
    "title": "Fooling Contrastive Language-Image Pre-Trained Models with CLIPMasterPrints",
    "volume": "main",
    "abstract": "Models leveraging both visual and textual data such as Contrastive Language-Image Pre-training (CLIP), are the backbone of many recent advances in artificial intelligence. In this work, we show that despite their versatility, such models are vulnerable to what we refer to as fooling master images. Fooling master images are capable of maximizing the confidence score of a CLIP model for a significant number of widely varying prompts, while being either unrecognizable or unrelated to the attacked prompts for humans. We demonstrate how fooling master images can be mined using stochastic gradient descent, projected gradient descent, or gradient-free optimisation. Contrary to many common adversarial attacks, the gradient-free optimisation approach allows us to mine fooling examples even when the weights of the model are not accessible. We investigate the properties of the mined fooling master images, and find that images trained on a small number of image captions potentially generalize to a much larger number of semantically related captions. Finally, we evaluate possible mitigation strategies and find that vulnerability to fooling master examples appears to be closely related to a modality gap in contrastive pre-trained multi-modal networks",
    "checked": true,
    "id": "cfc208f167e1a4b6390e1732bda6f320a7cca28d",
    "semantic_title": "fooling contrastive language-image pre-trained models with clipmasterprints",
    "citation_count": 2,
    "authors": [
      "Matthias Freiberger",
      "Peter Kun",
      "Christian Igel",
      "Anders Sundnes LÃ¸vlie",
      "Sebastian Risi"
    ]
  },
  "https://openreview.net/forum?id=QSvb6jBXML": {
    "title": "ZigZag: Universal Sampling-free Uncertainty Estimation Through Two-Step Inference",
    "volume": "main",
    "abstract": "Whereas the ability of deep networks to produce useful predictions on many kinds of data has been amply demonstrated, estimating the reliability of these predictions remains challenging. Sampling approaches such as MC-Dropout and Deep Ensembles have emerged as the most popular ones for this purpose. Unfortunately, they require many forward passes at inference time, which slows them down. Sampling-free approaches can be faster but often suffer from other drawbacks, such as lower reliability of uncertainty estimates, difficulty of use, and limited applicability to different types of tasks and data. In this work, we introduce a sampling-free approach that is generic and easy to deploy, while producing reliable uncertainty estimates on par with state-of-the-art methods at a significantly lower computational cost. It is predicated on training the network to produce the same output with and without additional information about it. At inference time, when no prior information is given, we use the network's own prediction as the additional information. We then take the distance between the predictions with and without prior information as our uncertainty measure. We demonstrate our approach on several classification and regression tasks. We show that it delivers results on par with those of Ensembles but at a much lower computational cost",
    "checked": true,
    "id": "321aa1e91d2665d9fdada0737c3c0f6ba158eec3",
    "semantic_title": "zigzag: universal sampling-free uncertainty estimation through two-step inference",
    "citation_count": 10,
    "authors": [
      "Nikita Durasov",
      "Nik Dorndorf",
      "Hieu Le",
      "Pascal Fua"
    ]
  },
  "https://openreview.net/forum?id=uCZJaqJchs": {
    "title": "Personalised Federated Learning On Heterogeneous Feature Spaces",
    "volume": "main",
    "abstract": "Personalised federated learning (FL) approaches assume that raw data of all clients are defined in a common space \\emph{i.e.} all clients store their data according to the same schema. For real-world applications, this assumption is restrictive as clients, having their own systems to collect and then store data, may use {\\em heterogeneous} data representations. To bridge the gap between the assumption of a shared subspace and the more realistic situation of client-specific spaces, we propose a general framework coined FLIC that maps client's data onto a common feature space via local embedding functions, in a federated manner. Preservation of class information in the latent space is ensured by a distribution alignment with respect to a learned reference distribution. We provide the algorithmic details of FLIC as well as theoretical insights supporting the relevance of our methodology. We compare its performances against FL benchmarks involving heterogeneous input features spaces. Notably, we are the first to present a successful application of FL to Brain-Computer Interface signals acquired on a different number of sensors",
    "checked": true,
    "id": "abbc7f2b10d63c82b4bb5da61237078da3b55d76",
    "semantic_title": "personalised federated learning on heterogeneous feature spaces",
    "citation_count": 8,
    "authors": [
      "Alain Rakotomamonjy",
      "Maxime Vono",
      "Hamlet Jesse Medina Ruiz",
      "Liva Ralaivola"
    ]
  },
  "https://openreview.net/forum?id=qYceFeHgm4": {
    "title": "MUBen: Benchmarking the Uncertainty of Molecular Representation Models",
    "volume": "main",
    "abstract": "Large molecular representation models pre-trained on massive unlabeled data have shown great success in predicting molecular properties. However, these models may tend to overfit the fine-tuning data, resulting in over-confident predictions on test data that fall outside of the training distribution. To address this issue, uncertainty quantification (UQ) methods can be used to improve the models' calibration of predictions. Although many UQ approaches exist, not all of them lead to improved performance. While some studies have included UQ to improve molecular pre-trained models, the process of selecting suitable backbone and UQ methods for reliable molecular uncertainty estimation remains underexplored. To address this gap, we present MUBen, which evaluates different UQ methods for state-of-the-art backbone molecular representation models to investigate their capabilities. By fine-tuning various backbones using different molecular descriptors as inputs with UQ methods from different categories, we assess the influence of architectural decisions and training strategies on property prediction and uncertainty estimation. Our study offers insights for selecting UQ for backbone models, which can facilitate research on uncertainty-critical applications in fields such as materials science and drug discovery",
    "checked": true,
    "id": "d8c0ff00e7d8094cd00493923eea3dfffbc9e8ed",
    "semantic_title": "muben: benchmarking the uncertainty of molecular representation models",
    "citation_count": 11,
    "authors": [
      "Yinghao Li",
      "Lingkai Kong",
      "Yuanqi Du",
      "Yue Yu",
      "Yuchen Zhuang",
      "Wenhao Mu",
      "Chao Zhang"
    ]
  },
  "https://openreview.net/forum?id=BRl7fqMwaJ": {
    "title": "GSURE-Based Diffusion Model Training with Corrupted Data",
    "volume": "main",
    "abstract": "Diffusion models have demonstrated impressive results in both data generation and downstream tasks such as inverse problems, text-based editing, classification, and more. However, training such models usually requires large amounts of clean signals which are often difficult or impossible to obtain. In this work, we propose a novel training technique for generative diffusion models based only on corrupted data. We introduce a loss function based on the Generalized Stein's Unbiased Risk Estimator (GSURE), and prove that under some conditions, it is equivalent to the training objective used in fully supervised diffusion models. We demonstrate our technique on face images as well as Magnetic Resonance Imaging (MRI), where the use of undersampled data significantly alleviates data collection costs. Our approach achieves generative performance comparable to its fully supervised counterpart without training on any clean signals. In addition, we deploy the resulting diffusion model in various downstream tasks beyond the degradation present in the training set, showcasing promising results",
    "checked": true,
    "id": "6b6920ea541049f0035750ed9a2a2224c585f8c7",
    "semantic_title": "gsure-based diffusion model training with corrupted data",
    "citation_count": 31,
    "authors": [
      "Bahjat Kawar",
      "Noam Elata",
      "Tomer Michaeli",
      "Michael Elad"
    ]
  },
  "https://openreview.net/forum?id=2la55BeWwy": {
    "title": "A note on regularised NTK dynamics with an application to PAC-Bayesian training",
    "volume": "main",
    "abstract": "We establish explicit dynamics for neural networks whose training objective has a regularising term that constrains the parameters to remain close to their initial value. This keeps the network in a lazy training regime, where the dynamics can be linearised around the initialisation. The standard neural tangent kernel (NTK) governs the evolution during the training in the infinite-width limit, although the regularisation yields an additional term appears in the differential equation describing the dynamics. This setting provides an appropriate framework to study the evolution of wide networks trained to optimise generalisation objectives such as PAC-Bayes bounds, and hence contribute to a deeper theoretical understanding of such networks",
    "checked": true,
    "id": "9708d5b168cda3f07ed10fe4ee74fa9d35088ddc",
    "semantic_title": "a note on regularised ntk dynamics with an application to pac-bayesian training",
    "citation_count": 0,
    "authors": [
      "Eugenio Clerico",
      "Benjamin Guedj"
    ]
  },
  "https://openreview.net/forum?id=PuhF0hyDq1": {
    "title": "New Evaluation Metrics Capture Quality Degradation due to LLM Watermarking",
    "volume": "main",
    "abstract": "With the increasing use of large-language models (LLMs) like ChatGPT, watermarking has emerged as a promising approach for tracing machine-generated content. However, research on LLM watermarking often relies on simple perplexity or diversity-based measures to assess the quality of watermarked text, which can mask important limitations in watermarking. Here we introduce two new easy-to-use methods for evaluating watermarking algorithms for LLMs: 1) evaluation by LLM-judger with specific guidelines; and 2) binary classification on text embeddings to distinguish between watermarked and unwatermarked text. We apply these methods to characterize the effectiveness of current watermarking techniques. Our experiments, conducted across various datasets, reveal that current watermarking methods are moderately detectable by even simple classifiers, challenging the notion of watermarking subtlety. We also found, through the LLM judger, that watermarking impacts text quality, especially in degrading the coherence and depth of the response. Our findings underscore the trade-off between watermark robustness and text quality and highlight the importance of having more informative metrics to assess watermarking quality",
    "checked": true,
    "id": "92105d2f3716786528bd8e7498e13162b409cd37",
    "semantic_title": "new evaluation metrics capture quality degradation due to llm watermarking",
    "citation_count": 9,
    "authors": [
      "Karanpartap Singh",
      "James Zou"
    ]
  },
  "https://openreview.net/forum?id=YY2iA0hfia": {
    "title": "Does Representation Similarity Capture Function Similarity?",
    "volume": "main",
    "abstract": "Representation similarity metrics are widely used to compare learned representations in neural networks, as is evident in extensive literature investigating metrics that accurately capture information encoded in representations. However, aiming to capture all of the information available in representations may have little to do with what information is actually used by the downstream network. One solution is to experiment with interventions on network function. By ablating groups of units thought to carry information and observing whether those ablations affect network performance, we can focus on an outcome that mechanistically links representations to function. In this paper, we systematically test representation similarity metrics to evaluate their sensitivity to functional changes induced by ablation. We use network performance changes after ablation as a way to measure the influence of representation on function. These measures of function allow us to test how well similarity metrics capture changes in network performance versus changes to linear decodability. Network performance measures index the information used by the downstream network, while linear decoding methods index available information in the representation. We show that all of the tested metrics are more sensitive to decodable features than network performance. When comparing these metrics, Procrustes and CKA outperform regularized CCA-based methods on average. Although Procrustes and CKA outperform on average, these metrics have a diminished advantage when looking at network performance. We provide ablation tests of the utility of different representational similarity metrics. Our results suggest that interpretability methods will be more effective if they are based on representational similarity metrics that have been evaluated using ablation tests",
    "checked": true,
    "id": "cafc61111110805dff5386e828036c31ab2beff4",
    "semantic_title": "does representation similarity capture function similarity?",
    "citation_count": 2,
    "authors": [
      "Lucas Hayne",
      "Heejung Jung",
      "R. Carter"
    ]
  },
  "https://openreview.net/forum?id=TZdEgwZ6f3": {
    "title": "Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA",
    "volume": "main",
    "abstract": "Recent works demonstrate a remarkable ability to customize text-to-image diffusion models while only providing a few example images. What happens if you try to customize such models using multiple, fine-grained concepts in a sequential (i.e., continual) manner? In our work, we show that recent state-of-the-art customization of text-to-image models suffer from catastrophic forgetting when new concepts arrive sequentially. Specifically, when adding a new concept, the ability to generate high quality images of past, similar concepts degrade. To circumvent this forgetting, we propose a new method, C-LoRA, composed of a continually self-regularized low-rank adaptation in cross attention layers of the popular Stable Diffusion model. Furthermore, we use customization prompts which do not include the word of the customized object (i.e., \"person\" for a human face dataset) and are initialized as completely random embeddings. Importantly, our method induces only marginal additional parameter costs and requires no storage of user data for replay. We show that C-LoRA not only outperforms several baselines for our proposed setting of text-to-image continual customization, which we refer to as Continual Diffusion, but that we achieve a new state-of-the-art in the well-established rehearsal-free continual learning setting for image classification. The high achieving performance of C-LoRA in two separate domains positions it as a compelling solution for a wide range of applications, and we believe it has significant potential for practical impact",
    "checked": true,
    "id": "d0590894ef9edb5fce917cb8221e5ab0226522a9",
    "semantic_title": "continual diffusion: continual customization of text-to-image diffusion with c-lora",
    "citation_count": 105,
    "authors": [
      "James Seale Smith",
      "Yen-Chang Hsu",
      "Lingyu Zhang",
      "Ting Hua",
      "Zsolt Kira",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://openreview.net/forum?id=3kYgouAfqk": {
    "title": "BP($\\mathbf{\\lambda}$): Online Learning via Synthetic Gradients",
    "volume": "main",
    "abstract": "Training recurrent neural networks typically relies on backpropagation through time (BPTT). BPTT depends on forward and backward passes to be completed, rendering the network locked to these computations before loss gradients are available. Recently, Jaderberg et al. proposed synthetic gradients to alleviate the need for full BPTT. In their implementation synthetic gradients are learned through a mixture of backpropagated gradients and bootstrapped synthetic gradients, analogous to the temporal difference (TD) algorithm in Reinforcement Learning (RL). However, as in TD learning, heavy use of bootstrapping can result in bias which leads to poor synthetic gradient estimates. Inspired by the accumulate $\\mathrm{TD}(\\lambda)$ in RL, we propose a fully online method for learning synthetic gradients which avoids the use of BPTT altogether: \\emph{accumulate} $BP(\\lambda)$. As in accumulate $\\mathrm{TD}(\\lambda)$, we show analytically that {accumulate~$\\mathrm{BP}(\\lambda)$} can control the level of bias by using a mixture of temporal difference errors and recursively defined eligibility traces. We next demonstrate empirically that our model outperforms the original implementation for learning synthetic gradients in a variety of tasks, and is particularly suited for capturing longer timescales. Finally, building on recent work we reflect on accumulate $\\mathrm{BP}(\\lambda)$ as a principle for learning in biological circuits. In summary, inspired by RL principles we introduce an algorithm capable of bias-free online learning via synthetic gradients",
    "checked": false,
    "id": "956b83eff99811bb0c782e4b90e64e95eef30117",
    "semantic_title": "bp(Î»): online learning via synthetic gradients",
    "citation_count": 0,
    "authors": [
      "Joseph Oliver Pemberton",
      "Rui Ponte Costa"
    ]
  },
  "https://openreview.net/forum?id=kZFKwApeQO": {
    "title": "GUARD: A Safe Reinforcement Learning Benchmark",
    "volume": "main",
    "abstract": "Due to the trial-and-error nature, it is typically challenging to apply RL algorithms to safety-critical real-world applications, such as autonomous driving, human-robot interaction, robot manipulation, etc, where such errors are not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly in the literature, in which the agents explore the environment while satisfying constraints. Due to the diversity of algorithms and tasks, it remains difficult to compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a Generalized Unified SAfe Reinforcement Learning Development Benchmark. GUARD has several advantages compared to existing benchmarks. First, GUARD is a generalized benchmark with a wide variety of RL agents, tasks, and safety constraint specifications. Second, GUARD comprehensively covers state-of-the-art safe RL algorithms with self-contained implementations. Third, GUARD is highly customizable in tasks and algorithms. We present a comparison of state-of-the-art on-policy safe RL algorithms in various task settings using GUARD and establish baselines that future work can build on",
    "checked": true,
    "id": "498d75d17609af4d5f235654423d90bbe3a5c621",
    "semantic_title": "guard: a safe reinforcement learning benchmark",
    "citation_count": 13,
    "authors": [
      "Weiye Zhao",
      "Yifan Sun",
      "Feihan Li",
      "Rui Chen",
      "Ruixuan Liu",
      "Tianhao Wei",
      "Changliu Liu"
    ]
  },
  "https://openreview.net/forum?id=IzmLJ1t49R": {
    "title": "Incremental Extractive Opinion Summarization Using Cover Trees",
    "volume": "main",
    "abstract": "Extractive opinion summarization involves automatically producing a summary of text about an entity (e.g., a product's reviews) by extracting representative sentences that capture prevalent opinions in the review set. Typically, in online marketplaces user reviews accrue over time, and opinion summaries must be updated periodically to provide customers with up-to-date information. In this work, we study the task of extractive opinion summarization in an incremental setting, where the underlying review set evolves over time. Many of the state-of-the-art extractive opinion summarization approaches are centrality-based, such as CentroidRank (Radev et al., 2004; Chowdhury et al., 2022). CentroidRank performs extractive summarization by selecting a subset of review sentences closest to the centroid in the representation space as the summary. However, these methods are not capable of operating efficiently in an incremental setting, where reviews arrive one at a time. In this paper, we present an efficient algorithm for accurately computing the CentroidRank summaries in an incremental setting. Our approach, CoverSumm, relies on indexing review representations in a cover tree and maintaining a reservoir of candidate summary review sentences. CoverSumm's efficacy is supported by a theoretical and empirical analysis of running time. Empirically, on a diverse collection of data (both real and synthetically created to illustrate scaling considerations), we demonstrate that CoverSumm is up to 25x faster than baseline methods, and capable of adapting to nuanced changes in data distribution. We also conduct human evaluations of the generated summaries and find that CoverSumm is capable of producing informative summaries consistent with the underlying review set",
    "checked": true,
    "id": "85f9ac65d7e7a38b179f534db47b497d0e07ffeb",
    "semantic_title": "incremental extractive opinion summarization using cover trees",
    "citation_count": 3,
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Nicholas Monath",
      "Kumar Avinava Dubey",
      "Manzil Zaheer",
      "Andrew McCallum",
      "Amr Ahmed",
      "Snigdha Chaturvedi"
    ]
  },
  "https://openreview.net/forum?id=qunyX9WYr6": {
    "title": "Persistent Local Homology in Graph Learning",
    "volume": "main",
    "abstract": "In this study, we introduce Persistent Local Homology (PLH) for graphs, a novel method that synergizes persistent homology with local homology to analyze graph structures. We begin by mathematically formalizing PLH, defining it as the application of persistent homology to annular local subgraphs. This foundation paves the way for the development of a computational pipeline, specifically tailored for PLH, which we explore in various graph learning contexts. Despite its utility, a complexity analysis reveals potential computational bottlenecks in PLH application. To address this, we propose Reduced PLH (rPLH), an efficient variant designed to significantly lower computational complexity. Experimental evaluations with rPLH demonstrate its capability to retain the effectiveness of the original PLH while substantially reducing computational demands. The practical utility of PLH and rPLH is further corroborated through comprehensive experiments on both synthetic and real-world datasets, highlighting their broad applicability and potential in diverse analytical scenarios",
    "checked": true,
    "id": "02954c178f78b0e920073fabbe0d465290e238cf",
    "semantic_title": "persistent local homology in graph learning",
    "citation_count": 5,
    "authors": [
      "Minghua Wang",
      "Yan HU",
      "Ziyun Huang",
      "Di Wang",
      "Jinhui Xu"
    ]
  },
  "https://openreview.net/forum?id=I8FMYa2BdP": {
    "title": "Adversarially Robust Spiking Neural Networks Through Conversion",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) provide an energy-efficient alternative to a variety of artificial neural network (ANN) based AI applications. As the progress in neuromorphic computing with SNNs expands their use in applications, the problem of adversarial robustness of SNNs becomes more pronounced. To the contrary of the widely explored end-to-end adversarial training based solutions, we address the limited progress in scalable robust SNN training methods by proposing an adversarially robust ANN-to-SNN conversion algorithm. Our method provides an efficient approach to embrace various computationally demanding robust learning objectives that have been proposed for ANNs. During a post-conversion robust finetuning phase, our method adversarially optimizes both layer-wise firing thresholds and synaptic connectivity weights of the SNN to maintain transferred robustness gains from the pre-trained ANN. We perform experimental evaluations in a novel setting proposed to rigorously assess the robustness of SNNs, where numerous adaptive adversarial attacks that account for the spike-based operation dynamics are considered. Results show that our approach yields a scalable state-of-the-art solution for adversarially robust deep SNNs with low-latency",
    "checked": true,
    "id": "075ad710f548810560e2844b39f6e89147cbc34c",
    "semantic_title": "adversarially robust spiking neural networks through conversion",
    "citation_count": 10,
    "authors": [
      "Ozan Ozdenizci",
      "Robert Legenstein"
    ]
  },
  "https://openreview.net/forum?id=ekvsBtCBUK": {
    "title": "Anomaly detection with semi-supervised classification based on risk estimators",
    "volume": "main",
    "abstract": "A significant limitation of one-class classification anomaly detection methods is their reliance on the assumption that unlabeled training data only contains normal instances. To overcome this impractical assumption, we propose two novel classification-based anomaly detection methods. Firstly, we introduce a semi-supervised shallow anomaly detection method based on an unbiased risk estimator. Secondly, we present a semi-supervised deep anomaly detection method utilizing a nonnegative (biased) risk estimator. We establish estimation error bounds and excess risk bounds for both risk minimizers. Additionally, we propose techniques to select appropriate regularization parameters that ensure the nonnegativity of the empirical risk in the shallow model under specific loss functions. Our extensive experiments provide evidence of the effectiveness of the risk-based anomaly detection methods",
    "checked": true,
    "id": "47456375b49e94df090ec87ccbfa7ecfa2ecc803",
    "semantic_title": "anomaly detection with semi-supervised classification based on risk estimators",
    "citation_count": 0,
    "authors": [
      "Le Thi Khanh Hien",
      "Sukanya Patra",
      "Souhaib Ben Taieb"
    ]
  },
  "https://openreview.net/forum?id=2M9CUnYnBA": {
    "title": "Exponential Moving Average of Weights in Deep Learning: Dynamics and Benefits",
    "volume": "main",
    "abstract": "Weight averaging of Stochastic Gradient Descent (SGD) iterates is a popular method for training deep learning models. While it is often used as part of complex training pipelines to improve generalization or serve as a `teacher' model, weight averaging lacks proper evaluation on its own. In this work, we present a systematic study of the Exponential Moving Average (EMA) of weights. We first explore the training dynamics of EMA, give guidelines for hyperparameter tuning, and highlight its good early performance, partly explaining its success as a teacher. We also observe that EMA requires less learning rate decay compared to SGD since averaging naturally reduces noise, introducing a form of implicit regularization. Through extensive experiments, we show that EMA solutions differ from last-iterate solutions. EMA models not only generalize better but also exhibit improved i) robustness to noisy labels, ii) prediction consistency, iii) calibration and iv) transfer learning. Therefore, we suggest that an EMA of weights is a simple yet effective plug-in to improve the performance of deep learning models",
    "checked": true,
    "id": "42c658e1ad85f2b4f054d6aa699f36ad34fddedd",
    "semantic_title": "exponential moving average of weights in deep learning: dynamics and benefits",
    "citation_count": 23,
    "authors": [
      "Daniel Morales-Brotons",
      "Thijs Vogels",
      "Hadrien Hendrikx"
    ]
  },
  "https://openreview.net/forum?id=qH4YFMyhce": {
    "title": "Scalable Hierarchical Self-Attention with Learnable Hierarchy for Long-Range Interactions",
    "volume": "main",
    "abstract": "Self-attention models have made great strides toward accurately modeling a wide array of data modalities, including, more recently, graph-structured data. This paper demonstrates that adaptive hierarchical attention can go a long way toward successfully applying transformers to graphs. Our proposed model Sequoia provides a powerful inductive bias towards long-range interaction modeling, leading to better generalization. We propose an end-to-end mechanism for a data-dependent construction of a hierarchy which in turn guides the self-attention mechanism. Using adaptive hierarchy provides a natural pathway toward sparse attention by constraining node-to-node interactions with the immediate family of each node in the hierarchy (e.g., parent, children, and siblings). This in turn dramatically reduces the computational complexity of a self-attention layer from quadratic to log-linear in terms of the input size while maintaining or sometimes even surpassing the standard transformer's ability to model long-range dependencies across the entire input. Experimentally, we report state-of-the-art performance on long-range graph benchmarks while remaining computationally efficient. Moving beyond graphs, we also display competitive performance on long-range sequence modeling, point-clouds classification, and segmentation when using a fixed hierarchy. Our source code is publicly available at https://github.com/HySonLab/HierAttention",
    "checked": true,
    "id": "0fa6bd29f51b82c3fe6e275129e4518ba646b59b",
    "semantic_title": "scalable hierarchical self-attention with learnable hierarchy for long-range interactions",
    "citation_count": 4,
    "authors": [
      "Thuan Nguyen Anh Trang",
      "Khang Nhat Ngo",
      "Hugo Sonnery",
      "Thieu Vo",
      "Siamak Ravanbakhsh",
      "Truong Son Hy"
    ]
  },
  "https://openreview.net/forum?id=AoOi9Zgdsv": {
    "title": "The Cross-entropy of Piecewise Linear Probability Density Functions",
    "volume": "main",
    "abstract": "The cross-entropy and its related terms from information theory (e.g.~entropy, KullbackâLeibler divergence) are used throughout artificial intelligence and machine learning. This includes many of the major successes, both current and historic, where they commonly appear as the natural objective of an optimisation procedure for learning model parameters, or their distributions. This paper presents a novel derivation of the differential cross-entropy between two 1D probability density functions represented as piecewise linear functions. Implementation challenges are resolved and experimental validation is presented, including a rigorous analysis of accuracy and a demonstration of using the presented result as the objective of a neural network. Previously, cross-entropy would need to be approximated via numerical integration, or equivalent, for which calculating gradients is impractical. Machine learning models with high parameter counts are optimised primarily with gradients, so if piecewise linear density representations are to be used then the presented analytic solution is essential. This paper contributes the necessary theory for the practical optimisation of information theoretic objectives when dealing with piecewise linear distributions directly. Removing this limitation expands the design space for future algorithms",
    "checked": true,
    "id": "73536a237a0a75dec205a9c98d233cb082e64f84",
    "semantic_title": "the cross-entropy of piecewise linear probability density functions",
    "citation_count": 0,
    "authors": [
      "Tom S. F. Haines"
    ]
  },
  "https://openreview.net/forum?id=QvipGVdE6L": {
    "title": "3D Molecular Generation via Virtual Dynamics",
    "volume": "main",
    "abstract": "Structure-based drug design, a critical aspect of drug discovery, aims to identify high-affinity molecules for target protein pockets. Traditional virtual screening methods, which involve exhaustive searches within large molecular databases, are inefficient and limited in discovering novel molecules. The pocket-based 3D molecular generation model offers a promising alternative by directly generating molecules with 3D structures and binding positions in the pocket. In this paper, we present VD-Gen, a novel pocket-based 3D molecular generation pipeline. VD-Gen features a series of carefully designed stages to generate fine-grained 3D molecules with binding positions in the pocket cavity end-to-end. Rather than directly generating or sampling atoms with 3D positions in the pocket, VD-Gen randomly initializes multiple virtual particles within the pocket and learns to iteratively move them to approximate the distribution of molecular atoms in 3D space. After the iterative movement, a 3D molecule is extracted and further refined through additional iterative movement, yielding a high-quality 3D molecule with a confidence score. Comprehensive experimental results on pocket-based molecular generation demonstrate that VD-Gen can generate novel 3D molecules that fill the target pocket cavity with high binding affinities, significantly outperforming previous baselines",
    "checked": true,
    "id": "2bc52556e167ab5a84f032963a4dcbee5246df09",
    "semantic_title": "3d molecular generation via virtual dynamics",
    "citation_count": 7,
    "authors": [
      "Shuqi Lu",
      "Lin Yao",
      "Xi Chen",
      "Hang Zheng",
      "Di He",
      "Guolin Ke"
    ]
  },
  "https://openreview.net/forum?id=KokkP2nQ24": {
    "title": "How good is Good-Turing for Markov samples?",
    "volume": "main",
    "abstract": "The Good-Turing (GT) estimator for the missing mass (i.e., total probability of missing symbols) in $n$ samples is the number of symbols that appeared exactly once divided by $n$. For i.i.d. samples, the bias and squared-error risk of the GT estimator can be shown to fall as $1/n$ by bounding the expected error uniformly over all symbols. In this work, we study convergence of the GT estimator for missing stationary mass (i.e., total stationary probability of missing symbols) of Markov samples on an alphabet $\\mathcal{X}$ with stationary distribution $[\\pi_x:x\\in\\cX]$ and transition probability matrix (t.p.m.) $P$. This is an important and interesting problem because GT is widely used in applications with temporal dependencies such as language models assigning probabilities to word sequences, which are modelled as Markov. We show that convergence of GT depends on convergence of $(P^{\\sim x})^n$, where $P^{\\sim x}$ is $P$ with the $x$-th column zeroed out. This, in turn, depends on the Perron eigenvalue $\\lambda^{\\sim x}$ of $P^{\\sim x}$ and its relationship with $\\pi_x$ uniformly over $x$. For randomly generated t.p.ms and t.p.ms derived from New York Times and Charles Dickens corpora, we numerically exhibit such uniform-over-$x$ relationships between $\\lambda^{\\sim x}$ and $\\pi_x$. This supports the observed success of GT in language models and practical text data scenarios. For Markov chains with rank-2, diagonalizable t.p.ms having spectral gap $\\beta$, we show minimax rate upper and lower bounds of $1/(n\\beta^5)$ and $1/(n\\beta)$, respectively, for the estimation of stationary missing mass. This theoretical result extends the $1/n$ minimax rate for i.i.d. or rank-1 t.p.ms to rank-2 Markov, and is a first such minimax rate result for missing mass of Markov samples. We also show, through experiments, that the MSE of GT decays at a slower rate as the rank of the t.p.m increases",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prafulla Chandra",
      "Andrew Thangaraj",
      "Nived Rajaraman"
    ]
  },
  "https://openreview.net/forum?id=NgK5etmhz9": {
    "title": "State-wise Constrained Policy Optimization",
    "volume": "main",
    "abstract": "Reinforcement Learning (RL) algorithms have shown tremendous success in simulation environments, but their application to real-world problems faces significant challenges, with safety being a major concern. In particular, enforcing state-wise constraints is essential for many challenging tasks such as autonomous driving and robot manipulation. However, existing safe RL algorithms under the framework of Constrained Markov Decision Process (CMDP) do not consider state-wise constraints. To address this gap, we propose State-wise Constrained Policy Optimization (SCPO), the first general-purpose policy search algorithm for state-wise constrained reinforcement learning. SCPO provides guarantees for state-wise constraint satisfaction in expectation. In particular, we introduce the framework of Maximum Markov Decision Process, and prove that the worst-case safety violation is bounded under SCPO. We demonstrate the effectiveness of our approach on training neural network policies for extensive robot locomotion tasks, where the agent must satisfy a variety of state-wise safety constraints. Our results show that SCPO significantly outperforms existing methods and can handle state-wise constraints in high-dimensional robotics tasks",
    "checked": true,
    "id": "9af5047a2db2bbe3e3fea322a7e66bf86b0f4e97",
    "semantic_title": "state-wise constrained policy optimization",
    "citation_count": 10,
    "authors": [
      "Weiye Zhao",
      "Rui Chen",
      "Yifan Sun",
      "Feihan Li",
      "Tianhao Wei",
      "Changliu Liu"
    ]
  },
  "https://openreview.net/forum?id=3ludyxPbb6": {
    "title": "Provable Membership Inference Privacy",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1cc36266e3ce0ac751d431c48edbfd9d41f5931c",
    "semantic_title": "provable membership inference privacy",
    "citation_count": 5,
    "authors": [
      "Zachary Izzo",
      "Jinsung Yoon",
      "Sercan O Arik",
      "James Zou"
    ]
  },
  "https://openreview.net/forum?id=1fbTGC3BUD": {
    "title": "Adaptive Conformal Regression with Split-Jackknife+ Scores",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7526e8120b37403bdae61672564cb5231e53e450",
    "semantic_title": "adaptive conformal regression with split-jackknife+ scores",
    "citation_count": 3,
    "authors": [
      "Nicolas Deutschmann",
      "Mattia Rigotti",
      "Maria Rodriguez Martinez"
    ]
  },
  "https://openreview.net/forum?id=5psgQEHn6t": {
    "title": "Neural networks can be FLOP-efficient integrators of 1D oscillatory integrands",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e271d34c24d0407632418f6e908ae70c3c646941",
    "semantic_title": "neural networks can be flop-efficient integrators of 1d oscillatory integrands",
    "citation_count": 1,
    "authors": [
      "Anshuman Sinha",
      "Spencer H Bryngelson"
    ]
  },
  "https://openreview.net/forum?id=RGewtLtvHz": {
    "title": "Towards generalizing deep-audio fake detection networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e59128960429cc0fcb93cf8b66fc66b0a2ae68dd",
    "semantic_title": "towards generalizing deep-audio fake detection networks",
    "citation_count": 4,
    "authors": [
      "Konstantin Gasenzer",
      "Moritz Wolter"
    ]
  },
  "https://openreview.net/forum?id=t4nnCi5AO6": {
    "title": "Scaling (Down) CLIP: A Comprehensive Analysis of Data,Architecture, and Training Strategies",
    "volume": "main",
    "abstract": "This paper investigates the performance of the Contrastive Language-Image Pre-training (CLIP) when scaled down to limited computation budgets. We explore CLIP along three dimensions: data, architecture, and training strategies. With regards to data, we demonstrate the significance of high-quality training data and show that a smaller dataset of high-quality data can outperform a larger dataset with lower quality. We also examine how model performance varies with different dataset sizes, suggesting that smaller ViT models are better suited for smaller datasets, while larger models perform better on larger datasets with fixed compute. Additionally, we provide guidance on when to choose a CNN-based architecture or a ViT-based architecture for CLIP training. We compare four CLIP training strategies - SLIP, FLIP, CLIP, and CLIP+Data Augmentation - and show that the choice of training strategy depends on the available compute resource. Our analysis reveals that CLIP+Data Augmentation can achieve comparable performance to CLIP using only half of the training data. This work provides practical insights into how to effectively train and deploy CLIP models, making them more accessible and affordable for practical use in various applications",
    "checked": false,
    "id": "51ee1cc17da1430bb5cdb4e1feba7591d9a2cb68",
    "semantic_title": "scaling (down) clip: a comprehensive analysis of data, architecture, and training strategies",
    "citation_count": 9,
    "authors": [
      "Zichao Li",
      "Cihang Xie",
      "Ekin Dogus Cubuk"
    ]
  },
  "https://openreview.net/forum?id=w4DXLzBPPw": {
    "title": "Low-Rank Tensor-Network Encodings for Video-to-Action Behavioral Cloning",
    "volume": "main",
    "abstract": "We describe a tensor-network latent-space encoding approach for increasing the scalability of behavioral cloning of a video game player's actions entirely from video streams of the gameplay. Specifically, we address challenges associated with the high computational requirements of traditional deep-learning based encoders such as convolutional variational autoencoders that prohibit their use in widely available hardware or for large scale data. Our approach uses tensor networks instead of deep variational autoencoders for this purpose, and it yields significant speedups with no loss of accuracy. Empirical results on ATARI games demonstrate that our approach leads to a speedup in the time it takes to encode data and train a predictor using the encodings (between 2.6Ã to 9.6Ã compared to autoencoders or variational autoencoders). Furthermore, the tensor train encoding can be efficiently trained on CPU as well, which leads to comparable or better training times than the autoencoder and variational autoencoder trained on GPU (0.9Ã to 5.4Ã faster). These results suggest significant possibilities in mitigating the need for cost and time-intensive hardware for training deep-learning architectures for behavioral cloning",
    "checked": true,
    "id": "8f46b2c854160cf419fb901123e8403c4cc1b6e2",
    "semantic_title": "low-rank tensor-network encodings for video-to-action behavioral cloning",
    "citation_count": 0,
    "authors": [
      "Brian Chen",
      "Doruk Aksoy",
      "David J Gorsich",
      "Shravan Veerapaneni",
      "Alex Gorodetsky"
    ]
  },
  "https://openreview.net/forum?id=DIGkJhGeqi": {
    "title": "EHRDiff : Exploring Realistic EHR Synthesis with Diffusion Models",
    "volume": "main",
    "abstract": "Electronic health records (EHR) contain a wealth of biomedical information, serving as valuable resources for the development of precision medicine systems. However, privacy concerns have resulted in limited access to high-quality and large-scale EHR data for researchers, impeding progress in methodological development. Recent research has delved into synthesizing realistic EHR data through generative modeling techniques, where a majority of proposed methods relied on generative adversarial networks (GAN) and their variants for EHR synthesis. Despite GAN-based methods attaining state-of-the-art performance in generating EHR data, these approaches are difficult to train and prone to mode collapse. Recently introduced in generative modeling, diffusion models have established cutting-edge performance in image generation, but their efficacy in EHR data synthesis remains largely unexplored. In this study, we investigate the potential of diffusion models for EHR data synthesis and introduce a novel method, EHRDiff. Through extensive experiments, EHRDiff establishes new state-of-the-art quality for synthetic EHR data, protecting private information in the meanwhile",
    "checked": false,
    "id": "4e05bad5ed0b8ef54ae3813f27ac5c87cf1ddd8a",
    "semantic_title": "ehrdiff: exploring realistic ehr synthesis with diffusion models",
    "citation_count": 18,
    "authors": [
      "Hongyi Yuan",
      "Songchi Zhou",
      "Sheng Yu"
    ]
  },
  "https://openreview.net/forum?id=BkEqk7pS1I": {
    "title": "Finite-Time Analysis of Entropy-Regularized Neural Natural Actor-Critic Algorithm",
    "volume": "main",
    "abstract": "Natural actor-critic (NAC) and its variants, equipped with the representation power of neural networks, have demonstrated impressive empirical success in solving Markov decision problems with large (potentially infinite) state spaces. In this paper, we present a finite-time analysis of NAC with neural network approximation, and identify the roles of neural networks, regularization and optimization techniques (e.g., gradient clipping and weight decay) to achieve provably good performance in terms of sample complexity, iteration complexity and overparametrization bounds for the actor and the critic. In particular, we prove that (i) entropy regularization and weight decay ensure stability by providing sufficient exploration to avoid near-deterministic and strictly suboptimal policies and (ii) regularization leads to sharp sample complexity and network width bounds in the regularized MDPs, yielding a favorable bias-variance tradeoff in policy optimization. In the process, we identify the importance of uniform approximation power of the actor neural network to achieve global optimality in policy optimization due to distributional shift",
    "checked": true,
    "id": "d5c8a3b613a52b1c7d480bbafbac3f050196d083",
    "semantic_title": "finite-time analysis of entropy-regularized neural natural actor-critic algorithm",
    "citation_count": 14,
    "authors": [
      "Semih Cayci",
      "Niao He",
      "R. Srikant"
    ]
  },
  "https://openreview.net/forum?id=cPDVjsOytS": {
    "title": "PopulAtion Parameter Averaging (PAPA)",
    "volume": "main",
    "abstract": "Ensemble methods combine the predictions of multiple models to improve performance, but they require significantly higher computation costs at inference time. To avoid these costs, multiple neural networks can be combined into one by averaging their weights. However, this usually performs significantly worse than ensembling. Weight averaging is only beneficial when different enough to benefit from combining them, but similar enough to average well. Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): a method that combines the generality of ensembling with the efficiency of weight averaging. PAPA leverages a population of diverse models (trained on different data orders, augmentations, and regularizations) while slowly pushing the weights of the networks toward the population average of the weights. We also propose PAPA variants (PAPA-all, and PAPA-2) that average weights rarely rather than continuously; all methods increase generalization, but PAPA tends to perform best. PAPA reduces the performance gap between averaging and ensembling, increasing the average accuracy of a population of models by up to 0.8% on CIFAR-10, 1.9% on CIFAR-100, and 1.6% on ImageNet when compared to training independent (non-averaged) models",
    "checked": true,
    "id": "2fb84dcdfa68e31742e20ffff3f32a04ec85d3da",
    "semantic_title": "population parameter averaging (papa)",
    "citation_count": 21,
    "authors": [
      "Alexia Jolicoeur-Martineau",
      "Emy Gervais",
      "Kilian FATRAS",
      "Yan Zhang",
      "Simon Lacoste-Julien"
    ]
  },
  "https://openreview.net/forum?id=Y4YWzBiTEV": {
    "title": "The Missing U for Efficient Diffusion Models",
    "volume": "main",
    "abstract": "Diffusion Probabilistic Models stand as a critical tool in generative modelling, enabling the generation of complex data distributions. This family of generative models yields record-breaking performance in tasks such as image synthesis, video generation, and molecule design. Despite their capabilities, their efficiency, especially in the reverse process, remains a challenge due to slow convergence rates and high computational costs. In this paper, we introduce an approach that leverages continuous dynamical systems to design a novel denoising network for diffusion models that is more parameter-efficient, exhibits faster convergence, and demonstrates increased noise robustness. Experimenting with Denoising Diffusion Probabilistic Models (DDPMs), our framework operates with approximately a quarter of the parameters, and $\\sim$ 30\\% of the Floating Point Operations (FLOPs) compared to standard U-Nets in DDPMs. Furthermore, our model is notably faster in inference than the baseline when measured in fair and equal conditions. We also provide a mathematical intuition as to why our proposed reverse process is faster as well as a mathematical discussion of the empirical tradeoffs in the denoising downstream task. Finally, we argue that our method is compatible with existing performance enhancement techniques, enabling further improvements in efficiency, quality, and speed",
    "checked": true,
    "id": "bac74fa84c99d08371f87e156a286c4bb8c8d512",
    "semantic_title": "the missing u for efficient diffusion models",
    "citation_count": 4,
    "authors": [
      "Sergio Calvo OrdoÃ±ez",
      "Chun-Wun Cheng",
      "Jiahao Huang",
      "Lipei Zhang",
      "Guang Yang",
      "Carola-Bibiane SchÃ¶nlieb",
      "Angelica I Aviles-Rivero"
    ]
  },
  "https://openreview.net/forum?id=N05OnQG1BA": {
    "title": "CoDeC: Communication-Efficient Decentralized Continual Learning",
    "volume": "main",
    "abstract": "Training at the edge utilizes continuously evolving data generated at different locations. Privacy concerns prohibit the co-location of this spatially as well as temporally distributed data, deeming it crucial to design training algorithms that enable efficient continual learning over decentralized private data. Decentralized learning allows serverless training with spatially distributed data. A fundamental barrier in such setups is the high bandwidth cost of communicating model updates between agents. Moreover, existing works under this training paradigm are not inherently suitable for learning a temporal sequence of tasks while retaining the previously acquired knowledge. In this work, we propose CoDeC, a novel communication-efficient decentralized continual learning algorithm that addresses these challenges. We mitigate catastrophic forgetting while learning a distributed task sequence by incorporating orthogonal gradient projection within a gossip-based decentralized learning algorithm. Further, CoDeC includes a novel lossless communication compression scheme based on the gradient subspaces. We theoretically analyze the convergence rate for our algorithm and demonstrate through an extensive set of experiments that CoDeC successfully learns distributed continual tasks with minimal forgetting. The proposed compression scheme results in up to 4.8Ã reduction in communication costs without any loss in performance",
    "checked": true,
    "id": "14fc27f151a12e141e8cc84da050e64b8d90eb56",
    "semantic_title": "codec: communication-efficient decentralized continual learning",
    "citation_count": 3,
    "authors": [
      "Sakshi Choudhary",
      "Sai Aparna Aketi",
      "Gobinda Saha",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=75OwvzZZBT": {
    "title": "Bias Amplification Enhances Minority Group Performance",
    "volume": "main",
    "abstract": "Neural networks produced by standard training are known to suffer from poor accuracy on rare subgroups despite achieving high accuracy on average, due to the correlations between certain spurious features and labels. Previous approaches based on worst-group loss minimization (e.g. Group-DRO) are effective in improving worse-group accuracy but require expensive group annotations for all the training samples. In this paper, we focus on the more challenging and realistic setting where group annotations are only available on a small validation set or are not available at all. We propose BAM, a novel two-stage training algorithm: in the first stage, the model is trained using a bias amplification scheme via introducing a learnable auxiliary variable for each training sample; in the second stage, we upweight the samples that the bias-amplified model misclassifies, and then continue training the same model on the reweighted dataset. Empirically, BAM achieves competitive performance compared with existing methods evaluated on spurious correlation benchmarks in computer vision and natural language processing. Moreover, we find a simple stopping criterion based on minimum class accuracy difference that can remove the need for group annotations, with little or no loss in worst-group accuracy. We perform extensive analyses and ablations to verify the effectiveness and robustness of our algorithm in varying class and group imbalance ratios",
    "checked": true,
    "id": "d1df8b8160e222525990b40dcef323eccc16a74c",
    "semantic_title": "bias amplification enhances minority group performance",
    "citation_count": 8,
    "authors": [
      "Gaotang Li",
      "Jiarui Liu",
      "Wei Hu"
    ]
  },
  "https://openreview.net/forum?id=j5T4pcLbcY": {
    "title": "Fast and Expressive Gesture Recognition using a Combination-Homomorphic Electromyogram Encoder",
    "volume": "main",
    "abstract": "We study the task of gesture recognition from electromyography (EMG), with the goal of enabling expressive human-computer interaction at high accuracy, while minimizing the time required for new subjects to provide calibration data. To fulfill these goals, we define combination gestures consisting of a direction component and a modifier component. New subjects only demonstrate the single component gestures and we seek to extrapolate from these to all possible single or combination gestures. We extrapolate to unseen combination gestures by combining the feature vectors of real single gestures to produce synthetic training data. This strategy allows us to provide a large and flexible gesture vocabulary, while not requiring new subjects to demonstrate combinatorially many example gestures. We pre-train an encoder and a combination operator using self-supervision, so that we can produce useful synthetic training data for unseen test subjects. To evaluate the proposed method, we collect a real-world EMG dataset, and measure the effect of augmented supervision against two baselines: a partially-supervised model trained with only single gesture data from the unseen subject, and a fully-supervised model trained with real single and real combination gesture data from the unseen subject. We find that the proposed method provides a dramatic improvement over the partially-supervised model, and achieves a useful classification accuracy that in some cases approaches the performance of the fully-supervised model",
    "checked": true,
    "id": "adc02afb466c4f6978e49a9026ae371fcc728a63",
    "semantic_title": "fast and expressive gesture recognition using a combination-homomorphic electromyogram encoder",
    "citation_count": 0,
    "authors": [
      "Niklas Smedemark-Margulies",
      "Yunus Bicer",
      "Elifnur Sunger",
      "Tales Imbiriba",
      "Eugene Tunik",
      "Deniz Erdogmus",
      "Mathew Yarossi",
      "Robin Walters"
    ]
  },
  "https://openreview.net/forum?id=zn3fB4VVF0": {
    "title": "Navigating Noise: A Study of How Noise Influences Generalisation and Calibration of Neural Networks",
    "volume": "main",
    "abstract": "Enhancing the generalisation abilities of neural networks (NNs) through integrating noise such as MixUp or Dropout during training has emerged as a powerful and adaptable technique. Despite the proven efficacy of noise in NN training, there is no consensus regarding which noise sources, types and placements yield maximal benefits in generalisation and confidence calibration. This study thoroughly explores diverse noise modalities to evaluate their impacts on NN's generalisation and calibration under in-distribution or out-of-distribution settings, paired with experiments investigating the metric landscapes of the learnt representations, across a spectrum of NN architectures, tasks, and datasets. Our study shows that AugMix and weak augmentation exhibit cross-task effectiveness in computer vision, emphasising the need to tailor noise to specific domains. Our findings emphasise the efficacy of combining noises and successful hyperparameter transfer within a single domain but the difficulties in transferring the benefits to other domains. Furthermore, the study underscores the complexity of simultaneously optimising for both generalisation and calibration, emphasising the need for practitioners to carefully consider noise combinations and hyperparameter tuning for optimal performance in specific tasks and datasets",
    "checked": true,
    "id": "b48cd04a9a71d6808c4a9060c224a63a6b5b7edd",
    "semantic_title": "navigating noise: a study of how noise influences generalisation and calibration of neural networks",
    "citation_count": 4,
    "authors": [
      "Martin Ferianc",
      "Ondrej Bohdal",
      "Timothy Hospedales",
      "Miguel R. D. Rodrigues"
    ]
  },
  "https://openreview.net/forum?id=OyXS4ZIqd3": {
    "title": "On the Robustness of Neural Collapse and the Neural Collapse of Robustness",
    "volume": "main",
    "abstract": "Neural Collapse refers to the curious phenomenon in the end of training of a neural network, where feature vectors and classification weights converge to a very simple geometrical arrangement (a simplex). While it has been observed empirically in various cases and has been theoretically motivated, its connection with crucial properties of neural networks, like their generalization and robustness, remains unclear. In this work, we study the stability properties of these simplices. We find that the simplex structure disappears under small adversarial attacks, and that perturbed examples \"leap\" between simplex vertices. We further analyze the geometry of networks that are optimized to be robust against adversarial perturbations of the input, and find that Neural Collapse is a pervasive phenomenon in these cases as well, with clean and perturbed representations forming aligned simplices, and giving rise to a robust simple nearest-neighbor classifier. By studying the propagation of the amount of collapse inside the network, we identify novel properties of both robust and non-robust machine learning models, and show that earlier, unlike later layers maintain reliable simplices on perturbed data",
    "checked": true,
    "id": "72da387dda40b29fa25d28e324a4e9a0cc3feec9",
    "semantic_title": "on the robustness of neural collapse and the neural collapse of robustness",
    "citation_count": 7,
    "authors": [
      "Jingtong Su",
      "Ya Shi Zhang",
      "Nikolaos Tsilivis",
      "Julia Kempe"
    ]
  },
  "https://openreview.net/forum?id=bZ80b0wb9d": {
    "title": "Discrete Graph Auto-Encoder",
    "volume": "main",
    "abstract": "Despite advances in generative methods, accurately modeling the distribution of graphs remains a challenging task primarily because of the absence of predefined or inherent unique graph representation. Two main strategies have emerged to tackle this issue: 1) restricting the number of possible representations by sorting the nodes, or 2) using permutation-invariant/equivariant functions, specifically Graph Neural Networks (GNNs). In this paper, we introduce a new framework named Discrete Graph Auto-Encoder (DGAE), which leverages the strengths of both strategies and mitigate their respective limitations. In essence, we propose a strategy in 2 steps. We first use a permutation-equivariant auto-encoder to convert graphs into sets of discrete latent node representations, each node being represented by a sequence of quantized vectors. In the second step, we sort the sets of discrete latent representations and learn their distribution with a specifically designed auto-regressive model based on the Transformer architecture. Through multiple experimental evaluations, we demonstrate the competitive performances of our model in comparison to the existing state-of-the-art across various datasets. Various ablation studies support the interest of our method",
    "checked": true,
    "id": "014a80979ebeac7e3e688306caf217485885b463",
    "semantic_title": "discrete graph auto-encoder",
    "citation_count": 4,
    "authors": [
      "Yoann Boget",
      "Magda Gregorova",
      "Alexandros Kalousis"
    ]
  },
  "https://openreview.net/forum?id=wE9kpJSemv": {
    "title": "Indexed Minimum Empirical Divergence-Based Algorithms for Linear Bandits",
    "volume": "main",
    "abstract": "The Indexed Minimum Empirical Divergence (IMED) algorithm is a highly effective approach that offers a stronger theoretical guarantee of the asymptotic optimality compared to the Kullback--Leibler Upper Confidence Bound (KL-UCB) algorithm for the multi-armed bandit problem. Additionally, it has been observed to empirically outperform UCB-based algorithms and Thompson Sampling. Despite its effectiveness, the generalization of this algorithm to contextual bandits with linear payoffs has remained elusive. In this paper, we present novel linear versions of the IMED algorithm, which we call the family of LinIMED algorithms. We demonstrate that LinIMED provides a $\\widetilde{O}(d\\sqrt{T})$ upper regret bound where $d$ is the dimension of the context and $T$ is the time horizon. Furthermore, extensive empirical studies reveal that LinIMED and its variants outperform widely-used linear bandit algorithms such as LinUCB and Linear Thompson Sampling in some regimes",
    "checked": true,
    "id": "d33512acb3f91631a0ed2d67ba7ea0fa5f0ec37d",
    "semantic_title": "indexed minimum empirical divergence-based algorithms for linear bandits",
    "citation_count": 0,
    "authors": [
      "Jie Bian",
      "Vincent Y. F. Tan"
    ]
  },
  "https://openreview.net/forum?id=Fu4mwB0XIU": {
    "title": "PID Control-Based Self-Healing to Improve the Robustness of Large Language Models",
    "volume": "main",
    "abstract": "Despite the effectiveness of deep neural networks in numerous natural language processing applications, recent findings have exposed the vulnerability of these language models when minor perturbations are introduced. While appearing semantically indistinguishable to humans, these perturbations can significantly reduce the performance of well-trained language models, raising concerns about the reliability of deploying them in safe-critical situations. In this work, we construct a computationally efficient self-healing process to correct undesired model behavior during online inference when perturbations are applied to input data. This is formulated as a trajectory optimization problem in which the internal states of the neural network layers are automatically corrected using a PID (Proportional-Integral-Derivative) control mechanism. The P controller targets immediate state adjustments, while the I and D controllers consider past states and future dynamical trends, respectively. We leverage the geometrical properties of the training data to design effective linear PID controllers. This approach reduces the computational cost to that of using just the P controller, instead of the full PID control. Further, we introduce an analytical method for approximating the optimal control solutions, enhancing the real-time inference capabilities of this controlled system. Moreover, we conduct a theoretical error analysis of the analytic solution in a simplified setting. The proposed PID control-based self-healing is a low-cost framework that improves the robustness of pre-trained large language models, whether standard or robustly trained, against a wide range of perturbations",
    "checked": true,
    "id": "4302593601e57a1c4cb487d871723b9d11a8e2b2",
    "semantic_title": "pid control-based self-healing to improve the robustness of large language models",
    "citation_count": 1,
    "authors": [
      "Zhuotong Chen",
      "Zihu Wang",
      "Yifan Yang",
      "Qianxiao Li",
      "Zheng Zhang"
    ]
  },
  "https://openreview.net/forum?id=c5o4HUypqm": {
    "title": "Synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity",
    "volume": "main",
    "abstract": "In federated learning, data heterogeneity is a critical challenge. A straightforward solution is to shuffle the clients' data to homogenize the distribution. However, this may violate data access rights, and how and when shuffling can accelerate the convergence of a federated optimization algorithm is not theoretically well understood. In this paper, we establish a precise and quantifiable correspondence between data heterogeneity and parameters in the convergence rate when a fraction of data is shuffled across clients. We discuss that shuffling can, in some cases, quadratically reduce the gradient dissimilarity with respect to the shuffling percentage, accelerating convergence. Inspired by the theory, we propose a practical approach that addresses the data access rights issue by shuffling locally generated synthetic data. The experimental results show that shuffling synthetic data improves the performance of multiple existing federated learning algorithms by a large margin",
    "checked": true,
    "id": "5779b4c9488633ce70830c88c90b0bf78b81cec9",
    "semantic_title": "synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity",
    "citation_count": 3,
    "authors": [
      "Bo Li",
      "Yasin Esfandiari",
      "Mikkel N. Schmidt",
      "Tommy Sonne AlstrÃ¸m",
      "Sebastian U Stich"
    ]
  },
  "https://openreview.net/forum?id=LO02YHxrxd": {
    "title": "Graph Neural Networks Formed via Layer-wise Ensembles of Heterogeneous Base Models",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) with numerical node features and graph structure as inputs have demonstrated superior performance on various semi-supervised learning tasks with graph data. However, the numerical node features utilized by GNNs are commonly extracted from raw data which is of text or tabular (numeric/categorical) type in most real-world applications. The best models for such data types in most standard supervised learning settings with IID (non-graph) data are not simple neural network layers and thus are not easily incorporated into a GNN. Here we propose a robust stacking framework that fuses graph-aware propagation with arbitrary models intended for IID data, which are ensembled and stacked in multiple layers. Our layer-wise framework leverages bagging and stacking strategies to enjoy strong generalization, in a manner which effectively mitigates label leakage and overfitting. Across a variety of graph datasets with tabular/text node features, our method achieves comparable or superior performance relative to both tabular/text and graph neural network models, as well as existing state-of-the-art hybrid strategies that combine the two",
    "checked": true,
    "id": "9a678caf2e4c94a92a4355e9a2c4c10faaa87530",
    "semantic_title": "graph neural networks formed via layer-wise ensembles of heterogeneous base models",
    "citation_count": 0,
    "authors": [
      "Jiuhai Chen",
      "Jonas Mueller",
      "Vassilis N. Ioannidis",
      "Tom Goldstein",
      "David Wipf"
    ]
  },
  "https://openreview.net/forum?id=lQE2AcbYge": {
    "title": "Online Continuous Hyperparameter Optimization for Generalized Linear Contextual Bandits",
    "volume": "main",
    "abstract": "In stochastic contextual bandits, an agent sequentially makes actions from a time-dependent action set based on past experience to minimize the cumulative regret. Like many other machine learning algorithms, the performance of bandits heavily depends on the values of hyperparameters, and theoretically derived parameter values may lead to unsatisfactory results in practice. Moreover, it is infeasible to use offline tuning methods like cross-validation to choose hyperparameters under the bandit environment, as the decisions should be made in real-time. To address this challenge, we propose the first online continuous hyperparameter tuning framework for contextual bandits to learn the optimal parameter configuration in practice within a search space on the fly. Specifically, we use a double-layer bandit framework named CDT (Continuous Dynamic Tuning) and formulate the hyperparameter optimization as a non-stationary continuum-armed bandit, where each arm represents a combination of hyperparameters, and the corresponding reward is the algorithmic result. For the top layer, we propose the Zooming TS algorithm that utilizes Thompson Sampling (TS) for exploration and a restart technique to get around the \\textit{switching} environment. The proposed CDT framework can be easily utilized to tune contextual bandit algorithms without any pre-specified candidate set for multiple hyperparameters. We further show that it could achieve a sublinear regret in theory and performs consistently better than all existing methods on both synthetic and real datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Kang",
      "Cho-Jui Hsieh",
      "Thomas Lee"
    ]
  },
  "https://openreview.net/forum?id=VBAKc4DtZ1": {
    "title": "Faster Convergence of Local SGD for Over-Parameterized Models",
    "volume": "main",
    "abstract": "Modern machine learning architectures are often highly expressive. They are usually over-parameterized and can interpolate the data by driving the empirical loss close to zero. We analyze the convergence of Local SGD (or FedAvg) for such over-parameterized models in the heterogeneous data setting and improve upon the existing literature by establishing the following convergence rates. For general convex loss functions, we establish an error bound of $\\mathcal {O}(1/T)$ under a mild data similarity assumption and an error bound of $\\mathcal {O}(K/T)$ otherwise, where $K$ is the number of local steps and $T$ is the total number of iterations. For non-convex loss functions we prove an error bound of $\\mathcal {O}(K/T)$. These bounds improve upon the best previous bound of $\\mathcal {O}(1/\\sqrt{nT})$ in both cases, where $n$ is the number of agents, when no assumption on the model being over-parameterized is made. We complete our results by providing problem instances in which our established convergence rates are tight to a constant factor with a reasonably small stepsize. Finally, we validate our theoretical results by performing large-scale numerical experiments that reveal the convergence behavior of Local SGD for practical over-parameterized deep learning models, in which the $\\mathcal {O}(1/T)$ convergence rate of Local SGD is clearly shown",
    "checked": true,
    "id": "e48364267077e5063492bc6b0d0e9ae22eda18e1",
    "semantic_title": "faster convergence of local sgd for over-parameterized models",
    "citation_count": 6,
    "authors": [
      "Tiancheng Qin",
      "S. Rasoul Etesami",
      "Cesar A Uribe"
    ]
  },
  "https://openreview.net/forum?id=zOGJxw07Z6": {
    "title": "Asynchronous Training Schemes in Distributed Learning with Time Delay",
    "volume": "main",
    "abstract": "In the context of distributed deep learning, the issue of stale weights or gradients could result in poor algorithmic performance. This issue is usually tackled by delay tolerant algorithms with some mild assumptions on the objective functions and step sizes. In this paper, we propose a different approach to develop a new algorithm, called \\textbf{P}redicting \\textbf{C}lipping \\textbf{A}synchronous \\textbf{S}tochastic \\textbf{G}radient \\textbf{D}escent (aka, PC-ASGD). Specifically, PC-ASGD has two steps - the \\textit{predicting step} leverages the gradient prediction using Taylor expansion to reduce the staleness of the outdated weights while the \\textit{clipping step} selectively drops the outdated weights to alleviate their negative effects. A tradeoff parameter is introduced to balance the effects between these two steps. Theoretically, we present the convergence rate considering the effects of delay of the proposed algorithm with constant step size when the smooth objective functions are weakly strongly-convex, general convex, and nonconvex. One practical variant of PC-ASGD is also proposed by adopting a condition to help with the determination of the tradeoff parameter. For empirical validation, we demonstrate the performance of the algorithm with four deep neural network architectures on three benchmark datasets",
    "checked": true,
    "id": "4527389934c209c050a482ac20ba86f14cf17b42",
    "semantic_title": "asynchronous training schemes in distributed learning with time delay",
    "citation_count": 2,
    "authors": [
      "Haoxiang Wang",
      "Zhanhong Jiang",
      "Chao Liu",
      "Soumik Sarkar",
      "Dongxiang Jiang",
      "Young M Lee"
    ]
  },
  "https://openreview.net/forum?id=qNGo6ghWFB": {
    "title": "Merging by Matching Models in Task Parameter Subspaces",
    "volume": "main",
    "abstract": "Model merging aims to cheaply combine individual task-specific models into a single multitask model. In this work, we view past merging methods as leveraging different notions of a ''task parameter subspace'' in which models are matched before being merged. We connect the task parameter subspace of a given model to its loss landscape and formalize how this approach to model merging can be seen as solving a linear system of equations. While past work has generally been limited to linear systems that have a closed-form solution, we consider using the conjugate gradient method to find a solution. We show that using the conjugate gradient method can outperform closed-form solutions, enables merging via linear systems that are otherwise intractable to solve, and flexibly allows choosing from a wide variety of initializations and estimates for the ''task parameter subspace''. We ultimately demonstrate that our merging framework called ''Matching Models in their Task Parameter Subspace'' (MATS) achieves state-of-the-art results in multitask and intermediate-task model merging. We release all of the code and checkpoints used in our work",
    "checked": true,
    "id": "e5a2c0759027c946df23cce37a8a3104d5c48841",
    "semantic_title": "merging by matching models in task parameter subspaces",
    "citation_count": 12,
    "authors": [
      "Derek Tam",
      "Mohit Bansal",
      "Colin Raffel"
    ]
  },
  "https://openreview.net/forum?id=6yzIuqKGnq": {
    "title": "INSPIRE: Incorporating Diverse Feature Preferences in Recourse",
    "volume": "main",
    "abstract": "Most recourse generation approaches optimize for indirect distance-based metrics like diversity, proximity, and sparsity, or a shared cost function across all users. A shared cost function in particular is an unrealistic assumption because users can have diverse feature preferences (FPs), i.e. the features they are willing to act upon to obtain recourse. In this work, we propose a novel method, INSPIRE to incorporate diverse feature preferences in both recourse generation and evaluation procedures by focusing on the cost incurred by a user when opting for a recourse. To achieve this, we first propose an objective function, Expected Minimum Cost (EMC) based on two key ideas: (1) the user should be comfortable adopting at least one solution when presented with multiple options, and (2) we can provide users with multiple options that cover a wide variety of FPs when the user's FPs are unknown. To optimize for EMC, we propose a novel discrete optimization algorithm, Cost-Optimized Local Search (COLS), that is guaranteed to improve the quality of the recourse set over iterations. Next, we propose a cost-based evaluation procedure that computes user satisfaction by simulating each user's cost function and then computing the incurred cost for the provided recourse set. Experiments on popular real-world datasets demonstrate that our method is more fair compared to baselines and satisfies up to 25.9% more users. We also show that our method is robust to misspecifications of the cost function distribution. Our code is available at \\href{https://github.com/prateeky2806/EMC-COLS-recourse}{https://github.com/prateeky2806/EMC-COLS-recourse}",
    "checked": true,
    "id": "0f8b740d097885d6dfd32fcd183280c8fb2b5cf0",
    "semantic_title": "inspire: incorporating diverse feature preferences in recourse",
    "citation_count": 0,
    "authors": [
      "Prateek Yadav",
      "Peter Hase",
      "Mohit Bansal"
    ]
  },
  "https://openreview.net/forum?id=1QjCzP0KIw": {
    "title": "Unsupervised 3D Scene Representation Learning via Movable Object Inference",
    "volume": "main",
    "abstract": "Unsupervised, category-agnostic, object-centric 3D representation learning for complex scenes remains an open problem in computer vision. While a few recent methods can discover 3D objects from a single image, they remain struggling on scenes with diverse and complex object configurations as they discover objects mostly by appearance similarity which is insufficient for textured objects. In this work, we propose Movable Object Radiance Fields (MORF), aiming at scaling to complex scenes with diverse categories of objects. Inspired by cognitive science studies of object learning in babies, MORF learns 3D object representations via movable object inference. While obtaining 3D movable object signals requires multi-view videos of moving objects, we propose lifting a 2D movable object inference module that can be unsupervisedly pretrained on monocular videos. Thus, MORF requires only multi-view images of static training scenes. During testing, MORF can discover, reconstruct, and move unseen objects from novel categories, all from a single image of novel scenes. We propose a challenging simulated dataset with a diverse set of textured objects for training and testing. Experiments show that MORF extracts accurate object geometry and supports realistic object and scene reconstruction and editing, significantly outperforming the state-of-the-art",
    "checked": true,
    "id": "3508622191ed3d09942ebb7ab35f03058dbfd6b2",
    "semantic_title": "unsupervised 3d scene representation learning via movable object inference",
    "citation_count": 3,
    "authors": [
      "Honglin Chen",
      "Wanhee Lee",
      "Hong-Xing Yu",
      "Rahul Mysore Venkatesh",
      "Joshua B. Tenenbaum",
      "Daniel Bear",
      "Jiajun Wu",
      "Daniel LK Yamins"
    ]
  },
  "https://openreview.net/forum?id=OycfV3Mhfq": {
    "title": "Convergence Analysis of Fractional Gradient Descent",
    "volume": "main",
    "abstract": "Fractional derivatives are a well-studied generalization of integer order derivatives. Naturally, for optimization, it is of interest to understand the convergence properties of gradient descent using fractional derivatives. Convergence analysis of fractional gradient descent is currently limited both in the methods analyzed and the settings analyzed. This paper aims to fill in these gaps by analyzing variations of fractional gradient descent in smooth and convex, smooth and strongly convex, and smooth and non-convex settings. First, novel bounds will be established bridging fractional and integer derivatives. Then, these bounds will be applied to the aforementioned settings to prove linear convergence for smooth and strongly convex functions and $O(1/T)$ convergence for smooth and convex functions. Additionally, we prove $O(1/T)$ convergence for smooth and non-convex functions using an extended notion of smoothness - H\\\"older smoothness - that is more natural for fractional derivatives. Finally, empirical results will be presented on the potential speed up of fractional gradient descent over standard gradient descent as well as some preliminary theoretical results explaining this speed up",
    "checked": true,
    "id": "6be30d276a9462a971b46573c77f12aa6b6f7c1d",
    "semantic_title": "convergence analysis of fractional gradient descent",
    "citation_count": 1,
    "authors": [
      "Ashwani Aggarwal"
    ]
  },
  "https://openreview.net/forum?id=i02A009I5a": {
    "title": "VidEdit: Zero-Shot and Spatially Aware Text-Driven Video Editing",
    "volume": "main",
    "abstract": "Recently, diffusion-based generative models have achieved remarkable success for image generation and edition. However, existing diffusion-based video editing approaches lack the ability to offer precise control over generated content that maintains temporal consistency in long-term videos. On the other hand, atlas-based methods provide strong temporal consistency but are costly to edit a video and lack spatial control. In this work, we introduce VidEdit, a novel method for zero-shot text-based video editing that guarantees robust temporal and spatial consistency. In particular, we combine an atlas-based video representation with a pre-trained text-to-image diffusion model to provide a training-free and efficient video editing method, which by design fulfills temporal smoothness. To grant precise user control over generated content, we utilize conditional information extracted from off-the-shelf panoptic segmenters and edge detectors which guides the diffusion sampling process. This method ensures a fine spatial control on targeted regions while strictly preserving the structure of the original video. Our quantitative and qualitative experiments show that VidEdit outperforms state-of-the-art methods on DAVIS dataset, regarding semantic faithfulness, image preservation, and temporal consistency metrics. With this framework, processing a single video only takes approximately one minute, and it can generate multiple compatible edits based on a unique text prompt",
    "checked": true,
    "id": "33e7493ebe199b44620957e91f65f5b2de34df5e",
    "semantic_title": "videdit: zero-shot and spatially aware text-driven video editing",
    "citation_count": 30,
    "authors": [
      "Paul Couairon",
      "ClÃ©ment Rambour",
      "Jean-Emmanuel HAUGEARD",
      "Nicolas THOME"
    ]
  },
  "https://openreview.net/forum?id=oYIjw37pTP": {
    "title": "An optimal control perspective on diffusion-based generative modeling",
    "volume": "main",
    "abstract": "We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton--Jacobi--Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback--Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approaches on multiple numerical examples",
    "checked": true,
    "id": "5f8c041cb8985ee922625b5e65bece10e646f31f",
    "semantic_title": "an optimal control perspective on diffusion-based generative modeling",
    "citation_count": 95,
    "authors": [
      "Julius Berner",
      "Lorenz Richter",
      "Karen Ullrich"
    ]
  },
  "https://openreview.net/forum?id=xqAVkqrLjx": {
    "title": "HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes",
    "volume": "main",
    "abstract": "Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on image datasets show that HQ-VAE enhances codebook usage and improves reconstruction performance. We also validated HQ-VAE in terms of its applicability to a different modality with an audio dataset",
    "checked": true,
    "id": "316073877918ffe26e5a3baeb28d1c2dec760d54",
    "semantic_title": "hq-vae: hierarchical discrete representation learning with variational bayes",
    "citation_count": 13,
    "authors": [
      "Yuhta Takida",
      "Yukara Ikemiya",
      "Takashi Shibuya",
      "Kazuki Shimada",
      "Woosung Choi",
      "Chieh-Hsin Lai",
      "Naoki Murata",
      "Toshimitsu Uesaka",
      "Kengo Uchida",
      "Wei-Hsiang Liao",
      "Yuki Mitsufuji"
    ]
  },
  "https://openreview.net/forum?id=chbRsWwjax": {
    "title": "InfoNCE is variational inference in a recognition parameterised model",
    "volume": "main",
    "abstract": "Here, we develop a new class of Bayesian latent variable model, the recognition parameterised model (RPM). RPMs have an implicit likelihood, which is defined in terms of the recognition model. Therefore, it is not possible to do traditional \"generation\" with RPMs. Instead, RPMs are designed to learn good latent representations of data (in modern parlance, they solve a self-supervised learning task). Indeed, the RPM implicit likelihood is specifically designed so that it drops out of the VI objective, the ELBO. That allows us to learn an RPM without a \"reconstruction\" step, which is believed to be at the root of poor latent representations learned by VAEs. Indeed, in a very specific setting where we learn the optimal prior, the RPM ELBO becomes equal to the mutual information (MI; up to a constant), establishing a connection to pre-existing self-supervised learning methods such as InfoNCE",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Laurence Aitchison",
      "Stoil Krasimirov Ganev"
    ]
  },
  "https://openreview.net/forum?id=cgSXpAR4Gl": {
    "title": "Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees",
    "volume": "main",
    "abstract": "Robustness and safety are critical for the trustworthy deployment of deep reinforcement learning. Real-world decision making applications require algorithms that can guarantee robust performance and safety in the presence of general environment disturbances, while making limited assumptions on the data collection process during training. In order to accomplish this goal, we introduce a safe reinforcement learning framework that incorporates robustness through the use of an optimal transport cost uncertainty set. We provide an efficient implementation based on applying Optimal Transport Perturbations to construct worst-case virtual state transitions, which does not impact data collection during training and does not require detailed simulator access. In experiments on continuous control tasks with safety constraints, our approach demonstrates robust performance while significantly improving safety at deployment time compared to standard safe reinforcement learning",
    "checked": true,
    "id": "29c218fa2bf6e2f01c6bd8f3e4db95fcc7b47fb4",
    "semantic_title": "optimal transport perturbations for safe reinforcement learning with robustness guarantees",
    "citation_count": 7,
    "authors": [
      "James Queeney",
      "Erhan Can Ozcan",
      "Ioannis Paschalidis",
      "Christos Cassandras"
    ]
  },
  "https://openreview.net/forum?id=mhawjZcmrJ": {
    "title": "New Guarantees for Learning Revenue Maximizing Menus of Lotteries and Two-Part Tariffs",
    "volume": "main",
    "abstract": "We advance a recently flourishing line of work at the intersection of learning theory and computational economics by studying the learnability of two classes of mechanisms prominent in economics, namely menus of lotteries and two-part tariffs. The former is a family of randomized mechanisms designed for selling multiple items, known to achieve revenue beyond deterministic mechanisms, while the latter is designed for selling multiple units (copies) of a single item with applications in real-world scenarios such as car or bike-sharing services. We focus on learning high-revenue mechanisms of this form from buyer valuation data in both distributional settings, where we have access to buyers' valuation samples up-front, and the more challenging and less-studied online settings, where buyers arrive one-at-a-time and no distributional assumption is made about their values. We provide a suite of results with regard to these two families of mechanisms. We provide the first online learning algorithms for menus of lotteries and two-part tariffs with strong regret-bound guarantees. Since the space of parameters is infinite and the revenue functions have discontinuities, the known techniques do not readily apply. However, we are able to provide a reduction to online learning over a finite number of experts, in our case, a finite number of parameters. Furthermore, in the limited buyers type case, we show a reduction to online linear optimization, which allows us to obtain no-regret guarantees by presenting buyers with menus that correspond to a barycentric spanner. In addition, we provide algorithms with improved running times over prior work for the distributional settings. Finally, we demonstrate how techniques from the recent literature in data-driven algorithm design are insufficient for our studied problems",
    "checked": true,
    "id": "0333aa501a7cec4363c0f395774812c38f9ee013",
    "semantic_title": "new guarantees for learning revenue maximizing menus of lotteries and two-part tariffs",
    "citation_count": 4,
    "authors": [
      "Maria Florina Balcan",
      "Hedyeh Beyhaghi"
    ]
  },
  "https://openreview.net/forum?id=Xxw0edFFQC": {
    "title": "Optical Transformers",
    "volume": "main",
    "abstract": "The rapidly increasing size of deep-learning models has renewed interest in alternatives to digital-electronic computers as a means to dramatically reduce the energy cost of running state-of-the-art neural networks. Optical matrix-vector multipliers are best suited to performing computations with very large operands, which suggests that large Transformer models could be a good target for them. In this paper, we investigate---through a combination of simulations and experiments on prototype optical hardware---the feasibility and potential energy benefits of running Transformer models on future optical accelerators that perform matrix-vector multiplication. We use simulations, with noise models validated by small-scale optical experiments, to show that optical accelerators for matrix-vector multiplication should be able to accurately run a typical Transformer architecture model for language processing. We demonstrate that optical accelerators can achieve the same (or better) perplexity as digital-electronic processors at 8-bit precision, provided that the optical hardware uses sufficiently many photons per inference, which translates directly to a requirement on optical energy per inference. We studied numerically how the requirement on optical energy per inference changes as a function of the Transformer width $d$ and found that the optical energy per multiply--accumulate (MAC) scales approximately as $\\frac{1}{d}$, giving an asymptotic advantage over digital systems. We also analyze the total system energy costs for optical accelerators running Transformers, including both optical and electronic costs, as a function of model size. We predict that well-engineered, large-scale optical hardware should be able to achieve a $100 \\times$ energy-efficiency advantage over current digital-electronic processors in running some of the largest current Transformer models, and if both the models and the optical hardware are scaled to the quadrillion-parameter regime, optical accelerators could have a $>8,000\\times$ energy-efficiency advantage. Under plausible assumptions about future improvements to electronics and Transformer quantization techniques (5Ã cheaper memory access, double the digital--analog conversion efficiency, and 4-bit precision), we estimate that the energy advantage for optical processors versus electronic processors operating at 300~fJ/MAC could grow to $>100,000\\times$",
    "checked": true,
    "id": "139ebdcaa3d5f60a3c5289bb61d5865141886d51",
    "semantic_title": "optical transformers",
    "citation_count": 23,
    "authors": [
      "Maxwell Anderson",
      "Shi-Yuan Ma",
      "Tianyu Wang",
      "Logan Wright",
      "Peter McMahon"
    ]
  },
  "https://openreview.net/forum?id=Db5c3Wxj9E": {
    "title": "Embracing Unknown Step by Step: Towards Reliable Sparse Training in Real World",
    "volume": "main",
    "abstract": "Sparse training has emerged as a promising method for resource-efficient deep neural networks (DNNs) in real-world applications. However, the reliability of sparse models remains a crucial concern, particularly in detecting unknown out-of-distribution (OOD) data. This study addresses the knowledge gap by investigating the reliability of sparse training from an OOD perspective and reveals that sparse training exacerbates OOD unreliability. The lack of unknown information and the sparse constraints hinder the effective exploration of weight space and accurate differentiation between known and unknown knowledge. To tackle these challenges, we propose a new unknown-aware sparse training method, which incorporates a loss modification, auto-tuning strategy, and a voting scheme to guide weight space exploration and mitigate confusion between known and unknown information without incurring significant additional costs or requiring access to additional OOD data. Theoretical insights demonstrate how our method reduces model confidence when faced with OOD samples. Empirical experiments across multiple datasets, model architectures, and sparsity levels validate the effectiveness of our method, with improvements of up to \\textbf{8.4\\%} in AUROC while maintaining comparable or higher accuracy and calibration. This research enhances the understanding and readiness of sparse DNNs for deployment in resource-limited applications. Our code is available on: \\url{https://github.com/StevenBoys/MOON}",
    "checked": true,
    "id": "3483f2ac5e931d991ae11aa54996e23c7827a5ae",
    "semantic_title": "embracing unknown step by step: towards reliable sparse training in real world",
    "citation_count": 0,
    "authors": [
      "Bowen Lei",
      "Dongkuan Xu",
      "Ruqi Zhang",
      "Bani Mallick"
    ]
  },
  "https://openreview.net/forum?id=WbbgOHpoPX": {
    "title": "Revisiting Random Weight Perturbation for Efficiently Improving Generalization",
    "volume": "main",
    "abstract": "Improving the generalization ability of modern deep neural networks (DNNs) is a fundamental challenge in machine learning. Two branches of methods have been proposed to seek flat minima and improve generalization: one led by sharpness-aware minimization (SAM) minimizes the worst-case neighborhood loss through adversarial weight perturbation (AWP), and the other minimizes the expected Bayes objective with random weight perturbation (RWP). While RWP offers advantages in computation and is closely linked to AWP on a mathematical basis, its empirical performance has consistently lagged behind that of AWP. In this paper, we revisit the use of RWP for improving generalization and propose improvements from two perspectives: i) the trade-off between generalization and convergence and ii) the random perturbation generation. Through extensive experimental evaluations, we demonstrate that our enhanced RWP methods achieve greater efficiency in enhancing generalization, particularly in large-scale problems, while also offering comparable or even superior performance to SAM. The code is released at https://github.com/nblt/mARWP",
    "checked": true,
    "id": "3839d0b22aba059b28cc394dea285701592878ea",
    "semantic_title": "revisiting random weight perturbation for efficiently improving generalization",
    "citation_count": 6,
    "authors": [
      "Tao Li",
      "Qinghua Tao",
      "Weihao Yan",
      "Yingwen Wu",
      "Zehao Lei",
      "Kun Fang",
      "Mingzhen He",
      "Xiaolin Huang"
    ]
  },
  "https://openreview.net/forum?id=HxfqTdLIRF": {
    "title": "Double Descent and Overfitting under Noisy Inputs and Distribution Shift for Linear Denoisers",
    "volume": "main",
    "abstract": "Despite the importance of denoising in modern machine learning and ample empirical work on supervised denoising, its theoretical understanding is still relatively scarce. One concern about studying supervised denoising is that one might not always have noiseless training data from the test distribution. It is more reasonable to have access to noiseless training data from a different dataset than the test dataset. Motivated by this, we study supervised denoising and noisy-input regression under distribution shift. We add three considerations to increase the applicability of our theoretical insights to real-life data and modern machine learning. First, while most past theoretical work assumes that the data covariance matrix is full-rank and well-conditioned, empirical studies have shown that real-life data is approximately low-rank. Thus, we assume that our data matrices are low-rank. Second, we drop independence assumptions on our data. Third, the rise in computational power and dimensionality of data have made it important to study non-classical regimes of learning. Thus, we work in the non-classical proportional regime, where data dimension $d$ and number of samples $N$ grow as $d/N = c + o(1)$. For this setting, we derive \\rishi{data-dependent, instance specific} expressions for the test error for both denoising and noisy-input regression, and study when overfitting the noise is benign, tempered or catastrophic. We show that the test error exhibits double descent under general distribution shift, providing insights for data augmentation and the role of noise as an implicit regularizer. We also perform experiments using real-life data, where we match the theoretical predictions with under 1\\% MSE error for low-rank data",
    "checked": true,
    "id": "0f831471a596a5cbc0c49f0f3dcb1f73b1ec83cf",
    "semantic_title": "double descent and overfitting under noisy inputs and distribution shift for linear denoisers",
    "citation_count": 0,
    "authors": [
      "Chinmaya Kausik",
      "Kashvi Srivastava",
      "Rishi Sonthalia"
    ]
  },
  "https://openreview.net/forum?id=daXqjb6dVE": {
    "title": "From Differential Privacy to Bounds on Membership Inference: Less can be More",
    "volume": "main",
    "abstract": "Differential Privacy (DP) is the de facto standard for reasoning about the privacy of a training algorithm. Yet, learning with DP often yields poor performance unless one trains on a large dataset. In this paper, we instead outline how training on less data can be beneficial when we are only interested in defending against specific attacks; we take the canonical example of defending against membership inference. To arrive at this result, we first derive (tight) bounds on the success of all membership inference attacks. These bounds do not replace DP, rather they introduce a complementary interpretation of a DP algorithm's ability to defend against membership inference specifically. Because our bound more tightly captures the effect of how training data was selected, we can show that decreasing the sampling rate when constructing the training dataset has a disparate effect on the bound when compared to strengthening the DP guarantee. Thus, when the privacy protection we care about is defending against membership inference, training on less data can yield more advantageous trade-offs between preventing membership inference and utility than strengthening the DP guarantee. We empirically illustrate this on MNIST, CIFAR10 and SVHN-extended",
    "checked": true,
    "id": "ccae56b0054151feaf16f6d1c24155067d8168af",
    "semantic_title": "from differential privacy to bounds on membership inference: less can be more",
    "citation_count": 0,
    "authors": [
      "Anvith Thudi",
      "Ilia Shumailov",
      "Franziska Boenisch",
      "Nicolas Papernot"
    ]
  },
  "https://openreview.net/forum?id=1fNcpcdr1o": {
    "title": "CiPR: An Efficient Framework with Cross-instance Positive Relations for Generalized Category Discovery",
    "volume": "main",
    "abstract": "We tackle the issue of generalized category discovery (GCD). GCD considers the open-world problem of automatically clustering a partially labelled dataset, in which the unlabelled data may contain instances from both novel categories and labelled classes. In this paper, we address the GCD problem with an unknown category number for the unlabelled data. We propose a framework, named CiPR, to bootstrap the representation by exploiting cross-instance positive relations in the partially labelled data for contrastive learning, which have been neglected in existing methods. To obtain reliable cross-instance relations to facilitate representation learning, we introduce a semi-supervised hierarchical clustering algorithm, named selective neighbor clustering (SNC), which can produce a clustering hierarchy directly from the connected components of a graph constructed from selective neighbors. We further present a method to estimate the unknown class number using SNC with a joint reference score that considers clustering indexes of both labelled and unlabelled data, and extend SNC to allow label assignment for the unlabelled instances with a given class number. We thoroughly evaluate our framework on public generic image recognition datasets and challenging fine-grained datasets, and establish a new state-of-the-art. Code: https://github.com/haoosz/CiPR",
    "checked": true,
    "id": "c2c114fb7747dc7eb240a8657a810ab229c4ee49",
    "semantic_title": "cipr: an efficient framework with cross-instance positive relations for generalized category discovery",
    "citation_count": 18,
    "authors": [
      "Shaozhe Hao",
      "Kai Han",
      "Kwan-Yee K. Wong"
    ]
  },
  "https://openreview.net/forum?id=H2EeStRTQn": {
    "title": "Introducing \"Forecast Utterance\" for Conversational Data Science",
    "volume": "main",
    "abstract": "Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes. A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks. In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances. Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task. We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques. Our experiments, evaluated with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances",
    "checked": true,
    "id": "f8bd251dfb1f0640440eafc3e535821f2d007dd5",
    "semantic_title": "introducing \"forecast utterance\" for conversational data science",
    "citation_count": 0,
    "authors": [
      "Md. Mahadi Hassan",
      "Alex Knipper",
      "Shubhra Kanti Karmaker Santu"
    ]
  },
  "https://openreview.net/forum?id=Pe6hldOUkw": {
    "title": "Optimal Inference in Contextual Stochastic Block Models",
    "volume": "main",
    "abstract": "The contextual stochastic block model (CSBM) was proposed for unsupervised community detection on attributed graphs where both the graph and the high-dimensional node information correlate with node labels. In the context of machine learning on graphs, the CSBM has been widely used as a synthetic dataset for evaluating the performance of graph-neural networks (GNNs) for semi-supervised node classification. We consider a probabilistic Bayes-optimal formulation of the inference problem and we derive a belief-propagation-based algorithm for the semi-supervised CSBM; we conjecture it is optimal in the considered setting and we provide its implementation. We show that there can be a considerable gap between the accuracy reached by this algorithm and the performance of the GNN architectures proposed in the literature. This suggests that the CSBM, along with the comparison to the performance of the optimal algorithm, readily accessible via our implementation, can be instrumental in the development of more performant GNN architectures",
    "checked": true,
    "id": "e73d0775b3964906594e0f0980515642d656db26",
    "semantic_title": "optimal inference in contextual stochastic block models",
    "citation_count": 10,
    "authors": [
      "O Duranthon",
      "Lenka Zdeborova"
    ]
  },
  "https://openreview.net/forum?id=ux9BrxPCl8": {
    "title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity",
    "volume": "main",
    "abstract": "In some settings neural networks exhibit a phenomenon known as \\textit{grokking}, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression, linear regression and Bayesian neural networks. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures shows that grokking is not restricted to settings considered in current theoretical and empirical studies. Instead, grokking may be possible in any model where solution search is guided by complexity and error",
    "checked": true,
    "id": "0c8b7af8ebb4c1039ba730803bc3e82dd02f8b62",
    "semantic_title": "grokking beyond neural networks: an empirical exploration with model complexity",
    "citation_count": 10,
    "authors": [
      "Jack William Miller",
      "Charles O'Neill",
      "Thang D Bui"
    ]
  },
  "https://openreview.net/forum?id=s1qh12FReM": {
    "title": "Compressing the Activation Maps in Deep Convolutional Neural Networks and Its Regularizing Effect",
    "volume": "main",
    "abstract": "Deep learning has dramatically improved performance in various image analysis applications in the last few years. However, recent deep learning architectures can be very large, with up to hundreds of layers and millions or even billions of model parameters that are impossible to fit into commodity graphics processing units. We propose a novel approach for compressing high-dimensional activation maps, the most memory-consuming part when training modern deep learning architectures. The proposed method can be used to compress the feature maps of a single layer, multiple layers, or the entire network according to specific needs. To this end, we also evaluated three different methods to compress the activation maps: Wavelet Transform, Discrete Cosine Transform, and Simple Thresholding. We performed experiments in two classification tasks for natural images and two semantic segmentation tasks for medical images. Using the proposed method, we could reduce the memory usage for activation maps by up to 95%. Additionally, we show that the proposed method induces a regularization effect that acts on the layer weight gradients",
    "checked": true,
    "id": "8ee8cd336177c828e71d32ac0fec8a5c7c4d4911",
    "semantic_title": "compressing the activation maps in deep convolutional neural networks and its regularizing effect",
    "citation_count": 1,
    "authors": [
      "Minh Hoang Vu",
      "Anders Garpebring",
      "Tufve Nyholm",
      "Tommy LÃ¶fstedt"
    ]
  },
  "https://openreview.net/forum?id=bQKHMSE4SH": {
    "title": "Towards Understanding Dual BN In Hybrid Adversarial Training",
    "volume": "main",
    "abstract": "There is a growing concern about applying batch normalization (BN) in adversarial training (AT), especially when the model is trained on both adversarial samples and clean samples (termed Hybrid-AT). With the assumption that adversarial and clean samples are from two different domains, a common practice in prior works is to adopt Dual BN, where BN$_{adv}$ and BN$_{clean}$ are used for adversarial and clean branches, respectively. A popular belief for motivating Dual BN is that estimating normalization statistics of this mixture distribution is challenging and thus disentangling it for normalization achieves stronger robustness. In contrast to this belief, we reveal that disentangling statistics plays a less role than disentangling affine parameters in model training. This finding aligns with prior work (Rebuffi et al., 2023), and we build upon their research for further investigations. We demonstrate that the domain gap between adversarial and clean samples is not very large, which is counter-intuitive considering the significant influence of adversarial perturbation on the model accuracy. We further propose a two-task hypothesis which serves as the empirical foundation and a unified framework for Hybrid-AT improvement. We also investigate Dual BN in test-time and reveal that affine parameters characterize the robustness during inference. Overall, our work sheds new light on understanding the mechanism of Dual BN in Hybrid-AT and its underlying justification",
    "checked": true,
    "id": "0204ff243f758f325153371c1ce97dc4ce19d786",
    "semantic_title": "towards understanding dual bn in hybrid adversarial training",
    "citation_count": 1,
    "authors": [
      "Chenshuang Zhang",
      "Chaoning Zhang",
      "Kang Zhang",
      "Axi Niu",
      "Junmo Kim",
      "In So Kweon"
    ]
  },
  "https://openreview.net/forum?id=1LoVwFkZNo": {
    "title": "ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions",
    "volume": "main",
    "abstract": "Asking insightful questions is crucial for acquiring knowledge and expanding our understanding of the world. However, the importance of questioning has been largely overlooked in AI research, where models have been primarily developed to answer questions. With the recent advancements of large language models (LLMs) like ChatGPT, we discover their capability to ask high-quality questions when provided with a suitable prompt. This discovery presents a new opportunity to develop an automatic questioning system. In this paper, we introduce ChatCaptioner, a novel automatic-questioning method deployed in image captioning. Here, ChatGPT is prompted to ask a series of informative questions about images to BLIP-2, a strong vision question-answering model. In ChatCaptioner, we investigate whether two AI models, unable to individually describe images in detail, can collaborate through an automated, visually guided dialogue to generate a better and more enriched image description than a single AI model. We conduct human-subject evaluations on common image caption datasets such as COCO, Conceptual Caption, and WikiArt, and compare ChatCaptioner with BLIP-2 as well as ground truth. Our results demonstrate that ChatCaptioner's captions are significantly more informative, receiving three times as many votes from human evaluators as BLIP-2 alone for providing the most image information. Besides, ChatCaptioner identifies 53% more objects within the image than BLIP-2 alone measured by WordNet synset matching",
    "checked": true,
    "id": "69cfdc8df16ae63b7acba4ac6f727f78b86893c3",
    "semantic_title": "chatgpt asks, blip-2 answers: automatic questioning towards enriched visual descriptions",
    "citation_count": 104,
    "authors": [
      "Deyao Zhu",
      "Jun Chen",
      "Kilichbek Haydarov",
      "Xiaoqian Shen",
      "Wenxuan Zhang",
      "Mohamed Elhoseiny"
    ]
  },
  "https://openreview.net/forum?id=q4iSLPoFe7": {
    "title": "Revisiting Generalized p-Laplacian Regularized Framelet GCNs: Convergence, Energy Dynamic and as Non-Linear Diffusion",
    "volume": "main",
    "abstract": "This paper presents a comprehensive theoretical analysis of the graph p-Laplacian regularized framelet network (pL-UFG) to establish a solid understanding of its properties. We conduct a convergence analysis on pL-UFG, addressing the gap in the understanding of its asymptotic behaviors. Further by investigating the generalized Dirichlet energy of pL-UFG, we demonstrate that the Dirichlet energy remains non-zero throughout convergence, ensuring the avoidance of over-smoothing issues. Additionally, we elucidate the energy dynamic perspective, highlighting the synergistic relationship between the implicit layer in pL-UFG and graph framelets. This synergy enhances the model's adaptability to both homophilic and heterophilic data. Notably, we reveal that pL-UFG can be interpreted as a generalized non-linear diffusion process, thereby bridging the gap between pL-UFG and differential equations on the graph. Importantly, these multifaceted analyses lead to unified conclusions that offer novel insights for understanding and implementing pL-UFG, as well as other graph neural network (GNN) models. Finally, based on our dynamic analysis, we propose two novel pL-UFG models with manually controlled energy dynamics. We demonstrate empirically and theoretically that our proposed models not only inherit the advantages of pL-UFG but also significantly reduce computational costs for training on large-scale graph datasets",
    "checked": true,
    "id": "5334fab208faeac2d164086cc4254a45abaf4883",
    "semantic_title": "revisiting generalized p-laplacian regularized framelet gcns: convergence, energy dynamic and as non-linear diffusion",
    "citation_count": 4,
    "authors": [
      "Dai Shi",
      "Zhiqi Shao",
      "Yi Guo",
      "Qibin Zhao",
      "Junbin Gao"
    ]
  },
  "https://openreview.net/forum?id=H4OE7toXpa": {
    "title": "Inverse Kernel Decomposition",
    "volume": "main",
    "abstract": "The state-of-the-art dimensionality reduction approaches largely rely on complicated optimization procedures. On the other hand, closed-form approaches requiring merely eigen-decomposition do not have enough sophistication and nonlinearity. In this paper, we propose a novel nonlinear dimensionality reduction method---Inverse Kernel Decomposition (IKD)---based on an eigen-decomposition of the sample covariance matrix of data. The method is inspired by Gaussian process latent variable models (GPLVMs) and has comparable performance with GPLVMs. To deal with very noisy data with weak correlations, we propose two solutions---blockwise and geodesic---to make use of locally correlated data points and provide better and numerically more stable latent estimations. We use synthetic datasets and four real-world datasets to show that IKD is a better dimensionality reduction method than other eigen-decomposition-based methods, and achieves comparable performance against optimization-based methods with faster running speeds. Open-source IKD implementation in Python can be accessed at \\url{https://github.com/JerrySoybean/ikd}",
    "checked": true,
    "id": "34a61e9d173eb6ffa1d13d59c39732ece8e67c47",
    "semantic_title": "inverse kernel decomposition",
    "citation_count": 1,
    "authors": [
      "Chengrui Li",
      "Anqi Wu"
    ]
  },
  "https://openreview.net/forum?id=yUmJ483OB0": {
    "title": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding",
    "volume": "main",
    "abstract": "This paper presents Predictive Pipelined Decoding (PPD), an approach that speeds up decoding in Large Language Models (LLMs) while maintaining the exact same output as the original decoding. Unlike conventional strategies, PPD employs additional compute resources to parallelize the initiation of subsequent token decoding during the current token decoding. This method reduces decoding latency and reshapes the understanding of trade-offs in LLM decoding strategies. We have developed a theoretical framework that allows us to analyze the trade-off between computation and latency. Using this framework, we can analytically estimate the potential reduction in latency associated with our proposed method, achieved through the assessment of the match rate, represented as $p_\\text{correct}$. The results demonstrate that the use of extra computational resources has the potential to accelerate LLM decoding. Additionally, we implement PPD and conduct preliminary experiments to empirically validate its efficacy, addressing potential practical overheads not covered by theoretical analysis",
    "checked": true,
    "id": "d988eb48e8b4e471f5df9d081bfc32db0781e6bf",
    "semantic_title": "predictive pipelined decoding: a compute-latency trade-off for exact llm decoding",
    "citation_count": 38,
    "authors": [
      "Seongjun Yang",
      "Gibbeum Lee",
      "Jaewoong Cho",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ]
  },
  "https://openreview.net/forum?id=8GI1SXqJBk": {
    "title": "Maximizing Global Model Appeal in Federated Learning",
    "volume": "main",
    "abstract": "Federated learning (FL) aims to collaboratively train a global model using local data from a network of clients. To warrant collaborative training, each federated client may expect the resulting global model to satisfy some individual requirement, such as achieving a certain loss threshold on their local data. However, in real FL scenarios, the global model may not satisfy the requirements of all clients in the network due to the data heterogeneity across clients. In this work, we explore the problem of global model appeal in FL, which we define as the total number of clients that find that the global model satisfies their individual requirements. We discover that global models trained using traditional FL approaches can result in a significant number of clients unsatisfied with the model based on their local requirements. As a consequence, we show that global model appeal can directly impact how clients participate in training and how the model performs on new clients at inference time. Our work proposes MaxFL, which maximizes the number of clients that find the global model appealing. MaxFL achieves a $22$-$40\\%$ and $18$-$50\\%$ improvement in the test accuracy of training clients and (unseen) test clients respectively, compared to a wide range of FL approaches that tackle data heterogeneity, aim to incentivize clients, and learn personalized/fair models",
    "checked": true,
    "id": "1fc0ba6c30ed0af6858245465c851d98e80b3236",
    "semantic_title": "maximizing global model appeal in federated learning",
    "citation_count": 7,
    "authors": [
      "Yae Jee Cho",
      "Divyansh Jhunjhunwala",
      "Tian Li",
      "Virginia Smith",
      "Gauri Joshi"
    ]
  },
  "https://openreview.net/forum?id=f9l4eiPKpV": {
    "title": "Learning Sparse Graphs for Functional Regression using Graph-induced Operator-valued Kernels",
    "volume": "main",
    "abstract": "A functional regression problem aims to learn a map $\\mathfrak{F}:\\mathcal{Z}\\mapsto\\mathcal{Y}$, where $\\mathcal{Z}$ is an appropriate input space and $\\mathcal{Y}$ is a space of output functions. When $\\mathcal{Z}$ is also a space of functions, the learning problem is known as function-to-function regression. In this work, we consider the problem of learning a map of the form ${F}:{\\mathcal{Z}}^p\\mapsto\\mathcal{Y}$, a many-to-one function-to-function regression problem, where the aim is to learn a suitable $F$ which maps $p$ input functions to an output function. In order to solve this regression problem with $p$ input functions and a corresponding output function, we propose a graph-induced operator-valued kernel (OVK) obtained by imposing a graphical structure describing the inter-relationships among the $p$ input functions. When the underlying graphical structure is unknown, we propose to learn an appropriate Laplacian matrix characterizing the graphical structure, which would also aid in learning the map $F$. We formulate a learning problem using the proposed graph-induced OVK, and devise an alternating minimization framework to solve the learning problem. To learn $F$ along with meaningful and important interactions in the graphical structure, a minimax concave penalty (MCP) is used as a sparsity-inducing regularization on the Laplacian matrix. We further extend the alternating minimization framework to learn $F$, where each of the $p$ constituent input functions as well as the output function are multi-dimensional. To scale the proposed algorithm to large datasets, we design an efficient sample-based approximation algorithm. Further, we provide bounds on generalization error for the map obtained by solving the proposed learning problem. An extensive empirical evaluation on both synthetic and real data demonstrates the utility of the proposed learning framework. Our experiments show that simultaneous learning of $F$ along with sparse graphical structure helps in discovering significant relationships among the input functions, and motivates interpretability of such relationships driving the regression problem",
    "checked": true,
    "id": "4f06e7e46a529ffe5b9636f32ccd64a338cabd23",
    "semantic_title": "learning sparse graphs for functional regression using graph-induced operator-valued kernels",
    "citation_count": 0,
    "authors": [
      "Akash Saha",
      "Balamurugan Palaniappan"
    ]
  },
  "https://openreview.net/forum?id=JYbnJ92TJf": {
    "title": "Addressing Attribute Bias with Adversarial Support-Matching",
    "volume": "main",
    "abstract": "When trained on diverse labelled data, machine learning models have proven themselves to be a powerful tool in all facets of society. However, due to budget limitations, deliberate or non-deliberate censorship, and other problems during data collection, certain groups may be under-represented in the labelled training set. We investigate a scenario in which the absence of certain data is linked to the second level of a two-level hierarchy in the data. Inspired by the idea of protected attributes from algorithmic fairness, we consider generalised secondary \"attributes\" which subdivide the classes into smaller partitions. We refer to the partitions defined by the combination of an attribute and a class label, or leaf nodes in aforementioned hierarchy, as groups. To characterise the problem, we introduce the concept of classes with incomplete attribute support. The representational bias in the training set can give rise to spurious correlations between the classes and the attributes which cause standard classification models to generalise poorly to unseen groups. To overcome this bias, we make use of an additional, diverse but unlabelled dataset, called the deployment set, to learn a representation that is invariant to the attributes. This is done by adversarially matching the support of the training and deployment sets in representation space using a set discriminator operating on sets, or bags, of samples. In order to learn the desired invariance, it is paramount that the bags are balanced by class; this is easily achieved for the training set, but requires using semi-supervised clustering for the deployment set. We demonstrate the effectiveness of our method on several datasets and realisations of the problem",
    "checked": true,
    "id": "ed71c8ed6b386950c004157f83ee933bf2a3c0eb",
    "semantic_title": "addressing attribute bias with adversarial support-matching",
    "citation_count": 0,
    "authors": [
      "Thomas Kehrenberg",
      "Myles Bartlett",
      "Viktoriia Sharmanska",
      "Novi Quadrianto"
    ]
  },
  "https://openreview.net/forum?id=ZSWKdRi2cU": {
    "title": "Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access",
    "volume": "main",
    "abstract": "Fair machine learning methods seek to train models that balance model performance across demographic subgroups defined over sensitive attributes like race and gender. Although sensitive attributes are typically assumed to be known during training, they may not be available in practice due to privacy and other logistical concerns. Recent work has sough to train fair models without sensitive attributes on training data. However, these methods need extensive hyper-parameter tuning to achieve good results, and hence assume that sensitive attributes are known on validation data. However, this assumption too might not be practical. Here, we propose Antigone, a framework to train fair classifiers without access to sensitive attributes on either training or validation data. Instead, we generate pseudo sensitive attributes on the validation data by training a ERM model and using the classifier's incorrectly (correctly) classified examples as proxies for disadvantaged (advantaged) groups. Since fairness metrics like demographic parity, equal opportunity and subgroup accuracy can be estimated to within a proportionality constant even with noisy sensitive attribute information, we show theoretically and empirically that these proxy labels can be used to maximize fairness under average accuracy constraints. Key to our results is a principled approach to select the hyper-parameters of the ERM model in a completely unsupervised fashion (meaning without access to ground truth sensitive attributes) that minimizes the gap between fairness estimated using noisy versus ground-truth sensitive labels. We demonstrate that Antigone outperforms existing methods on CelebA, Waterbirds, and UCI datasets",
    "checked": true,
    "id": "1050c8c016b341bdf50feef2811dde4c0690d4b7",
    "semantic_title": "hyper-parameter tuning for fair classification without sensitive attribute access",
    "citation_count": 6,
    "authors": [
      "Akshaj Kumar Veldanda",
      "Ivan Brugere",
      "Sanghamitra Dutta",
      "Alan Mishler",
      "Siddharth Garg"
    ]
  },
  "https://openreview.net/forum?id=7PNJzAxkij": {
    "title": "E(n)-equivariant Graph Neural Cellular Automata",
    "volume": "main",
    "abstract": "Cellular automata (CAs) are notable computational models exhibiting rich dynamics emerging from the local interaction of cells arranged in a regular lattice. Graph CAs (GCAs) generalise standard CAs by allowing for arbitrary graphs rather than regular lattices, similar to how Graph Neural Networks (GNNs) generalise Convolutional NNs. Recently, Graph Neural CAs (GNCAs) have been proposed as models built on top of standard GNNs that can be trained to approximate the transition rule of any arbitrary GCA. We note that existing GNCAs can violate the locality principle of CAs by leveraging global information and, furthermore, are anisotropic in the sense that their transition rules are not equivariant to isometries of the nodes' spatial locations. However, it is desirable for instances related by such transformations to be treated identically by the model. By replacing standard graph convolutions with E(n)-equivariant ones, we avoid anisotropy by design and propose a class of isotropic automata that we call E(n)-GNCAs. These models are lightweight, but can nevertheless handle large graphs, capture complex dynamics and exhibit emergent self-organising behaviours. We showcase the broad and successful applicability of E(n)-GNCAs on three different tasks: (i) isotropic pattern formation, (ii) graph auto-encoding, and (iii) simulation of E(n)-equivariant dynamical systems",
    "checked": true,
    "id": "a17a7abe9c4341748b4fb8da03e98370af184dd2",
    "semantic_title": "e(n)-equivariant graph neural cellular automata",
    "citation_count": 3,
    "authors": [
      "Gennaro Gala",
      "Daniele Grattarola",
      "Erik Quaeghebeur"
    ]
  },
  "https://openreview.net/forum?id=WOrdoKbxh6": {
    "title": "Layer-diverse Negative Sampling for Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) are a powerful solution for various structure learning applications due to their strong representation capabilities for graph data. However, traditional GNNs, relying on message-passing mechanisms that gather information exclusively from first-order neighbours (known as positive samples), can lead to issues such as over-smoothing and over-squashing. To mitigate these issues, we propose a layer-diverse negative sampling method for message-passing propagation. This method employs a sampling matrix within a determinantal point process, which transforms the candidate set into a space and selectively samples from this space to generate negative samples. To further enhance the diversity of the negative samples during each forward pass, we develop a space-squeezing method to achieve layer-wise diversity in multi-layer GNNs. Experiments on various real-world graph datasets demonstrate the effectiveness of our approach in improving the diversity of negative samples and overall learning performance. Moreover, adding negative samples dynamically changes the graph's topology, thus with the strong potential to improve the expressiveness of GNNs and reduce the risk of over-squashing",
    "checked": true,
    "id": "fd8806e41d8c6885f0bf4a47fc70c5f9dbeb3545",
    "semantic_title": "layer-diverse negative sampling for graph neural networks",
    "citation_count": 5,
    "authors": [
      "Wei Duan",
      "Jie Lu",
      "Yu Guang Wang",
      "Junyu Xuan"
    ]
  },
  "https://openreview.net/forum?id=N2wx9UVHkH": {
    "title": "Personalized Federated Learning with Spurious Features: An Adversarial Approach",
    "volume": "main",
    "abstract": "One of the common approaches for personalizing federated learning is fine-tuning the global model for each local client. While this addresses some issues of statistical heterogeneity, we find that such personalization methods are vulnerable to spurious features at local agents, leading to reduced generalization performance. This work considers a setup where spurious features correlate with the label in each client's training environment, and the mixture of multiple training environments (i.e., the global environment) diminishes the spurious correlations. In other words, while the global federated learning model trained over the global environment suffers less from spurious features, the local fine-tuning step may lead to personalized models vulnerable to spurious correlations. In light of this practical and pressing challenge, we propose a novel strategy to mitigate the effect of spurious features during personalization by maintaining the adversarial transferability between the global and personalized models. Empirical results on object and action recognition tasks show that our proposed approach bounds personalized models from further exploiting spurious features while preserving the benefit of enhanced accuracy from fine-tuning",
    "checked": true,
    "id": "d1aedc04df8c16fdc06f4aea0aafecc29b3cdfda",
    "semantic_title": "personalized federated learning with spurious features: an adversarial approach",
    "citation_count": 1,
    "authors": [
      "Xiaoyang Wang",
      "Han Zhao",
      "Klara Nahrstedt",
      "Sanmi Koyejo"
    ]
  },
  "https://openreview.net/forum?id=QySD5r7PeE": {
    "title": "A Pseudo-Metric between Probability Distributions based on Depth-Trimmed Regions",
    "volume": "main",
    "abstract": "The design of a metric between probability distributions is a longstanding problem motivated by numerous applications in machine learning. Focusing on continuous probability distributions in the Euclidean space $\\mathbb{R}^d$, we introduce a novel pseudo-metric between probability distributions by leveraging the extension of univariate quantiles to multivariate spaces. Data depth is a nonparametric statistical tool that measures the centrality of any element $x\\in\\mathbb{R}^d$ with respect to (w.r.t.) a probability distribution or a dataset. It is a natural median-oriented extension of the cumulative distribution function (cdf) to the multivariate case. Thus, its upper-level sets---the depth-trimmed regions---give rise to a definition of multivariate quantiles. The new pseudo-metric relies on the average of the Hausdorff distance between the depth-based quantile regions for each distribution. Its good behavior regarding major transformation groups, as well as its ability to factor out translations, are depicted. Robustness, an appealing feature of this pseudo-metric, is studied through the finite sample breakdown point. Moreover, we propose an efficient approximation method with linear time complexity w.r.t. the size of the dataset and its dimension. The quality of this approximation and the performance of the proposed approach are illustrated in numerical experiments",
    "checked": false,
    "id": "7dead3a28fe38717d315870280ac8911f8b64b98",
    "semantic_title": "probabilistic evaluation of susceptibility to fluid injection-induced seismicity based on statistics of fracture criticality",
    "citation_count": 8,
    "authors": [
      "Guillaume Staerman",
      "Pavlo Mozharovskyi",
      "Pierre Colombo",
      "Stephan ClÃ©menÃ§on",
      "Florence d'AlchÃ©-Buc"
    ]
  },
  "https://openreview.net/forum?id=9CcgO0LhKG": {
    "title": "World Models via Policy-Guided Trajectory Diffusion",
    "volume": "main",
    "abstract": "World models are a powerful tool for developing intelligent agents. By predicting the outcome of a sequence of actions, world models enable policies to be optimised via on-policy reinforcement learning (RL) using synthetic data, i.e. in \"in imagination\". Existing world models are autoregressive in that they interleave predicting the next state with sampling the next action from the policy. Prediction error inevitably compounds as the trajectory length grows. In this work, we propose a novel world modelling approach that is not autoregressive and generates entire on-policy trajectories in a single pass through a diffusion model. Our approach, Policy-Guided Trajectory Diffusion (PolyGRAD), leverages a denoising model in addition to the gradient of the action distribution of the policy to diffuse a trajectory of initially random states and actions into an on-policy synthetic trajectory. We analyse the connections between PolyGRAD, score-based generative models, and classifier-guided diffusion models. Our results demonstrate that PolyGRAD outperforms state-of-the-art baselines in terms of trajectory prediction error for short trajectories, with the exception of autoregressive diffusion. For short trajectories, PolyGRAD obtains similar errors to autoregressive diffusion, but with lower computational requirements. For long trajectories, PolyGRAD obtains comparable performance to baselines. Our experiments demonstrate that PolyGRAD enables performant policies to be trained via on-policy RL in imagination for MuJoCo continuous control domains. Thus, PolyGRAD introduces a new paradigm for accurate on-policy world modelling without autoregressive sampling",
    "checked": true,
    "id": "bebcb0832cdafb102c75c96ca18207d05034ab0c",
    "semantic_title": "world models via policy-guided trajectory diffusion",
    "citation_count": 21,
    "authors": [
      "Marc Rigter",
      "Jun Yamada",
      "Ingmar Posner"
    ]
  },
  "https://openreview.net/forum?id=YCgX7sJRF1": {
    "title": "Adapting Contrastive Language-Image Pretrained (CLIP) Models for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "We present a comprehensive experimental study on pre-trained feature extractors for visual out-of-distribution (OOD) detection, focusing on leveraging contrastive language-image pre-trained (CLIP) models. Without fine-tuning on the training data, we are able to establish a positive correlation ($R^2\\geq0.92$) between in-distribution classification and unsupervised OOD detection for CLIP models in $4$ benchmarks. We further propose a new simple and scalable method called \\textit{pseudo-label probing} (PLP) that adapts vision-language models for OOD detection. Given a set of label names of the training set, PLP trains a linear layer using the pseudo-labels derived from the text encoder of CLIP. Intriguingly, we show that without modifying the weights of CLIP or training additional image/text encoders (i) PLP outperforms the previous state-of-the-art on all $5$ large-scale benchmarks based on ImageNet, specifically by an average AUROC gain of 3.4\\% using the largest CLIP model (ViT-G), (ii) linear probing outperforms fine-tuning by large margins for CLIP architectures (i.e. CLIP ViT-H achieves a mean gain of 7.3\\% AUROC on average on all ImageNet-based benchmarks), and (iii) billion-parameter CLIP models still fail at detecting feature-based adversarially manipulated OOD images. The code is available at https://github.com/HHU-MMBS/plp-official-tmlr2024",
    "checked": true,
    "id": "eb1dbaf8e7a92a95050fd8f6e025ff4fbebadb5e",
    "semantic_title": "adapting contrastive language-image pretrained (clip) models for out-of-distribution detection",
    "citation_count": 0,
    "authors": [
      "Nikolas Adaloglou",
      "Felix Michels",
      "Tim Kaiser",
      "Markus Kollmann"
    ]
  },
  "https://openreview.net/forum?id=5VotySkajV": {
    "title": "Multi-conditioned Graph Diffusion for Neural Architecture Search",
    "volume": "main",
    "abstract": "Neural architecture search automates the design of neural network architectures usually by exploring a large and thus complex architecture search space. To advance the architecture search, we present a graph diffusion-based NAS approach that uses discrete conditional graph diffusion processes to generate high-performing neural network architectures. We then propose a multi-conditioned classifier-free guidance approach applied to graph diffusion networks to jointly impose constraints such as high accuracy and low hardware latency. Unlike the related work, our method is completely differentiable and requires only a single model training. In our evaluations, we show promising results on six standard benchmarks, yielding novel and unique architectures at a fast speed, i.e. less than 0.2 seconds per architecture. Furthermore, we demonstrate the generalisability and efficiency of our method through experiments on ImageNet dataset",
    "checked": true,
    "id": "989552c9131953d7b5f2d8cb6f06e75ea05a415f",
    "semantic_title": "multi-conditioned graph diffusion for neural architecture search",
    "citation_count": 6,
    "authors": [
      "Rohan Asthana",
      "Joschua Conrad",
      "Youssef Dawoud",
      "Maurits Ortmanns",
      "Vasileios Belagiannis"
    ]
  },
  "https://openreview.net/forum?id=aD0ExytnEK": {
    "title": "Controlling the Inductive Bias of Wide Neural Networks by Modifying the Kernel's Spectrum",
    "volume": "main",
    "abstract": "Wide neural networks are biased towards learning certain functions, influencing both the rate of convergence of gradient descent (GD) and the functions that are reachable with GD in finite training time. As such, there is a great need for methods that can modify this bias according to the task at hand. To that end, we introduce Modified Spectrum Kernels (MSKs), a novel family of constructed kernels that can be used to approximate kernels with desired eigenvalues for which no closed form is known. We leverage the duality between wide neural networks and Neural Tangent Kernels and propose a preconditioned gradient descent method, which alters the trajectory of GD. As a result, this allows for a polynomial and, in some cases, exponential training speedup without changing the final solution. Our method is both computationally efficient and simple to implement",
    "checked": true,
    "id": "3c5dafeab83eaeee3c31db8525ce3f37a82bf3ca",
    "semantic_title": "controlling the inductive bias of wide neural networks by modifying the kernel's spectrum",
    "citation_count": 6,
    "authors": [
      "Amnon Geifman",
      "Daniel Barzilai",
      "Ronen Basri",
      "Meirav Galun"
    ]
  },
  "https://openreview.net/forum?id=HhbqHBBrfZ": {
    "title": "Attending to Graph Transformers",
    "volume": "main",
    "abstract": "Recently, transformer architectures for graphs emerged as an alternative to established techniques for machine learning with graphs, such as (message-passing) graph neural networks. So far, they have shown promising empirical results, e.g., on molecular prediction datasets, often attributed to their ability to circumvent graph neural networks' shortcomings, such as over-smoothing and over-squashing. Here, we derive a taxonomy of graph transformer architectures, bringing some order to this emerging field. We overview their theoretical properties, survey structural and positional encodings, and discuss extensions for important graph classes, e.g., 3D molecular graphs. Empirically, we probe how well graph transformers can recover various graph properties, how well they can deal with heterophilic graphs, and to what extent they prevent over-squashing. Further, we outline open challenges and research direction to stimulate future work",
    "checked": true,
    "id": "30258c205060af5ce958dc6c9e184c9498ee48ed",
    "semantic_title": "attending to graph transformers",
    "citation_count": 93,
    "authors": [
      "Luis MÃ¼ller",
      "Mikhail Galkin",
      "Christopher Morris",
      "Ladislav RampÃ¡Å¡ek"
    ]
  },
  "https://openreview.net/forum?id=2iOOvQmJBK": {
    "title": "Discovering Model Structure of Dynamical Systems with Combinatorial Bayesian Optimization",
    "volume": "main",
    "abstract": "Deciding on a model structure is a fundamental problem in machine learning. In this paper we consider the problem of building a data-based model for dynamical systems from a library of discrete components. In addition to optimizing performance, we consider crash and inequality constraints that arise from additional requirements, such as real-time capability and model complexity. We address this task of model structure selection with a focus on dynamical systems and propose to search over potential model structures efficiently using a constrained combinatorial Bayesian Optimization (BO) algorithm. We propose expressive surrogate models suited for combinatorial domains and an acquisition function that can handle inequality and crash constraints. We provide simulated benchmark problems within the domain of equation discovery of nonlinear dynamical systems. Our method outperforms the state-of-the-art in constrained combinatorial optimization of black-box functions and has a favorable computational overhead compared to other BO methods. As a real-world application example, we apply our method to optimize the configuration of an electric vehicle's digital twin while ensuring its real-time capability for the use in one of the world's largest driving simulators",
    "checked": true,
    "id": "00bb3148c2df49953a9f3682627e5bf45c404551",
    "semantic_title": "discovering model structure of dynamical systems with combinatorial bayesian optimization",
    "citation_count": 0,
    "authors": [
      "Lucas Rath",
      "Alexander von Rohr",
      "Andreas Schultze",
      "Sebastian Trimpe",
      "Burkhard Corves"
    ]
  },
  "https://openreview.net/forum?id=1ZGA5mSkoB": {
    "title": "An Improved Federated Clustering Algorithm with Model-based Clustering",
    "volume": "main",
    "abstract": "Federated learning (FL) is a distributed learning paradigm that allows multiple clients to collaboratively train a shared model via communications to a central server. However, optimal models of different clients often differ due to heterogeneity of data across clients. In this paper, we address the dichotomy between heterogeneous models and simultaneous training in FL via a clustering structure among the clients. The clustering framework is one way to allow for high heterogeneity level between clients, while clients with similar data can still train a shared model. We define a new clustering framework for FL based on the (optimal) local models of the clients: two clients belong to the same cluster if their local models are close. We propose an algorithm, \\emph{Successive Refine Federated Clustering Algorithm} (\\texttt{SR-FCA}), that treats each client as a singleton cluster as an initialization, and then successively refine the cluster estimation via exploiting similarity with other clients. In any intermediate step, \\texttt{SR-FCA} uses an {\\em error-tolerant} federated learning algorithm within each cluster to exploit simultaneous training and to correct clustering errors. Unlike some prominent prior works \\texttt{SR-FCA} does not require any \\emph{good} initialization (or warm start), both in theory and practice. We show that with proper choice of learning rate, \\texttt{SR-FCA} incurs arbitrarily small clustering error. Additionally, \\texttt{SR-FCA} does not require the knowledge of the number of clusters apriori like some prior works. We validate the performance of \\texttt{SR-FCA} on real-world FL datasets including FEMNIST and Shakespeare in non-convex problems and show the benefits of \\texttt{SR-FCA} over several baselines",
    "checked": true,
    "id": "e8cb64048075a27e6782f180a213be48744736f2",
    "semantic_title": "an improved federated clustering algorithm with model-based clustering",
    "citation_count": 1,
    "authors": [
      "Harsh Vardhan",
      "Avishek Ghosh",
      "Arya Mazumdar"
    ]
  },
  "https://openreview.net/forum?id=qBZeQBEDIW": {
    "title": "Series of Hessian-Vector Products for Tractable Saddle-Free Newton Optimisation of Neural Networks",
    "volume": "main",
    "abstract": "Despite their popularity in the field of continuous optimisation, second-order quasi-Newton methods are challenging to apply in machine learning, as the Hessian matrix is intractably large. This computational burden is exacerbated by the need to address non-convexity, for instance by modifying the Hessian's eigenvalues as in Saddle-Free Newton methods. We propose an optimisation algorithm which addresses both of these concerns â to our knowledge, the first efficiently-scalable optimisation algorithm to asymptotically use the exact inverse Hessian with absolute-value eigenvalues. Our method frames the problem as a series which principally square-roots and inverts the squared Hessian, then uses it to precondition a gradient vector, all without explicitly computing or eigendecomposing the Hessian. A truncation of this infinite series provides a new optimisation algorithm which is scalable and comparable to other first- and second-order optimisation methods in both runtime and optimisation performance. We demonstrate this in a variety of settings, including a ResNet-18 trained on CIFAR-10",
    "checked": true,
    "id": "606f7aeb3e02a120d829cb22760de9ac34e44e39",
    "semantic_title": "series of hessian-vector products for tractable saddle-free newton optimisation of neural networks",
    "citation_count": 1,
    "authors": [
      "Elre Talea Oldewage",
      "Ross M Clarke",
      "JosÃ© Miguel HernÃ¡ndez-Lobato"
    ]
  },
  "https://openreview.net/forum?id=8W6IDyFZgC": {
    "title": "Demographically-Informed Prediction Discrepancy Index: Early Warnings of Demographic Biases for Unlabeled Populations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b210ab52cd35a1a80a1d5e3480a3436d73dcea63",
    "semantic_title": "demographically-informed prediction discrepancy index: early warnings of demographic biases for unlabeled populations",
    "citation_count": 1,
    "authors": [
      "Lucas Mansilla",
      "Estanislao Claucich",
      "Rodrigo Echeveste",
      "Diego H Milone",
      "Enzo Ferrante"
    ]
  },
  "https://openreview.net/forum?id=vTBjBtGioE": {
    "title": "Fast Training of Diffusion Models with Masked Transformers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8c42e56ebc1328c55d4e7641adcdb3d85fed22c3",
    "semantic_title": "fast training of diffusion models with masked transformers",
    "citation_count": 73,
    "authors": [
      "Hongkai Zheng",
      "Weili Nie",
      "Arash Vahdat",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=ZOqJCP4eMk": {
    "title": "Functional Linear Regression of Cumulative Distribution Functions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b813d1535a222072517aa3173b77bb572252be9",
    "semantic_title": "functional linear regression of cumulative distribution functions",
    "citation_count": 3,
    "authors": [
      "Qian Zhang",
      "Anuran Makur",
      "Kamyar Azizzadenesheli"
    ]
  },
  "https://openreview.net/forum?id=4TnFbv16hK": {
    "title": "Bias/Variance is not the same as Approximation/Estimation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1657ac7717b92926efb3eb1a5cf544c51e55a002",
    "semantic_title": "bias/variance is not the same as approximation/estimation",
    "citation_count": 5,
    "authors": [
      "Gavin Brown",
      "Riccardo Ali"
    ]
  },
  "https://openreview.net/forum?id=HhjSalvWVe": {
    "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel",
    "volume": "main",
    "abstract": "It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of NNs and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping function based on either Nystrom approximation or random Fourier features, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demonstrate that ICK has superior performance and flexibility on both synthetic and real-world datasets including a remote sensing dataset. The ICK framework can be used to include prior information into neural networks in many applications",
    "checked": true,
    "id": "35fc6239a0658eeca805572ffea1296a8379f2ef",
    "semantic_title": "incorporating prior knowledge into neural networks through an implicit composite kernel",
    "citation_count": 4,
    "authors": [
      "Ziyang Jiang",
      "Tongshu Zheng",
      "Yiling Liu",
      "David Carlson"
    ]
  },
  "https://openreview.net/forum?id=Ai9XpjGxjl": {
    "title": "Using Sum-Product Networks to Assess Uncertainty in Deep Active Learning",
    "volume": "main",
    "abstract": "The success of deep active learning hinges on the choice of an effective acquisition function, which ranks not yet labeled data points according to their expected informativeness. Many acquisition functions are (partly) based on the uncertainty that the current model has about the class label of a point, yet there is no generally agreed upon strategy for computing such uncertainty. This paper proposes a new and very simple approach to computing uncertainty in deep active learning with a Convolutional Neural Network (CNN). The main idea is to use the feature representation extracted by the CNN as data for training a Sum-Product Network (SPN). Since SPNs are typically used for estimating the distribution of a dataset, they are well suited to the task of estimating class probabilities that can be used directly by standard acquisition functions such as max entropy and variational ratio. The effectiveness of our method is demonstrated in an experimental study on several standard benchmark datasets for image classification, where we compare it to various state-of-the-art methods for assessing uncertainty in deep active learning",
    "checked": true,
    "id": "46282bb5a0e4066e243e35b72a992ca704af96b7",
    "semantic_title": "using sum-product networks to assess uncertainty in deep active learning",
    "citation_count": 0,
    "authors": [
      "Mohamadsadegh Khosravani",
      "Sandra Zilles"
    ]
  },
  "https://openreview.net/forum?id=UVE7LllpXe": {
    "title": "How Much Pre-training Is Enough to Discover a Good Subnetwork?",
    "volume": "main",
    "abstract": "Neural network pruning helps discover efficient, high-performing subnetworks within pre-trained, dense network architectures. More often than not, it involves a three-step processâpre-training, pruning, and re-trainingâthat is computationally expensive, as the dense model must be fully pre-trained. While previous work has revealed through experiments the relationship between the amount of pre-training and the performance of the pruned network, a theoretical characterization of such dependency is still missing. Aiming to mathematically analyze the amount of dense network pre-training needed for a pruned network to perform well, we discover a simple theoretical bound in the number of gradient descent pre-training iterations on a two-layer fully connected network in the NTK regime, beyond which pruning via greedy forward selection \\citep{provable_subnetworks} yields a subnetwork that achieves good training error. Interestingly, this threshold is logarithmically dependent upon the size of the dataset, meaning that experiments with larger datasets require more pre-training for subnetworks obtained via pruning to perform well. Lastly, we empirically validate our theoretical results on multi-layer perceptions and residual-based convolutional networks trained on MNIST, CIFAR, and ImageNet datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cameron R. Wolfe",
      "Fangshuo Liao",
      "Qihan Wang",
      "Junhyung Lyle Kim",
      "Anastasios Kyrillidis"
    ]
  },
  "https://openreview.net/forum?id=7yswRA8zzw": {
    "title": "Pull-back Geometry of Persistent Homology Encodings",
    "volume": "main",
    "abstract": "Persistent homology (PH) is a method for generating topology-inspired representations of data. Empirical studies that investigate the properties of PH, such as its sensitivity to perturbations or ability to detect a feature of interest, commonly rely on training and testing an additional model on the basis of the PH representation. To gain more intrinsic insights about PH, independently of the choice of such a model, we propose a novel methodology based on the pull-back geometry that a PH encoding induces on the data manifold. The spectrum and eigenvectors of the induced metric help to identify the most and least significant information captured by PH. Furthermore, the pull-back norm of tangent vectors provides insights about the sensitivity of PH to a given perturbation, or its potential to detect a given feature of interest, and in turn its ability to solve a given classification or regression problem. Experimentally, the insights gained through our methodology align well with the existing knowledge about PH. Moreover, we show that the pull-back norm correlates with the performance on downstream tasks, and can therefore guide the choice of a suitable PH encoding",
    "checked": true,
    "id": "4c7ee2d082ac78d4a8df1501e63c3acacc701f77",
    "semantic_title": "pull-back geometry of persistent homology encodings",
    "citation_count": 0,
    "authors": [
      "Shuang Liang",
      "Renata Turkes",
      "Jiayi Li",
      "Nina Otter",
      "Guido Montufar"
    ]
  },
  "https://openreview.net/forum?id=bG3ICt3E0C": {
    "title": "MC Layer Normalization for calibrated uncertainty in Deep Learning",
    "volume": "main",
    "abstract": "Efficiently estimating the uncertainty of neural network predictions has become an increasingly important challenge as machine learning models are adopted for high-stakes industrial applications where shifts in data distribution may occur. Thus, calibrated prediction uncertainty is crucial to determine when to trust a model's output and when to discard them as implausible. We propose a novel deep learning module - MC Layer Normalization - that acts as a drop-in replacement for Layer Normalization blocks and endows a neural network with uncertainty estimation capabilities. Our method is motivated from an approximate Bayesian perspective, but it is simple to deploy with no significant computational overhead thanks to an efficient one-shot approximation of Monte Carlo integration at prediction time. To evaluate the effectiveness of our module, we conduct experiments in two distinct settings. First, we investigate its potential to replace existing methods such as MC-Dropout and Prediction-Time Batch Normalization. Second, we explore its suitability for use cases where such conventional modules are either unsuitable or sub-optimal for certain tasks (as is the case with modules based on Batch Normalization, which is incompatible for instance with transformers). We empirically demonstrate the competitiveness of our module in terms of prediction accuracy and uncertainty calibration on established out-of-distribution image classification benchmarks, as well as its flexibility by applying it on tasks and architectures where previous methods are unsuitable",
    "checked": true,
    "id": "70f64d7538ed49b64a577d71bda7bc2ef8360304",
    "semantic_title": "mc layer normalization for calibrated uncertainty in deep learning",
    "citation_count": 1,
    "authors": [
      "Thomas Frick",
      "Diego Antognini",
      "Ioana Giurgiu",
      "Benjamin F Grewe",
      "Cristiano Malossi",
      "Rong J.B. Zhu",
      "Mattia Rigotti"
    ]
  },
  "https://openreview.net/forum?id=Uv3XVAEgG6": {
    "title": "Kernel Normalized Convolutional Networks",
    "volume": "main",
    "abstract": "Existing convolutional neural network architectures frequently rely upon batch normalization (BatchNorm) to effectively train the model. BatchNorm, however, performs poorly with small batch sizes, and is inapplicable to differential privacy. To address these limitations, we propose the kernel normalization (KernelNorm) and kernel normalized convolutional layers, and incorporate them into kernel normalized convolutional networks (KNConvNets) as the main building blocks. We implement KNConvNets corresponding to the state-of-the-art ResNets while forgoing the BatchNorm layers. Through extensive experiments, we illustrate that KNConvNets achieve higher or competitive performance compared to the BatchNorm counterparts in image classification and semantic segmentation. They also significantly outperform their batch-independent competitors including those based on layer and group normalization in non-private and differentially private training. Given that, KernelNorm combines the batch-independence property of layer and group normalization with the performance advantage of BatchNorm",
    "checked": true,
    "id": "fff40fa88682803540aeb057e0f6ce1646273f86",
    "semantic_title": "kernel normalized convolutional networks",
    "citation_count": 2,
    "authors": [
      "Reza Nasirigerdeh",
      "Reihaneh Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ]
  },
  "https://openreview.net/forum?id=kNCZ95mw7N": {
    "title": "A VAE-based Framework for Learning Multi-Level Neural Granger-Causal Connectivity",
    "volume": "main",
    "abstract": "Granger causality has been widely used in various application domains to capture lead-lag relationships amongst the components of complex dynamical systems, and the focus in extant literature has been on a single dynamical system. In certain applications in macroeconomics and neuroscience, one has access to data from a collection of related such systems, wherein the modeling task of interest is to extract the shared common structure that is embedded across them, as well as to identify the idiosyncrasies within individual ones. This paper introduces a Variational Autoencoder (VAE) based framework that jointly learns Granger-causal relationships amongst components in a collection of related-yet-heterogeneous dynamical systems, and handles the aforementioned task in a principled way. The performance of the proposed framework is evaluated on several synthetic data settings and benchmarked against existing approaches designed for individual system learning. The method is further illustrated on a real dataset involving time series data from a neurophysiological experiment and produces interpretable results",
    "checked": true,
    "id": "798b2f3ea41127ba5698a3f08af96f8450a7773b",
    "semantic_title": "a vae-based framework for learning multi-level neural granger-causal connectivity",
    "citation_count": 0,
    "authors": [
      "Jiahe Lin",
      "Huitian Lei",
      "George Michailidis"
    ]
  },
  "https://openreview.net/forum?id=KutEe24Yai": {
    "title": "Exploit CAM by itself: Complementary Learning System for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has long been suffering from fragmentary object regions led by Class Activation Map (CAM), which is incapable of generating fine-grained masks for semantic segmentation. To guide CAM to find more non-discriminating object patterns, this paper turns to an interesting working mechanism in agent learning named Complementary Learning System (CLS). CLS holds that the neocortex builds a sensation of general knowledge, while the hippocampus specially learns specific details, completing the learned patterns. Motivated by this simple but effective learning pattern, we propose a General-Specific Learning Mechanism (GSLM) to explicitly drive a coarse-grained CAM to a fine-grained pseudo mask. Specifically, GSLM develops a General Learning Module (GLM) and a Specific Learning Module (SLM). The GLM is trained with image-level supervision to extract coarse and general localization representations from CAM. Based on the general knowledge in the GLM, the SLM progressively exploits the specific spatial knowledge from the localization representations, expanding the CAM in an explicit way. To this end, we propose the Seed Reactivation to help SLM reactivate non-discriminating regions by setting a boundary for activation values, which successively identifies more regions of CAM. Without extra refinement processes, our method is able to achieve improvements for CAM of over 20.0% mIoU on PASCAL VOC 2012 and 10.0% mIoU on MS COCO 2014 datasets, representing a new state-of-the-art among existing WSSS methods. The code is publicly available at: https://github.com/tmlr-group/GSLM",
    "checked": true,
    "id": "9ce6fc2d6392853ffbc41f2c2d6da2405bf13d3f",
    "semantic_title": "exploit cam by itself: complementary learning system for weakly supervised semantic segmentation",
    "citation_count": 1,
    "authors": [
      "Wankou Yang",
      "Jiren Mai",
      "Fei Zhang",
      "Tongliang Liu",
      "Bo Han"
    ]
  },
  "https://openreview.net/forum?id=xo3hI5MwvU": {
    "title": "Learning from Natural Language Feedback",
    "volume": "main",
    "abstract": "The potential for pre-trained large language models (LLMs) to use natural language feedback at inference time has been an exciting recent development. We build upon this observation by formalizing an algorithm for learning from natural language feedback at training time instead, which we call Imitation learning from Language Feedback (ILF). ILF requires only a small amount of human-written feedback during training and does not require the same feedback at test time, making it both user-friendly and sample-efficient. We further show that ILF can be seen as a form of minimizing the KL divergence to the target distribution and demonstrate proof-of-concepts on text summarization and program synthesis tasks. For code generation, ILF improves a Codegen-Mono 6.1B model's pass@1 rate by 38% relative (and 10% absolute) on the Mostly Basic Python Problems (MBPP) benchmark, outperforming both fine-tuning on MBPP and fine-tuning on repaired programs written by humans. For summarization, we show that ILF can be combined with learning from human preferences to improve a GPT-3 model's summarization performance to be comparable to human quality, outperforming fine-tuning on human-written summaries. Overall, our results suggest that learning from human-written natural language feedback is both more effective and sample-efficient than training exclusively on demonstrations for improving an LLM's performance on a variety of tasks",
    "checked": true,
    "id": "c43a6f12b062a50617244611af180a8146e792de",
    "semantic_title": "learning from natural language feedback",
    "citation_count": 14,
    "authors": [
      "Angelica Chen",
      "JÃ©rÃ©my Scheurer",
      "Jon Ander Campos",
      "Tomasz Korbak",
      "Jun Shern Chan",
      "Samuel R. Bowman",
      "Kyunghyun Cho",
      "Ethan Perez"
    ]
  },
  "https://openreview.net/forum?id=lVE1VeGQwg": {
    "title": "Manifold Contrastive Learning with Variational Lie Group Operators",
    "volume": "main",
    "abstract": "Self-supervised learning of deep neural networks has become a prevalent paradigm for learning representations that transfer to a variety of downstream tasks. Similar to proposed models of the ventral stream of biological vision, it is observed that these networks lead to a separation of category manifolds in the representations of the penultimate layer. Although this observation matches the manifold hypothesis of representation learning, current self-supervised approaches are limited in their ability to explicitly model this manifold. Indeed, current approaches often only apply a pre-specified set of augmentations for \"positive pairs\" during learning. In this work, we propose a contrastive learning approach that directly models the latent manifold using Lie group operators parameterized by coefficients with a sparsity-promoting prior. A variational distribution over these coefficients provides a generative model of the manifold, with samples which provide feature augmentations applicable both during contrastive training and downstream tasks. Additionally, learned coefficient distributions provide a quantification of which transformations are most likely at each point on the manifold while preserving identity. We demonstrate benefits in self-supervised benchmarks for image datasets, as well as a downstream semi-supervised task. In the former case, we demonstrate that the proposed methods can effectively apply manifold feature augmentations and improve learning both with and without a projection head. In the latter case, we demonstrate that feature augmentations sampled from learned Lie group operators can improve classification performance when using few labels",
    "checked": true,
    "id": "5861aeb9659b9449f7482e0d5543933216577727",
    "semantic_title": "manifold contrastive learning with variational lie group operators",
    "citation_count": 1,
    "authors": [
      "Kion Fallah",
      "Alec Helbling",
      "Kyle A. Johnsen",
      "Christopher John Rozell"
    ]
  },
  "https://openreview.net/forum?id=805jKZ0Gqf": {
    "title": "Pseudo-Differential Neural Operator: Generalize Fourier Neural operator for Learning Solution Operators of Partial Differential Equations",
    "volume": "main",
    "abstract": "Learning mapping between two function spaces has attracted considerable research attention. However, learning the solution operator of partial differential equations (PDEs) remains a challenge in scientific computing. Fourier neural operator (FNO) is recently proposed to learn the solution operators with an excellent performance. In this study, we propose a novel pseudo-differential integral operator (PDIO) to analyze and generalize the Fourier integral operator in FNO. PDIO is inspired by a pseudo-differential operator, which is a generalization of a differential operator and characterized by a certain symbol. We parameterize the symbol by using a neural network and show that the neural-network-based symbol is contained in a smooth symbol class. Subsequently, we prove that the PDIO is a bounded linear operator, and thus is continuous in the Sobolev space. We combine the PDIO with the neural operator to develop a pseudo-differential neural operator (PDNO) to learn the nonlinear solution operator of PDEs. We experimentally validate the effectiveness of the proposed model by using Darcy flow and the Navier-Stokes equation. The results reveal that the proposed PDNO outperforms the existing neural operator approaches in most experiments",
    "checked": true,
    "id": "72551363d7f8e457239bb7852ee64b6e06d437d6",
    "semantic_title": "pseudo-differential neural operator: generalize fourier neural operator for learning solution operators of partial differential equations",
    "citation_count": 3,
    "authors": [
      "Jin Young Shin",
      "Jae Yong Lee",
      "Hyung Ju Hwang"
    ]
  },
  "https://openreview.net/forum?id=TTRDCVnbjI": {
    "title": "Are Population Graphs Really as Powerful as Believed?",
    "volume": "main",
    "abstract": "Population graphs and their use in combination with graph neural networks (GNNs) have demonstrated promising results for multi-modal medical data integration and improving disease diagnosis and prognosis. Several different methods for constructing these graphs and advanced graph learning techniques have been established to maximise the predictive power of GNNs on population graphs. However, in this work, we raise the question of whether existing methods are really strong enough by showing that simple baseline methods --such as random forests or linear regressions--, perform on par with advanced graph learning models on several population graph datasets for a variety of different clinical applications. We use the commonly used public population graph datasets TADPOLE and ABIDE, a brain age estimation and a cardiac dataset from the UK Biobank, and a real-world in-house COVID dataset. We (a) investigate the impact of different graph construction methods, graph convolutions, and dataset size and complexity on GNN performance and (b) discuss the utility of GNNs for multi-modal data integration in the context of population graphs. Based on our results, we argue towards the need for \"better\" graph construction methods or innovative applications for population graphs to render them beneficial",
    "checked": true,
    "id": "5b636a833df6bd16462f508e7d00458f8ee639cd",
    "semantic_title": "are population graphs really as powerful as believed?",
    "citation_count": 0,
    "authors": [
      "Tamara T. MÃ¼ller",
      "Sophie Starck",
      "Kyriaki-Margarita Bintsi",
      "Alexander Ziller",
      "Rickmer Braren",
      "Georgios Kaissis",
      "Daniel Rueckert"
    ]
  },
  "https://openreview.net/forum?id=sPlhAIp6mk": {
    "title": "Multitask Learning Can Improve Worst-Group Outcomes",
    "volume": "main",
    "abstract": "In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the standard setting of fine-tuning a pre-trained model, where, following recent work \\citep{gururangan2020don, dery2023aang}, we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not consistently, achieves better worst-group accuracy than Just-Train-Twice (JTT; \\citet{pmlr-v139-liu21f}) -- a representative distributionally robust optimization (DRO) method. Leveraging insights from synthetic data experiments, we propose to modify standard MTL by regularizing the joint multitask representation space. We run a large number of fine-tuning experiments across computer vision and natural language processing datasets and find that our regularized MTL approach \\emph{consistently} outperforms JTT on both average and worst-group outcomes. Our official code can be found here: \\href{https://github.com/atharvajk98/MTL-group-robustness.git}{\\url{https://github.com/atharvajk98/MTL-group-robustness}}",
    "checked": true,
    "id": "e36dbc1ae9b5116b798d519948de097c3bf19e5b",
    "semantic_title": "multitask learning can improve worst-group outcomes",
    "citation_count": 2,
    "authors": [
      "Atharva Kulkarni",
      "Lucio M. Dery",
      "Amrith Setlur",
      "Aditi Raghunathan",
      "Ameet Talwalkar",
      "Graham Neubig"
    ]
  },
  "https://openreview.net/forum?id=3nprbNR3HB": {
    "title": "ASPEST: Bridging the Gap Between Active Learning and Selective Prediction",
    "volume": "main",
    "abstract": "Selective prediction aims to learn a reliable model that abstains from making predictions when uncertain. These predictions can then be deferred to humans for further evaluation. As an everlasting challenge for machine learning, in many real-world scenarios, the distribution of test data is different from the training data. This results in more inaccurate predictions, and often increased dependence on humans, which can be difficult and expensive. Active learning aims to lower the overall labeling effort, and hence human dependence, by querying the most informative examples. Selective prediction and active learning have been approached from different angles, with the connection between them missing. In this work, we introduce a new learning paradigm, active selective prediction, which aims to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new paradigm, we propose a simple yet effective approach, ASPEST, that utilizes ensembles of model snapshots with self-training with their aggregated outputs as pseudo labels. Extensive experiments on numerous image, text and structured datasets, which suffer from domain shifts, demonstrate that ASPEST can significantly outperform prior work on selective prediction and active learning (e.g. on the MNIST$\\to$SVHN benchmark with the labeling budget of 100, ASPEST improves the AUACC metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop",
    "checked": true,
    "id": "217d5e0c5ed75f45256e14e122035eeb9af1722b",
    "semantic_title": "aspest: bridging the gap between active learning and selective prediction",
    "citation_count": 1,
    "authors": [
      "Jiefeng Chen",
      "Jinsung Yoon",
      "Sayna Ebrahimi",
      "Sercan O Arik",
      "Somesh Jha",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=OUWG6O4yo9": {
    "title": "Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures",
    "volume": "main",
    "abstract": "Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler \"statistical component separation\" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it performs surprisingly well in terms of peak signal-to-noise ratio on full signal reconstruction. In comparison, representation 2) appears less suitable for image denoising. Finally, we extend this method by introducing a diffusive stepwise algorithm which gives a new perspective to the initial method and leads to promising results for image denoising under specific circumstances",
    "checked": true,
    "id": "63a2bd0261a3f28f52327c8f43f4c8c44e2f1fed",
    "semantic_title": "statistical component separation for targeted signal recovery in noisy mixtures",
    "citation_count": 2,
    "authors": [
      "Bruno RÃ©galdo-Saint Blancard",
      "Michael Eickenberg"
    ]
  },
  "https://openreview.net/forum?id=WeiRR8h87X": {
    "title": "Budgeted Online Model Selection and Fine-Tuning via Federated Learning",
    "volume": "main",
    "abstract": "Online model selection involves selecting a model from a set of candidate models `on the fly' to perform prediction on a stream of data. The choice of candidate models henceforth has a crucial impact on the performance. Although employing a larger set of candidate models naturally leads to more flexibility in model selection, this may be infeasible in cases where prediction tasks are performed on edge devices with limited memory. Faced with this challenge, the present paper proposes an online federated model selection framework where a group of learners (clients) interacts with a server with sufficient memory such that the server stores all candidate models. However, each client only chooses to store a subset of models that can be fit into its memory and performs its own prediction task using one of the stored models. Furthermore, employing the proposed algorithm, clients and the server collaborate to fine-tune models to adapt them to a non-stationary environment. Theoretical analysis proves that the proposed algorithm enjoys sub-linear regret with respect to the best model in hindsight. Experiments on real datasets demonstrate the effectiveness of the proposed algorithm",
    "checked": true,
    "id": "fa74e4a136cc81ffe79e7b936de451d947310a99",
    "semantic_title": "budgeted online model selection and fine-tuning via federated learning",
    "citation_count": 2,
    "authors": [
      "Pouya M. Ghari",
      "Yanning Shen"
    ]
  },
  "https://openreview.net/forum?id=icoP08mrQJ": {
    "title": "Leveraging Endo- and Exo-Temporal Regularization for Black-box Video Domain Adaptation",
    "volume": "main",
    "abstract": "To enable video models to be applied seamlessly across video tasks in different environments, various Video Unsupervised Domain Adaptation (VUDA) methods have been proposed to improve the robustness and transferability of video models. Despite improvements made in model robustness, these VUDA methods require access to both source data and source model parameters for adaptation, raising serious data privacy and model portability issues. To cope with the above concerns, this paper firstly formulates Black-box Video Domain Adaptation (BVDA) as a more realistic yet challenging scenario where the source video model is provided only as a black-box predictor. While a few methods for Black-box Domain Adaptation (BDA) are proposed in the image domain, these methods cannot apply to the video domain since video modality has more complicated temporal features that are harder to align. To address BVDA, we propose a novel Endo and eXo-TEmporal Regularized Network (EXTERN) by applying mask-to-mix strategies and video-tailored regularizations. They are the endo-temporal regularization and exo-temporal regularization, which are performed across both clip and temporal features, while distilling knowledge from the predictions obtained from the black-box predictor. Empirical results demonstrate the state-of-the-art performance of EXTERN across various cross-domain closed-set and partial-set action recognition benchmarks, which even surpasses most existing video domain adaptation methods with source data accessibility. Code will be available at https://xuyu0010.github.io/b2vda.html",
    "checked": true,
    "id": "5c22f7d443a98ff02dd7c15c4473979205b42098",
    "semantic_title": "leveraging endo- and exo-temporal regularization for black-box video domain adaptation",
    "citation_count": 4,
    "authors": [
      "Yuecong Xu",
      "Jianfei Yang",
      "Haozhi Cao",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ]
  },
  "https://openreview.net/forum?id=Ryf1TVCjBz": {
    "title": "Correlation Clustering with Active Learning of Pairwise Similarities",
    "volume": "main",
    "abstract": "Correlation clustering is a well-known unsupervised learning setting that deals with positive and negative pairwise similarities. In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic active learning framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide, adaptation to any correlation clustering algorithm and query strategy, and robustness to noise. In addition, we propose and analyze a number of novel query strategies suited to this setting. We demonstrate the effectiveness of our framework and the proposed query strategies via several experimental studies",
    "checked": true,
    "id": "f672dec6afd24e63652363a58b69614cf0bd11de",
    "semantic_title": "correlation clustering with active learning of pairwise similarities",
    "citation_count": 4,
    "authors": [
      "Linus Aronsson",
      "Morteza Haghir Chehreghani"
    ]
  },
  "https://openreview.net/forum?id=uxNfN2PU1W": {
    "title": "Effective Latent Differential Equation Models via Attention and Multiple Shooting",
    "volume": "main",
    "abstract": "Scientific Machine Learning (SciML) is a burgeoning field that synergistically combines domain-aware and interpretable models with agnostic machine learning techniques. In this work, we introduce GOKU-UI, an evolution of the SciML generative model GOKU-nets. GOKU-UI not only broadens the original model's spectrum to incorporate other classes of differential equations, such as Stochastic Differential Equations (SDEs), but also integrates attention mechanisms and a novel multiple shooting training strategy in the latent space. These modifications have led to a significant increase in its performance in both reconstruction and forecast tasks, as demonstrated by our evaluation on simulated and empirical data. Specifically, GOKU-UI outperformed all baseline models on synthetic datasets even with a training set 16-fold smaller, underscoring its remarkable data efficiency. Furthermore, when applied to empirical human brain data, while incorporating stochastic Stuart-Landau oscillators into its dynamical core, our proposed enhancements markedly increased the model's effectiveness in capturing complex brain dynamics. GOKU-UI demonstrated a reconstruction error five times lower than other baselines, and the multiple shooting method reduced the GOKU-nets prediction error for future brain activity up to 15 seconds ahead. By training GOKU-UI on resting state fMRI data, we encoded whole-brain dynamics into a latent representation, learning a low-dimensional dynamical system model that could offer insights into brain functionality and open avenues for practical applications such as the classification of mental states or psychiatric conditions. Ultimately, our research provides further impetus for the field of Scientific Machine Learning, showcasing the potential for advancements when established scientific insights are interwoven with modern machine learning",
    "checked": true,
    "id": "379daf9fe029249ce15b5e6f53c2ee834693233c",
    "semantic_title": "effective latent differential equation models via attention and multiple shooting",
    "citation_count": 1,
    "authors": [
      "GermÃ¡n Abrevaya",
      "Mahta Ramezanian-Panahi",
      "Jean-Christophe Gagnon-Audet",
      "Pablo Polosecki",
      "Irina Rish",
      "Silvina Ponce Dawson",
      "Guillermo Cecchi",
      "Guillaume Dumas"
    ]
  },
  "https://openreview.net/forum?id=9TqAUYB6tC": {
    "title": "Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets",
    "volume": "main",
    "abstract": "In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data with any number of gates with adequately smooth and bounded activations, like sigmoid and tanh, and for a class of distributions from which the initial weight is sampled. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show that the logistic loss function on any size neural net can be Frobenius norm regularized by a width-independent parameter such that the regularized loss is a ``Villani function'' -- and thus be able to build on recent progress with analyzing SGD on such objectives",
    "checked": true,
    "id": "2b6040d20a0bf41d1d20caf886de57371ed464b0",
    "semantic_title": "global convergence of sgd for logistic loss on two layer neural nets",
    "citation_count": 2,
    "authors": [
      "Pulkit Gopalani",
      "Samyak Jha",
      "Anirbit Mukherjee"
    ]
  },
  "https://openreview.net/forum?id=uGVFtjvI3v": {
    "title": "Why should autoencoders work?",
    "volume": "main",
    "abstract": "Deep neural network autoencoders are routinely used computationally for model reduction. They allow recognizing the intrinsic dimension of data that lie in a $k$-dimensional subset $K$ of an input Euclidean space $\\mathbb{R}^n$. The underlying idea is to obtain both an encoding layer that maps $\\mathbb{R}^n$ into $\\mathbb{R}^k$ (called the bottleneck layer or the space of latent variables) and a decoding layer that maps $\\mathbb{R}^k$ back into $\\mathbb{R}^n$, in such a way that the input data from the set $K$ is recovered when composing the two maps. This is achieved by adjusting parameters (weights) in the network to minimize the discrepancy between the input and the reconstructed output. Since neural networks (with continuous activation functions) compute continuous maps, the existence of a network that achieves perfect reconstruction would imply that $K$ is homeomorphic to a $k$-dimensional subset of $\\mathbb{R}^k$, so clearly there are topological obstructions to finding such a network. On the other hand, in practice the technique is found to ``work'' well, which leads one to ask if there is a way to explain this effectiveness. We show that, up to small errors, indeed the method is guaranteed to work. This is done by appealing to certain facts from differential topology. A computational example is also included to illustrate the ideas",
    "checked": true,
    "id": "31e6d857ac83fe4dd2d9084d5c0485cb6b42504b",
    "semantic_title": "why should autoencoders work?",
    "citation_count": 2,
    "authors": [
      "Matthew Kvalheim",
      "Eduardo Sontag"
    ]
  },
  "https://openreview.net/forum?id=n2gAD8Fdzk": {
    "title": "Enhancing Robustness to Class-Conditional Distribution Shift in Long-Tailed Recognition",
    "volume": "main",
    "abstract": "For long-tailed recognition problem, beyond imbalanced label distribution, unreliable empirical data distribution due to instance scarcity has recently emerged as a concern. It inevitably causes Class-Conditional Distribution (CCD) shift between training and test. Data augmentation and head-to-tail information transfer methods indirectly alleviate the problem by synthesizing novel examples but may remain biased. In this paper, we conduct a thorough study on the impact of CCD shift and propose Distributionally Robust Augmentation (DRA) to directly train models robust to the shift. DRA admits a novel generalization bound reflecting the benefit of distributional robustness to CCD shift for long-tailed recognition. Extensive experiments show DRA greatly improves existing re-balancing and data augmentation methods when cooperating with them. It also alleviates the recently discovered saddle-point issue, verifying its ability to achieve enhanced robustness",
    "checked": true,
    "id": "4a4752eba69c7ce66ba4c0edb7c94a94f6ea4b8f",
    "semantic_title": "enhancing robustness to class-conditional distribution shift in long-tailed recognition",
    "citation_count": 0,
    "authors": [
      "Keliang Li",
      "Hong Chang",
      "Shiguang Shan",
      "Xilin CHEN"
    ]
  },
  "https://openreview.net/forum?id=Eg8Rnb0Hdd": {
    "title": "Expected Pinball Loss For Quantile Regression And Inverse CDF Estimation",
    "volume": "main",
    "abstract": "We analyze and improve a recent strategy to train a quantile regression model by minimizing an expected pinball loss over all quantiles. Through an asymptotic convergence analysis, we show that minimizing the expected pinball loss can be more efficient at estimating single quantiles than training with the standard pinball loss for that quantile, an insight that generalizes the known deficiencies of the sample quantile in the unconditioned setting. Then, to guarantee a legitimate inverse CDF, we propose using flexible deep lattice networks with a monotonicity constraint on the quantile input to guarantee non-crossing quantiles, and show lattice models can be regularized to the same location-scale family. Our analysis and experiments on simulated and real datasets show that the proposed method produces state-of-the-art legitimate inverse CDF estimates that are likely to be as good or better for specific target quantiles",
    "checked": true,
    "id": "559c57ec361e8086588a299b50dfc95083493018",
    "semantic_title": "expected pinball loss for quantile regression and inverse cdf estimation",
    "citation_count": 3,
    "authors": [
      "Taman Narayan",
      "Serena Lutong Wang",
      "Kevin Robert Canini",
      "Maya Gupta"
    ]
  },
  "https://openreview.net/forum?id=OZbn8ULouY": {
    "title": "The Slingshot Effect: A Late-Stage Optimization Anomaly in Adaptive Gradient Methods",
    "volume": "main",
    "abstract": "Adaptive gradient methods, notably Adam ~\\citep{kingma2014adam, loshchilov2017decoupled}, have become indispensable for optimizing neural networks, particularly in conjunction with Transformers ~\\citep{vaswani2017attention, dosovitskiy2020an}. In this paper, we present a novel optimization anomaly called the \\emph{Slingshot Effect}, which manifests during extremely late stages of training. We identify a distinctive characteristic of this phenomenon through cyclic phase transitions between stable and unstable training regimes, as evidenced by the cyclic behavior of the norm of the last layer's weights. Although the Slingshot Effect can be easily reproduced in more general settings, it does not align with any known optimization theories, emphasizing the need for in-depth examination. Moreover, we make a noteworthy observation that Grokking, as reported by ~\\citet{power2021grokking}, occurs predominantly during the onset of the Slingshot Effects and is absent without it, even in the absence of explicit regularization. This finding suggests a surprising inductive bias of adaptive gradient optimizers at late training stages, urging a revised theoretical analysis of their origin. Our study sheds light on an intriguing optimization behavior that has significant implications for understanding the inner workings of adaptive gradient methods",
    "checked": true,
    "id": "407f3147b3c1eb4c0ba9b6eb0b31c08c533b28a9",
    "semantic_title": "the slingshot effect: a late-stage optimization anomaly in adaptive gradient methods",
    "citation_count": 0,
    "authors": [
      "Vimal Thilak",
      "Etai Littwin",
      "Shuangfei Zhai",
      "Omid Saremi",
      "Roni Paiss",
      "Joshua M. Susskind"
    ]
  },
  "https://openreview.net/forum?id=mqMzerrVOB": {
    "title": "Mixed Nash for Robust Federated Learning",
    "volume": "main",
    "abstract": "We study robust federated learning (FL) within a game theoretic framework to alleviate the server vulnerabilities to even an informed adversary who can tailor training-time attacks. Specifically, we introduce RobustTailor, a simulation-based framework that prevents the adversary from being omniscient and derives its convergence guarantees. RobustTailor improves robustness to training-time attacks significantly while preserving almost the same privacy guarantees as standard robust aggregation schemes in FL. Empirical results under challenging attacks show that RobustTailor performs close to an upper bound with perfect knowledge of honest clients",
    "checked": true,
    "id": "aea10c5336e7f321af5800aafbf6faac3374b2dd",
    "semantic_title": "mixed nash for robust federated learning",
    "citation_count": 4,
    "authors": [
      "Wanyun Xie",
      "Thomas Pethick",
      "Ali Ramezani-Kebrya",
      "Volkan Cevher"
    ]
  },
  "https://openreview.net/forum?id=oCBsxCov2g": {
    "title": "PNeRV: A Polynomial Neural Representation for Videos",
    "volume": "main",
    "abstract": "Extracting Implicit Neural Representations (INRs) on video data poses unique challenges due to the additional temporal dimension. In the context of videos, INRs have predominantly relied on a frame-only parameterization, which sacrifices the spatiotemporal continuity observed in pixel-level (spatial) representations. To mitigate this, we introduce Polynomial Neural Representation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR for videos that preserves spatiotemporal continuity. PNeRV leverages the modeling capabilities of Polynomial Neural Networks to perform the modulation of a continuous spatial (patch) signal with a continuous time (frame) signal. We further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme that ensures spatial continuity while retaining parameter efficiency. We also employ a carefully designed Positional Embedding methodology to further enhance PNeRV's performance. Our extensive experimentation demonstrates that PNeRV outperforms the baselines in conventional Implicit Neural Representation tasks like compression along with downstream applications that require spatiotemporal continuity in the underlying representation. PNeRV not only addresses the challenges posed by video data in the realm of INRs but also opens new avenues for advanced video processing and analysis",
    "checked": true,
    "id": "c216d8d79503107bf68897f9206d81cf153823b8",
    "semantic_title": "pnerv: a polynomial neural representation for videos",
    "citation_count": 0,
    "authors": [
      "Sonam Gupta",
      "Snehal Singh Tomar",
      "Grigorios Chrysos",
      "Sukhendu Das",
      "Rajagopalan N Ambasamduram"
    ]
  },
  "https://openreview.net/forum?id=daX2UkLMS0": {
    "title": "Exploring Simple, High Quality Out-of-Distribution Detection with L2 Normalization",
    "volume": "main",
    "abstract": "We demonstrate that L2 normalization over feature space can produce capable performance for Out-of-Distribution (OoD) detection for some models and datasets. Although it does not demonstrate outright state-of-the-art performance, this method is notable for its extreme simplicity: it requires only two addition lines of code, and does not need specialized loss functions, image augmentations, outlier exposure or extra parameter tuning. We also observe that training may be more efficient for some datasets and architectures. Notably, only 60 epochs with ResNet18 on CIFAR10 (or 100 epochs with ResNet50) can produce performance within two percentage points (AUROC) of several state-of-the-art methods for some near and far OoD datasets. We provide theoretical and empirical support for this method, and demonstrate viability across five architectures and three In-Distribution (ID) datasets",
    "checked": true,
    "id": "9b952ed671fa82de294ae53c275c443f393896bd",
    "semantic_title": "exploring simple, high quality out-of-distribution detection with l2 normalization",
    "citation_count": 2,
    "authors": [
      "Jarrod Haas",
      "William Yolland",
      "Bernhard T Rabus"
    ]
  },
  "https://openreview.net/forum?id=TySx8fsSSU": {
    "title": "On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning",
    "volume": "main",
    "abstract": "Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how the addition of conformal prediction affects out-of-distribution coverage that we would otherwise see; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets (i.e. not using conformal prediction). Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. In particular, we study the extent to which the addition of conformal prediction increases or decreases out-of-distribution coverage for a variety of inference techniques. In particular, (i) stochastic gradient descent, (ii) deep ensembles, (iii) mean-field variational inference, (iv) stochastic gradient Hamiltonian Monte Carlo, and (v) Laplace approximation. Our results suggest that the application of conformal prediction to different predictive deep learning methods can have significantly different consequences",
    "checked": true,
    "id": "5e7707e2133d965ff48718ecf9ce61b19c65b570",
    "semantic_title": "on the out-of-distribution coverage of combining split conformal prediction and bayesian deep learning",
    "citation_count": 0,
    "authors": [
      "Paul Scemama",
      "Ariel Kapusta"
    ]
  },
  "https://openreview.net/forum?id=RUNiIDU8P7": {
    "title": "Estimating Optimal Policy Value in Linear Contextual Bandits Beyond Gaussianity",
    "volume": "main",
    "abstract": "In many bandit problems, the maximal reward achievable by a policy is often unknown in advance. We consider the problem of estimating the optimal policy value in the sublinear data regime before the optimal policy is even learnable. We refer to this as $V^*$ estimation. It was previously shown that fast $V^*$ estimation is possible but only in disjoint linear bandits with Gaussian covariates. Whether this is possible for more realistic context distributions has remained an open and important question for tasks such as model selection. In this paper, we first provide lower bounds showing that this general problem is hard. However, under stronger assumptions, we give an algorithm and analysis proving that $\\widetilde{\\mathcal{O}}(\\sqrt{d})$ sublinear estimation of $V^*$ is indeed information-theoretically possible, where $d$ is the dimension. We subsequently introduce a practical and computationally efficient algorithm that estimates a problem-specific upper bound on $V^*$, valid for general distributions and tight for Gaussian context distributions. We prove our algorithm requires only $\\widetilde{\\mathcal{O}}(\\sqrt{d})$ samples to estimate the upper bound. We use this upper bound in conjunction with the estimator to derive novel and improved guarantees for several applications in bandit model selection and testing for treatment effects. We present promising experimental benefits on a semi-synthetic simulation using historical data on warfarin treatment dosage outcomes",
    "checked": true,
    "id": "a9ede635d2bcd3232698791dbc4b7fa93ee45eac",
    "semantic_title": "estimating optimal policy value in linear contextual bandits beyond gaussianity",
    "citation_count": 0,
    "authors": [
      "Jonathan Lee",
      "Weihao Kong",
      "Aldo Pacchiano",
      "Vidya Muthukumar",
      "Emma Brunskill"
    ]
  },
  "https://openreview.net/forum?id=48pHFcg0YO": {
    "title": "DynaConF: Dynamic Forecasting of Non-Stationary Time Series",
    "volume": "main",
    "abstract": "Deep learning has shown impressive results in a variety of time series forecasting tasks, where modeling the conditional distribution of the future given the past is the essence. However, when this conditional distribution is non-stationary, it poses challenges for these models to learn consistently and to predict accurately. In this work, we propose a new method to model non-stationary conditional distributions over time by clearly decoupling stationary conditional distribution modeling from non-stationary dynamics modeling. Our method is based on a Bayesian dynamic model that can adapt to conditional distribution changes and a deep conditional distribution model that handles multivariate time series using a factorized output space. Our experimental results on synthetic and real-world datasets show that our model can adapt to non-stationary time series better than state-of-the-art deep learning solutions",
    "checked": false,
    "id": "d111d372e1f0ae5982c7a52726b1bf9c502466e9",
    "semantic_title": "dynaconf: dynamic forecasting of non-stationary time-series",
    "citation_count": 2,
    "authors": [
      "Siqi Liu",
      "Andreas Lehrmann"
    ]
  },
  "https://openreview.net/forum?id=uXGUSX8GoY": {
    "title": "QDC: Quantum Diffusion Convolution Kernels on Graphs",
    "volume": "main",
    "abstract": "Graph convolutional neural networks (GCNs) operate by aggregating messages over local neighborhoods given the prediction task under interest. Many GCNs can be understood as a form of generalized diffusion of input features on the graph, and significant work has been dedicated to improving predictive accuracy by altering the ways of message passing. In this work, we propose a new convolution kernel that effectively rewires the graph according to the occupation correlations of the vertices by trading on the generalized diffusion paradigm for the propagation of a quantum particle over the graph. We term this new convolution kernel the Quantum Diffusion Convolution (QDC) operator. In addition, we introduce a multiscale variant that combines messages from the QDC operator and the traditional combinatorial Laplacian. To understand our method, we explore the spectral dependence of homophily and the importance of quantum dynamics in the construction of a bandpass filter. Through these studies, as well as experiments on a range of datasets, we observe that QDC improves predictive performance on the widely used benchmark datasets when compared to similar methods",
    "checked": true,
    "id": "82aa9b8b8ccf2f879665397d023c4ca1173e6b34",
    "semantic_title": "qdc: quantum diffusion convolution kernels on graphs",
    "citation_count": 4,
    "authors": [
      "Thomas Markovich"
    ]
  },
  "https://openreview.net/forum?id=torWsEui9N": {
    "title": "Image Reconstruction via Deep Image Prior Subspaces",
    "volume": "main",
    "abstract": "Deep learning has been widely used for solving image reconstruction tasks but its deployability has been held back due to the shortage of high-quality paired training data. Unsupervised learning methods, e.g., deep image prior (DIP), naturally fill this gap, but bring a host of new issues: the susceptibility to overfitting due to a lack of robust early stopping strategies and unstable convergence. We present a novel approach to tackle these issues by restricting DIP optimisation to a sparse linear subspace of its parameters, employing a synergy of dimensionality reduction techniques and second order optimisation methods. The low-dimensionality of the subspace reduces DIP's tendency to fit noise and allows the use of stable second order optimisation methods, e.g., natural gradient descent or L-BFGS. Experiments across both image restoration and tomographic tasks of different geometry and ill-posedness show that second order optimisation within a low-dimensional subspace is favourable in terms of optimisation stability to reconstruction fidelity trade-off",
    "checked": true,
    "id": "174910a4357196a37632efa3022afb5bd254e676",
    "semantic_title": "image reconstruction via deep image prior subspaces",
    "citation_count": 1,
    "authors": [
      "Riccardo Barbano",
      "Javier Antoran",
      "Johannes Leuschner",
      "JosÃ© Miguel HernÃ¡ndez-Lobato",
      "Bangti Jin",
      "Zeljko Kereta"
    ]
  },
  "https://openreview.net/forum?id=0yMuNezwJ1": {
    "title": "On the Dual Problem of Convexified Convolutional Neural Networks",
    "volume": "main",
    "abstract": "We study the dual problem of convexified convolutional neural networks (DCCNNs). First, we introduce a primal learning problem motivated by convexified convolutional neural networks (CCNNs), and then construct the dual convex training program through careful analysis of the Karush-Kuhn-Tucker (KKT) conditions and Fenchel conjugates. Our approach reduces the computational overhead of constructing a large kernel matrix and more importantly, eliminates the ambiguity of factorizing the matrix. Due to the low-rank structure in CCNNs and the related subdifferential of nuclear norms, there is no closed-form expression to recover the primal solution from the dual solution. To overcome this, we propose a highly novel weight recovery algorithm, which takes the dual solution and the kernel information as the input, and recovers the linear weight and the output of convolutional layer, instead of weight parameter. Furthermore, our recovery algorithm exploits the low-rank structure and imposes a small number of filters indirectly, which reduces the parameter size. As a result, DCCNNs inherit all the statistical benefits of CCNNs, while enjoying a more formal and efficient workflow",
    "checked": true,
    "id": "93f105f79e9af12590c129b7bc3755956262dc66",
    "semantic_title": "on the dual problem of convexified convolutional neural networks",
    "citation_count": 0,
    "authors": [
      "Site Bai",
      "Chuyang Ke",
      "Jean Honorio"
    ]
  },
  "https://openreview.net/forum?id=xkiflfKCw3": {
    "title": "Evaluating Spatial Understanding of Large Language Models",
    "volume": "main",
    "abstract": "Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training, several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here, we explore LLM representations of a particularly salient kind of grounded knowledge --- spatial relationships. We design natural-language navigation tasks and evaluate the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures. We also compare these abilities to human performance on the same tasks. These tasks reveal substantial variability in LLM performance across different spatial structures, including square, hexagonal, and triangular grids, rings, and trees. In extensive error analysis, we find that LLMs' mistakes reflect both spatial and non-spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly, but room for improvement remains",
    "checked": true,
    "id": "a00cb75a2bf2ee20b778ec5587f802ea2db013e3",
    "semantic_title": "evaluating spatial understanding of large language models",
    "citation_count": 43,
    "authors": [
      "Yutaro Yamada",
      "Yihan Bao",
      "Andrew Kyle Lampinen",
      "Jungo Kasai",
      "Ilker Yildirim"
    ]
  },
  "https://openreview.net/forum?id=3PbxuMNQkp": {
    "title": "Robust Learning Rate Selection for Stochastic Optimization via Splitting Diagnostic",
    "volume": "main",
    "abstract": "This paper proposes SplitSGD, a new dynamic learning rate schedule for stochastic optimization. This method decreases the learning rate for better adaptation to the local geometry of the objective function whenever a stationary phase is detected, that is, the iterates are likely to bounce at around a vicinity of a local minimum. The detection is performed by splitting the single thread into two and using the inner product of the gradients from the two threads as a measure of stationarity. Owing to this simple yet provably valid stationarity detection, SplitSGD is easy-to-implement and essentially does not incur additional computational cost than standard SGD. Through a series of extensive experiments, we show that this method is appropriate for both convex problems and training (non-convex) neural networks, with performance compared favorably to other stochastic optimization methods. Importantly, this method is observed to be very robust with a set of default parameters for a wide range of problems and, moreover, can yield better generalization performance than other adaptive gradient methods such as Adam",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Sordello",
      "Niccolo Dalmasso",
      "Hangfeng He",
      "Weijie J Su"
    ]
  },
  "https://openreview.net/forum?id=d3xwrfAG4V": {
    "title": "Transfer Learning for High-dimensional Quantile Regression with Statistical Guarantee",
    "volume": "main",
    "abstract": "The task of transfer learning is to improve estimation/inference of a target model by migrating data from closely related source populations. In this article, we propose transfer learning algorithms for high-dimensional Quantile Regression (QR) models with the technique of convolution-type smoothing. Given the transferable source populations, we derive $\\ell_1/\\ell_2$-estimation error bounds for the estimators of the target regression coefficients under mild conditions. Theoretical analysis shows that the upper bounds are improved over those of the classical penalized QR estimator with only the target data, as long as the target and the sources are sufficiently similar to each other. When the set of informative sources is unknown, a transferable source detection algorithm is proposed to detect informative sources from all available sources. Thorough simulation studies justify our theoretical analysis",
    "checked": true,
    "id": "e5b434cb641b572f60bec85d335227273ca76f52",
    "semantic_title": "transfer learning for high-dimensional quantile regression with statistical guarantee",
    "citation_count": 2,
    "authors": [
      "Sheng Qiao",
      "Yong He",
      "Wenxin Zhou"
    ]
  },
  "https://openreview.net/forum?id=JdXzKSyqbH": {
    "title": "Recovering Exact Support in Federated lasso without Optimization",
    "volume": "main",
    "abstract": "Federated learning provides a framework to address the challenges of distributed computing, data ownership, and privacy over a large number of distributed clients with low computational and communication capabilities. In this paper, we study the problem of learning the exact support of sparse linear regression in the federated learning setup. We provide a simple communication efficient algorithm that only needs one-shot communication with the centralized server to compute the exact support by majority voting. Our method does not require the clients to solve any optimization problem and thus, can be run on devices with low computational capabilities. Our method is naturally robust to the problems of client failure, model poisoning, and straggling clients. We formally prove that our method requires a number of samples per client that is polynomial with respect to the support size, but independent of the dimension of the problem. We require the number of distributed clients to be logarithmic in the dimension of the problem. For certain classes of predictor variables (e.g. mutually independent, correlated Gaussian, etc.), the overall sample complexity matches the optimal sample complexity of the non-federated centralized setting. Furthermore, our method is easy to implement and has an overall polynomial time complexity",
    "checked": true,
    "id": "559e73fc2e9caacb4e8fa86103198150d479d884",
    "semantic_title": "recovering exact support in federated lasso without optimization",
    "citation_count": 1,
    "authors": [
      "Adarsh Barik",
      "Jean Honorio"
    ]
  },
  "https://openreview.net/forum?id=ebiAFpQ0Lw": {
    "title": "NorMatch: Matching Normalizing Flows with Discriminative Classifiers for Semi-Supervised Learning",
    "volume": "main",
    "abstract": "Semi-Supervised Learning (SSL) aims to learn a model using a tiny labeled set and massive amounts of unlabeled data. To better exploit the unlabeled data the latest SSL methods use pseudo-labels predicted from \\emph{a single discriminative classifier}. However, the generated pseudo-labels are inevitably linked to inherent confirmation bias and noise which greatly affects the model performance. In this work, we introduce a new framework for SSL named NorMatch. Firstly, we introduce a new uncertainty estimation scheme based on normalizing flows, as an auxiliary classifier, to enforce highly certain pseudo-labels yielding a boost of the discriminative classifiers. Secondly, we introduce a threshold-free sample weighting strategy to exploit better both high and low confidence pseudo-labels. Furthermore, we utilize normalizing flows to model, in an unsupervised fashion, the distribution of unlabeled data. This modelling assumption can further improve the performance of generative classifiers via unlabeled data, and thus, implicitly contributing to training a better discriminative classifier. We demonstrate, through numerical and visual results, that NorMatch achieves state-of-the-art performance on several datasets",
    "checked": true,
    "id": "38058ad084ad771925cd31b4d5a5fb2f7353cee0",
    "semantic_title": "normatch: matching normalizing flows with discriminative classifiers for semi-supervised learning",
    "citation_count": 0,
    "authors": [
      "Zhongying Deng",
      "Rihuan Ke",
      "Carola-Bibiane SchÃ¶nlieb",
      "Angelica I Aviles-Rivero"
    ]
  },
  "https://openreview.net/forum?id=CyjG4ZKCtE": {
    "title": "Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step Q-learning: A Novel Correction Approach",
    "volume": "main",
    "abstract": "Compared to on-policy counterparts, off-policy model-free deep reinforcement learning can improve data efficiency by repeatedly using the previously gathered data. However, off-policy learning becomes challenging when the discrepancy between the underlying distributions of the agent's policy and collected data increases. Although the well-studied importance sampling and off-policy policy gradient techniques were proposed to compensate for this discrepancy, they usually require a collection of long trajectories and induce additional problems such as vanishing/exploding gradients or discarding many useful experiences, which eventually increases the computational complexity. Moreover, their generalization to either continuous action domains or policies approximated by deterministic deep neural networks is strictly limited. To overcome these limitations, we introduce a novel policy similarity measure to mitigate the effects of such discrepancy in continuous control. Our method offers an adequate single-step off-policy correction that is applicable to deterministic policy networks. Theoretical and empirical studies demonstrate that it can achieve a \"safe\" off-policy learning and substantially improve the state-of-the-art by attaining higher returns in fewer steps than the competing methods through an effective schedule of the learning rate in Q-learning and policy optimization",
    "checked": true,
    "id": "1dd9c9eb635fe8f77b1c4d5ed958f26612f90c2b",
    "semantic_title": "mitigating off-policy bias in actor-critic methods with one-step q-learning: a novel correction approach",
    "citation_count": 1,
    "authors": [
      "Baturay Saglam",
      "DoÄan Can ÃiÃ§ek",
      "Furkan Burak Mutlu",
      "Suleyman Kozat"
    ]
  },
  "https://openreview.net/forum?id=SSqOqAwpN7": {
    "title": "Provable Guarantees for Sparsity Recovery with Deterministic Missing Data Patterns",
    "volume": "main",
    "abstract": "We study the problem of consistently recovering the sparsity pattern of a regression parameter vector from correlated observations governed by deterministic missing data patterns using Lasso. We consider the case in which the observed dataset is censored by a deterministic, non-uniform filter. Recovering the sparsity pattern in datasets with deterministic missing structure can be arguably more challenging than recovering in a uniformly-at-random scenario. In this paper, we propose an efficient algorithm for missing value imputation by utilizing the topological property of the censorship filter. We then provide novel theoretical results for exact recovery of the sparsity pattern using the proposed imputation strategy. Our analysis shows that, under certain statistical and topological conditions, the hidden sparsity pattern can be recovered consistently with high probability in polynomial time and logarithmic sample complexity",
    "checked": true,
    "id": "6f13e295b6d50e025a35784d954b5d44ba0b67c7",
    "semantic_title": "provable guarantees for sparsity recovery with deterministic missing data patterns",
    "citation_count": 0,
    "authors": [
      "Chuyang Ke",
      "Jean Honorio"
    ]
  },
  "https://openreview.net/forum?id=dUVejidXO7": {
    "title": "Visual Prompt Based Personalized Federated Learning",
    "volume": "main",
    "abstract": "As a popular paradigm of distributed learning, personalized federated learning (PFL) allows personalized models to improve generalization ability and robustness by utilizing knowledge from all distributed clients. Most existing PFL algorithms tackle personalization in a model-centric way, such as personalized layer partition, model regularization, and model interpolation, which all fail to take into account the data characteristics of distributed clients. In this paper, we propose a novel PFL framework for image classification tasks, dubbed pFedPT, that leverages personalized visual prompts to implicitly represent local data distribution information of clients and provides that information to the aggregation model to help with classification tasks. Specifically, in each round of pFedPT training, each client generates a local personalized prompt related to local data distribution. Then, the local model is trained on the input composed of raw data and a visual prompt to learn the distribution information contained in the prompt. During model testing, the aggregated model obtains client-specific knowledge of the data distributions based on the prompts, which can be seen as an adaptive fine-tuning of the aggregation model to improve model performances on different clients. Furthermore, the visual prompt can be added as an orthogonal method to implement personalization on the client for existing FL methods to boost their performance. Experiments on the CIFAR10 and CIFAR100 datasets show that pFedPT outperforms several state-of-the-art (SOTA) PFL algorithms by a large margin in various settings. The code is available at: https://github.com/hkgdifyu/pFedPT",
    "checked": true,
    "id": "92c2c090ad911db57166821f8494de60fafe7d1d",
    "semantic_title": "visual prompt based personalized federated learning",
    "citation_count": 18,
    "authors": [
      "Guanghao Li",
      "Wansen Wu",
      "Yan Sun",
      "Li Shen",
      "Baoyuan Wu",
      "Dacheng Tao"
    ]
  },
  "https://openreview.net/forum?id=qKIvn9xL1R": {
    "title": "CR-MoE: Consistent Routed Mixture-of-Experts for Scaling Contrastive Learning",
    "volume": "main",
    "abstract": "While Contrastive Learning (CL) achieves great success in many downstream tasks, its good performance heavily relies on a large model capacity. As previous methods focus on scaling dense models, training and inference costs increase rapidly with model sizes, leading to large resource consumption. In this paper, we explore CL with an efficient scaling method, Mixture of Experts (MoE), to obtain a large but sparse model. We start by plugging in the state-of-the-art CL method to MoE. However, this naive combination fails to visibly improve performance despite a much larger capacity. A closer look reveals that the naive MoE+CL model has a strong tendency to route two augmented views of the same image token to different subsets of experts: such ``cross-view instability\" breaks the weight-sharing nature in CL and misleads the invariant feature learning. To address this issue, we introduce a new regularization mechanism, by enforcing expert-routing similarity between different views of the same image (or its overlapped patch tokens), while promoting expert-routing diversity of patches from different images. The resultant method, called CR-MoE, improves by 1.7 points in terms of 1\\% semi-supervised learning accuracy on ImageNet, compared to the naive combination baseline. It further surpasses the state-of-the-art CL methods on ImageNet pre-training of Vision Transformer (ViT) by 2.8 points, at the same computational cost. Our findings validate CR-MoE as an effective and efficient image representation learner. Code is available at https://github.com/VITA-Group/CRMoE",
    "checked": true,
    "id": "40891680185dd23b1270cb814ea555811c3b4618",
    "semantic_title": "cr-moe: consistent routed mixture-of-experts for scaling contrastive learning",
    "citation_count": 0,
    "authors": [
      "Ziyu Jiang",
      "Guoqing Zheng",
      "Yu Cheng",
      "Ahmed Hassan Awadallah",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=uqQPyWFDhY": {
    "title": "Error Bounds for Flow Matching Methods",
    "volume": "main",
    "abstract": "Score-based generative models are a popular class of generative modelling techniques relying on stochastic differential equations (SDEs). From their inception, it was realized that it was also possible to perform generation using ordinary differential equations (ODEs) rather than SDEs. This led to the introduction of the probability flow ODE approach and denoising diffusion implicit models. Flow matching methods have recently further extended these ODE-based approaches and approximate a flow between two arbitrary probability distributions. Previous work derived bounds on the approximation error of diffusion models under the stochastic sampling regime, given assumptions on the $L^2$ loss. We present error bounds for the flow matching procedure using fully deterministic sampling, assuming an $L^2$ bound on the approximation error and a certain regularity condition on the data distributions",
    "checked": true,
    "id": "465ea43827d145fef68e100bb367208ad85678bb",
    "semantic_title": "error bounds for flow matching methods",
    "citation_count": 38,
    "authors": [
      "Joe Benton",
      "George Deligiannidis",
      "Arnaud Doucet"
    ]
  },
  "https://openreview.net/forum?id=17ESEjETbP": {
    "title": "Non-Uniform Smoothness for Gradient Descent",
    "volume": "main",
    "abstract": "The analysis of gradient descent-type methods typically relies on the Lipschitz continuity of the objective gradient. This generally requires an expensive hyperparameter tuning process to appropriately calibrate a stepsize for a given problem. In this work we introduce a local first-order smoothness oracle (LFSO) which generalizes the Lipschitz continuous gradients smoothness condition and is applicable to any twice-differentiable function. We show that this oracle can encode all relevant problem information for tuning stepsizes for a suitably modified gradient descent method and give global and local convergence results. We also show that LFSOs in this modified first-order method can yield global linear convergence rates for non-strongly convex problems with extremely flat minima, and thus improve over the lower bound on rates achievable by general (accelerated) first-order methods",
    "checked": true,
    "id": "ab21e7ee715a02b76c209e20d90a58f758cbcad8",
    "semantic_title": "non-uniform smoothness for gradient descent",
    "citation_count": 4,
    "authors": [
      "Albert S. Berahas",
      "Lindon Roberts",
      "Fred Roosta"
    ]
  },
  "https://openreview.net/forum?id=Jy2IgzjoFH": {
    "title": "Hierarchical Neural Simulation-Based Inference Over Event Ensembles",
    "volume": "main",
    "abstract": "When analyzing real-world data it is common to work with event ensembles, which comprise sets of observations that collectively constrain the parameters of an underlying model of interest. Such models often have a hierarchical structure, where ``local'' parameters impact individual events and ``global'' parameters influence the entire dataset. We introduce practical approaches for frequentist and Bayesian dataset-wide probabilistic inference in cases where the likelihood is intractable, but simulations can be realized via a hierarchical forward model. We construct neural estimators for the likelihood(-ratio) or posterior and show that explicitly accounting for the model's hierarchical structure can lead to significantly tighter parameter constraints. We ground our discussion using case studies from the physical sciences, focusing on examples from particle physics and cosmology",
    "checked": true,
    "id": "69667fd30ec42d34e78345bb6e19071e6e5a9b5b",
    "semantic_title": "hierarchical neural simulation-based inference over event ensembles",
    "citation_count": 7,
    "authors": [
      "Lukas Heinrich",
      "Siddharth Mishra-Sharma",
      "Chris Pollard",
      "Philipp Windischhofer"
    ]
  },
  "https://openreview.net/forum?id=HyqSwNhM3x": {
    "title": "What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning?",
    "volume": "main",
    "abstract": "Various methods for Multi-Agent Reinforcement Learning (MARL) have been developed with the assumption that agents' policies are based on accurate state information. However, policies learned through Deep Reinforcement Learning (DRL) are susceptible to adversarial state perturbation attacks. In this work, we propose a State-Adversarial Markov Game (SAMG) and make the first attempt to investigate different solution concepts of MARL under state uncertainties. Our analysis shows that the commonly used solution concepts of optimal agent policy and robust Nash equilibrium do not always exist in SAMGs. To circumvent this difficulty, we consider a new solution concept called robust agent policy, where agents aim to maximize the worst-case expected state value. We prove the existence of robust agent policy for finite state and finite action SAMGs. Additionally, we propose a Robust Multi-Agent Adversarial Actor-Critic (RMA3C) algorithm to learn robust policies for MARL agents under state uncertainties. Our experiments demonstrate that our algorithm outperforms existing methods when faced with state perturbations and greatly improves the robustness of MARL policies. Our code is public on https://songyanghan.github.io/what_is_solution/",
    "checked": true,
    "id": "cfd2c668504c0a97e73fe6e40fe7fc869aa5a40a",
    "semantic_title": "what is the solution for state-adversarial multi-agent reinforcement learning?",
    "citation_count": 25,
    "authors": [
      "Songyang Han",
      "Sanbao Su",
      "Sihong He",
      "Shuo Han",
      "Haizhao Yang",
      "Shaofeng Zou",
      "Fei Miao"
    ]
  },
  "https://openreview.net/forum?id=Y2ru0LuQeS": {
    "title": "MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation",
    "volume": "main",
    "abstract": "We introduce MESSY estimation, a Maximum-Entropy based Stochastic and Symbolic densitY estimation method. The proposed approach recovers probability density functions symbolically from samples using moments of a Gradient flow in which the ansatz serves as the driving force. In particular, we construct a gradient-based drift-diffusion process that connects samples of the unknown distribution function to a guess symbolic expression. We then show that when the guess distribution has the maximum entropy form, the parameters of this distribution can be found efficiently by solving a linear system of equations constructed using the moments of the provided samples. Furthermore, we use Symbolic regression to explore the space of smooth functions and find optimal basis functions for the exponent of the maximum entropy functional leading to good conditioning. The cost of the proposed method for each set of selected basis functions is linear with the number of samples and quadratic with the number of basis functions. However, the underlying acceptance/rejection procedure for finding optimal and well-conditioned bases adds to the computational cost. We validate the proposed MESSY estimation method against other benchmark methods for the case of a bi-modal and a discontinuous density, as well as a density at the limit of physical realizability. We find that the addition of a symbolic search for basis functions improves the accuracy of the estimation at a reasonable additional computational cost. Our results suggest that the proposed method outperforms existing density recovery methods in the limit of a small to moderate number of samples by providing a low-bias and tractable symbolic description of the unknown density at a reasonable computational cost",
    "checked": true,
    "id": "f248be199edf5dce636f958814d50f9b9e52bc34",
    "semantic_title": "messy estimation: maximum-entropy based stochastic and symbolic density estimation",
    "citation_count": 3,
    "authors": [
      "Tony Tohme",
      "Mohsen Sadr",
      "KAMAL YOUCEF-TOUMI",
      "Nicolas Hadjiconstantinou"
    ]
  },
  "https://openreview.net/forum?id=ynG5Ak7n7Q": {
    "title": "The Fair Value of Data Under Heterogeneous Privacy Constraints in Federated Learning",
    "volume": "main",
    "abstract": "Modern data aggregation often involves a platform collecting data from a network of users with various privacy options. Platforms must solve the problem of how to allocate incentives to users to convince them to share their data. This paper puts forth an idea for a fair amount to compensate users for their data at a given privacy level based on an axiomatic definition of fairness, along the lines of the celebrated Shapley value. To the best of our knowledge, these are the first fairness concepts for data that explicitly consider privacy constraints. We also formulate a heterogeneous federated learning problem for the platform with privacy level options for users. By studying this problem, we investigate the amount of compensation users receive under fair allocations with different privacy levels, amounts of data, and degrees of heterogeneity. We also discuss what happens when the platform is forced to design fair incentives. Under certain conditions we find that when privacy sensitivity is low, the platform will set incentives to ensure that it collects all the data with the lowest privacy options. When the privacy sensitivity is above a given threshold, the platform will provide no incentives to users. Between these two extremes, the platform will set the incentives so some fraction of the users chooses the higher privacy option and the others chooses the lower privacy option",
    "checked": false,
    "id": "3fa0bf2a4f563f25514bafe79098d2ea18f0f56d",
    "semantic_title": "the fair value of data under heterogeneous privacy constraints",
    "citation_count": 5,
    "authors": [
      "Justin Singh Kang",
      "Ramtin Pedarsani",
      "Kannan Ramchandran"
    ]
  },
  "https://openreview.net/forum?id=pWsfWDnJDa": {
    "title": "Out-of-Distribution Optimality of Invariant Risk Minimization",
    "volume": "main",
    "abstract": "Deep Neural Networks often inherit spurious correlations embedded in training data and hence may fail to generalize to unseen domains, which have different distributions from the domain to provide training data. M. Arjovsky et al. (2019) introduced the concept out-of-distribution (o.o.d.) risk, which is the maximum risk among all domains, and formulated the issue caused by spurious correlations as a minimization problem of the o.o.d. risk. Invariant Risk Minimization (IRM) is considered to be a promising approach to minimize the o.o.d. risk: IRM estimates a minimum of the o.o.d. risk by solving a bi-level optimization problem. While IRM has attracted considerable attention with empirical success, it comes with few theoretical guarantees. Especially, a solid theoretical guarantee that the bi-level optimization problem gives the minimum of the o.o.d. risk has not yet been established. Aiming at providing a theoretical justification for IRM, this paper rigorously proves that a solution to the bi-level optimization problem minimizes the o.o.d. risk under certain conditions. The result also provides sufficient conditions on distributions providing training data and on a dimension of feature space for the bi-leveled optimization problem to minimize the o.o.d. risk",
    "checked": true,
    "id": "1b326b04bfe326295e588e18ebfd94b26a878c85",
    "semantic_title": "out-of-distribution optimality of invariant risk minimization",
    "citation_count": 1,
    "authors": [
      "Shoji Toyota",
      "Kenji Fukumizu"
    ]
  },
  "https://openreview.net/forum?id=ZLVbQEu4Ab": {
    "title": "When is Momentum Extragradient Optimal? A Polynomial-Based Analysis",
    "volume": "main",
    "abstract": "The extragradient method has gained popularity due to its robust convergence properties for differentiable games. Unlike single-objective optimization, game dynamics involve complex interactions reflected by the eigenvalues of the game vector field's Jacobian scattered across the complex plane. This complexity can cause the simple gradient method to diverge, even for bilinear games, while the extragradient method achieves convergence. Building on the recently proven accelerated convergence of the momentum extragradient method for bilinear games \\citep{azizian2020accelerating}, we use a polynomial-based analysis to identify three distinct scenarios where this method exhibits further accelerated convergence. These scenarios encompass situations where the eigenvalues reside on the (positive) real line, lie on the real line alongside complex conjugates, or exist solely as complex conjugates. Furthermore, we derive the hyperparameters for each scenario that achieve the fastest convergence rate",
    "checked": true,
    "id": "1412997ab05fabe40a9dec6e1d8622c8480a8c71",
    "semantic_title": "when is momentum extragradient optimal? a polynomial-based analysis",
    "citation_count": 1,
    "authors": [
      "Junhyung Lyle Kim",
      "Gauthier Gidel",
      "Anastasios Kyrillidis",
      "Fabian Pedregosa"
    ]
  },
  "https://openreview.net/forum?id=Wqn8zirthg": {
    "title": "DDLP: Unsupervised Object-centric Video Prediction with Deep Dynamic Latent Particles",
    "volume": "main",
    "abstract": "We propose a new object-centric video prediction algorithm based on the deep latent particle (DLP) representation of Daniel and Tamar (2022). In comparison to existing slot- or patch-based representations, DLPs model the scene using a set of keypoints with learned parameters for properties such as position and size, and are both efficient and interpretable. Our method, \\textit{deep dynamic latent particles} (DDLP), yields state-of-the-art object-centric video prediction results on several challenging datasets. The interpretable nature of DDLP allows us to perform ``what-if'' generation -- predict the consequence of changing properties of objects in the initial frames, and DLP's compact structure enables efficient diffusion-based unconditional video generation. Videos, code and pre-trained models are available: https://taldatech.github.io/ddlp-web",
    "checked": true,
    "id": "7d22e6d110a2be18ef7236fb2238fd85463de4b2",
    "semantic_title": "ddlp: unsupervised object-centric video prediction with deep dynamic latent particles",
    "citation_count": 8,
    "authors": [
      "Tal Daniel",
      "Aviv Tamar"
    ]
  },
  "https://openreview.net/forum?id=vWTZO1RXZR": {
    "title": "Introspective Experience Replay: Look Back When Surprised",
    "volume": "main",
    "abstract": "In reinforcement learning (RL), experience replay-based sampling techniques are crucial in promoting convergence by eliminating spurious correlations. However, widely used methods such as uniform experience replay (UER) and prioritized experience replay (PER) have been shown to have sub-optimal convergence and high seed sensitivity, respectively. To address these issues, we propose a novel approach called Introspective Experience Replay (IER) that selectively samples batches of data points prior to surprising events. Our method is inspired from the reverse experience replay (RER) technique, which has been shown to reduce bias in the output of Q-learning-type algorithms with linear function approximation. However, RER is not always practically reliable when using neural function approximation. Through empirical evaluations, we demonstrate that IER with neural function approximation yields reliable and superior performance compared to UER, PER, and hindsight experience replay (HER) across most tasks",
    "checked": true,
    "id": "e6bd20a796c48f9c17ef55c6a821ec678a341b3b",
    "semantic_title": "introspective experience replay: look back when surprised",
    "citation_count": 2,
    "authors": [
      "Ramnath Kumar",
      "Dheeraj Mysore Nagaraj"
    ]
  },
  "https://openreview.net/forum?id=O9RUANpPmb": {
    "title": "Domain-Generalizable Multiple-Domain Clustering",
    "volume": "main",
    "abstract": "This work generalizes the problem of unsupervised domain generalization to the case in which no labeled samples are available (completely unsupervised). We are given unlabeled samples from multiple source domains, and we aim to learn a shared predictor that assigns examples to semantically related clusters. Evaluation is done by predicting cluster assignments in previously unseen domains. Towards this goal, we propose a two-stage training framework: (1) self-supervised pre-training for extracting domain invariant semantic features. (2) multi-head cluster prediction with pseudo labels, which rely on both the feature space and cluster head prediction, further leveraging a novel prediction-based label smoothing scheme. We demonstrate empirically that our model is more accurate than baselines that require fine-tuning using samples from the target domain or some level of supervision. Our code is available at \\url{https://github.com/AmitRozner/domain-generalizable-multiple-domain-clustering}",
    "checked": true,
    "id": "dfe2fffe974ec43dff94f02228d545270e3e63fb",
    "semantic_title": "domain-generalizable multiple-domain clustering",
    "citation_count": 9,
    "authors": [
      "Amit Rozner",
      "Barak Battash",
      "Lior Wolf",
      "Ofir Lindenbaum"
    ]
  },
  "https://openreview.net/forum?id=Igxp7FC8uf": {
    "title": "Fixed-Budget Best-Arm Identification in Sparse Linear Bandits",
    "volume": "main",
    "abstract": "We study the best-arm identification problem in sparse linear bandits under the fixed-budget setting. In sparse linear bandits, the unknown feature vector $\\theta^*$ may be of large dimension $d$, but only a few, say $s \\ll d$ of these features have non-zero values. We design a two-phase algorithm, Lasso and Optimal-Design- (Lasso-OD) based linear best-arm identification. The first phase of Lasso-OD leverages the sparsity of the feature vector by applying the thresholded Lasso introduced by Zhou (2009), which estimates the support of $\\theta^*$ correctly with high probability using rewards from the selected arms and a judicious choice of the design matrix. The second phase of Lasso-OD applies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated support. We derive a non-asymptotic upper bound on the error probability of Lasso-OD by carefully choosing hyperparameters (such as Lasso's regularization parameter) and balancing the error probabilities of both phases. For fixed sparsity $s$ and budget $T$, the exponent in the error probability of Lasso-OD depends on $s$ but not on the dimension $d$, yielding a significant performance improvement for sparse and high-dimensional linear bandits. Furthermore, we show that Lasso-OD is almost minimax optimal in the exponent. Finally, we provide numerical examples to demonstrate the significant performance improvement over the existing algorithms for non-sparse linear bandits such as OD-LinBAI, BayesGap, Peace, LinearExploration, and GSE",
    "checked": true,
    "id": "e59f0a8bceffaefb7f646723e53afcb3ff3bc9e0",
    "semantic_title": "fixed-budget best-arm identification in sparse linear bandits",
    "citation_count": 2,
    "authors": [
      "Recep Can Yavas",
      "Vincent Y. F. Tan"
    ]
  },
  "https://openreview.net/forum?id=6BDHUkSPna": {
    "title": "Understanding the Role of Layer Normalization in Label-Skewed Federated Learning",
    "volume": "main",
    "abstract": "Layer normalization (LN) is a widely adopted deep learning technique especially in the era of foundation models. Recently, LN has been shown to be surprisingly effective in federated learning (FL) with non-i.i.d. data. However, exactly why and how it works remains mysterious. In this work, we reveal the profound connection between layer normalization and the label shift problem in federated learning. To understand layer normalization better in FL, we identify the key contributing mechanism of normalization methods in FL, called feature normalization (FN), which applies normalization to the latent feature representation before the classifier head. Although LN and FN do not improve expressive power, they control feature collapse and local overfitting to heavily skewed datasets, and thus accelerates global training. Empirically, we show that normalization leads to drastic improvements on standard benchmarks under extreme label shift. Moreover, we conduct extensive ablation studies to understand the critical factors of layer normalization in FL. Our results verify that FN is an essential ingredient inside LN to significantly improve the convergence of FL while remaining robust to learning rate choices, especially under extreme label shift where each client has access to few classes",
    "checked": true,
    "id": "dcf939f84b63e38a0235868ac3e7b9f99a196765",
    "semantic_title": "understanding the role of layer normalization in label-skewed federated learning",
    "citation_count": 3,
    "authors": [
      "Guojun Zhang",
      "Mahdi Beitollahi",
      "Alex Bie",
      "Xi Chen"
    ]
  },
  "https://openreview.net/forum?id=KKARKoPcEA": {
    "title": "Learning to Abstain From Uninformative Data",
    "volume": "main",
    "abstract": "Learning and decision-making in domains with naturally high noise-to-signal ratios â such as Finance or Healthcare â is often challenging, while the stakes are very high. In this paper, we study the problem of learning and acting under a general noisy generative process. In this problem, the data distribution has a significant proportion of uninformative samples with high noise in the label, while part of the data contains useful information represented by low label noise. This dichotomy is present during both training and inference, which requires the proper handling of uninformative data during both training and testing. We propose a novel approach to learning under these conditions via a loss inspired by the selective learning theory. By minimizing this loss, the model is guaranteed to make a near-optimal decision by distinguishing informative data from uninformative data and making predictions. We build upon the strength of our theoretical guarantees by describing an iterative algorithm, which jointly optimizes both a predictor and a selector, and evaluates its empirical performance in a variety of settings",
    "checked": true,
    "id": "6df82e80441fc2a67c6ad81879001313fab36568",
    "semantic_title": "learning to abstain from uninformative data",
    "citation_count": 2,
    "authors": [
      "Yikai Zhang",
      "Songzhu Zheng",
      "Mina Dalirrooyfard",
      "Pengxiang Wu",
      "Anderson Schneider",
      "Anant Raj",
      "Yuriy Nevmyvaka",
      "Chao Chen"
    ]
  },
  "https://openreview.net/forum?id=6wpInwnzs8": {
    "title": "WaveBench: Benchmarking Data-driven Solvers for Linear Wave Propagation PDEs",
    "volume": "main",
    "abstract": "Wave-based imaging techniques play a critical role in diverse scientific, medical, and industrial endeavors, from discovering hidden structures beneath the Earth's surface to ultrasound diagnostics. They rely on accurate solutions to the forward and inverse problems for partial differential equations (PDEs) that govern wave propagation. Surrogate PDE solvers based on machine learning emerged as an effective approach to computing the solutions more efficiently than via classical numerical schemes. However, existing datasets for PDE surrogates offer only limited coverage of the wave propagation phenomenon. In this paper, we present WaveBench, a comprehensive collection of benchmark datasets for wave propagation PDEs. WaveBench (1) contains 24 datasets that cover a wide range of forward and inverse problems for time-harmonic and time-varying wave phenomena; (2) includes a user-friendly PyTorch environment for comparing learning-based methods; and (3) comprises reference performance and model checkpoints of popular PDE surrogates such as Fourier neural operators and U-Nets. Our evaluation on WaveBench demonstrates the impressive performance of PDE surrogates on in-distribution samples, while simultaneously unveiling their limitations on out-of-distribution samples, indicating room for future improvements. We anticipate that WaveBench will stimulate the development of accurate wave-based imaging techniques through machine learning",
    "checked": true,
    "id": "ad319a06082af904a1c1b4ee82a96e9b159d2eff",
    "semantic_title": "wavebench: benchmarking data-driven solvers for linear wave propagation pdes",
    "citation_count": 0,
    "authors": [
      "Tianlin Liu",
      "Jose Antonio Lara Benitez",
      "Florian Faucher",
      "AmirEhsan Khorashadizadeh",
      "Maarten V. de Hoop",
      "Ivan DokmaniÄ"
    ]
  },
  "https://openreview.net/forum?id=fUhOb14sQv": {
    "title": "Using Motion Cues to Supervise Single-frame Body Pose & Shape Estimation in Low Data Regimes",
    "volume": "main",
    "abstract": "When enough annotated training data is available, supervised deep-learning algorithms excel at estimating human body pose and shape using a single camera. The effects of too little such data being available can be mitigated by using other information sources, such as databases of body shapes, to learn priors. Unfortunately, such sources are not always available either. We show that, in such cases, easy to-obtain unannotated videos can be used instead to provide the required supervisory signals. Given a trained model using too little annotated data, we compute poses in consecutive frames along with the optical flow between them. We then enforce consistency between the image optical flow and the one that can be inferred from the change in pose from one frame to the next. This provides enough additional supervision to effectively refine the network weights and to perform on par with methods trained using far more annotated data",
    "checked": true,
    "id": "65a276ca79f5ed3a669366e817fc9c5ed7385dcc",
    "semantic_title": "using motion cues to supervise single-frame body pose & shape estimation in low data regimes",
    "citation_count": 0,
    "authors": [
      "Andrey Davydov",
      "Alexey Sidnev",
      "Artsiom Sanakoyeu",
      "Yuhua Chen",
      "Mathieu Salzmann",
      "Pascal Fua"
    ]
  },
  "https://openreview.net/forum?id=E8m8oySvPJ": {
    "title": "LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations",
    "volume": "main",
    "abstract": "Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some \"core knowledge\" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we propose an object-based representation that is obtained through an external tool, resulting in nearly doubling the performance on solved ARC tasks and near-perfect scores on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \"reason\" perfectly within non-language domains such as the 1D-ARC or a simple ARC subset, our study reveals that the use of object-based representations can significantly improve its reasoning ability. Visualizations, GPT logs, and data are available at https://khalil-research.github.io/LLM4ARC",
    "checked": true,
    "id": "8826311d922135dbf0cfdb4a661ebab347e3b826",
    "semantic_title": "llms and the abstraction and reasoning corpus: successes, failures, and the importance of object-based representations",
    "citation_count": 66,
    "authors": [
      "Yudong Xu",
      "Wenhao Li",
      "Pashootan Vaezipoor",
      "Scott Sanner",
      "Elias Boutros Khalil"
    ]
  },
  "https://openreview.net/forum?id=fJAwemcvpL": {
    "title": "Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder",
    "volume": "main",
    "abstract": "Composed image retrieval aims to find an image that best matches a given multi-modal user query consisting of a reference image and text pair. Existing methods commonly pre-compute image embeddings over the entire corpus and compare these to a reference image embedding modified by the query text at test time. Such a pipeline is very efficient at test time since fast vector distances can be used to evaluate candidates, but modifying the reference image embedding guided only by a short textual description can be difficult, especially independent of potential candidates. An alternative approach is to allow interactions between the query and every possible candidate, i.e., reference-text-candidate triplets, and pick the best from the entire set. Though this approach is more discriminative, for large-scale datasets the computational cost is prohibitive since pre-computation of candidate embeddings is no longer possible. We propose to combine the merits of both schemes using a two-stage model. Our first stage adopts the conventional vector distancing metric and performs a fast pruning among candidates. Meanwhile, our second stage employs a dual-encoder architecture, which effectively attends to the input triplet of reference-text-candidate and re-ranks the candidates. Both stages utilize a vision-and-language pre-trained network, which has proven beneficial for various downstream tasks. Our method consistently outperforms state-of-the-art approaches on standard benchmarks for the task. Our implementation is available at https://github.com/Cuberick-Orion/Candidate-Reranking-CIR",
    "checked": true,
    "id": "5eceaeac5d45d49e1d5698947ed8292ff3fccd81",
    "semantic_title": "candidate set re-ranking for composed image retrieval with dual multi-modal encoder",
    "citation_count": 18,
    "authors": [
      "Zheyuan Liu",
      "Weixuan Sun",
      "Damien Teney",
      "Stephen Gould"
    ]
  },
  "https://openreview.net/forum?id=jesKcQxQ7j": {
    "title": "A Review of the Applications of Deep Learning-Based Emergent Communication",
    "volume": "main",
    "abstract": "Emergent communication, or emergent language, is the field of research which studies how human language-like communication systems emerge de novo in deep multi-agent reinforcement learning environments. The possibilities of replicating the emergence of a complex behavior like language have strong intuitive appeal, yet it is necessary to complement this with clear notions of how such research can be applicable to other fields of science, technology, and engineering. This paper comprehensively reviews the applications of emergent communication research across machine learning, natural language processing, linguistics, and cognitive science. Each application is illustrated with a description of its scope, an explication of emergent communication's unique role in addressing it, a summary of the extant literature working towards the application, and brief recommendations for near-term research directions",
    "checked": true,
    "id": "5b19fb4c441856490cbfe8c3eab05187e4063d33",
    "semantic_title": "a review of the applications of deep learning-based emergent communication",
    "citation_count": 8,
    "authors": [
      "Brendon Boldt",
      "David R Mortensen"
    ]
  },
  "https://openreview.net/forum?id=mH6TelHVKD": {
    "title": "Data-Dependent Generalization Bounds for Neural Networks with ReLU",
    "volume": "main",
    "abstract": "We try to establish that one of the correct data-dependent quantities to look at while trying to prove generalization bounds, even for overparameterized neural networks, are the gradients encountered by stochastic gradient descent while training the model. If these are small, then the model generalizes. To make this conclusion rigorous, we weaken the notion of uniform stability of a learning algorithm in a probabilistic way by positing the notion of almost sure (a.s.) support stability and showing that algorithms that have this form of stability have generalization error tending to 0 as the training set size increases. Further, we show that for Stochastic Gradient Descent to be a.s. support stable we only need the loss function to be a.s. locally Lipschitz and locally Smooth at the training points, thereby showing low generalization error with weaker conditions than have been used in the literature. We then show that Neural Networks with ReLU activation and a doubly differentiable loss function possess these properties. Our notion of stability is the first data-dependent notion to be able to show good generalization bounds for non-convex functions with learning rates strictly slower than $1/t$ at the $t$-th step. Finally, we present experimental evidence to validate our theoretical results",
    "checked": true,
    "id": "26363cbad28c93b60485a21ee9cbf7da4c293ad3",
    "semantic_title": "data-dependent generalization bounds for neural networks with relu",
    "citation_count": 0,
    "authors": [
      "Harsh Pandey",
      "Amitabha Bagchi",
      "Srikanta J. Bedathur",
      "Arindam Bhattacharya"
    ]
  },
  "https://openreview.net/forum?id=5nBqY1y96B": {
    "title": "Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs",
    "volume": "main",
    "abstract": "Large language models (LLMs) have achieved widespread success on a variety of in-context few-shot tasks, but this success is typically evaluated via correctness rather than consistency. We argue that self-consistency is an important criteria for valid multi-step reasoning in tasks where the solution is composed of the answers to multiple sub-steps. We propose two types of self-consistency that are particularly important for multi-step reasoning -- hypothetical consistency (a model's ability to predict what its output would be in a hypothetical other context) and compositional consistency (consistency of a model's final outputs when intermediate sub-steps are replaced with the model's outputs for those steps). We demonstrate that multiple variants of the GPT-3/-4 models exhibit poor consistency rates across both types of consistency on a variety of tasks",
    "checked": true,
    "id": "3200a0d6fef7164f0341cf1938f584da6057ffd6",
    "semantic_title": "two failures of self-consistency in the multi-step reasoning of llms",
    "citation_count": 32,
    "authors": [
      "Angelica Chen",
      "Jason Phang",
      "Alicia Parrish",
      "Vishakh Padmakumar",
      "Chen Zhao",
      "Samuel R. Bowman",
      "Kyunghyun Cho"
    ]
  },
  "https://openreview.net/forum?id=emXh4M7TyH": {
    "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces",
    "volume": "main",
    "abstract": "Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on \"training\" functions. These training functions are typically required to have the same domain as the \"test\" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks",
    "checked": true,
    "id": "7889cf92ff5120430db0371ff5c70aeb151ac71d",
    "semantic_title": "transfer learning for bayesian optimization on heterogeneous search spaces",
    "citation_count": 9,
    "authors": [
      "Zhou Fan",
      "Xinran Han",
      "Zi Wang"
    ]
  },
  "https://openreview.net/forum?id=zc0Y0cAuTV": {
    "title": "A Multilinear Least-Squares Formulation for Sparse Tensor Canonical Correlation Analysis",
    "volume": "main",
    "abstract": "Tensor data are becoming important recently in various applications, e.g., image and video recognition, which pose new challenges for data modeling and analysis approaches, such as high-order relations of large complexity, varying data scale and gross noise. In this paper, we consider the problem of sparse canonical correlation analysis for arbitrary tensor data. Although several methods have been proposed for this task, there are still limitations hindering its practical applications. To this end, we present a general Sparse Tensor Canonical Correlation Analysis (gSTCCA) method from a multilinear least-squares perspective. Specifically, we formulate the problem as a constrained multilinear least-squares problem with tensor-structured sparsity regularization based on CANDECOMP/PARAFAC (CP) decomposition. Then we present a divide-and-conquer deflation approach to tackle the problem by successive rank-one tensor estimation of the residual tensors, where the overall model is broken up into a set of unconstrained linear least-squares problems that can be efficiently solved. Through extensive experiments conducted on five different datasets for recognition tasks, we demonstrate that the proposed method achieves promising performance compared to the SOTA vector- and tensor-based canonical correlation analysis methods in terms of classification accuracy, model sparsity, and robustness to missing and noisy data. The code is publicly available at https://github.com/junfish/gSTCCA",
    "checked": true,
    "id": "c3435b396472eb8231e3dc153858e12b1db47ed6",
    "semantic_title": "a multilinear least-squares formulation for sparse tensor canonical correlation analysis",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Zhaoming Kong",
      "Kun Chen",
      "Xin Zhang",
      "Yong Chen",
      "Lifang He"
    ]
  },
  "https://openreview.net/forum?id=xLg8ljlEba": {
    "title": "Generalizing Neural Additive Models via Statistical Multimodal Analysis",
    "volume": "main",
    "abstract": "Interpretable models are gaining increasing attention in the machine learning community, and significant progress is being made to develop simple, interpretable, yet powerful deep learning approaches. Generalized Additive Models (GAM) and Neural Additive Models (NAM) are prime examples. Despite these methods' great potential and popularity in critical applications, e.g., medical applications, they fail to generalize to distributions with more than one mode (multimodal\\footnote{In this paper, multimodal refers to the context of distributions, wherein a distribution possesses more than one mode.}). The main reason behind this limitation is that these \"all-fit-one\" models collapse multiple relationships by being forced to fit the data unimodally. We address this critical limitation by proposing interpretable multimodal network frameworks capable of learning a Mixture of Neural Additive Models (MNAM). The proposed MNAM learns relationships between input features and outputs in a multimodal fashion and assigns a probability to each mode. The proposed method shares similarities with Mixture Density Networks (MDN) while keeping the interpretability that characterizes GAM and NAM. We demonstrate how the proposed MNAM balances between rich representations and interpretability with numerous empirical observations and pedagogical studies. We present and discuss different training alternatives and provided extensive practical evaluation to assess the proposed framework. The code is available at \\href{https://github.com/youngkyungkim93/MNAM}{https://github.com/youngkyungkim93/MNAM}",
    "checked": true,
    "id": "2511437a4198b6e3c972382aff50b78a852438f0",
    "semantic_title": "generalizing neural additive models via statistical multimodal analysis",
    "citation_count": 1,
    "authors": [
      "Young Kyung Kim",
      "Juan Matias Di Martino",
      "Guillermo Sapiro"
    ]
  },
  "https://openreview.net/forum?id=5G3PI1hEdw": {
    "title": "A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models",
    "volume": "main",
    "abstract": "Key to tasks that require reasoning about natural language in visual contexts is grounding words and phrases to image regions. However, observing this grounding in contemporary models is complex, even if it is generally expected to take place if the task is addressed in a way that is conductive to generalization. We propose a framework to jointly study task performance and phrase grounding, and propose three benchmarks to study the relation between the two. Our results show that contemporary models demonstrate inconsistency between their ability to ground phrases and solve tasks. We show how this can be addressed through brute-force training on ground phrasing annotations, and analyze the dynamics it creates. Code and data are available at https://github.com/lil-lab/phrase_grounding",
    "checked": true,
    "id": "b38a634a2902a333cce1f97789df03ae3189ed76",
    "semantic_title": "a joint study of phrase grounding and task performance in vision and language models",
    "citation_count": 2,
    "authors": [
      "Noriyuki Kojima",
      "Hadar Averbuch-Elor",
      "Yoav Artzi"
    ]
  },
  "https://openreview.net/forum?id=RwmWODTNFE": {
    "title": "Size Lowerbounds for Deep Operator Networks",
    "volume": "main",
    "abstract": "Deep Operator Networks are an increasingly popular paradigm for solving regression in infinite dimensions and hence solve families of PDEs in one shot. In this work, we aim to establish a first-of-its-kind data-dependent lowerbound on the size of DeepONets required for them to be able to reduce empirical error on noisy data. In particular, we show that for low training errors to be obtained on $n$ data points it is necessary that the common output dimension of the branch and the trunk net be scaling as $\\Omega \\left ( \\sqrt[\\leftroot{-1}\\uproot{-1}4]{n} \\right )$. This inspires our experiments with DeepONets solving the advection-diffusion-reaction PDE, where we demonstrate the possibility that at a fixed model size, to leverage increase in this common output dimension and get monotonic lowering of training error, the size of the training data might necessarily need to scale at least quadratically with it",
    "checked": true,
    "id": "cf80dd08c9a3783c62585203a71f50e6e1a238f8",
    "semantic_title": "size lowerbounds for deep operator networks",
    "citation_count": 3,
    "authors": [
      "Anirbit Mukherjee",
      "Amartya Roy"
    ]
  },
  "https://openreview.net/forum?id=0T2OTVCCC1": {
    "title": "Extending Path-Dependent NJ-ODEs to Noisy Observations and a Dependent Observation Framework",
    "volume": "main",
    "abstract": "The \\emph{Path-Dependent Neural Jump Ordinary Differential Equation (PD-NJ-ODE)} is a model for predicting continuous-time stochastic processes with irregular and incomplete observations. In particular, the method learns optimal forecasts given irregularly sampled time series of incomplete past observations. So far the process itself and the coordinate-wise observation times were assumed to be independent and observations were assumed to be noiseless. In this work we discuss two extensions to lift these restrictions and provide theoretical guarantees as well as empirical examples for them. In particular, we can lift the assumption of independence by extending the theory to much more realistic settings of conditional independence without any need to change the algorithm. Moreover, we introduce a new loss function, which allows us to deal with noisy observations and explain why the previously used loss function did not lead to a consistent estimator",
    "checked": true,
    "id": "4c384b8a6b5ff1550926eeddb8f32f7f77771469",
    "semantic_title": "extending path-dependent nj-odes to noisy observations and a dependent observation framework",
    "citation_count": 2,
    "authors": [
      "William Andersson",
      "Jakob Heiss",
      "Florian Krach",
      "Josef Teichmann"
    ]
  },
  "https://openreview.net/forum?id=3s7ior0WZ5": {
    "title": "Blind Biological Sequence Denoising with Self-Supervised Set Learning",
    "volume": "main",
    "abstract": "Biological sequence analysis relies on the ability to denoise the imprecise output of sequencing platforms. We consider a common setting where a short sequence is read out repeatedly using a high-throughput long-read platform to generate multiple subreads, or noisy obser- vations of the same sequence. Denoising these subreads with alignment-based approaches often fails when too few subreads are available or error rates are too high. In this paper, we propose a novel method for blindly denoising sets of sequences without directly observing clean source sequence labels. Our method, Self-Supervised Set Learning (SSSL), gathers subreads together in an embedding space and estimates a single set embedding as the mid- point of the subreads in both the latent and sequence spaces. This set embedding represents the \"average\" of the subreads and can be decoded into a prediction of the clean sequence. In experiments on simulated long-read DNA data, SSSL methods denoise small reads of â¤ 6 subreads with 17% fewer errors and large reads of > 6 subreads with 8% fewer errors compared to the best baseline. On a real dataset of antibody sequences, SSSL improves over baselines on two self-supervised metrics, with a significant improvement on difficult small reads that comprise over 60% of the test set. By accurately denoising these reads, SSSL promises to better realize the potential of high-throughput DNA sequencing data for downstream scientific applications",
    "checked": true,
    "id": "512d4baaacb28578464db7697a49ee5dcd69f915",
    "semantic_title": "blind biological sequence denoising with self-supervised set learning",
    "citation_count": 0,
    "authors": [
      "Nathan Hoyen Ng",
      "Ji Won Park",
      "Jae Hyeon Lee",
      "Ryan Lewis Kelly",
      "Stephen Ra",
      "Kyunghyun Cho"
    ]
  },
  "https://openreview.net/forum?id=wyU3Q4gahM": {
    "title": "Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled",
    "volume": "main",
    "abstract": "Deep generative models (DGMs) have been widely developed for graph data. However, much less investigation has been carried out on understanding the latent space of such pretrained graph DGMs. These understandings possess the potential to provide constructive guidelines for crucial tasks, such as graph controllable generation. Thus in this work, we are interested in studying this problem and propose GraphCG, a method for the unsupervised discovery of steerable factors in the latent space of pretrained graph DGMs. We first examine the representation space of three pretrained graph DGMs with six disentanglement metrics, and we observe that the pretrained representation space is entangled. Motivated by this observation, GraphCG learns the steerable factors via maximizing the mutual information between semantic-rich directions, where the controlled graph moving along the same direction will share the same steerable factors. We quantitatively verify that GraphCG outperforms four competitive baselines on two graph DGMs pretrained on two molecule datasets. Additionally, we qualitatively illustrate seven steerable factors learned by GraphCG on five pretrained DGMs over five graph datasets, including two for molecules and three for point clouds",
    "checked": true,
    "id": "7856380962bcdd4a98ca7c8381dc7c80f963623e",
    "semantic_title": "unsupervised discovery of steerable factors when graph deep generative models are entangled",
    "citation_count": 3,
    "authors": [
      "Shengchao Liu",
      "Chengpeng Wang",
      "Jiarui Lu",
      "Weili Nie",
      "Hanchen Wang",
      "Zhuoxinran Li",
      "Bolei Zhou",
      "Jian Tang"
    ]
  },
  "https://openreview.net/forum?id=n2YifD4Dxo": {
    "title": "Are you using test log-likelihood correctly?",
    "volume": "main",
    "abstract": "Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error",
    "checked": true,
    "id": "b6e363f617667014aea2d609136816fad22affc7",
    "semantic_title": "are you using test log-likelihood correctly?",
    "citation_count": 7,
    "authors": [
      "Sameer Deshpande",
      "Soumya Ghosh",
      "Tin D. Nguyen",
      "Tamara Broderick"
    ]
  },
  "https://openreview.net/forum?id=M2m618iIPk": {
    "title": "Blockwise Self-Supervised Learning at Scale",
    "volume": "main",
    "abstract": "Current state-of-the-art deep networks are all powered by backpropagation. However, long backpropagation paths as found in end-to-end training are biologically implausible, as well as inefficient in terms of energy consumption. In this paper, we explore alternatives to full backpropagation in the form of blockwise learning rules, leveraging the latest developments in self-supervised learning. We show that a blockwise pretraining procedure consisting of training independently the 4 main blocks of layers of a ResNet-50 with Barlow Twins' loss function at each block performs almost as well as end-to-end backpropagation on ImageNet: a linear probe trained on top of our blockwise pretrained model obtains a top-1 classification accuracy of 70.48\\%, only 1.1\\% below the accuracy of an end-to-end pretrained network (71.57\\% accuracy). We perform extensive experiments to understand the impact of different components within our method and explore a variety of adaptations of self-supervised learning to the blockwise paradigm, building an exhaustive understanding of the critical avenues for scaling local learning rules to large networks, with implications ranging from hardware design to neuroscience",
    "checked": true,
    "id": "a09a197325be3fb2e865692b164e8827042201d1",
    "semantic_title": "blockwise self-supervised learning at scale",
    "citation_count": 16,
    "authors": [
      "Shoaib Siddiqui",
      "David Krueger",
      "Yann LeCun",
      "Stephane Deny"
    ]
  },
  "https://openreview.net/forum?id=zSeoG5dRHK": {
    "title": "Temporally Rich Deep Learning Models for Magnetoencephalography",
    "volume": "main",
    "abstract": "Deep learning has been used in a wide range of applications, but it has only very recently been applied to Magnetoencephalography (MEG). MEG is a neurophysiological technique used to investigate a variety of cognitive processes such as language and learning, and an emerging technology in the quest to identify neural correlates of cognitive impairments such as those occurring in dementia. Recent work has shown that it is possible to apply deep learning to MEG to categorise induced responses to stimuli across subjects. While novel in the application of deep learning, such work has generally used relatively simple neural network (NN) models compared to those being used in domains such as computer vision and natural language processing. In these other domains, there is a long history in developing complex NN models that combine spatial and temporal information. We propose more complex NN models that focus on modelling temporal relationships in the data, and apply them to the challenges of MEG data. We apply these models to an extended range of MEG-based tasks, and find that they substantially outperform existing work on a range of tasks, particularly but not exclusively temporally-oriented ones. We also show that an autoencoder-based preprocessing component that focuses on the temporal aspect of the data can improve the performance of existing models. Our source code is available at https://github.com/tim-chard/DeepLearningForMEG",
    "checked": true,
    "id": "56b36b5339450db4ab8f4dafeb54a0313690e40e",
    "semantic_title": "temporally rich deep learning models for magnetoencephalography",
    "citation_count": 1,
    "authors": [
      "Tim Chard",
      "Mark Dras",
      "Paul Sowman",
      "Steve Cassidy",
      "Jia Wu"
    ]
  },
  "https://openreview.net/forum?id=KhMLfEIoUm": {
    "title": "Disciplined Saddle Programming",
    "volume": "main",
    "abstract": "We consider convex-concave saddle point problems, and more generally convex optimization problems we refer to as saddle problems, which include the partial supremum or infimum of convex-concave saddle functions. Saddle problems arise in a wide range of applications, including game theory, machine learning, and finance. It is well known that a saddle problem can be reduced to a single convex optimization problem by dualizing either the convex (min) or concave (max) objectives, reducing a min-max problem into a min-min (or max-max) problem. Carrying out this conversion by hand can be tedious and error prone. In this paper we introduce disciplined saddle programming (DSP), a domain specific language (DSL) for specifying saddle problems, for which the dualizing trick can be automated. The language and methods are based on recent work by Juditsky and Nemirovski, who developed the idea of conic-representable saddle point programs, and showed how to carry out the required dualization automatically using conic duality. Juditsky and Nemirovski's conic representation of saddle problems extends Nesterov and Nemirovski's earlier development of conic representable convex problems; DSP can be thought of as extending disciplined convex programming (DCP) to saddle problems. Just as DCP makes it easy for users to formulate and solve complex convex problems, DSP allows users to easily formulate and solve saddle problems. Our method is implemented in an open-source package, also called DSP",
    "checked": true,
    "id": "3e544c28b964c434885dee829b7c83ab3814d0f0",
    "semantic_title": "disciplined saddle programming",
    "citation_count": 6,
    "authors": [
      "Philipp Schiele",
      "Eric Sager Luxenberg",
      "Stephen P. Boyd"
    ]
  },
  "https://openreview.net/forum?id=Sj7bFPeR6W": {
    "title": "Federated Sampling with Langevin Algorithm under Isoperimetry",
    "volume": "main",
    "abstract": "Federated learning uses a set of techniques to efficiently distribute the training of a machine learning algorithm across several devices, who own the training data. These techniques critically rely on reducing the communication cost---the main bottleneck---between the devices and a central server. Federated learning algorithms usually take an optimization approach: they are algorithms for minimizing the training loss subject to communication (and other) constraints. In this work, we instead take a Bayesian approach for the training task, and propose a communication-efficient variant of the Langevin algorithm to sample \\textit{a posteriori}. The latter approach is more robust and provides more knowledge of the \\textit{a posteriori} distribution than its optimization counterpart. We analyze our algorithm without assuming that the target distribution is strongly log-concave. Instead, we assume the weaker log Sobolev inequality, which allows for nonconvexity",
    "checked": true,
    "id": "c76ac22ce1f27098be1ec07e50948c5ec465d259",
    "semantic_title": "federated sampling with langevin algorithm under isoperimetry",
    "citation_count": 2,
    "authors": [
      "Lukang Sun",
      "Adil Salim",
      "Peter RichtÃ¡rik"
    ]
  },
  "https://openreview.net/forum?id=rQqzt4gYcc": {
    "title": "TensorVAE: a simple and efficient generative model for conditional molecular conformation generation",
    "volume": "main",
    "abstract": "Efficient generation of 3D conformations of a molecule from its 2D graph is a key challenge in in-silico drug discovery. Deep learning (DL) based generative modelling has recently become a potent tool to tackling this challenge. However, many existing DL-based methods are either indirectâleveraging inter-atomic distances or directâbut requiring numerous sampling steps to generate conformations. In this work, we propose a simple model abbreviated TensorVAE capable of generating conformations directly from a 2D molecular graph in a single step. The main novelty of the proposed method is focused on feature engineering. We develop a novel encoding and feature extraction mechanism relying solely on standard convolution operation to generate token-like feature vector for each atom. These feature vectors are then transformed through standard transformer encoders under a conditional Variational Autoencoder framework for generating conformations directly. We show through experiments on two benchmark datasets that with intuitive feature engineering, a relatively simple and standard model can provide promising generative capability outperforming more than a dozen state-of-the-art models employing more sophisticated and specialized generative architecture",
    "checked": true,
    "id": "3e16332485dba71d2ee6f0a2b2f1d76225601cb4",
    "semantic_title": "tensorvae: a simple and efficient generative model for conditional molecular conformation generation",
    "citation_count": 1,
    "authors": [
      "Hongyang Yu",
      "Hongjiang Yu"
    ]
  },
  "https://openreview.net/forum?id=qyfz0QrkqP": {
    "title": "PixMIM: Rethinking Pixel Reconstruction in Masked Image Modeling",
    "volume": "main",
    "abstract": "Masked Image Modeling (MIM) has achieved promising progress with the advent of Masked Autoencoders (MAE) and BEiT. However, subsequent works have complicated the framework with new auxiliary tasks or extra pre-trained models, inevitably increasing computational overhead. This paper undertakes a fundamental analysis of MIM from the perspective of pixel reconstruction, which examines the input image patches and reconstruction target, and highlights two critical but previously overlooked bottlenecks. Based on this analysis, we propose a remarkably simple and effective method, PixMIM, that entails two strategies: 1) filtering the high-frequency components from the reconstruction target to de-emphasize the network's focus on texture-rich details and 2) adopting a conservative data transform strategy to alleviate the problem of missing foreground in MIM training. PixMIM can be easily integrated into most existing pixel-based MIM approaches (i.e., using raw images as reconstruction target) with negligible additional computation. Without bells and whistles, our method consistently improves four MIM approaches, MAE, MFF, ConvMAE, and LSMAE, across various downstream tasks. We believe this effective plug-and-play method will serve as a strong baseline for self-supervised learning and provide insights for future improvements of the MIM framework. Code and models will be available",
    "checked": true,
    "id": "0a84577447a81d34aa9363a6790a65eb600f8384",
    "semantic_title": "pixmim: rethinking pixel reconstruction in masked image modeling",
    "citation_count": 29,
    "authors": [
      "Yuan Liu",
      "Songyang Zhang",
      "Jiacheng Chen",
      "Kai Chen",
      "Dahua Lin"
    ]
  },
  "https://openreview.net/forum?id=oGIR0ic3jU": {
    "title": "Bandits Corrupted by Nature: Lower Bounds on Regret and Robust Optimistic Algorithms",
    "volume": "main",
    "abstract": "We study the corrupted bandit problem, i.e. a stochastic multi-armed bandit problem with $k$ unknown reward distributions, which are heavy-tailed and corrupted by a history-independent adversary or Nature. To be specific, the reward obtained by playing an arm comes from corresponding heavy-tailed reward distribution with probability $1-\\varepsilon \\in (0.5,1]$ and an arbitrary corruption distribution of unbounded support with probability $\\varepsilon \\in [0,0.5)$. First, we provide \\textit{a problem-dependent lower bound on the regret} of any corrupted bandit algorithm. The lower bounds indicate that the corrupted bandit problem is harder than the classical stochastic bandit problem with subGaussian or heavy-tail rewards. Following that, we propose a novel UCB-type algorithm for corrupted bandits, namely \\texttt{HubUCB}, that builds on Huber's estimator for robust mean estimation. Leveraging a novel concentration inequality of Huber's estimator, we prove that \\texttt{HubUCB} achieves a near-optimal regret upper bound. Since computing Huber's estimator has quadratic complexity, we further introduce a sequential version of Huber's estimator that exhibits linear complexity. We leverage this sequential estimator to design \\texttt{SeqHubUCB} that enjoys similar regret guarantees while reducing the computational burden. Finally, we experimentally illustrate the efficiency of \\texttt{HubUCB} and \\texttt{SeqHubUCB} in solving corrupted bandits for different reward distributions and different levels of corruptions",
    "checked": false,
    "id": "9f2e889bf4c099b7b26613320f716c43120fd3f4",
    "semantic_title": "bandits corrupted by nature: lower bounds on regret and robust optimistic algorithm",
    "citation_count": 7,
    "authors": [
      "TimothÃ©e Mathieu",
      "Debabrota Basu",
      "Odalric-Ambrym Maillard"
    ]
  },
  "https://openreview.net/forum?id=eTgxr7gPuU": {
    "title": "High-dimensional Bayesian Optimization via Covariance Matrix Adaptation Strategy",
    "volume": "main",
    "abstract": "Bayesian Optimization (BO) is an effective method for finding the global optimum of expensive black-box functions. However, it is well known that applying BO to high-dimensional optimization problems is challenging. To address this issue, a promising solution is to use a local search strategy that partitions the search domain into local regions with high likelihood of containing the global optimum, and then use BO to optimize the objective function within these regions. In this paper, we propose a novel technique for defining the local regions using the Covariance Matrix Adaptation (CMA) strategy. Specifically, we use CMA to learn a search distribution that can estimate the probabilities of data points being the global optimum of the objective function. Based on this search distribution, we then define the local regions consisting of data points with high probabilities of being the global optimum. Our approach serves as a meta-algorithm as it can incorporate existing black-box BO optimizers, such as BO, TuRBO, and BAxUS, to find the global optimum of the objective function within our derived local regions. We evaluate our proposed method on various benchmark synthetic and real-world problems. The results demonstrate that our method outperforms existing state-of-the-art techniques",
    "checked": true,
    "id": "7c1ee8b8c4065b0ae6a81946696b6bc72e1514d7",
    "semantic_title": "high-dimensional bayesian optimization via covariance matrix adaptation strategy",
    "citation_count": 2,
    "authors": [
      "Lam Ngo",
      "Huong Ha",
      "Jeffrey Chan",
      "Vu Nguyen",
      "Hongyu Zhang"
    ]
  },
  "https://openreview.net/forum?id=cvOpIhQQMN": {
    "title": "A general framework for formulating structured variable selection",
    "volume": "main",
    "abstract": "In variable selection, a selection rule that prescribes the permissible sets of selected variables (called a \"selection dictionary\") is desirable due to the inherent structural constraints among the candidate variables. Such selection rules can be complex in real-world data analyses, and failing to incorporate such restrictions could not only compromise the interpretability of the model but also lead to decreased prediction accuracy. However, no general framework has been proposed to formalize selection rules and their applications, which poses a significant challenge for practitioners seeking to integrate these rules into their analyses. In this work, we establish a framework for structured variable selection that can incorporate universal structural constraints. We develop a mathematical language for constructing arbitrary selection rules, where the selection dictionary is formally defined. We demonstrate that all selection rules can be expressed as combinations of operations on constructs, facilitating the identification of the corresponding selection dictionary. We use a detailed and complex example to illustrate the developed framework. Once this selection dictionary is derived, practitioners can apply their own user-defined criteria to select the optimal model. Additionally, our framework enhances existing penalized regression methods for variable selection by providing guidance on how to appropriately group variables to achieve the desired selection rule. Furthermore, our innovative framework opens the door to establishing new $\\ell_0$-based penalized regression techniques that can be tailored to respect arbitrary selection rules, thereby expanding the possibilities for more robust and tailored model development",
    "checked": false,
    "id": "cd2909a3a21914e175712fed7aba185ee111ef70",
    "semantic_title": "constrained shortest-path reformulations via decision diagrams for structured two-stage optimization problems",
    "citation_count": 1,
    "authors": [
      "Guanbo Wang",
      "Mireille Schnitzer",
      "Tom Chen",
      "Rui Wang",
      "Robert W Platt"
    ]
  },
  "https://openreview.net/forum?id=gllUnpYuXg": {
    "title": "Towards fully covariant machine learning",
    "volume": "main",
    "abstract": "Any representation of data involves arbitrary investigator choices. Because those choices are external to the data-generating process, each choice leads to an exact symmetry, corresponding to the group of transformations that takes one possible representation to another. These are the passive symmetries; they include coordinate freedom, gauge symmetry, and units covariance, all of which have led to important results in physics. In machine learning, the most visible passive symmetry is the relabeling or permutation symmetry of graphs. The active symmetries are those that must be established by observation and experiment. They include, for instance, translations invariances or rotation invariances of physical law. These symmetries are the subject of most of the equivariant machine learning literature. Our goal, in this conceptual contribution, is to understand the implications for machine learning of the many passive and active symmetries in play. We discuss dos and don'ts for machine learning practice if passive symmetries are to be respected. We discuss links to causal modeling and argue that the implementation of passive symmetries is particularly valuable when the goal of the learning problem is to generalize out of sample. We conjecture that the implementation of passive symmetries might help machine learning in the same ways that it transformed physics in the twentieth century",
    "checked": true,
    "id": "f6fe532c25cd480a66f097ac1f1f9e53a7a55d26",
    "semantic_title": "towards fully covariant machine learning",
    "citation_count": 11,
    "authors": [
      "Soledad Villar",
      "David W Hogg",
      "Weichi Yao",
      "George A Kevrekidis",
      "Bernhard SchÃ¶lkopf"
    ]
  },
  "https://openreview.net/forum?id=VDy6LgErFM": {
    "title": "Empowering GNNs via Edge-Aware Weisfeiler-Leman Algorithm",
    "volume": "main",
    "abstract": "Message passing graph neural networks (GNNs) are known to have their expressiveness upper-bounded by 1-dimensional Weisfeiler-Leman (1-WL) algorithm. To achieve more powerful GNNs, existing attempts either require \\emph{ad hoc} features, or involve operations that incur high time and space complexities. In this work, we propose a \\textit{general} and \\textit{provably powerful} GNN framework that preserves the \\textit{scalability} of the message passing scheme. In particular, we first propose to empower 1-WL for graph isomorphism test by considering edges among neighbors, giving rise to NC-1-WL. The expressiveness of NC-1-WL is shown to be strictly above 1-WL and below 3-WL theoretically. Further, we propose the NC-GNN framework as a differentiable neural version of NC-1-WL. Our simple implementation of NC-GNN is provably as powerful as NC-1-WL. Experiments demonstrate that our NC-GNN performs effectively and efficiently on various benchmarks",
    "checked": true,
    "id": "5036b6ddd2e19e601cc391b516daab0ba7e63761",
    "semantic_title": "empowering gnns via edge-aware weisfeiler-leman algorithm",
    "citation_count": 1,
    "authors": [
      "Meng Liu",
      "Haiyang Yu",
      "Shuiwang Ji"
    ]
  },
  "https://openreview.net/forum?id=BNP4MxzDEI": {
    "title": "To Transfer or Not to Transfer: Suppressing Concepts from Source Representations",
    "volume": "main",
    "abstract": "With the proliferation of large pre-trained models in various domains, transfer learning has gained prominence where intermediate representations from these models can be leveraged to train better (target) task-specific models, with possibly limited labeled data. Although transfer learning can be beneficial in many applications, it can transfer undesirable information to target tasks that may severely curtail its performance in the target domain or raise ethical concerns related to privacy and/or fairness. In this paper, we propose a novel approach for suppressing the transfer of user-determined semantic concepts (viz. color, glasses, etc.) in intermediate source representations to target tasks without retraining the source model which can otherwise be expensive or even infeasible. Notably, we tackle a bigger challenge in the input data as a given intermediate source representation is biased towards the source task, thus possibly further entangling the desired concepts. We evaluate our approach qualitatively and quantitatively in the visual domain showcasing its efficacy for classification and generative source models. Finally, we provide a concept selection approach that automatically suppresses the undesirable concepts",
    "checked": true,
    "id": "6206021e2c5838be293f31f40dde408433420e0c",
    "semantic_title": "to transfer or not to transfer: suppressing concepts from source representations",
    "citation_count": 0,
    "authors": [
      "Vijay Sadashivaiah",
      "Keerthiram Murugesan",
      "Ronny Luss",
      "Pin-Yu Chen",
      "Chris Sims",
      "James Hendler",
      "Amit Dhurandhar"
    ]
  },
  "https://openreview.net/forum?id=DPvwr4HJdt": {
    "title": "On the Choice of Learning Rate for Local SGD",
    "volume": "main",
    "abstract": "Distributed data-parallel optimization accelerates the training of neural networks, but requires constant synchronization of gradients between the workers, which can become a bottleneck. One way to reduce communication overhead is to use Local SGD, where each worker asynchronously takes multiple local gradient steps, after which the model weights are averaged. In this work, we discuss the choice of learning rate for Local SGD, showing that it faces an intricate trade-off. Unlike in the synchronous case, its gradient estimate is biased, with the bias dependent on the learning rate itself. Thus using learning rate scaling techniques designed for faster convergence in the synchronous case with Local SGD results in a performance degradation as previously observed. To analyze the manifestation of this bias, we study convergence behaviour of Local SGD and synchronous data-parallel SGD when using their optimal learning rates. Our experiments show that the optimal learning rate for Local SGD differs substantially from that of SGD, and when using it the performance of Local SGD matches that of SGD. However, this performance comes at the cost of added training iterations, rendering Local SGD faster than SGD only when communication is much more time-consuming than computation. This suggests that Local SGD may be of limited practical utility",
    "checked": true,
    "id": "0b15ec181efd73af6d73160c6ccddce306dfd7fa",
    "semantic_title": "on the choice of learning rate for local sgd",
    "citation_count": 2,
    "authors": [
      "Lukas Balles",
      "Prabhu Teja S",
      "Cedric Archambeau"
    ]
  },
  "https://openreview.net/forum?id=bfsNmgN5je": {
    "title": "Semantic similarity prediction is better than other semantic similarity measures",
    "volume": "main",
    "abstract": "Semantic similarity between natural language texts is typically measured either by looking at the overlap between subsequences (e.g., BLEU) or by using embeddings (e.g., BERTScore, S-BERT). Within this paper, we argue that when we are only interested in measuring the semantic similarity, it is better to directly predict the similarity using a fine-tuned model for such a task. Using a fine-tuned model for the Semantic Textual Similarity Benchmark tasks (STS-B) from the GLUE benchmark, we define the STSScore approach and show that the resulting similarity is better aligned with our expectations on a robust semantic similarity measure than other approaches",
    "checked": true,
    "id": "96bfa287ace006d6b9fd9a73a84571e6c8cb7908",
    "semantic_title": "semantic similarity prediction is better than other semantic similarity measures",
    "citation_count": 4,
    "authors": [
      "Steffen Herbold"
    ]
  },
  "https://openreview.net/forum?id=R7H43YD6Lo": {
    "title": "Prismer: A Vision-Language Model with Multi-Task Experts",
    "volume": "main",
    "abstract": "Recent vision-language models have shown impressive multi-modal generation capabilities. However, typically they require training huge models on massive datasets. As a more scalable alternative, we introduce Prismer, a data- and parameter-efficient vision-language model that leverages an ensemble of task-specific experts. Prismer only requires training of a small number of components, with the majority of network weights inherited from multiple readily-available, pre-trained experts, and kept frozen during training. By leveraging experts from a wide range of domains, we show Prismer can efficiently pool this expert knowledge and adapt it to various vision-language reasoning tasks. In our experiments, we show that Prismer achieves fine-tuned and few-shot learning performance which is competitive with current state-of-the-arts, whilst requiring up to two orders of magnitude less training data. Code is available at https://github.com/NVlabs/prismer",
    "checked": true,
    "id": "f02d56e630986997e0aea3d92bf53e0f363ce401",
    "semantic_title": "prismer: a vision-language model with multi-task experts",
    "citation_count": 24,
    "authors": [
      "Shikun Liu",
      "Linxi Fan",
      "Edward Johns",
      "Zhiding Yu",
      "Chaowei Xiao",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=4i1MXH8Sle": {
    "title": "CAREER: A Foundation Model for Labor Sequence Data",
    "volume": "main",
    "abstract": "Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences, outperforming econometric baselines on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables. For example, incorporating CAREER into a wage model provides better predictions than the econometric models currently in use",
    "checked": true,
    "id": "6325d9a0bb710687e12241a47d4df0eadc6a6d9d",
    "semantic_title": "career: a foundation model for labor sequence data",
    "citation_count": 6,
    "authors": [
      "Keyon Vafa",
      "Emil Palikot",
      "Tianyu Du",
      "Ayush Kanodia",
      "Susan Athey",
      "David Blei"
    ]
  },
  "https://openreview.net/forum?id=z3ZlnaOM0d": {
    "title": "Hyperspherical Prototype Node Clustering",
    "volume": "main",
    "abstract": "The general workflow of deep node clustering is to encode the nodes into node embeddings via graph neural networks and uncover clustering decisions from them, so clustering performance is heavily affected by the embeddings. However, existing works only consider preserving the semantics of the graph but ignore the inter-cluster separability of the nodes, so there's no guarantee that the embeddings can present a clear clustering structure. To remedy this deficiency, we propose Hyperspherical Prototype Node Clustering (HPNC), an end-to-end clustering paradigm that explicitly enhances the inter-cluster separability of learned node embeddings. Concretely, we constrain the embedding space to a unit-hypersphere, enabling us to scatter the cluster prototypes over the space with maximized pairwise distances. Then, we employ a graph autoencoder to map nodes onto the same hypersphere manifold. Consequently, cluster affinities can be directly retrieved from cosine similarities between node embeddings and prototypes. A clustering-oriented loss is imposed to sharpen the affinity distribution so that the learned node embeddings are encouraged to have small intra-cluster distances and large inter-cluster distances. Based on the proposed HPNC paradigm, we devise two schemes (HPNC-IM and HPNC-DEC) with distinct clustering backbones. Empirical results on popular benchmark datasets demonstrate the superiority of our method compared to other state-of-the-art clustering methods, and visualization results illustrate improved separability of the learned embeddings",
    "checked": true,
    "id": "b6dccff36f94daca36c7455517eff1b1fc317f84",
    "semantic_title": "hyperspherical prototype node clustering",
    "citation_count": 0,
    "authors": [
      "Jitao Lu",
      "Danyang Wu",
      "Feiping Nie",
      "Rong Wang",
      "Xuelong Li"
    ]
  },
  "https://openreview.net/forum?id=rFecyFpFUp": {
    "title": "AdaFed: Fair Federated Learning via Adaptive Common Descent Direction",
    "volume": "main",
    "abstract": "Federated learning (FL) is a promising technology via which some edge devices/clients collaboratively train a machine learning model orchestrated by a server. Learning an unfair model is known as a critical problem in federated learning, where the trained model may unfairly advantage or disadvantage some of the devices. To tackle this problem, in this work, we propose AdaFed. The goal of AdaFed is to find an updating direction for the server along which (i) all the clients' loss functions are decreasing; and (ii) more importantly, the loss functions for the clients with larger values decrease with a higher rate. AdaFed adaptively tunes this common direction based on the values of local gradients and loss functions. We validate the effectiveness of AdaFed on a suite of federated datasets, and demonstrate that AdaFed outperforms state-of-the-art fair FL methods",
    "checked": true,
    "id": "f87c32ce9af0da40a49382810f9f79e679f17b2f",
    "semantic_title": "adafed: fair federated learning via adaptive common descent direction",
    "citation_count": 11,
    "authors": [
      "Shayan Mohajer Hamidi",
      "EN-HUI YANG"
    ]
  },
  "https://openreview.net/forum?id=nzG9KGssSe": {
    "title": "Variational autoencoder with weighted samples for high-dimensional non-parametric adaptive importance sampling",
    "volume": "main",
    "abstract": "Adaptive importance sampling is a well-known family of algorithms for density approximation, generation and Monte Carlo integration including rare event estimation. The main common denominator of this family of algorithms is to perform density estimation with weighted samples at each iteration. However, the classical existing methods to do so, such as kernel smoothing or approximation by a Gaussian distribution, suffer from the curse of dimensionality and/or a lack of flexibility. Both are limitations in high dimension and when we do not have any prior knowledge on the form of the target distribution, such as its number of modes. Variational autoencoders are probabilistic tools able to represent with fidelity high-dimensional data in a lower dimensional space. They constitute a parametric family of distributions robust faced to the dimension and since they are based on deep neural networks, they are flexible enough to be considered as non-parametric models. In this paper, we propose to use a variational autoencoder as the auxiliary importance sampling distribution by extending the existing framework to weighted samples. We integrate the proposed procedure in existing adaptive importance sampling algorithms and we illustrate its practical interest on diverse examples",
    "checked": true,
    "id": "e1a08b6a72895499c5609cee6de40ea4bf9cf281",
    "semantic_title": "variational autoencoder with weighted samples for high-dimensional non-parametric adaptive importance sampling",
    "citation_count": 2,
    "authors": [
      "Julien Demange-Chryst",
      "Francois Bachoc",
      "JÃ©rÃ´me Morio",
      "TimothÃ© Krauth"
    ]
  },
  "https://openreview.net/forum?id=ALRWXT1RLZ": {
    "title": "Separability Analysis for Causal Discovery in Mixture of DAGs",
    "volume": "main",
    "abstract": "Directed acyclic graphs (DAGs) are effective for compactly representing causal systems and specifying the causal relationships among the system's constituents. Specifying such causal relationships in some systems requires a mixture of multiple DAGs -- a single DAG is insufficient. Some examples include time-varying causal systems or aggregated subgroups of a population. Recovering the causal structure of the systems represented by single DAGs is investigated extensively, but it remains mainly open for the systems represented by a mixture of DAGs. A major difference between single- versus mixture-DAG recovery is the existence of node pairs that are separable in the individual DAGs but become inseparable in their mixture. This paper provides the theoretical foundations for analyzing such inseparable node pairs. Specifically, the notion of \\emph{emergent edges} is introduced to represent such inseparable pairs that do not exist in the single DAGs but emerge in their mixtures. Necessary conditions for identifying the emergent edges are established. Operationally, these conditions serve as sufficient conditions for separating a pair of nodes in the mixture of DAGs. These results are further extended, and matching necessary and sufficient conditions for identifying the emergent edges in tree-structured DAGs are established. Finally, a novel graphical representation is formalized to specify these conditions, and an algorithm is provided for inferring the learnable causal relations",
    "checked": true,
    "id": "61523d0574d1cb6e8148edfc9c436a5bdc526ba7",
    "semantic_title": "separability analysis for causal discovery in mixture of dags",
    "citation_count": 2,
    "authors": [
      "Burak Varici",
      "Dmitriy Katz",
      "Dennis Wei",
      "Prasanna Sattigeri",
      "Ali Tajer"
    ]
  },
  "https://openreview.net/forum?id=0CM7Hfsy61": {
    "title": "Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization",
    "volume": "main",
    "abstract": "Bayesian optimization (BO) is widely used to optimize expensive-to-evaluate black-box functions. It first builds a surrogate for the objective and quantifies its uncertainty. It then decides where to sample by maximizing an acquisition function (AF) defined by the surrogate model. However, when dealing with high-dimensional problems, finding the global maximum of the AF becomes increasingly challenging. In such cases, the manner in which the AF maximizer is initialized plays a pivotal role. An inappropriate initialization can severely limit the potential of AF. This paper investigates a largely understudied problem concerning the impact of AF maximizer initialization on exploiting AFs' capability. Our large-scale empirical study shows that the widely used random initialization strategy may fail to harness the potential of an AF. Based on this observation, we propose a better initialization approach by employing multiple heuristic optimizers to leverage the historical data of black-box optimization to generate initial points for an AF maximizer. We evaluate our approach with a variety of heavily studied synthetic test functions and real-world applications. Experimental results show that our techniques, while simple, can significantly enhance the standard BO and outperform state-of-the-art methods by a large margin in most test cases",
    "checked": true,
    "id": "d6600d43daaaeaad75e343a1a4bc8de16e9b0a79",
    "semantic_title": "unleashing the potential of acquisition functions in high-dimensional bayesian optimization",
    "citation_count": 4,
    "authors": [
      "Jiayu Zhao",
      "Renyu Yang",
      "SHENGHAO QIU",
      "Zheng Wang"
    ]
  },
  "https://openreview.net/forum?id=6SofFlwhEv": {
    "title": "On the Adversarial Robustness of Camera-based 3D Object Detection",
    "volume": "main",
    "abstract": "In recent years, camera-based 3D object detection has gained widespread attention for its ability to achieve high performance with low computational cost. However, the robustness of these methods to adversarial attacks has not been thoroughly examined, especially when considering their deployment in safety-critical domains like autonomous driving. In this study, we conduct the first comprehensive investigation of the robustness of leading camera-based 3D object detection approaches under various adversarial conditions. We systematically analyze the resilience of these models under two attack settings: white-box and black-box; focusing on two primary objectives: classification and localization. Additionally, we delve into two types of adversarial attack techniques: pixel-based and patch-based. Our experiments yield four interesting findings: (a) bird's-eye-view-based representations exhibit stronger robustness against localization attacks; (b) depth-estimation-free approaches have the potential to show stronger robustness; (c) accurate depth estimation effectively improves robustness for depth-estimation-based methods; (d) incorporating multi-frame benign inputs can effectively mitigate adversarial attacks. We hope our findings can steer the development of future camera-based object detection models with enhanced adversarial robustness. The code is available at: https://github.com/Daniel-xsy/BEV-Attack",
    "checked": true,
    "id": "c60c9928b4c1dfd259d190a24c338eadb8b4b5fd",
    "semantic_title": "on the adversarial robustness of camera-based 3d object detection",
    "citation_count": 20,
    "authors": [
      "Shaoyuan Xie",
      "Zichao Li",
      "Zeyu Wang",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=txpYITR8oa": {
    "title": "AmbientFlow: Invertible generative models from incomplete, noisy measurements",
    "volume": "main",
    "abstract": "Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of AmbientFlow in learning the object distribution. The utility of AmbientFlow in a downstream inference task of image reconstruction is demonstrated",
    "checked": true,
    "id": "1356a03fcbcbfa9b5a60ccdfbd6310dcbe3ac4c1",
    "semantic_title": "ambientflow: invertible generative models from incomplete, noisy measurements",
    "citation_count": 7,
    "authors": [
      "Varun A. Kelkar",
      "Rucha Deshpande",
      "Arindam Banerjee",
      "Mark Anastasio"
    ]
  },
  "https://openreview.net/forum?id=fovUNTilp9": {
    "title": "Multi-Horizon Representations with Hierarchical Forward Models for Reinforcement Learning",
    "volume": "main",
    "abstract": "Learning control from pixels is difficult for reinforcement learning (RL) agents because representation learning and policy learning are intertwined. Previous approaches remedy this issue with auxiliary representation learning tasks, but they either do not consider the temporal aspect of the problem or only consider single-step transitions, which may cause learning inefficiencies if important environmental changes take many steps to manifest. We propose Hierarchical $k$-Step Latent (HKSL), an auxiliary task that learns multiple representations via a hierarchy of forward models that learn to communicate and an ensemble of $n$-step critics that all operate at varying magnitudes of step skipping. We evaluate HKSL in a suite of 30 robotic control tasks with and without distractors and a task of our creation. We find that HKSL either converges to higher or optimal episodic returns more quickly than several alternative representation learning approaches. Furthermore, we find that HKSL's representations capture task-relevant details accurately across timescales (even in the presence of distractors) and that communication channels between hierarchy levels organize information based on both sides of the communication process, both of which improve sample efficiency",
    "checked": true,
    "id": "50dc64ab218420b121da5c956371b2d35d1a2ae2",
    "semantic_title": "multi-horizon representations with hierarchical forward models for reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Trevor McInroe",
      "Lukas SchÃ¤fer",
      "Stefano V Albrecht"
    ]
  },
  "https://openreview.net/forum?id=aYkYajcJDN": {
    "title": "Neural Task Synthesis for Visual Programming",
    "volume": "main",
    "abstract": "Generative neural models hold great promise in enhancing programming education by synthesizing new content. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visual tasks for these codes. We demonstrate the effectiveness of NeurTaskSyn through an extensive empirical evaluation and a qualitative study on reference tasks taken from the Hour of Code: Classic Maze challenge by Code.org and the Intro to Programming with Karel course by CodeHS.com",
    "checked": true,
    "id": "59a4a5db0a913b99b7afe1c6b2bf6e24f0d31857",
    "semantic_title": "neural task synthesis for visual programming",
    "citation_count": 17,
    "authors": [
      "Victor-Alexandru PÄdurean",
      "Georgios Tzannetos",
      "Adish Singla"
    ]
  },
  "https://openreview.net/forum?id=umggDfMHha": {
    "title": "Federated Classification in Hyperbolic Spaces via Secure Aggregation of Convex Hulls",
    "volume": "main",
    "abstract": "Hierarchical and tree-like data sets arise in many relevant applications, including language processing, graph data mining, phylogeny and genomics. It is known that tree-like data cannot be embedded into Euclidean spaces of finite dimension with small distortion, and that this problem can be mitigated through the use of hyperbolic spaces. When such data also has to be processed in a distributed and privatized setting, it becomes necessary to work with new federated learning methods tailored to hyperbolic spaces. As an initial step towards the development of the field of federated learning in hyperbolic spaces, we propose the first known approach to federated classification in hyperbolic spaces. Our contributions are as follows. First, we develop distributed versions of convex SVM classifiers for Poincar\\'e discs. In this setting, the information conveyed from clients to the global classifier are convex hulls of clusters present in individual client data. Second, to avoid label switching issues, we introduce a number-theoretic approach for label recovery based on the so-called integer $B_h$ sequences. Third, we compute the complexity of the convex hulls in hyperbolic spaces to assess the extent of data leakage; at the same time, in order to limit the communication cost for the hulls, we propose a new quantization method for the Poincar\\'e disc coupled with Reed-Solomon-like encoding. Fourth, at the server level, we introduce a new approach for aggregating convex hulls of the clients based on balanced graph partitioning. We test our method on a collection of diverse data sets, including hierarchical single-cell RNA-seq data from different patients distributed across different repositories that have stringent privacy constraints. The classification accuracy of our method is up to $\\sim11\\%$ better than its Euclidean counterpart, demonstrating the importance of privacy-preserving learning in hyperbolic spaces. Our implementation for the proposed method is available at \\url{https://github.com/sauravpr/hyperbolic_federated_classification}",
    "checked": true,
    "id": "460a12b01476b681528bb693498157795bc9c929",
    "semantic_title": "federated classification in hyperbolic spaces via secure aggregation of convex hulls",
    "citation_count": 2,
    "authors": [
      "Saurav Prakash",
      "Jin Sima",
      "Chao Pan",
      "Eli Chien",
      "Olgica Milenkovic"
    ]
  },
  "https://openreview.net/forum?id=8sg2I9zXgO": {
    "title": "Personalized Algorithmic Recourse with Preference Elicitation",
    "volume": "main",
    "abstract": "Algorithmic Recourse (AR) is the problem of computing a sequence of actions that -- once performed by a user -- overturns an undesirable machine decision. It is paramount that the sequence of actions does not require too much effort for users to implement. Yet, most approaches to AR assume that actions cost the same for all users, and thus may recommend unfairly expensive recourse plans to certain users. Prompted by this observation, we introduce PEAR, the first human-in-the-loop approach capable of providing personalized algorithmic recourse tailored to the needs of any end-user. PEAR builds on insights from Bayesian Preference Elicitation to iteratively refine an estimate of the costs of actions by asking choice set queries to the target user. The queries themselves are computed by maximizing the Expected Utility of Selection, a principled measure of information gain accounting for uncertainty on both the cost estimate and the user's responses. PEAR integrates elicitation into a Reinforcement Learning agent coupled with Monte Carlo Tree Search to quickly identify promising recourse plans. Our empirical evaluation on real-world datasets highlights how PEAR produces high-quality personalized recourse in only a handful of iterations",
    "checked": true,
    "id": "2ae21771e4d66a4835e02bdca0836a4ec5d8e7d4",
    "semantic_title": "personalized algorithmic recourse with preference elicitation",
    "citation_count": 9,
    "authors": [
      "Giovanni De Toni",
      "Paolo Viappiani",
      "Stefano Teso",
      "Bruno Lepri",
      "Andrea Passerini"
    ]
  },
  "https://openreview.net/forum?id=MppUW90uU2": {
    "title": "A Fully Decentralized Surrogate for Multi-Agent Policy Optimization",
    "volume": "main",
    "abstract": "The study of fully decentralized learning or independent learning in cooperative multi-agent reinforcement learning has a history of decades. Recent empirical studies have shown that independent PPO (IPPO) can achieve good performance, comparable to or even better than the methods of centralized training with decentralized execution, in several benchmarks. However, a decentralized actor-critic algorithm with a convergence guarantee is still an open problem. In this paper, we propose decentralized policy optimization (DPO), a decentralized actor-critic algorithm with monotonic improvement and convergence guarantee. We derive a novel decentralized surrogate for policy optimization such that the monotonic improvement of joint policy can be guaranteed by each agent independently optimizing the surrogate. For practical implementation, this decentralized surrogate can be realized by two adaptive coefficients for policy optimization at each agent. Empirically, we evaluate DPO, IPPO, and independent Q-learning (IQL) in a variety of cooperative multi-agent tasks, covering discrete and continuous action spaces, as well as fully and partially observable environments. The results show DPO outperforms both IPPO and IQL in most tasks, which serves as evidence for our theoretical results. The code is available at https://github.com/PKU-RL/DPO",
    "checked": true,
    "id": "7e7fc9a94dbced6707b3679d2f7665c5fa346347",
    "semantic_title": "a fully decentralized surrogate for multi-agent policy optimization",
    "citation_count": 3,
    "authors": [
      "Kefan Su",
      "Zongqing Lu"
    ]
  },
  "https://openreview.net/forum?id=EDqCY6ihbr": {
    "title": "A Globally Convergent Algorithm for Neural Network Parameter Optimization Based on Difference-of-Convex Functions",
    "volume": "main",
    "abstract": "We propose an algorithm for optimizing the parameters of single hidden layer neural networks. Specifically, we derive a blockwise difference-of-convex (DC) functions representation of the objective function. Based on the latter, we propose a block coordinate descent (BCD) approach that we combine with a tailored difference-of-convex functions algorithm (DCA). We prove global convergence of the proposed algorithm. Furthermore, we mathematically analyze the convergence rate of parameters and the convergence rate in value (i.e., the training loss). We give conditions under which our algorithm converges linearly or even faster depending on the local shape of the loss function. We confirm our theoretical derivations numerically and compare our algorithm against state-of-the-art gradient-based solvers in terms of both training loss and test loss",
    "checked": true,
    "id": "484108d2f939be95808d2f5c8a38f1d057b16f4e",
    "semantic_title": "a globally convergent algorithm for neural network parameter optimization based on difference-of-convex functions",
    "citation_count": 0,
    "authors": [
      "Daniel Tschernutter",
      "Mathias Kraus",
      "Stefan Feuerriegel"
    ]
  },
  "https://openreview.net/forum?id=pfbVayaUMc": {
    "title": "Online Reference Tracking For Linear Systems with Unknown Dynamics and Unknown Disturbances",
    "volume": "main",
    "abstract": "This paper presents an online learning mechanism to address the challenge of state tracking for unknown linear systems under general adversarial disturbances. The reference trajectory is assumed to be generated by unknown exosystem dynamics, which relaxes the common assumption of known dynamics for exosystems. Learning a tracking control policy for unknown systems with unknown exosystem dynamics under general disturbances is challenging and surprisingly unsettled. To face this challenge, the presented online learning algorithm has two stages: In the first stage, an algorithm identifies the dynamics of the uncertain system, and in the second stage, an online parametrized memory-augmented controller accounts for the identification error, unknown exosystem dynamics as well as disturbances. The controller's parameters are learned to optimize a general convex cost function, and learning the control parameters is formulated as an online convex optimization problem. This approach uses the memory of previous disturbances and reference values to capture their effects on performance over time. Besides, it implicitly learns the dynamics of the exosystems. The algorithm enables online tuning of controller parameters to achieve state tracking and disturbance rejection while minimizing general convex costs. It is shown that the algorithm achieves a policy regret of $\\mathcal{O}({T}^{\\frac{2}{3}})$. In the simulation results, the performance of the presented tracking algorithm was compared with the certainty equivalent $H_{\\infty}$-control and linear quadratic regulator",
    "checked": true,
    "id": "9a58ccd4f6933f73b43aa2a4c6e4780dc66f97cb",
    "semantic_title": "online reference tracking for linear systems with unknown dynamics and unknown disturbances",
    "citation_count": 5,
    "authors": [
      "Nariman Niknejad",
      "Farnaz Adib Yaghmaie",
      "Hamidreza Modares"
    ]
  },
  "https://openreview.net/forum?id=NYdThkjNW1": {
    "title": "Boomerang: Local sampling on image manifolds using diffusion models",
    "volume": "main",
    "abstract": "The inference stage of diffusion models can be seen as running a reverse-time diffusion stochastic differential equation, where samples from a Gaussian latent distribution are transformed into samples from a target distribution that usually reside on a low-dimensional manifold, e.g., an image manifold. The intermediate values between the initial latent space and the image manifold can be interpreted as noisy images, with the amount of noise determined by the forward diffusion process noise schedule. We utilize this interpretation to present Boomerang, an approach for local sampling of image manifolds exploiting the reverse diffusion process dynamics. As implied by its name, Boomerang local sampling involves adding noise to an input image, moving it closer to the latent space, and then mapping it back to the image manifold through a partial reverse diffusion process. Thus, Boomerang generates images on the manifold that are ``similar,'' but nonidentical, to the original input image. We can control the proximity of the generated images to the original by adjusting the amount of noise added. Furthermore, due to the stochastic nature of the partial reverse diffusion process in Boomerang, the generated images display a certain degree of stochasticity, allowing us to obtain ample local samples from the manifold without encountering any duplicates. Boomerang offers the flexibility to work seamlessly with any pretrained diffusion model, such as Stable Diffusion, without necessitating any adjustments to the reverse diffusion process. We present three applications for local sampling using Boomerang. First, we provide a framework for constructing privacy-preserving datasets having controllable degrees of anonymity. Second, we show that using Boomerang for data augmentation increases generalization performance and outperforms state-of-the-art synthetic data augmentation. Lastly, we introduce a perceptual image enhancement framework powered by Boomerang, which enables resolution enhancement",
    "checked": true,
    "id": "e607c4516c7f2dda67b326ddda8c5afd1b2ff2a9",
    "semantic_title": "boomerang: local sampling on image manifolds using diffusion models",
    "citation_count": 20,
    "authors": [
      "Lorenzo Luzi",
      "Paul M Mayer",
      "Josue Casco-Rodriguez",
      "Ali Siahkoohi",
      "Richard Baraniuk"
    ]
  },
  "https://openreview.net/forum?id=RyZB4qXEgt": {
    "title": "Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures",
    "volume": "main",
    "abstract": "Diagrams matter. Unfortunately, the deep learning community has no standard method for diagramming architectures. The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail. However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances. I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures. Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations. A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve. Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation. In this work, I introduce neural circuit diagrams for an audience of machine learning researchers. After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity. This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer. I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code. Finally, I examine backpropagation using neural circuit diagrams. I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities",
    "checked": true,
    "id": "3be78b45d1cc14a496a7eafdc0e5cfec34cbb030",
    "semantic_title": "neural circuit diagrams: robust diagrams for the communication, implementation, and analysis of deep learning architectures",
    "citation_count": 5,
    "authors": [
      "Vincent Abbott"
    ]
  },
  "https://openreview.net/forum?id=YRKS2J0x36": {
    "title": "DyG2Vec: Efficient Representation Learning for Dynamic Graphs",
    "volume": "main",
    "abstract": "Temporal graph neural networks have shown promising results in learning inductive representations by automatically extracting temporal patterns. However, previous works often rely on complex memory modules or inefficient random walk methods to construct temporal representations. To address these limitations, we present an efficient yet effective attention-based encoder that leverages temporal edge encodings and window-based subgraph sampling to generate task-agnostic embeddings. Moreover, we propose a joint-embedding architecture using non-contrastive SSL to learn rich temporal embeddings without labels. Experimental results on 7 benchmark datasets indicate that on average, our model outperforms SoTA baselines on the future link prediction task by 4.23% for the transductive setting and 3.30% for the inductive setting while only requiring 5-10x less training/inference time. Lastly, different aspects of the proposed framework are investigated through experimental analysis and ablation studies. The code is publicly available at https://github.com/huawei-noah/noah-research/tree/master/graph_atlas",
    "checked": true,
    "id": "07fdc2b9c97b371b83a7596d488b0735c78400a0",
    "semantic_title": "dyg2vec: efficient representation learning for dynamic graphs",
    "citation_count": 3,
    "authors": [
      "Mohammad Alomrani",
      "Mahdi Biparva",
      "Yingxue Zhang",
      "Mark Coates"
    ]
  },
  "https://openreview.net/forum?id=nYjSkOy8ij": {
    "title": "A Survey on Out-of-Distribution Detection in NLP",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics",
    "checked": true,
    "id": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
    "semantic_title": "a survey on out-of-distribution detection in nlp",
    "citation_count": 25,
    "authors": [
      "Hao Lang",
      "Yinhe Zheng",
      "Yixuan Li",
      "Jian SUN",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "https://openreview.net/forum?id=vyRBsqj5iG": {
    "title": "Proximal Mean Field Learning in Shallow Neural Networks",
    "volume": "main",
    "abstract": "We propose a custom learning algorithm for shallow over-parameterized neural networks, i.e., networks with single hidden layer having infinite width. The infinite width of the hidden layer serves as an abstraction for the over-parameterization. Building on the recent mean field interpretations of learning dynamics in shallow neural networks, we realize mean field learning as a computational algorithm, rather than as an analytical tool. Specifically, we design a Sinkhorn regularized proximal algorithm to approximate the distributional flow for the learning dynamics over weighted point clouds. In this setting, a contractive fixed point recursion computes the time-varying weights, numerically realizing the interacting Wasserstein gradient flow of the parameter distribution supported over the neuronal ensemble. An appealing aspect of the proposed algorithm is that the measure-valued recursions allow meshless computation. We demonstrate the proposed computational framework of interacting weighted particle evolution on binary and multi-class classification. Our algorithm performs gradient descent of the free energy associated with the risk functional",
    "checked": true,
    "id": "be4c0c6d3590401ea41a0eca481beb9ea20b22c1",
    "semantic_title": "proximal mean field learning in shallow neural networks",
    "citation_count": 1,
    "authors": [
      "Alexis Teter",
      "Iman Nodozi",
      "Abhishek Halder"
    ]
  },
  "https://openreview.net/forum?id=42BKnT2qW3": {
    "title": "Synaptic Interaction Penalty: Appropriate Penalty Term for Energy-Efficient Spiking Neural Networks",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) are energy-efficient neural networks because of their spiking nature. However, as the spike firing rate of SNNs increases, the energy consumption does as well, and thus, the advantage of SNNs diminishes. Here, we tackle this problem by introducing a novel penalty term for the spiking activity into the objective function in the training phase. Our method is designed so as to optimize the energy consumption metric directly without modifying the network architecture. Therefore, the proposed method can reduce the energy consumption more than other methods while maintaining the accuracy. We conducted experiments for image classification tasks, and the results indicate the effectiveness of the proposed method, which mitigates the dilemma of the energy--accuracy trade-off",
    "checked": true,
    "id": "94a680ceb5f106b41b3d0f10369ae06c44bcf6be",
    "semantic_title": "synaptic interaction penalty: appropriate penalty term for energy-efficient spiking neural networks",
    "citation_count": 2,
    "authors": [
      "Kazuma Suetake",
      "Takuya Ushimaru",
      "Ryuji Saiin",
      "Yoshihide Sawada"
    ]
  },
  "https://openreview.net/forum?id=n8fZ6mY6PB": {
    "title": "Exploring Format Consistency for Instruction Tuning",
    "volume": "main",
    "abstract": "Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. In this work, a framework named Unified Instruction Tuning (UIT) is proposed, which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets such as PromptSource, FLAN and CrossFit. With the framework, we (1) demonstrate the necessity of maintaining format consistency in instruction tuning; (2) improve the generalization performance on unseen instructions on T5-LM-xl; (3) provide a novel perplexity-based denoising method to reduce the noise of automatic format transfer to make the UIT framework more practical and a smaller offline model based on GPT-J that achieves comparable format transfer capability to OpenAI APIs to reduce costs in practice. Further analysis regarding variations of targeted formats and other effects is intended. The code and trained models will soon be available",
    "checked": true,
    "id": "46ac88bb0acbf736840ff8a392cec2bf43d917e1",
    "semantic_title": "exploring format consistency for instruction tuning",
    "citation_count": 13,
    "authors": [
      "Shihao Liang",
      "Runchu Tian",
      "Kunlun Zhu",
      "Yujia Qin",
      "Huadong Wang",
      "Xin Cong",
      "Zhiyuan Liu",
      "Xiaojiang Liu",
      "Maosong Sun"
    ]
  },
  "https://openreview.net/forum?id=EWv9XGOpB3": {
    "title": "Variational Classification: A Probabilistic Generalization of the Softmax Classifier",
    "volume": "main",
    "abstract": "We present a latent variable model for classification that provides a novel probabilistic interpretation of neural network softmax classifiers. We derive a variational objective to train the model, analogous to the evidence lower bound (ELBO) used to train variational auto-encoders, that generalises the cross-entropy loss used to train classification models. Treating inputs to the softmax layer as samples of a latent variable, our abstracted perspective reveals a potential inconsistency between their anticipated distribution, required for accurate label predictions to be output, and the empirical distribution found in practice. We augment the variational objective to mitigate such inconsistency and encourage a chosen latent distribution, instead of the implicit assumption in off-the-shelf softmax classifiers. Overall, we provide new theoretical insight into the inner workings of widely-used softmax classification. Empirical evaluation on image and text classification datasets demonstrates that our proposed approach, variational classification, maintains classification accuracy while the reshaped latent space improves other desirable properties of a classifier, such as calibration, adversarial robustness, robustness to distribution shift and sample efficiency useful in low data settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shehzaad Zuzar Dhuliawala",
      "Mrinmaya Sachan",
      "Carl Allen"
    ]
  },
  "https://openreview.net/forum?id=K85nJ60lDR": {
    "title": "Regularized Proportional Fairness Mechanism for Resource Allocation Without Money",
    "volume": "featured",
    "abstract": "Mechanism design in resource allocation studies dividing limited resources among self-interested agents whose satisfaction with the allocation depends on privately held utilities. We consider the problem in a payment-free setting, with the aim of maximizing social welfare while enforcing incentive compatibility (IC), i.e., agents cannot inflate allocations by misreporting their utilities. The well-known proportional fairness (PF) mechanism achieves the maximum possible social welfare but incurs an undesirably high exploitability (the maximum unilateral inflation in utility from misreport and a measure of deviation from IC). In fact, it is known that no mechanism can achieve the maximum social welfare and exact incentive compatibility (IC) simultaneously without the use of monetary incentives (Cole et al., 2013). Motivated by this fact, we propose learning an approximate mechanism that desirably trades off the competing objectives. Our main contribution is to design an innovative neural network architecture tailored to the resource allocation problem, which we name Regularized Proportional Fairness Network (RPF-Net). RPF-Net regularizes the output of the PF mechanism by a learned function approximator of the most exploitable allocation, with the aim of reducing the incentive for any agent to misreport. We derive generalization bounds that guarantee the mechanism performance when trained under finite and out-of-distribution samples and experimentally demonstrate the merits of the proposed mechanism compared to the state-of-the-art. The PF mechanism acts as an important benchmark for comparing the social welfare of any mechanism. However, there exists no established way of computing its exploitability. The challenge here is that we need to find the maximizer of an optimization problem for which the gradient is only implicitly defined. We for the first time provide a systematic method for finding such (sub)gradients, which enables the evaluation of the exploitability of the PF mechanism through iterative (sub)gradient ascent",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihan Zeng",
      "Sujay Bhatt",
      "Alec Koppel",
      "Sumitra Ganesh"
    ]
  },
  "https://openreview.net/forum?id=HZi9PfLwMn": {
    "title": "BBCaL: Black-box Backdoor Detection under the Causality Lens",
    "volume": "featured",
    "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks, where attackers can inject hidden backdoors during the training stage. This poses a serious threat to the Model-as-a-Service setting, where downstream users directly utilize third-party models (e.g., HuggingFace Hub, ChatGPT). To this end, we study the inference-stage black-box backdoor detection problem in the paper, where defenders aim to build a firewall to filter out the backdoor inputs in the inference stage, with only input samples and prediction labels available. Existing investigations on this problem either rely on strong assumptions on types of triggers and attacks or suffer from poor efficiency. To build a more generalized and efficient method, we first provide a novel causality-based lens to analyze heterogeneous prediction behaviors for clean and backdoored samples in the inference stage, considering both sample-specific and sample-agnostic backdoor attacks. Motivated by the causal analysis and do-calculus in causal inference, we introduce Black-box Backdoor detection under the Causality Lens (BBCaL) which distinguishes backdoor and clean samples by analyzing prediction consistency after progressively constructing counterfactual samples. Theoretical analysis also sheds light on the effectiveness of the BBCaL. Extensive experiments on three benchmark datasets validate the effectiveness and efficiency of our method",
    "checked": true,
    "id": "9148355997d70b23c1061e457f7bd580f69468f8",
    "semantic_title": "bbcal: black-box backdoor detection under the causality lens",
    "citation_count": 0,
    "authors": [
      "Mengxuan Hu",
      "Zihan Guan",
      "Junfeng Guo",
      "Zhongliang Zhou",
      "Jielu Zhang",
      "Sheng Li"
    ]
  },
  "https://openreview.net/forum?id=KZRnDZ70M2": {
    "title": "Non-Stationary Dueling Bandits Under a Weighted Borda Criterion",
    "volume": "featured",
    "abstract": "In $K$-armed dueling bandits, the learner receives preference feedback between arms, and the regret of an arm is defined in terms of its suboptimality to a winner arm. The non-stationary variant of the problem, motivated by concerns of changing user preferences, has received recent interest (Saha and Gupta, 2022; Buening and Saha, 2023; Suk and Agarwal, 2023). The goal here is to design algorithms with low dynamic regret, ideally without foreknowledge of the amount of change. The notion of regret here is tied to a notion of winner arm, most typically taken to be a so-called Condorcet winner or a Borda winner. However, the aforementioned results mostly focus on the Condorcet winner. In comparison, the Borda version of this problem has received less attention which is the focus of this work. We establish the first optimal and adaptive dynamic regret upper bound $\\tilde{O}(\\tilde{L}^{1/3} K^{1/3} T^{2/3})$, where $\\tilde{L}$ is the unknown number of significant Borda winner switches. We also introduce a novel weighted Borda score framework which generalizes both the Borda and Condorcet problems. This framework surprisingly allows a Borda-style regret analysis of the Condorcet problem and establishes improved bounds over the theoretical state-of-art in regimes with a large number of arms or many spurious changes in Condorcet winner. Such a generalization was not known and could be of independent interest",
    "checked": true,
    "id": "819c580b6c935475d19b7728393cc28166adedab",
    "semantic_title": "non-stationary dueling bandits under a weighted borda criterion",
    "citation_count": 1,
    "authors": [
      "Joe Suk",
      "Arpit Agarwal"
    ]
  },
  "https://openreview.net/forum?id=NYe2JuN3v3": {
    "title": "MaskBit: Embedding-free Image Generation via Bit Tokens",
    "volume": "reprod",
    "abstract": "Masked transformer models for class-conditional image generation have become a compelling alternative to diffusion models. Typically comprising two stages - an initial VQGAN model for transitioning between latent space and image space, and a subsequent Transformer model for image generation within latent space - these frameworks offer promising avenues for image synthesis. In this study, we present two primary contributions: Firstly, an empirical and systematic examination of VQGANs, leading to a modernized VQGAN. Secondly, a novel embedding-free generation network operating directly on bit tokens - a binary quantized representation of tokens with rich semantics. The first contribution furnishes a transparent, reproducible, and high-performing VQGAN model, enhancing accessibility and matching the performance of current state-of-the-art methods while revealing previously undisclosed details. The second contribution demonstrates that embedding-free image generation using bit tokens achieves a new state-of-the-art FID of 1.52 on the ImageNet $256\\times256$ benchmark, with a compact generator model of mere 305M parameters. The code for this project is available on https://github.com/markweberdev/maskbit",
    "checked": true,
    "id": "86e606832d8a5bb7ee04040d983a71eceffab440",
    "semantic_title": "maskbit: embedding-free image generation via bit tokens",
    "citation_count": 40,
    "authors": [
      "Mark Weber",
      "Lijun Yu",
      "Qihang Yu",
      "Xueqing Deng",
      "Xiaohui Shen",
      "Daniel Cremers",
      "Liang-Chieh Chen"
    ]
  },
  "https://openreview.net/forum?id=pRvhMSV48t": {
    "title": "Training LLMs over Neurally Compressed Text",
    "volume": "featured",
    "abstract": "In this paper, we explore the idea of training large language models (LLMs) over highly compressed text. While standard subword tokenizers compress text by a small factor, neural text compressors can achieve much higher rates of compression. If it were possible to train LLMs directly over neurally compressed text, this would confer advantages in training and serving efficiency, as well as easier handling of long text spans. The main obstacle to this goal is that strong compression tends to produce opaque outputs that are not well-suited for learning. In particular, we find that text naÃ¯vely compressed via Arithmetic Coding is not readily learnable by LLMs. To overcome this, we propose Equal-Info Windows, a novel compression technique whereby text is segmented into blocks that each compress to the same bit length. Using this method, we demonstrate effective learning over neurally compressed text that improves with scale, and outperforms byte-level baselines by a wide margin on perplexity and inference speed benchmarks. While our method delivers worse perplexity than subword tokenizers for models trained with the same parameter count, it has the benefit of shorter sequence lengths. Shorter sequence lengths require fewer autoregressive generation steps, often reducing latency. Finally, we provide extensive analysis of the properties that contribute to learnability, and offer concrete suggestions for how to further improve the performance of high-compression tokenizers",
    "checked": true,
    "id": "e27c9c39ecb67e8e7708d8d53bec2f891cfa7a40",
    "semantic_title": "training llms over neurally compressed text",
    "citation_count": 7,
    "authors": [
      "Brian Lester",
      "Jaehoon Lee",
      "Alexander A Alemi",
      "Jeffrey Pennington",
      "Adam Roberts",
      "Jascha Sohl-Dickstein",
      "Noah Constant"
    ]
  },
  "https://openreview.net/forum?id=g12Gdl6aDL": {
    "title": "Improving Text-to-Image Consistency via Automatic Prompt Optimization",
    "volume": "featured",
    "abstract": "Impressive advances in text-to-image (T2I) generative models have yielded a plethora of high performing models which are able to generate aesthetically appealing, photorealistic images. Despite the progress, these models still struggle to produce images that are consistent with the input prompt, oftentimes failing to capture object quantities, relations and attributes properly. Existing solutions to improve prompt-image consistency suffer from the following challenges: (1) they oftentimes require model fine-tuning, (2) they only focus on nearby prompt samples, and (3) they are affected by unfavorable trade-offs among image quality, representation diversity, and prompt-image consistency. In this paper, we address these challenges and introduce a T2I optimization-by-prompting framework, OPT2I, which leverages a large language model (LLM) to improve prompt-image consistency in T2I models. Our framework starts from a user prompt and iteratively generates revised prompts with the goal of maximizing a consistency score. Our extensive validation on two datasets, MSCOCO and PartiPrompts, shows that OPT2I can boost the initial consistency score by up to 24.9% in terms of DSG score while preserving the FID and increasing the recall between generated and real data. Our work paves the way toward building more reliable and robust T2I systems by harnessing the power of LLMs",
    "checked": true,
    "id": "4777305738fd1aa30243f96a1687d57d8f70fa5d",
    "semantic_title": "improving text-to-image consistency via automatic prompt optimization",
    "citation_count": 36,
    "authors": [
      "Oscar MaÃ±as",
      "Pietro Astolfi",
      "Melissa Hall",
      "Candace Ross",
      "Jack Urbanek",
      "Adina Williams",
      "Aishwarya Agrawal",
      "Adriana Romero-Soriano",
      "Michal Drozdzal"
    ]
  },
  "https://openreview.net/forum?id=X59U5CHnfr": {
    "title": "Hessian Free Efficient Single Loop Iterative Differentiation Methods for Bi-Level Optimization Problems",
    "volume": "featured",
    "abstract": "Bilevel optimization problems have been actively studied in recent machine learning research due to their broad applications. In this work, we investigate single-loop methods with iterative differentiation (ITD) for nonconvex bilevel optimization problems. For deterministic bilevel problems, we propose an efficient single-loop ITD-type method (ES-ITDM). Our method employs historical updates to approximate the hypergradient. More importantly, based on ES-ITDM, we propose a new method that avoids computing Hessians. This Hessian-free method requires fewer backpropagations and thus has a lower computational cost. We analyze the convergence properties of the proposed methods in two aspects. We provide the convergence rates of the sequences generated by ES-ITD based on the Kurdyka-\\L ojasiewicz (KL) property. We also show that the Hessian-free stochastic ES-ITDM has the best-known complexity while has cheaper computation. The empirical studies show that our Hessian-free stochastic variant is more efficient than existing Hessian-free methods and other state-of-the-art bilevel optimization approaches",
    "checked": true,
    "id": "f196d509ec820a53d0647cd14dde9ad8ebbb2b17",
    "semantic_title": "hessian free efficient single loop iterative differentiation methods for bi-level optimization problems",
    "citation_count": 0,
    "authors": [
      "Peiran Yu",
      "Junyi Li",
      "Heng Huang"
    ]
  },
  "https://openreview.net/forum?id=VOGlTb27ob": {
    "title": "Multi-Accurate CATE is Robust to Unknown Covariate Shifts",
    "volume": "featured",
    "abstract": "Estimating heterogeneous treatment effects is important to tailor treatments to those individuals who would most likely benefit. However, conditional average treatment effect predictors may often be trained on one population but possibly deployed on different, possibly unknown populations. We use methodology for learning multi-accurate predictors to post-process CATE T-learners (differenced regressions) to become robust to unknown covariate shifts at the time of deployment. The method works in general for pseudo-outcome regression, such as the DR-learner. We show how this approach can combine (large) confounded observational and (smaller) randomized datasets by learning a confounded predictor from the observational dataset, and auditing for multi-accuracy on the randomized controlled trial. We show improvements in bias and mean squared error in simulations with increasingly larger covariate shift, and on a semi-synthetic case study of a parallel large observational study and smaller randomized controlled experiment. Overall, we establish a connection between methods developed for multi-distribution learning and achieve appealing desiderata (e.g. external validity) in causal inference and machine learning",
    "checked": true,
    "id": "1eeb2a0f7fac3cb8ccf973b64ff6a20fa2cc0bf3",
    "semantic_title": "multi-accurate cate is robust to unknown covariate shifts",
    "citation_count": 0,
    "authors": [
      "Christoph Kern",
      "Michael P. Kim",
      "Angela Zhou"
    ]
  },
  "https://openreview.net/forum?id=z116TO4LDT": {
    "title": "Reward Guided Latent Consistency Distillation",
    "volume": "featured",
    "abstract": "Latent Consistency Distillation (LCD) has emerged as a promising paradigm for efficient text-to-image synthesis. By distilling a latent consistency model (LCM) from a pre-trained teacher latent diffusion model (LDM), LCD facilitates the generation of high-fidelity images within merely 2 to 4 inference steps. However, the LCM's efficient inference is obtained at the cost of the sample quality. In this paper, we propose compensating the quality loss by aligning LCM's output with human preference during training. Specifically, we introduce Reward Guided LCD (RG-LCD), which integrates feedback from a reward model (RM) into the LCD process by augmenting the original LCD loss with the objective of maximizing the reward associated with LCM's single-step generation. As validated through human evaluation, when trained with the feedback of a good RM, the 2-step generations from our RG-LCM are favored by humans over the 50-step DDIM samples from the teacher LDM, representing a 25-time inference acceleration without quality loss. As directly optimizing towards differentiable RMs can suffer from over-optimization, we take the initial step to overcome this difficulty by proposing the use of a latent proxy RM (LRM). This novel component serves as an intermediary, connecting our LCM with the RM. Empirically, we demonstrate that incorporating the LRM into our RG-LCD successfully avoids high-frequency noise in the generated images, contributing to both improved FrÃ©chet Inception Distance (FID) on MS-COCO and a higher HPSv2.1 score on HPSv2's test set, surpassing those achieved by the baseline LCM. Project Page: https://rg-lcd.github.io/",
    "checked": true,
    "id": "df9ad7a8e603760a8e2ffe8b4571e8871fc09916",
    "semantic_title": "reward guided latent consistency distillation",
    "citation_count": 15,
    "authors": [
      "Jiachen Li",
      "Weixi Feng",
      "Wenhu Chen",
      "William Yang Wang"
    ]
  },
  "https://openreview.net/forum?id=xBORyL316c": {
    "title": "Data Valuation in the Absence of a Reliable Validation Set",
    "volume": "featured",
    "abstract": "Data valuation plays a pivotal role in ensuring data quality and equitably compensating data contributors. Existing game-theoretic data valuation techniques mostly rely on the availability of a high-quality validation set for their efficacy. However, the feasibility of obtaining a clean validation set drawn from the test distribution may be limited in practice. In this work, we show that the choice of validation set can significantly impact the final data value scores. In order to mitigate this, we introduce a general paradigm that converts a traditional validation-based game-theoretic data valuation method into a validation-free alternative. Specifically, we utilize the cross-validation error as a surrogate for to evaluate the model's performance on a validation set. As computing the cross-validation error can be computationally expensive, we propose using the cross-validation error of a kernel regression model as an effective and efficient surrogate for the true performance score on the population. We compare the performance of the validation-free variant of existing data valuation techniques with their original validation-based counterparts. Our results indicate that the validation-free variants generally match or often significantly surpass the performance of their validation-based counterparts",
    "checked": true,
    "id": "d7dab6e098af35f00c6a80ffd9c5b61f855723b7",
    "semantic_title": "data valuation in the absence of a reliable validation set",
    "citation_count": 1,
    "authors": [
      "Himanshu Jahagirdar",
      "Jiachen T. Wang",
      "Ruoxi Jia"
    ]
  },
  "https://openreview.net/forum?id=4unJi0qrTE": {
    "title": "Tweedie Moment Projected Diffusions for Inverse Problems",
    "volume": "featured",
    "abstract": "Diffusion generative models unlock new possibilities for inverse problems as they allow for the incorporation of strong empirical priors into the process of scientific inference. Recently, diffusion models are repurposed for solving inverse problems using Gaussian approximations to conditional densities of the reverse process via Tweedie's formula to parameterise the mean, complemented with various heuristics. To address various challenges arising from these approximations, we leverage higher order information using Tweedie's formula and obtain a statistically principled approximation. We further provide a theoretical guarantee specifically for posterior sampling which can lead to better theoretical understanding of diffusion-based conditional sampling. Finally, we illustrate the empirical effectiveness of our approach for general linear inverse problems on toy synthetic examples as well as image restoration. We show that our method (i) removes any time-dependent step-size hyperparameters required by earlier methods, (ii) brings stability and better sample quality across multiple noise levels, (iii) is the only method that works in a stable way with variance exploding (VE) forward processes as opposed to earlier works",
    "checked": true,
    "id": "c51cd38054318d5a79cb060f80575f78ffc7bd1e",
    "semantic_title": "tweedie moment projected diffusions for inverse problems",
    "citation_count": 33,
    "authors": [
      "Benjamin Boys",
      "Mark Girolami",
      "Jakiw Pidstrigach",
      "Sebastian Reich",
      "Alan Mosca",
      "Omer Deniz Akyildiz"
    ]
  },
  "https://openreview.net/forum?id=7DAFwp0Vne": {
    "title": "Equivariant Graph Network Approximations of High-Degree Polynomials for Force Field Prediction",
    "volume": "featured",
    "abstract": "Recent advancements in equivariant deep models have shown promise in accurately predicting atomic potentials and force fields in molecular dynamics simulations. Using spherical harmonics (SH) and tensor products (TP), these equivariant networks gain enhanced physical understanding, like symmetries and many-body interactions. Beyond encoding physical insights, SH and TP are also crucial to represent equivariant polynomial functions. In this work, we analyze the equivariant polynomial functions for the equivariant architecture, and introduce a novel equivariant network, named PACE. The proposed PACE utilizes edge booster and the Atomic Cluster Expansion (ACE) technique to approximate a greater number of $SE(3) \\times S_n$ equivariant polynomial functions with enhanced degrees. As experimented in commonly used benchmarks, PACE demonstrates state-of-the-art performance in predicting atomic energy and force fields, with robust generalization capability across various geometric distributions under molecular dynamics (MD) across different temperature conditions. Our code is publicly available as part of the AIRS library \\url{https://github.com/divelab/AIRS/}",
    "checked": true,
    "id": "99fd08812389de5253515bc51bd0568deefdbdf8",
    "semantic_title": "equivariant graph network approximations of high-degree polynomials for force field prediction",
    "citation_count": 2,
    "authors": [
      "Zhao Xu",
      "Haiyang Yu",
      "Montgomery Bohde",
      "Shuiwang Ji"
    ]
  },
  "https://openreview.net/forum?id=mqoxLkX210": {
    "title": "Causal Reasoning and Large Language Models: Opening a New Frontier for Causality",
    "volume": "featured",
    "abstract": "The causal capabilities of large language models (LLMs) are a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We conduct a \"behavorial\" study of LLMs to benchmark their capability in generating causal arguments. Across a wide range of tasks, we find that LLMs can generate text corresponding to correct causal arguments with high probability, surpassing the best-performing existing methods. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain) and event causality (86% accuracy in determining necessary and sufficient causes in vignettes). We perform robustness checks across tasks and show that the capabilities cannot be explained by dataset memorization alone, especially since LLMs generalize to novel datasets that were created after the training cutoff date. That said, LLMs exhibit unpredictable failure modes and we discuss the kinds of errors that may be improved and what are the fundamental limits of LLM-based answers. Overall, by operating on the text metadata, LLMs bring capabilities so far understood to be restricted to humans, such as using collected knowledge to generate causal graphs or identifying background causal context from natural language. As a result, LLMs may be used by human domain experts to save effort in setting up a causal analysis, one of the biggest impediments to the widespread adoption of causal methods. Given that LLMs ignore the actual data, our results also point to a fruitful research direction of developing algorithms that combine LLMs with existing causal techniques. Code and datasets are available at https://github.com/py-why/pywhy-llm",
    "checked": true,
    "id": "10632e0a667cbc3c52cc8f11a46d8e8e9c7739e3",
    "semantic_title": "causal reasoning and large language models: opening a new frontier for causality",
    "citation_count": 283,
    "authors": [
      "Emre Kiciman",
      "Robert Ness",
      "Amit Sharma",
      "Chenhao Tan"
    ]
  },
  "https://openreview.net/forum?id=aloEru2qCG": {
    "title": "LoRA Learns Less and Forgets Less",
    "volume": "featured",
    "abstract": "Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning method for large language models. LoRA saves memory by training only low rank perturbations to selected weight matrices. In this work, we compare the performance of LoRA and full finetuning on two target domains, programming and mathematics. We consider both the instruction finetuning ($\\approx$100K prompt-response pairs) and continued pretraining ($\\approx$20B unstructured tokens) data regimes. Our results show that, in the standard low-rank settings, LoRA substantially underperforms full finetuning. Nevertheless, LoRA better maintains the base model's performance on tasks outside the target domain. We show that LoRA mitigates forgetting more than common regularization techniques such as weight decay and dropout; it also helps maintain more diverse generations. Finally, we show that full finetuning learns perturbations with a rank that is 10-100$\\times$ greater than typical LoRA configurations, possibly explaining some of the reported gaps. We conclude by proposing best practices for finetuning with LoRA",
    "checked": true,
    "id": "be12e6806e9190c3954cb34af7a6923b65cfedba",
    "semantic_title": "lora learns less and forgets less",
    "citation_count": 141,
    "authors": [
      "Dan Biderman",
      "Jacob Portes",
      "Jose Javier Gonzalez Ortiz",
      "Mansheej Paul",
      "Philip Greengard",
      "Connor Jennings",
      "Daniel King",
      "Sam Havens",
      "Vitaliy Chiley",
      "Jonathan Frankle",
      "Cody Blakeney",
      "John Patrick Cunningham"
    ]
  },
  "https://openreview.net/forum?id=QaCCuDfBk2": {
    "title": "Revisiting Feature Prediction for Learning Visual Representations from Video",
    "volume": "featured",
    "abstract": "This paper explores feature prediction as a stand-alone objective for unsupervised learning from video and introduces V-JEPA, a collection of vision models trained solely using a feature prediction objective, without the use of pretrained image encoders, text, negative examples, reconstruction, or other sources of supervision. The models are trained on 2 million videos collected from public datasets and are evaluated on downstream image and video tasks. Our results show that learning by predicting video features leads to versatile visual representations that perform well on both motion and appearance-based tasks, without adaption of the model's parameters; e.g., using a frozen backbone. Our largest model, a ViT-H/16 trained only on videos, obtains 81.9% on Kinetics-400, 72.2% on Something-Something-v2, and 77.9% on ImageNet1K",
    "checked": true,
    "id": "872d78c04c8fb115d492eea98199407991670533",
    "semantic_title": "revisiting feature prediction for learning visual representations from video",
    "citation_count": 87,
    "authors": [
      "Adrien Bardes",
      "Quentin Garrido",
      "Jean Ponce",
      "Xinlei Chen",
      "Michael Rabbat",
      "Yann LeCun",
      "Mido Assran",
      "Nicolas Ballas"
    ]
  },
  "https://openreview.net/forum?id=cT8oOJ6Q6F": {
    "title": "Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building",
    "volume": "featured",
    "abstract": "Animals and robots navigate through environments by building and refining maps of space. These maps enable functions including navigation back to home, planning, search and foraging. Here, we use observations from neuroscience, specifically the observed fragmentation of grid cell map in compartmentalized spaces, to propose and apply the concept of Fragmentation-and-Recall (FARMap) in the mapping of large spaces. Agents solve the mapping problem by building local maps via a surprisal-based clustering of space, which they use to set subgoals for spatial exploration. Agents build and use a local map to predict their observations; high surprisal leads to a \"fragmentation event\" that truncates the local map. At these events, the recent local map is placed into long-term memory (LTM) and a different local map is initialized. If observations at a fracture point match observations in one of the stored local maps, that map is recalled (and thus reused) from LTM. The fragmentation points induce a natural online clustering of the larger space, forming a set of intrinsic potential subgoals that are stored in LTM as a topological graph. Agents choose their next subgoal from the set of near and far potential subgoals from within the current local map or LTM, respectively. Thus, local maps guide exploration locally, while LTM promotes global exploration. We demonstrate that FARMap replicates the fragmentation points observed in animal studies. We evaluate FARMap on complex procedurally-generated spatial environments and realistic simulations to demonstrate that this mapping strategy much more rapidly covers the environment (number of agent steps and wall clock time) and is more efficient in active memory usage, without loss of performance",
    "checked": true,
    "id": "ebf08ce4732eff603f6b05e3191277ff418d6562",
    "semantic_title": "grid cell-inspired fragmentation and recall for efficient map building",
    "citation_count": 2,
    "authors": [
      "Jaedong Hwang",
      "Zhang-Wei Hong",
      "Eric R Chen",
      "Akhilan Boopathy",
      "Pulkit Agrawal",
      "Ila R Fiete"
    ]
  },
  "https://openreview.net/forum?id=kfhoeZCeW7": {
    "title": "Fine-tuning can cripple your foundation model; preserving features may be the solution",
    "volume": "featured",
    "abstract": "Pre-trained foundation models, due to their enormous capacity and exposure to vast amounts of data during pre-training, are known to have learned plenty of real-world concepts. An important step in making these pre-trained models effective on downstream tasks is to fine-tune them on related datasets. While various fine-tuning methods have been devised and have been shown to be highly effective, we observe that a fine-tuned model's ability to recognize concepts on tasks different from the downstream one is reduced significantly compared to its pre-trained counterpart. This is an undesirable effect of fine-tuning as a substantial amount of resources was used to learn these pre-trained concepts in the first place. We call this phenomenon \"concept forgetting'' and via experiments show that most end-to-end fine-tuning approaches suffer heavily from this side effect. To this end, we propose a simple fix to this problem by designing a new fine-tuning method called LDIFS (short for $\\ell_2$ distance in feature space) that, while learning new concepts related to the downstream task, allows a model to preserve its pre-trained knowledge as well. Through extensive experiments on 10 fine-tuning tasks we show that LDIFS significantly reduces concept forgetting. Additionally, we show that LDIFS is highly effective in performing continual fine-tuning on a sequence of tasks as well, in comparison with both fine-tuning as well as continual learning baselines",
    "checked": true,
    "id": "76c03e6eeaab71f18e7ed5548ca6bf5962ae16c0",
    "semantic_title": "fine-tuning can cripple your foundation model; preserving features may be the solution",
    "citation_count": 47,
    "authors": [
      "Jishnu Mukhoti",
      "Yarin Gal",
      "Philip Torr",
      "Puneet K. Dokania"
    ]
  },
  "https://openreview.net/forum?id=lQBsLfAWhj": {
    "title": "Layerwise complexity-matched learning yields an improved model of cortical area V2",
    "volume": "featured",
    "abstract": "Human ability to recognize complex visual patterns arises through transformations performed by successive areas in the ventral visual cortex. Deep neural networks trained endto-end for object recognition approach human capabilities, and offer the best descriptions to date of neural responses in the late stages of the hierarchy. But these networks provide a poor account of the early stages, compared to traditional hand-engineered models, or models optimized for coding efficiency or prediction. Moreover, the gradient backpropagation used in end-to-end learning is generally considered to be biologically implausible. Here, we overcome both of these limitations by developing a bottom-up self-supervised training methodology that operates independently on successive layers. Specifically, we maximize feature similarity between pairs of locally-deformed natural image patches, while decorrelating features across patches sampled from other images. Crucially, the deformation amplitudes are adjusted proportionally to receptive field sizes in each layer, thus matching the task complexity to the capacity at each stage of processing. In comparison with architecturematched versions of previous models, we demonstrate that our layerwise complexity-matched learning (LCL) formulation produces a two-stage model (LCL-V2) that is better aligned with selectivity properties and neural activity in primate area V2. We demonstrate that the complexity-matched learning paradigm is responsible for much of the emergence of the improved biological alignment. Finally, when the two-stage model is used as a fixed front end for a deep network trained to perform object recognition, the resultant model (LCL-V2Net) is significantly better than standard end-to-end self-supervised, supervised, and adversarially-trained models in terms of generalization to out-of-distribution tasks and alignment with human behavior. Our code and pre-trained checkpoints are available at https://github.com/nikparth/LCL-V2.git",
    "checked": true,
    "id": "92fd10cfa008285120e910c62a40ee11ef4de199",
    "semantic_title": "layerwise complexity-matched learning yields an improved model of cortical area v2",
    "citation_count": 1,
    "authors": [
      "Nikhil Parthasarathy",
      "Olivier J Henaff",
      "Eero P Simoncelli"
    ]
  },
  "https://openreview.net/forum?id=10YJTIsVYq": {
    "title": "Gradient Scarcity in Graph Learning with Bilevel Optimization",
    "volume": "featured",
    "abstract": "Gradient scarcity emerges when learning graphs by minimizing a loss on a subset of nodes under the semi-supervised setting. It consists in edges between unlabeled nodes that are far from the labeled ones receiving zero gradients. The phenomenon was first described when jointly optimizing the graph and the parameters of a shallow Graph Neural Network (GNN) using a single loss function. In this work, we give a precise mathematical characterization of this phenomenon, and prove that it also emerges in bilevel optimization. While for GNNs gradient scarcity occurs due to their finite receptive field, we show that it also occurs with the Laplacian regularization as gradients decrease exponentially in amplitude with distance to labeled nodes, despite the infinite receptive field of this model. We study several solutions to this issue including latent graph learning using a Graph-to-Graph model (G2G), graph regularization to impose a prior structure on the graph, and reducing the graph diameter by optimizing for a larger set of edges. Our empirical results validate our analysis and show that this issue also occurs with the Approximate Personalized Propagation of Neural Predictions (APPNP), which approximates a model of infinite receptive field",
    "checked": true,
    "id": "dfb3f0041fa606d69658f1a37598da925f428834",
    "semantic_title": "gradient scarcity in graph learning with bilevel optimization",
    "citation_count": 0,
    "authors": [
      "Hashem Ghanem",
      "Samuel Vaiter",
      "Nicolas Keriven"
    ]
  },
  "https://openreview.net/forum?id=1Yp6xpTV55": {
    "title": "Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments",
    "volume": "featured",
    "abstract": "As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of POMDPs under a uniform controlled filter stability (which does not require the knowledge of the model), and (iv) for multi-agent models where convergence of learning dynamics to a new class of equilibria, subjective Q-learning equilibria, will be studied. In addition to the convergence theorem, some implications of the theorem above are new to the literature and others are interpreted as applications of the convergence theorem. Some open problems are noted",
    "checked": true,
    "id": "03f753b36e3ee75dbb3e323acd4c977c96c44fd8",
    "semantic_title": "q-learning for stochastic control under general information structures and non-markovian environments",
    "citation_count": 10,
    "authors": [
      "Ali Devran Kara",
      "Serdar Yuksel"
    ]
  },
  "https://openreview.net/forum?id=agT8ojoH0X": {
    "title": "Self-Improvement for Neural Combinatorial Optimization: Sample Without Replacement, but Improvement",
    "volume": "featured",
    "abstract": "Current methods for end-to-end constructive neural combinatorial optimization usually train a policy using behavior cloning from expert solutions or policy gradient methods from reinforcement learning. While behavior cloning is straightforward, it requires expensive expert solutions, and policy gradient methods are often computationally demanding and complex to fine-tune. In this work, we bridge the two and simplify the training process by sampling multiple solutions for random instances using the current model in each epoch and then selecting the best solution as an expert trajectory for supervised imitation learning. To achieve progressively improving solutions with minimal sampling, we introduce a method that combines round-wise Stochastic Beam Search with an update strategy derived from a provable policy improvement. This strategy refines the policy between rounds by utilizing the advantage of the sampled sequences with almost no computational overhead. We evaluate our approach on the Traveling Salesman Problem and the Capacitated Vehicle Routing Problem. The models trained with our method achieve comparable performance and generalization to those trained with expert data. Additionally, we apply our method to the Job Shop Scheduling Problem using a transformer-based architecture and outperform existing state-of-the-art methods by a wide margin",
    "checked": true,
    "id": "3e1fe99c76a3264f2c56e15c033e708982268db1",
    "semantic_title": "self-improvement for neural combinatorial optimization: sample without replacement, but improvement",
    "citation_count": 12,
    "authors": [
      "Jonathan Pirnay",
      "Dominik G. Grimm"
    ]
  },
  "https://openreview.net/forum?id=CrpDwMFgxr": {
    "title": "Linear Bandits with Memory",
    "volume": "featured",
    "abstract": "Nonstationary phenomena, such as satiation effects in recommendations, have mostly been modeled using bandits with finitely many arms. However, the richer action space provided by linear bandits is often preferred in practice. In this work, we introduce a novel nonstationary linear bandit model, where current rewards are influenced by the learner's past actions in a fixed-size window. Our model, which recovers stationary linear bandits as a special case, leverages two parameters: the window size $m \\ge 0$, and an exponent $\\gamma$ that captures the rotting ($\\gamma < 0)$ or rising ($\\gamma > 0$) nature of the phenomenon. When both $m$ and $\\gamma$ are known, we propose and analyze a variant of OFUL which minimizes regret against cyclic policies. By choosing the cycle length so as to trade-off approximation and estimation errors, we then prove a bound of order $\\sqrt{d}\\,(m+1)^{\\frac{1}{2}+\\max\\{\\gamma,0\\}}\\,T^{3/4}$ (ignoring log factors) on the regret against the optimal sequence of actions, where $T$ is the horizon and $d$ is the dimension of the linear action space. Through a bandit model selection approach, our results are then extended to the case where both $m$ and $\\gamma$ are unknown. Finally, we complement our theoretical results with experiments comparing our approach to natural baselines",
    "checked": false,
    "id": "95747b752ddbece07d5108519ed0c51f36e5d9a0",
    "semantic_title": "linear bandits with memory: from rotting to rising",
    "citation_count": 3,
    "authors": [
      "Giulia Clerici",
      "Pierre Laforgue",
      "NicolÃ² Cesa-Bianchi"
    ]
  },
  "https://openreview.net/forum?id=wczqrpOrIc": {
    "title": "LeanVec: Searching vectors faster by making them fit",
    "volume": "featured",
    "abstract": "Modern deep learning models have the ability to generate high-dimensional vectors whose similarity reflects semantic resemblance. Thus, similarity search, i.e., the operation of retrieving those vectors in a large collection that are similar to a given query, has become a critical component of a wide range of applications that demand highly accurate and timely answers. In this setting, the high vector dimensionality puts similarity search systems under compute and memory pressure, leading to subpar performance. Additionally, cross-modal retrieval tasks have become increasingly common, e.g., where a user inputs a text query to find the most relevant images for that query. However, these queries often have different distributions than the database embeddings, making it challenging to achieve high accuracy. In this work, we present LeanVec, a framework that combines linear dimensionality reduction with vector quantization to accelerate similarity search on high-dimensional vectors while maintaining accuracy. We present LeanVec variants for in-distribution (ID) and out-of-distribution (OOD) queries. LeanVec-ID yields accuracies on par with those from recently introduced deep learning alternatives whose computational overhead precludes their usage in practice. LeanVec-OOD uses a novel technique for dimensionality reduction that considers the query and database distributions to simultaneously boost the accuracy and the performance of the framework even further (even presenting competitive results when the query and database distributions match). All in all, our extensive and varied experimental results show that LeanVec produces state-of-the-art results, with up to 3.7x improvement in search throughput and up to 4.9x faster index build time over the state of the art",
    "checked": true,
    "id": "972aef1670e0c2eebac43f6d1c8678417588fa33",
    "semantic_title": "leanvec: searching vectors faster by making them fit",
    "citation_count": 2,
    "authors": [
      "Mariano Tepper",
      "Ishwar Singh Bhati",
      "Cecilia Aguerrebere",
      "Mark Hildebrand",
      "Theodore L. Willke"
    ]
  },
  "https://openreview.net/forum?id=7I199lc54z": {
    "title": "Soft Merging of Experts with Adaptive Routing",
    "volume": "featured",
    "abstract": "Neural networks that learn to route their inputs through different \"expert\" subnetworks provide a form of modularity that standard dense models lack. Despite their possible benefits, modular models with learned routing often underperform their parameter-matched dense counterparts as well as models that use non-learned heuristic routing strategies. In this paper, we hypothesize that these shortcomings stem from the gradient estimation techniques used to train modular models that use non-differentiable discrete routing decisions. To address this issue, we introduce $\\textbf{S}$oft $\\textbf{M}$erging of $\\textbf{E}$xperts with $\\textbf{A}$daptive $\\textbf{R}$outing (SMEAR), which avoids discrete routing by using a single \"merged\" expert constructed via a weighted average of all of the experts' parameters. By routing activations through a single merged expert, SMEAR does not incur a significant increase in computational costs and enables standard gradient-based training. We empirically validate that models using SMEAR outperform models that route based on metadata or learn routing through gradient estimation. Furthermore, we provide qualitative analysis demonstrating that the experts learned via SMEAR exhibit a significant amount of specialization",
    "checked": true,
    "id": "7a816dd242c4c3f652a448dba54daa53f89a9e4f",
    "semantic_title": "soft merging of experts with adaptive routing",
    "citation_count": 54,
    "authors": [
      "Mohammed Muqeeth",
      "Haokun Liu",
      "Colin Raffel"
    ]
  },
  "https://openreview.net/forum?id=H7gLN5nqVF": {
    "title": "Deep Generalized Prediction Set Classifier and Its Theoretical Guarantees",
    "volume": "featured",
    "abstract": "A standard classification rule returns a single-valued prediction for any observation without a confidence guarantee, which may result in severe consequences in many critical applications when the uncertainty is high. In contrast, set-valued classification is a new paradigm to handle the uncertainty in classification by reporting a set of plausible labels to observations in highly ambiguous regions. In this article, we propose the Deep Generalized Prediction Set (DeepGPS) method, a network-based set-valued classifier induced by acceptance region learning. DeepGPS is capable of identifying ambiguous observations and detecting out-of-distribution (OOD) observations. It is the first set-valued classification of this kind with a theoretical guarantee and scalable to large datasets. Our nontrivial proof shows that the risk of DeepGPS, defined as the expected size of the prediction set, attains the optimality within a neural network hypothesis class while simultaneously achieving the user-prescribed class-specific accuracy. Additionally, by using a weighted loss, DeepGPS returns tighter acceptance regions, leading to informative predictions and improved OOD detection performance. Empirically, our method outperforms the baselines on several benchmark datasets",
    "checked": true,
    "id": "2aa4c5526adfaec8890e0cbf917b1f841db81c0c",
    "semantic_title": "deep generalized prediction set classifier and its theoretical guarantees",
    "citation_count": 1,
    "authors": [
      "Zhou Wang",
      "Xingye Qiao"
    ]
  },
  "https://openreview.net/forum?id=xRy1YRcHWj": {
    "title": "As large as it gets â Studying Infinitely Large Convolutions via Neural Implicit Frequency Filters",
    "volume": "featured",
    "abstract": "Recent work in neural networks for image classification has seen a strong tendency towards increasing the spatial context during encoding. Whether achieved through large convolution kernels or self-attention, models scale poorly with the increased spatial context, such that the improved model accuracy often comes at significant costs. In this paper, we propose a module for studying the effective filter size of convolutional neural networks (CNNs). To facilitate such a study, several challenges need to be addressed: (i) we need an effective means to train models with large filters (potentially as large as the input data) without increasing the number of learnable parameters, (ii) the employed convolution operation should be a plug-and-play module that can replace conventional convolutions in a CNN and allow for an efficient implementation in current frameworks, (iii) the study of filter sizes has to be decoupled from other aspects such as the network width or the number of learnable parameters, and (iv) the cost of the convolution operation itself has to remain manageable i.e.~we can not naÃ¯vely increase the size of the convolution kernel. To address these challenges, we propose to learn the frequency representations of filter weights as neural implicit functions, such that the better scalability of the convolution in the frequency domain can be leveraged. Additionally, due to the implementation of the proposed neural implicit function, even large and expressive spatial filters can be parameterized by only a few learnable weights. Interestingly, our analysis shows that, although the proposed networks could learn very large convolution kernels, the learned filters are well localized and relatively small in practice when transformed from the frequency to the spatial domain. We anticipate that our analysis of individually optimized filter sizes will allow for more efficient, yet effective, models in the future. Our code is available at https://github.com/GeJulia/NIFF",
    "checked": false,
    "id": "78fbdad00b2864e8dfd37abfae6e2cd3d811d050",
    "semantic_title": "as large as it gets - studying infinitely large convolutions via neural implicit frequency filters",
    "citation_count": 7,
    "authors": [
      "Julia Grabinski",
      "Janis Keuper",
      "Margret Keuper"
    ]
  },
  "https://openreview.net/forum?id=iulMde3dP1": {
    "title": "What Has Been Overlooked in Contrastive Source-Free Domain Adaptation: Leveraging Source-Informed Latent Augmentation within Neighborhood Context",
    "volume": "featured",
    "abstract": "Source-free domain adaptation (SFDA) involves adapting a model originally trained using a labeled dataset (source domain) to perform effectively on an unlabeled dataset (target domain) without relying on any source data during adaptation. This adaptation is especially crucial when significant disparities in data distributions exist between the two domains and when there are privacy concerns regarding the source model's training data. The absence of access to source data during adaptation makes it challenging to analytically estimate the domain gap. To tackle this issue, various techniques have been proposed, such as unsupervised clustering, contrastive learning, and continual learning. In this paper, we first conduct an extensive theoretical analysis of SFDA based on contrastive learning, primarily because it has demonstrated superior performance compared to other techniques. Motivated by the obtained insights, we then introduce a straightforward yet highly effective latent augmentation method tailored for contrastive SFDA. This augmentation method leverages the dispersion of latent features within the neighborhood of the query sample, guided by the source pre-trained model, to enhance the informativeness of positive keys. Our approach, based on a single InfoNCE-based contrastive loss, outperforms state-of-the-art SFDA methods on widely recognized benchmark datasets",
    "checked": true,
    "id": "dbb2912bbfef37eb5249fb059d55309f15877290",
    "semantic_title": "what has been overlooked in contrastive source-free domain adaptation: leveraging source-informed latent augmentation within neighborhood context",
    "citation_count": 1,
    "authors": [
      "Jing Wang",
      "Wonho Bae",
      "Jiahong Chen",
      "Kuangen Zhang",
      "Leonid Sigal",
      "Clarence W. de Silva"
    ]
  },
  "https://openreview.net/forum?id=Gh0cxhbz3c": {
    "title": "On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization",
    "volume": "featured",
    "abstract": "Adaptive gradient methods are workhorses in deep learning. However, the convergence guarantees of adaptive gradient methods for nonconvex optimization have not been thoroughly studied. In this paper, we provide a fine-grained convergence analysis for a general class of adaptive gradient methods including AMSGrad, RMSProp and AdaGrad. For smooth nonconvex functions, we prove that adaptive gradient methods in expectation converge to a first-order stationary point. Our convergence rate is better than existing results for adaptive gradient methods in terms of dimension. In addition, we also prove high probability bounds on the convergence rates of AMSGrad, RMSProp as well as AdaGrad, which have not been established before. Our analyses shed light on better understanding the mechanism behind adaptive gradient methods in optimizing nonconvex objectives",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongruo Zhou",
      "Jinghui Chen",
      "Yuan Cao",
      "Ziyan Yang",
      "Quanquan Gu"
    ]
  },
  "https://openreview.net/forum?id=hFALpTb4fR": {
    "title": "LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models",
    "volume": "featured",
    "abstract": "Recent advancements in text-to-image diffusion models have yielded impressive results in generating realistic and diverse images. However, these models still struggle with complex prompts, such as those that involve numeracy and spatial reasoning. This work proposes to enhance prompt understanding capabilities in diffusion models. Our method leverages a pretrained large language model (LLM) for grounded generation in a novel two-stage process. In the first stage, the LLM generates a scene layout that comprises captioned bounding boxes from a given prompt describing the desired image. In the second stage, a novel controller guides an off-the-shelf diffusion model for layout-grounded image generation. Both stages utilize existing pretrained models without additional model parameter optimization. Our method significantly outperforms the base diffusion model and several strong baselines in accurately generating images according to prompts that require various capabilities, doubling the generation accuracy across four tasks on average. Furthermore, our method enables instruction-based multi-round scene specification and can handle prompts in languages not supported by the underlying diffusion model. We anticipate that our method will unleash users' creativity by accurately following more complex prompts. Our code, demo, and benchmark are available at: https://llm-grounded-diffusion.github.io",
    "checked": true,
    "id": "e9ae0c76a71b8f302eb17b1c4462b9cc97d87cd0",
    "semantic_title": "llm-grounded diffusion: enhancing prompt understanding of text-to-image diffusion models with large language models",
    "citation_count": 163,
    "authors": [
      "Long Lian",
      "Boyi Li",
      "Adam Yala",
      "Trevor Darrell"
    ]
  },
  "https://openreview.net/forum?id=r9p9CV52MV": {
    "title": "ModuLoRA: Finetuning 2-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers",
    "volume": "featured",
    "abstract": "We propose a memory-efficient finetuning algorithm for large language models (LLMs) that supports finetuning LLMs with 65B parameters in 2/3/4-bit precision on as little as one 24GB GPU. Our method, modular low-rank adaptation (ModuLoRA), integrates any user-specified weight quantizer with finetuning via low-rank adapters (LoRAs). Our approach relies on a simple quantization-agnostic backward pass that adaptively materializes low-precision LLM weights from a custom black-box quantization module. This approach enables finetuning 2-bit and 3-bit LLMs for the first time---leveraging state-of-the-art 2-bit QuIP# quantization and 3-bit OPTQ quantization---outperforming finetuning that relies on less sophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains competitive performance on text classification, natural language infernece, and instruction following tasks using significantly less memory than existing approaches, and we also surpass the state-of-the-art ROUGE score on a popular summarization task. We release ModuLoRA together with a series of low-precision models as part of LLMTOOLS, a user-friendly library for quantizing, running, and finetuning LLMs on consumer GPUs",
    "checked": true,
    "id": "e3314e18032898b33a2e2b067a45ae4cb02e1a95",
    "semantic_title": "modulora: finetuning 2-bit llms on consumer gpus by integrating with modular quantizers",
    "citation_count": 5,
    "authors": [
      "Junjie Yin",
      "Jiahao Dong",
      "Yingheng Wang",
      "Christopher De Sa",
      "Volodymyr Kuleshov"
    ]
  },
  "https://openreview.net/forum?id=NmpjDHWIvg": {
    "title": "Wasserstein Distributionally Robust Policy Evaluation and Learning for Contextual Bandits",
    "volume": "featured",
    "abstract": "Off-policy evaluation and learning are concerned with assessing a given policy and learning an optimal policy from offline data without direct interaction with the environment. Often, the environment in which the data are collected differs from the environment in which the learned policy is applied. To account for the effect of different environments during learning and execution, distributionally robust optimization (DRO) methods have been developed that compute worst-case bounds on the policy values assuming that the distribution of the new environment lies within an uncertainty set. Typically, this uncertainty set is defined based on the KL divergence around the empirical distribution computed from the logging dataset. However, the KL uncertainty set fails to encompass distributions with varying support and lacks awareness of the geometry of the distribution support. As a result, KL approaches fall short in addressing practical environment mismatches and lead to over-fitting to worst-case scenarios. To overcome these limitations, we propose a novel DRO approach that employs the Wasserstein distance instead. While Wasserstein DRO is generally computationally more expensive compared to KL DRO, we present a regularized method and a practical (biased) stochastic gradient descent method to optimize the policy efficiently. We also provide a theoretical analysis of the finite sample complexity and iteration complexity for our proposed method. We further validate our approach using a public dataset that was recorded in a randomized stoke trial",
    "checked": true,
    "id": "96c77909fd7ee5bb27213ddf4309475873f8a958",
    "semantic_title": "wasserstein distributionally robust policy evaluation and learning for contextual bandits",
    "citation_count": 5,
    "authors": [
      "Yi Shen",
      "Pan Xu",
      "Michael Zavlanos"
    ]
  },
  "https://openreview.net/forum?id=a68SUt6zFt": {
    "title": "DINOv2: Learning Robust Visual Features without Supervision",
    "volume": "featured",
    "abstract": "The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP on most of the benchmarks at image and pixel levels",
    "checked": true,
    "id": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891",
    "semantic_title": "dinov2: learning robust visual features without supervision",
    "citation_count": 3513,
    "authors": [
      "Maxime Oquab",
      "TimothÃ©e Darcet",
      "ThÃ©o Moutakanni",
      "Huy V. Vo",
      "Marc Szafraniec",
      "Vasil Khalidov",
      "Pierre Fernandez",
      "Daniel HAZIZA",
      "Francisco Massa",
      "Alaaeldin El-Nouby",
      "Mido Assran",
      "Nicolas Ballas",
      "Wojciech Galuba",
      "Russell Howes",
      "Po-Yao Huang",
      "Shang-Wen Li",
      "Ishan Misra",
      "Michael Rabbat",
      "Vasu Sharma",
      "Gabriel Synnaeve",
      "Hu Xu",
      "Herve Jegou",
      "Julien Mairal",
      "Patrick Labatut",
      "Armand Joulin",
      "Piotr Bojanowski"
    ]
  },
  "https://openreview.net/forum?id=TQfQUksaC8": {
    "title": "Pathologies of Predictive Diversity in Deep Ensembles",
    "volume": "featured",
    "abstract": "Classic results establish that encouraging predictive diversity improves performance in ensembles of low-capacity models, e.g. through bagging or boosting. Here we demonstrate that these intuitions do not apply to high-capacity neural network ensembles (deep ensembles), and in fact the opposite is often true. In a large scale study of nearly 600 neural network classification ensembles, we examine a variety of interventions that trade off component model performance for predictive diversity. While such interventions can improve the performance of small neural network ensembles (in line with standard intuitions), they harm the performance of the large neural network ensembles most often used in practice. Surprisingly, we also find that discouraging predictive diversity is often benign in large-network ensembles, fully inverting standard intuitions. Even when diversity-promoting interventions do not sacrifice component model performance (e.g. using heterogeneous architectures and training paradigms), we observe an opportunity cost associated with pursuing increased predictive diversity. Examining over 1000 ensembles, we observe that the performance benefits of diverse architectures/training procedures are easily dwarfed by the benefits of simply using higher-capacity models, despite the fact that such higher capacity models often yield significantly less predictive diversity. Overall, our findings demonstrate that standard intuitions around predictive diversity, originally developed for low-capacity ensembles, do not directly apply to modern high-capacity deep ensembles. This work clarifies fundamental challenges to the goal of improving deep ensembles by making them more diverse, while suggesting an alternative path: simply forming ensembles from ever more powerful (and less diverse) component models",
    "checked": true,
    "id": "20113225d61a160bdab4ad2228a2918e41232e29",
    "semantic_title": "pathologies of predictive diversity in deep ensembles",
    "citation_count": 14,
    "authors": [
      "Taiga Abe",
      "E. Kelly Buchanan",
      "Geoff Pleiss",
      "John Patrick Cunningham"
    ]
  },
  "https://openreview.net/forum?id=FDt2UGM1Nz": {
    "title": "DIG In: Evaluating Disparities in Image Generations with Indicators for Geographic Diversity",
    "volume": "featured",
    "abstract": "The unprecedented photorealistic results achieved by recent text-to-image generative systems and their increasing use as plug-and-play content creation solutions make it crucial to understand their potential biases. In this work, we introduce three indicators to evaluate the realism, diversity and prompt-generation consistency of text-to-image generative systems when prompted to generate objects from across the world. Our indicators complement qualitative analysis of the broader impact of such systems by enabling automatic and efficient benchmarking of geographic disparities, an important step towards building responsible visual content creation systems. We use our proposed indicators to analyze potential geographic biases in state-of-the-art visual content creation systems and find that: (1) models have less realism and diversity of generations when prompting for Africa and West Asia than Europe, (2) prompting with geographic information comes at a cost to prompt-consistency and diversity of generated images, and (3) models exhibit more region-level disparities for some objects than others. Perhaps most interestingly, our indicators suggest that progress in image generation quality has come at the cost of real-world geographic representation. Our comprehensive evaluation constitutes a crucial step towards ensuring a positive experience of visual content creation for everyone. Code is available at https://github.com/facebookresearch/DIG-In/",
    "checked": true,
    "id": "a00537a398ce1cacf3b6835a9817ade535d2dae2",
    "semantic_title": "dig in: evaluating disparities in image generations with indicators for geographic diversity",
    "citation_count": 7,
    "authors": [
      "Melissa Hall",
      "Candace Ross",
      "Adina Williams",
      "Nicolas Carion",
      "Michal Drozdzal",
      "Adriana Romero-Soriano"
    ]
  },
  "https://openreview.net/forum?id=NLoaLyuUUF": {
    "title": "Reconciling Kaplan and Chinchilla Scaling Laws",
    "volume": "reprod",
    "abstract": "Kaplan and Chinchilla studied the scaling behavior of transformers trained on next-token language prediction. These studies produced different estimates for how the number of parameters ($N$) and training tokens ($D$) should be set to achieve the lowest possible loss for a given compute budget ($C$). Kaplan: $N_\\text{optimal} \\propto C^{0.73}$, Chinchilla: $N_\\text{optimal} \\propto C^{0.50}$. This paper finds that much of this discrepancy can be attributed to Kaplan counting non-embedding rather than total parameters, combined with their analysis being performed at small scale. Simulating the Chinchilla study under these conditions produces biased scaling coefficients close to Kaplan's. Hence, this paper reaffirms Chinchilla's scaling coefficients, by explaining the primary cause of Kaplan's original overestimation. As a second contribution, the paper explains differences in the reported relationships between loss and compute. These findings lead us to recommend that future scaling studies use total parameters and compute",
    "checked": true,
    "id": "df6227869dd72951c9c46f02cd65f6b588f129ab",
    "semantic_title": "reconciling kaplan and chinchilla scaling laws",
    "citation_count": 8,
    "authors": [
      "Tim Pearce",
      "Jinyeop Song"
    ]
  },
  "https://openreview.net/forum?id=RFrJCkw2oa": {
    "title": "AnyV2V: A Tuning-Free Framework For Any Video-to-Video Editing Tasks",
    "volume": "reprod",
    "abstract": "In the dynamic field of digital content creation using generative models, state-of-the-art video editing models still do not offer the level of quality and control that users desire. Previous works on video editing either extended from image-based generative models in a zero-shot manner or necessitated extensive fine-tuning, which can hinder the production of fluid video edits. Furthermore, these methods frequently rely on textual input as the editing guidance, leading to ambiguities and limiting the types of edits they can perform. Recognizing these challenges, we introduce AnyV2V, a novel tuning-free paradigm designed to simplify video editing into two primary steps: (1) employing an off-the-shelf image editing model to modify the first frame, (2) utilizing an existing image-to-video generation model to generate the edited video through temporal feature injection. AnyV2V can leverage any existing image editing tools to support an extensive array of video editing tasks, including prompt-based editing, reference-based style transfer, subject-driven editing, and identity manipulation, which were unattainable by previous methods. AnyV2V can also support any video length. Our evaluation shows that AnyV2V achieved CLIP Scores comparable to other baseline methods. Furthermore, AnyV2V significantly outperformed these baselines in human evaluations, demonstrating notable improvements in visual consistency with the source video while producing high-quality edits across all editing tasks",
    "checked": true,
    "id": "8e489ab4bcc959a12f0bcacf2975cba9a6395561",
    "semantic_title": "anyv2v: a tuning-free framework for any video-to-video editing tasks",
    "citation_count": 29,
    "authors": [
      "Max Ku",
      "Cong Wei",
      "Weiming Ren",
      "Huan Yang",
      "Wenhu Chen"
    ]
  },
  "https://openreview.net/forum?id=CtEGxIqtud": {
    "title": "Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research",
    "volume": "reprod",
    "abstract": "Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. In order to do this, we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. The objective of this study is to try and identify hidden effects that influence model performance. To this end, we employ the aforementioned ontology to control for a broad selection of sources and turn our attention to another critical challenge in machine learning. The curse of dimensionality, which induces complication in data collection, representation, and analysis, makes it harder to find representative data and impedes the training and inference processes. The closely linked concept of geometric intrinsic dimension is employed to investigate the extent to which the machine learning models under consideration are influenced by the intrinsic dimension of the data sets on which they are trained",
    "checked": true,
    "id": "66023a26f513d211f3d1550a685802a17b4d9f88",
    "semantic_title": "reproducibility and geometric intrinsic dimensionality: an investigation on graph neural network research",
    "citation_count": 0,
    "authors": [
      "Tobias Hille",
      "Maximilian Stubbemann",
      "Tom Hanika"
    ]
  },
  "https://openreview.net/forum?id=DOWSP7y2cu": {
    "title": "Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds",
    "volume": "reprod",
    "abstract": "Protecting privacy during inference with deep neural networks is possible by adding Gaussian noise to the activations in the last layers prior to the final classifiers or other task-specific layers. The activations in such layers are known as \"features\" (or, less commonly, as \"embeddings\" or \"feature embeddings\"). The added noise helps prevent reconstruction of the inputs from the noisy features. Lower bounding the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising from such added noise. Convenient, computationally tractable bounds are available from classic inequalities of Hammersley and of Chapman and Robbins -- the HCR bounds. Numerical experiments indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the data sets, \"MNIST\" and \"CIFAR-10,\" which contain 10 classes each for image classification. The HCR bounds appear to be insufficient on their own to guarantee confidentiality of the inputs to inference with standard deep neural nets, \"ResNet-18\" and \"Swin-T,\" pre-trained on the data set, \"ImageNet-1000,\" which contains 1000 classes. Supplementing the addition of Gaussian noise to features with other methods for providing confidentiality may be warranted in the case of ImageNet. In all cases, the results reported here limit consideration to amounts of added noise that incur little degradation in the accuracy of classification from the noisy features. Thus, the added noise enhances confidentiality without much reduction in the accuracy on the task of image classification",
    "checked": true,
    "id": "8ea871e149cd74db6009468505b6e060b4b70a4e",
    "semantic_title": "guarantees of confidentiality via hammersley-chapman-robbins bounds",
    "citation_count": 1,
    "authors": [
      "Kamalika Chaudhuri",
      "Chuan Guo",
      "Laurens van der Maaten",
      "Saeed Mahloujifar",
      "Mark Tygert"
    ]
  },
  "https://openreview.net/forum?id=y0b0H1ndGQ": {
    "title": "GCondNet: A Novel Method for Improving Neural Networks on Small High-Dimensional Tabular Data",
    "volume": "reprod",
    "abstract": "Neural networks often struggle with high-dimensional but small sample-size tabular datasets. One reason is that current weight initialisation methods assume independence between weights, which can be problematic when there are insufficient samples to estimate the model's parameters accurately. In such small data scenarios, leveraging additional structures can improve the model's performance and training stability. To address this, we propose GCondNet, a general approach to enhance neural networks by leveraging implicit structures present in tabular data. We create a graph between samples for each data dimension, and utilise Graph Neural Networks (GNNs) to extract this implicit structure, and for conditioning the parameters of the first layer of an underlying predictor network. By creating many small graphs, GCondNet exploits the data's high-dimensionality, and thus improves the performance of an underlying predictor network. We demonstrate GCondNet's effectiveness on 12 real-world datasets, where it outperforms 14 standard and state-of-the-art methods. The results show that GCondNet is a versatile framework for injecting graph-regularisation into various types of neural networks, including MLPs and tabular Transformers. The code is available at https://github.com/andreimargeloiu/GCondNet",
    "checked": true,
    "id": "4411b0627fd59d08ccf6efc41c80383579755b8d",
    "semantic_title": "gcondnet: a novel method for improving neural networks on small high-dimensional tabular data",
    "citation_count": 5,
    "authors": [
      "Andrei Margeloiu",
      "Nikola Simidjievski",
      "Pietro Lio",
      "Mateja Jamnik"
    ]
  },
  "https://openreview.net/forum?id=C6wj17VBnu": {
    "title": "Attacking Bayes: On the Adversarial Robustness of Bayesian Neural Networks",
    "volume": "reprod",
    "abstract": "Adversarial examples have been shown to cause neural networks to fail on a wide range of vision and language tasks, but recent work has claimed that {\\em Bayesian} neural networks (BNNs) are inherently robust to adversarial perturbations. In this work, we examine this claim. To study the adversarial robustness of BNNs, we investigate whether it is possible to successfully break state-of-the-art BNN inference methods and prediction pipelines using even relatively unsophisticated attacks for three tasks: (1) label prediction under the posterior predictive mean, (2) adversarial example detection with Bayesian predictive uncertainty, and (3) semantic shift detection. We find that BNNs trained with state-of-the-art approximate inference methods, and even BNNs trained with Hamiltonian Monte Carlo, are highly susceptible to adversarial attacks. We also identify various conceptual and experimental errors in previous works that claimed inherent adversarial robustness of BNNs and conclusively demonstrate that BNNs and uncertainty-aware Bayesian prediction pipelines are {\\em not} inherently robust against adversarial attacks",
    "checked": true,
    "id": "ab0d1b915f27f7b9fede0fed0ce0d21b1bf59d46",
    "semantic_title": "attacking bayes: on the adversarial robustness of bayesian neural networks",
    "citation_count": 2,
    "authors": [
      "Yunzhen Feng",
      "Tim G. J. Rudner",
      "Nikolaos Tsilivis",
      "Julia Kempe"
    ]
  },
  "https://openreview.net/forum?id=Yj8fUQGXXL": {
    "title": "Reproducibility Study: Equal Improvability: A New Fairness Notion Considering the Long-Term Impact",
    "volume": "reprod",
    "abstract": "This reproducibility study aims to evaluate the robustness of Equal Improvability (EI) - an effort-based framework for ensuring long-term fairness. To this end, we seek to analyze the three proposed EI-ensuring regularization techniques, i.e. Covariance-based, KDE-based, and Loss-based EI. Our findings largely substantiate the initial assertions, demonstrating EI's enhanced performance over Empirical Risk Minimization (ERM) techniques on various test datasets. Furthermore, while affirming the long-term effectiveness in fairness, the study also uncovers challenges in resilience to overfitting, particularly in highly complex models. Building upon the original study, the experiments were extended to include a new dataset and multiple sensitive attributes. These additional tests further demonstrated the effec- tiveness of the EI approach, reinforcing its continued success. Our study highlights the importance of adaptable strategies in AI fairness, contributing to the ongoing discourse in this field of research",
    "checked": true,
    "id": "02fc6045b3b1a475176b1894066d7ec9a68f3dfc",
    "semantic_title": "reproducibility study: equal improvability: a new fairness notion considering the long-term impact",
    "citation_count": 0,
    "authors": [
      "Berkay Chakar",
      "Amina Izbassar",
      "Mina JaniÄijeviÄ",
      "Jakub Tomaszewski"
    ]
  },
  "https://openreview.net/forum?id=ydcrP55u2e": {
    "title": "Chain-of-Thought Unfaithfulness as Disguised Accuracy",
    "volume": "reprod",
    "abstract": "Understanding the extent to which Chain-of-Thought (CoT) generations align with a large language model's (LLM) internal computations is critical for deciding whether to trust an LLM's output. As a proxy for CoT faithfulness, Lanham et al. (2023) propose a metric that measures a model's dependence on its CoT for producing an answer. Within a single family of proprietary models, they find that LLMs exhibit a scaling-then-inverse-scaling relationship between model size and their measure of faithfulness, and that a 13 billion parameter model exhibits increased faithfulness compared to models ranging from 810 million to 175 billion parameters in size. We evaluate whether these results generalize as a property of all LLMs. We replicate the experimental setup in their section focused on scaling experiments with three different families of models and, under specific conditions, successfully reproduce the scaling trends for CoT faithfulness they report. However, after normalizing the metric to account for a model's bias toward certain answer choices, unfaithfulness drops significantly for smaller less-capable models. This normalized faithfulness metric is also strongly correlated ($R^2$=0.74) with accuracy, raising doubts about its validity for evaluating faithfulness",
    "checked": true,
    "id": "5f61ccb715f4ad9bef53794702e481e1a99f728b",
    "semantic_title": "chain-of-thought unfaithfulness as disguised accuracy",
    "citation_count": 15,
    "authors": [
      "Oliver Bentham",
      "Nathan Stringham",
      "Ana Marasovic"
    ]
  },
  "https://openreview.net/forum?id=srFEYJkqD7": {
    "title": "[Re] Classwise-Shapley values for data valuation",
    "volume": "reprod",
    "abstract": "We evaluate CS-Shapley, a data valuation method introduced in Schoch et al. (2022) for classification problems. We repeat the experiments in the paper, including two additional methods, the Least Core (Yan & Procaccia, 2021) and Data Banzhaf (Wang & Jia, 2023), a comparison not found in the literature. We include more conservative error estimates and additional metrics, like rank stability, and a variance-corrected version of Weighted Accuracy Drop, originally introduced in Schoch et al. (2022). We conclude that while CS-Shapley helps in the scenarios it was originally tested in, in particular for the detection of corrupted labels, it is outperformed by the conceptually simpler Data Banzhaf in the task of detecting highly influential points",
    "checked": true,
    "id": "162788e37cdf276e65a2eba08ccf9102fc7cdc66",
    "semantic_title": "[re] classwise-shapley values for data valuation",
    "citation_count": 0,
    "authors": [
      "Markus Semmler",
      "Miguel de Benito Delgado"
    ]
  },
  "https://openreview.net/forum?id=nPZgtpfgIx": {
    "title": "On the Reproducibility of: \"Learning Perturbations to Explain Time Series Predictions",
    "volume": "reprod",
    "abstract": "Deep Learning models have taken the front stage in the AI community, yet explainability challenges hinder their widespread adoption. Time series models, in particular, lack attention in this regard. This study tries to reproduce and extend the work of Enguehard (2023b), focusing on time series explainability by incorporating learnable masks and perturbations. Enguehard (2023b) employed two methods to learn these masks and perturbations, the preservation game (yielding SOTA results) and the deletion game (with poor performance). We extend the work by revising the deletion game's loss function, testing the robustness of the proposed method on a novel weather dataset, and visualizing the learned masks and perturbations. Despite notable discrepancies in results across many experiments, our findings demonstrate that the proposed method consistently outperforms all baselines and exhibits robust performance across datasets. However, visualizations for the preservation game reveal that the learned perturbations primarily resemble a constant zero signal, questioning the importance of learning perturbations. Nevertheless, our revised deletion game shows promise, recovering meaningful perturbations and, in certain instances, surpassing the performance of the preservation game",
    "checked": true,
    "id": "95a640805e90ba18380b85f7745cca8f69f68a7d",
    "semantic_title": "on the reproducibility of: \"learning perturbations to explain time series predictions",
    "citation_count": 0,
    "authors": [
      "Wouter Bant",
      "ÃdÃ¡m DivÃ¡k",
      "Jasper Eppink",
      "Floris Six Dijkstra"
    ]
  },
  "https://openreview.net/forum?id=Xu1sEPhjqH": {
    "title": "Reproducibility study of \"Robust Fair Clustering: A Novel Fairness Attack and Defense Framework",
    "volume": "reprod",
    "abstract": "This reproducibility study examines \"Robust Fair Clustering: A Novel Fairness Attack and Defense Framework\" by Chhabra et al. (2023), an innovative work in fair clustering algorithms. Our study focuses on validating the original paper's claims concerning the susceptibility of state-of-the-art fair clustering models to adversarial attacks and the efficacy of the proposed Consensus Fair Clustering (CFC) defence mechanism. We employ a similar experimental framework but extend our investigations by using additional datasets. Our findings confirm the original paper's claims, reinforcing the vulnerability of fair clustering models to adversarial attacks and the robustness of the CFC mechanism",
    "checked": true,
    "id": "f2db89f697edc6b703ab0d270a217bcb1144280d",
    "semantic_title": "reproducibility study of \"robust fair clustering: a novel fairness attack and defense framework",
    "citation_count": 0,
    "authors": [
      "Lucas Ponticelli",
      "Vincent Loos",
      "Eren Kocadag",
      "Kacper Bartosik"
    ]
  },
  "https://openreview.net/forum?id=Mf1H8X5DVb": {
    "title": "Reproducibility study of \"LICO: Explainable Models with Language-Image Consistency",
    "volume": "reprod",
    "abstract": "The growing reproducibility crisis in machine learning has brought forward a need for careful examination of research findings. This paper investigates the claims made by Lei et al. (2023) regarding their proposed method, LICO, for enhancing post-hoc interpretability techniques and improving image classification performance. LICO leverages natural language supervision from a vision-language model to enrich feature representations and guide the learning process. We conduct a comprehensive reproducibility study, employing (Wide) ResNets and established interpretability methods like Grad-CAM and RISE. We were mostly unable to reproduce the authors' results. In particular, we did not find that LICO consistently led to improved classification performance or improvements in quantitative and qualitative measures of interpretability. Thus, our findings highlight the importance of rigorous evaluation and transparent reporting in interpretability research",
    "checked": true,
    "id": "dbe5716b4e25f867ed0b4f40b2b5846f9447d039",
    "semantic_title": "reproducibility study of \"lico: explainable models with language-image consistency",
    "citation_count": 1,
    "authors": [
      "Luan Fletcher",
      "Robert van der Klis",
      "Martin SedlÃ¡Äek",
      "Stefan Vasilev",
      "Christos Athanasiadis"
    ]
  },
  "https://openreview.net/forum?id=QdeBbK5CSh": {
    "title": "Explaining RL Decisions with Trajectories': A Reproducibility Study",
    "volume": "reprod",
    "abstract": "This work investigates the reproducibility of the paper \"Explaining RL decisions with trajectories\" by Deshmukh et al. (2023). The original paper introduces a novel approach in explainable reinforcement learning based on the attribution decisions of an agent to specific clusters of trajectories encountered during training. We verify the main claims from the paper, which state that (i) training on less trajectories induces a lower initial state value, (ii) trajectories in a cluster present similar high-level patterns, (iii) distant trajectories influence the decision of an agent, and (iv) humans correctly identify the attributed trajectories to the decision of the agent. We recover the environments used by the authors based on the partial original code they provided for one of the environments (Grid-World), and implemented the remaining from scratch (Seaquest and HalfCheetah, Breakout, Q*Bert). While we confirm that (i), (ii), and (iii) partially hold, we extend on the largely qualitative experiments from the authors by introducing a quantitative metric to further support (iii), and new experiments and visual results for (i). Moreover, we investigate the use of different clustering algorithms and encoder architectures to further support (ii). We could not support (iv), given the limited extent of the original experiments. We conclude that, while some of the claims can be supported, further investigations and experiments could be of interest. We recognize the novelty of the work from the authors and hope that our work paves the way for clearer and more transparent approaches",
    "checked": true,
    "id": "339d8c705d166c8c976991bc4ab455bec0e6258c",
    "semantic_title": "explaining rl decisions with trajectories': a reproducibility study",
    "citation_count": 0,
    "authors": [
      "Karim Ahmed Abdel Sadek",
      "Matteo Nulli",
      "Joan Velja",
      "Jort Vincenti"
    ]
  },
  "https://openreview.net/forum?id=FEEKR0Vl9s": {
    "title": "Reproducibility Study on Adversarial Attacks Against Robust Transformer Trackers",
    "volume": "reprod",
    "abstract": "New transformer networks have been integrated into object tracking pipelines and have demonstrated strong performance on the latest benchmarks. This paper focuses on understanding how transformer trackers behave under adversarial attacks and how different attacks perform on tracking datasets as their parameters change. We conducted a series of experiments to evaluate the effectiveness of existing adversarial attacks on object trackers with transformer and non-transformer backbones. We experimented on 7 different trackers, including 3 that are transformer-based, and 4 which leverage other architectures. These trackers are tested against 4 recent attack methods to assess their performance and robustness on VOT2022ST, UAV123 and GOT10k datasets. Our empirical study focuses on evaluating adversarial robustness of object trackers based on bounding box versus binary mask predictions, and attack methods at different levels of perturbations. Interestingly, our study found that altering the perturbation level may not significantly affect the overall object tracking results after the attack. Similarly, the sparsity and imperceptibility of the attack perturbations may remain stable against perturbation level shifts. By applying a specific attack on all transformer trackers, we show that new transformer trackers having a stronger cross-attention modeling achieve a greater adversarial robustness on tracking datasets, such as VOT2022ST and GOT10k. Our results also indicate the necessity for new attack methods to effectively tackle the latest types of transformer trackers. The codes necessary to reproduce this study are available at https://github.com/fatemehN/ReproducibilityStudy",
    "checked": true,
    "id": "a07553fe94897fb3617ef4b96a2f2b2de25e344c",
    "semantic_title": "reproducibility study on adversarial attacks against robust transformer trackers",
    "citation_count": 2,
    "authors": [
      "Fatemeh Nourilenjan Nokabadi",
      "Jean-Francois Lalonde",
      "Christian GagnÃ©"
    ]
  },
  "https://openreview.net/forum?id=BbvSU02jLg": {
    "title": "Transfer Learning with Informative Priors: Simple Baselines Better than Previously Reported",
    "volume": "reprod",
    "abstract": "We pursue transfer learning to improve classifier accuracy on a target task with few labeled examples available for training. Recent work suggests that using a source task to learn a prior distribution over neural net weights, not just an initialization, can boost target task performance. In this study, we carefully compare transfer learning with and without source task informed priors across 5 datasets. We find that standard transfer learning informed by an initialization only performs far better than reported in previous comparisons. The relative gains of methods using informative priors over standard transfer learning vary in magnitude across datasets. For the scenario of 5-300 examples per class, we find negative or negligible gains on 2 datasets, modest gains (between 1.5-3 points of accuracy) on 2 other datasets, and substantial gains (>8 points) on one dataset. Among methods using informative priors, we find that an isotropic covariance appears competitive with learned low-rank covariance matrix while being substantially simpler to understand and tune. Further analysis suggests that the mechanistic justification for informed priors -- hypothesized improved alignment between train and test loss landscapes -- is not consistently supported due to high variability in empirical landscapes. We release code to allow independent reproduction of all experiments",
    "checked": true,
    "id": "5e19f2cdc6b22f8b5922d82f298fbdcbc04976f6",
    "semantic_title": "transfer learning with informative priors: simple baselines better than previously reported",
    "citation_count": 2,
    "authors": [
      "Ethan Harvey",
      "Mikhail Petrov",
      "Michael C Hughes"
    ]
  },
  "https://openreview.net/forum?id=fCNqD2IuoD": {
    "title": "Reproducibility Study of \"Learning Perturbations to Explain Time Series Predictions",
    "volume": "reprod",
    "abstract": "In this work, we attempt to reproduce the results of Enguehard (2023), which introduced ExtremalMask, a mask-based perturbation method for explaining time series data. We investigated the key claims of this paper, namely that (1) the model outperformed other models in several key metrics on both synthetic and real data, and (2) the model performed better when using the loss function of the preservation game relative to that of the deletion game. Although discrepancies exist, our results generally support the core of the original paper's conclusions. Next, we interpret ExtremalMask's outputs using new visualizations and metrics and discuss the insights each interpretation provides. Finally, we test whether ExtremalMask create out of distribution samples, and found the model does not exhibit this flaw on our tested synthetic dataset. Overall, our results support and add nuance to the original paper's findings",
    "checked": true,
    "id": "64f193008f4a30889737f761888364f64ab0a832",
    "semantic_title": "reproducibility study of \"learning perturbations to explain time series predictions",
    "citation_count": 0,
    "authors": [
      "Jiapeng Fan",
      "Luke Cadigan",
      "Paulius Skaisgiris",
      "Sebastian Uriel Arias"
    ]
  },
  "https://openreview.net/forum?id=VzKXbCzNoU": {
    "title": "Efficient Parallelized Simulation of Cyber-Physical Systems",
    "volume": "reprod",
    "abstract": "Advancements in accelerated physics simulations have greatly reduced training times for reinforcement learning policies, yet the conventional step-by-step agent-simulator interaction undermines simulation accuracy. In the real-world, interactions are asynchronous, with sensing, acting and processing happening simultaneously. Failing to capture this widens the sim2real gap and results in suboptimal real-world performance. In this paper, we address the challenges of simulating realistic asynchronicity and delays within parallelized simulations, crucial to bridging the sim2real gap in complex cyber-physical systems. Our approach efficiently parallelizes cyber-physical system simulations on accelerator hardware, including physics, sensors, actuators, processing components and their asynchronous interactions. We extend existing accelerated physics simulations with latency simulation capabilities by constructing a `supergraph' that encodes all data dependencies across parallelized simulation steps, ensuring accurate simulation. By finding the smallest supergraph, we minimize redundant computation. We validate our approach on two real-world systems and perform an extensive ablation, demonstrating superior performance compared to baseline methods",
    "checked": true,
    "id": "23d539811fef05d5dc3e77a35ff6c96e58e96cba",
    "semantic_title": "efficient parallelized simulation of cyber-physical systems",
    "citation_count": 0,
    "authors": [
      "Bas van der Heijden",
      "Laura Ferranti",
      "Jens Kober",
      "Robert Babuska"
    ]
  },
  "https://openreview.net/forum?id=H1hLNjwrGy": {
    "title": "Reproducibility Study of \"Robust Fair Clustering: A Novel Fairness Attack and Defense Framework",
    "volume": "reprod",
    "abstract": "Clustering algorithms play a pivotal role in various societal applications, where fairness is paramount to prevent adverse impacts on individuals. In this study, we revisit the robustness of fair clustering algorithms against adversarial attacks, affirming previous research findings that highlighted their susceptibility and the resilience of the Consensus Fair Clustering (CFC) model. Beyond reproducing these critical results, our work extends the original analysis by refining the codebase for enhanced experimentation, introducing additional metrics and datasets to deepen the evaluation of fairness and clustering quality, and exploring novel attack strategies, including targeted attacks on new metrics and a combined approach for balance and entropy as well as an ablation study. These contributions validate the original claims about the vulnerability and resilience of fair clustering algorithms and broaden the research landscape by offering a more comprehensive toolkit for assessing adversarial robustness in fair clustering",
    "checked": true,
    "id": "f2db89f697edc6b703ab0d270a217bcb1144280d",
    "semantic_title": "reproducibility study of \"robust fair clustering: a novel fairness attack and defense framework",
    "citation_count": 0,
    "authors": [
      "Iason Skylitsis",
      "Zheng Feng",
      "Idries Nasim",
      "Camille Niessink"
    ]
  },
  "https://openreview.net/forum?id=sHSKFYyINO": {
    "title": "InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers",
    "volume": "reprod",
    "abstract": "We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, whichâas we found outâproduced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MARCO and TREC DL 2020. In the same three-shot prompting scenario, our 435M parameter DeBERTA v3 ranker was at par with the 7x larger monoT5-3B (average gain over BM25 of 1.3 vs 1.32): In fact, on three out of five datasets, DeBERTA slightly outperformed monoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022). We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25. Our code and data is publicly available. https://github.com/searchivarius/inpars_light/",
    "checked": true,
    "id": "3a30217c4115777fb30c182c97cc77d34d065556",
    "semantic_title": "inpars-light: cost-effective unsupervised training of efficient rankers",
    "citation_count": 20,
    "authors": [
      "Leonid Boytsov",
      "Preksha Patel",
      "Vivek Sourabh",
      "Riddhi Nisar",
      "Sayani Kundu",
      "Ramya Ramanathan",
      "Eric Nyberg"
    ]
  },
  "https://openreview.net/forum?id=10R6iX6JHm": {
    "title": "We're Not Using Videos Effectively: An Updated Domain Adaptive Video Segmentation Baseline",
    "volume": "reprod",
    "abstract": "There has been abundant work in unsupervised domain adaptation for semantic segmentation (DAS) seeking to adapt a model trained on images from a labeled source domain to an unlabeled target domain. While the vast majority of prior work has studied this as a frame-level Image-DAS problem, a few Video-DAS works have sought to additionally leverage the temporal signal present in adjacent frames. However, Video-DAS works have historically studied a distinct set of benchmarks from Image-DAS, with minimal cross-benchmarking. In this work, we address this gap. Surprisingly, we find that (1) even after carefully controlling for data and model architecture, state-of-the-art Image-DAS methods (HRDA and HRDA+MIC)} outperform Video-DAS methods on established Video-DAS benchmarks (+14.5 mIoU on Viper$\\rightarrow$CityscapesSeq, +19.0 mIoU on Synthia$\\rightarrow$CityscapesSeq), and (2) naive combinations of Image-DAS and Video-DAS techniques only lead to marginal improvements across datasets. To avoid siloed progress between Image-DAS and Video-DAS, we open-source our codebase with support for a comprehensive set of Video-DAS and Image-DAS methods on a common benchmark. Code available at https://github.com/SimarKareer/UnifiedVideoDA",
    "checked": true,
    "id": "e96e71694d02a631e48f39874c42c6480ed7078e",
    "semantic_title": "we're not using videos effectively: an updated domain adaptive video segmentation baseline",
    "citation_count": 2,
    "authors": [
      "Simar Kareer",
      "Vivek Vijaykumar",
      "Harsh Maheshwari",
      "Judy Hoffman",
      "Prithvijit Chattopadhyay",
      "Viraj Uday Prabhu"
    ]
  },
  "https://openreview.net/forum?id=yiqeh2ZYUh": {
    "title": "Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models",
    "volume": "survey",
    "abstract": "Vision-and-Language Navigation (VLN) has gained increasing attention over recent years and many approaches have emerged to advance their development. The remarkable achievements of foundation models have shaped the challenges and proposed methods for VLN research. In this survey, we provide a top-down review that adopts a principled framework for embodied planning and reasoning, and emphasizes the current methods and future opportunities leveraging foundation models to address VLN challenges. We hope our in-depth discussions could provide valuable resources and insights: on one hand, to document the progress and explore opportunities and potential roles for foundation models in this field, and on the other, to organize different challenges and solutions in VLN to foundation model researchers",
    "checked": true,
    "id": "03c0a606b8f9bdbc4832cb061ad524fb5d16287b",
    "semantic_title": "vision-and-language navigation today and tomorrow: a survey in the era of foundation models",
    "citation_count": 24,
    "authors": [
      "Yue Zhang",
      "Ziqiao Ma",
      "Jialu Li",
      "Yanyuan Qiao",
      "Zun Wang",
      "Joyce Chai",
      "Qi Wu",
      "Mohit Bansal",
      "Parisa Kordjamshidi"
    ]
  },
  "https://openreview.net/forum?id=tH1dQH20eZ": {
    "title": "The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources",
    "volume": "survey",
    "abstract": "Foundation model development attracts a rapidly expanding body of contributors, scientists, and applications. To help shape responsible development practices, we introduce the Foundation Model Development Cheatsheet: a growing collection of 250+ tools and resources spanning text, vision, and speech modalities. We draw on a large body of prior work to survey resources (e.g. software, documentation, frameworks, guides, and practical tools) that support informed data selection, processing, and understanding, precise and limitation-aware artifact documentation, efficient model training, advance awareness of the environmental impact from training, careful model evaluation of capabilities, risks, and claims, as well as responsible model release, licensing and deployment practices. We hope this curated collection of resources helps guide more responsible development. The process of curating this list, enabled us to review the AI development ecosystem, revealing what tools are critically missing, misused, or over-used in existing practices. We find that (i) tools for data sourcing, model evaluation, and monitoring are critically under-serving ethical and real-world needs, (ii) evaluations for model safety, capabilities, and environmental impact all lack reproducibility and transparency, (iii) text and particularly English-centric analyses continue to dominate over multilingual and multi-modal analyses, and (iv) evaluation of systems, rather than just models, is needed so that capabilities and impact are assessed in context",
    "checked": true,
    "id": "e5b3e02748e9d5aabb8f2756a90d7ac9feb4d49d",
    "semantic_title": "the responsible foundation model development cheatsheet: a review of tools & resources",
    "citation_count": 11,
    "authors": [
      "Shayne Longpre",
      "Stella Biderman",
      "Alon Albalak",
      "Hailey Schoelkopf",
      "Daniel McDuff",
      "Sayash Kapoor",
      "Kevin Klyman",
      "Kyle Lo",
      "Gabriel Ilharco",
      "Nay San",
      "Maribeth Rauh",
      "Aviya Skowron",
      "Bertie Vidgen",
      "Laura Weidinger",
      "Arvind Narayanan",
      "Victor Sanh",
      "David Ifeoluwa Adelani",
      "Percy Liang",
      "Rishi Bommasani",
      "Peter Henderson",
      "Sasha Luccioni",
      "Yacine Jernite",
      "Luca Soldaini"
    ]
  },
  "https://openreview.net/forum?id=xG8un9ZbqT": {
    "title": "Neural Graph Reasoning: A Survey on Complex Logical Query Answering",
    "volume": "survey",
    "abstract": "Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves the far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs. The task received significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications. Finally, we point out promising directions, unsolved problems and applications of CLQA for future research",
    "checked": true,
    "id": "70769d0be95ae2173580a0c5c6d673043d186f9c",
    "semantic_title": "neural graph reasoning: a survey on complex logical query answering",
    "citation_count": 0,
    "authors": [
      "Hongyu Ren",
      "Mikhail Galkin",
      "Zhaocheng Zhu",
      "Jure Leskovec",
      "Michael Cochez"
    ]
  },
  "https://openreview.net/forum?id=BXDxwItNqQ": {
    "title": "A Survey on Compositional Learning of AI Models: Theoretical and Experimental Practices",
    "volume": "survey",
    "abstract": "Compositional learning, mastering the ability to combine basic concepts and construct more intricate ones, is crucial for human cognition, especially in human language comprehension and visual perception. This notion is tightly connected to generalization over unobserved situations. Despite its integral role in intelligence, there is a lack of systematic theoretical and experimental research methodologies, making it difficult to analyze the compositional learning abilities of computational models. In this paper, we survey the literature on compositional learning of AI models and the connections made to cognitive studies. We identify abstract concepts of compositionality in cognitive and linguistic studies and connect these to the computational challenges faced by language and vision models in compositional reasoning. We overview the formal definitions, tasks, evaluation benchmarks, various computational models, and theoretical findings. Our primary focus is on linguistic benchmarks and combining language and vision, though there is a large amount of research on compositional concept learning in the computer vision community alone. We cover modern studies on large language models to provide a deeper understanding of the cutting-edge compositional capabilities exhibited by state-of-the-art AI models and pinpoint important directions for future research",
    "checked": false,
    "id": "59e812ed99785aa8de4356243ee7a7b4088667c9",
    "semantic_title": "a survey on compositional learning of ai models: theoretical and experimetnal practices",
    "citation_count": 7,
    "authors": [
      "Sania Sinha",
      "Tanawan Premsri",
      "Parisa Kordjamshidi"
    ]
  },
  "https://openreview.net/forum?id=eskQMcIbMS": {
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "volume": "survey",
    "abstract": "One of the most striking findings in modern research on large language models (LLMs) is that scaling up compute during training leads to better results. However, less attention has been given to the benefits of scaling compute during inference. This survey focuses on these inference-time approaches. We explore three areas under a unified mathematical formalism: token-level generation algorithms, meta-generation algorithms, and efficient generation. Token-level generation algorithms, often called decoding algorithms, operate by sampling a single token at a time or constructing a token-level search space and then selecting an output. These methods typically assume access to a language model's logits, next-token distributions, or probability scores. Meta-generation algorithms work on partial or full sequences, incorporating domain knowledge, enabling backtracking, and integrating external information. Efficient generation methods aim to reduce token costs and improve the speed of generation. Our survey unifies perspectives from three research communities: traditional natural language processing, modern LLMs, and machine learning systems",
    "checked": true,
    "id": "99b38b72026775a1e91d83fb71e984b5e8b7b374",
    "semantic_title": "from decoding to meta-generation: inference-time algorithms for large language models",
    "citation_count": 77,
    "authors": [
      "Sean Welleck",
      "Amanda Bertsch",
      "Matthew Finlayson",
      "Hailey Schoelkopf",
      "Alex Xie",
      "Graham Neubig",
      "Ilia Kulikov",
      "Zaid Harchaoui"
    ]
  },
  "https://openreview.net/forum?id=rJSHjhEYJx": {
    "title": "Video Diffusion Models: A Survey",
    "volume": "survey",
    "abstract": "Diffusion generative models have recently become a powerful technique for creating and modifying high-quality, coherent video content. This survey provides a comprehensive overview of the critical components of diffusion models for video generation, including their applications, architectural design, and temporal dynamics modeling. The paper begins by discussing the core principles and mathematical formulations, then explores various architectural choices and methods for maintaining temporal consistency. A taxonomy of applications is presented, categorizing models based on input modalities such as text prompts, images, videos, and audio signals. Advancements in text-to-video generation are discussed to illustrate the state-of-the-art capabilities and limitations of current approaches. Additionally, the survey summarizes recent developments in training and evaluation practices, including the use of diverse video and image datasets and the adoption of various evaluation metrics to assess model performance. The survey concludes with an examination of ongoing challenges, such as generating longer videos and managing computational costs, and offers insights into potential future directions for the field. By consolidating the latest research and developments, this survey aims to serve as a valuable resource for researchers and practitioners working with video diffusion models. Website: \\url{https://github.com/ndrwmlnk/Awesome-Video-Diffusion-Models}",
    "checked": true,
    "id": "48cbad923c60ff4cfab54a52de491fa62268cf43",
    "semantic_title": "video diffusion models: a survey",
    "citation_count": 16,
    "authors": [
      "Andrew Melnik",
      "Michal Ljubljanac",
      "Cong Lu",
      "Qi Yan",
      "Weiming Ren",
      "Helge Ritter"
    ]
  },
  "https://openreview.net/forum?id=upAWnMgpnH": {
    "title": "A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law",
    "volume": "survey",
    "abstract": "In the fast-evolving domain of artificial intelligence, large language models (LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance, healthcare, and law: domains characterized by their reliance on professional expertise, challenging data acquisition, high-stakes, and stringent regulatory compliance. This survey offers a detailed exploration of the methodologies, applications, challenges, and forward-looking opportunities of LLMs within these high-stakes sectors. We highlight the instrumental role of LLMs in enhancing diagnostic and treatment methodologies in healthcare, innovating financial analytics, and refining legal interpretation and compliance strategies. Moreover, we critically examine the ethics for LLM applications in these fields, pointing out the existing ethical concerns and the need for transparent, fair, and robust AI systems that respect regulatory norms. By presenting a thorough review of current literature and practical applications, we showcase the transformative impact of LLMs, and outline the imperative for interdisciplinary cooperation, methodological advancements, and ethical vigilance. Through this lens, we aim to spark dialogue and inspire future research dedicated to maximizing the benefits of LLMs while mitigating their risks in these precision-dependent sectors. To facilitate future research on LLMs in these critical societal domains, we also initiate a reading list that tracks the latest advancements under this topic, which will be released and continually updated",
    "checked": true,
    "id": "c631a5458bfb0d86053af2258c219825477ba4f6",
    "semantic_title": "a survey on large language models for critical societal domains: finance, healthcare, and law",
    "citation_count": 37,
    "authors": [
      "Zhiyu Chen",
      "Jing Ma",
      "Xinlu Zhang",
      "Nan Hao",
      "An Yan",
      "Armineh Nourbakhsh",
      "Xianjun Yang",
      "Julian McAuley",
      "Linda Ruth Petzold",
      "William Yang Wang"
    ]
  },
  "https://openreview.net/forum?id=H2ZKqfNd0U": {
    "title": "How Far Are We From AGI: Are LLMs All We Need?",
    "volume": "survey",
    "abstract": "The evolution of artificial intelligence (AI) has profoundly impacted human society, driving significant advancements in multiple sectors. Yet, the escalating demands on AI have highlighted the limitations of AI's current offerings, catalyzing a movement towards Arti- ficial General Intelligence (AGI). AGI, distinguished by its ability to execute diverse real-world tasks with efficiency and effectiveness comparable to human intelligence, reflects a paramount milestone in AI evolution. While existing studies have reviewed specific advancements in AI and proposed potential paths to AGI, such as large language models (LLMs), they fall short of providing a thorough exploration of AGI's definitions, objectives, and developmental trajectories. Unlike previous survey papers, this work goes beyond summarizing LLMs by addressing key questions about our progress toward AGI and outlining the strategies essential for its realization through comprehensive analysis, in-depth discussions, and novel insights. We start by articulating the requisite capability frameworks for AGI, integrating the internal, interface, and system dimensions. As the realization of AGI requires more advanced capabilities and adherence to stringent constraints, we further discuss necessary AGI alignment technologies to harmonize these factors. Notably, we emphasize the importance of approaching AGI responsibly by first defining the key levels of AGI progression, followed by the evaluation framework that situates the status-quo, and finally giving our roadmap of how to reach the pinnacle of AGI. Moreover, to give tangible insights into the ubiquitous impact of the integration of AI, we outline existing challenges and potential pathways toward AGI in multiple domains. In sum, serving as a pioneering exploration into the current state and future trajectory of AGI, this paper aims to foster a collective comprehension and catalyze broader public discussions among researchers and practitioners on AGI",
    "checked": true,
    "id": "1c410c4363b59b5b5d1f66a5df415ced23c7bb2d",
    "semantic_title": "how far are we from agi: are llms all we need?",
    "citation_count": 2,
    "authors": [
      "Tao Feng",
      "Chuanyang Jin",
      "Jingyu Liu",
      "Kunlun Zhu",
      "Haoqin Tu",
      "Zirui Cheng",
      "Guanyu Lin",
      "Jiaxuan You"
    ]
  },
  "https://openreview.net/forum?id=NQPo8ZhQPa": {
    "title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey",
    "volume": "survey",
    "abstract": "Large language models have demonstrated remarkable few-shot in-context learning (ICL) capabilities, adapting to new tasks with few-shots demonstrations. However, the efficacy of ICL is highly dependent on the selection of these demonstrations. Recent developments have introduced retrieval-based in-context learning (RetICL), which dynamically retrieves demonstrations tailored to each input query. This approach leverages existing databases and retrieval systems, enhancing efficiency and scalability while mitigating biases inherent in manual example selection. Given the promising results and growing interest in RetICL, we present a comprehensive survey of this field. Our review encompasses: design choices for ICL demonstration retrieval models, retrieval training procedures, inference strategies and current applications of RetICL. In the end, we explore future directions for this emerging technology",
    "checked": true,
    "id": "b2f4d22fddf3619a38a1754d9497935aa0848426",
    "semantic_title": "in-context learning with retrieved demonstrations for language models: a survey",
    "citation_count": 70,
    "authors": [
      "Man Luo",
      "Xin Xu",
      "Yue Liu",
      "Panupong Pasupat",
      "Mehran Kazemi"
    ]
  },
  "https://openreview.net/forum?id=xrO70E8UIZ": {
    "title": "From Persona to Personalization: A Survey on Role-Playing Language Agents",
    "volume": "survey",
    "abstract": "Recent advancements in large language models (LLMs) have significantly boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI systems designed to simulate assigned personas. By harnessing multiple advanced abilities of LLMs, including in-context learning, instruction following, and social intelligence, RPLAs achieve a remarkable sense of human likeness and vivid role-playing performance. RPLAs can mimic a wide range of personas, ranging from historical figures and fictional characters to real-life individuals. Consequently, they have catalyzed numerous AI applications, such as emotional companions, interactive video games, personalized assistants and copilots, and digital clones. In this paper, we conduct a comprehensive survey of this field, illustrating the evolution and recent progress in RPLAs integrating with cutting-edge LLM technologies. We categorize personas into three types: 1) Demographic Persona, which leverages statistical stereotypes; 2) Character Persona, focused on well-established figures; and 3) Individualized Persona, customized through ongoing user interactions for personalized services. We begin by presenting a comprehensive overview of current methodologies for RPLAs, followed by the details for each persona type, covering corresponding data sourcing, agent construction, and evaluation. Afterward, we discuss the fundamental risks, existing limitations, and prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI products in the market, which reflects practical user demands that shape and drive RPLA research. Through this survey, we aim to establish a clear taxonomy of RPLA research and applications, facilitate future research in this critical and ever-evolving field, and pave the way for a future where humans and RPLAs coexist in harmony",
    "checked": true,
    "id": "7f575e1a8e4c465b31f8928ffd13ad48aa961789",
    "semantic_title": "from persona to personalization: a survey on role-playing language agents",
    "citation_count": 98,
    "authors": [
      "Jiangjie Chen",
      "Xintao Wang",
      "Rui Xu",
      "Siyu Yuan",
      "Yikai Zhang",
      "Wei Shi",
      "Jian Xie",
      "Shuang Li",
      "Ruihan Yang",
      "Tinghui Zhu",
      "Aili Chen",
      "Nianqi Li",
      "Lida Chen",
      "Caiyu Hu",
      "Siye Wu",
      "Scott Ren",
      "Ziquan Fu",
      "Yanghua Xiao"
    ]
  },
  "https://openreview.net/forum?id=a90WpmSi0I": {
    "title": "Deep Generative Models through the Lens of the Manifold Hypothesis: A Survey and New Connections",
    "volume": "expert",
    "abstract": "In recent years there has been increased interest in understanding the interplay between deep generative models (DGMs) and the manifold hypothesis. Research in this area focuses on understanding the reasons why commonly-used DGMs succeed or fail at learning distributions supported on unknown low-dimensional manifolds, as well as developing new models explicitly designed to account for manifold-supported data. This manifold lens provides both clarity as to why some DGMs (e.g. diffusion models and some generative adversarial networks) empirically surpass others (e.g. likelihood-based models such as variational autoencoders, normalizing flows, or energy-based models) at sample generation, and guidance for devising more performant DGMs. We carry out the first survey of DGMs viewed through this lens, making two novel contributions along the way. First, we formally establish that numerical instability of likelihoods in high ambient dimensions is unavoidable when modelling data with low intrinsic dimension. We then show that DGMs on learned representations of autoencoders can be interpreted as approximately minimizing Wasserstein distance: this result, which applies to latent diffusion models, helps justify their outstanding empirical results. The manifold lens provides a rich perspective from which to understand DGMs, and we aim to make this perspective more accessible and widespread",
    "checked": true,
    "id": "479551ebaa9995c3e723cde9cfeef0effdc8865d",
    "semantic_title": "deep generative models through the lens of the manifold hypothesis: a survey and new connections",
    "citation_count": 20,
    "authors": [
      "Gabriel Loaiza-Ganem",
      "Brendan Leigh Ross",
      "Rasa Hosseinzadeh",
      "Anthony L. Caterini",
      "Jesse C. Cresswell"
    ]
  },
  "https://openreview.net/forum?id=ePUVetPKu6": {
    "title": "Mechanistic Interpretability for AI Safety - A Review",
    "volume": "expert",
    "abstract": "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable. For an HTML version of the paper, visit https://leonardbereska.github.io/blog/2024/mechinterpreview/",
    "checked": true,
    "id": "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
    "semantic_title": "mechanistic interpretability for ai safety - a review",
    "citation_count": 158,
    "authors": [
      "Leonard Bereska",
      "Stratis Gavves"
    ]
  },
  "https://openreview.net/forum?id=Mm2cMDl9r5": {
    "title": "Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions",
    "volume": "survey",
    "abstract": "Deep generative models (DGMs) have demonstrated great success across various domains, particularly in generating texts and images using models trained from offline data. Similarly, data-driven decision-making also necessitates learning a generator function from the offline data to serve as the policy. Applying DGMs in offline policy learning exhibits great potential, and numerous studies have explored in this direction. However, this field still lacks a comprehensive review and so developments of different branches are relatively independent. In this paper, we provide the first systematic review on the applications of DGMs for offline policy learning. We cover five mainstream DGMs, including Variational Auto-Encoders, Generative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion Models, and their applications in both offline reinforcement learning (offline RL) and imitation learning (IL). Offline RL and IL are two main branches of offline policy learning and are widely-adopted techniques for sequential decision-making. Notably, for each type of DGM-based offline policy learning, we distill its fundamental scheme, categorize related works based on the usage of the DGM, and sort out the development process of algorithms in that field. In addition, we provide in-depth discussions on DGMs and offline policy learning as a summary, based on which we present our perspectives on future research directions. This work offers a hands-on reference for the research progress in DGMs for offline policy learning, and aims to inspire improved DGM-based offline RL or IL algorithms. For convenience, we maintain a paper list on https://github.com/LucasCJYSDL/DGMs-for-Offline-Policy-Learning",
    "checked": true,
    "id": "f1c704686d53265bb1613bf9d37908f898192668",
    "semantic_title": "deep generative models for offline policy learning: tutorial, survey, and perspectives on future directions",
    "citation_count": 10,
    "authors": [
      "Jiayu Chen",
      "Bhargav Ganguly",
      "Yang Xu",
      "Yongsheng Mei",
      "Tian Lan",
      "Vaneet Aggarwal"
    ]
  },
  "https://openreview.net/forum?id=XiK8tHDQNX": {
    "title": "Structural Pruning of Pre-trained Language Models via Neural Architecture Search",
    "volume": "expert",
    "abstract": "Pre-trained language models (PLM), for example BERT or RoBERTa, mark the state-of-the-art for natural language understanding task when fine-tuned on labeled data. However, their large size poses challenges in deploying them for inference in real-world applications, due to significant GPU memory requirements and high inference latency. This paper explores neural architecture search (NAS) for structural pruning to find sub-parts of the fine-tuned network that optimally trade-off efficiency, for example in terms of model size or latency, and generalization performance. We also show how we can utilize more recently developed two-stage weight-sharing NAS approaches in this setting to accelerate the search process. Unlike traditional pruning methods with fixed thresholds, we propose to adopt a multi-objective approach that identifies the Pareto optimal set of sub-networks, allowing for a more flexible and automated compression process",
    "checked": true,
    "id": "8e3b5beeeb07df8f15e8c0e2f93ce01faa204d3f",
    "semantic_title": "structural pruning of pre-trained language models via neural architecture search",
    "citation_count": 2,
    "authors": [
      "Aaron Klein",
      "Jacek Golebiowski",
      "Xingchen Ma",
      "Valerio Perrone",
      "Cedric Archambeau"
    ]
  },
  "https://openreview.net/forum?id=oVTkOs8Pka": {
    "title": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models",
    "volume": "expert",
    "abstract": "This work identifies 18 foundational challenges in assuring the alignment and safety of large language models (LLMs). These challenges are organized into three different categories: scientific understanding of LLMs, development and deployment methods, and sociotechnical challenges. Based on the identified challenges, we pose 200+, concrete research questions",
    "checked": true,
    "id": "6f98525dc695257bdcb9a491e4d77f4d12bb5144",
    "semantic_title": "foundational challenges in assuring alignment and safety of large language models",
    "citation_count": 141,
    "authors": [
      "Usman Anwar",
      "Abulhair Saparov",
      "Javier Rando",
      "Daniel Paleka",
      "Miles Turpin",
      "Peter Hase",
      "Ekdeep Singh Lubana",
      "Erik Jenner",
      "Stephen Casper",
      "Oliver Sourbut",
      "Benjamin L. Edelman",
      "Zhaowei Zhang",
      "Mario GÃ¼nther",
      "Anton Korinek",
      "Jose Hernandez-Orallo",
      "Lewis Hammond",
      "Eric J Bigelow",
      "Alexander Pan",
      "Lauro Langosco",
      "Tomasz Korbak",
      "Heidi Chenyu Zhang",
      "Ruiqi Zhong",
      "Sean O hEigeartaigh",
      "Gabriel Recchia",
      "Giulio Corsi",
      "Alan Chan",
      "Markus Anderljung",
      "Lilian Edwards",
      "Aleksandar Petrov",
      "Christian Schroeder de Witt",
      "Sumeet Ramesh Motwani",
      "Yoshua Bengio",
      "Danqi Chen",
      "Philip Torr",
      "Samuel Albanie",
      "Tegan Maharaj",
      "Jakob Nicolaus Foerster",
      "Florian TramÃ¨r",
      "He He",
      "Atoosa Kasirzadeh",
      "Yejin Choi",
      "David Krueger"
    ]
  },
  "https://openreview.net/forum?id=HduK51xNtS": {
    "title": "Graph Reinforcement Learning for Combinatorial Optimization: A Survey and Unifying Perspective",
    "volume": "survey",
    "abstract": "Graphs are a natural representation for systems based on relations between connected entities. Combinatorial optimization problems, which arise when considering an objective function related to a process of interest on discrete structures, are often challenging due to the rapid growth of the solution space. The trial-and-error paradigm of Reinforcement Learning has recently emerged as a promising alternative to traditional methods, such as exact algorithms and (meta)heuristics, for discovering better decision-making strategies in a variety of disciplines including chemistry, computer science, and statistics. Despite the fact that they arose in markedly different fields, these techniques share significant commonalities. Therefore, we set out to synthesize this work in a unifying perspective that we term Graph Reinforcement Learning, interpreting it as a constructive decision-making method for graph problems. After covering the relevant technical background, we review works along the dividing line of whether the goal is to optimize graph structure given a process of interest, or to optimize the outcome of the process itself under fixed graph structure. Finally, we discuss the common challenges facing the field and open research questions. In contrast with other surveys, the present work focuses on non-canonical graph problems for which performant algorithms are typically not known and Reinforcement Learning is able to provide efficient and effective solutions",
    "checked": true,
    "id": "f4df0608f6b042d162c463f74984f1eb2b468ea8",
    "semantic_title": "graph reinforcement learning for combinatorial optimization: a survey and unifying perspective",
    "citation_count": 7,
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ]
  },
  "https://openreview.net/forum?id=3Wg1oErMcJ": {
    "title": "Self-Supervised Visual Representation Learning for Medical Image Analysis: A Comprehensive Survey",
    "volume": "survey",
    "abstract": "Deep learning has developed as a great tool for many computer vision or natural language processing tasks. However, supervised deep learning algorithms require a large amount of labelled data to achieve satisfactory performance. Self-supervised learning, a subcategory of unsupervised learning, circumvents the issue of the requirement of a large amount of data by learning representations from the data without labelled examples. Over the past few years, Self-supervised learning has been applied to various tasks to achieve performance at par with or surpassing the supervised counterparts in several tasks. However, the progress has been so rapid, that a comprehensive account of these developments is lacking. In this study, we attempt to present a review of those methods and show how the self-supervised learning paradigm evolved over the years. Additionally, we also present an exhaustive review of the self-supervised methods applied to medical image analysis. Furthermore, we also present an extensive compilation of the details of the datasets used in the different works and provide performance metrics of some notable works on image and video datasets",
    "checked": true,
    "id": "9499d52688286984290fd6d6fa101a7b1e5478d2",
    "semantic_title": "self-supervised visual representation learning for medical image analysis: a comprehensive survey",
    "citation_count": 1,
    "authors": [
      "Siladittya Manna",
      "Saumik Bhattacharya",
      "Umapada Pal"
    ]
  },
  "https://openreview.net/forum?id=ul2tbUPtIQ": {
    "title": "Vision-Language Instruction Tuning: A Review and Analysis",
    "volume": "survey",
    "abstract": "Instruction tuning is a crucial supervised training phase in Large Language Models (LLMs), aiming to enhance the LLM's ability to generalize instruction execution and adapt to user preferences. With the increasing integration of multi-modal data into LLMs, there is growing interest in Vision-Language Instruction Tuning (VLIT), which presents more complex characteristics compared to pure text instruction tuning. In this paper, we systematically review the latest VLIT settings and corresponding datasets in multi-modal LLMs and provide insights into the intrinsic motivations behind their design. For the first time, we offer a detailed multi-perspective categorization for existing VLIT datasets and identify the characteristics that high-quality VLIT data should possess. By incorporating these characteristics as guiding principles into the existing VLIT data construction process, we conduct extensive experiments and verify their positive impact on the performance of tuned multi-modal LLMs. Furthermore, we discuss the current challenges and future research directions of VLIT, providing insights for the continuous development of this field. The code and dataset related to this paper have been open-sourced at \\url{https://github.com/palchenli/VL-Instruction-Tuning}",
    "checked": true,
    "id": "3cc6c4e88b6135d53938315a262285a501803c48",
    "semantic_title": "vision-language instruction tuning: a review and analysis",
    "citation_count": 11,
    "authors": [
      "Chen Li",
      "Yixiao Ge",
      "Dian Li",
      "Ying Shan"
    ]
  },
  "https://openreview.net/forum?id=XfHWcNTSHp": {
    "title": "A Survey on Data Selection for Language Models",
    "volume": "survey",
    "abstract": "A major factor in the recent success of large language models is the use of enormous and ever-growing text datasets for unsupervised pre-training. However, naively training a model on all available data may not be optimal (or feasible), as the quality of available text data can vary. Filtering out data can also decrease the carbon footprint and financial costs of training models by reducing the amount of training required. Data selection methods aim to determine which candidate data points to include in the training dataset and how to appropriately sample from the selected data points. The promise of improved data selection methods has caused the volume of research in the area to rapidly expand. However, because deep learning is mostly driven by empirical evidence and experimentation on large-scale data is expensive, few organizations have the resources for extensive data selection research. Consequently, knowledge of effective data selection practices has become concentrated within a few organizations, many of which do not openly share their findings and methodologies. To narrow this gap in knowledge, we present a comprehensive review of existing literature on data selection methods and related research areas, providing a taxonomy of existing approaches. By describing the current landscape of research, this work aims to accelerate progress in data selection by establishing an entry point for new and established researchers. Additionally, throughout this review we draw attention to noticeable holes in the literature and conclude the paper by proposing promising avenues for future research",
    "checked": true,
    "id": "e95bb39748a497fbeed1b221fb3d1296c2b1eec2",
    "semantic_title": "a survey on data selection for language models",
    "citation_count": 146,
    "authors": [
      "Alon Albalak",
      "Yanai Elazar",
      "Sang Michael Xie",
      "Shayne Longpre",
      "Nathan Lambert",
      "Xinyi Wang",
      "Niklas Muennighoff",
      "Bairu Hou",
      "Liangming Pan",
      "Haewon Jeong",
      "Colin Raffel",
      "Shiyu Chang",
      "Tatsunori Hashimoto",
      "William Yang Wang"
    ]
  },
  "https://openreview.net/forum?id=bsCCJHbO8A": {
    "title": "Efficient Large Language Models: A Survey",
    "volume": "survey",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in important tasks such as natural language understanding and language generation, and thus have the potential to make a substantial impact on our society. Such capabilities, however, come with the considerable resources they demand, highlighting the strong need to develop effective techniques for addressing their efficiency challenges. In this survey, we provide a systematic and comprehensive review of efficient LLMs research. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient LLMs topics from model-centric, data-centric, and framework-centric perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey. We will actively maintain the repository and incorporate new research as it emerges. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient LLMs research and inspire them to contribute to this important and exciting field",
    "checked": true,
    "id": "d13adc935c02fa1ab7a714b6b92433a931679b60",
    "semantic_title": "efficient large language models: a survey",
    "citation_count": 55,
    "authors": [
      "Zhongwei Wan",
      "Xin Wang",
      "Che Liu",
      "Samiul Alam",
      "Yu Zheng",
      "Jiachen Liu",
      "Zhongnan Qu",
      "Shen Yan",
      "Yi Zhu",
      "Quanlu Zhang",
      "Mosharaf Chowdhury",
      "Mi Zhang"
    ]
  },
  "https://openreview.net/forum?id=IhXM3g2gxg": {
    "title": "A Short Survey on Importance Weighting for Machine Learning",
    "volume": "survey",
    "abstract": "Importance weighting is a fundamental procedure in statistics and machine learning that weights the objective function or probability distribution based on the importance of the instance in some sense. The simplicity and usefulness of the idea has led to many applications of importance weighting. For example, it is known that supervised learning under an assumption about the difference between the training and test distributions, called distribution shift, can guarantee statistically desirable properties through importance weighting by their density ratio. This survey summarizes the broad applications of importance weighting in machine learning and related research",
    "checked": true,
    "id": "8feca4f15b7fe6bd61e8d634ff4ef869378d4485",
    "semantic_title": "a short survey on importance weighting for machine learning",
    "citation_count": 8,
    "authors": [
      "Masanari Kimura",
      "Hideitsu Hino"
    ]
  },
  "https://openreview.net/forum?id=bNtr6SLgZf": {
    "title": "A Survey of Temporal Credit Assignment in Deep Reinforcement Learning",
    "volume": "survey",
    "abstract": "The Credit Assignment Problem (CAP) refers to the longstanding challenge of Reinforcement Learning agents to associate actions with their long-term consequences. Solving the CAP is a crucial step towards the successful deployment of RL in the real world since most decision problems provide feedback that is noisy, delayed, and with little or no information about the causes. These conditions make it hard to distinguish serendipitous outcomes from those caused by informed decision-making. However, the mathematical nature of credit and the CAP remains poorly understood and defined. In this survey, we review the state of the art of Temporal Credit Assignment (CA) in deep RL. We propose a unifying formalism for credit that enables equitable comparisons of state-of-the-art algorithms and improves our understanding of the trade-offs between the various methods. We cast the CAP as the problem of learning the influence of an action over an outcome from a finite amount of experience. We discuss the challenges posed by delayed effects, dilution, and a lack of action influence, and analyse how existing methods aim to address them. Finally, we survey the protocols to evaluate a credit assignment method and suggest ways to diagnose the sources of struggle for different methods. Overall, this survey provides an overview of the field for new-entry practitioners and researchers, it offers a coherent perspective for scholars looking to expedite the starting stages of a new study on the CAP, and it suggests potential directions for future research",
    "checked": true,
    "id": "c03e530e7d91b6d74f4ec5a2088c90e5db7810f7",
    "semantic_title": "a survey of temporal credit assignment in deep reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Eduardo Pignatelli",
      "Johan Ferret",
      "Matthieu Geist",
      "Thomas Mesnard",
      "Hado van Hasselt",
      "Laura Toni"
    ]
  },
  "https://openreview.net/forum?id=YgmBD2c9qX": {
    "title": "A Unified View of Differentially Private Deep Generative Modeling",
    "volume": "survey",
    "abstract": "The availability of rich and vast data sources has greatly advanced machine learning applications in various domains. However, data with privacy concerns comes with stringent regulations that frequently prohibit data access and data sharing. Overcoming these obstacles in compliance with privacy considerations is key for technological progress in many real-world application scenarios that involve sensitive data. Differentially private (DP) data publishing provides a compelling solution, where only a sanitized form of the data is publicly released, enabling privacy-preserving downstream analysis and reproducible research in sensitive domains. In recent years, various approaches have been proposed for achieving privacy-preserving high-dimensional data generation by private training on top of deep neural networks. In this paper, we present a novel unified view that systematizes these approaches. Our view provides a joint design space for systematically deriving methods that cater to different use cases. We then discuss the strengths, limitations, and inherent correlations between different approaches, aiming to shed light on crucial aspects and inspire future research. We conclude by presenting potential paths forward for the field of DP data generation, with the aim of steering the community toward making the next important steps in advancing privacy-preserving learning",
    "checked": true,
    "id": "724b9cd48f1a524aa889a76fdb5babdb0a24fdba",
    "semantic_title": "a unified view of differentially private deep generative modeling",
    "citation_count": 4,
    "authors": [
      "Dingfan Chen",
      "Raouf Kerkouche",
      "Mario Fritz"
    ]
  },
  "https://openreview.net/forum?id=1i6ZCvflQJ": {
    "title": "Cognitive Architectures for Language Agents",
    "volume": "survey",
    "abstract": "Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence",
    "checked": true,
    "id": "e4bb1b1f97711a7634bf4bff72c56891be2222e6",
    "semantic_title": "cognitive architectures for language agents",
    "citation_count": 179,
    "authors": [
      "Theodore Sumers",
      "Shunyu Yao",
      "Karthik Narasimhan",
      "Thomas Griffiths"
    ]
  },
  "https://openreview.net/forum?id=fPQSxjqa2o": {
    "title": "From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "008ff48d90ea1776419ae0d2dbf528572dc2c0e0",
    "semantic_title": "from continuous dynamics to graph neural networks: neural diffusion and beyond",
    "citation_count": 24,
    "authors": [
      "Andi Han",
      "Dai Shi",
      "Lequan Lin",
      "Junbin Gao"
    ]
  },
  "https://openreview.net/forum?id=qhtHsvF5zj": {
    "title": "Automated Design of Metaheuristic Algorithms: A Survey",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "29c96f5358556930fb86ba2242a4d8a074d9df95",
    "semantic_title": "automated design of metaheuristic algorithms: a survey",
    "citation_count": 11,
    "authors": [
      "Qi Zhao",
      "Qiqi Duan",
      "Bai Yan",
      "Shi Cheng",
      "Yuhui Shi"
    ]
  },
  "https://openreview.net/forum?id=kQmz1BMIYi": {
    "title": "Accountable Textual-Visual Chat Learns to Reject Human Instructions in Image Re-creation",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "53df959bcf6499c45e316086a96a624389a39a52",
    "semantic_title": "accountable textual-visual chat learns to reject human instructions in image re-creation",
    "citation_count": 0,
    "authors": [
      "Zhiwei Zhang",
      "Yuliang Liu"
    ]
  },
  "https://openreview.net/forum?id=tQVZgvXhZb": {
    "title": "A Unified View on Solving Objective Mismatch in Model-Based Reinforcement Learning",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "690fe81e99b1486ff49c9fc4da9bcd1a7e674668",
    "semantic_title": "a unified view on solving objective mismatch in model-based reinforcement learning",
    "citation_count": 7,
    "authors": [
      "Ran Wei",
      "Nathan Lambert",
      "Anthony D McDonald",
      "Alfredo Garcia",
      "Roberto Calandra"
    ]
  },
  "https://openreview.net/forum?id=sWlHhfijcS": {
    "title": "A Survey on Graph Construction for Geometric Deep Learning in Medicine: Methods and Recommendations",
    "volume": "survey",
    "abstract": "Graph neural networks are powerful tools that enable deep learning on non-Euclidean data structures like graphs, point clouds, and meshes. They leverage the connectivity of data points and can even benefit learning tasks on data, which is not naturally graph-structured -like point clouds. In these cases, the graph structure needs to be determined from the dataset, which adds a significant challenge to the learning process. This opens up a multitude of design choices for creating suitable graph structures, which have a substantial impact on the success of the graph learning task. However, so far no concrete guidance for choosing the most appropriate graph construction is available, not only due to the large variety of methods out there but also because of its strong connection to the dataset at hand. In medicine, for example, a large variety of different data types complicates the selection of graph construction methods even more. We therefore summarise the current state-of-the-art graph construction methods, especially for medical data. In this work, we introduce a categorisation scheme for graph types and graph construction methods. We identify two main strands of graph construction: static and adaptive methods, discuss their advantages and disadvantages, and formulate recommendations for choosing a suitable graph construction method. We furthermore discuss how a created graph structure can be assessed and to what degree it supports graph learning. We hope to support medical research with graph deep learning with this work by elucidating the wide variety of graph construction methods",
    "checked": true,
    "id": "21d8c97d588f6dfed0df00d8e2609da1bba8f07b",
    "semantic_title": "a survey on graph construction for geometric deep learning in medicine: methods and recommendations",
    "citation_count": 5,
    "authors": [
      "Tamara T. MÃ¼ller",
      "Sophie Starck",
      "Alina Dima",
      "Stephan Wunderlich",
      "Kyriaki-Margarita Bintsi",
      "Kamilia Zaripova",
      "Rickmer Braren",
      "Daniel Rueckert",
      "Anees Kazi",
      "Georgios Kaissis"
    ]
  },
  "https://openreview.net/forum?id=gerNCVqqtR": {
    "title": "Chronos: Learning the Language of Time Series",
    "volume": "expert",
    "abstract": "We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines",
    "checked": true,
    "id": "02fa77e4f355198cb4270f6d4a07517bf09c46dd",
    "semantic_title": "chronos: learning the language of time series",
    "citation_count": 222,
    "authors": [
      "Abdul Fatir Ansari",
      "Lorenzo Stella",
      "Ali Caner Turkmen",
      "Xiyuan Zhang",
      "Pedro Mercado",
      "Huibin Shen",
      "Oleksandr Shchur",
      "Syama Sundar Rangapuram",
      "Sebastian Pineda Arango",
      "Shubham Kapoor",
      "Jasper Zschiegner",
      "Danielle C. Maddix",
      "Hao Wang",
      "Michael W. Mahoney",
      "Kari Torkkola",
      "Andrew Gordon Wilson",
      "Michael Bohlke-Schneider",
      "Bernie Wang"
    ]
  },
  "https://openreview.net/forum?id=vzZ3pbNRvh": {
    "title": "Graph Knowledge Distillation to Mixture of Experts",
    "volume": "expert",
    "abstract": "In terms of accuracy, Graph Neural Networks (GNNs) are the best architectural choice for the node classification task. Their drawback in real-world deployment is the latency that emerges from the neighbourhood processing operation. One solution to the latency issue is to perform knowledge distillation from a trained GNN to a Multi-Layer Perceptron (MLP), where the MLP processes only the features of the node being classified (and possibly some pre-computed structural information). However, the performance of such MLPs in both transductive and inductive settings remains inconsistent for existing knowledge distillation techniques. We propose to address the performance concerns by using a specially-designed student model instead of an MLP. Our model, named Routing-by-Memory (RbM), is a form of Mixture-of-Experts (MoE), with a design that enforces expert specialization. By encouraging each expert to specialize on a certain region on the hidden representation space, we demonstrate experimentally that it is possible to derive considerably more consistent performance across multiple datasets. Code available at https://github.com/Rufaim/routing-by-memory",
    "checked": true,
    "id": "7f18e0dfbe199a633e1163b88913387f19535125",
    "semantic_title": "graph knowledge distillation to mixture of experts",
    "citation_count": 0,
    "authors": [
      "Pavel Rumiantsev",
      "Mark Coates"
    ]
  },
  "https://openreview.net/forum?id=3FsVtsISHW": {
    "title": "Deconfounding Imitation Learning with Variational Inference",
    "volume": "expert",
    "abstract": "Standard imitation learning can fail when the expert demonstrators have different sensory inputs than the imitating agent. This is because partial observability gives rise to hidden confounders in the causal graph. In previous work, to work around the confounding problem, policies have been trained using query access to the expert's policy or inverse reinforcement learning (IRL). However, both approaches have drawbacks as the expert's policy may not be available and IRL can be unstable in practice. Instead, we propose to train a variational inference model to infer the expert's latent information and use it to train a latent-conditional policy. We prove that using this method, under strong assumptions, the identification of the correct imitation learning policy is theoretically possible from expert demonstrations alone. In practice, we focus on a setting with less strong assumptions where we use exploration data for learning the inference model. We show in theory and practice that this algorithm converges to the correct interventional policy, solves the confounding issue, and can under certain assumptions achieve an asymptotically optimal imitation performance",
    "checked": true,
    "id": "7efa53c4b17902ff3631467a11d64c0159a1bf8e",
    "semantic_title": "deconfounding imitation learning with variational inference",
    "citation_count": 5,
    "authors": [
      "Risto Vuorio",
      "Pim De Haan",
      "Johann Brehmer",
      "Hanno Ackermann",
      "Daniel Dijkman",
      "Taco Cohen"
    ]
  },
  "https://openreview.net/forum?id=Aoj9H6jl6F": {
    "title": "Improving Predictor Reliability with Selective Recalibration",
    "volume": "expert",
    "abstract": "A reliable deep learning system should be able to accurately express its confidence with respect to its predictions, a quality known as calibration. One of the most effective ways to produce reliable confidence estimates with a pre-trained model is by applying a post-hoc recalibration method. Popular recalibration methods like temperature scaling are typically fit on a small amount of data and work in the model's output space, as opposed to the more expressive feature embedding space, and thus usually have only one or a handful of parameters. However, the target distribution to which they are applied is often complex and difficult to fit well with such a function. To this end we propose selective recalibration, where a selection model learns to reject some user-chosen proportion of the data in order to allow the recalibrator to focus on regions of the input space that can be well-captured by such a model. We provide theoretical analysis to motivate our algorithm, and test our method through comprehensive experiments on difficult medical imaging and zero-shot classification tasks. Our results show that selective recalibration consistently leads to significantly lower calibration error than a wide range of selection and recalibration baselines",
    "checked": true,
    "id": "db0b23b1611276cfcd423699155c72175a1ba14f",
    "semantic_title": "improving predictor reliability with selective recalibration",
    "citation_count": 0,
    "authors": [
      "Thomas P Zollo",
      "Zhun Deng",
      "Jake Snell",
      "Toniann Pitassi",
      "Richard Zemel"
    ]
  },
  "https://openreview.net/forum?id=dLaazW9zuF": {
    "title": "Multi-Fidelity Active Learning with GFlowNets",
    "volume": "expert",
    "abstract": "In the last decades, the capacity to generate large amounts of data in science and engineering applications has been growing steadily. Meanwhile, machine learning has progressed to become a suitable tool to process and utilise the available data. Nonetheless, many relevant scientific and engineering problems present challenges where current machine learning methods cannot yet efficiently leverage the available data and resources. For example, in scientific discovery, we are often faced with the problem of exploring very large, structured and high-dimensional spaces. Moreover, the high fidelity, black-box objective function is often very expensive to evaluate. Progress in machine learning methods that can efficiently tackle such challenges would help accelerate currently crucial areas such as drug and materials discovery. In this paper, we propose a multi-fidelity active learning algorithm with GFlowNets as a sampler, to efficiently discover diverse, high-scoring candidates where multiple approximations of the black-box function are available at lower fidelity and cost. Our evaluation on molecular discovery tasks shows that multi-fidelity active learning with GFlowNets can discover high-scoring candidates at a fraction of the budget of its single-fidelity counterpart while maintaining diversity, unlike RL-based alternatives. These results open new avenues for multi-fidelity active learning to accelerate scientific discovery and engineering design",
    "checked": true,
    "id": "2e065651fe8851238544cecb4185811744af5300",
    "semantic_title": "multi-fidelity active learning with gflownets",
    "citation_count": 15,
    "authors": [
      "Alex HernÃ¡ndez-GarcÃ­a",
      "Nikita Saxena",
      "Moksh Jain",
      "Cheng-Hao Liu",
      "Yoshua Bengio"
    ]
  },
  "https://openreview.net/forum?id=q2AbLOwmHm": {
    "title": "Incorporating Unlabelled Data into Bayesian Neural Networks",
    "volume": "expert",
    "abstract": "Conventional Bayesian Neural Networks (BNNs) are unable to leverage unlabelled data to improve their predictions. To overcome this limitation, we introduce Self-Supervised Bayesian Neural Networks, which use unlabelled data to learn models with suitable prior predictive distributions. This is achieved by leveraging contrastive pretraining techniques and optimising a variational lower bound. We then show that the prior predictive distributions of self-supervised BNNs capture problem semantics better than conventional BNN priors. In turn, our approach offers improved predictive performance over conventional BNNs, especially in low-budget regimes",
    "checked": true,
    "id": "958e9c67dbd4da171c334db14a325cdfcc4f9215",
    "semantic_title": "incorporating unlabelled data into bayesian neural networks",
    "citation_count": 10,
    "authors": [
      "Mrinank Sharma",
      "Tom Rainforth",
      "Yee Whye Teh",
      "Vincent Fortuin"
    ]
  },
  "https://openreview.net/forum?id=mKtlzW0bWc": {
    "title": "CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion",
    "volume": "expert",
    "abstract": "This paper proposes a novel diffusion-based model, CompoDiff, for solving zero-shot Composed Image Retrieval (ZS-CIR) with latent diffusion. This paper also introduces a new synthetic dataset, named SynthTriplets18M, with 18.8 million reference images, conditions, and corresponding target image triplets to train CIR models. CompoDiff and SynthTriplets18M tackle the shortages of the previous CIR approaches, such as poor generalizability due to the small dataset scale and the limited types of conditions. CompoDiff not only achieves a new state-of-the-art on four ZS-CIR benchmarks, including FashionIQ, CIRR, CIRCO, and GeneCIS, but also enables a more versatile and controllable CIR by accepting various conditions, such as negative text, and image mask conditions. CompoDiff also shows the controllability of the condition strength between text and image queries and the trade-off between inference speed and performance, which are unavailable with existing CIR methods. The code and dataset samples are available at https://github.com/navervision/CompoDiff",
    "checked": true,
    "id": "b6eb82fc94cacdf4575fe509ef437634bf090ac2",
    "semantic_title": "compodiff: versatile composed image retrieval with latent diffusion",
    "citation_count": 57,
    "authors": [
      "Geonmo Gu",
      "Sanghyuk Chun",
      "Wonjae Kim",
      "HeeJae Jun",
      "Yoohoon Kang",
      "Sangdoo Yun"
    ]
  },
  "https://openreview.net/forum?id=iRDwUXYsSJ": {
    "title": "Differential Equation Scaling Limits of Shaped and Unshaped Neural Networks",
    "volume": "expert",
    "abstract": "Recent analyses of neural networks with shaped activations (i.e. the activation function is scaled as the network size grows) have led to scaling limits described by differential equations. However, these results do not a priori tell us anything about ``ordinary'' unshaped networks, where the activation is unchanged as the network size grows. In this article, we find similar differential equation based asymptotic characterization for two types of unshaped networks. Firstly, we show that the following two architectures converge to the same infinite-depth-and-width limit at initialization: (i) a fully connected ResNet with a $d^{-1/2}$ factor on the residual branch, where $d$ is the network depth. (ii) a multilayer perceptron (MLP) with depth $d \\ll$ width $n$ and shaped ReLU activation at rate $d^{-1/2}$. Secondly, for an unshaped MLP at initialization, we derive the first order asymptotic correction to the layerwise correlation. In particular, if $\\rho_\\ell$ is the correlation at layer $\\ell$, then $q_t = \\ell^2 (1 - \\rho_\\ell)$ with $t = \\frac{\\ell}{n}$ converges to an SDE with a singularity at $t=0$. These results together provide a connection between shaped and unshaped network architectures, and opens up the possibility of studying the effect of normalization methods and how it connects with shaping activation functions",
    "checked": true,
    "id": "196803e4e33df1c35f1f05ba988c9508cc80c989",
    "semantic_title": "differential equation scaling limits of shaped and unshaped neural networks",
    "citation_count": 2,
    "authors": [
      "Mufan Bill Li",
      "Mihai Nica"
    ]
  },
  "https://openreview.net/forum?id=lNAyUngGFK": {
    "title": "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models",
    "volume": "expert",
    "abstract": "Fine-tuning language models~(LMs) on human-generated data remains a prevalent practice. However, the performance of such models is often limited by the quantity and diversity of high-quality human data. In this paper, we explore whether we can go beyond human data on tasks where we have access to scalar feedback, for example, on math problems where one can verify correctness. To do so, we investigate a simple self-training method based on expectation-maximization, which we call \\method, where we (1) generate samples from the model and filter them using binary feedback, (2) fine-tune the model on these samples, and (3) repeat this process a few times. Testing on advanced MATH reasoning and APPS coding benchmarks using PaLM-2 models, we find that \\method{} scales favorably with model size and significantly surpasses fine-tuning only on human data. Overall, our findings suggest self-training with feedback can reduce dependence on human-generated data",
    "checked": true,
    "id": "48362b169a235ca650918c489c8cea4c597da645",
    "semantic_title": "beyond human data: scaling self-training for problem-solving with language models",
    "citation_count": 190,
    "authors": [
      "Avi Singh",
      "John D Co-Reyes",
      "Rishabh Agarwal",
      "Ankesh Anand",
      "Piyush Patil",
      "Xavier Garcia",
      "Peter J Liu",
      "James Harrison",
      "Jaehoon Lee",
      "Kelvin Xu",
      "Aaron T Parisi",
      "Abhishek Kumar",
      "Alexander A Alemi",
      "Alex Rizkowsky",
      "Azade Nova",
      "Ben Adlam",
      "Bernd Bohnet",
      "Gamaleldin Fathy Elsayed",
      "Hanie Sedghi",
      "Igor Mordatch",
      "Isabelle Simpson",
      "Izzeddin Gur",
      "Jasper Snoek",
      "Jeffrey Pennington",
      "Jiri Hron",
      "Kathleen Kenealy",
      "Kevin Swersky",
      "Kshiteej Mahajan",
      "Laura A Culp",
      "Lechao Xiao",
      "Maxwell Bileschi",
      "Noah Constant",
      "Roman Novak",
      "Rosanne Liu",
      "Tris Warkentin",
      "Yamini Bansal",
      "Ethan Dyer",
      "Behnam Neyshabur",
      "Jascha Sohl-Dickstein",
      "Noah Fiedel"
    ]
  },
  "https://openreview.net/forum?id=CD9Snc73AW": {
    "title": "Improving and generalizing flow-based generative models with minibatch optimal transport",
    "volume": "expert",
    "abstract": "Continuous normalizing flows (CNFs) are an attractive generative modeling technique, but they have been held back by limitations in their simulation-based maximum likelihood training. We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs. CFM features a stable regression objective like that used to train the stochastic flow in diffusion models but enjoys the efficient inference of deterministic flow models. In contrast to both diffusion models and prior CNF training algorithms, CFM does not require the source distribution to be Gaussian or require evaluation of its density. A variant of our objective is optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference, as evaluated in our experiments. Furthermore, we show that when the true OT plan is available, our OT-CFM method approximates dynamic OT. Training CNFs with CFM improves results on a variety of conditional and unconditional generation tasks, such as inferring single cell dynamics, unsupervised image translation, and SchrÃ¶dinger bridge inference. The Python code is available at https://github.com/atong01/conditional-flow-matching",
    "checked": true,
    "id": "5396c55bee2a2abf2207e1cc5e5ae72c9edef9fa",
    "semantic_title": "improving and generalizing flow-based generative models with minibatch optimal transport",
    "citation_count": 304,
    "authors": [
      "Alexander Tong",
      "Kilian FATRAS",
      "Nikolay Malkin",
      "Guillaume Huguet",
      "Yanlei Zhang",
      "Jarrid Rector-Brooks",
      "Guy Wolf",
      "Yoshua Bengio"
    ]
  },
  "https://openreview.net/forum?id=YH3oERVYjF": {
    "title": "A density estimation perspective on learning from pairwise human preferences",
    "volume": "expert",
    "abstract": "Learning from human feedback (LHF)âand in particular learning from pairwise preferencesâhas recently become a crucial ingredient in training large language models (LLMs), and has been the subject of much research. Most recent works frame it as a reinforcement learning problem, where a reward function is learned from pairwise preference data and the LLM is treated as a policy which is adapted to maximize the rewards, often under additional regularization constraints. We propose an alternative interpretation which centers on the generative process for pairwise preferences and treats LHF as a density estimation problem. We provide theoretical and empirical results showing that for a family of generative processes defined via preference behavior distribution equations, training a reward function on pairwise preferences effectively models an annotator's implicit preference distribution. Finally, we discuss and present findings on \"annotator misspecification\"âfailure cases where wrong modeling assumptions are made about annotator behavior, resulting in poorly-adapted modelsâsuggesting that approaches that learn from pairwise human preferences could have trouble learning from a population of annotators with diverse viewpoints",
    "checked": true,
    "id": "12cf8be0865649b5e878051182b69f51e67fb8d4",
    "semantic_title": "a density estimation perspective on learning from pairwise human preferences",
    "citation_count": 15,
    "authors": [
      "Vincent Dumoulin",
      "Daniel D. Johnson",
      "Pablo Samuel Castro",
      "Hugo Larochelle",
      "Yann Dauphin"
    ]
  },
  "https://openreview.net/forum?id=vFSsRYGpjW": {
    "title": "Distributional GFlowNets with Quantile Flows",
    "volume": "expert",
    "abstract": "Generative Flow Networks (GFlowNets) are a new family of probabilistic samplers where an agent learns a stochastic policy for generating complex combinatorial structure through a series of decision-making steps. There have been recent successes in applying GFlowNets to a number of practical domains where diversity of the solutions is crucial, while reinforcement learning aims to learn an optimal solution based on the given reward function only and fails to discover diverse and high-quality solutions. However, the current GFlowNet framework is relatively limited in its applicability and cannot handle stochasticity in the reward function. In this work, we adopt a distributional paradigm for GFlowNets, turning each flow function into a distribution, thus providing more informative learning signals during training. By parameterizing each edge flow through their quantile functions, our proposed \\textit{quantile matching} GFlowNet learning algorithm is able to learn a risk-sensitive policy, an essential component for handling scenarios with risk uncertainty. Moreover, we find that the distributional approach can achieve substantial improvement on existing benchmarks compared to prior methods due to our enhanced training algorithm, even in settings with deterministic rewards",
    "checked": true,
    "id": "8031bfd2408b9fa41e85b346b9452ebd63073076",
    "semantic_title": "distributional gflownets with quantile flows",
    "citation_count": 28,
    "authors": [
      "Dinghuai Zhang",
      "Ling Pan",
      "Ricky T. Q. Chen",
      "Aaron Courville",
      "Yoshua Bengio"
    ]
  },
  "https://openreview.net/forum?id=Ytp9KFKZfZ": {
    "title": "Leveraging Function Space Aggregation for Federated Learning at Scale",
    "volume": "expert",
    "abstract": "The federated learning paradigm has motivated the development of methods for aggregating multiple client updates into a global server model, without sharing client data. Many federated learning algorithms, including the canonical Federated Averaging (FedAvg), take a direct (possibly weighted) average of the client parameter updates, motivated by results in distributed optimization. In this work, we adopt a function space perspective and propose a new algorithm, FedFish, that aggregates local approximations to the functions learned by clients, using an estimate based on their Fisher information. We evaluate FedFish on realistic, large-scale cross-device benchmarks. While the performance of FedAvg can suffer as client models drift further apart, we demonstrate that FedFish is more robust to longer local training. Our evaluation across several settings in image and language benchmarks shows that FedFish outperforms FedAvg as local training epochs increase. Further, FedFish results in global networks that are more amenable to efficient personalization via local fine-tuning on the same or shifted data distributions. For instance, federated pretraining on the C4 dataset, followed by few-shot personalization on Stack Overflow, results in a 7% improvement in next-token prediction by FedFish over FedAvg",
    "checked": true,
    "id": "ea88649be9fbc54d49833edcf8903df21afb5f6f",
    "semantic_title": "leveraging function space aggregation for federated learning at scale",
    "citation_count": 3,
    "authors": [
      "Nikita Dhawan",
      "Nicole Elyse Mitchell",
      "Zachary Charles",
      "Zachary Garrett",
      "Gintare Karolina Dziugaite"
    ]
  },
  "https://openreview.net/forum?id=UAT4j3Y7HP": {
    "title": "Break it, Imitate it, Fix it: Robustness by Generating Human-Like Attacks",
    "volume": "expert",
    "abstract": "Real-world natural language processing systems need to be robust to human adversaries. Collecting examples of human adversaries for training is an effective but expensive solution. On the other hand, training on synthetic attacks with small perturbations---such as word-substitution---does not actually improve robustness to human adversaries. In this paper, we propose an adversarial training framework that uses limited human adversarial examples to generate more useful adversarial examples at scale. We demonstrate the advantages of this system on the ANLI and hate speech detection benchmark datasets---both collected via an iterative, adversarial human-and-model-in-the-loop procedure. Compared to training only on observed human attacks, also training on our synthetic adversarial examples improves model robustness to future rounds. In ANLI, we see accuracy gains on the current set of attacks (44.1\\%$\\,\\to\\,$50.1\\%) and on two future unseen rounds of human generated attacks (32.5\\%$\\,\\to\\,$43.4\\%, and 29.4\\%$\\,\\to\\,$40.2\\%). In hate speech detection, we see AUC gains on current attacks (0.76 $\\to$ 0.84) and a future round (0.77 $\\to$ 0.79). Attacks from methods that do not learn the distribution of existing human adversaries, meanwhile, degrade robustness",
    "checked": true,
    "id": "9262e201ecaf678429bf86481b1c1d1ae6332b44",
    "semantic_title": "break it, imitate it, fix it: robustness by generating human-like attacks",
    "citation_count": 4,
    "authors": [
      "Aradhana Sinha",
      "Ananth Balashankar",
      "Ahmad Beirami",
      "Thi Avrahami",
      "Jilin Chen",
      "Alex Beutel"
    ]
  },
  "https://openreview.net/forum?id=ga5SNulYet": {
    "title": "Wavelet Networks: Scale-Translation Equivariant Learning From Raw Time-Series",
    "volume": "expert",
    "abstract": "Leveraging the symmetries inherent to specific data domains for the construction of equivariant neural networks has lead to remarkable improvements in terms of data efficiency and generalization. However, most existing research focuses on symmetries arising from planar and volumetric data, leaving a crucial data source largely underexplored: *time-series*. In this work, we fill this gap by leveraging the symmetries inherent to time-series for the construction of equivariant neural network. We identify two core symmetries: *scale and translation*, and construct scale-translation equivariant neural networks for time-series learning. Intriguingly, we find that scale-translation equivariant mappings share strong resemblance with the *wavelet transform*. Inspired by this resemblance, we term our networks *Wavelet Networks*, and show that they perform nested non-linear wavelet-like time-frequency transforms. Empirical results show that Wavelet Networks outperform conventional CNNs on raw waveforms, and match strongly engineered spectrogram techniques across several tasks and time-series types, including audio, environmental sounds, and electrical signals. Our code is publicly available at https://github.com/dwromero/wavelet_networks",
    "checked": false,
    "id": "1ad1d4691c74f25a6d3548214bcd1b2c10611bce",
    "semantic_title": "sossf: landsat-8 image synthesis on the blending of sentinel-1 and modis data",
    "citation_count": 1,
    "authors": [
      "David W. Romero",
      "Erik J Bekkers",
      "Jakub M. Tomczak",
      "Mark Hoogendoorn"
    ]
  },
  "https://openreview.net/forum?id=lTOku838Zv": {
    "title": "Neural Implicit Manifold Learning for Topology-Aware Density Estimation",
    "volume": "expert",
    "abstract": "Natural data observed in $\\mathbb{R}^n$ is often constrained to an $m$-dimensional manifold $\\mathcal{M}$, where $m < n$. This work focuses on the task of building theoretically principled generative models for such data. Current generative models learn $\\mathcal{M}$ by mapping an $m$-dimensional latent variable through a neural network $f_\\theta: \\mathbb{R}^m \\to \\mathbb{R}^n$. These procedures, which we call pushforward models, incur a straightforward limitation: manifolds cannot in general be represented with a single parameterization, meaning that attempts to do so will incur either computational instability or the inability to learn probability densities within the manifold. To remedy this problem, we propose to model $\\mathcal{M}$ as a neural implicit manifold: the set of zeros of a neural network. We then learn the probability density within $\\mathcal{M}$ with a constrained energy-based model, which employs a constrained variant of Langevin dynamics to train and sample from the learned manifold. In experiments on synthetic and natural data, we show that our model can learn manifold-supported distributions with complex topologies more accurately than pushforward models",
    "checked": true,
    "id": "914b2aed4d0938d7dce4695d1c25069ea68a1d37",
    "semantic_title": "neural implicit manifold learning for topology-aware density estimation",
    "citation_count": 3,
    "authors": [
      "Brendan Leigh Ross",
      "Gabriel Loaiza-Ganem",
      "Anthony L. Caterini",
      "Jesse C. Cresswell"
    ]
  },
  "https://openreview.net/forum?id=nvmGBcElus": {
    "title": "Risk-Controlling Model Selection via Guided Bayesian Optimization",
    "volume": "main",
    "abstract": "Adjustable hyperparameters of machine learning models typically impact various key trade-offs such as accuracy, fairness, robustness, or inference cost. Our goal in this paper is to find a configuration that adheres to user-specified limits on certain risks while being useful with respect to other conflicting metrics. We solve this by combining Bayesian Optimization (BO) with rigorous risk-controlling procedures, where our core idea is to steer BO towards an efficient testing strategy. Our BO method identifies a set of Pareto optimal configurations residing in a designated region of interest. The resulting candidates are statistically verified, and the best-performing configuration is selected with guaranteed risk levels. We demonstrate the effectiveness of our approach on a range of tasks with multiple desiderata, including low error rates, equitable predictions, handling spurious correlations, managing rate and distortion in generative models, and reducing computational costs",
    "checked": null,
    "id": "c88c4d8c2689e463afcf54f47320305e75b94000",
    "semantic_title": "risk-controlling model selection via guided bayesian optimization",
    "citation_count": 4,
    "authors": [
      "Bracha Laufer-Goldshtein",
      "Adam Fisch",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ]
  },
  "https://openreview.net/forum?id=tHKH4DNSR5": {
    "title": "Equivariant Symmetry Breaking Sets",
    "volume": "main",
    "abstract": "Equivariant neural networks (ENNs) have been shown to be extremely effective in applications involving underlying symmetries. By construction ENNs cannot produce lower symmetry outputs given a higher symmetry input. However, symmetry breaking occurs in many physical systems and we may obtain a less symmetric stable state from an initial highly symmetric one. Hence, it is imperative that we understand how to systematically break symmetry in ENNs. In this work, we propose a novel symmetry breaking framework that is fully equivariant and is the first which fully addresses spontaneous symmetry breaking. We emphasize that our approach is general and applicable to equivariance under any group. To achieve this, we introduce the idea of symmetry breaking sets (SBS). Rather than redesign existing networks, we design sets of symmetry breaking objects which we feed into our network based on the symmetry of our inputs and outputs. We show there is a natural way to define equivariance on these sets, which gives an additional constraint. Minimizing the size of these sets equates to data efficiency. We prove that minimizing these sets translates to a well studied group theory problem, and tabulate solutions to this problem for the point groups. Finally, we provide some examples of symmetry breaking to demonstrate how our approach works in practice. The code for these examples is available at \\url{https://github.com/atomicarchitects/equivariant-SBS}",
    "checked": null,
    "id": "9dcd23f8fd284d91cb92e39bfe9caed01c527ef1",
    "semantic_title": "equivariant symmetry breaking sets",
    "citation_count": 4,
    "authors": [
      "YuQing Xie",
      "Tess Smidt"
    ]
  },
  "https://openreview.net/forum?id=wnI4sJtjqL": {
    "title": "VideoGLUE: Video General Understanding Evaluation of Foundation Models",
    "volume": "main",
    "abstract": "We evaluate the video understanding capabilities of existing foundation models (FMs) using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition,temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring an FM for downstream tasks. Furthermore,we jointly profile FMs' efficacy and efficiency when adapting to general video understanding tasks using cost measurements during both training and inference. Our main findings areas follows. First, task-specialized models significantly outperform the seven FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding. Second, video-native FMs, whose pretraining data mainly contains the video modality, are generally better than image-native FMs in classifying motion-rich videos,localizing actions in time, and understanding a video of more than one action. Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks (e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning. The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs. Our code is released under: https://github.com/tensorflow/models/tree/master/official/projects/videoglue",
    "checked": null,
    "id": "c5202ab27294d5c1eb4d2f0ca7e82afef91888f0",
    "semantic_title": "videoglue: video general understanding evaluation of foundation models",
    "citation_count": 10,
    "authors": [
      "Liangzhe Yuan",
      "Nitesh Bharadwaj Gundavarapu",
      "Long Zhao",
      "Hao Zhou",
      "Yin Cui",
      "Lu Jiang",
      "Xuan Yang",
      "Menglin Jia",
      "Tobias Weyand",
      "Luke Friedman",
      "Mikhail Sirotenko",
      "Huisheng Wang",
      "Florian Schroff",
      "Hartwig Adam",
      "Ming-Hsuan Yang",
      "Ting Liu",
      "Boqing Gong"
    ]
  },
  "https://openreview.net/forum?id=6XPwSwEWsV": {
    "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford Algebra and Convexity",
    "volume": "main",
    "abstract": "In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers",
    "checked": null,
    "id": "225c03141144b21de4ab8f2da2ffc0a6b98837c6",
    "semantic_title": "from complexity to clarity: analytical expressions of deep neural network weights via clifford algebra and convexity",
    "citation_count": 1,
    "authors": [
      "Mert Pilanci"
    ]
  },
  "https://openreview.net/forum?id=8Vk1Bmg3sY": {
    "title": "Controlling the Fidelity and Diversity of Deep Generative Models via Pseudo Density",
    "volume": "main",
    "abstract": "We introduce an approach to bias deep generative models, such as GANs and diffusion models, towards generating data with either enhanced fidelity or increased diversity. Our approach involves manipulating the distribution of training and generated data through a novel metric for individual samples, named pseudo density, which is based on the nearest-neighbor information from real samples. Our approach offers three distinct techniques to adjust the fidelity and diversity of deep generative models: 1) Per-sample perturbation, enabling precise adjustments for individual samples towards either more common or more unique characteristics; 2) Importance sampling during model inference to enhance either fidelity or diversity in the generated data; 3) Fine-tuning with importance sampling, which guides the generative model to learn an adjusted distribution, thus controlling fidelity and diversity. Furthermore, our fine-tuning method demonstrates the ability to improve the Frechet Inception Distance (FID) for pre-trained generative models with minimal iterations",
    "checked": null,
    "id": "e2f8b9d7fb85e49fa32112486766e6b8ceaefd13",
    "semantic_title": "controlling the fidelity and diversity of deep generative models via pseudo density",
    "citation_count": 2,
    "authors": [
      "Shuangqi Li",
      "Chen Liu",
      "Tong Zhang",
      "Hieu Le",
      "Sabine Susstrunk",
      "Mathieu Salzmann"
    ]
  },
  "https://openreview.net/forum?id=MMtK0kUML7": {
    "title": "Generating Less Certain Adversarial Examples Improves Robust Generalization",
    "volume": "main",
    "abstract": "This paper revisits the robust overfitting phenomenon of adversarial training. Observing that models with better robust generalization performance are less certain in predicting adversarially generated training inputs, we argue that overconfidence in predicting adversarial examples is a potential cause. Therefore, we propose a formal definition of adversarial certainty that captures the variance of the model's predicted logits on adversarial examples and hypothesize that generating adversarial examples after the optimization of decreasing adversarial certainty improves robust generalization. Our theoretical analysis of synthetic distributions characterizes the connection between adversarial certainty and robust generalization. Accordingly, built upon the notion of adversarial certainty, we develop a general method to search for models that can generate training-time adversarial inputs with reduced certainty, while maintaining the model's capability in distinguishing adversarial examples. Extensive experiments on image benchmarks demonstrate that our method effectively learns models with consistently improved robustness and mitigates robust overfitting, confirming the importance of generating less certain adversarial examples for robust generalization. Our implementations are available as open-source code at: \\url{https://github.com/TrustMLRG/AdvCertainty}",
    "checked": null,
    "id": "83792509864acba5e083b09be1f9db4bb4904cb2",
    "semantic_title": "generating less certain adversarial examples improves robust generalization",
    "citation_count": 1,
    "authors": [
      "Minxing Zhang",
      "Michael Backes",
      "Xiao Zhang"
    ]
  },
  "https://openreview.net/forum?id=h2C3rkn0zR": {
    "title": "Recurrent Inertial Graph-Based Estimator (RING): A Single Pluripotent Inertial Motion Tracking Solution",
    "volume": "main",
    "abstract": "This paper introduces a novel ML-based method for Inertial Motion Tracking (IMT) that fundamentally changes the way this technology is used. The proposed method, named RING (Recurrent Inertial Graph-Based Estimator), provides a pluripotent, problem-unspecific plug-and-play IMT solution that, in contrast to conventional IMT solutions, eliminates the need for expert knowledge to identify, select, and parameterize the appropriate method. RING's pluripotency is enabled by a novel online-capable neural network architecture that uses a decentralized network of message-passing, parameter-sharing recurrent neural networks, which map local IMU measurements and nearest-neighbour messages to local orientations. This architecture enables RING to address a broad range of IMT problems that vary greatly in aspects such as the number of attached sensors, or the number of segments in the kinematic chain, and even generalize to previously unsolved IMT problems, including the challenging combination of magnetometer-free and sparse sensing with unknown sensor-to-segment parameters. Remarkably, RING is trained solely on simulated data, yet evaluated on experimental data, which indicates its exceptional ability to zero-shot generalize from simulation to experiment, while outperforming several state-of-the-art problem-specific solutions. For example, RING can, for the first time, accurately track a four-segment kinematic chain (which requires estimating four orientations) using only two magnetometer-free inertial measurement units. This research not only makes IMT more powerful and less restrictive in established domains ranging from biomechanics to autonomous systems, but also opens its application to new users and fields previously untapped by motion tracking technology. Code and data is available at https://github.com/simon-bachhuber/ring_supplementary_material",
    "checked": null,
    "id": "3d1f7c2d1f2c914c3dba3f83e6485dafe54739de",
    "semantic_title": "recurrent inertial graph-based estimator (ring): a single pluripotent inertial motion tracking solution",
    "citation_count": 0,
    "authors": [
      "Simon Bachhuber",
      "Ive Weygers",
      "Dustin Lehmann",
      "Mischa Dombrowski",
      "Thomas Seel"
    ]
  },
  "https://openreview.net/forum?id=dyQ9vFbF6D": {
    "title": "Plug, Play, and Generalize: Length Extrapolation with Pointer-Augmented Neural Memory",
    "volume": "main",
    "abstract": "We introduce Pointer-Augmented Neural Memory (PANM), a versatile module designed to enhance neural networks' ability to process symbols and extend their capabilities to longer data sequences. PANM integrates an external neural memory utilizing novel physical addresses and pointer manipulation techniques, emulating human and computer-like symbol processing abilities. PANM facilitates operations like pointer assignment, dereferencing, and arithmetic by explicitly employing physical pointers for memory access. This module can be trained end-to-end on sequence data, empowering various sequential models, from simple recurrent networks to large language models (LLMs). Our experiments showcase PANM's exceptional length extrapolation capabilities and its enhancement of recurrent neural networks in symbol processing tasks, including algorithmic reasoning and Dyck language recognition. PANM enables Transformers to achieve up to 100% generalization accuracy in compositional learning tasks and significantly improves performance in mathematical reasoning, question answering, and machine translation. Notably, the generalization effectiveness scales with stronger backbone models, as evidenced by substantial performance gains when we test LLMs finetuned with PANM for tasks up to 10-100 times longer than the training data",
    "checked": null,
    "id": "5915c22bc7717006bf58b295e9bdd7d798493041",
    "semantic_title": "plug, play, and generalize: length extrapolation with pointer-augmented neural memory",
    "citation_count": 0,
    "authors": [
      "Hung Le",
      "Dung Nguyen",
      "Kien Do",
      "Svetha Venkatesh",
      "Truyen Tran"
    ]
  },
  "https://openreview.net/forum?id=BqSi73krYd": {
    "title": "UCB Exploration for Fixed-Budget Bayesian Best Arm Identification",
    "volume": "main",
    "abstract": "We study best-arm identification (BAI) in the fixed-budget setting. Adaptive allocations based on upper confidence bounds (UCBs), such as UCBE, are known to work well in BAI. However, it is well-known that its optimal regret is theoretically dependent on instances, which we show to be an artifact in many fixed-budget BAI problems. In this paper we propose an UCB exploration algorithm that is both theoretically and empirically efficient for the fixed budget BAI problem under a Bayesian setting. The key idea is to learn prior information, which can enhance the performance of UCB-based BAI algorithm as it has done in the cumulative regret minimization problem. We establish bounds on the failure probability and the simple regret for the Bayesian BAI problem, providing upper bounds of order $\\tilde{O}(\\sqrt{K/n})$, up to logarithmic factors, where $n$ represents the budget and $K$ denotes the number of arms. Furthermore, we demonstrate through empirical results that our approach consistently outperforms state-of-the-art baselines",
    "checked": null,
    "id": "a3f3de9cf2fdc30298768847982a100deefc366c",
    "semantic_title": "ucb exploration for fixed-budget bayesian best arm identification",
    "citation_count": 0,
    "authors": [
      "Rong J.B. Zhu",
      "Yanqi Qiu"
    ]
  },
  "https://openreview.net/forum?id=JmKAYb7I00": {
    "title": "Revisiting Energy Based Models as Policies: Ranking Noise Contrastive Estimation and Interpolating Energy Models",
    "volume": "main",
    "abstract": "A crucial design decision for any robot learning pipeline is the choice of policy representation: what type of model should be used to generate the next set of robot actions? Owing to the inherent multi-modal nature of many robotic tasks, combined with the recent successes in generative modeling, researchers have turned to state-of-the-art probabilistic models such as diffusion models for policy representation. In this work, we revisit the choice of energy-based models (EBM) as a policy class. We show that the prevailing folklore---that energy models in high dimensional continuous spaces are impractical to train---is false. We develop a practical training objective and algorithm for energy models which combines several key ingredients: (i) ranking noise contrastive estimation (R-NCE), (ii) learnable negative samplers, and (iii) non-adversarial joint training. We prove that our proposed objective function is asymptotically consistent and quantify its limiting variance. On the other hand, we show that the Implicit Behavior Cloning (IBC) objective is actually biased even at the population level, providing a mathematical explanation for the poor performance of IBC trained energy policies in several independent follow-up works. We further extend our algorithm to learn a continuous stochastic process that bridges noise and data, modeling this process with a family of EBMs indexed by scale variable. In doing so, we demonstrate that the core idea behind recent progress in generative modeling is actually compatible with EBMs. Altogether, our proposed training algorithms enable us to train energy-based models as policies which compete with---and even outperform---diffusion models and other state-of-the-art approaches in several challenging multi-modal benchmarks: obstacle avoidance path planning and contact-rich block pushing",
    "checked": null,
    "id": "2e540ee579608898aa2c958c890e673ed3b26a50",
    "semantic_title": "revisiting energy based models as policies: ranking noise contrastive estimation and interpolating energy models",
    "citation_count": 0,
    "authors": [
      "Sumeet Singh",
      "Stephen Tu",
      "Vikas Sindhwani"
    ]
  },
  "https://openreview.net/forum?id=lM4nHnxGfL": {
    "title": "Learning multi-modal generative models with permutation-invariant encoders and tighter variational objectives",
    "volume": "main",
    "abstract": "Devising deep latent variable models for multi-modal data has been a long-standing theme in machine learning research. Multi-modal Variational Autoencoders (VAEs) have been a popular generative model class that learns latent representations that jointly explain multiple modalities. Various objective functions for such models have been suggested, often motivated as lower bounds on the multi-modal data log-likelihood or from information-theoretic considerations. To encode latent variables from different modality subsets, Product-of-Experts (PoE) or Mixture-of-Experts (MoE) aggregation schemes have been routinely used and shown to yield different trade-offs, for instance, regarding their generative quality or consistency across multiple modalities. In this work, we consider a variational objective that can tightly approximate the data log-likelihood. We develop more flexible aggregation schemes that avoid the inductive biases in PoE or MoE approaches by combining encoded features from different modalities based on permutation-invariant neural networks. Our numerical experiments illustrate trade-offs for multi-modal variational objectives and various aggregation schemes. We show that our variational objective and more flexible aggregation models can become beneficial when one wants to approximate the true joint distribution over observed modalities and latent variables in identifiable models",
    "checked": null,
    "id": "c5dbea8f5c0068f6bafe74de91133e00ea386be2",
    "semantic_title": "learning multi-modal generative models with permutation-invariant encoders and tighter variational objectives",
    "citation_count": 0,
    "authors": [
      "Marcel Hirt",
      "Domenico Campolo",
      "Victoria Leong",
      "Juan-Pablo Ortega"
    ]
  },
  "https://openreview.net/forum?id=yfrNkb2Ldd": {
    "title": "Noise Stability Optimization for Finding Flat Minima: A Hessian-based Regularization Approach",
    "volume": "main",
    "abstract": "The training of over-parameterized neural networks has received much study in recent literature. An important consideration is the regularization of over-parameterized networks due to their highly nonconvex and nonlinear geometry. In this paper, we study noise injection algorithms, which can regularize the Hessian of the loss, leading to regions with flat loss surfaces. Specifically, by injecting isotropic Gaussian noise into the weight matrices of a neural network, we can obtain an approximately unbiased estimate of the trace of the Hessian. However, naively implementing the noise injection via adding noise to the weight matrices before backpropagation presents limited empirical improvements. To address this limitation, we design a two-point estimate of the Hessian penalty, which injects noise into the weight matrices along both positive and negative directions of the random noise. In particular, this two-point estimate eliminates the variance of the first-order Taylor's expansion term on the Hessian. We show a PAC-Bayes generalization bound that depends on the trace of the Hessian (and the radius of the weight space), which can be measured from data. We conduct a detailed experimental study to validate our approach and show that it can effectively regularize the Hessian and improve generalization. First, our algorithm can outperform prior approaches on sharpness-reduced training, delivering up to a 2.4% test accuracy increase for fine-tuning ResNets on six image classification datasets. Moreover, the trace of the Hessian reduces by 15.8%, and the largest eigenvalue is reduced by 9.7% with our approach. We also find that the regularization of the Hessian can be combined with alternative regularization methods, such as weight decay and data augmentation, leading to stronger regularization. Second, our approach remains highly effective for improving generalization in pretraining multimodal CLIP models and chain-of-thought fine-tuning",
    "checked": null,
    "id": "42040bdac466bfd89341110ff62df3df0b63e423",
    "semantic_title": "noise stability optimization for finding flat minima: a hessian-based regularization approach",
    "citation_count": 5,
    "authors": [
      "Hongyang R. Zhang",
      "Dongyue Li",
      "Haotian Ju"
    ]
  },
  "https://openreview.net/forum?id=zVDMh6JvWc": {
    "title": "A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization",
    "volume": "main",
    "abstract": "We propose NeuFace, a 3D face mesh pseudo annotation method on videos via neural re-parameterized optimization. Despite the huge progress in 3D face reconstruction methods, generating reliable 3D face labels for in-the-wild dynamic videos remains challenging. Using NeuFace optimization, we annotate the per-view/-frame accurate and consistent face meshes on large-scale face videos, called the NeuFace-dataset. We investigate how neural re-parameterization helps to reconstruct image-aligned facial details on 3D meshes via gradient analysis. By exploiting the naturalness and diversity of 3D faces in our dataset, we demonstrate the usefulness of our dataset for 3D face-related tasks: improving the reconstruction accuracy of an existing 3D face reconstruction model and learning 3D facial motion prior",
    "checked": null,
    "id": "303cbce0db4b020c99a39ee35c968153354029dd",
    "semantic_title": "a large-scale 3d face mesh video dataset via neural re-parameterized optimization",
    "citation_count": 3,
    "authors": [
      "Kim Youwang",
      "Lee Hyun",
      "Kim Sung-Bin",
      "Suekyeong Nam",
      "Janghoon Ju",
      "Tae-Hyun Oh"
    ]
  },
  "https://openreview.net/forum?id=OcFjqiJ98b": {
    "title": "PCNN: Probable-Class Nearest-Neighbor Explanations Improve Fine-Grained Image Classification Accuracy for AIs and Humans",
    "volume": "main",
    "abstract": "Nearest neighbors (NN) are traditionally used to compute final decisions, e.g., in Support Vector Machines or k-NN classifiers, and to provide users with explanations for the model's decision. In this paper, we show a novel utility of nearest neighbors: To improve predictions of a frozen, pretrained image classifier C. We leverage an image comparator S that (1) compares the input image with NN images from the top-K most probable classes given by C; and (2) uses scores from S to weight the confidence scores of C to refine predictions. Our method consistently improves fine-grained image classification accuracy on CUB-200, Cars-196, and Dogs-120. Also, a human study finds that showing users our probable-class nearest neighbors (PCNN) reduces over-reliance on AI, thus improving their decision accuracy over prior work which only shows only the most-probable (top-1) class examples",
    "checked": null,
    "id": "3e0ded0123eda4d2a0f4d18d9da1c8eb598deef1",
    "semantic_title": "pcnn: probable-class nearest-neighbor explanations improve fine-grained image classification accuracy for ais and humans",
    "citation_count": 4,
    "authors": [
      "Giang Nguyen",
      "Valerie Chen",
      "Mohammad Reza Taesiri",
      "Anh Totti Nguyen"
    ]
  },
  "https://openreview.net/forum?id=u0eiu1MTS7": {
    "title": "Re-Thinking Inverse Graphics With Large Language Models",
    "volume": "main",
    "abstract": "Inverse graphics -- the task of inverting an image into physical variables that, when rendered, enable reproduction of the observed scene -- is a fundamental challenge in computer vision and graphics. Successfully disentangling an image into its constituent elements, such as the shape, color, and material properties of the objects of the 3D scene that produced it, requires a comprehensive understanding of the environment. This complexity limits the ability of existing carefully engineered approaches to generalize across domains. Inspired by the zero-shot ability of large language models (LLMs) to generalize to novel contexts, we investigate the possibility of leveraging the broad world knowledge encoded in such models to solve inverse-graphics problems. To this end, we propose the Inverse-Graphics Large Language Model (IG-LLM), an inverse-graphics framework centered around an LLM, that autoregressively decodes a visual embedding into a structured, compositional 3D-scene representation. We incorporate a frozen pre-trained visual encoder and a continuous numeric head to enable end-to-end training. Through our investigation, we demonstrate the potential of LLMs to facilitate inverse graphics through next-token prediction, without the application of image-space supervision. Our analysis enables new possibilities for precise spatial reasoning about images that exploit the visual knowledge of LLMs. We release our code and data at https://ig-llm.is.tue.mpg.de/ to ensure the reproducibility of our investigation and to facilitate future research",
    "checked": null,
    "id": "3ae618cf5c264dcbf6c4d30ce40c4315502fe6de",
    "semantic_title": "re-thinking inverse graphics with large language models",
    "citation_count": 9,
    "authors": [
      "Peter Kulits",
      "Haiwen Feng",
      "Weiyang Liu",
      "Victoria Fernandez Abrevaya",
      "Michael J. Black"
    ]
  },
  "https://openreview.net/forum?id=gVNyEVKjqf": {
    "title": "AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models",
    "volume": "main",
    "abstract": "Classifiers built upon vision-language models such as CLIP have shown remarkable zero-shot performance across a broad range of image classification tasks. Prior work has studied different ways of automatically creating descriptor sets for every class based on prompt templates, ranging from manually engineered templates over templates obtained from a large language model to templates built from random words and characters. Up until now, deriving zero-shot classifiers from the respective encoded class descriptors has remained nearly unchanged, i.e., classify to the class that maximizes cosine similarity between its averaged encoded class descriptors and the image encoding. However, weighing all class descriptors equally can be suboptimal when certain descriptors match visual clues on a given image better than others. In this work, we propose AutoCLIP, a method for auto-tuning zero-shot classifiers. AutoCLIP tunes per-image weights to each prompt template at inference time, based on statistics of class descriptor-image similarities. AutoCLIP is fully unsupervised, has only a minor additional computation overhead, and can be easily implemented in few lines of code. We show that AutoCLIP outperforms baselines across a broad range of vision-language models, datasets, and prompt templates consistently and by up to 3 percent point accuracy",
    "checked": null,
    "id": "99bd3e04b6b65abf3f03de69654059c3710d03e8",
    "semantic_title": "autoclip: auto-tuning zero-shot classifiers for vision-language models",
    "citation_count": 5,
    "authors": [
      "Jan Hendrik Metzen",
      "Piyapat Saranrittichai",
      "Chaithanya Kumar Mummadi"
    ]
  },
  "https://openreview.net/forum?id=Kxtpa9rvM0": {
    "title": "Sensitivity-Aware Amortized Bayesian Inference",
    "volume": "main",
    "abstract": "Sensitivity analyses reveal the influence of various modeling choices on the outcomes of statistical analyses. While theoretically appealing, they are overwhelmingly inefficient for complex Bayesian models. In this work, we propose sensitivity-aware amortized Bayesian inference (SA-ABI), a multifaceted approach to efficiently integrate sensitivity analyses into simulation-based inference with neural networks. First, we utilize weight sharing to encode the structural similarities between alternative likelihood and prior specifications in the training process with minimal computational overhead. Second, we leverage the rapid inference of neural networks to assess sensitivity to data perturbations and preprocessing steps. In contrast to most other Bayesian approaches, both steps circumvent the costly bottleneck of refitting the model for each choice of likelihood, prior, or data set. Finally, we propose to use deep ensembles to detect sensitivity arising from unreliable approximation (e.g., due to model misspecification). We demonstrate the effectiveness of our method in applied modeling problems, ranging from disease outbreak dynamics and global warming thresholds to human decision-making. Our results support sensitivity-aware inference as a default choice for amortized Bayesian workflows, automatically providing modelers with insights into otherwise hidden dimensions",
    "checked": null,
    "id": "d515929849c2970fe47b18506734031e08717606",
    "semantic_title": "sensitivity-aware amortized bayesian inference",
    "citation_count": 9,
    "authors": [
      "Lasse ElsemÃ¼ller",
      "Hans OlischlÃ¤ger",
      "Marvin Schmitt",
      "Paul-Christian BÃ¼rkner",
      "Ullrich Koethe",
      "Stefan T. Radev"
    ]
  },
  "https://openreview.net/forum?id=JoYMJJdvry": {
    "title": "Byzantine-Resilient Decentralized Multi-Armed Bandits",
    "volume": "main",
    "abstract": "In decentralized cooperative multi-armed bandits (MAB), each agent observes a distinct stream of rewards, and seeks to exchange information with others to select a sequence of arms so as to minimize its regret. Agents in the cooperative setting can outperform a single agent running a MAB method such as Upper-Confidence Bound (UCB) independently. In this work, we study how to recover such salient behavior when an unknown fraction of the agents can be Byzantine, that is, communicate arbitrarily wrong information in the form of reward mean-estimates or confidence sets. This framework can be used to model attackers in computer networks, instigators of offensive content into recommender systems, or manipulators of financial markets. Our key contribution is the development of a fully decentralized resilient upper confidence bound (UCB) algorithm that fuses an information mixing step among agents with a truncation of inconsistent and extreme values. This truncation step enables us to establish that the performance of each normal agent is no worse than the classic single-agent UCB1 algorithm in terms of regret, and more importantly, the cumulative regret of all normal agents is strictly better than the non-cooperative case, provided that each agent has at least $3f+1$ neighbors where $f$ is the maximum possible Byzantine agents in each agent's neighborhood. Extensions to time-varying neighbor graphs, and minimax lower bounds are further established on the achievable regret. Experiments corroborate the merits of this framework in practice",
    "checked": null,
    "id": "972347dca45496e042f6d092a034ca028e9610c8",
    "semantic_title": "byzantine-resilient decentralized multi-armed bandits",
    "citation_count": 6,
    "authors": [
      "Jingxuan Zhu",
      "Alec Koppel",
      "Alvaro Velasquez",
      "Ji Liu"
    ]
  },
  "https://openreview.net/forum?id=aggyMifxLQ": {
    "title": "Defending Against Unknown Corrupted Agents: Reinforcement Learning of Adversarially Robust Nash Equilibria",
    "volume": "main",
    "abstract": "We consider a Multi-agent Reinforcement Learning (MARL) setting, in which an attacker can arbitrarily corrupt any subset of up to $k$ out of $n$ agents at deployment. Our goal is to design agents that are robust against such an attack, by accounting for the presence of corrupted agents at test time. To that end, we introduce a novel solution concept, the Adversarially Robust Nash Equilibrium (ARNEQ), and provide theoretical proof of its existence in general-sum Markov games. Furthermore, we introduce a proof-of-concept model-based approach to computing it and theoretically prove its convergence under standard assumptions. We also present a practical approach called Adversarially Robust Training (ART), an independent learning algorithm based on stochastic gradient descent ascent. Our experiments in both cooperative and mixed cooperative-competitive environments demonstrate ART's effectiveness and practical value in enhancing MARL resilience against adversarial behavior",
    "checked": null,
    "id": "36725a24108a36682ad57ad19432e4615b2985ce",
    "semantic_title": "defending against unknown corrupted agents: reinforcement learning of adversarially robust nash equilibria",
    "citation_count": 1,
    "authors": [
      "Andi Nika",
      "Jonathan NÃ¶ther",
      "Adish Singla",
      "Goran Radanovic"
    ]
  },
  "https://openreview.net/forum?id=s9ylaDLvdO": {
    "title": "Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel Precision Matrices",
    "volume": "main",
    "abstract": "The Hilbert-space Gaussian process (HGP) approach offers a hyperparameter-independent basis function approximation for speeding up Gaussian process (GP) inference by projecting the GP onto $M$ basis functions. These properties result in a favorable data-independent $\\mathcal{O}(M^3)$ computational complexity during hyperparameter optimization but require a dominating one-time precomputation of the precision matrix costing $\\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating computational complexity to $\\mathcal{O}(NM)$ with no additional approximations. We can do this because we realize that the precision matrix can be split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$ unique entries. Based on this realization we propose computing only these unique entries at $\\mathcal{O}(NM)$ costs. Further, we develop two theorems that prescribe sufficient conditions for the complexity reduction to hold generally for a wide range of other approximate GP models, such as the Variational Fourier features approach. The two theorems do this with no assumptions on the data and no additional approximations of the GP models themselves. Thus, our contribution provides a pure speed-up of several existing, widely used, GP approximations, without further approximations",
    "checked": null,
    "id": "b2cf1b581eec68b05ee0eb33f0497fa90396e59a",
    "semantic_title": "exploiting hankel-toeplitz structures for fast computation of kernel precision matrices",
    "citation_count": 0,
    "authors": [
      "Frida Marie Viset",
      "Anton Kullberg",
      "Frederiek Wesel",
      "Arno Solin"
    ]
  },
  "https://openreview.net/forum?id=uQYomAuo7M": {
    "title": "Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition",
    "volume": "main",
    "abstract": "Perturbation robustness evaluates the vulnerabilities of models, arising from a variety of perturbations, such as data corruptions and adversarial attacks. Understanding the mechanisms of perturbation robustness is critical for global interpretability. We present a model-agnostic, global mechanistic interpretability method to interpret the perturbation robustness of image models. This research is motivated by two key aspects. First, previous global interpretability works, in tandem with robustness benchmarks, *eg.* mean corruption error (mCE), are not designed to directly interpret the mechanisms of perturbation robustness within image models. Second, we notice that the spectral signal-to-noise ratios (SNR) of perturbed natural images exponentially decay over the frequency. This power-law-like decay implies that: Low-frequency signals are generally more robust than high-frequency signals -- yet high classification accuracy can not be achieved by low-frequency signals alone. By applying Shapley value theory, our method axiomatically quantifies the predictive powers of robust features and non-robust features within an information theory framework. Our method, dubbed as **I-ASIDE** (**I**mage **A**xiomatic **S**pectral **I**mportance **D**ecomposition **E**xplanation), provides a unique insight into model robustness mechanisms. We conduct extensive experiments over a variety of vision models pre-trained on ImageNet, including both convolutional neural networks (*eg.* *AlexNet*, *VGG*, *GoogLeNet/Inception-v1*, *Inception-v3*, *ResNet*, *SqueezeNet*, *RegNet*, *MnasNet*, *MobileNet*, *EfficientNet*, *etc.*) and vision transformers (*eg.* *ViT*, *Swin Transformer*, and *MaxViT*), to show that **I-ASIDE** can not only **measure** the perturbation robustness but also **provide interpretations** of its mechanisms",
    "checked": null,
    "id": "f61cad8c1b2a33492968475ad0da1285b158932f",
    "semantic_title": "interpreting global perturbation robustness of image models using axiomatic spectral importance decomposition",
    "citation_count": 1,
    "authors": [
      "Roisin Luo",
      "James McDermott",
      "Colm O'Riordan"
    ]
  },
  "https://openreview.net/forum?id=Yf8iHCfG4W": {
    "title": "Towards Unbiased Calibration using Meta-Regularization",
    "volume": "main",
    "abstract": "Model miscalibration has been frequently identified in modern deep neural networks. Recent work aims to improve model calibration directly through a differentiable calibration proxy. However, the calibration produced is often biased due to the binning mechanism. In this work, we propose to learn better-calibrated models via meta-regularization, which has two components: (1) gamma network (gamma-net), a meta learner that outputs sample-wise gamma value (continuous variable) for Focal loss for regularizing the backbone network; (2) smooth expected calibration error (SECE), a Gaussian-kernel based, unbiased, and differentiable surrogate to ECE that enables the smooth optimization of gamma-net. We evaluate the effectiveness of the proposed approach in regularizing neural networks towards improved and unbiased calibration on three computer vision datasets. We empirically demonstrate that: (a) learning sample-wise $\\gamma$ as continuous variables can effectively improve calibration; (b) SECE smoothly optimizes gamma-net towards unbiased and robust calibration with respect to the binning schemes; and (c) the combination of gamma-net and SECE achieves the best calibration performance across various calibration metrics while retaining very competitive predictive performance as compared to multiple recently proposed methods",
    "checked": null,
    "id": "aced52d6a0af51d27c4710aa90f1a48a71e73d37",
    "semantic_title": "towards unbiased calibration using meta-regularization",
    "citation_count": 1,
    "authors": [
      "Cheng Wang",
      "Jacek Golebiowski"
    ]
  },
  "https://openreview.net/forum?id=gcf1anBL9e": {
    "title": "SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks",
    "volume": "main",
    "abstract": "As the size of large language models continue to scale, so does the computational resources required to run them. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and until now, SNNs have yet to succeed at language generation on large-scale datasets. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 46M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model when released, rendering it suitable for both the generation and comprehension of natural language. We achieve this by modifying the transformer block to replace multi-head self-attention to reduce quadratic computational complexity $\\mathcal{O}(T^2)$ to linear complexity $\\mathcal{O}(T)$ with increasing sequence length. Input tokens are instead streamed in sequentially to our attention mechanism (as with typical SNNs). Our experiments show that SpikeGPT remains competitive with non-spiking models on tested benchmarks, while maintaining 32.2$\\times$ fewer operations when processed on neuromorphic hardware that can leverage sparse, event-driven activations. Our code implementation is available at https://github.com/ridgerchu/SpikeGPT",
    "checked": null,
    "id": "9f52317ea9c5a6804b978987ff2a6557f98b5b2c",
    "semantic_title": "spikegpt: generative pre-trained language model with spiking neural networks",
    "citation_count": 87,
    "authors": [
      "Rui-Jie Zhu",
      "Qihang Zhao",
      "Guoqi Li",
      "Jason Eshraghian"
    ]
  },
  "https://openreview.net/forum?id=0zKvH7YiAq": {
    "title": "Improved Convergence of Score-Based Diffusion Models via Prediction-Correction",
    "volume": "main",
    "abstract": "Score-based generative models (SGMs) are powerful tools to sample from complex data distributions. Their underlying idea is to \\emph{(i)} run a forward process for time $T_1$ by adding noise to the data, \\emph{(ii)} estimate its score function, and \\emph{(iii)} use such estimate to run a reverse process. As the reverse process is initialized with the stationary distribution of the forward one, the existing analysis paradigm requires $T_1\\to\\infty$. This is however problematic: from a theoretical viewpoint, for a given precision of the score approximation, the convergence guarantee fails as $T_1$ diverges; from a practical viewpoint, a large $T_1$ increases computational costs and leads to error propagation. This paper addresses the issue by considering a version of the popular \\emph{predictor-corrector} scheme: after running the forward process, we first estimate the final distribution via an inexact Langevin dynamics and then revert the process. Our key technical contribution is to provide convergence guarantees which require to run the forward process \\emph{only for a fixed finite time} $T_1$. Our bounds exhibit a mild logarithmic dependence on the input dimension and the subgaussian norm of the target distribution, have minimal assumptions on the data, and require only to control the $L^2$ loss on the score approximation, which is the quantity minimized in practice",
    "checked": null,
    "id": "58f3c674390dc9f0386dca4a7028f4a52306fb9e",
    "semantic_title": "improved convergence of score-based diffusion models via prediction-correction",
    "citation_count": 15,
    "authors": [
      "Francesco Pedrotti",
      "Jan Maas",
      "Marco Mondelli"
    ]
  },
  "https://openreview.net/forum?id=yXnwrs2Tl6": {
    "title": "Certified Deductive Reasoning with Language Models",
    "volume": "main",
    "abstract": "Language models often achieve higher accuracy when reasoning step-by-step in complex tasks. However, even when arriving at a correct final answer, their rationales are often logically unsound or inconsistent. This is a major issue when reliable reasoning traces are needed, such as when fine-tuning on model-generated reasoning for self-improvement. To tackle these issues, we introduce a class of tools for language models called guides, that use state and incremental constraints to guide generation. A guide can be invoked by the model to constrain its own generation to a set of valid statements given by the tool. In turn, the model's choices can change the guide's state. We show how a general system for logical reasoning can be used as a guide, which we call LogicGuide. Given a reasoning problem in natural language, a model can formalize its assumptions for LogicGuide and guarantee that its step-by-step reasoning is sound. In experiments on PrOntoQA, ProofWriter and Syllogism Validity datasets, LogicGuide significantly improves the performance of GPT-3, GPT-3.5 Turbo and LLaMA (accuracy gains up to 35%), while drastically reducing content effects â the interference between unwanted prior assumptions and reasoning, which humans and language models suffer from. We then explore bootstrapping GPT-3.5 Turbo and LLaMA using their own reasoning traces. We find that LogicGuide is critical: by training only on certified self-generated reasoning, models can self-improve, avoiding learning from their own hallucinations. Moreover, bootstrapped models enjoy significant boosts on ReClor, a challenging real-world reasoning dataset, even when not relying on formalization at inference time",
    "checked": null,
    "id": "f9e33614577f03ddfda62c3122186407aa6be7d3",
    "semantic_title": "certified deductive reasoning with language models",
    "citation_count": 0,
    "authors": [
      "Gabriel Poesia",
      "Kanishk Gandhi",
      "Eric Zelikman",
      "Noah Goodman"
    ]
  },
  "https://openreview.net/forum?id=UuU6C6CUoF": {
    "title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion Models",
    "volume": "main",
    "abstract": "Privacy concerns have led to a surge in the creation of synthetic datasets, with diffusion models emerging as a promising avenue. Although prior studies have performed empirical evaluations on these models, there has been a gap in providing a mathematical characterization of their privacy-preserving capabilities. To address this, we present the pioneering theoretical exploration of the privacy preservation inherent in \\emph{discrete diffusion models} (DDMs) for discrete dataset generation. Focusing on per-instance differential privacy (pDP), our framework elucidates the potential privacy leakage for each data point in a given training dataset, offering insights into how the privacy loss of each point correlates with the dataset's distribution. Our bounds also show that training with $s$-sized data points leads to a surge in privacy leakage from $(\\epsilon, \\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon, \\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP of the DDM during the transition from the pure noise to the synthetic clean data phase, and a faster decay in diffusion coefficients amplifies the privacy guarantee. Finally, we empirically verify our theoretical findings on both synthetic and real-world datasets",
    "checked": null,
    "id": "e71528f4898d4e271694d6420f3bb038d0262e98",
    "semantic_title": "on the inherent privacy properties of discrete denoising diffusion models",
    "citation_count": 0,
    "authors": [
      "Rongzhe Wei",
      "Eleonora Kreacic",
      "Haoyu Peter Wang",
      "Haoteng Yin",
      "Eli Chien",
      "Vamsi K. Potluru",
      "Pan Li"
    ]
  },
  "https://openreview.net/forum?id=4E2XLydJiv": {
    "title": "Normed Spaces for Graph Embedding",
    "volume": "main",
    "abstract": "Theoretical results from discrete geometry suggest that normed spaces can abstractly embed finite metric spaces with surprisingly low theoretical bounds on distortion in low dimensions. Inspired by this theoretical insight, we highlight in this paper normed spaces as a more flexible and computationally efficient alternative to several popular Riemannian manifolds for learning graph embeddings. Normed space embeddings significantly outperform several popular manifolds on a large range of synthetic and real-world graph reconstruction benchmark datasets while requiring significantly fewer computational resources. We also empirically verify the superiority of normed space embeddings on growing families of graphs associated with negative, zero, and positive curvature, further reinforcing the flexibility of normed spaces in capturing diverse graph structures as graph sizes increase. Lastly, we demonstrate the utility of normed space embeddings on two applied graph embedding tasks, namely, link prediction and recommender systems. Our work highlights the potential of normed spaces for geometric graph representation learning, raises new research questions, and offers a valuable tool for experimental mathematics in the field of finite metric space embeddings. We make our code and data publically available \\footnote{\\url{https://github.com/andyweizhao/graphs-normed-spaces}}",
    "checked": null,
    "id": "231de94467170d514625a96530c5def3ad573995",
    "semantic_title": "normed spaces for graph embedding",
    "citation_count": 0,
    "authors": [
      "Diaaeldin Taha",
      "Wei Zhao",
      "J. Maxwell Riestenberg",
      "Michael Strube"
    ]
  },
  "https://openreview.net/forum?id=DWkJCSxKU5": {
    "title": "Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models",
    "volume": "main",
    "abstract": "Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains. However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification (UQ) for NLG. Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or computational constraints. In this work, we investigate UQ in NLG for *black-box* LLMs. We first differentiate *uncertainty* vs *confidence*: the former refers to the ``dispersion'' of the potential predictions for a fixed input, and the latter refers to the confidence on a particular prediction/generation. We then propose and compare several confidence/uncertainty measures, applying them to *selective NLG* where unreliable results could either be ignored or yielded for further assessment. Experiments were carried out with several popular LLMs on question-answering datasets (for evaluation purposes). Results reveal that a simple measure for the semantic dispersion can be a reliable predictor of the quality of LLM responses, providing valuable insights for practitioners on uncertainty management when adopting LLMs",
    "checked": null,
    "id": "ad934a9344f68fcc0b9aa704102aa48c39c5b591",
    "semantic_title": "generating with confidence: uncertainty quantification for black-box large language models",
    "citation_count": 155,
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ]
  },
  "https://openreview.net/forum?id=JkFEVbW6wE": {
    "title": "Enhancing Vision-Language Model with Unmasked Token Alignment",
    "volume": "main",
    "abstract": "Contrastive pre-training on image-text pairs, exemplified by CLIP, becomes a standard technique for learning multi-modal visual-language representations. Although CLIP has demonstrated remarkable performance, training it from scratch on noisy web-scale datasets is computationally demanding. On the other hand, mask-then-predict pre-training approaches, like Masked Image Modeling (MIM), offer efficient self-supervised learning for single-modal representations. This paper introduces $\\textbf{U}$nmasked $\\textbf{T}$oken $\\textbf{A}$lignment ($\\textbf{UTA}$), a method that leverages existing CLIP models to further enhance its vision-language representations. UTA trains a Vision Transformer (ViT) by aligning unmasked visual tokens to the corresponding image tokens from a frozen CLIP vision encoder, which automatically aligns the ViT model with the CLIP text encoder. The pre-trained ViT can be directly applied for zero-shot evaluation even without training on image-text pairs. Compared to MIM approaches, UTA does not suffer from training-finetuning inconsistency and is much more training-efficient by avoiding using the extra $\\mathrm{[MASK]}$ tokens. Extensive experimental results demonstrate that UTA can enhance CLIP models and outperform existing MIM methods on various uni- and multi-modal benchmarks",
    "checked": null,
    "id": "632e55d7bf1612c94a5a8e577b57e28117414026",
    "semantic_title": "enhancing vision-language model with unmasked token alignment",
    "citation_count": 0,
    "authors": [
      "Jihao Liu",
      "Jinliang Zheng",
      "Boxiao Liu",
      "Yu Liu",
      "Hongsheng Li"
    ]
  },
  "https://openreview.net/forum?id=098mb06uhA": {
    "title": "Extreme Risk Mitigation in Reinforcement Learning using Extreme Value Theory",
    "volume": "main",
    "abstract": "Risk-sensitive reinforcement learning (RL) has garnered significant attention in recent years due to the growing interest in deploying RL agents in real-world scenarios. A critical aspect of risk awareness involves modelling highly rare risk events (rewards) that could potentially lead to catastrophic outcomes. These infrequent occurrences present a formidable challenge for data-driven methods aiming to capture such risky events accurately. While risk-aware RL techniques do exist, they suffer from high variance estimation due to the inherent data scarcity. Our work proposes to enhance the resilience of RL agents when faced with very rare and risky events by focusing on refining the predictions of the extreme values predicted by the state-action value distribution. To achieve this, we formulate the extreme values of the state-action value function distribution as parameterized distributions, drawing inspiration from the principles of extreme value theory (EVT). We propose an extreme value theory based actor-critic approach, namely, Extreme Valued Actor-Critic (EVAC) which effectively addresses the issue of infrequent occurrence by leveraging EVT-based parameterization. Importantly, we theoretically demonstrate the advantages of employing these parameterized distributions in contrast to other risk-averse algorithms. Our evaluations show that the proposed method outperforms other risk averse RL algorithms on a diverse range of benchmark tasks, each encompassing distinct risk scenarios",
    "checked": null,
    "id": "dfdc9861a2ff4c9b49a5bfaeab5b5863542eaa49",
    "semantic_title": "extreme risk mitigation in reinforcement learning using extreme value theory",
    "citation_count": 2,
    "authors": [
      "Karthik Somayaji NS",
      "Yu Wang",
      "Malachi Schram",
      "Jan Drgona",
      "Mahantesh M Halappanavar",
      "Frank Liu",
      "Peng Li"
    ]
  },
  "https://openreview.net/forum?id=zOKAmm8R9B": {
    "title": "GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models",
    "volume": "main",
    "abstract": "Offline Goal-Conditioned RL (GCRL) offers a feasible paradigm for learning general-purpose policies from diverse and multi-task offline datasets. Despite notable recent progress, the predominant offline GCRL methods, mainly model-free, face constraints in handling limited data and generalizing to unseen goals. In this work, we propose Goal-conditioned Offline Planning (GOPlan), a novel model-based framework that contains two key phases: (1) pretraining a prior policy capable of capturing multi-modal action distribution within the multi-goal dataset; (2) employing the reanalysis method with planning to generate imagined trajectories for funetuning policies. Specifically, we base the prior policy on an advantage-weighted conditioned generative adversarial network, which facilitates distinct mode separation, mitigating the pitfalls of out-of-distribution (OOD) actions. For further policy optimization, the reanalysis method generates high-quality imaginary data by planning with learned models for both intra-trajectory and inter-trajectory goals. With thorough experimental evaluations, we demonstrate that GOPlan achieves state-of-the-art performance on various offline multi-goal navigation and manipulation tasks. Moreover, our results highlight the superior ability of GOPlan to handle small data budgets and generalize to OOD goals",
    "checked": null,
    "id": "1d97ed822e13688ef48eb005f428081fb08d6f28",
    "semantic_title": "goplan: goal-conditioned offline reinforcement learning by planning with learned models",
    "citation_count": 11,
    "authors": [
      "Mianchu Wang",
      "Rui Yang",
      "Xi Chen",
      "Hao Sun",
      "Meng Fang",
      "Giovanni Montana"
    ]
  },
  "https://openreview.net/forum?id=XHEhjDxPDl": {
    "title": "Solving Inverse Problems with Model Mismatch using Untrained Neural Networks within Model-based Architectures",
    "volume": "main",
    "abstract": "Model-based deep learning methods such as loop unrolling (LU) and deep equilibrium model (DEQ) extensions offer outstanding performance in solving inverse problems (IP). These methods unroll the optimization iterations into a sequence of neural networks that in effect learn a regularization function from data. While these architectures are currently state-of-the-art in numerous applications, their success heavily relies on the accuracy of the forward model. This assumption can be limiting in many physical applications due to model simplifications or uncertainties in the apparatus. To address forward model mismatch, we introduce an untrained forward model residual block within the model-based architecture to match the data consistency in the measurement domain for each instance. We propose two variants in well-known model-based architectures (LU and DEQ) and prove convergence under mild conditions. Our approach offers a unified solution that is less parameter-sensitive, requires no additional data, and enables simultaneous fitting of the forward model and reconstruction in a single pass, benefiting both linear and nonlinear inverse problems. The experiments show significant quality improvement in removing artifacts and preserving details across three distinct applications, encompassing both linear and nonlinear inverse problems. Moreover, we highlight reconstruction effectiveness in intermediate steps and showcase robustness to random initialization of the residual block and a higher number of iterations during evaluation",
    "checked": null,
    "id": "7a5b0f18597f7ca466c1f68e7673d2e929c4f441",
    "semantic_title": "solving inverse problems with model mismatch using untrained neural networks within model-based architectures",
    "citation_count": 2,
    "authors": [
      "Peimeng Guan",
      "Naveed Iqbal",
      "Mark A. Davenport",
      "Mudassir Masood"
    ]
  },
  "https://openreview.net/forum?id=dwFRov8xhr": {
    "title": "E-Valuating Classifier Two-Sample Tests",
    "volume": "main",
    "abstract": "We introduce a powerful deep classifier two-sample test for high-dimensional data based on E-values, called E-C2ST. Our test combines ideas from existing work on split likelihood ratio tests and predictive independence tests. The resulting E-values are suitable for anytime-valid sequential two-sample tests. This feature allows for more effective use of data in constructing test statistics. Through simulations and real data applications, we empirically demonstrate that E-C2ST achieves enhanced statistical power by partitioning datasets into multiple batches, beyond the conventional two-split (training and testing) approach of standard two-sample classifier tests. This strategy increases the power of the test, while keeping the type I error well below the desired significance level",
    "checked": null,
    "id": "05599cb143f6162030153abf069a74cb0b7b3fd5",
    "semantic_title": "e-valuating classifier two-sample tests",
    "citation_count": 12,
    "authors": [
      "Teodora Pandeva",
      "Tim Bakker",
      "Christian A. Naesseth",
      "Patrick ForrÃ©"
    ]
  },
  "https://openreview.net/forum?id=8bnsoL2IyJ": {
    "title": "Variance-aware decision making with linear function approximation under heavy-tailed rewards",
    "volume": "main",
    "abstract": "This paper studies how to achieve variance-aware regrets for online decision-making in the presence of heavy-tailed rewards with only finite variances. For linear stochastic bandits, we address the issue of heavy-tailed rewards by modifying the adaptive Huber regression and proposing AdaOFUL. AdaOFUL achieves a state-of-the-art regret bound of $\\widetilde{\\mathcal{O}}\\big(d\\big(\\sum_{t=1}^T \\nu_{t}^2\\big)^{1/2}+d\\big)$ as if the rewards were uniformly bounded, where $\\nu_{t}^2$ is the conditional variance of the reward at round $t$, $d$ is the feature dimension, {and $T$ is number of online rounds}. Building upon AdaOFUL, we propose VARA for linear MDPs, which achieves a variance-aware regret bound of $\\widetilde{\\mathcal{O}}(d\\sqrt{H\\mathcal{G}^*K})$. Here, $H$ is the length of episodes, $K$ is the number of episodes, and $\\mathcal{G}^*$ is a smaller instance-dependent quantity that can be bounded by other instance-dependent quantities when additional structural conditions on the MDP are satisfied. Overall, our modified adaptive Huber regression algorithm may serve as a useful building block in the design of algorithms for online problems with heavy-tailed rewards",
    "checked": null,
    "id": "e3fa32bc7972a4c46ffa228aaec2b309e2dddff7",
    "semantic_title": "variance-aware decision making with linear function approximation under heavy-tailed rewards",
    "citation_count": 2,
    "authors": [
      "Xiang Li",
      "Qiang Sun"
    ]
  },
  "https://openreview.net/forum?id=wTGjn7JvYK": {
    "title": "On the Optimization and Generalization of Multi-head Attention",
    "volume": "main",
    "abstract": "The training and generalization dynamics of the Transformer's core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on single-head attention. Inspired by the demonstrated benefits of overparameterization when training fully-connected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations",
    "checked": null,
    "id": "6cee47349bf526bd63ee62da15b3c88701f97f15",
    "semantic_title": "on the optimization and generalization of multi-head attention",
    "citation_count": 34,
    "authors": [
      "Puneesh Deora",
      "Rouzbeh Ghaderi",
      "Hossein Taheri",
      "Christos Thrampoulidis"
    ]
  },
  "https://openreview.net/forum?id=iBgmoMTlaz": {
    "title": "Understanding Fairness Surrogate Functions in Algorithmic Fairness",
    "volume": "main",
    "abstract": "It has been observed that machine learning algorithms exhibit biased predictions against certain population groups. To mitigate such bias while achieving comparable accuracy, a promising approach is to introduce surrogate functions of the concerned fairness definition and solve a constrained optimization problem. However, it is intriguing in previous work that such fairness surrogate functions may yield unfair results and high instability. In this work, in order to deeply understand them, taking a widely used fairness definitionâdemographic parity as an example, we show that there is a surrogate-fairness gap between the fairness definition and the fairness surrogate function. Also, the theoretical analysis and experimental results about the \"gap\" motivate us that the fairness and stability will be affected by the points far from the decision boundary, which is the large margin points issue investigated in this paper. To address it, we propose the general sigmoid surrogate to simultaneously reduce both the surrogate-fairness gap and the variance, and offer a rigorous fairness and stability upper bound. Interestingly, the theory also provides insights into two important issues that deal with the large margin points as well as obtaining a more balanced dataset are beneficial to fairness and stability. Furthermore, we elaborate a novel and general algorithm called Balanced Surrogate, which iteratively reduces the \"gap\" to mitigate unfairness. Finally, we provide empirical evidence showing that our methods consistently improve fairness and stability while maintaining accuracy comparable to the baselines in three real-world datasets",
    "checked": null,
    "id": "e83c814656dbe816e2db1c11f7a3f3bbd45673b3",
    "semantic_title": "understanding fairness surrogate functions in algorithmic fairness",
    "citation_count": 5,
    "authors": [
      "Wei Yao",
      "Zhanke Zhou",
      "Zhicong Li",
      "Bo Han",
      "Yong Liu"
    ]
  },
  "https://openreview.net/forum?id=kxYqgSkH8I": {
    "title": "Optimization with Access to Auxiliary Information",
    "volume": "main",
    "abstract": "We investigate the fundamental optimization question of minimizing a \\emph{target} function $f(x)$, whose gradients are expensive to compute or have limited availability, given access to some \\emph{auxiliary} side function $h(x)$ whose gradients are cheap or more available. This formulation captures many settings of practical relevance, such as i) re-using batches in SGD, ii) transfer learning, iii) federated learning, iv) training with compressed models/dropout, etcetera. We propose two generic new algorithms that apply in all these settings; we also prove that we can benefit from this framework under the Hessian similarity assumption between the target and side information. A benefit is obtained when this similarity measure is small; we also show a potential benefit from stochasticity when the auxiliary noise is correlated with that of the target function",
    "checked": null,
    "id": "49b9c5eeff14f7196d2fb551b01a83c2d96e1a2f",
    "semantic_title": "optimization with access to auxiliary information",
    "citation_count": 10,
    "authors": [
      "El Mahdi Chayti",
      "Sai Praneeth Karimireddy"
    ]
  },
  "https://openreview.net/forum?id=ehfRiF0R3a": {
    "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
    "volume": "main",
    "abstract": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in an open-ended world that continuously explores, acquires diverse skills, and makes novel discoveries without human intervention in Minecraft. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's capability rapidly and alleviates catastrophic forgetting. Empirically, Voyager demonstrates strong in-context lifelong learning capabilities. It outperforms prior SOTA by obtaining 3.1x more unique items, unlocking tech tree milestones up to 15.3x faster, and traveling 2.3x longer distances. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize",
    "checked": null,
    "id": "f197bf0fc2f228483f6af3285000d54d8d97f9eb",
    "semantic_title": "voyager: an open-ended embodied agent with large language models",
    "citation_count": 841,
    "authors": [
      "Guanzhi Wang",
      "Yuqi Xie",
      "Yunfan Jiang",
      "Ajay Mandlekar",
      "Chaowei Xiao",
      "Yuke Zhu",
      "Linxi Fan",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=ue9igTDLN2": {
    "title": "Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models",
    "volume": "main",
    "abstract": "As general purpose vision models get increasingly effective at a wide set of tasks, it is imperative that they be consistent across the tasks they support. Inconsistent AI models are considered brittle and untrustworthy by human users and are more challenging to incorporate into larger systems that take dependencies on their outputs. Measuring consistency between very heterogeneous tasks that might include outputs in different modalities is challenging since it is difficult to determine if the predictions are consistent with one another. As a solution, we introduce a benchmark dataset, CocoCON, where we create contrast sets by modifying test instances for multiple tasks in small but semantically meaningful ways to change the gold label and outline metrics for measuring if a model is consistent by ranking the original and perturbed instances across tasks. We find that state-of-the-art vision-language models suffer from a surprisingly high degree of inconsistent behavior across tasks, especially for more heterogeneous tasks. To alleviate this issue, we propose a rank correlation-based auxiliary training objective, computed over large automatically created cross-task contrast sets, that improves the multi-task consistency of large unified models while retaining their original accuracy on downstream tasks",
    "checked": null,
    "id": "7ac75cb733140d9ec7829b751b974f56dfe3b38f",
    "semantic_title": "exposing and addressing cross-task inconsistency in unified vision-language models",
    "citation_count": 3,
    "authors": [
      "Adyasha Maharana",
      "Amita Kamath",
      "Christopher Clark",
      "Mohit Bansal",
      "Aniruddha Kembhavi"
    ]
  },
  "https://openreview.net/forum?id=WFI9xhJrxF": {
    "title": "Policy Gradient with Kernel Quadrature",
    "volume": "main",
    "abstract": "Reward evaluation of episodes becomes a bottleneck in a broad range of reinforcement learning tasks. Our aim in this paper is to select a small but representative subset of a large batch of episodes, only on which we actually compute rewards for more efficient policy gradient iterations. We build a Gaussian process modeling of discounted returns or rewards to derive a positive definite kernel on the space of episodes, run an ``episodic\" kernel quadrature method to compress the information of sample episodes, and pass the reduced episodes to the policy network for gradient updates. We present the theoretical background of this procedure as well as its numerical illustrations in MuJoCo tasks",
    "checked": null,
    "id": "ffbf87817e86739040ef7e80169d55db707ea947",
    "semantic_title": "policy gradient with kernel quadrature",
    "citation_count": 1,
    "authors": [
      "Satoshi Hayakawa",
      "Tetsuro Morimura"
    ]
  },
  "https://openreview.net/forum?id=vsCpILiWHu": {
    "title": "RoboCat: A Self-Improving Generalist Agent for Robotic Manipulation",
    "volume": "main",
    "abstract": "The ability to leverage heterogeneous robotic experience from different robots and tasks to quickly master novel skills and embodiments has the potential to transform robot learning. Inspired by recent advances in foundation models for vision and language, we propose a multi-embodiment, multi-task generalist agent for robotic manipulation. This agent, named RoboCat, is a visual goal-conditioned decision transformer capable of consuming action-labelled visual experience. This data spans a large repertoire of motor control skills from simulated and real robotic arms with varying sets of observations and actions. With RoboCat, we demonstrate the ability to generalise to new tasks and robots, both zero-shot as well as through adaptation using only 100â1000 examples for the target task. We also show how a trained model itself can be used to generate data for subsequent training iterations, thus providing a basic building block for an autonomous improvement loop. We investigate the agent's capabilities, with large-scale evaluations both in simulation and on three different real robot embodiments. We find that as we grow and diversify its training data, RoboCat not only shows signs of cross-task transfer, but also becomes more efficient at adapting to new tasks",
    "checked": null,
    "id": "2562fe379554d201aad312f786903f4c60b68acf",
    "semantic_title": "robocat: a self-improving generalist agent for robotic manipulation",
    "citation_count": 52,
    "authors": [
      "Konstantinos Bousmalis",
      "Giulia Vezzani",
      "Dushyant Rao",
      "Coline Manon Devin",
      "Alex X. Lee",
      "Maria Bauza Villalonga",
      "Todor Davchev",
      "Yuxiang Zhou",
      "Agrim Gupta",
      "Akhil Raju",
      "Antoine Laurens",
      "Claudio Fantacci",
      "Valentin Dalibard",
      "Martina Zambelli",
      "Murilo Fernandes Martins",
      "Rugile Pevceviciute",
      "Michiel Blokzijl",
      "Misha Denil",
      "Nathan Batchelor",
      "Thomas Lampe",
      "Emilio Parisotto",
      "Konrad Zolna",
      "Scott Reed",
      "Sergio GÃ³mez Colmenarejo",
      "Jonathan Scholz",
      "Abbas Abdolmaleki",
      "Oliver Groth",
      "Jean-Baptiste Regli",
      "Oleg Sushkov",
      "Thomas RothÃ¶rl",
      "Jose Enrique Chen",
      "Yusuf Aytar",
      "David Barker",
      "Joy Ortiz",
      "Martin Riedmiller",
      "Jost Tobias Springenberg",
      "Raia Hadsell",
      "Francesco Nori",
      "Nicolas Heess"
    ]
  },
  "https://openreview.net/forum?id=OdDsCaacZ0": {
    "title": "MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments",
    "volume": "main",
    "abstract": "Self-supervised learning can be used for mitigating the greedy needs of Vision Transformer networks for very large fully-annotated datasets. Different classes of self-supervised learning offer representations with either good contextual reasoning properties, e.g., using masked image modeling strategies, or invariance to image perturbations, e.g., with contrastive methods. In this work, we propose a single-stage and standalone method, MOCA, which unifies both desired properties using novel mask-and-predict objectives defined with high-level features (instead of pixel-level details). Moreover, we show how to effectively employ both learning paradigms in a synergistic and computation-efficient way. Doing so, we achieve new state-of-the-art results on low-shot settings and strong experimental results in various evaluation protocols with a training that is at least 3 times faster than prior methods. We provide the implementation code at https://github.com/valeoai/MOCA",
    "checked": null,
    "id": "39ffd546e3b64b6313035164ed899339456307a2",
    "semantic_title": "moca: self-supervised representation learning by predicting masked online codebook assignments",
    "citation_count": 3,
    "authors": [
      "Spyros Gidaris",
      "Andrei Bursuc",
      "Oriane SimÃ©oni",
      "AntonÃ­n VobeckÃ½",
      "Nikos Komodakis",
      "Matthieu Cord",
      "Patrick Perez"
    ]
  },
  "https://openreview.net/forum?id=eN9CjU3h1b": {
    "title": "MMD-Regularized Unbalanced Optimal Transport",
    "volume": "main",
    "abstract": "We study the unbalanced optimal transport (UOT) problem, where the marginal constraints are enforced using Maximum Mean Discrepancy (MMD) regularization. Our work is motivated by the observation that the literature on UOT is focused on regularization based on $\\phi$-divergence (e.g., KL divergence). Despite the popularity of MMD, its role as a regularizer in the context of UOT seems less understood. We begin by deriving a specific dual of MMD-regularized UOT (MMD-UOT), which helps us prove several useful properties. One interesting outcome of this duality result is that MMD-UOT induces novel metrics, which not only lift the ground metric like the Wasserstein but are also sample-wise efficient to estimate like the MMD. Further, for real-world applications involving non-discrete measures, we present an estimator for the transport plan that is supported only on the given ($m$) samples. Under certain conditions, we prove that the estimation error with this finitely-supported transport plan is also $\\mathcal{O}(1/\\sqrt{m})$. As far as we know, such error bounds that are free from the curse of dimensionality are not known for $\\phi$-divergence regularized UOT. Finally, we discuss how the proposed estimator can be computed efficiently using accelerated gradient descent. Our experiments show that MMD-UOT consistently outperforms popular baselines, including KL-regularized UOT and MMD, in diverse machine learning applications",
    "checked": null,
    "id": "4a3d67894e699f7dcba0b54a5b0684702126e8bf",
    "semantic_title": "unbalanced low-rank optimal transport solvers",
    "citation_count": 1,
    "authors": [
      "Piyushi Manupriya",
      "SakethaNath Jagarlapudi",
      "Pratik Jawanpuria"
    ]
  },
  "https://openreview.net/forum?id=KcmWZSk53y": {
    "title": "Improved Regret Bounds for Linear Adversarial MDPs via Linear Optimization",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": "64c44e4d7f405ae8df334980642fbb21942a889f",
    "semantic_title": "improved regret bounds for linear adversarial mdps via linear optimization",
    "citation_count": 12,
    "authors": [
      "Fang Kong",
      "XiangCheng Zhang",
      "Baoxiang Wang",
      "Shuai Li"
    ]
  },
  "https://openreview.net/forum?id=NQi9U0YLW3": {
    "title": "Autoencoding Hyperbolic Representation for Adversarial Generation",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": "45d78d730bfd5384998ab65b7a1111993df892d8",
    "semantic_title": "autoencoding hyperbolic representation for adversarial generation",
    "citation_count": 5,
    "authors": [
      "Eric Qu",
      "Dongmian Zou"
    ]
  },
  "https://openreview.net/forum?id=FozLrZ3CI5": {
    "title": "Neural incomplete factorization: learning preconditioners for the conjugate gradient method",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": "2c19696390b32582cac72edd8a6fae5fe8856119",
    "semantic_title": "neural incomplete factorization: learning preconditioners for the conjugate gradient method",
    "citation_count": 8,
    "authors": [
      "Paul HÃ¤usner",
      "Ozan Ãktem",
      "Jens SjÃ¶lund"
    ]
  },
  "https://openreview.net/forum?id=lcPtUhoGYc": {
    "title": "GraphPrivatizer: Improved Structural Differential Privacy for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": "4dcf24266b6ec13330d3821133cf516593293cac",
    "semantic_title": "graphprivatizer: improved structural differential privacy for graph neural networks",
    "citation_count": 0,
    "authors": [
      "Rucha Bhalchandra Joshi",
      "Patrick Indri",
      "Subhankar Mishra"
    ]
  },
  "https://openreview.net/forum?id=koC6zyaj73": {
    "title": "On the Equivalence of Graph Convolution and Mixup",
    "volume": "main",
    "abstract": "This paper investigates the relationship between graph convolution and Mixup techniques. Graph convolution in a graph neural network involves aggregating features from neighboring samples to learn representative features for a specific node or sample. On the other hand, Mixup is a data augmentation technique that generates new examples by averaging features and one-hot labels from multiple samples. One commonality between these techniques is their utilization of information from multiple samples to derive feature representation. This study aims to explore whether a connection exists between the two. Our investigation reveals that, under two mild modifications, graph convolution can be viewed as a specialized form of Mixup that is applied during both the training and testing phases. The two modifications are 1) \\textit{Homophily Relabel} - assigning the target node's label to all its neighbors, and 2) \\textit{Test-Time Mixup} - Mixup the feature during the test time. We establish this equivalence mathematically by demonstrating that graph convolution networks and simplified graph convolution can be expressed as a form of Mixup. We also empirically verify the equivalence by training an MLP using the two modifications to achieve comparable performance",
    "checked": null,
    "id": "077a8ceae6e6945596bc36e49eca9328de94dd63",
    "semantic_title": "on the equivalence of graph convolution and mixup",
    "citation_count": 0,
    "authors": [
      "Xiaotian Han",
      "Hanqing Zeng",
      "Yu Chen",
      "Shaoliang Nie",
      "Jingzhou Liu",
      "Kanika Narang",
      "Zahra Shakeri",
      "Karthik Abinav Sankararaman",
      "Song Jiang",
      "Madian Khabsa",
      "Qifan Wang",
      "Xia Hu"
    ]
  },
  "https://openreview.net/forum?id=N8cPv95zOU": {
    "title": "TacoGFN: Target-conditioned GFlowNet for Structure-based Drug Design",
    "volume": "main",
    "abstract": "Searching the vast chemical space for drug-like molecules that bind with a protein pocket is a challenging task in drug discovery. Recently, structure-based generative models have been introduced which promise to be more efficient by learning to generate molecules for any given protein structure. However, since they learn the distribution of a limited protein-ligand complex dataset, structure-based methods do not yet outperform optimization-based methods that generate binding molecules for just one pocket. To overcome limitations on data while leveraging learning across protein targets, we choose to model the reward distribution conditioned on pocket structure, instead of the training data distribution. We design TacoGFN, a novel GFlowNet-based approach for structure-based drug design, which can generate molecules conditioned on any protein pocket structure with probabilities proportional to its affinity and property rewards. In the generative setting for CrossDocked2020 benchmark, TacoGFN attains a state-of-the-art success rate of 56.0% and -8.44 kcal/mol in median Vina Dock score while improving the generation time by multiple orders of magnitude. Fine-tuning TacoGFN further improves the median Vina Dock score to -10.93 kcal/mol and the success rate to 88.8\\%, outperforming all optimization-based methods",
    "checked": null,
    "id": "9521f06cfe9c343fdb208cacd5d932e73f836402",
    "semantic_title": "tacogfn: target conditioned gflownet for structure-based drug design",
    "citation_count": 19,
    "authors": [
      "Tony Shen",
      "Seonghwan Seo",
      "Grayson Lee",
      "Mohit Pandey",
      "Jason R Smith",
      "Artem Cherkasov",
      "Woo Youn Kim",
      "Martin Ester"
    ]
  },
  "https://openreview.net/forum?id=7kWjB9zW90": {
    "title": "Object-Centric Relational Representations for Image Generation",
    "volume": "main",
    "abstract": "Conditioning image generation on specific features of the desired output is a key ingredient of modern generative models. However, existing approaches lack a general and unified way of representing structural and semantic conditioning at diverse granularity levels. This paper explores a novel method to condition image generation, based on object-centric relational representations. In particular, we propose a methodology to condition the generation of objects in an image on the attributed graph representing their structure and the associated semantic information. We show that such architectural biases entail properties that facilitate the manipulation and conditioning of the generative process and allow for regularizing the training procedure. The proposed conditioning framework is implemented by means of a neural network that learns to generate a 2D, multi-channel, layout mask of the objects, which can be used as a soft inductive bias in the downstream generative task. To do so, we leverage both 2D and graph convolutional operators. We also propose a novel benchmark for image generation consisting of a synthetic dataset of images paired with their relational representation. Empirical results show that the proposed approach compares favorably against relevant baselines",
    "checked": null,
    "id": "497feefea82004c2843d735004003af9289f0dc2",
    "semantic_title": "object-centric relational representations for image generation",
    "citation_count": 0,
    "authors": [
      "Luca Butera",
      "Andrea Cini",
      "Alberto Ferrante",
      "Cesare Alippi"
    ]
  },
  "https://openreview.net/forum?id=abfi5plvQ4": {
    "title": "SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation",
    "volume": "main",
    "abstract": "Permutation-invariant diffusion models of graphs achieve the invariant sampling and invariant loss functions by restricting architecture designs, which often sacrifice empirical performances. In this work, we first show that the performance degradation may also be contributed by the increasing modes of target distributions brought by invariant architectures since 1) the optimal one-step denoising scores are score functions of Gaussian mixtures models (GMMs) whose components center on these modes and 2) learning the scores of GMMs with more components is often harder. Motivated by the analysis, we propose SwinGNN along with a simple yet provable trick that enables permutation-invariant sampling. It benefits from more flexible (non-invariant) architecture designs and permutation-invariant sampling. We further design an efficient 2-WL message passing network using the shifted-window self-attention. Extensive experiments on synthetic and real-world protein and molecule datasets show that SwinGNN outperforms existing methods by a substantial margin on most metrics. Our code is released at https://github.com/qiyan98/SwinGNN",
    "checked": null,
    "id": "7e243fd3fc349ff9fc7c3011543823645ac25ed6",
    "semantic_title": "swingnn: rethinking permutation invariance in diffusion models for graph generation",
    "citation_count": 18,
    "authors": [
      "Qi Yan",
      "Zhengyang Liang",
      "Yang Song",
      "Renjie Liao",
      "Lele Wang"
    ]
  },
  "https://openreview.net/forum?id=xDTKRLyaNN": {
    "title": "AGALE: A Graph-Aware Continual Learning Evaluation Framework",
    "volume": "main",
    "abstract": "In recent years, continual learning (CL) techniques have made significant progress in learning from streaming data while preserving knowledge across sequential tasks, particularly in the realm of euclidean data. To foster fair evaluation and recognize challenges in CL settings, several evaluation frameworks have been proposed, focusing mainly on the single- and multi-label classification task on euclidean data. However, these evaluation frameworks are not trivially applicable when the input data is graph-structured, as they do not consider the topological structure inherent in graphs. Existing continual graph learning (CGL) evaluation frameworks have predominantly focussed on single-label scenarios in the node classification (NC) task. This focus has overlooked the complexities of multi-label scenarios, where nodes may exhibit affiliations with multiple labels, simultaneously participating in multiple tasks. We develop a graph-aware evaluation (AGALE) framework that accommodates both single-labeled and multi-labeled nodes, addressing the limitations of previous evaluation frameworks. In particular, we define new incremental settings and devise data partitioning algorithms tailored to CGL datasets. We perform extensive experiments comparing methods from the domains of continual learning, continual graph learning, and dynamic graph learning (DGL). We theoretically analyze \\agale and provide new insights about the role of homophily in the performance of compared methods. We release our framework at https://github.com/Tianqi-py/AGALE",
    "checked": null,
    "id": "190f9507c4e6e1640955f5fc1eabc1a0932e1899",
    "semantic_title": "agale: a graph-aware continual learning evaluation framework",
    "citation_count": 1,
    "authors": [
      "Tianqi Zhao",
      "Alan Hanjalic",
      "Megha Khosla"
    ]
  },
  "https://openreview.net/forum?id=fdyHzoGT8g": {
    "title": "Depth Scaling in Graph Neural Networks: Understanding the Flat Curve Behavior",
    "volume": "main",
    "abstract": "Training deep Graph Neural Networks (GNNs) has proved to be a challenging task. A key goal of many new GNN architectures is to enable the depth scaling seen in other types of deep learning models. However, unlike deep learning methods in other domains, deep GNNs do not show significant performance boosts when compared to their shallow counterparts (resulting in a flat curve of performance over depth). In this work, we investigate some of the reasons why this goal of depth still eludes GNN researchers. We also question the effectiveness of current methods to train deep GNNs and show evidence of different types of pathological behavior in these networks. Our results suggest that current approaches hide the problems with deep GNNs rather than solve them, as current deep GNNs are only as discriminative as their respective shallow versions",
    "checked": null,
    "id": "a76748586e27f86d8f0c6441087b3d413ee30dff",
    "semantic_title": "depth scaling in graph neural networks: understanding the flat curve behavior",
    "citation_count": 1,
    "authors": [
      "Diana Gomes",
      "Kyriakos Efthymiadis",
      "Ann Nowe",
      "Peter Vrancx"
    ]
  },
  "https://openreview.net/forum?id=RZPN8cgqST": {
    "title": "InduCE: Inductive Counterfactual Explanations for Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) drive several real-world applications including drug-discovery, recommendation engines, and chip designing. Unfortunately, GNNs are a black-box since they do not allow human-intelligible explanations of their predictions. Counterfactual reasoning is an effort to overcome this limitation. Specifically, the objective is to minimally perturb the input graph to a GNN, so that its prediction changes. While several algorithms have been proposed towards counterfactual explanations of GNNs, majority suffer from three key limitations: (1) they only consider perturbations in the form of deletions of existing edges, (2) they perform an inefficient exploration of the combinatorial search space, (3) the counterfactual explanation model is transductive in nature, i.e., they do not generalize to unseen data. In this work, we propose an inductive algorithm called InduCE, that overcomes these limitations. Through extensive experiments on graph datasets, we show that incorporating edge additions, and modelling marginal effect of perturbations aid in generating better counterfactuals among available recourse. Furthermore, inductive modeling enables InduCE to directly predict counterfactual perturbations without requiring instance-specific training. This leads to significant computational speed-up over baselines and allows counterfactual analyses for GNNs at scale",
    "checked": null,
    "id": "059b45e666b9105a659df3771fd6e6800a507206",
    "semantic_title": "induce: inductive counterfactual explanations for graph neural networks",
    "citation_count": 2,
    "authors": [
      "Samidha Verma",
      "Burouj Armgaan",
      "Sourav Medya",
      "Sayan Ranu"
    ]
  },
  "https://openreview.net/forum?id=N0Sc0KY0AH": {
    "title": "Improving Subgraph-GNNs via Edge-Level Ego-Network Encodings",
    "volume": "main",
    "abstract": "We present a novel edge-level ego-network encoding for learning on graphs that can boost Message Passing Graph Neural Networks (MP-GNNs) by providing additional node and edge features or extending message-passing formats. The proposed encoding is sufficient to distinguish Strongly Regular Graphs, a family of challenging 3-WL equivalent graphs. We show theoretically that such encoding is more expressive than node-based sub-graph MP-GNNs. In an empirical evaluation on four benchmarks with 10 graph datasets, our results match or improve previous baselines on expressivity, graph classification, graph regression, and proximity tasks---while reducing memory usage by 18.1x in certain real-world settings",
    "checked": null,
    "id": "c22a2ef9512c3e47d79744bab70861f2ebe0a5e3",
    "semantic_title": "improving subgraph-gnns via edge-level ego-network encodings",
    "citation_count": 2,
    "authors": [
      "Nurudin Alvarez-Gonzalez",
      "Andreas Kaltenbrunner",
      "VicenÃ§ GÃ³mez"
    ]
  },
  "https://openreview.net/forum?id=HSQTv3R8Iz": {
    "title": "A True-to-the-model Axiomatic Benchmark for Graph-based Explainers",
    "volume": "main",
    "abstract": "Regulators, researchers, and practitioners recognize the urgency of explainability in artificial intelligence systems, including the ones based on machine learning for graph-structured data. Despite the large number of proposals, however, a common understanding of what constitutes a good explanation is still lacking: different explainers often arrive at different conclusions on the same problem instance, making it hard for practitioners to choose among them. Furthermore, explainers often produce explanations through opaque logic hard to understand and assess -- ironically mirroring the black box nature they aim to elucidate. Recent proposals in the literature for benchmarking graph-based explainers typically involve embedding specific logic into data, training a black-box model, and then empirically assessing how well the explanation matches the embedded logic, i.e., they test truthfulness to the data. In contrast, we propose a true-to-the-model axiomatic framework for auditing explainers in the task of node classification on graphs. Our proposal hinges on the fundamental idea that an explainer should discern if a model relies on a particular feature for classifying a node. Building on this concept, we develop three types of white-box classifiers, with clear internal logic, that are relevant in real-world applications. We then formally prove that the set of features that can induce a change in the classification correctly corresponds to a ground-truth set of predefined important features. This property allows us to use the white-box classifiers to build a testing framework. We apply this framework to both synthetic and real data and evaluate various state-of-the-art explainers, thus characterizing their behavior. Our findings highlight how explainers often react in a rather counter-intuitive fashion to technical details that might be easily overlooked. Our approach offers valuable insights and recommended practices for selecting the right explainer given the task at hand, and for developing new methods for explaining graph-learning models",
    "checked": null,
    "id": "773bb2a832db8eb52aa91df313af192dfa55dffd",
    "semantic_title": "a true-to-the-model axiomatic benchmark for graph-based explainers",
    "citation_count": 1,
    "authors": [
      "Corrado Monti",
      "Paolo Bajardi",
      "Francesco Bonchi",
      "AndrÃ© Panisson",
      "Alan Perotti"
    ]
  },
  "https://openreview.net/forum?id=KJRoQvRWNs": {
    "title": "How does over-squashing affect the power of GNNs?",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). While understanding the expressive power of MPNNs is a key question, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of *pairwise interactions* between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be large enough, depending on properties of the input graph structure, such as commute times. For many relevant scenarios, our analysis results in impossibility statements in practice, showing that *over-squashing hinders the expressive power of MPNNs*. Our theory also holds for geometric graphs and hence extends to equivariant MPNNs on point clouds. We validate our analysis through extensive controlled experiments and ablation studies",
    "checked": null,
    "id": "dc8f407e9eae9ff2383c4d6d8325bbf9d5c6a5b0",
    "semantic_title": "how does over-squashing affect the power of gnns?",
    "citation_count": 38,
    "authors": [
      "Francesco Di Giovanni",
      "T. Konstantin Rusch",
      "Michael Bronstein",
      "Andreea Deac",
      "Marc Lackenby",
      "Siddhartha Mishra",
      "Petar VeliÄkoviÄ"
    ]
  },
  "https://openreview.net/forum?id=dltUedmUVT": {
    "title": "Temporal Difference Learning with Compressed Updates: Error-Feedback meets Reinforcement Learning",
    "volume": "main",
    "abstract": "In large-scale distributed machine learning, recent works have studied the effects of compressing gradients in stochastic optimization to alleviate the communication bottleneck. These works have collectively revealed that stochastic gradient descent (SGD) is robust to structured perturbations such as quantization, sparsification, and delays. Perhaps surprisingly, despite the surge of interest in multi-agent reinforcement learning, almost nothing is known about the analogous question: \\textit{Are common reinforcement learning (RL) algorithms also robust to similar perturbations?} We investigate this question by studying a variant of the classical temporal difference (TD) learning algorithm with a perturbed update direction, where a general compression operator is used to model the perturbation. Our work makes three important technical contributions. First, we prove that compressed TD algorithms, coupled with an error-feedback mechanism used widely in optimization, exhibit the same non-asymptotic theoretical guarantees as their SGD counterparts. Second, we show that our analysis framework extends seamlessly to nonlinear stochastic approximation schemes that subsume Q-learning. Third, we prove that for multi-agent TD learning, one can achieve linear convergence speedups with respect to the number of agents while communicating just $\\tilde{O}(1)$ bits per iteration. Notably, these are the first finite-time results in RL that account for general compression operators and error-feedback in tandem with linear function approximation and Markovian sampling. Our proofs hinge on the construction of novel Lyapunov functions that capture the dynamics of a memory variable introduced by error-feedback",
    "checked": null,
    "id": "a58ea65258e4c3569cd02d2038246b2b8720bf1d",
    "semantic_title": "temporal difference learning with compressed updates: error-feedback meets reinforcement learning",
    "citation_count": 12,
    "authors": [
      "Aritra Mitra",
      "George J. Pappas",
      "Hamed Hassani"
    ]
  },
  "https://openreview.net/forum?id=iA2KQyoun1": {
    "title": "Granger Causal Interaction Skill Chains",
    "volume": "main",
    "abstract": "Reinforcement Learning (RL) has demonstrated promising results in learning policies for complex tasks, but it often suffers from low sample efficiency and limited transferability. Hierarchical RL (HRL) methods aim to address the difficulty of learning long-horizon tasks by decomposing policies into skills, abstracting states, and reusing skills in new tasks. However, many HRL methods require some initial task success to discover useful skills, which paradoxically may be very unlikely without access to useful skills. On the other hand, reward-free HRL methods often need to learn far too many skills to achieve proper coverage in high-dimensional domains. In contrast, we introduce the Chain of Interaction Skills (COInS) algorithm, which focuses on \\textit{controllability} in factored domains to identify a small number of task-agnostic skills that allow for a high degree of control of the factored state. COInS uses learned detectors to identify interactions between state factors and then trains a chain of skills to control each of these factors successively. We evaluate COInS on a robotic pushing task with obstaclesâa challenging domain where other RL and HRL methods fall short. We also demonstrate the transferability of skills learned by COInS, using variants of Breakout, a common RL benchmark, and show 2-3x improvement in both sample efficiency and final performance compared to standard RL baselines",
    "checked": null,
    "id": "d324e77123e9d5cfdeeb6f9172a76be2713910b4",
    "semantic_title": "granger causal interaction skill chains",
    "citation_count": 1,
    "authors": [
      "Caleb Chuck",
      "Kevin Black",
      "Aditya Arjun",
      "Yuke Zhu",
      "Scott Niekum"
    ]
  },
  "https://openreview.net/forum?id=hpKJkVoThY": {
    "title": "Models of human preference for learning reward functions",
    "volume": "main",
    "abstract": "The utility of reinforcement learning is limited by the alignment of reward functions with the interests of human stakeholders. One promising method for alignment is to learn the reward function from human-generated preferences between pairs of trajectory segments, a type of reinforcement learning from human feedback (RLHF). These human preferences are typically assumed to be informed solely by partial return, the sum of rewards along each segment. We find this assumption to be flawed and propose modeling human preferences instead as informed by each segment's regret, a measure of a segment's deviation from optimal decision-making. Given infinitely many preferences generated according to regret, we prove that we can identify a reward function equivalent to the reward function that generated those preferences, and we prove that the previous partial return model lacks this identifiability property in multiple contexts. We empirically show that our proposed regret preference model outperforms the partial return preference model with finite training data in otherwise the same setting. Additionally, we find that our proposed regret preference model better predicts real human preferences and also learns reward functions from these preferences that lead to policies that are better human-aligned. Overall, this work establishes that the choice of preference model is impactful, and our proposed regret preference model provides an improvement upon a core assumption of recent research. We have open sourced our experimental code, the human preferences dataset we gathered, and our training and preference elicitation interfaces for gathering such a dataset",
    "checked": null,
    "id": "9f9b61e429e85e37d6df0e3c478a074f7e6cb9fc",
    "semantic_title": "models of human preference for learning reward functions",
    "citation_count": 50,
    "authors": [
      "W. Bradley Knox",
      "Stephane Hatgis-Kessell",
      "Serena Booth",
      "Scott Niekum",
      "Peter Stone",
      "Alessandro G Allievi"
    ]
  },
  "https://openreview.net/forum?id=axBIMcGZn9": {
    "title": "Continual Learning: Applications and the Road Forward",
    "volume": "main",
    "abstract": "Continual learning is a subfield of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: \"Why should one care about continual learning in the first place?\". We set the stage by examining recent continual learning papers published at four major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they might seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model editing, personalization and specialization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023",
    "checked": null,
    "id": "3d7e5485fae2965ddf081dc64be6ab52f5834cf8",
    "semantic_title": "continual learning: applications and the road forward",
    "citation_count": 47,
    "authors": [
      "Eli Verwimp",
      "Rahaf Aljundi",
      "Shai Ben-David",
      "Matthias Bethge",
      "Andrea Cossu",
      "Alexander Gepperth",
      "Tyler L. Hayes",
      "Eyke HÃ¼llermeier",
      "Christopher Kanan",
      "Dhireesha Kudithipudi",
      "Christoph H. Lampert",
      "Martin Mundt",
      "Razvan Pascanu",
      "Adrian Popescu",
      "Andreas S. Tolias",
      "Joost van de Weijer",
      "Bing Liu",
      "Vincenzo Lomonaco",
      "Tinne Tuytelaars",
      "Gido M van de Ven"
    ]
  },
  "https://openreview.net/forum?id=cAthubStyG": {
    "title": "AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks",
    "volume": "main",
    "abstract": "The fields of both Natural Language Processing (NLP) and Automated Machine Learning (AutoML) have achieved remarkable results over the past years. In NLP, especially Large Language Models (LLMs) have experienced a rapid series of breakthroughs very recently. We envision that the two fields can radically push the boundaries of each other through tight integration. To showcase this vision, we explore the potential of a symbiotic relationship between AutoML and LLMs, shedding light on how they can benefit each other. In particular, we investigate both the opportunities to enhance AutoML approaches with LLMs from different perspectives and the challenges of leveraging AutoML to further improve LLMs. To this end, we survey existing work, and we critically assess risks. We strongly believe that the integration of the two fields has the potential to disrupt both fields, NLP and AutoML. By highlighting conceivable synergies, but also risks, we aim to foster further exploration at the intersection of AutoML and LLMs",
    "checked": null,
    "id": "9afa0c3227fd0ec3a76928784e59c4205cbace24",
    "semantic_title": "automl in the age of large language models: current challenges, future opportunities and risks",
    "citation_count": 24,
    "authors": [
      "Alexander Tornede",
      "Difan Deng",
      "Theresa Eimer",
      "Joseph Giovanelli",
      "Aditya Mohan",
      "Tim Ruhkopf",
      "Sarah Segel",
      "Daphne Theodorakopoulos",
      "Tanja Tornede",
      "Henning Wachsmuth",
      "Marius Lindauer"
    ]
  },
  "https://openreview.net/forum?id=g01OVahtN9": {
    "title": "Controlling Federated Learning for Covertness",
    "volume": "main",
    "abstract": "A learner aims to minimize a function $f$ by repeatedly querying a distributed oracle that provides noisy gradient evaluations. At the same time, the learner seeks to hide $\\arg\\min f$ from a malicious eavesdropper that observes the learner's queries. This paper considers the problem of \\textit{covert} or \\textit{learner-private} optimization, where the learner has to dynamically choose between learning and obfuscation by exploiting the stochasticity. The problem of controlling the stochastic gradient algorithm for covert optimization is modeled as a Markov decision process, and we show that the dynamic programming operator has a supermodular structure implying that the optimal policy has a monotone threshold structure. A computationally efficient policy gradient algorithm is proposed to search for the optimal querying policy without knowledge of the transition probabilities. As a practical application, our methods are demonstrated on a hate speech classification task in a federated setting where an eavesdropper can use the optimal weights to generate toxic content, which is more easily misclassified. Numerical results show that when the learner uses the optimal policy, an eavesdropper can only achieve a validation accuracy of $52\\%$ with no information and $69\\%$ when it has a public dataset with $10\\%$ positive samples compared to $83\\%$ when the learner employs a greedy policy",
    "checked": null,
    "id": "2a864f9dbd52e8965818cce75b2b51fecc6d47f4",
    "semantic_title": "controlling federated learning for covertness",
    "citation_count": 6,
    "authors": [
      "Adit Jain",
      "Vikram Krishnamurthy"
    ]
  },
  "https://openreview.net/forum?id=TYYApLzjaQ": {
    "title": "Unmasking the Veil: An Investigation into Concept Ablation for Privacy and Copyright Protection in Images",
    "volume": "main",
    "abstract": "In this paper, we extend the study of concept ablation within pre-trained models as introduced in 'Ablating Concepts in Text-to-Image Diffusion Models' by $\\citep{Kumari2022}$. Our work focuses on reproducing the results achieved by the different variants of concept ablation proposed through predefined metrics. We also introduce a novel variant of concept ablationâtrademark ablation. This variant combines the principles of memorization and instance ablation to tackle the nuanced influence of proprietary or branded elements in model outputs. Further, our research contributions include an observational analysis of the model's limitations. Moreover, we investigate the model's behavior in response to ablation leakage-inducing prompts, which aim to indirectly ablate concepts, revealing insights into the model's resilience and adaptability. We also observe the model's performance degradation on images generated by concepts far from its target ablation concept, which is documented in the appendix",
    "checked": null,
    "id": "f81a1ef3154346be192588637105974766464060",
    "semantic_title": "unmasking the veil: an investigation into concept ablation for privacy and copyright protection in images",
    "citation_count": 2,
    "authors": [
      "Shivank Garg",
      "Manyana Tiwari"
    ]
  },
  "https://openreview.net/forum?id=d3Vj360Wi2": {
    "title": "Reproducibility Study of \"ITI-GEN: Inclusive Text-to-Image Generation",
    "volume": "main",
    "abstract": "Text-to-image generative models often present issues regarding fairness with respect to certain sensitive attributes, such as gender or skin tone. This study aims to reproduce the results presented in \"ITI-GEN: Inclusive Text-to-Image Generation\" by Zhang et al. (2023), which introduces a model to improve inclusiveness in these kinds of models. We show that most of the claims made by the authors about ITI-GEN hold: it improves the diversity and quality of generated images, it is scalable to different domains, it has plug-and-play capabilities, and it is efficient from a computational point of view. However, ITI-GEN sometimes uses undesired attributes as proxy features and it is unable to disentangle some pairs of (correlated) attributes such as gender and baldness. In addition, when the number of considered attributes increases, the training time grows exponentially and ITI-GEN struggles to generate inclusive images for all elements in the joint distribution. To solve these issues, we propose using Hard Prompt Search with negative prompting, a method that does not require training and that handles negation better than vanilla Hard Prompt Search. Nonetheless, Hard Prompt Search (with or without negative prompting) cannot be used for continuous attributes that are hard to express in natural language, an area where ITI-GEN excels as it is guided by images during training. Finally, we propose combining ITI-GEN and Hard Prompt Search with negative prompting",
    "checked": null,
    "id": "54cfe67fb02467fbf45b24f8ce1caa34728cde30",
    "semantic_title": "reproducibility study of \"iti-gen: inclusive text-to-image generation",
    "citation_count": 0,
    "authors": [
      "Daniel Gallo FernÃ¡ndez",
      "RÄzvan-Andrei MatiÈan",
      "Alejandro Monroy MuÃ±oz",
      "Janusz Partyka"
    ]
  },
  "https://openreview.net/forum?id=ccDi5jtSF7": {
    "title": "Reproducibility study of FairAC",
    "volume": "main",
    "abstract": "This work aims to reproduce the findings of the paper \"Fair Attribute Completion on Graph with Missing Attributes\" written by Guo et al. (2023) by investigating the claims made in the paper. This paper suggests that the results of the original paper are reproducible and thus, the claims hold. However, the claim that FairAC is a generic framework for many downstream tasks is very broad and could therefore only be partially tested. Moreover, we show that FairAC is generalizable to various datasets and sensitive attributes and show evidence that the improvement in group fairness of the FairAC framework does not come at the expense of individual fairness. Lastly, the codebase of FairAC has been refactored and is now easily applicable for various datasets and models",
    "checked": null,
    "id": "24a348dfaf029a87e10bb46eb8c3ab6dd54197a3",
    "semantic_title": "reproducibility study of fairac",
    "citation_count": 0,
    "authors": [
      "Gijs de Jong",
      "Macha J. Meijer",
      "Derck W. E. Prinzhorn",
      "Harold Ruiter"
    ]
  },
  "https://openreview.net/forum?id=Wm6d44I8St": {
    "title": "[Re] CUDA: Curriculum of Data Augmentation for Longâtailed Recognition",
    "volume": "main",
    "abstract": "In this reproducibility study, we present our results and experience during replicating the paper, titled CUDA: Curriculum of Data Augmentation for Long-Tailed Recognition(Ahn et al., 2023).Traditional datasets used in image recognition, such as ImageNet, are often synthetically balanced, meaning each class has an equal number of samples. In practical scenarios, datasets frequently exhibit significant class imbalances, with certain classes having a disproportionately larger number of samples compared to others. This discrepancy poses a challenge for traditional image recognition models, as they tend to favor classes with larger sample sizes, leading to poor performance on minority classes. CUDA proposes a class-wise data augmentation technique which can be used over any existing model to improve the accuracy for LTR: Long Tailed Recognition. We successfully replicated all of the results pertaining to the long-tailed CIFAR-100-LT dataset and extended our analysis to provide deeper insights into how CUDA efficiently tackles class imbalance. The code and the readings are available in https://anonymous.4open.science/r/CUDA-org--C2FD/README.md",
    "checked": null,
    "id": "1e6c5ebf8d03eacc501fd344531e9a25b139e504",
    "semantic_title": "[re] cuda: curriculum of data augmentation for long-tailed recognition",
    "citation_count": 5,
    "authors": [
      "Barath Chandran.C"
    ]
  },
  "https://openreview.net/forum?id=9M2XqvH2SB": {
    "title": "[Re] Reproducibility Study of \"Explaining Temporal Graph Models Through an Explorer-Navigator Framework",
    "volume": "main",
    "abstract": "This paper seeks to reproduce and extend the results of the paper \"Explaining Temporal Graph Models Through an Explorer-Navigator Framework\" by (Xia et al., 2023). The main contribution of the original authors is a novel explainer for temporal graph networks, the Temporal GNN Explainer (T-GNNExplainer), which finds a subset of preceding events that \"explain\" a prediction made by a temporal graph model. The explorer is tested on two temporal graph models that are trained on two real-world and two synthetic datasets. The explorer is evaluated using a newly proposed metric for explanatory graph models. The authors compare the performance of their explorer to three baseline explainer methods, either adapted from a GNN explainer or developed by the authors. The authors claim that T-GNNExplainer achieves superior performance compared to the baselines when evaluated with their proposed metric. This work reproduces the original experiments by using the code (with minor adjustments), model specifications, and hyperparameters provided by the original authors. To evaluate the robustness of these claims, the method was extended to one new dataset (MOOC). Results show that the T-GNNexplainer performs best on some, but not all metrics as reported in the original findings. We conclude that the main lines of this paper hold up even though all results are less pronounced than claimed. Results show that the T-GNNExplainer does not perform similarly across different T-GNN models, precise dataset specifications are needed to obtain high performance, and there are simpler, less computationally costly explainer methods (like PBONE) that could offer competitive results",
    "checked": null,
    "id": "5b58f532809ef51513f5e8c27e349abc5710a7f6",
    "semantic_title": "[re] reproducibility study of \"explaining temporal graph models through an explorer-navigator framework",
    "citation_count": 0,
    "authors": [
      "Helia Ghasemi",
      "Christina Isaicu",
      "Jesse Wonnink",
      "Andreas Berentzen"
    ]
  },
  "https://openreview.net/forum?id=8cYcR23WUo": {
    "title": "[Re] GNNInterpreter: A probabilistic generative model-level explanation for Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph Neural Networks have recently gained recognition for their performance on graph machine learning tasks. The increasing attention on these models' trustworthiness and decision-making mechanisms has instilled interest in the exploration of explainability tech- niques, including the model proposed in \"GNNInterpreter: A probabilistic generative model- level explanation for Graph Neural Networks.\" (Wang & Shen (2022)). This work aims to reproduce the findings of the original paper, by investigation the main claims made by its authors, namely that GNNInterpreter (i) generates faithful and realistic explanations with- out requiring domain-specific knowledge, (ii) has the ability to work with various node and edge features, (iii) produces explanations that are representative for the target class and (iv) has a much lower training time compared to XGNN, the current state-of-the-art model- level GNN explanation technique. To reproduce the results, we make use of the open-source implementation and we test the interpreter on the same datasets and GNN models as in the original paper. We conduct an enhanced quantitative and qualitative evaluation, and additionally we extend the original experiments to include another real-world dataset. Our results show that we are not able to validate the first claim, due to significant hyperpa- rameter and seed variation, as well as due to training instability. Furthermore, we partially validate the second claim by testing on datasets with different node and edge features, but we reject the third claim due to GNNInterpreter's failure to outperform XGNN in producing dataset aligned explanations. Lastly, we are able to confirm the last claim",
    "checked": null,
    "id": "f0f69efbd5dd3ea955f8fa62086640c9387b1a57",
    "semantic_title": "[re] gnninterpreter: a probabilistic generative model-level explanation for graph neural networks",
    "citation_count": 1,
    "authors": [
      "Ana Vasilcoiu",
      "T.H.F. Stessen",
      "Thies Kersten",
      "Batu Helvacioglu"
    ]
  },
  "https://openreview.net/forum?id=FI1XvwpchC": {
    "title": "[Re] Explaining Temporal Graph Models through an Explorer-Navigator Framework",
    "volume": "main",
    "abstract": "Temporal graphs model complex dynamic relations that change over time, and are being used in a growing number of applications. In recent years, several graph neural networks (GNNs) were proposed, designed specifically for this temporal setting (Xu et al., 2020; Rossi et al., 2020). However, these models are notoriously hard to interpret. For this reason, the original authors (Xia et al., 2023) propose the Temporal GNN Explainer (T-GNNExplainer) â an explorer-navigator framework to efficiently compute sparse explanations of target Temporal GNNs. We reproduce the main findings of the original paper, extend their work by proposing a different type of navigator method, and examine in detail the explanation capabilities and efficiency of the provided framework within various model and hyperparameter settings. We confirm that their explainer outperforms the other baselines across nearly all datasets and metrics. Our findings suggest the navigator helps bias the search process, as well as that T-GNNExplainer can find an exact influential event set. Moreover, we examine the effect of different navigator methods and quantify the runtime-fidelity tradeoff controlled by two hyper-parameters",
    "checked": null,
    "id": "6cdbd0c38baca989d257d803b85bf487bb05b7b8",
    "semantic_title": "[re] explaining temporal graph models through an explorer-navigator framework",
    "citation_count": 2,
    "authors": [
      "MiklÃ³s Hamar",
      "Matey Krastev",
      "Kristiyan Danielov Hristov",
      "David Beglou"
    ]
  },
  "https://openreview.net/forum?id=8UfhCZjOV7": {
    "title": "[Re] On the Reproducibility of Post-Hoc Concept Bottleneck Models",
    "volume": "main",
    "abstract": "To obtain state-of-the-art performance, many deeper artificial intelligence models sacrifice human explainability in their decision-making. One solution proposed for achieving top performance and retaining explainability is the Post-Hoc Concept Bottleneck Model (PCBM) (Yuksekgonul et al., 2023), which can convert the embeddings of any deep neural network into a set of human-interpretable concept weights. In this work, we reproduce and expand upon the findings of Yuksekgonul et al. (2023). Our results show that while most of the authors' claims and results hold, some of the results they obtained could not be sufficiently replicated. Specifically, the claims relating to PCBM performance preservation and its non-requirement of labeled concept datasets were generally reproduced, whereas the one claiming its model editing capabilities was not. Beyond these results, our contributions to their work include evidence that PCBMs may work for audio classification problems, verification of the interpretability of their methods, and updates to their code for missing implementations. The code for our implementations can be found at https://github.com/dgcnz/FACT",
    "checked": null,
    "id": "9be1a1ad73aa42bef615507bc49617893cbb4346",
    "semantic_title": "[re] on the reproducibility of post-hoc concept bottleneck models",
    "citation_count": 2,
    "authors": [
      "Nesta Midavaine",
      "Gregory Hok Tjoan Go",
      "Diego Canez",
      "Ioana Simion",
      "Satchit Chatterji"
    ]
  },
  "https://openreview.net/forum?id=JQoWmeNaC2": {
    "title": "Reproducibility Study of \"Explaining RL Decisions with Trajectories",
    "volume": "main",
    "abstract": "This paper reports on the reproducibility study on the paper `Explaining RL Decisions with Trajectories' by Deshmukh et al. (2023). The authors proposed a method to elucidate the decisions of an offline RL agent by attributing them to clusters of trajectories encountered during training. The original paper explored various environments and conducted a human study to gauge real-world performance. Our objective is to validate the effectiveness of their proposed approach. This paper conducted quantitative and qualitative experiments across three environments: a Grid-world, an Atari video game (Seaquest), and a continuous control task from MuJoCo (HalfCheetah). While the authors provided the code for the Grid-world environment, we re-implemented it for the Seaquest and HalfCheetah environments. This work extends the original paper by including trajectory rankings within a cluster, experimenting with alternative trajectory clustering, and expanding the human study. The results affirm the effectiveness of the method, both in its reproduction and in the additional experiments. However, the results of the human study suggest that the method's explanations are more challenging to interpret for humans in more complex environments. Our implementations can be found on GitHub",
    "checked": null,
    "id": "b444f3471e4027eac47211b77437a97af067820c",
    "semantic_title": "reproducibility study of \"explaining rl decisions with trajectories",
    "citation_count": 0,
    "authors": [
      "Clio Feng",
      "Colin Bot",
      "Bart den Boef",
      "Bart Aaldering"
    ]
  }
}